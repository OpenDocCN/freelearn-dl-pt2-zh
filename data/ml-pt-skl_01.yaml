- en: '1'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '1'
- en: Giving Computers the Ability to Learn from Data
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 赋予计算机从数据中学习的能力
- en: In my opinion, **machine learning**, the application and science of algorithms
    that make sense of data, is the most exciting field of all the computer sciences!
    We are living in an age where data comes in abundance; using self-learning algorithms
    from the field of machine learning, we can turn this data into knowledge. Thanks
    to the many powerful open-source libraries that have been developed in recent
    years, there has probably never been a better time to break into the machine learning
    field and learn how to utilize powerful algorithms to spot patterns in data and
    make predictions about future events.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在我看来，**机器学习**，即利用算法理解数据的应用与科学，是所有计算机科学领域中最激动人心的领域！我们生活在一个数据丰富的时代；利用来自机器学习领域的自学习算法，我们可以将这些数据转化为知识。多亏了近年来开发的许多强大开源库，现在可能是进入机器学习领域并学习如何利用强大算法来识别数据模式并对未来事件进行预测的最佳时机。
- en: In this chapter, you will learn about the main concepts and different types
    of machine learning. Together with a basic introduction to the relevant terminology,
    we will lay the groundwork for successfully using machine learning techniques
    for practical problem solving.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将了解主要概念和不同类型的机器学习。与相关术语的基本介绍一起，我们将为成功利用机器学习技术解决实际问题奠定基础。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: The general concepts of machine learning
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习的一般概念
- en: The three types of learning and basic terminology
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 三种学习类型和基本术语
- en: The building blocks for successfully designing machine learning systems
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 成功设计机器学习系统的构建模块
- en: Installing and setting up Python for data analysis and machine learning
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装和设置Python进行数据分析和机器学习
- en: Building intelligent machines to transform data into knowledge
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建智能机器以将数据转化为知识
- en: 'In this age of modern technology, there is one resource that we have in abundance:
    a large amount of structured and unstructured data. In the second half of the
    20th century, machine learning evolved as a subfield of **artificial intelligence**
    (**AI**) involving self-learning algorithms that derive knowledge from data to
    make predictions.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在现代技术时代，我们拥有大量结构化和非结构化数据资源。在20世纪下半叶，**人工智能**（**AI**）的一个子领域——机器学习，作为自学习算法的一部分，通过从数据中获取知识来进行预测逐渐发展起来。
- en: Instead of requiring humans to manually derive rules and build models from analyzing
    large amounts of data, machine learning offers a more efficient alternative for
    capturing the knowledge in data to gradually improve the performance of predictive
    models and make data-driven decisions.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 与要求人类手动推导规则并从分析大量数据中构建模型相比，机器学习提供了更高效的选择，即从数据中提取知识以逐步改进预测模型的性能并做出数据驱动的决策。
- en: Not only is machine learning becoming increasingly important in computer science
    research, but it is also playing an ever-greater role in our everyday lives. Thanks
    to machine learning, we enjoy robust email spam filters, convenient text and voice
    recognition software, reliable web search engines, recommendations on entertaining
    movies to watch, mobile check deposits, estimated meal delivery times, and much
    more. Hopefully, soon, we will add safe and efficient self-driving cars to this
    list. Also, notable progress has been made in medical applications; for example,
    researchers demonstrated that deep learning models can detect skin cancer with
    near-human accuracy ([https://www.nature.com/articles/nature21056](https://www.nature.com/articles/nature21056)).
    Another milestone was recently achieved by researchers at DeepMind, who used deep
    learning to predict 3D protein structures, outperforming physics-based approaches
    by a substantial margin ([https://deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology](https://deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology)).
    While accurate 3D protein structure prediction plays an essential role in biological
    and pharmaceutical research, there have been many other important applications
    of machine learning in healthcare recently. For instance, researchers designed
    systems for predicting the oxygen needs of COVID-19 patients up to four days in
    advance to help hospitals allocate resources for those in need ([https://ai.facebook.com/blog/new-ai-research-to-help-predict-covid-19-resource-needs-from-a-series-of-x-rays/](https://ai.facebook.com/blog/new-ai-research-to-help-predict-covid-19-resource-needs-from-a-series-of-x-rays/)).
    Another important topic of our day and age is climate change, which presents one
    of the biggest and most critical challenges. Today, many efforts are being directed
    toward developing intelligent systems to combat it ([https://www.forbes.com/sites/robtoews/2021/06/20/these-are-the-startups-applying-ai-to-tackle-climate-change](https://www.forbes.com/sites/robtoews/2021/06/20/these-are-the-startups-applying-ai-to-tackle-climate-change)).
    One of the many approaches to tackling climate change is the emergent field of
    precision agriculture. Here, researchers aim to design computer vision-based machine
    learning systems to optimize resource deployment to minimize the use and waste
    of fertilizers.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习不仅在计算机科学研究中变得日益重要，而且在我们的日常生活中也扮演着越来越重要的角色。由于机器学习，我们享受到强大的电子邮件垃圾邮件过滤器，便捷的文本和语音识别软件，可靠的网络搜索引擎，推荐有趣电影观看，移动支票存款，估计送餐时间等服务。希望不久的将来，我们还将增加安全高效的自动驾驶汽车到这一列表中。在医疗应用方面也取得了显著进展；例如，研究人员证明深度学习模型可以以接近人类的准确度检测皮肤癌（[https://www.nature.com/articles/nature21056](https://www.nature.com/articles/nature21056)）。最近，DeepMind的研究人员使用深度学习预测了三维蛋白质结构，表现出色地超过了基于物理的方法（[https://deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology](https://deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology)）。准确的三维蛋白质结构预测在生物和制药研究中发挥着重要作用，最近在医疗保健领域中也有许多其他重要的机器学习应用。例如，研究人员设计了系统，可以预测COVID-19患者未来四天的氧需求，以帮助医院分配资源给需要的人群（[https://ai.facebook.com/blog/new-ai-research-to-help-predict-covid-19-resource-needs-from-a-series-of-x-rays/](https://ai.facebook.com/blog/new-ai-research-to-help-predict-covid-19-resource-needs-from-a-series-of-x-rays/)）。当今社会的另一个重要话题是气候变化，这是我们面临的最大和最关键的挑战之一。目前，许多工作致力于开发智能系统来应对气候变化（[https://www.forbes.com/sites/robtoews/2021/06/20/these-are-the-startups-applying-ai-to-tackle-climate-change](https://www.forbes.com/sites/robtoews/2021/06/20/these-are-the-startups-applying-ai-to-tackle-climate-change)）。解决气候变化的众多方法之一是精准农业的新兴领域。在这里，研究人员旨在设计基于计算机视觉的机器学习系统，优化资源配置，以最小化化肥的使用和浪费。
- en: The three different types of machine learning
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习的三种不同类型
- en: 'In this section, we will take a look at the three types of machine learning:
    **supervised learning**, **unsupervised learning**, and **reinforcement learning**.
    We will learn about the fundamental differences between the three different learning
    types and, using conceptual examples, we will develop an understanding of the
    practical problem domains where they can be applied:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将详细介绍三种机器学习类型：**监督学习**，**无监督学习**和**强化学习**。我们将了解这三种不同学习类型之间的基本差异，并使用概念示例来理解它们可以应用于的实际问题领域：
- en: '![Graphical user interface, text, application  Description automatically generated](img/B17582_01_01.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![图形用户界面，文本，应用 由自动生成描述](img/B17582_01_01.png)'
- en: 'Figure 1.1: The three different types of machine learning'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '图 1.1: 三种不同类型的机器学习'
- en: Making predictions about the future with supervised learning
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用监督学习对未来进行预测
- en: The main goal in supervised learning is to learn a model from labeled training
    data that allows us to make predictions about unseen or future data. Here, the
    term “supervised” refers to a set of training examples (data inputs) where the
    desired output signals (labels) are already known. Supervised learning is then
    the process of modeling the relationship between the data inputs and the labels.
    Thus, we can also think of supervised learning as “label learning.”
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 监督学习的主要目标是从带标签的训练数据中学习模型，使我们能够对未见过或将来的数据进行预测。在这里，“监督”一词指的是一组训练示例（数据输入），其中已知所需的输出信号（标签）。监督学习就是对数据输入和标签之间关系建模的过程。因此，我们也可以将监督学习看作是“标签学习”。
- en: '*Figure 1.2* summarizes a typical supervised learning workflow, where the labeled
    training data is passed to a machine learning algorithm for fitting a predictive
    model that can make predictions on new, unlabeled data inputs:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 1.2* 概述了典型的监督学习工作流程，其中标记的训练数据传递给机器学习算法，以拟合一个可以对新的未标记数据输入进行预测的预测模型：'
- en: '![Diagram  Description automatically generated](img/B17582_01_02.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![自动生成的图表描述](img/B17582_01_02.png)'
- en: 'Figure 1.2: Supervised learning process'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '图 1.2: 监督学习过程'
- en: Considering the example of email spam filtering, we can train a model using
    a supervised machine learning algorithm on a corpus of labeled emails, which are
    correctly marked as spam or non-spam, to predict whether a new email belongs to
    either of the two categories. A supervised learning task with discrete class labels,
    such as in the previous email spam filtering example, is also called a **classification
    task**. Another subcategory of supervised learning is **regression**, where the
    outcome signal is a continuous value.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑电子邮件垃圾邮件过滤的例子，我们可以使用监督机器学习算法在一组带标记的电子邮件上进行模型训练，这些电子邮件已正确标记为垃圾邮件或非垃圾邮件，以预测新电子邮件是否属于这两个类别之一。像前面的电子邮件垃圾邮件过滤例子中这样的监督学习任务，也被称为**分类任务**。监督学习的另一个子类是**回归**，在回归中，输出信号是连续值。
- en: Classification for predicting class labels
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 预测类标签的分类
- en: 'Classification is a subcategory of supervised learning where the goal is to
    predict the categorical class labels of new instances or data points based on
    past observations. Those class labels are discrete, unordered values that can
    be understood as the group memberships of the data points. The previously mentioned
    example of email spam detection represents a typical example of a binary classification
    task, where the machine learning algorithm learns a set of rules to distinguish
    between two possible classes: spam and non-spam emails.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 分类是监督学习的一个子类，其目标是根据过去的观察预测新实例或数据点的分类类标签。这些类标签是离散的、无序的值，可以理解为数据点的组成员资格。先前提到的电子邮件垃圾检测示例代表了二元分类任务的典型例子，其中机器学习算法学习一组规则来区分两个可能的类别：垃圾邮件和非垃圾邮件。
- en: '*Figure 1.3* illustrates the concept of a binary classification task given
    30 training examples; 15 training examples are labeled as class A and 15 training
    examples are labeled as class B. In this scenario, our dataset is two-dimensional,
    which means that each example has two values associated with it: *x*[1] and *x*[2].
    Now, we can use a supervised machine learning algorithm to learn a rule—the decision
    boundary represented as a dashed line—that can separate those two classes and
    classify new data into each of those two categories given its *x*[1] and *x*[2]
    values:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 1.3* 说明了一个二元分类任务的概念，给出了 30 个训练示例；其中 15 个训练示例标记为 A 类，15 个标记为 B 类。在这种情况下，我们的数据集是二维的，这意味着每个示例都与两个值相关联：*x*[1]
    和 *x*[2]。现在，我们可以使用监督机器学习算法学习一个规则——以虚线表示的决策边界，它可以分开这两个类，并根据其 *x*[1] 和 *x*[2] 值将新数据分类到这两个类别中：'
- en: '![](img/B17582_01_03.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17582_01_03.png)'
- en: 'Figure 1.3: Classifying a new data point'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '图 1.3: 分类新数据点'
- en: However, the set of class labels does not have to be of a binary nature. The
    predictive model learned by a supervised learning algorithm can assign any class
    label that was presented in the training dataset to a new, unlabeled data point
    or instance.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，类标签集合不必具有二进制性质。监督学习算法学习的预测模型可以将训练数据集中呈现的任何类标签分配给新的未标记数据点或实例。
- en: A typical example of a **multiclass classification** task is handwritten character
    recognition. We can collect a training dataset that consists of multiple handwritten
    examples of each letter in the alphabet. The letters (“A,” “B,” “C,” and so on)
    will represent the different unordered categories or class labels that we want
    to predict. Now, if a user provides a new handwritten character via an input device,
    our predictive model will be able to predict the correct letter in the alphabet
    with certain accuracy. However, our machine learning system will be unable to
    correctly recognize any of the digits between 0 and 9, for example, if they were
    not part of the training dataset.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '**多类分类**任务的典型例子是手写字符识别。我们可以收集一个训练数据集，其中包含每个字母在字母表中的多个手写示例。这些字母（“A”，“B”，“C”等）代表我们想要预测的不同无序类别或类标签。现在，如果用户通过输入设备提供了一个新的手写字符，我们的预测模型将能够以一定的准确率预测字母表中的正确字母。然而，如果这些数字不是训练数据集的一部分，例如，我们的机器学习系统将无法正确识别任何数字0到9中的任何一个。'
- en: Regression for predicting continuous outcomes
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 用于预测连续结果的回归
- en: We learned in the previous section that the task of classification is to assign
    categorical, unordered labels to instances. A second type of supervised learning
    is the prediction of continuous outcomes, which is also called **regression analysis**.
    In regression analysis, we are given a number of predictor (**explanatory**) variables
    and a continuous response variable (**outcome**), and we try to find a relationship
    between those variables that allows us to predict an outcome.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在前一节中学到，分类任务的目标是将无序标签分配给实例。监督学习的第二种类型是预测连续结果，也称为**回归分析**。在回归分析中，我们给定一些预测（解释）变量和一个连续的响应变量（结果），并试图找到这些变量之间的关系，以便预测结果。
- en: Note that in the field of machine learning, the predictor variables are commonly
    called “features,” and the response variables are usually referred to as “target
    variables.” We will adopt these conventions throughout this book.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在机器学习领域，预测变量通常被称为“特征”，响应变量通常被称为“目标变量”。我们将在本书中沿用这些约定。
- en: For example, let’s assume that we are interested in predicting the math SAT
    scores of students. (The SAT is a standardized test frequently used for college
    admissions in the United States.) If there is a relationship between the time
    spent studying for the test and the final scores, we could use it as training
    data to learn a model that uses the study time to predict the test scores of future
    students who are planning to take this test.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设我们有兴趣预测学生的数学 SAT 成绩。（SAT 是美国常用的大学入学标准化测试。）如果学习时间与最终成绩之间存在关系，我们可以将其作为训练数据，学习一个模型，该模型使用学习时间来预测计划参加该测试的未来学生的测试成绩。
- en: '**Regression toward the mean**'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**均值回归**'
- en: The term “regression” was devised by Francis Galton in his article *Regression
    towards Mediocrity in Hereditary Stature* in 1886\. Galton described the biological
    phenomenon that the variance of height in a population does not increase over
    time.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: “回归”一词由弗朗西斯·高尔顿在他的文章《遗传体质的中等回归》中于1886年创造。高尔顿描述了一个生物现象，即人群中身高的变异不会随时间增加。
- en: He observed that the height of parents is not passed on to their children, but
    instead, their children’s height regresses toward the population mean.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 他观察到父母的身高并不会传递给他们的孩子，而是他们孩子的身高会回归到人群的平均水平。
- en: '*Figure 1.4* illustrates the concept of linear regression. Given a feature
    variable, *x*, and a target variable, *y*, we fit a straight line to this data
    that minimizes the distance—most commonly the average squared distance—between
    the data points and the fitted line.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 1.4* 说明了线性回归的概念。给定一个特征变量 *x* 和一个目标变量 *y*，我们拟合一条直线到这些数据上，以最小化数据点与拟合线之间的距离——通常是平均平方距离。'
- en: 'We can now use the intercept and slope learned from this data to predict the
    target variable of new data:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以使用从这些数据中学到的截距和斜率来预测新数据的目标变量：
- en: '![Chart, scatter chart  Description automatically generated](img/B17582_01_04.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![图表，散点图 描述自动生成](img/B17582_01_04.png)'
- en: 'Figure 1.4: A linear regression example'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.4：线性回归示例
- en: Solving interactive problems with reinforcement learning
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用强化学习解决交互式问题
- en: Another type of machine learning is **reinforcement learning**. In reinforcement
    learning, the goal is to develop a system (**agent**) that improves its performance
    based on interactions with the environment. Since the information about the current
    state of the environment typically also includes a so-called **reward signal**,
    we can think of reinforcement learning as a field related to supervised learning.
    However, in reinforcement learning, this feedback is not the correct ground truth
    label or value, but a measure of how well the action was measured by a reward
    function. Through its interaction with the environment, an agent can then use
    reinforcement learning to learn a series of actions that maximizes this reward
    via an exploratory trial-and-error approach or deliberative planning.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种机器学习的类型是**强化学习**。在强化学习中，目标是开发一个系统（**代理**），通过与环境的互动来提高其性能。由于关于环境当前状态的信息通常还包括所谓的**奖励信号**，我们可以将强化学习看作与监督学习相关的领域。然而，在强化学习中，这种反馈不是正确的地面真实标签或值，而是一个衡量行动如何受奖励函数影响的度量。通过与环境的互动，代理可以利用强化学习来学习一系列通过探索性试错方法或审慎计划最大化此奖励的动作。
- en: 'A popular example of reinforcement learning is a chess program. Here, the agent
    decides upon a series of moves depending on the state of the board (the environment),
    and the reward can be defined as **win** or **lose** at the end of the game:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 强化学习的一个流行例子是象棋程序。在这里，代理根据棋盘的状态（环境）决定一系列动作，奖励可以定义为在比赛结束时**赢**或**输**：
- en: '![Diagram  Description automatically generated](img/B17582_01_05.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![Diagram  Description automatically generated](img/B17582_01_05.png)'
- en: 'Figure 1.5: Reinforcement learning process'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.5：强化学习过程
- en: There are many different subtypes of reinforcement learning. However, a general
    scheme is that the agent in reinforcement learning tries to maximize the reward
    through a series of interactions with the environment. Each state can be associated
    with a positive or negative reward, and a reward can be defined as accomplishing
    an overall goal, such as winning or losing a game of chess. For instance, in chess,
    the outcome of each move can be thought of as a different state of the environment.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 强化学习有许多不同的子类型。然而，一个通用的方案是，在强化学习中，代理试图通过与环境的一系列互动来最大化奖励。每个状态可以与正面或负面奖励相关联，奖励可以定义为实现总体目标，例如赢得或输掉一场象棋比赛。例如，在象棋中，每一步的结果可以被看作是环境的不同状态。
- en: To explore the chess example further, let’s think of visiting certain configurations
    on the chessboard as being associated with states that will more likely lead to
    winning—for instance, removing an opponent’s chess piece from the board or threatening
    the queen. Other positions, however, are associated with states that will more
    likely result in losing the game, such as losing a chess piece to the opponent
    in the following turn. Now, in the game of chess, the reward (either positive
    for winning or negative for losing the game) will not be given until the end of
    the game. In addition, the final reward will also depend on how the opponent plays.
    For example, the opponent may sacrifice the queen but eventually win the game.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 进一步探讨象棋的例子，我们可以将访问棋盘上特定配置视为与更有可能导致获胜的状态相关联——例如，从棋盘上移除对手的棋子或威胁王后。然而，其他位置则与更有可能导致输掉比赛的状态相关联，例如在接下来的回合中失去对手的棋子。现在，在象棋游戏中，奖励（无论是赢得比赛的正面奖励还是输掉比赛的负面奖励）直到游戏结束后才会给出。此外，最终的奖励还取决于对手的棋局。例如，对手可能会牺牲王后，但最终赢得比赛。
- en: In sum, reinforcement learning is concerned with learning to choose a series
    of actions that maximizes the total reward, which could be earned either immediately
    after taking an action or via *delayed* feedback.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，强化学习关注于学习选择一系列动作，以最大化总奖励，这可以通过即时采取行动后或通过*延迟*反馈来获得。
- en: Discovering hidden structures with unsupervised learning
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 用无监督学习发现隐藏结构
- en: In supervised learning, we know the right answer (the label or target variable)
    beforehand when we train a model, and in reinforcement learning, we define a measure
    of reward for particular actions carried out by the agent. In unsupervised learning,
    however, we are dealing with unlabeled data or data of an unknown structure. Using
    unsupervised learning techniques, we are able to explore the structure of our
    data to extract meaningful information without the guidance of a known outcome
    variable or reward function.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在监督学习中，当我们训练模型时，我们事先知道正确答案（标签或目标变量），在强化学习中，我们为代理执行的特定操作定义奖励措施。然而，在无监督学习中，我们处理的是未标记数据或未知结构的数据。使用无监督学习技术，我们能够探索数据的结构，从中提取有意义的信息，而无需已知的结果变量或奖励函数的指导。
- en: Finding subgroups with clustering
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 利用聚类找到子群体
- en: '**Clustering** is an exploratory data analysis or pattern discovery technique
    that allows us to organize a pile of information into meaningful subgroups (**clusters**)
    without having any prior knowledge of their group memberships. Each cluster that
    arises during the analysis defines a group of objects that share a certain degree
    of similarity but are more dissimilar to objects in other clusters, which is why
    clustering is also sometimes called **unsupervised classification**. Clustering
    is a great technique for structuring information and deriving meaningful relationships
    from data. For example, it allows marketers to discover customer groups based
    on their interests, in order to develop distinct marketing programs.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '**聚类**是一种探索性数据分析或模式发现技术，允许我们将一堆信息组织成有意义的子群体（**簇**），而不需要事先了解它们的群组成员资格。在分析过程中产生的每个簇定义了一组共享某种相似度但与其他簇中的对象更为不同的对象，这也是为什么有时将聚类称为**无监督分类**。聚类是一种从数据中提取有意义关系的重要技术。例如，它允许市场营销人员根据客户的兴趣发现客户群体，以制定不同的营销计划。'
- en: '*Figure 1.6* illustrates how clustering can be applied to organizing unlabeled
    data into three distinct groups or clusters (A, B, and C, in arbitrary order)
    based on the similarity of their features, *x*[1] and *x*[2]:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '*图1.6*说明了如何将聚类应用于将未标记数据组织成三个不同组或簇（A、B和C，顺序任意），基于它们特征的相似性，*x*[1]和*x*[2]：'
- en: '![Diagram  Description automatically generated](img/B17582_01_06.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![Diagram  Description automatically generated](img/B17582_01_06.png)'
- en: 'Figure 1.6: How clustering works'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.6：聚类的工作原理
- en: Dimensionality reduction for data compression
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据压缩的降维
- en: Another subfield of unsupervised learning is **dimensionality reduction**. Often,
    we are working with data of high dimensionality—each observation comes with a
    high number of measurements—that can present a challenge for limited storage space
    and the computational performance of machine learning algorithms. Unsupervised
    dimensionality reduction is a commonly used approach in feature preprocessing
    to remove noise from data, which can degrade the predictive performance of certain
    algorithms. Dimensionality reduction compresses the data onto a smaller dimensional
    subspace while retaining most of the relevant information.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 无监督学习的另一个子领域是**降维**。通常，我们处理的是高维数据——每个观测都伴随着大量的测量，这可能会对有限的存储空间和机器学习算法的计算性能构成挑战。无监督降维是特征预处理中常用的方法，用于从数据中去除噪声，这些噪声可能会降低某些算法的预测性能。降维将数据压缩到更小的维度子空间，同时保留大部分相关信息。
- en: 'Sometimes, dimensionality reduction can also be useful for visualizing data;
    for example, a high-dimensional feature set can be projected onto one-, two-,
    or three-dimensional feature spaces to visualize it via 2D or 3D scatterplots
    or histograms. *Figure 1.7* shows an example where nonlinear dimensionality reduction
    was applied to compress a 3D Swiss roll onto a new 2D feature subspace:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，降维也可以用于数据可视化；例如，可以将高维特征集投影到一维、二维或三维特征空间中，以通过2D或3D散点图或直方图进行可视化。*图1.7*展示了一个例子，其中非线性降维被应用于将一个3D瑞士卷压缩到一个新的2D特征子空间中：
- en: '![](img/B17582_01_07.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17582_01_07.png)'
- en: 'Figure 1.7: An example of dimensionality reduction from three to two dimensions'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.7：从三维到二维的降维示例
- en: Introduction to the basic terminology and notations
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基本术语和符号介绍
- en: Now that we have discussed the three broad categories of machine learning—supervised,
    unsupervised, and reinforcement learning—let’s have a look at the basic terminology
    that we will be using throughout this book. The following subsection covers the
    common terms we will be using when referring to different aspects of a dataset,
    as well as the mathematical notation to communicate more precisely and efficiently.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经讨论了机器学习的三大类别——监督学习、无监督学习和强化学习——让我们来看看本书中将要使用的基本术语。下面的小节涵盖了我们在谈论数据集不同方面时会使用的常见术语，以及更精确和高效地进行数学表示的符号约定。
- en: As machine learning is a vast field and very interdisciplinary, you are guaranteed
    to encounter many different terms that refer to the same concepts sooner rather
    than later. The second subsection collects many of the most commonly used terms
    that are found in machine learning literature, which may be useful to you as a
    reference section when reading machine learning publications.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 由于机器学习是一个广泛且跨学科的领域，您很可能会很快遇到许多指代相同概念的不同术语。第二小节汇总了机器学习文献中使用的许多常用术语，这对您作为参考资料可能会很有用。
- en: Notation and conventions used in this book
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 本书中使用的符号和约定
- en: '*Figure 1.8* depicts an excerpt of the Iris dataset, which is a classic example
    in the field of machine learning (more information can be found at [https://archive.ics.uci.edu/ml/datasets/iris](https://archive.ics.uci.edu/ml/datasets/iris)).
    The Iris dataset contains the measurements of 150 Iris flowers from three different
    species—Setosa, Versicolor, and Virginica.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '*图1.8* 描述了鸢尾花数据集的摘录，这是机器学习领域中的一个经典例子（更多信息可在 [https://archive.ics.uci.edu/ml/datasets/iris](https://archive.ics.uci.edu/ml/datasets/iris)
    找到）。鸢尾花数据集包含了来自三种不同物种——山鸢尾、变色鸢尾和维吉尼亚鸢尾——的150朵鸢尾花的测量数据。'
- en: 'Here, each flower example represents one row in our dataset, and the flower
    measurements in centimeters are stored as columns, which we also call the **features**
    of the dataset:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，每个花样本代表数据集中的一行，而以厘米为单位的花测量数据则以列的形式存储，我们也称之为数据集的**特征**：
- en: '![Diagram  Description automatically generated](img/B17582_01_08.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.8 描述 自动生成](img/B17582_01_08.png)'
- en: 'Figure 1.8: The Iris dataset'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.8：鸢尾花数据集
- en: To keep the notation and implementation simple yet efficient, we will make use
    of some of the basics of linear algebra. In the following chapters, we will use
    a matrix notation to refer to our data. We will follow the common convention to
    represent each example as a separate row in a feature matrix, **X**, where each
    feature is stored as a separate column.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 为了保持符号简单且高效，我们将使用线性代数的基础知识。在接下来的章节中，我们将使用矩阵符号来表示我们的数据。我们将遵循通常的约定，将每个样本表示为特征矩阵
    **X** 中的单独行，其中每个特征存储为单独的列。
- en: 'The Iris dataset, consisting of 150 examples and four features, can then be
    written as a 150×4 matrix, formally denoted as ![](img/B17582_01_001.png):'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 鸢尾花数据集包含150个样本和四个特征，可以写成一个150×4的矩阵，形式上表示为 ![](img/B17582_01_001.png)：
- en: '![](img/B17582_01_002.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17582_01_002.png)'
- en: '**Notational conventions**'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '**符号约定**'
- en: For most parts of this book, unless noted otherwise, we will use the superscript
    *i* to refer to the *i*th training example, and the subscript *j* to refer to
    the *j*th dimension of the training dataset.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的大部分内容中，除非另有说明，我们将使用上标 *i* 表示第 *i* 个训练样本，使用下标 *j* 表示训练数据集的第 *j* 个维度。
- en: We will use lowercase, bold-face letters to refer to vectors (![](img/B17582_01_003.png))
    and uppercase, bold-face letters to refer to matrices (![](img/B17582_01_004.png)).
    To refer to single elements in a vector or matrix, we will write the letters in
    italics (*x*^(^n^) or ![](img/B17582_01_005.png), respectively).
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用小写的粗体字母来指代向量 (![](img/B17582_01_003.png))，使用大写的粗体字母来指代矩阵 (![](img/B17582_01_004.png))。为了指代向量或矩阵中的单个元素，我们将字母写成斜体
    (*x*^(^n^) 或 ![](img/B17582_01_005.png))。
- en: 'For example, ![](img/B17582_01_006.png) refers to the first dimension of flower
    example 150, the sepal length. Each row in matrix **X** represents one flower
    instance and can be written as a four-dimensional row vector, ![](img/B17582_01_007.png):'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，![](img/B17582_01_006.png) 指的是鸢尾花样本150的第一维，即萼片长度。矩阵 **X** 中的每一行代表一个花实例，并且可以写成一个四维行向量，![](img/B17582_01_007.png)：
- en: '![](img/B17582_01_008.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17582_01_008.png)'
- en: 'And each feature dimension is a 150-dimensional column vector, ![](img/B17582_01_009.png).
    For example:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 每个特征维度是一个150维列向量，![](img/B17582_01_009.png)。例如：
- en: '![](img/B17582_01_010.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17582_01_010.png)'
- en: 'Similarly, we can represent the target variables (here, class labels) as a
    150-dimensional column vector:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，我们可以将目标变量（这里是类标签）表示为一个150维列向量：
- en: '![](img/B17582_01_011.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17582_01_011.png)'
- en: Machine learning terminology
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习术语
- en: 'Machine learning is a vast field and also very interdisciplinary as it brings
    together many scientists from other areas of research. As it happens, many terms
    and concepts have been rediscovered or redefined and may already be familiar to
    you but appear under different names. For your convenience, in the following list,
    you can find a selection of commonly used terms and their synonyms that you may
    find useful when reading this book and machine learning literature in general:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习是一个广泛的领域，也是一个非常跨学科的领域，它将许多其他研究领域的科学家聚集在一起。事实上，许多术语和概念已经被重新发现或重新定义，可能已经对您不陌生，但在不同的名称下出现。为了您的方便，在以下列表中，您可以找到一些常用术语及其同义词的选择，这在阅读本书和机器学习文献时可能会对您有所帮助：
- en: '**Training example**: A row in a table representing the dataset and synonymous
    with an observation, record, instance, or sample (in most contexts, sample refers
    to a collection of training examples).'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**训练示例**：表中的一行，表示数据集中的一个观察值、记录、实例或样本（在大多数情况下，“样本”指的是训练示例的集合）。'
- en: '**Training**: Model fitting, for parametric models similar to parameter estimation.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**训练**：模型拟合，对于类似参数估计的参数模型。'
- en: '**Feature, abbrev.** **x**: A column in a data table or data (design) matrix.
    Synonymous with predictor, variable, input, attribute, or covariate.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**特征，缩写** **x**：数据表或数据（设计）矩阵中的一列。同义词为预测变量、变量、输入、属性或协变量。'
- en: '**Target, abbrev.** **y**: Synonymous with outcome, output, response variable,
    dependent variable, (class) label, and ground truth.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**目标，缩写** **y**：与结果、输出、响应变量、因变量（类）标签和地面真实值同义。'
- en: '**Loss function**: Often used synonymously with a *cost* function. Sometimes
    the loss function is also called an *error* function. In some literature, the
    term “loss” refers to the loss measured for a single data point, and the cost
    is a measurement that computes the loss (average or summed) over the entire dataset.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**损失函数**：通常与*成本*函数同义使用。有时损失函数也被称为*误差*函数。在一些文献中，“损失”一词指的是单个数据点的损失，而成本是计算整个数据集上的损失（平均或总和）的度量。'
- en: A roadmap for building machine learning systems
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建机器学习系统的路线图
- en: In previous sections, we discussed the basic concepts of machine learning and
    the three different types of learning. In this section, we will discuss the other
    important parts of a machine learning system accompanying the learning algorithm.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在前几节中，我们讨论了机器学习的基本概念和三种不同类型的学习。在本节中，我们将讨论伴随学习算法的机器学习系统的其他重要部分。
- en: '*Figure 1.9* shows a typical workflow for using machine learning in predictive
    modeling, which we will discuss in the following subsections:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '*图1.9*展示了在预测建模中使用机器学习的典型工作流程，我们将在以下小节中讨论它：'
- en: '![Diagram  Description automatically generated](img/B17582_01_09.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![自动生成的图表描述](img/B17582_01_09.png)'
- en: 'Figure 1.9: Predictive modeling workflow'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.9：预测建模工作流程
- en: Preprocessing – getting data into shape
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 预处理 - 将数据整理成形
- en: Let’s begin by discussing the roadmap for building machine learning systems.
    Raw data rarely comes in the form and shape that is necessary for the optimal
    performance of a learning algorithm. Thus, the preprocessing of the data is one
    of the most crucial steps in any machine learning application.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先讨论构建机器学习系统的路线图。原始数据很少以学习算法优化性能所需的形式和形状出现。因此，数据预处理是任何机器学习应用中最关键的步骤之一。
- en: If we take the Iris flower dataset from the previous section as an example,
    we can think of the raw data as a series of flower images from which we want to
    extract meaningful features. Useful features could be centered around the color
    of the flowers or the height, length, and width of the flowers.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们以前一节中的鸢尾花数据集为例，我们可以将原始数据看作一系列花卉图像，我们希望从中提取有意义的特征。有用的特征可能围绕花卉的颜色或花卉的高度、长度和宽度。
- en: Many machine learning algorithms also require that the selected features are
    on the same scale for optimal performance, which is often achieved by transforming
    the features in the range [0, 1] or a standard normal distribution with zero mean
    and unit variance, as we will see in later chapters.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 许多机器学习算法还要求所选特征在相同的尺度上以实现最佳性能，这通常通过将特征转换为范围为[0, 1]或具有零均值和单位方差的标准正态分布来实现，我们将在后面的章节中看到。
- en: Some of the selected features may be highly correlated and therefore redundant
    to a certain degree. In those cases, dimensionality reduction techniques are useful
    for compressing the features onto a lower-dimensional subspace. Reducing the dimensionality
    of our feature space has the advantage that less storage space is required, and
    the learning algorithm can run much faster. In certain cases, dimensionality reduction
    can also improve the predictive performance of a model if the dataset contains
    a large number of irrelevant features (or noise); that is, if the dataset has
    a low signal-to-noise ratio.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 选定的一些特征可能高度相关，因此在一定程度上是多余的。在这些情况下，降维技术对于将特征压缩到较低维子空间是有用的。减少特征空间的维度具有存储空间需求较少和学习算法运行更快的优势。在某些情况下，如果数据集包含大量无关特征（或噪声），降维还可以改善模型的预测性能；也就是说，如果数据集具有低信噪比。
- en: To determine whether our machine learning algorithm not only performs well on
    the training dataset but also generalizes well to new data, we also want to randomly
    divide the dataset into separate training and test datasets. We use the training
    dataset to train and optimize our machine learning model, while we keep the test
    dataset until the very end to evaluate the final model.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确定我们的机器学习算法不仅在训练数据集上表现良好，而且在新数据上也能很好地泛化，我们还希望将数据集随机分成单独的训练和测试数据集。我们使用训练数据集来训练和优化我们的机器学习模型，而将测试数据集保留到最后用于评估最终模型。
- en: Training and selecting a predictive model
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练和选择预测模型
- en: As you will see in later chapters, many different machine learning algorithms
    have been developed to solve different problem tasks. An important point that
    can be summarized from David Wolpert’s famous *No free lunch theorems* is that
    we can’t get learning “for free” (*The Lack of A Priori Distinctions Between Learning
    Algorithms*, D.H. Wolpert, 1996; *No free lunch theorems for optimization*, D.H.
    Wolpert and W.G. Macready, 1997). We can relate this concept to the popular saying,
    *I suppose it is tempting, if the only tool you have is a hammer, to treat everything
    as if it were a nail* (Abraham Maslow, 1966). For example, each classification
    algorithm has its inherent biases, and no single classification model enjoys superiority
    if we don’t make any assumptions about the task. In practice, it is therefore
    essential to compare at least a handful of different learning algorithms in order
    to train and select the best performing model. But before we can compare different
    models, we first have to decide upon a metric to measure performance. One commonly
    used metric is classification accuracy, which is defined as the proportion of
    correctly classified instances.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您将在后续章节中看到的那样，已经开发了许多不同的机器学习算法来解决不同的问题任务。从大卫·沃尔珀特（David Wolpert）著名的*无免费午餐定理*中可以总结出一个重要观点，即我们不能“免费”学习（*没有先验区分的学习算法*，D.H.沃尔珀特，1996年；*优化的无免费午餐定理*，D.H.沃尔珀特和W.G.麦克瑞迪，1997年）。我们可以将这个概念与流行的说法联系起来，*我想如果你唯一拥有的工具是一把锤子，那么处理一切就像处理钉子一样是诱人的*（亚伯拉罕·马斯洛，1966年）。例如，每种分类算法都有其固有的偏见，如果我们不对任务做任何假设，没有单一的分类模型能够享有优势。因此，在实践中，比较至少几种不同的学习算法以训练和选择表现最佳的模型至关重要。但在我们能够比较不同模型之前，我们首先必须决定一个用于衡量性能的度量标准。一个常用的度量标准是分类准确度，它定义为正确分类实例的比例。
- en: 'One legitimate question to ask is this: how do we know which model performs
    well on the final test dataset and real-world data if we don’t use this test dataset
    for the model selection, but keep it for the final model evaluation? To address
    the issue embedded in this question, different techniques summarized as “cross-validation”
    can be used. In cross-validation, we further divide a dataset into training and
    validation subsets in order to estimate the generalization performance of the
    model.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 一个合理的问题是：如果我们不在模型选择中使用这个测试数据集，而是将其保留到最后模型评估时使用，那么我们如何知道哪个模型在最终测试数据集和真实世界数据上表现良好？为了解决这个问题，可以使用总称为“交叉验证”的不同技术。在交叉验证中，我们进一步将数据集分成训练和验证子集，以估计模型的泛化性能。
- en: Finally, we also cannot expect that the default parameters of the different
    learning algorithms provided by software libraries are optimal for our specific
    problem task. Therefore, we will make frequent use of hyperparameter optimization
    techniques that help us to fine-tune the performance of our model in later chapters.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们也不能期望软件库提供的不同学习算法的默认参数对我们的特定问题任务是最优的。因此，在后续章节中，我们将频繁使用超参数优化技术，这些技术帮助我们调整模型的性能。
- en: We can think of those hyperparameters as parameters that are not learned from
    the data but represent the knobs of a model that we can turn to improve its performance.
    This will become much clearer in later chapters when we see actual examples.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将这些超参数视为不从数据中学习的参数，而是表示模型旋钮，我们可以调整它们以提高其性能。在后续章节中，当我们看到实际示例时，这将变得更加清晰。
- en: Evaluating models and predicting unseen data instances
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 评估模型和预测未见数据实例
- en: After we have selected a model that has been fitted on the training dataset,
    we can use the test dataset to estimate how well it performs on this unseen data
    to estimate the so-called *generalization error*. If we are satisfied with its
    performance, we can now use this model to predict new, future data. It is important
    to note that the parameters for the previously mentioned procedures, such as feature
    scaling and dimensionality reduction, are solely obtained from the training dataset,
    and the same parameters are later reapplied to transform the test dataset, as
    well as any new data instances—the performance measured on the test data may be
    overly optimistic otherwise.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们选择了在训练数据集上拟合的模型之后，我们可以使用测试数据集来估计它在这些未见数据上的表现，以估算所谓的*泛化误差*。如果我们对其性能满意，现在可以使用这个模型来预测新的未来数据。需要注意的是，先前提到的程序的参数（如特征缩放和降维）仅从训练数据集中获取，并且稍后相同的参数将重新应用于转换测试数据集以及任何新的数据实例——否则在测试数据上测得的性能可能会过于乐观。
- en: Using Python for machine learning
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Python 进行机器学习
- en: Python is one of the most popular programming languages for data science, and
    thanks to its very active developer and open-source community, a large number
    of useful libraries for scientific computing and machine learning have been developed.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: Python 是数据科学中最流行的编程语言之一，得益于其非常活跃的开发者和开源社区，已经开发出大量有用的科学计算和机器学习库。
- en: Although the performance of interpreted languages, such as Python, for computation-intensive
    tasks is inferior to lower-level programming languages, extension libraries such
    as NumPy and SciPy have been developed that build upon lower-layer Fortran and
    C implementations for fast vectorized operations on multidimensional arrays.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管解释性语言（如Python）在计算密集型任务中的性能不如低级别编程语言，但已开发出诸如 NumPy 和 SciPy 等扩展库，这些库建立在底层的 Fortran
    和 C 实现之上，用于在多维数组上进行快速向量化操作。
- en: For machine learning programming tasks, we will mostly refer to the scikit-learn
    library, which is currently one of the most popular and accessible open-source
    machine learning libraries. In the later chapters, when we focus on a subfield
    of machine learning called *deep learning*, we will use the latest version of
    the PyTorch library, which specializes in training so-called *deep neural network*
    models very efficiently by utilizing graphics cards.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 对于机器学习编程任务，我们将主要参考 scikit-learn 库，这是目前最流行和易于访问的开源机器学习库之一。在后续章节中，当我们专注于机器学习的一个子领域*深度学习*时，我们将使用
    PyTorch 库的最新版本，该库通过利用图形卡高效训练所谓的*深度神经网络*模型。
- en: Installing Python and packages from the Python Package Index
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安装 Python 和从 Python 包索引中安装包
- en: 'Python is available for all three major operating systems—Microsoft Windows,
    macOS, and Linux—and the installer, as well as the documentation, can be downloaded
    from the official Python website: [https://www.python.org](https://www.python.org).'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: Python 可用于三大主要操作系统——Microsoft Windows、macOS 和 Linux——安装程序和文档均可从官方 Python 网站下载：[https://www.python.org](https://www.python.org)。
- en: The code examples provided in this book have been written for and tested in
    Python 3.9, and we generally recommend that you use the most recent version of
    Python 3 that is available. Some of the code may also be compatible with Python
    2.7, but as the official support for Python 2.7 ended in 2019, and the majority
    of open-source libraries have already stopped supporting Python 2.7 ([https://python3statement.org](https://python3statement.org)),
    we strongly advise that you use Python 3.9 or newer.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中提供的代码示例已针对Python 3.9编写和测试，我们通常建议您使用最新版本的Python 3。一些代码也可能与Python 2.7兼容，但由于Python
    2.7的官方支持已于2019年结束，并且大多数开源库已停止支持Python 2.7（[https://python3statement.org](https://python3statement.org)），我们强烈建议您使用Python
    3.9或更新版本。
- en: You can check your Python version by executing
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过执行以下命令检查您的Python版本
- en: '[PRE0]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: or
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 或
- en: '[PRE1]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: in your terminal (or PowerShell if you are using Windows).
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在您的终端（如果使用Windows，则为PowerShell）中执行。
- en: The additional packages that we will be using throughout this book can be installed
    via the `pip` installer program, which has been part of the Python Standard Library
    since Python 3.3\. More information about `pip` can be found at [https://docs.python.org/3/installing/index.html](https://docs.python.org/3/installing/index.html).
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中将使用的额外软件包可以通过`pip`安装程序安装，`pip`已成为Python标准库的一部分，自Python 3.3起。有关`pip`的更多信息，请访问[https://docs.python.org/3/installing/index.html](https://docs.python.org/3/installing/index.html)。
- en: 'After we have successfully installed Python, we can execute `pip` from the
    terminal to install additional Python packages:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 成功安装Python后，我们可以在终端中执行`pip`来安装额外的Python软件包：
- en: '[PRE2]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Already installed packages can be updated via the `--upgrade` flag:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 已安装的软件包可以通过`--upgrade`标志进行更新：
- en: '[PRE3]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Using the Anaconda Python distribution and package manager
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Anaconda Python发行版和包管理器
- en: 'A highly recommended open-source package management system for installing Python
    for scientific computing contexts is conda by Continuum Analytics. Conda is free
    and licensed under a permissive open-source license. Its goal is to help with
    the installation and version management of Python packages for data science, math,
    and engineering across different operating systems. If you want to use conda,
    it comes in different flavors, namely Anaconda, Miniconda, and Miniforge:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 一个高度推荐的开源软件包管理系统，用于安装用于科学计算的Python，是由Continuum Analytics提供的conda。Conda是免费的，并在宽松的开源许可下授权。其目标是帮助在不同操作系统上管理Python数据科学、数学和工程软件包的安装和版本。如果您希望使用conda，它有不同的版本，包括Anaconda、Miniconda和Miniforge：
- en: Anaconda comes with many scientific computing packages pre-installed. The Anaconda
    installer can be downloaded at [https://docs.anaconda.com/anaconda/install/](https://docs.anaconda.com/anaconda/install/),
    and an Anaconda quick start guide is available at [https://docs.anaconda.com/anaconda/user-guide/getting-started/](https://docs.anaconda.com/anaconda/user-guide/getting-started/).
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Anaconda预装了许多科学计算软件包。可以在[https://docs.anaconda.com/anaconda/install/](https://docs.anaconda.com/anaconda/install/)下载Anaconda安装程序，并在[https://docs.anaconda.com/anaconda/user-guide/getting-started/](https://docs.anaconda.com/anaconda/user-guide/getting-started/)找到Anaconda快速入门指南。
- en: Miniconda is a leaner alternative to Anaconda ([https://docs.conda.io/en/latest/miniconda.html](https://docs.conda.io/en/latest/miniconda.html)).
    Essentially, it is similar to Anaconda but without any packages pre-installed,
    which many people (including the authors) prefer.
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Miniconda是Anaconda的精简替代品（[https://docs.conda.io/en/latest/miniconda.html](https://docs.conda.io/en/latest/miniconda.html)）。本质上，它与Anaconda类似，但没有预安装任何软件包，这是许多人（包括作者）喜欢的。
- en: Miniforge is similar to Miniconda but community-maintained and uses a different
    package repository (conda-forge) from Miniconda and Anaconda. We found that Miniforge
    is a great alternative to Miniconda. Download and installation instructions can
    be found in the GitHub repository at [https://github.com/conda-forge/miniforge](https://github.com/conda-forge/miniforge).
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Miniforge类似于Miniconda，但由社区维护，并使用不同的软件包仓库（conda-forge），与Miniconda和Anaconda不同。我们发现Miniforge是Miniconda的一个很好的替代方案。下载和安装说明可在GitHub仓库中找到：[https://github.com/conda-forge/miniforge](https://github.com/conda-forge/miniforge)。
- en: 'After successfully installing conda through either Anaconda, Miniconda, or
    Miniforge, we can install new Python packages using the following command:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 成功安装conda（通过Anaconda、Miniconda或Miniforge），我们可以使用以下命令安装新的Python软件包：
- en: '[PRE4]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Existing packages can be updated using the following command:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 可使用以下命令更新现有软件包：
- en: '[PRE5]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Packages that are not available through the official conda channel might be
    available via the community-supported conda-forge project ([https://conda-forge.org](https://conda-forge.org)),
    which can be specified via the `--channel conda-forge` flag. For example:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 通过社区支持的conda-forge项目（[https://conda-forge.org](https://conda-forge.org)）可能会提供不在官方conda频道中的包，可以通过`--channel
    conda-forge`标志指定。例如：
- en: '[PRE6]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Packages that are not available through the default conda channel or conda-forge
    can be installed via `pip` as explained earlier. For example:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 不能通过默认的conda频道或conda-forge获取的包可以通过`pip`安装，如前所述。例如：
- en: '[PRE7]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Packages for scientific computing, data science, and machine learning
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 用于科学计算、数据科学和机器学习的包
- en: Throughout the first half of this book, we will mainly use NumPy’s multidimensional
    arrays to store and manipulate data. Occasionally, we will make use of pandas,
    which is a library built on top of NumPy that provides additional higher-level
    data manipulation tools that make working with tabular data even more convenient.
    To augment your learning experience and visualize quantitative data, which is
    often extremely useful to make sense of it, we will use the very customizable
    Matplotlib library.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的前半部分，我们主要使用NumPy的多维数组来存储和操作数据。偶尔，我们将使用建立在NumPy之上的pandas库，它提供了额外的高级数据操作工具，使得处理表格数据变得更加方便。为了增强您的学习体验并可视化定量数据，Matplotlib库是非常可定制化的，对于理解数据非常有帮助。
- en: The main machine learning library used in this book is scikit-learn (*Chapters
    3* to *11*). *Chapter 12*, *Parallelizing Neural Network Training with PyTorch*,
    will then introduce the PyTorch library for deep learning.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 本书主要使用的机器学习库是scikit-learn（*第3章*至*第11章*）。*第12章*，“使用PyTorch并行化神经网络训练”，将介绍深度学习库PyTorch。
- en: 'The version numbers of the major Python packages that were used to write this
    book are mentioned in the following list. Please make sure that the version numbers
    of your installed packages are, ideally, equal to these version numbers to ensure
    that the code examples run correctly:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 编写本书所用的主要Python包的版本号列在以下列表中。请确保您安装的包的版本号与这些版本号理想情况下相等，以确保代码示例正确运行：
- en: NumPy 1.21.2
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NumPy 1.21.2
- en: SciPy 1.7.0
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SciPy 1.7.0
- en: Scikit-learn 1.0
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Scikit-learn 1.0
- en: Matplotlib 3.4.3
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Matplotlib 3.4.3
- en: pandas 1.3.2
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: pandas 1.3.2
- en: 'After installing these packages, you can double-check the installed version
    by importing the package in Python and accessing its `__version__` attribute,
    for example:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 安装这些包后，您可以通过在Python中导入包并访问其`__version__`属性来再次检查安装的版本，例如：
- en: '[PRE8]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: For your convenience, we included a `python-environment-check.py` script in
    this book’s complimentary code repository at [https://github.com/rasbt/machine-learning-book](https://github.com/rasbt/machine-learning-book)
    so that you can check both your Python version and the package versions by executing
    this script.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 为了方便起见，我们在本书的免费代码存储库[https://github.com/rasbt/machine-learning-book](https://github.com/rasbt/machine-learning-book)中包含了一个名为`python-environment-check.py`的脚本，这样您可以通过执行此脚本检查您的Python版本和包版本。
- en: Certain chapters will require additional packages and will provide information
    about the installations. For instance, do not worry about installing PyTorch at
    this point. *Chapter 12* will provide tips and instructions when you need them.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 某些章节将需要额外的包，并将提供有关安装的信息。例如，目前不需要安装PyTorch。*第12章*将在需要时提供提示和说明。
- en: If you encounter errors even though your code matches the code in the chapter
    exactly, we recommend you first check the version numbers of the underlying packages
    before spending more time on debugging or reaching out to the publisher or authors.
    Sometimes, newer versions of libraries introduce backward-incompatible changes
    that could explain these errors.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 如果尽管您的代码与章节中的代码完全相同仍然遇到错误，请先检查底层包的版本号，然后再花时间调试或与出版商或作者联系。有时，库的新版本引入了不向后兼容的更改，这可能解释这些错误。
- en: 'If you do not want to change the package version in your main Python installation,
    we recommend using a virtual environment for installing the packages used in this
    book. If you use Python without the conda manager, you can use the `venv` library
    to create a new virtual environment. For example, you can create and activate
    the virtual environment via the following two commands:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你不想改变主要的Python安装包版本，我们建议在安装本书中使用的包时使用虚拟环境。如果你使用Python而没有conda管理器，你可以使用`venv`库创建一个新的虚拟环境。例如，你可以通过以下两个命令创建和激活虚拟环境：
- en: '[PRE9]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Note that you need to activate the virtual environment every time you open a
    new terminal or PowerShell. You can find more information about `venv` at [https://docs.python.org/3/library/venv.html](https://docs.python.org/3/library/venv.html).
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，每次打开新终端或PowerShell时都需要激活虚拟环境。你可以在[https://docs.python.org/3/library/venv.html](https://docs.python.org/3/library/venv.html)找到更多关于`venv`的信息。
- en: 'If you are using Anaconda with the conda package manager, you can create and
    activate a virtual environment as follows:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在使用带有conda包管理器的Anaconda，你可以按照以下方式创建和激活虚拟环境：
- en: '[PRE10]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Summary
  id: totrans-155
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: 'In this chapter, we explored machine learning at a very high level and familiarized
    ourselves with the big picture and major concepts that we are going to explore
    in the following chapters in more detail. We learned that supervised learning
    is composed of two important subfields: classification and regression. While classification
    models allow us to categorize objects into known classes, we can use regression
    analysis to predict the continuous outcomes of target variables. Unsupervised
    learning not only offers useful techniques for discovering structures in unlabeled
    data, but it can also be useful for data compression in feature preprocessing
    steps.'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们以非常高的层次探讨了机器学习，并熟悉了我们将在后续章节中更详细探讨的大局和主要概念。我们了解到监督学习由两个重要的子领域组成：分类和回归。虽然分类模型允许我们将对象分类到已知类别中，但我们可以使用回归分析来预测目标变量的连续结果。无监督学习不仅提供了发现未标记数据结构的有用技术，还可用于特征预处理步骤中的数据压缩。
- en: We briefly went over the typical roadmap for applying machine learning to problem
    tasks, which we will use as a foundation for deeper discussions and hands-on examples
    in the following chapters. Finally, we set up our Python environment and installed
    and updated the required packages to get ready to see machine learning in action.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 我们简要地介绍了将机器学习应用于问题任务的典型路线图，这将作为我们在后续章节中进行更深入讨论和实际示例的基础。最后，我们设置了我们的Python环境，并安装和更新了所需的包，以准备观看机器学习的实际操作。
- en: Later in this book, in addition to machine learning itself, we will introduce
    different techniques to preprocess a dataset, which will help you to get the best
    performance out of different machine learning algorithms. While we will cover
    classification algorithms quite extensively throughout the book, we will also
    explore different techniques for regression analysis and clustering.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的后续部分中，除了机器学习本身，我们还将介绍不同的技术来预处理数据集，这将帮助你充分发挥不同机器学习算法的性能。虽然我们将在整本书中广泛涵盖分类算法，但我们也将探讨回归分析和聚类的不同技术。
- en: We have an exciting journey ahead, covering many powerful techniques in the
    vast field of machine learning. However, we will approach machine learning one
    step at a time, building upon our knowledge gradually throughout the chapters
    of this book. In the following chapter, we will start this journey by implementing
    one of the earliest machine learning algorithms for classification, which will
    prepare us for *Chapter 3*, *A Tour of Machine Learning Classifiers Using Scikit-Learn*,
    where we will cover more advanced machine learning algorithms using the scikit-learn
    open-source machine learning library.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 我们前方有一段激动人心的旅程，涵盖机器学习广阔领域中的许多强大技术。然而，我们将一步步地接近机器学习，通过本书的各章节逐渐建立我们的知识基础。在接下来的章节中，我们将通过实现最早的分类机器学习算法之一来开始这段旅程，这将为我们准备好*第三章*，*使用scikit-learn进行机器学习分类器的导览*，在那里我们将涵盖更高级的机器学习算法，使用scikit-learn开源机器学习库。
- en: Join our book’s Discord space
  id: totrans-160
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入我们书籍的Discord空间
- en: 'Join the book’s Discord workspace for a monthly *Ask me Anything* session with
    the authors:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 加入书籍的Discord工作空间，与作者进行每月的*问我任何*会话：
- en: '[https://packt.link/MLwPyTorch](https://packt.link/MLwPyTorch)'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.link/MLwPyTorch](https://packt.link/MLwPyTorch)'
- en: '![](img/QR_Code874410888448293359.png)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![](img/QR_Code874410888448293359.png)'
