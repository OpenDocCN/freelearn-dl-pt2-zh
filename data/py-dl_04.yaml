- en: ChapterÂ 4.Â Unsupervised Feature Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç¬¬4ç« ã€‚æ— ç›‘ç£ç‰¹å¾å­¦ä¹ 
- en: One of the reasons why deep neural networks can succeed where other traditional
    machine learning techniques struggle is the capability of learning the right representations
    of entities in the data (features) without needing (much) human and domain knowledge.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: æ·±åº¦ç¥ç»ç½‘ç»œèƒ½å¤ŸæˆåŠŸçš„ä¸€ä¸ªåŸå› æ˜¯èƒ½å¤Ÿå­¦ä¹ æ•°æ®ä¸­å®ä½“ï¼ˆç‰¹å¾ï¼‰çš„æ­£ç¡®è¡¨ç¤ºï¼Œè€Œä¸éœ€è¦ï¼ˆå¤ªå¤šï¼‰äººç±»å’Œé¢†åŸŸçŸ¥è¯†ã€‚
- en: Theoretically, neural networks are able to consume raw data directly as it is
    and map the input layers to the desired output via the hidden intermediate representations.
    Traditional machine learning techniques focus mainly on the final mapping and
    assume the task of "feature engineering" to have already been done.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: ç†è®ºä¸Šï¼Œç¥ç»ç½‘ç»œèƒ½å¤Ÿç›´æ¥æ¶ˆè€—åŸå§‹æ•°æ®ï¼Œå¹¶é€šè¿‡éšè—çš„ä¸­é—´è¡¨ç¤ºå°†è¾“å…¥å±‚æ˜ å°„åˆ°æ‰€éœ€çš„è¾“å‡ºã€‚ä¼ ç»Ÿçš„æœºå™¨å­¦ä¹ æŠ€æœ¯ä¸»è¦ä¸“æ³¨äºæœ€ç»ˆæ˜ å°„ï¼Œå‡å®šâ€œç‰¹å¾å·¥ç¨‹â€çš„ä»»åŠ¡å·²ç»å®Œæˆã€‚
- en: Feature engineering is the process that uses the available domain knowledge
    to create smart representations of the data, so that it can be processed by the
    machine learning algorithm.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ç‰¹å¾å·¥ç¨‹æ˜¯åˆ©ç”¨ç°æœ‰çš„é¢†åŸŸçŸ¥è¯†åˆ›å»ºæ™ºèƒ½æ•°æ®è¡¨ç¤ºçš„è¿‡ç¨‹ï¼Œä»¥ä¾¿å®ƒå¯ä»¥è¢«æœºå™¨å­¦ä¹ ç®—æ³•å¤„ç†ã€‚
- en: Andrew Yan-Tak Ng is a professor at Stanford University and one of the most
    renowned researchers in the field of machine learning and artificial intelligence.
    In his publications and talks, he describes the limitations of traditional machine
    learning when applied to solving real-world problems.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Andrew Yan-Tak Ngæ˜¯æ–¯å¦ç¦å¤§å­¦çš„æ•™æˆï¼Œä¹Ÿæ˜¯æœºå™¨å­¦ä¹ å’Œäººå·¥æ™ºèƒ½é¢†åŸŸæœ€è‘—åçš„ç ”ç©¶è€…ä¹‹ä¸€ã€‚ä»–åœ¨å‡ºç‰ˆç‰©å’Œè®²è¯ä¸­æè¿°äº†ä¼ ç»Ÿæœºå™¨å­¦ä¹ åœ¨è§£å†³å®é™…é—®é¢˜æ—¶çš„å±€é™æ€§ã€‚
- en: 'The hardest part of making a machine learning system work is to find the right
    feature representations:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿æœºå™¨å­¦ä¹ ç³»ç»Ÿæ­£å¸¸å·¥ä½œæœ€å›°éš¾çš„éƒ¨åˆ†æ˜¯æ‰¾åˆ°æ­£ç¡®çš„ç‰¹å¾è¡¨ç¤ºï¼š
- en: '*Coming up with features is difficult, time-consuming, requires expert knowledge.
    When working applications of learning, we spend a lot of time tuning features.*'
  id: totrans-6
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*æå‡ºç‰¹å¾æ˜¯å›°éš¾çš„ï¼Œè€—æ—¶çš„ï¼Œéœ€è¦ä¸“ä¸šçŸ¥è¯†ã€‚åœ¨åº”ç”¨å­¦ä¹ åº”ç”¨ç¨‹åºæ—¶ï¼Œæˆ‘ä»¬èŠ±è´¹äº†å¤§é‡æ—¶é—´è°ƒæ•´ç‰¹å¾ã€‚*'
- en: ''
  id: totrans-7
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*Anrew Ng, Machine Learning and AI via Brain simulations, Stanford University*'
  id: totrans-8
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*å®‰å¾·é²Â·å´ï¼Œæœºå™¨å­¦ä¹ å’Œäººå·¥æ™ºèƒ½é€šè¿‡å¤§è„‘æ¨¡æ‹Ÿï¼Œæ–¯å¦ç¦å¤§å­¦*'
- en: 'Let''s assume we are classifying pictures into a few categories, such as animals
    versus vehicles. The raw data is a matrix of the pixels in the image. If we used
    those pixels directly in a logistic regression or a decision tree, we would create
    rules (or associating weights) for every single picture that might work for the
    given training samples, but that would be very hard to generalize enough to small
    variations of the same pictures. In other words, let''s suppose that my decision
    tree finds that there are five important pixels whose brightness (supposing we
    are displaying only black and white tones) can determine where most of the training
    data get grouped into the two classes--animals and vehicles. The same pictures,
    if cropped, shifted, rotated, or re-colored, would not follow the same rules as
    before. Thus, the model would probably randomly classify them. The main reason
    is that the features we are considering are too weak and unstable. However, we
    could instead first preprocess the data such that we could extract features like
    these:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬å‡è®¾æˆ‘ä»¬æ­£åœ¨å°†å›¾ç‰‡åˆ†ç±»ä¸ºå‡ ä¸ªç±»åˆ«ï¼Œä¾‹å¦‚åŠ¨ç‰©ä¸è½¦è¾†ã€‚åŸå§‹æ•°æ®æ˜¯å›¾åƒä¸­çš„åƒç´ çŸ©é˜µã€‚å¦‚æœæˆ‘ä»¬ç›´æ¥åœ¨é€»è¾‘å›å½’æˆ–å†³ç­–æ ‘ä¸­ä½¿ç”¨è¿™äº›åƒç´ ï¼Œæˆ‘ä»¬å°†ä¸ºå¯èƒ½é€‚ç”¨äºç»™å®šçš„è®­ç»ƒæ ·æœ¬çš„æ¯ä¸€å¼ å›¾ç‰‡åˆ›å»ºè§„åˆ™ï¼ˆæˆ–å…³è”æƒé‡ï¼‰ï¼Œä½†è¿™å°†éå¸¸éš¾ä»¥æ¦‚æ‹¬åˆ°ç›¸åŒå›¾ç‰‡çš„è½»å¾®å˜åŒ–ã€‚æ¢å¥è¯è¯´ï¼Œå‡è®¾æˆ‘çš„å†³ç­–æ ‘å‘ç°æœ‰äº”ä¸ªé‡è¦çš„åƒç´ ï¼Œå®ƒä»¬çš„äº®åº¦ï¼ˆå‡è®¾æˆ‘ä»¬åªæ˜¾ç¤ºé»‘ç™½è‰²è°ƒï¼‰å¯ä»¥ç¡®å®šå¤§å¤šæ•°è®­ç»ƒæ•°æ®è¢«åˆ†æˆä¸¤ç±»--åŠ¨ç‰©å’Œè½¦è¾†ã€‚ç›¸åŒçš„ç…§ç‰‡ï¼Œå¦‚æœè£å‰ªã€ç§»ä½ã€æ—‹è½¬æˆ–é‡æ–°ç€è‰²ï¼Œå°†ä¸å†éµå¾ªä»¥å‰çš„é‚£äº›è§„åˆ™ã€‚å› æ­¤ï¼Œæ¨¡å‹å¯èƒ½ä¼šå¯¹å®ƒä»¬è¿›è¡Œéšæœºåˆ†ç±»ã€‚ä¸»è¦åŸå› æ˜¯æˆ‘ä»¬æ­£åœ¨è€ƒè™‘çš„ç‰¹å¾å¤ªå¼±è€Œä¸ç¨³å®šã€‚ç„¶è€Œï¼Œæˆ‘ä»¬å¯ä»¥é¦–å…ˆé¢„å¤„ç†æ•°æ®ï¼Œä»¥ä¾¿æå–è¿™æ ·çš„ç‰¹å¾ï¼š
- en: Does the picture contain symmetric centric, shapes like wheels?
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å›¾ç‰‡æ˜¯å¦åŒ…å«å¯¹ç§°çš„ï¼Œåƒè½¦è½®ä¸€æ ·çš„å½¢çŠ¶ï¼Ÿ
- en: Does it contain handlebars or a steering wheel?
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å®ƒæ˜¯å¦åŒ…å«æŠŠæ‰‹æˆ–æ–¹å‘ç›˜ï¼Ÿ
- en: Does it contain legs or heads?
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å®ƒæ˜¯å¦åŒ…å«è…¿æˆ–å¤´ï¼Ÿ
- en: Does it have a face with two eyes?
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å®ƒæ˜¯å¦æœ‰ä¸¤åªçœ¼ç›çš„è„¸ï¼Ÿ
- en: 'In such cases, the decision rules would be quite easy and robust, as follows:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå†³ç­–è§„åˆ™ä¼šéå¸¸å®¹æ˜“å’Œå¼ºå¤§ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '![Unsupervised Feature Learning](img/00118.jpeg)![Unsupervised Feature Learning](img/00119.jpeg)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![æ— ç›‘ç£ç‰¹å¾å­¦ä¹ ](img/00118.jpeg)![æ— ç›‘ç£ç‰¹å¾å­¦ä¹ ](img/00119.jpeg)'
- en: How much effort is needed in order to extract those relevant features?
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: éœ€è¦å¤šå°‘åŠªåŠ›æ‰èƒ½æå–è¿™äº›ç›¸å…³ç‰¹å¾ï¼Ÿ
- en: Since we don't have handlebar detectors, we could try to hand-design features
    to capture some statistical properties of the picture, for example, finding edges
    in different orientations in different picture quadrants. We need to find a better
    way to represent images than pixels.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºæˆ‘ä»¬æ²¡æœ‰æŠŠæ‰‹æ£€æµ‹å™¨ï¼Œæˆ‘ä»¬å¯ä»¥å°è¯•æ‰‹åŠ¨è®¾è®¡ç‰¹å¾æ¥æ•æ‰å›¾ç‰‡çš„ä¸€äº›ç»Ÿè®¡ç‰¹æ€§ï¼Œä¾‹å¦‚ï¼Œåœ¨ä¸åŒçš„å›¾ç‰‡è±¡é™ä¸­æ‰¾åˆ°ä¸åŒæ–¹å‘çš„è¾¹ç¼˜ã€‚æˆ‘ä»¬éœ€è¦æ‰¾åˆ°æ¯”åƒç´ æ›´å¥½çš„å›¾åƒè¡¨ç¤ºæ–¹æ³•ã€‚
- en: 'Moreover, robust and significant features are generally made out of hierarchies
    of previously extracted features. We could start extracting edges in the first
    step, then take the generated "edges vector", and combine them to recognize object
    parts, such as an eye, a nose, a mouth, rather than a light, a mirror, or a spoiler.
    The resulting object parts can again be combined into object models; for example,
    two eyes, one nose, and one mouth form a face, or two wheels, a seat, and a handlebar
    form a motorcycle. The whole detection algorithm could be simplified in the following
    way:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: è€Œä¸”ï¼Œå¼ºå¤§å’Œæ˜¾è‘—çš„ç‰¹å¾é€šå¸¸æ˜¯ç”±å…ˆå‰æå–çš„ç‰¹å¾å±‚æ¬¡ç»“æ„åˆ¶æˆçš„ã€‚æˆ‘ä»¬å¯ä»¥åœ¨ç¬¬ä¸€æ­¥å¼€å§‹æå–è¾¹ç¼˜ï¼Œç„¶åå–å¾—ç”Ÿæˆçš„â€œè¾¹ç¼˜å‘é‡â€ï¼Œå¹¶å°†å®ƒä»¬ç»„åˆèµ·æ¥è¯†åˆ«ç‰©ä½“éƒ¨åˆ†ï¼Œæ¯”å¦‚çœ¼ç›ã€é¼»å­ã€å˜´å·´ï¼Œè€Œä¸æ˜¯å…‰ã€é•œå­æˆ–è€…æ‰°æµæ¿ã€‚æœ€ç»ˆçš„ç‰©ä½“éƒ¨åˆ†å¯ä»¥å†æ¬¡ç»„åˆæˆå¯¹è±¡æ¨¡å‹ï¼›ä¾‹å¦‚ï¼Œä¸¤åªçœ¼ç›ï¼Œä¸€åªé¼»å­å’Œä¸€å¼ å˜´å·´å½¢æˆä¸€å¼ è„¸ï¼Œæˆ–è€…ä¸¤ä¸ªè½¦è½®ã€ä¸€ä¸ªåº§æ¤…å’Œä¸€ä¸ªæŠŠæ‰‹å½¢æˆä¸€è¾†æ‘©æ‰˜è½¦ã€‚æ•´ä¸ªæ£€æµ‹ç®—æ³•å¯ä»¥ä»¥ä»¥ä¸‹æ–¹å¼ç®€åŒ–ï¼š
- en: '![Unsupervised Feature Learning](img/00120.jpeg)![Unsupervised Feature Learning](img/00121.jpeg)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![æ— ç›‘ç£ç‰¹å¾å­¦ä¹ ](img/00120.jpeg)![æ— ç›‘ç£ç‰¹å¾å­¦ä¹ ](img/00121.jpeg)'
- en: By recursively applying sparse features, we manage to get higher-level features.
    This is why you need deeper neural network architectures as opposed to the shallow
    algorithms. The single network can learn how to move from one representation to
    the following, but stacking them together will enable the whole end-to-end workflow.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡é€’å½’åº”ç”¨ç¨€ç–ç‰¹å¾ï¼Œæˆ‘ä»¬è®¾æ³•è·å¾—æ›´é«˜çº§çš„ç‰¹å¾ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆä½ éœ€è¦æ¯”æµ…å±‚ç®—æ³•æ›´æ·±çš„ç¥ç»ç½‘ç»œæ¶æ„ã€‚å•ä¸ªç½‘ç»œå¯ä»¥å­¦ä¹ å¦‚ä½•ä»ä¸€ä¸ªè¡¨ç¤ºè½¬ç§»åˆ°å¦ä¸€ä¸ªï¼Œä½†æ˜¯å°†å®ƒä»¬å †å åœ¨ä¸€èµ·å°†ä½¿æ•´ä¸ªç«¯åˆ°ç«¯çš„å·¥ä½œæµèƒ½å¤Ÿå®ç°ã€‚
- en: The real power is not just in the hierarchical structures though. It is important
    to note that we have only used unlabeled data so far. We are learning the hidden
    structures by reverse-engineering the data itself instead of relying on manually
    labeled samples. The supervised learning represents only the final classification
    steps, where we need to assign to either the vehicle class or the animal class.
    All of the previous steps are performed in an unsupervised fashion.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸è¿‡ï¼ŒçœŸæ­£çš„å¨åŠ›å¹¶ä¸ä»…åœ¨äºå±‚æ¬¡ç»“æ„ã€‚é‡è¦çš„æ˜¯è¦æ³¨æ„åˆ°ï¼Œåˆ°ç›®å‰ä¸ºæ­¢æˆ‘ä»¬åªä½¿ç”¨äº†æ— æ ‡ç­¾æ•°æ®ã€‚æˆ‘ä»¬é€šè¿‡å¯¹æ•°æ®æœ¬èº«è¿›è¡Œé€†å‘å·¥ç¨‹æ¥å­¦ä¹ éšè—çš„ç»“æ„ï¼Œè€Œä¸æ˜¯ä¾èµ–äºæ‰‹åŠ¨æ ‡è®°çš„æ ·æœ¬ã€‚ç›‘ç£å­¦ä¹ ä»…è¡¨ç¤ºæœ€ç»ˆçš„åˆ†ç±»æ­¥éª¤ï¼Œæˆ‘ä»¬éœ€è¦å°†å…¶åˆ†é…åˆ°è½¦è¾†ç±»åˆ«æˆ–åŠ¨ç‰©ç±»åˆ«ã€‚æ‰€æœ‰å…ˆå‰çš„æ­¥éª¤éƒ½æ˜¯ä»¥æ— ç›‘ç£çš„æ–¹å¼æ‰§è¡Œçš„ã€‚
- en: We will see how the specific feature extraction for pictures is done in the
    following [Chapter 5](part0030_split_000.html#SJGS1-c1ed1b54ca0b4e9fbb9fe2b2431d634f
    "ChapterÂ 5.Â Image Recognition"), *Image Recognition*. In this chapter, we will
    focus on the general approach of learning feature representations for any type
    of data (for example, time signals, text, or general attribute vectors).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†åœ¨ä»¥ä¸‹[ç¬¬5ç« ](part0030_split_000.html#SJGS1-c1ed1b54ca0b4e9fbb9fe2b2431d634f "ç¬¬5ç« 
    å›¾åƒè¯†åˆ«")ä¸­çœ‹åˆ°å¦‚ä½•ä¸ºå›¾ç‰‡æ‰§è¡Œç‰¹å®šçš„ç‰¹å¾æå–ï¼Œ*å›¾åƒè¯†åˆ«*ã€‚åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å°†ç€é‡ä»‹ç»å­¦ä¹ ä»»ä½•ç±»å‹æ•°æ®ï¼ˆä¾‹å¦‚æ—¶é—´ä¿¡å·ã€æ–‡æœ¬æˆ–ä¸€èˆ¬çš„å±æ€§å‘é‡ï¼‰çš„ç‰¹å¾è¡¨ç¤ºçš„ä¸€èˆ¬æ–¹æ³•ã€‚
- en: 'For that purpose, we will cover two of the most powerful and quite used architectures
    for unsupervised feature learning: autoencoders and restricted Boltzmann machines.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºæ­¤ï¼Œæˆ‘ä»¬å°†ä»‹ç»ä¸¤ç§æœ€å¼ºå¤§ä¸”å¹¿æ³›ä½¿ç”¨çš„æ— ç›‘ç£ç‰¹å¾å­¦ä¹ æ¶æ„ï¼šè‡ªåŠ¨ç¼–ç å™¨å’Œå—é™æ³¢å°”å…¹æ›¼æœºã€‚
- en: Autoencoders
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: è‡ªåŠ¨ç¼–ç å™¨
- en: 'Autoencoders are symmetric networks used for unsupervised learning, where output
    units are connected back to input units:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: è‡ªåŠ¨ç¼–ç å™¨æ˜¯ç”¨äºæ— ç›‘ç£å­¦ä¹ çš„å¯¹ç§°ç½‘ç»œï¼Œå…¶ä¸­è¾“å‡ºå•å…ƒè¿æ¥å›è¾“å…¥å•å…ƒï¼š
- en: '![Autoencoders](img/00122.jpeg)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![è‡ªåŠ¨ç¼–ç å™¨](img/00122.jpeg)'
- en: Autoencoder simple representation from H2O training book (https://github.com/h2oai/h2o-training-book/blob/master/hands-on_training/images/autoencoder.png)
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: H2O è®­ç»ƒæ‰‹å†Œä¸­çš„è‡ªåŠ¨ç¼–ç å™¨ç®€å•è¡¨ç¤º (https://github.com/h2oai/h2o-training-book/blob/master/hands-on_training/images/autoencoder.png)
- en: The output layer has the same size of the input layer because its purpose is
    to reconstruct its own inputs rather than predicting a dependent target value.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: è¾“å‡ºå±‚çš„å¤§å°ä¸è¾“å…¥å±‚ç›¸åŒï¼Œå› ä¸ºå®ƒçš„ç›®çš„æ˜¯é‡æ„è‡ªå·±çš„è¾“å…¥ï¼Œè€Œä¸æ˜¯é¢„æµ‹ä¸€ä¸ªä¾èµ–ç›®æ ‡å€¼ã€‚
- en: 'The goal of those networks is to act as a compression filter via an encoding
    layer, Î¦ that fits the input vector *X* into a smaller latent representation (the
    code) *c*, and then a decoding layer, Î¦ tries to reconstruct it back to *X''*:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›ç½‘ç»œçš„ç›®æ ‡æ˜¯é€šè¿‡ç¼–ç å±‚ Î¦ å……å½“å‹ç¼©æ»¤æ³¢å™¨ï¼Œå°†è¾“å…¥å‘é‡ *X* é€‚åˆåˆ°è¾ƒå°çš„æ½œåœ¨è¡¨ç¤ºï¼ˆç¼–ç ï¼‰ *c*ï¼Œç„¶åè§£ç å±‚ Î¦ è¯•å›¾å°†å…¶é‡æ„å› *X'*ï¼š
- en: '![Autoencoders](img/00123.jpeg)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![è‡ªç¼–ç å™¨](img/00123.jpeg)'
- en: 'The loss function is the reconstruction error, which will force the network
    to find the most efficient compact representation of the training data with minimum
    information loss. For numerical input, the loss function can be the mean squared
    error:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: æŸå¤±å‡½æ•°æ˜¯é‡æ„è¯¯å·®ï¼Œå®ƒå°†è¿«ä½¿ç½‘ç»œæ‰¾åˆ°è®­ç»ƒæ•°æ®çš„æœ€æœ‰æ•ˆçš„ç´§å‡‘è¡¨ç¤ºï¼ŒåŒæ—¶æœ€å°åŒ–ä¿¡æ¯æŸå¤±ã€‚å¯¹äºæ•°å€¼è¾“å…¥ï¼ŒæŸå¤±å‡½æ•°å¯ä»¥æ˜¯å‡æ–¹è¯¯å·®ï¼š
- en: '![Autoencoders](img/00124.jpeg)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![è‡ªç¼–ç å™¨](img/00124.jpeg)'
- en: 'If the input data is not numerical but is represented as a vector of bits or
    multinomial distributions, we can use the cross-entropy of the reconstruction:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœè¾“å…¥æ•°æ®ä¸æ˜¯æ•°å€¼å‹ï¼Œè€Œæ˜¯è¡¨ç¤ºä¸ºæ¯”ç‰¹å‘é‡æˆ–å¤šé¡¹åˆ†å¸ƒçš„å‘é‡ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨é‡æ„çš„äº¤å‰ç†µï¼š
- en: '![Autoencoders](img/00125.jpeg)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![è‡ªç¼–ç å™¨](img/00125.jpeg)'
- en: Here, *d* is the dimensionality of the input vectors.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œï¼Œ*d* æ˜¯è¾“å…¥å‘é‡çš„ç»´åº¦ã€‚
- en: The central layer (the code) of the network is the compressed representation
    of the data. We are effectively translating an n-dimensional array into a smaller
    m-dimensional array, where *m < n*. This process is very similar to dimensionality
    reduction using **Principal Component Analysis** (**PCA**). PCA divides the input
    matrix into orthogonal axes (called components) in such, way that you can reconstruct
    an approximation of the original matrix by projecting the original points on those
    axes. By sorting them by their importance, we can extract the top *m* components
    that can be though as high-level features of the original data.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: ç½‘ç»œçš„ä¸­å¤®å±‚ï¼ˆç¼–ç ï¼‰æ˜¯æ•°æ®çš„å‹ç¼©è¡¨ç¤ºã€‚æˆ‘ä»¬å®é™…ä¸Šå°†ä¸€ä¸ª n ç»´æ•°ç»„è½¬æ¢ä¸ºä¸€ä¸ªè¾ƒå°çš„ m ç»´æ•°ç»„ï¼Œå…¶ä¸­ *m < n*ã€‚è¿™ä¸ªè¿‡ç¨‹ä¸ä½¿ç”¨**ä¸»æˆåˆ†åˆ†æ**ï¼ˆ**PCA**ï¼‰è¿›è¡Œé™ç»´éå¸¸ç›¸ä¼¼ã€‚PCA
    å°†è¾“å…¥çŸ©é˜µåˆ†æˆæ­£äº¤è½´ï¼ˆç§°ä¸ºåˆ†é‡ï¼‰ï¼Œä»¥ä¾¿æ‚¨å¯ä»¥é€šè¿‡åœ¨è¿™äº›è½´ä¸ŠæŠ•å½±åŸå§‹ç‚¹æ¥é‡æ„åŸå§‹çŸ©é˜µçš„è¿‘ä¼¼å€¼ã€‚é€šè¿‡æŒ‰é‡è¦æ€§å¯¹å®ƒä»¬è¿›è¡Œæ’åºï¼Œæˆ‘ä»¬å¯ä»¥æå–å‡ºå‰ *m* ä¸ªç»„ä»¶ï¼Œè¿™äº›ç»„ä»¶å¯ä»¥è¢«è§†ä¸ºåŸå§‹æ•°æ®çš„é«˜çº§ç‰¹å¾ã€‚
- en: 'For example, in a multivariate Gaussian distribution, we could represent each
    point as a coordinate over the two orthogonal components that would describe the
    largest possible variance in the data:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œåœ¨å¤šå…ƒé«˜æ–¯åˆ†å¸ƒä¸­ï¼Œæˆ‘ä»¬å¯ä»¥å°†æ¯ä¸ªç‚¹è¡¨ç¤ºä¸ºä¸¤ä¸ªæ­£äº¤åˆ†é‡ä¸Šçš„åæ ‡ï¼Œè¿™ä¸¤ä¸ªåˆ†é‡æè¿°äº†æ•°æ®ä¸­å¯èƒ½çš„æœ€å¤§æ–¹å·®ï¼š
- en: '![Autoencoders](img/00126.jpeg)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![è‡ªç¼–ç å™¨](img/00126.jpeg)'
- en: A scatter plot of samples that are distributed according a multivariate (bivariate)
    Gaussian distribution centered at (1,3) with a standard deviation of 3 in the
    (0.866, 0.5) direction and of 1 in the orthogonal direction. The directions represent
    the principal components (PC) associated with the sample. By Nicoguaro (own work)
    CC BY 4.0 (http://creativecommons.org/licenses/by/4.0), via Wikimedia Commons.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªæ ·æœ¬æ•£ç‚¹å›¾ï¼ŒæŒ‰ç…§ä»¥(1,3)ä¸ºä¸­å¿ƒï¼Œ(0.866, 0.5)æ–¹å‘ä¸Šæ ‡å‡†å·®ä¸º3ï¼Œåœ¨æ­£äº¤æ–¹å‘ä¸Šæ ‡å‡†å·®ä¸º1çš„å¤šå…ƒï¼ˆåŒå˜é‡ï¼‰é«˜æ–¯åˆ†å¸ƒè¿›è¡Œåˆ†å¸ƒã€‚è¿™äº›æ–¹å‘è¡¨ç¤ºä¸æ ·æœ¬ç›¸å…³è”çš„ä¸»æˆåˆ†ï¼ˆPCï¼‰ã€‚ç”±
    Nicoguaroï¼ˆè‡ªå·±çš„ä½œå“ï¼‰CC BY 4.0 (http://creativecommons.org/licenses/by/4.0)ï¼Œé€šè¿‡ç»´åŸºåª’ä½“å…¬å…±é¢†åŸŸã€‚
- en: The limitation of PCA is that it allows only linear transformation of the data,
    which is not always enough.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: PCA çš„å±€é™æ€§åœ¨äºå®ƒåªå…è®¸å¯¹æ•°æ®è¿›è¡Œçº¿æ€§å˜æ¢ï¼Œè¿™å¹¶ä¸æ€»æ˜¯è¶³å¤Ÿçš„ã€‚
- en: Autoencoders have the advantage of being able to represent even non-linear representations
    using a non-linear activation function.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: è‡ªç¼–ç å™¨çš„ä¼˜åŠ¿åœ¨äºå¯ä»¥ä½¿ç”¨éçº¿æ€§æ¿€æ´»å‡½æ•°è¡¨ç¤ºéçº¿æ€§è¡¨ç¤ºã€‚
- en: 'One famous example of an autoencoder was given by MITCHELL, T. M. in his book
    *Machine Learning*, wcb, 1997\. In that example, we have a dataset with eight
    categorical objects encoded in binary with eight mutually exclusive labels with
    bits. The network will learn a compact representation with just three hidden nodes:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: è‡ªç¼–ç å™¨çš„ä¸€ä¸ªè‘—åç¤ºä¾‹æ˜¯ MITCHELL åœ¨ä»–çš„ä¹¦ *æœºå™¨å­¦ä¹ * ä¸­ç»™å‡ºçš„ã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬æœ‰ä¸€ä¸ªæ•°æ®é›†ï¼Œå…¶ä¸­åŒ…å«å…«ä¸ªåˆ†ç±»å¯¹è±¡ï¼Œç”¨å…«ä¸ªç›¸äº’æ’æ–¥çš„æ¯”ç‰¹æ ‡è®°çš„äºŒè¿›åˆ¶ç¼–ç ã€‚ç½‘ç»œå°†å­¦ä¹ ä¸€ä¸ªä»…å…·æœ‰ä¸‰ä¸ªéšè—èŠ‚ç‚¹çš„ç´§å‡‘è¡¨ç¤ºï¼š
- en: '![Autoencoders](img/00127.jpeg)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![è‡ªç¼–ç å™¨](img/00127.jpeg)'
- en: Tom Mitchell's example of an autoencoder.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: Tom Mitchell çš„è‡ªç¼–ç å™¨ç¤ºä¾‹ã€‚
- en: By applying the right activation function, the learn-compact representation
    corresponds exactly with the binary representation with three bits.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡åº”ç”¨æ­£ç¡®çš„æ¿€æ´»å‡½æ•°ï¼Œå­¦ä¹ åˆ°çš„ç´§å‡‘è¡¨ç¤ºä¸ä¸‰æ¯”ç‰¹äºŒè¿›åˆ¶è¡¨ç¤ºå®Œå…¨å¯¹åº”ã€‚
- en: There are situations though where just the single hidden layer is not enough
    to represent the whole complexity and variance of the data. Deeper architecture
    can learn more complicated relationships between the input and hidden layers.
    The network is then able to learn latent features and use those to best represent
    the non-trivial informative components in the data.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œåœ¨æŸäº›æƒ…å†µä¸‹ï¼Œä»…ä»…å•ä¸ªéšè—å±‚ä¸è¶³ä»¥è¡¨ç¤ºæ•°æ®çš„æ•´ä¸ªå¤æ‚æ€§å’Œå˜å¼‚æ€§ã€‚æ›´æ·±çš„æ¶æ„å¯ä»¥å­¦ä¹ è¾“å…¥å’Œéšè—å±‚ä¹‹é—´æ›´å¤æ‚çš„å…³ç³»ã€‚ç„¶åï¼Œç½‘ç»œèƒ½å¤Ÿå­¦ä¹ æ½œåœ¨ç‰¹å¾å¹¶åˆ©ç”¨è¿™äº›ç‰¹å¾æ¥æœ€å¥½åœ°è¡¨ç¤ºæ•°æ®ä¸­çš„éå¹³å‡¡ä¿¡æ¯ç»„æˆéƒ¨åˆ†ã€‚
- en: 'A deep autoencoder is obtained by concatenating two symmetrical networks typically
    made of up to five shallow layers:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡è¿æ¥ä¸¤ä¸ªå¯¹ç§°ç½‘ç»œè·å¾—æ·±åº¦è‡ªåŠ¨ç¼–ç å™¨ï¼Œé€šå¸¸ç”±æœ€å¤šäº”ä¸ªæµ…å±‚ç»„æˆï¼š
- en: '![Autoencoders](img/00128.jpeg)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![è‡ªåŠ¨ç¼–ç å™¨](img/00128.jpeg)'
- en: Schematic structure of an autoencoder with 3 fully-connected hidden layers (https://en.wikipedia.org/wiki/Autoencoder#/media/File:Autoencoder_structure.png)
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: è‡ªåŠ¨ç¼–ç å™¨çš„ç¤ºæ„ç»“æ„ï¼Œå…·æœ‰3ä¸ªå®Œå…¨è¿æ¥çš„éšè—å±‚ï¼ˆhttps://en.wikipedia.org/wiki/Autoencoder#/media/File:Autoencoder_structure.pngï¼‰
- en: Deep autoencoders can learn new latent representations, combining the previously
    learned ones so that each hidden level can be seen as some compressed hierarchical
    representation of the original data. We could then use the code or any other hidden
    layer of the encoding network as valid features describing the input vector.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: æ·±åº¦è‡ªåŠ¨ç¼–ç å™¨å¯ä»¥å­¦ä¹ æ–°çš„æ½œåœ¨è¡¨ç¤ºï¼Œå°†å…ˆå‰å­¦åˆ°çš„è¡¨ç¤ºç»„åˆèµ·æ¥ï¼Œä»¥ä¾¿æ¯ä¸ªéšè—çº§åˆ«å¯ä»¥è¢«è§†ä¸ºåŸå§‹æ•°æ®çš„æŸç§å‹ç¼©å±‚æ¬¡è¡¨ç¤ºã€‚ç„¶åï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ç¼–ç ç½‘ç»œçš„ä»£ç æˆ–ä»»ä½•å…¶ä»–éšè—å±‚ä½œä¸ºæè¿°è¾“å…¥å‘é‡çš„æœ‰æ•ˆç‰¹å¾ã€‚
- en: Network design
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç½‘ç»œè®¾è®¡
- en: 'Probably the most common question when building a deep neural network is: how
    do we choose the number of hidden layers and the number of neurons for each layer?
    Furthermore, which activation and loss functions do we use?'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ„å»ºæ·±åº¦ç¥ç»ç½‘ç»œæ—¶ï¼Œæœ€å¸¸è§çš„é—®é¢˜å¯èƒ½æ˜¯ï¼šæˆ‘ä»¬å¦‚ä½•é€‰æ‹©éšè—å±‚çš„æ•°é‡å’Œæ¯ä¸ªå±‚çš„ç¥ç»å…ƒæ•°é‡ï¼Ÿæ­¤å¤–ï¼Œæˆ‘ä»¬ä½¿ç”¨å“ªç§æ¿€æ´»å’ŒæŸå¤±å‡½æ•°ï¼Ÿ
- en: There is no closed answer. The empirical approach consists of running a sequence
    of trial and error or a standard grid search, where the depth and the size of
    each layer are simply defined as tuning hyperparameters. We will look at a few
    design guidelines.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: æ²¡æœ‰ç¡®å®šçš„ç­”æ¡ˆã€‚ç»éªŒæ–¹æ³•åŒ…æ‹¬è¿è¡Œä¸€ç³»åˆ—è¯•éªŒå’Œé”™è¯¯æˆ–æ ‡å‡†ç½‘æ ¼æœç´¢ï¼Œå…¶ä¸­æ·±åº¦å’Œæ¯ä¸ªå±‚çš„å¤§å°ç®€å•åœ°è¢«å®šä¹‰ä¸ºè°ƒæ•´è¶…å‚æ•°ã€‚æˆ‘ä»¬å°†çœ‹ä¸€äº›è®¾è®¡å‡†åˆ™ã€‚
- en: 'For autoencoders, the problem is slightly simplified. Since there are many
    variants of autoencoders, we will define the guidelines for the general use case.
    Please keep in mind that each variation will have its own rules to be considered.
    We can suggest the following:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºè‡ªåŠ¨ç¼–ç å™¨ï¼Œé—®é¢˜ç•¥æœ‰ç®€åŒ–ã€‚ç”±äºè‡ªåŠ¨ç¼–ç å™¨æœ‰è®¸å¤šå˜ä½“ï¼Œæˆ‘ä»¬å°†å®šä¹‰é€šç”¨ç”¨ä¾‹çš„æŒ‡å—ã€‚è¯·è®°ä½ï¼Œæ¯ä¸ªå˜ä½“éƒ½å°†æœ‰å…¶è‡ªå·±çš„è§„åˆ™éœ€è¦è€ƒè™‘ã€‚æˆ‘ä»¬å¯ä»¥å»ºè®®ä»¥ä¸‹å†…å®¹ï¼š
- en: The output layer consists of exactly the same size of the input.
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¾“å‡ºå±‚çš„å¤§å°ä¸è¾“å…¥å®Œå…¨ç›¸åŒã€‚
- en: The network is symmetric most of the time. Having an asymmetric network would
    mean having different complexities of the encoder and decoder functions. Unless
    you have a particular reason for doing so, there is generally no advantage in
    having asymmetric networks. However, you could decide to share the same weights
    or decide to have different weights in the encoding and decoding networks.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç½‘ç»œå¤§å¤šæ•°æƒ…å†µä¸‹æ˜¯å¯¹ç§°çš„ã€‚æ‹¥æœ‰ä¸å¯¹ç§°ç½‘ç»œæ„å‘³ç€ç¼–ç å™¨å’Œè§£ç å™¨å‡½æ•°çš„ä¸åŒå¤æ‚æ€§ã€‚é™¤éæœ‰ç‰¹æ®ŠåŸå› ï¼Œé€šå¸¸æ²¡æœ‰å¯¹ç§°ç½‘ç»œçš„ä¼˜åŠ¿ã€‚ä½†æ˜¯ï¼Œæ‚¨å¯ä»¥å†³å®šå…±äº«ç›¸åŒçš„æƒé‡æˆ–è€…å†³å®šåœ¨ç¼–ç å’Œè§£ç ç½‘ç»œä¸­å…·æœ‰ä¸åŒçš„æƒé‡ã€‚
- en: During the encoding phase, the hidden layers are smaller than the input, in
    which case, we are talking about "undercomplete autoencoders". A multilayer encoder
    gradually decreases the representation size. The size of the hidden layer, generally,
    is at most half the size of the previous one. If the data input layer has 100
    nodes, then a plausible architecture could be 100-40-20-40-100\. Having bigger
    layers than the input would lead to no compression at all, which means no interesting
    patterns are learned. We will see in the *Regularization* section how this constraint
    is not necessary in case of sparse autoencoders.
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨ç¼–ç é˜¶æ®µï¼Œéšè—å±‚æ¯”è¾“å…¥å°ï¼Œè¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸ºâ€œæ¬ å®Œå¤‡è‡ªåŠ¨ç¼–ç å™¨â€ã€‚å¤šå±‚ç¼–ç å™¨é€æ¸å‡å°è¡¨ç¤ºå¤§å°ã€‚éšè—å±‚çš„å¤§å°é€šå¸¸æœ€å¤šæ˜¯å‰ä¸€ä¸ªçš„ä¸€åŠã€‚å¦‚æœæ•°æ®è¾“å…¥å±‚æœ‰100ä¸ªèŠ‚ç‚¹ï¼Œé‚£ä¹ˆä¸€ä¸ªåˆç†çš„æ¶æ„å¯èƒ½æ˜¯100-40-20-40-100ã€‚æ¯”è¾“å…¥æ›´å¤§çš„å±‚å°†å¯¼è‡´æ²¡æœ‰ä»»ä½•å‹ç¼©ï¼Œè¿™æ„å‘³ç€ä¸ä¼šå­¦ä¹ åˆ°æœ‰è¶£çš„æ¨¡å¼ã€‚æˆ‘ä»¬å°†åœ¨*æ­£åˆ™åŒ–*éƒ¨åˆ†çœ‹åˆ°ï¼Œè¿™ç§çº¦æŸåœ¨ç¨€ç–è‡ªåŠ¨ç¼–ç å™¨çš„æƒ…å†µä¸‹å¹¶éå¿…è¦ã€‚
- en: The middle layer (the code) covers an important role. In the case of feature
    reduction, we could keep it small and equal to 2, 3, or 4 in order to allow efficient
    data visualizations. In the case of stacked autoencoders, we should set it to
    be larger because it will represent the input layer of the next encoder.
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸­é—´å±‚ï¼ˆä»£ç ï¼‰èµ·ç€é‡è¦ä½œç”¨ã€‚åœ¨ç‰¹å¾å‡å°‘çš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¯ä»¥å°†å…¶ä¿æŒè¾ƒå°ï¼Œå¹¶ä¸”ç­‰äº2ã€3æˆ–4ï¼Œä»¥ä¾¿å…è®¸é«˜æ•ˆçš„æ•°æ®å¯è§†åŒ–ã€‚åœ¨å †å çš„è‡ªç¼–ç å™¨çš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬åº”è¯¥å°†å…¶è®¾ç½®å¾—æ›´å¤§ï¼Œå› ä¸ºå®ƒå°†ä»£è¡¨ä¸‹ä¸€ä¸ªç¼–ç å™¨çš„è¾“å…¥å±‚ã€‚
- en: In the case of binary inputs, we want to use sigmoid as the output activation
    function and cross-entropy, or more precisely, the sum of Bernoulli cross-entropies,
    as the loss function.
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨äºŒè¿›åˆ¶è¾“å…¥çš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¸Œæœ›ä½¿ç”¨sigmoidä½œä¸ºè¾“å‡ºæ¿€æ´»å‡½æ•°ï¼Œä½¿ç”¨äº¤å‰ç†µï¼Œæ›´ç¡®åˆ‡åœ°è¯´ï¼Œä½¿ç”¨ä¼¯åŠªåˆ©äº¤å‰ç†µçš„æ€»å’Œï¼Œä½œä¸ºæŸå¤±å‡½æ•°ã€‚
- en: For real values, we can use a linear activation function (ReLU or softmax) as
    the output and the **mean squared error** (**MSE**) as the loss function.
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äºå®å€¼ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨çº¿æ€§æ¿€æ´»å‡½æ•°ï¼ˆReLUæˆ–softmaxï¼‰ä½œä¸ºè¾“å‡ºï¼Œå¹¶ä¸”ä½¿ç”¨**å‡æ–¹è¯¯å·®**ï¼ˆ**MSE**ï¼‰ä½œä¸ºæŸå¤±å‡½æ•°ã€‚
- en: 'For different types of input data(*x*)and output *u*, you can follow the general
    approach, which consists of the following steps:'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äºä¸åŒç±»å‹çš„è¾“å…¥æ•°æ®ï¼ˆ*x*ï¼‰å’Œè¾“å‡º*u*ï¼Œæ‚¨å¯ä»¥éµå¾ªä¸€èˆ¬æ–¹æ³•ï¼Œå…¶ä¸­åŒ…æ‹¬ä»¥ä¸‹æ­¥éª¤ï¼š
- en: Finding the probability distribution of observing x, given *u*, P(x/u)
  id: totrans-62
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ‰¾åˆ°è§‚å¯Ÿåˆ°xçš„æ¦‚ç‡åˆ†å¸ƒï¼Œç»™å®š*u*ï¼ŒP(x/u)
- en: Finding the relationship between *u* and the hidden layer h(x)
  id: totrans-63
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ‰¾åˆ°*u*å’Œéšè—å±‚h(x)ä¹‹é—´çš„å…³ç³»
- en: Using ![Network design](img/00123.jpeg)
  id: totrans-64
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ ![ç½‘ç»œè®¾è®¡](img/00123.jpeg)
- en: In the case of deep networks (with more than one hidden layer), use the same
    activation function for all of them in order to not unbalance the complexity of
    the encoder and decoder.
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨æ·±å±‚ç½‘ç»œï¼ˆå…·æœ‰å¤šä¸ªéšè—å±‚ï¼‰çš„æƒ…å†µä¸‹ï¼Œä¸ºäº†ä¸ä½¿ç¼–ç å™¨å’Œè§£ç å™¨çš„å¤æ‚æ€§å¤±è¡¡ï¼Œä½¿ç”¨ç›¸åŒçš„æ¿€æ´»å‡½æ•°ã€‚
- en: If we use a linear activation function throughout the whole network, we will
    approximate the behavior of PCA.
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬åœ¨æ•´ä¸ªç½‘ç»œä¸­ä½¿ç”¨çº¿æ€§æ¿€æ´»å‡½æ•°ï¼Œæˆ‘ä»¬å°†è¿‘ä¼¼äºPCAçš„è¡Œä¸ºã€‚
- en: It is convenient to Gaussian scale (0 mean and unit standard deviation) your
    data unless it is binary, and it is better to leave the input values to be either
    0 or 1\. Categorical data can be represented using one-hot-encoding with dummy
    variables.
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é™¤éæ˜¯äºŒè¿›åˆ¶çš„ï¼Œå¦åˆ™æœ€å¥½å¯¹æ‚¨çš„æ•°æ®è¿›è¡Œé«˜æ–¯ç¼©æ”¾ï¼ˆ0å‡å€¼å’Œå•ä½æ ‡å‡†å·®ï¼‰ï¼Œå¹¶ä¸”æœ€å¥½å°†è¾“å…¥å€¼ä¿ç•™ä¸º0æˆ–1ã€‚åˆ†ç±»æ•°æ®å¯ä»¥ä½¿ç”¨å¸¦æœ‰è™šæ‹Ÿå˜é‡çš„ç‹¬çƒ­ç¼–ç æ¥è¡¨ç¤ºã€‚
- en: 'Activation functions are as follows:'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¿€æ´»å‡½æ•°å¦‚ä¸‹ï¼š
- en: ReLU is generally the default choice for majority of neural networks. Autoencoders,
    given their topology, may benefit from a symmetric activation function. Since
    ReLU tends to overfit more, it is preferred when combined with regularization
    techniques (such as dropout).
  id: totrans-69
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ReLUé€šå¸¸æ˜¯å¤§å¤šæ•°ç¥ç»ç½‘ç»œçš„é»˜è®¤é€‰æ‹©ã€‚ç”±äºå…¶æ‹“æ‰‘ç»“æ„ï¼Œè‡ªç¼–ç å™¨å¯èƒ½ä¼šå—ç›Šäºå¯¹ç§°æ¿€æ´»å‡½æ•°ã€‚ç”±äºReLUå¾€å¾€è¿‡æ‹Ÿåˆï¼Œå› æ­¤åœ¨ä¸æ­£åˆ™åŒ–æŠ€æœ¯ï¼ˆå¦‚dropoutï¼‰ç»“åˆæ—¶æ›´å—æ¬¢è¿ã€‚
- en: If your data is binary or can be scaled in the range of [0, 1], then you would
    probably use a sigmoid activation function. If you used one-hot-encoding for the
    input categorical data, then it's better use ReLU.
  id: totrans-70
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨çš„æ•°æ®æ˜¯äºŒè¿›åˆ¶çš„æˆ–è€…å¯ä»¥ç¼©æ”¾åˆ°[0,1]çš„èŒƒå›´å†…ï¼Œåˆ™å¯èƒ½ä¼šä½¿ç”¨sigmoidæ¿€æ´»å‡½æ•°ã€‚å¦‚æœæ‚¨å¯¹è¾“å…¥åˆ†ç±»æ•°æ®ä½¿ç”¨äº†ç‹¬çƒ­ç¼–ç ï¼Œåˆ™æœ€å¥½ä½¿ç”¨ReLUã€‚
- en: Hyperbolic tangent (*tanh*) is a good choice for computation optimization in
    case of gradient descent. Since data will be centered around 0, the derivatives
    will be higher. Another effect is reducing bias in the gradients as is well explained
    in the "Efficient BackProp" paper ([http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf](http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf)).
  id: totrans-71
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: åŒæ›²æ­£åˆ‡ï¼ˆ*tanh*ï¼‰æ˜¯åœ¨æ¢¯åº¦ä¸‹é™æƒ…å†µä¸‹è¿›è¡Œè®¡ç®—ä¼˜åŒ–çš„ä¸é”™é€‰æ‹©ã€‚ç”±äºæ•°æ®å°†å›´ç»•0ä¸­å¿ƒåŒ–ï¼Œå¯¼æ•°å°†æ›´é«˜ã€‚å¦ä¸€ä¸ªæ•ˆæœæ˜¯å‡å°‘æ¢¯åº¦ä¸­çš„åå·®ï¼Œæ­£å¦‚ã€Šé«˜æ•ˆçš„åå‘ä¼ æ’­ã€‹ä¸€æ–‡ä¸­æ‰€è§£é‡Šçš„é‚£æ ·ï¼ˆ[http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf](http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf)ï¼‰ã€‚
- en: '![Network design](img/00129.jpeg)'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![ç½‘ç»œè®¾è®¡](img/00129.jpeg)'
- en: Different activation functions commonly used for deep neural networks
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æ·±åº¦ç¥ç»ç½‘ç»œå¸¸ç”¨çš„ä¸åŒæ¿€æ´»å‡½æ•°
- en: Regularization techniques for autoencoders
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è‡ªç¼–ç å™¨çš„æ­£åˆ™åŒ–æŠ€æœ¯
- en: In the previous chapters, we already saw different forms of regularizations,
    such as L1, L2, early stopping, and dropout. In this section, we will describe
    a few popular techniques specifically tailored for autoencoders.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¹‹å‰çš„ç« èŠ‚ä¸­ï¼Œæˆ‘ä»¬å·²ç»çœ‹åˆ°äº†ä¸åŒå½¢å¼çš„æ­£åˆ™åŒ–ï¼Œä¾‹å¦‚L1ï¼ŒL2ï¼Œæå‰åœæ­¢å’Œdropoutã€‚åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†æè¿°ä¸€äº›ä¸“é—¨ä¸ºè‡ªç¼–ç å™¨é‡èº«å®šåˆ¶çš„å‡ ç§æµè¡ŒæŠ€æœ¯ã€‚
- en: So far, we have always described autoencoders as "undercomplete", which means
    the hidden layers are smaller than the input layer. This is because having a bigger
    layer would have no compression at all. The hidden units may just copy exactly
    the input and return an exact copy as the output.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬ä¸€ç›´æŠŠè‡ªåŠ¨ç¼–ç å™¨æè¿°ä¸º"æ¬ å®Œå¤‡"ï¼Œè¿™æ„å‘³ç€éšè—å±‚æ¯”è¾“å…¥å±‚å°ã€‚è¿™æ˜¯å› ä¸ºæ‹¥æœ‰æ›´å¤§çš„å±‚æ ¹æœ¬æ²¡æœ‰ä»»ä½•å‹ç¼©ã€‚éšè—å•å…ƒå¯èƒ½åªæ˜¯ç²¾ç¡®å¤åˆ¶è¾“å…¥å¹¶å°†ç²¾ç¡®å¤åˆ¶ä½œä¸ºè¾“å‡ºè¿”å›ã€‚
- en: On the other hand, having more hidden units would allow us to have more freedom
    on learning smarter representations.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: å¦ä¸€æ–¹é¢ï¼Œæ‹¥æœ‰æ›´å¤šçš„éšè—å•å…ƒå°†ä½¿æˆ‘ä»¬æœ‰æ›´å¤šçš„è‡ªç”±å­¦ä¹ æ™ºèƒ½è¡¨ç¤ºã€‚
- en: 'We will see how we can address this problem with three approaches: denoising
    autoencoders, contractive autoencoders, and sparse autoencoders.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†çœ‹åˆ°å¦‚ä½•ç”¨ä¸‰ç§æ–¹æ³•è§£å†³è¿™ä¸ªé—®é¢˜ï¼šå»å™ªè‡ªåŠ¨ç¼–ç å™¨ï¼Œå‹ç¼©è‡ªåŠ¨ç¼–ç å™¨å’Œç¨€ç–è‡ªåŠ¨ç¼–ç å™¨ã€‚
- en: Denoising autoencoders
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Denoisingè‡ªåŠ¨ç¼–ç å™¨
- en: The idea is that we want to train our model to learn how to reconstruct a noisy
    version of the input data.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: æƒ³æ³•æ˜¯æˆ‘ä»¬æƒ³è®­ç»ƒæˆ‘ä»¬çš„æ¨¡å‹å­¦ä¹ å¦‚ä½•é‡å»ºè¾“å…¥æ•°æ®çš„å˜ˆæ‚ç‰ˆæœ¬ã€‚
- en: We will use x to represent the original input, ![Denoising autoencoders](img/00130.jpeg),
    the noisy input, and ![Denoising autoencoders](img/00131.jpeg), the reconstructed
    output.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†ä½¿ç”¨xè¡¨ç¤ºåŸå§‹è¾“å…¥ï¼Œ![Denoising autoencoders](img/00130.jpeg)è¡¨ç¤ºå¸¦æœ‰å™ªéŸ³çš„è¾“å…¥ï¼Œ![Denoising
    autoencoders](img/00131.jpeg)è¡¨ç¤ºé‡å»ºçš„è¾“å‡ºã€‚
- en: The noisy input, ![Denoising autoencoders](img/00130.jpeg), is generated by
    randomly assigning a subset of the input ![Denoising autoencoders](img/00130.jpeg)
    to 0, with a given probability ğ‘, plus an additive isotropic Gaussian noise, with
    variance *v* for numerical inputs.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: å¸¦æœ‰å™ªå£°çš„è¾“å…¥ï¼Œ![Denoising autoencoders](img/00130.jpeg)ï¼Œæ˜¯é€šè¿‡éšæœºåˆ†é…è¾“å…¥![Denoising autoencoders](img/00130.jpeg)çš„å­é›†ä¸º0ï¼Œæ¦‚ç‡ä¸ºğ‘ï¼Œå†åŠ ä¸Šå…·æœ‰æ–¹å·®*v*çš„åŠ æ€§å„å‘åŒæ€§é«˜æ–¯å™ªå£°è€Œç”Ÿæˆçš„æ•°å€¼è¾“å…¥ã€‚
- en: We would then have two new hyper-parameters to tune ?? and ![Denoising autoencoders](img/00132.jpeg),
    which represent the noise level.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬å°†æœ‰ä¸¤ä¸ªæ–°çš„è¶…å‚æ•°è¦è°ƒæ•´??å’Œ![Denoising autoencoders](img/00132.jpeg)ï¼Œå®ƒä»¬ä»£è¡¨å™ªéŸ³æ°´å¹³ã€‚
- en: 'We will use the noisy variant, ![Denoising autoencoders](img/00130.jpeg), as
    the input of the network, but the loss function will still be the error between
    the output ![Denoising autoencoders](img/00131.jpeg) and the original noiseless
    input ![Denoising autoencoders](img/00130.jpeg). If the input dimensionality is
    *d*, the encoding function *f*, and the decoding function *g*, we will write the
    loss function *j* as this:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†ä½¿ç”¨å¸¦å™ªå£°çš„å˜ä½“ï¼Œ![Denoising autoencoders](img/00130.jpeg)ï¼Œä½œä¸ºç½‘ç»œçš„è¾“å…¥ï¼Œä½†æŸå¤±å‡½æ•°ä»ç„¶æ˜¯è¾“å‡º![Denoising
    autoencoders](img/00131.jpeg)ä¸åŸå§‹æ— å™ªå£°è¾“å…¥![Denoising autoencoders](img/00130.jpeg)ä¹‹é—´çš„è¯¯å·®ã€‚å¦‚æœè¾“å…¥ç»´åº¦æ˜¯*d*ï¼Œç¼–ç å‡½æ•°*f*ï¼Œè§£ç å‡½æ•°*g*ï¼Œæˆ‘ä»¬å°†æŠŠæŸå¤±å‡½æ•°*j*å†™æˆè¿™æ ·ï¼š
- en: '![Denoising autoencoders](img/00133.jpeg)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![Denoising autoencoders](img/00133.jpeg)'
- en: Here, *L* is the reconstruction error, typically either the MSE or the cross-entropy.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œï¼Œ*L*æ˜¯é‡æ„è¯¯å·®ï¼Œé€šå¸¸æ˜¯å‡æ–¹è¯¯å·®æˆ–äº¤å‰ç†µã€‚
- en: With this variant, if a hidden unit tries to exactly copy the input values,
    then the output layer cannot trust 100% because it knows that it could be the
    noise and not the original input. We are forcing the model to reconstruct based
    on the interrelationships between other input units, aka the meaningful structures
    of the data.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰äº†è¿™ç§å˜ä½“ï¼Œå¦‚æœä¸€ä¸ªéšè—å•å…ƒè¯•å›¾ç²¾ç¡®å¤åˆ¶è¾“å…¥å€¼ï¼Œé‚£ä¹ˆè¾“å‡ºå±‚å°±æ— æ³•å®Œå…¨ä¿¡ä»»ï¼Œå› ä¸ºå®ƒçŸ¥é“è¿™å¯èƒ½æ˜¯å™ªéŸ³è€Œä¸æ˜¯åŸå§‹è¾“å…¥ã€‚æˆ‘ä»¬æ­£åœ¨å¼ºè¿«æ¨¡å‹åŸºäºå…¶ä»–è¾“å…¥å•å…ƒä¹‹é—´çš„ç›¸äº’å…³ç³»æ¥é‡å»ºæ•°æ®çš„æœ‰æ„ä¹‰ç»“æ„ã€‚
- en: What we would expect is that the higher the added noise, the bigger the filters
    applied at each hidden unit. By filter, we mean the portion of the original input
    that is activated for that particular feature to be extracted. In case of no noise,
    hidden units tend to extract a tiny subset of the input data and propose it at
    the most untouched version to the next layer. By adding noise to the units, the
    error penalty on badly reconstructing ![Denoising autoencoders](img/00134.jpeg)
    will force the network to keep more information in order to contextualize the
    features regardless of the possible presence of noise.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æœŸæœ›çš„æ˜¯æ·»åŠ çš„å™ªå£°è¶Šå¤§ï¼Œåœ¨æ¯ä¸ªéšè—å•å…ƒä¸Šåº”ç”¨çš„æ»¤æ³¢å™¨å°±è¶Šå¤§ã€‚æ‰€è°“çš„æ»¤æ³¢å™¨æ˜¯æŒ‡é’ˆå¯¹æå–ç‰¹å®šç‰¹å¾è€Œæ¿€æ´»çš„åŸå§‹è¾“å…¥çš„éƒ¨åˆ†ã€‚å¦‚æœæ²¡æœ‰å™ªéŸ³ï¼Œéšè—å•å…ƒå€¾å‘äºæå–è¾“å…¥æ•°æ®çš„ä¸€ä¸ªå°å­é›†ï¼Œå¹¶å°†å…¶ä½œä¸ºæœ€ä¸è§¦åŠçš„ç‰ˆæœ¬æä¾›ç»™ä¸‹ä¸€å±‚ã€‚é€šè¿‡å‘å•å…ƒæ·»åŠ å™ªå£°ï¼Œå¯¹åé‡æ„![Denoising
    autoencoders](img/00134.jpeg)çš„é”™è¯¯æƒ©ç½šå°†è¿«ä½¿ç½‘ç»œä¿ç•™æ›´å¤šä¿¡æ¯ï¼Œä»¥ä¾¿åœ¨å¯èƒ½å­˜åœ¨å™ªéŸ³çš„æƒ…å†µä¸‹å¯¹ç‰¹å¾è¿›è¡Œä¸Šä¸‹æ–‡åŒ–ã€‚
- en: Please pay attention that just adding a small white noise could be equivalent
    to using weight decay regularization. Weight decay is a technique that consists
    of multiplying to a factor less than 1 the weights at each training epoch in order
    to limit the free parameters in our model. Although this is a popular technique
    to regularize neural networks, by setting inputs to 0 with probability *p*, we
    are effectively achieving a totally different result.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·æ³¨æ„ï¼Œåªéœ€æ·»åŠ ä¸€ä¸ªå°çš„ç™½å™ªå£°å°±ç›¸å½“äºä½¿ç”¨æƒé‡è¡°å‡æ­£åˆ™åŒ–ã€‚æƒé‡è¡°å‡æ˜¯ä¸€ç§æŠ€æœ¯ï¼Œå®ƒåœ¨æ¯ä¸ªè®­ç»ƒæ—¶æœŸå°†æƒé‡ä¹˜ä»¥å°äº1çš„å› å­ï¼Œä»¥ä¾¿é™åˆ¶æ¨¡å‹ä¸­çš„è‡ªç”±å‚æ•°ã€‚è™½ç„¶è¿™æ˜¯ä¸€ç§å¸¸ç”¨çš„ç¥ç»ç½‘ç»œæ­£åˆ™åŒ–æŠ€æœ¯ï¼Œä½†é€šè¿‡å°†è¾“å…¥è®¾ç½®ä¸º0çš„æ¦‚ç‡*p*ï¼Œæˆ‘ä»¬å®é™…ä¸Šå®ç°äº†å®Œå…¨ä¸åŒçš„ç»“æœã€‚
- en: We don't want to obtain high-frequency filters that when put together give us
    a more generalized model. Our denoising approach generates filters that do represent
    unique features of the underlying data structures and have individual meanings.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä¸å¸Œæœ›è·å¾—é«˜é¢‘æ»¤æ³¢å™¨ï¼Œè¿™äº›æ»¤æ³¢å™¨ç»„åˆåœ¨ä¸€èµ·ä¼šç»™å‡ºæ›´å¹¿ä¹‰çš„æ¨¡å‹ã€‚æˆ‘ä»¬çš„å»å™ªæ–¹æ³•ç”Ÿæˆä»£è¡¨æ½œåœ¨æ•°æ®ç»“æ„çš„ç‹¬ç‰¹ç‰¹å¾å¹¶å…·æœ‰ç‹¬ç«‹å«ä¹‰çš„æ»¤æ³¢å™¨ã€‚
- en: Contractive autoencoders
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æ”¶ç¼©è‡ªç¼–ç å™¨
- en: Contractive autoencoders aim to achieve a similar goal to that of the denoising
    approach by explicitly adding a term that penalizes when the model tries to learn
    uninteresting variations and promote only those variations that are observed in
    the training set.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: æ”¶ç¼©è‡ªç¼–ç å™¨æ—¨åœ¨é€šè¿‡æ˜ç¡®æ·»åŠ ä¸€ä¸ªæƒ©ç½šé¡¹æ¥å®ç°ç±»ä¼¼äºå»å™ªæ–¹æ³•çš„ç›®æ ‡ï¼Œå½“æ¨¡å‹è¯•å›¾å­¦ä¹ æ— è¶£çš„å˜åŒ–å¹¶ä¸”ä»…ä¿ƒè¿›åœ¨è®­ç»ƒé›†ä¸­è§‚å¯Ÿåˆ°çš„é‚£äº›å˜åŒ–æ—¶ï¼Œå®ƒå°±ä¼šå—åˆ°æƒ©ç½šã€‚
- en: In other words, the model may try to approximate the identity function by coming
    out with filters representing variations that are not necessarily present in the
    training data.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: æ¢å¥è¯è¯´ï¼Œæ¨¡å‹å¯èƒ½ä¼šè¯•å›¾é€šè¿‡äº§ç”Ÿä»£è¡¨è®­ç»ƒæ•°æ®ä¸­å¹¶éå¿…ç„¶å­˜åœ¨çš„å˜åŒ–çš„æ»¤æ³¢å™¨æ¥é€¼è¿‘æ’ç­‰å‡½æ•°ã€‚
- en: We can express this sensitivity as the sum of squares of all partial derivatives
    of the extracted features with respect to the input dimensions.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥å°†è¿™ç§æ•æ„Ÿæ€§è¡¨ç¤ºä¸ºæ‰€æå–ç‰¹å¾å¯¹è¾“å…¥ç»´åº¦çš„æ‰€æœ‰åå¯¼æ•°çš„å¹³æ–¹å’Œã€‚
- en: 'For an input *x* of dimensionality ![Contractive autoencoders](img/00135.jpeg)
    mapped by the encoding function *f* to the hidden representation *h* of size *d*[*h*],
    the following quantity corresponds to the L2 norm (Frobenius) of the Jacobian
    matrix ![Contractive autoencoders](img/00136.jpeg) of the encoder activations:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºç”±ç¼–ç å‡½æ•°*f*æ˜ å°„åˆ°å¤§å°ä¸º*d*[h]çš„éšè—è¡¨ç¤º*h*çš„ç»´åº¦ä¸º*x*çš„è¾“å…¥ï¼Œä»¥ä¸‹æ•°é‡å¯¹åº”äºç¼–ç å™¨æ¿€æ´»çš„é›…å¯æ¯”çŸ©é˜µçš„L2èŒƒæ•°ï¼ˆFrobeniusï¼‰ï¼š
- en: '![Contractive autoencoders](img/00137.jpeg)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![æ”¶ç¼©è‡ªç¼–ç å™¨](img/00137.jpeg)'
- en: 'The loss function will be modified as follows:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: æŸå¤±å‡½æ•°å°†ä¿®æ”¹å¦‚ä¸‹ï¼š
- en: '![Contractive autoencoders](img/00138.jpeg)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![æ”¶ç¼©è‡ªç¼–ç å™¨](img/00138.jpeg)'
- en: Here, Î» is the regularization factor. It is easy to see that the Frobenius norm
    of the Jacobian corresponds to L2 weight decay in the case of a linear encoder.
    The main difference is that for the linear case, the only way of achieving contraction
    would be by keeping weights very small. In case of a sigmoid non-linearity, we
    could also push the hidden units to their saturated regime.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼ŒÎ»æ˜¯æ­£åˆ™åŒ–å› å­ã€‚å¾ˆå®¹æ˜“çœ‹å‡ºï¼Œé›…å¯æ¯”çš„FrobeniusèŒƒæ•°åœ¨çº¿æ€§ç¼–ç å™¨çš„æƒ…å†µä¸‹å¯¹åº”äºL2æƒé‡è¡°å‡ã€‚ä¸»è¦çš„åŒºåˆ«åœ¨äºå¯¹äºçº¿æ€§æƒ…å†µï¼Œå®ç°æ”¶ç¼©çš„å”¯ä¸€æ–¹æ³•æ˜¯ä¿æŒæƒé‡éå¸¸å°ã€‚åœ¨sigmoidéçº¿æ€§çš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥æ¨åŠ¨éšè—å•å…ƒè¿›å…¥é¥±å’ŒçŠ¶æ€ã€‚
- en: Let's analyze the two terms.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬åˆ†æè¿™ä¸¤ä¸ªæœ¯è¯­ã€‚
- en: The error *J* (the MSE or cross-entropy) pushes toward keeping the most possible
    information to perfectly reconstruct the original value.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¯å·®*J*ï¼ˆMSEæˆ–äº¤å‰ç†µï¼‰æ¨åŠ¨ä¿ç•™å°½å¯èƒ½å¤šçš„ä¿¡æ¯ä»¥å®Œç¾é‡å»ºåŸå§‹å€¼ã€‚
- en: The penalty pushes toward getting rid of all of that information such that the
    derivatives of the hidden units with respect to *X* are minimized. A large value
    means that the learned representation is too unstable with respect to input variations.
    We obtain a small value when we observe very little change to the hidden representations
    as we change the input values. In case of the limit of these derivatives being
    0, we would only keep the information that is invariant with respect to the input
    *X*. We are effectively getting rid of all of the hidden features that are not
    stable enough and too sensitive to small perturbations.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: å¤„ç½šæ¨åŠ¨äº†æ‘†è„±æ‰€æœ‰è¿™äº›ä¿¡æ¯ï¼Œä½¿å¾—éšè—å•å…ƒå¯¹*X*çš„å¯¼æ•°æœ€å°åŒ–ã€‚å¤§å€¼æ„å‘³ç€æ‰€å­¦åˆ°çš„è¡¨ç¤ºå¯¹äºè¾“å…¥å˜åŒ–å¤ªä¸ç¨³å®šã€‚å½“æˆ‘ä»¬è§‚å¯Ÿåˆ°è¾“å…¥å€¼å˜åŒ–æ—¶ï¼Œæ‰€è§‚å¯Ÿåˆ°çš„éšè—è¡¨ç¤ºå‡ ä¹æ²¡æœ‰å˜åŒ–æ—¶ï¼Œæˆ‘ä»¬å¾—åˆ°ä¸€ä¸ªå°çš„å€¼ã€‚åœ¨è¿™äº›å¯¼æ•°é™åˆ¶ä¸º0çš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬åªä¿ç•™äº†ç›¸å¯¹äºè¾“å…¥*X*ä¸å˜çš„ä¿¡æ¯ã€‚æˆ‘ä»¬å®é™…ä¸Šæ‘†è„±äº†æ‰€æœ‰ä¸å¤Ÿç¨³å®šä¸”å¯¹å¾®å°æ‰°åŠ¨è¿‡äºæ•æ„Ÿçš„éšè—ç‰¹å¾ã€‚
- en: Let's suppose we have as input a lot of variations of the same data. In the
    case of images, they could be small rotations or different exposures of the same
    subject. In case of network traffic, they could be an increase/decrease of the
    packet header of the same type of traffic, maybe because of a packing/unpacking
    protocol.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: å‡è®¾æˆ‘ä»¬çš„è¾“å…¥æ˜¯åŒä¸€æ•°æ®çš„è®¸å¤šå˜åŒ–ã€‚åœ¨å›¾åƒçš„æƒ…å†µä¸‹ï¼Œå®ƒä»¬å¯èƒ½æ˜¯åŒä¸€ä¸»é¢˜çš„å°æ—‹è½¬æˆ–ä¸åŒæ›å…‰ã€‚åœ¨ç½‘ç»œæµé‡çš„æƒ…å†µä¸‹ï¼Œå®ƒä»¬å¯èƒ½æ˜¯åŒä¸€ç±»å‹æµé‡çš„æ•°æ®åŒ…å¤´éƒ¨çš„å¢åŠ /å‡å°‘ï¼Œå¯èƒ½æ˜¯ç”±äºåŒ…è£…/è§£åŒ…åè®®ã€‚
- en: If we only look at this dimension, the model is likely to be very sensitive.
    The Jacobian term would penalize the high sensitivity, but it is compensated by
    the low reconstruction error.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬åªçœ‹è¿™ä¸ªç»´åº¦ï¼Œæ¨¡å‹å¾ˆå¯èƒ½ä¼šéå¸¸æ•æ„Ÿã€‚é›…å¯æ¯”é¡¹å°†æƒ©ç½šé«˜æ•æ„Ÿæ€§ï¼Œä½†å®ƒä¼šè¢«ä½é‡æ„è¯¯å·®æ‰€æŠµæ¶ˆã€‚
- en: In this scenario, we would have one unit that is very sensitive on the variation
    direction but not very useful for all other directions. For example, in the case
    of pictures, we still have the same subject; thus, all of the remaining input
    values are constant. If we don't observe variations on a given direction in the
    training data, we want to discard the feature.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬ä¼šæœ‰ä¸€ä¸ªå•ä½ï¼Œå¯¹å˜åŒ–æ–¹å‘éå¸¸æ•æ„Ÿï¼Œä½†å¯¹æ‰€æœ‰å…¶ä»–æ–¹å‘å¹¶ä¸æ˜¯å¾ˆæœ‰ç”¨ã€‚ä¾‹å¦‚ï¼Œåœ¨å›¾ç‰‡çš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬ä»ç„¶æ‹¥æœ‰ç›¸åŒçš„ä¸»é¢˜ï¼›å› æ­¤ï¼Œæ‰€æœ‰å…¶ä½™çš„è¾“å…¥å€¼éƒ½æ˜¯å¸¸æ•°ã€‚å¦‚æœæˆ‘ä»¬åœ¨è®­ç»ƒæ•°æ®ä¸­æ²¡æœ‰è§‚å¯Ÿåˆ°ç»™å®šæ–¹å‘çš„å˜åŒ–ï¼Œæˆ‘ä»¬å¸Œæœ›ä¸¢å¼ƒè¯¥ç‰¹å¾ã€‚
- en: H2O currently does not support contractive autoencoders; however, an open issue
    can be found at [https://0xdata.atlassian.net/browse/PUBDEV-1265](https://0xdata.atlassian.net/browse/PUBDEV-1265).
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: H2Oç›®å‰ä¸æ”¯æŒæ”¶ç¼©è‡ªç¼–ç å™¨ï¼›ä½†æ˜¯ï¼Œå¯ä»¥åœ¨[https://0xdata.atlassian.net/browse/PUBDEV-1265](https://0xdata.atlassian.net/browse/PUBDEV-1265)æ‰¾åˆ°ä¸€ä¸ªæœªè§£å†³çš„é—®é¢˜ã€‚
- en: Sparse autoencoders
  id: totrans-107
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ç¨€ç–è‡ªç¼–ç å™¨
- en: Autoencoders, as we have seen them so far, always have the hidden layers smaller
    than the input.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: è‡ªç¼–ç å™¨ï¼Œæˆªè‡³ç›®å‰æˆ‘ä»¬æ‰€è§çš„ï¼Œéšè—å±‚å§‹ç»ˆå°äºè¾“å…¥ã€‚
- en: The major reason is that otherwise, the network would have enough capability
    to just memorize exactly the input and reconstruct it perfectly as it is. Adding
    extra capacity to the network would just be redundant.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸»è¦åŸå› æ˜¯å¦åˆ™ï¼Œç½‘ç»œå°†å…·æœ‰è¶³å¤Ÿçš„èƒ½åŠ›åªéœ€è®°å¿†è¾“å…¥å¹¶å®Œç¾åœ°é‡æ„å®ƒã€‚å‘ç½‘ç»œæ·»åŠ é¢å¤–çš„å®¹é‡åªä¼šæ˜¯å¤šä½™çš„ã€‚
- en: Reducing the capacity of the network forces to learn based on a compression
    version of the input. The algorithm will have to pick the most relevant features
    that help better reconstruct the training data.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: å‡å°‘ç½‘ç»œçš„å®¹é‡ä¼šè¿«ä½¿åŸºäºè¾“å…¥çš„å‹ç¼©ç‰ˆæœ¬è¿›è¡Œå­¦ä¹ ã€‚ç®—æ³•å°†ä¸å¾—ä¸é€‰æ‹©æœ€ç›¸å…³çš„ç‰¹å¾ï¼Œä»¥å¸®åŠ©æ›´å¥½åœ°é‡æ„è®­ç»ƒæ•°æ®ã€‚
- en: There are situations though where compressing is not feasible. Let's consider
    the case where each input node is formed by independent random variables. If the
    variables are not correlated with each other, the only way of achieving compression
    is to get rid of some of them entirely. We are effectively emulating the behavior
    of PCA.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œæœ‰äº›æƒ…å†µä¸‹å‹ç¼©æ˜¯ä¸å¯è¡Œçš„ã€‚è®©æˆ‘ä»¬è€ƒè™‘æ¯ä¸ªè¾“å…¥èŠ‚ç‚¹ç”±ç‹¬ç«‹éšæœºå˜é‡å½¢æˆçš„æƒ…å†µã€‚å¦‚æœå˜é‡å½¼æ­¤ä¸ç›¸å…³ï¼Œåˆ™å®ç°å‹ç¼©çš„å”¯ä¸€æ–¹æ³•æ˜¯å®Œå…¨æ‘†è„±å…¶ä¸­ä¸€äº›ã€‚æˆ‘ä»¬å®é™…ä¸Šæ­£åœ¨æ¨¡æ‹ŸPCAçš„è¡Œä¸ºã€‚
- en: In order to solve this problem, we can set a **sparsity** constraint on the
    hidden units. We will try to push each neuron to be inactive most of the time
    that corresponds to having the output of the activation function close to 0 for
    sigmoid and ReLU, -1 for tanh.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨éšè—å•å…ƒä¸Šè®¾ç½®ä¸€ä¸ª**ç¨€ç–**çº¦æŸã€‚æˆ‘ä»¬å°†å°è¯•æ¨åŠ¨æ¯ä¸ªç¥ç»å…ƒå¤§éƒ¨åˆ†æ—¶é—´å¤„äºä¸æ´»è·ƒçŠ¶æ€ï¼Œè¿™å¯¹äºsigmoidå’ŒReLUæ¥è¯´æ„å‘³ç€æ¿€æ´»å‡½æ•°çš„è¾“å‡ºæ¥è¿‘äº0ï¼Œå¯¹äºtanhæ¥è¯´æ˜¯-1ã€‚
- en: 'If we call ![Sparse autoencoders](img/00139.jpeg) the activation of hidden
    unit ![Sparse autoencoders](img/00140.jpeg) at layer ![Sparse autoencoders](img/00141.jpeg)
    when input is ![Sparse autoencoders](img/00142.jpeg), we can define the average
    activation of hidden unit ![Sparse autoencoders](img/00140.jpeg) as follows:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬ç§°å‘¼éšè—å•å…ƒ![Sparse autoencoders](img/00140.jpeg)åœ¨è¾“å…¥ä¸º![Sparse autoencoders](img/00142.jpeg)æ—¶çš„æ¿€æ´»ä¸º![Sparse
    autoencoders](img/00139.jpeg)ï¼Œæˆ‘ä»¬å¯ä»¥å¦‚ä¸‹å®šä¹‰éšè—å•å…ƒ![Sparse autoencoders](img/00140.jpeg)çš„å¹³å‡æ¿€æ´»ï¼š
- en: '![Sparse autoencoders](img/00143.jpeg)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![Sparse autoencoders](img/00143.jpeg)'
- en: Here, ![Sparse autoencoders](img/00144.jpeg) is the size of our training dataset
    (or batch of training data).
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œ![Sparse autoencoders](img/00144.jpeg)æ˜¯æˆ‘ä»¬çš„è®­ç»ƒæ•°æ®é›†ï¼ˆæˆ–è®­ç»ƒæ•°æ®æ‰¹æ¬¡ï¼‰çš„å¤§å°ã€‚
- en: The sparsity constraint consists of forcing ![Sparse autoencoders](img/00145.jpeg),
    where ![Sparse autoencoders](img/00146.jpeg) is the **sparsity parameter** bounded
    in the interval [1,0] and ideally close enough to 0.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: ç¨€ç–æ€§çº¦æŸåŒ…æ‹¬å¼ºåˆ¶![Sparse autoencoders](img/00145.jpeg)ï¼Œå…¶ä¸­![Sparse autoencoders](img/00146.jpeg)æ˜¯**ç¨€ç–å‚æ•°**ï¼Œåœ¨åŒºé—´[1,0]å†…ä¸”ç†æƒ³æƒ…å†µä¸‹è¶³å¤Ÿæ¥è¿‘0ã€‚
- en: The original paper ([http://web.stanford.edu/class/cs294a/sparseAutoencoder.pdf](http://web.stanford.edu/class/cs294a/sparseAutoencoder.pdf))
    recommends values near 0.05.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: åŸå§‹è®ºæ–‡([http://web.stanford.edu/class/cs294a/sparseAutoencoder.pdf](http://web.stanford.edu/class/cs294a/sparseAutoencoder.pdf))å»ºè®®å€¼æ¥è¿‘0.05ã€‚
- en: We model the average activation of each hidden unit as a Bernoulli random variable
    with mean ![Sparse autoencoders](img/00147.jpeg), and we want to force all of
    them to converge to a Bernoulli distribution with mean ![Sparse autoencoders](img/00146.jpeg)
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†æ¯ä¸ªéšè—å•å…ƒçš„å¹³å‡æ¿€æ´»å€¼å»ºæ¨¡ä¸ºå…·æœ‰å‡å€¼![ç¨€ç–è‡ªç¼–ç å™¨](img/00147.jpeg)çš„ä¼¯åŠªåˆ©éšæœºå˜é‡ï¼Œå¹¶ä¸”æˆ‘ä»¬å¸Œæœ›æ‰€æœ‰è¿™äº›éƒ½è¶‹å‘äºå…·æœ‰å‡å€¼![ç¨€ç–è‡ªç¼–ç å™¨](img/00146.jpeg)çš„ä¼¯åŠªåˆ©åˆ†å¸ƒã€‚
- en: In order to do so, we need to add an extra penalty that quantifies the divergence
    of those two distributions. We can define this penalty based on the **Kullback-Leibler**
    (**KL**) divergence between the real distribution ![Sparse autoencoders](img/00148.jpeg)
    and the theoretical one ![Sparse autoencoders](img/00149.jpeg) we would like to
    achieve.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†å®ç°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬éœ€è¦æ·»åŠ ä¸€ä¸ªé¢å¤–çš„æƒ©ç½šé¡¹ï¼Œç”¨äºé‡åŒ–è¿™ä¸¤ä¸ªåˆ†å¸ƒä¹‹é—´çš„å·®å¼‚ã€‚æˆ‘ä»¬å¯ä»¥æ ¹æ®æˆ‘ä»¬å¸Œæœ›å®ç°çš„å®é™…åˆ†å¸ƒ![ç¨€ç–è‡ªç¼–ç å™¨](img/00148.jpeg)å’Œç†è®ºåˆ†å¸ƒ![ç¨€ç–è‡ªç¼–ç å™¨](img/00149.jpeg)ä¹‹é—´çš„**Kullback-Leibler**ï¼ˆ**KL**ï¼‰æ•£åº¦æ¥å®šä¹‰è¿™ä¸ªæƒ©ç½šã€‚
- en: 'In general, for discrete probability distributions *P* and *Q*, the *KL* divergence
    when information is measured in bits is defined as follows:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: é€šå¸¸æƒ…å†µä¸‹ï¼Œå¯¹äºç¦»æ•£æ¦‚ç‡åˆ†å¸ƒ*P*å’Œ*Q*ï¼Œä»¥æ¯”ç‰¹ä¸ºå•ä½æµ‹é‡ä¿¡æ¯æ—¶ï¼Œ*KL*æ•£åº¦å®šä¹‰å¦‚ä¸‹ï¼š
- en: '![Sparse autoencoders](img/00150.jpeg)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![ç¨€ç–è‡ªç¼–ç å™¨](img/00150.jpeg)'
- en: One requirement is that *P* is absolutely continuous with respect to *Q*, that
    is, ![Sparse autoencoders](img/00151.jpeg) for any measurable value of *x*. This
    is also written as ![Sparse autoencoders](img/00152.jpeg). Whenever ![Sparse autoencoders](img/00153.jpeg),
    the contribution of that term will be ![Sparse autoencoders](img/00154.jpeg) since
    that ![Sparse autoencoders](img/00155.jpeg).
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ä¸€ä¸ªè¦æ±‚æ˜¯*P*å¯¹*Q*ç»å¯¹è¿ç»­ï¼Œå³å¯¹äºä»»æ„å¯æµ‹çš„å€¼*P*éƒ½æ»¡è¶³![ç¨€ç–è‡ªç¼–ç å™¨](img/00151.jpeg)ã€‚è¿™ä¹Ÿå¯ä»¥å†™æˆ![ç¨€ç–è‡ªç¼–ç å™¨](img/00152.jpeg)ã€‚æ¯å½“![ç¨€ç–è‡ªç¼–ç å™¨](img/00153.jpeg)æ—¶ï¼Œè¯¥é¡¹çš„è´¡çŒ®å°†æ˜¯![ç¨€ç–è‡ªç¼–ç å™¨](img/00154.jpeg)ï¼Œå› ä¸ºé‚£æ—¶çš„![ç¨€ç–è‡ªç¼–ç å™¨](img/00155.jpeg)ã€‚
- en: 'In our case, the ![Sparse autoencoders](img/00156.jpeg) divergence of unit
    *j* would be as follows:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘ä»¬çš„æ¡ˆä¾‹ä¸­ï¼Œå•å…ƒ*j*çš„ç¨€ç–è‡ªç¼–ç å™¨æ•£åº¦å¦‚ä¸‹ï¼š
- en: '![Sparse autoencoders](img/00157.jpeg)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![ç¨€ç–è‡ªç¼–ç å™¨](img/00157.jpeg)'
- en: This function has the property to be ![Sparse autoencoders](img/00154.jpeg)
    when the two means are equal and increase monotonically, otherwise until approaching
    8 when ![Sparse autoencoders](img/00158.jpeg) is close to
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ä¸¤ä¸ªå¹³å‡å€¼ç›¸ç­‰ä¸”å•è°ƒé€’å¢æ—¶ï¼Œæ­¤å‡½æ•°çš„æ€§è´¨æ˜¯![ç¨€ç–è‡ªç¼–ç å™¨](img/00154.jpeg)ï¼Œå¦åˆ™ç›´åˆ°![ç¨€ç–è‡ªç¼–ç å™¨](img/00158.jpeg)æ¥è¿‘8æ—¶ï¼Œ![ç¨€ç–è‡ªç¼–ç å™¨](img/00154.jpeg)ä¼šåƒè¿™æ ·å¢åŠ ã€‚
- en: '![Sparse autoencoders](img/00154.jpeg)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![ç¨€ç–è‡ªç¼–ç å™¨](img/00154.jpeg)'
- en: or 1.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ–1ã€‚
- en: 'The final loss function with extra penalty term added will be this:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€ç»ˆå¸¦æœ‰é¢å¤–æƒ©ç½šé¡¹çš„æŸå¤±å‡½æ•°å¦‚ä¸‹ï¼š
- en: '![Sparse autoencoders](img/00159.jpeg)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![ç¨€ç–è‡ªç¼–ç å™¨](img/00159.jpeg)'
- en: Here, *J* is the standard loss function (the RMSE), ![Sparse autoencoders](img/00160.jpeg)
    is the number of hidden units, and ÃŸ is a weight of the sparsity term.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œ*J*æ˜¯æ ‡å‡†æŸå¤±å‡½æ•°ï¼ˆå‡æ–¹æ ¹è¯¯å·®ï¼‰ï¼Œ![ç¨€ç–è‡ªç¼–ç å™¨](img/00160.jpeg)æ˜¯éšè—å•å…ƒçš„æ•°é‡ï¼ŒÃŸæ˜¯ç¨€ç–é¡¹çš„æƒé‡ã€‚
- en: This extra penalty will cause a small inefficiency to the backpropagation algorithm.
    In particular, the preceding formula will require an additional forward step over
    the whole training set to precompute the average activations ![Sparse autoencoders](img/00158.jpeg)
    before computing the backpropagation on each example.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªé¢å¤–çš„æƒ©ç½šå°†å¯¼è‡´åå‘ä¼ æ’­ç®—æ³•å‡ºç°ä¸€äº›å°çš„ä½æ•ˆã€‚ç‰¹åˆ«æ˜¯ï¼Œå‰è¿°å…¬å¼åœ¨è®¡ç®—æ¯ä¸ªç¤ºä¾‹çš„åå‘ä¼ æ’­ä¹‹å‰ï¼Œå°†éœ€è¦ç»è¿‡æ•´ä¸ªè®­ç»ƒé›†è¿›è¡Œé¢å¤–çš„å‰å‘æ­¥éª¤æ¥é¢„å…ˆè®¡ç®—å¹³å‡æ¿€æ´»å€¼![ç¨€ç–è‡ªç¼–ç å™¨](img/00158.jpeg)ã€‚
- en: Summary of autoencoders
  id: totrans-132
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è‡ªç¼–ç å™¨æ€»ç»“
- en: Autoencoders are powerful unsupervised learning algorithms, which are getting
    popularity in fields such as anomaly detection or feature engineering, using the
    output of intermediate layers as features to train a supervised model instead
    of the raw input data.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: è‡ªç¼–ç å™¨æ˜¯å¼ºå¤§çš„æ— ç›‘ç£å­¦ä¹ ç®—æ³•ï¼Œåœ¨å¼‚å¸¸æ£€æµ‹æˆ–ç‰¹å¾å·¥ç¨‹ç­‰é¢†åŸŸè¶Šæ¥è¶Šå—æ¬¢è¿ï¼Œä½¿ç”¨ä¸­é—´å±‚çš„è¾“å‡ºä½œä¸ºç‰¹å¾æ¥è®­ç»ƒç›‘ç£æ¨¡å‹ï¼Œè€Œä¸æ˜¯ä½¿ç”¨åŸå§‹è¾“å…¥æ•°æ®ã€‚
- en: Unsupervised means they do not require labels or ground truth to be specified
    during training. They just work with whatever data you put as input as long as
    the network has enough capability to learn and represent the intrinsic existing
    relationships. That means that we can set both the size of the code layer (the
    reduced dimensionality *m*) but obtain different results depending on the number
    and size of the hidden layers, if any.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: æ— ç›‘ç£æ„å‘³ç€åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¸éœ€è¦æŒ‡å®šæ ‡ç­¾æˆ–åœ°é¢çœŸç›¸ã€‚åªè¦ç½‘ç»œæœ‰è¶³å¤Ÿçš„èƒ½åŠ›å­¦ä¹ å’Œè¡¨ç¤ºå†…åœ¨çš„å­˜åœ¨å…³ç³»ï¼Œå®ƒä»¬å°±å¯ä»¥å¤„ç†è¾“å…¥çš„ä»»ä½•æ•°æ®ã€‚è¿™æ„å‘³ç€æˆ‘ä»¬å¯ä»¥è®¾å®šç¼–ç å±‚çš„å¤§å°ï¼ˆå‡å°‘çš„ç»´åº¦*m*ï¼‰ï¼Œä½†æ ¹æ®éšè—å±‚çš„æ•°é‡å’Œå¤§å°æ¥è·å¾—ä¸åŒçš„ç»“æœã€‚
- en: If we are building an autoencoder network, we want to achieve robustness in
    order to avoid wrong representations but at the same time not limit the capacity
    of the network by compressing the information through smaller sequential layers.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬æ­£åœ¨æ„å»ºä¸€ä¸ªè‡ªåŠ¨ç¼–ç å™¨ç½‘ç»œï¼Œæˆ‘ä»¬å¸Œæœ›åœ¨é¿å…é”™è¯¯è¡¨ç¤ºçš„åŒæ—¶å®ç°ç¨³å¥æ€§ï¼Œä½†åŒæ—¶ä¸è¦é€šè¿‡è¾ƒå°çš„é¡ºåºå±‚å‹ç¼©ä¿¡æ¯æ¥é™åˆ¶ç½‘ç»œçš„å®¹é‡ã€‚
- en: Denoising, contractive, and autoencoders are all great techniques for solving
    those problems.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: é™¤å™ªå£°ã€æ”¶ç¼©å’Œè‡ªåŠ¨ç¼–ç å™¨éƒ½æ˜¯è§£å†³è¿™äº›é—®é¢˜çš„å¾ˆå¥½çš„æŠ€æœ¯ã€‚
- en: Adding noise is generally simpler and doesn't add complexity in the loss function,
    which results in less computation. On the other hand, the noisy input makes the
    gradient to be sampled and also discard part of the information in exchange for
    better features.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: æ·»åŠ å™ªå£°é€šå¸¸æ›´ç®€å•ï¼Œè€Œä¸”ä¸ä¼šåœ¨æŸå¤±å‡½æ•°ä¸­å¢åŠ å¤æ‚æ€§ï¼Œè¿™ä¼šå¯¼è‡´æ›´å°‘çš„è®¡ç®—ã€‚å¦ä¸€æ–¹é¢ï¼Œå˜ˆæ‚çš„è¾“å…¥ä½¿æ¢¯åº¦å˜å¾—ä¸ç¨³å®šï¼Œå¹¶ä¸”ä¸ºäº†è·å¾—æ›´å¥½çš„ç‰¹å¾è€Œä¸¢å¼ƒéƒ¨åˆ†ä¿¡æ¯ã€‚
- en: Contractive autoencoders are very good at making the model more stable to small
    deviations from the training distribution. Thus, it is a very good candidate for
    reducing false alarms. The drawback is a sort of countereffect that increases
    the reconstruction error in order to reduce the sensibility.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: æ”¶ç¼©è‡ªåŠ¨ç¼–ç å™¨éå¸¸æ“…é•¿ä½¿æ¨¡å‹å¯¹è®­ç»ƒåˆ†å¸ƒçš„å°åå·®æ›´åŠ ç¨³å®šã€‚å› æ­¤ï¼Œå®ƒæ˜¯å‡å°‘è¯¯æŠ¥çš„ä¸€ä¸ªå¾ˆå¥½çš„é€‰æ‹©ã€‚ç¼ºç‚¹æ˜¯ä¸€ç§åæ•ˆæœï¼Œå®ƒä¼šå¢åŠ é‡æ„è¯¯å·®ä»¥å‡å°‘æ•æ„Ÿæ€§ã€‚
- en: Sparse autoencoders are probably the most complete around solution. It is the
    most expensive to compute for large datasets, but since the gradient is deterministic,
    it can be useful in case of second-order optimizers and, in general, to provide
    a good trade-off between stability and low reconstruction error.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: ç¨€ç–è‡ªåŠ¨ç¼–ç å™¨å¯èƒ½æ˜¯æœ€å®Œæ•´çš„è§£å†³æ–¹æ¡ˆã€‚å¯¹äºå¤§å‹æ•°æ®é›†æ¥è¯´ï¼Œå®ƒè®¡ç®—æˆæœ¬æœ€é«˜ï¼Œä½†ç”±äºæ¢¯åº¦æ˜¯ç¡®å®šçš„ï¼Œå®ƒå¯ä»¥åœ¨äºŒé˜¶ä¼˜åŒ–å™¨çš„æƒ…å†µä¸‹æä¾›å¾ˆå¥½çš„ç¨³å®šæ€§å’Œä½é‡æ„è¯¯å·®ã€‚
- en: Regardless of what choice you make, adopting a regularization technique is strongly
    recommended. They both come with hyper-parameters to tune, which we will see how
    to optimize in the corresponding *Tuning* section.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ç®¡ä½ åšå‡ºä»€ä¹ˆé€‰æ‹©ï¼Œé‡‡ç”¨æ­£åˆ™åŒ–æŠ€æœ¯éƒ½æ˜¯å¼ºçƒˆæ¨èçš„ã€‚å®ƒä»¬éƒ½å¸¦æœ‰è¶…å‚æ•°éœ€è°ƒæ•´ï¼Œæˆ‘ä»¬å°†åœ¨ç›¸åº”çš„*Tuning*éƒ¨åˆ†ä¸­çœ‹åˆ°å¦‚ä½•ä¼˜åŒ–ã€‚
- en: In addition to the techniques described so far, it is worth mentioning variational
    autoencoders, which seem to be the ultimate solution for regularizing autoencoders.
    Variational autoencoders belong to the class of generative models. They don't
    just learn the structures that better describe the training data, they learn the
    parameters of a latent unit Gaussian distribution that can best regenerate the
    input data. The final loss function will be the sum of the reconstruction error
    and the KL divergence between the reconstructed latent variable and the Gaussian
    distribution. The encoder phase will generate a code consisting of a vector of
    means and a vector of standard deviations. From the code, we can characterize
    the latent distribution parameters and reconstruct the original input by sampling
    from that distribution.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: é™¤äº†è¿„ä»Šä¸ºæ­¢æè¿°çš„æŠ€æœ¯å¤–ï¼Œå€¼å¾—ä¸€æçš„æ˜¯å˜åˆ†è‡ªåŠ¨ç¼–ç å™¨ï¼Œå®ƒä¼¼ä¹æ˜¯æ­£åˆ™åŒ–è‡ªåŠ¨ç¼–ç å™¨çš„æœ€ç»ˆè§£å†³æ–¹æ¡ˆã€‚å˜åˆ†è‡ªåŠ¨ç¼–ç å™¨å±äºç”Ÿæˆæ¨¡å‹ç±»åˆ«ã€‚å®ƒä¸ä»…å­¦ä¹ äº†æœ€å¥½åœ°æè¿°è®­ç»ƒæ•°æ®çš„ç»“æ„ï¼Œè¿˜å­¦ä¹ äº†æ½œåœ¨å•ä½é«˜æ–¯åˆ†å¸ƒçš„å‚æ•°ï¼Œè¿™äº›å‚æ•°å¯ä»¥æœ€å¥½åœ°å†ç°è¾“å…¥æ•°æ®ã€‚æœ€ç»ˆçš„æŸå¤±å‡½æ•°å°†æ˜¯é‡æ„è¯¯å·®å’Œé‡æ„çš„æ½œåœ¨å˜é‡ä¹‹é—´çš„KLæ•£åº¦çš„æ€»å’Œã€‚ç¼–ç å™¨é˜¶æ®µå°†ç”Ÿæˆç”±å‡å€¼å’Œæ ‡å‡†å·®å‘é‡ç»„æˆçš„ä»£ç ã€‚ä»ä»£ç ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥è¡¨å¾æ½œåœ¨åˆ†å¸ƒå‚æ•°ï¼Œå¹¶é€šè¿‡ä»è¯¥åˆ†å¸ƒä¸­é‡‡æ ·é‡æ„åŸå§‹è¾“å…¥ã€‚
- en: Restricted Boltzmann machines
  id: totrans-142
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å—é™ç»å°”å…¹æ›¼æœº
- en: In the early 90s, neural networks had largely gone out of fashion. The bulk
    of machine learning research was around other techniques, such as random forests
    and support vector machines. Neural networks with only a single hidden layer were
    less performant than these other techniques, and it was thought that deeper neural
    networks were too difficult to train.
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨90å¹´ä»£åˆï¼Œç¥ç»ç½‘ç»œåŸºæœ¬ä¸Šå·²ç»è¿‡æ—¶ã€‚æœºå™¨å­¦ä¹ ç ”ç©¶çš„å¤§éƒ¨åˆ†å†…å®¹æ˜¯å…³äºå…¶ä»–æŠ€æœ¯ï¼Œå¦‚éšæœºæ£®æ—å’Œæ”¯æŒå‘é‡æœºã€‚åªæœ‰ä¸€ä¸ªéšè—å±‚çš„ç¥ç»ç½‘ç»œè¡¨ç°ä¸å¦‚è¿™äº›å…¶ä»–æŠ€æœ¯ï¼Œè€Œä¸”äººä»¬è®¤ä¸ºè®­ç»ƒæ›´æ·±çš„ç¥ç»ç½‘ç»œå¤ªå›°éš¾ã€‚
- en: The resurgence of interest in neural networks was spearheaded by Geoffrey Hinton,
    who, in 2004, led a team of researchers who proceeded to make a series of breakthroughs
    using restricted Boltzmann machines (RBM) and creating neural networks with many
    layers; they called this approach deep learning. Within 10 years, deep learning
    would go from being a niche technique to dominating every single AI competition.
    RBMs were part of the big breakthrough, allowing Hinton and others to get world
    record scores on a variety of image and speech recognition problems.
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å…´è¶£å†æ¬¡é«˜æ¶¨äºç¥ç»ç½‘ç»œï¼Œç”±2004å¹´ç”±**Geoffrey Hinton**é¢†å¯¼çš„ç ”ç©¶å›¢é˜Ÿç‡å…ˆä½¿ç”¨å—é™ç»å°”å…¹æ›¼æœºï¼ˆRBMï¼‰å–å¾—ä¸€ç³»åˆ—çªç ´ï¼Œåˆ›é€ äº†å…·æœ‰å¤šå±‚çš„ç¥ç»ç½‘ç»œï¼›ä»–ä»¬å°†è¿™ç§æ–¹æ³•ç§°ä¸ºæ·±åº¦å­¦ä¹ ã€‚åœ¨10å¹´å†…ï¼Œæ·±åº¦å­¦ä¹ ä»ä¸€ç§å°ä¼—æŠ€æœ¯å‘å±•åˆ°ä¸»å¯¼æ¯ä¸€ä¸ªäººå·¥æ™ºèƒ½ç«èµ›ã€‚RBMæ˜¯è¿™ä¸€å·¨å¤§çªç ´çš„ä¸€éƒ¨åˆ†ï¼Œä½¿å¾—Hintonå’Œå…¶ä»–äººåœ¨å¤šç§å›¾åƒå’Œè¯­éŸ³è¯†åˆ«é—®é¢˜ä¸Šå–å¾—ä¸–ç•Œçºªå½•æˆç»©ã€‚
- en: In this section, we will look at the theory of how RBMs work, how to implement
    them, and how they can be combined into deep belief networks.
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸€éƒ¨åˆ†ä¸­ï¼Œæˆ‘ä»¬å°†ç ”ç©¶RBMçš„å·¥ä½œåŸç†ï¼Œå¦‚ä½•å®ç°å®ƒä»¬ä»¥åŠå¦‚ä½•å°†å®ƒä»¬ç»“åˆæˆæ·±åº¦ä¿¡å¿µç½‘ç»œã€‚
- en: 'A restricted Boltzmann machine looks a lot like a single layer of a neural
    network. There are a set of input nodes that have connections to another set of
    output nodes:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€å°å—é™ç»å°”å…¹æ›¼æœºçœ‹èµ·æ¥å¾ˆåƒæ˜¯ç¥ç»ç½‘ç»œçš„ä¸€ä¸ªå•å±‚ã€‚æœ‰ä¸€ç»„è¾“å…¥èŠ‚ç‚¹ä¸å¦ä¸€ç»„è¾“å‡ºèŠ‚ç‚¹ç›¸è¿ï¼š
- en: '![Restricted Boltzmann machines](img/00161.jpeg)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![å—é™ç»å°”å…¹æ›¼æœº](img/00161.jpeg)'
- en: Figure 1\. Restricted Boltzmann machine
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾1ã€‚å—é™ç»å°”å…¹æ›¼æœº
- en: The way these output nodes are activated is also identical to an autoencoder.
    There is a weight between each input node and output node, the activation of each
    input nodes multiplied by this matrix of weight mappings, and a bias vector is
    then applied, and the sum for each output node is then put through a sigmoid function.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: è¾“å‡ºèŠ‚ç‚¹è¢«æ¿€æ´»çš„æ–¹å¼ä¹Ÿä¸è‡ªç¼–ç å™¨å®Œå…¨ç›¸åŒã€‚æ¯ä¸ªè¾“å…¥èŠ‚ç‚¹å’Œè¾“å‡ºèŠ‚ç‚¹ä¹‹é—´æœ‰ä¸€ä¸ªæƒé‡ï¼Œæ¯ä¸ªè¾“å…¥èŠ‚ç‚¹çš„æ¿€æ´»ä¹˜ä»¥è¿™ä¸ªæƒé‡æ˜ å°„çŸ©é˜µï¼Œç„¶ååº”ç”¨åç½®å‘é‡ï¼Œå¹¶ä¸”æ¯ä¸ªè¾“å‡ºèŠ‚ç‚¹çš„æ€»å’Œå°†é€šè¿‡ä¸€ä¸ªsigmoidå‡½æ•°ã€‚
- en: What makes a restricted Boltzmann machine different is what the activations
    represent, how we think about them, and the way in which they are trained. To
    begin with, when talking about RBMs rather than talking about input and output
    layers, we refer to the layers as visible and hidden. This is because, when training,
    the visible nodes represent the known information we have. The hidden nodes will
    aim to represent some variables that generated the visible data. This contrasts
    with an autoencoder, where the output layer doesn't explicitly represent anything,
    is just a constrained space through which the information is passed.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿å¾—å—é™ç»å°”å…¹æ›¼æœºä¸ä¼—ä¸åŒçš„æ˜¯æ¿€æ´»ä»£è¡¨çš„å†…å®¹ã€æˆ‘ä»¬å¯¹å®ƒä»¬çš„æ€è€ƒæ–¹å¼ä»¥åŠå®ƒä»¬çš„è®­ç»ƒæ–¹å¼ã€‚é¦–å…ˆï¼Œå½“è°ˆè®ºRBMæ—¶ï¼Œæˆ‘ä»¬ä¸æ˜¯è°ˆè®ºè¾“å…¥å’Œè¾“å‡ºå±‚ï¼Œè€Œæ˜¯å°†å±‚ç§°ä¸ºå¯è§å±‚å’Œéšè—å±‚ã€‚è¿™æ˜¯å› ä¸ºåœ¨è®­ç»ƒæ—¶ï¼Œå¯è§èŠ‚ç‚¹ä»£è¡¨æˆ‘ä»¬å·²çŸ¥çš„ä¿¡æ¯ï¼Œè€Œéšè—èŠ‚ç‚¹å°†æ—¨åœ¨ä»£è¡¨ç”Ÿæˆå¯è§æ•°æ®çš„ä¸€äº›å˜é‡ã€‚è¿™ä¸è‡ªç¼–ç å™¨å½¢æˆå¯¹æ¯”ï¼Œè‡ªç¼–ç å™¨çš„è¾“å‡ºå±‚ä¸å†æ˜ç¡®åœ°ä»£è¡¨ä»»ä½•ä¸œè¥¿ï¼Œåªæ˜¯é€šè¿‡ä¿¡æ¯ä¼ é€’çš„ä¸€ç§å—é™ç©ºé—´ã€‚
- en: The basis of learning the weights of a restricted Boltzmann machine comes from
    statistical physics and uses an **energy-based model** (**EBM**). In these, every
    state is put through an energy function, which relates to the probability of a
    state occurring. If an energy function returns a high value, we expect this state
    to be unlikely, rarely occurring. Conversely, a low result from an energy function
    means a state that is more stable and will occur more frequently.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: å­¦ä¹ å—é™ç»å°”å…¹æ›¼æœºçš„æƒé‡åŸºç¡€äºç»Ÿè®¡ç‰©ç†å­¦ï¼Œå¹¶ä½¿ç”¨åŸºäºèƒ½é‡çš„æ¨¡å‹ï¼ˆEBMï¼‰ã€‚åœ¨è¿™äº›æ¨¡å‹ä¸­ï¼Œæ¯ä¸ªçŠ¶æ€éƒ½ç»å†ä¸€ä¸ªèƒ½é‡å‡½æ•°ï¼Œå®ƒä¸çŠ¶æ€å‘ç”Ÿæ¦‚ç‡ç›¸å…³ã€‚å¦‚æœèƒ½é‡å‡½æ•°è¿”å›ä¸€ä¸ªé«˜å€¼ï¼Œæˆ‘ä»¬æœŸæœ›è¿™ç§çŠ¶æ€ä¸å¤ªå¯èƒ½å‘ç”Ÿï¼Œå¾ˆå°‘å‘ç”Ÿã€‚ç›¸åï¼Œèƒ½é‡å‡½æ•°çš„ä½ç»“æœæ„å‘³ç€ä¸€ä¸ªæ›´ç¨³å®šçš„çŠ¶æ€ï¼Œä¼šæ›´é¢‘ç¹å‘ç”Ÿã€‚
- en: A good intuitive way of thinking about an energy function is to imagine a huge
    number of bouncy balls being thrown into a box. At first, all the balls have high
    energy and so will be bouncing very high. A state here would be a single snapshot
    in time of all the balls' positions and their associated velocities. These states,
    when the balls are bouncing, are going to be very transitory; they will only exist
    for moments and because of the range of movement of the balls, are very unlikely
    to reoccur. But as the balls start to settle, as the energy leaves the system,
    some of the balls will start to be increasingly stationary. These states are stable
    once it occurs once it never stops occurring. Eventually, once the balls have
    stopped bouncing and all become stationary, we have a completely stable state,
    which has high probability.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªå¾ˆå¥½çš„ç›´è§‚æ€è€ƒèƒ½é‡å‡½æ•°çš„æ–¹å¼æ˜¯æƒ³è±¡å°†å¤§é‡çš„å¼¹è·³çƒæ‰”è¿›ä¸€ä¸ªç®±å­ä¸­ã€‚èµ·åˆï¼Œæ‰€æœ‰çš„çƒéƒ½å…·æœ‰å¾ˆé«˜çš„èƒ½é‡ï¼Œå› æ­¤ä¼šå¼¹å¾—å¾ˆé«˜ã€‚è¿™é‡Œçš„çŠ¶æ€æ˜¯æ‰€æœ‰çƒçš„ä½ç½®å’Œå®ƒä»¬å…³è”é€Ÿåº¦çš„ä¸€ä¸ªæ—¶é—´ç‚¹å¿«ç…§ã€‚å½“çƒåœ¨å¼¹è·³æ—¶ï¼Œè¿™äº›çŠ¶æ€å°†ä¼šéå¸¸çŸ­æš‚ï¼›å®ƒä»¬åªä¼šå­˜åœ¨ç‰‡åˆ»ï¼Œå› ä¸ºçƒçš„ç§»åŠ¨èŒƒå›´å¾ˆå¤§ï¼Œå¾ˆä¸å¯èƒ½å†æ¬¡å‡ºç°ã€‚ä½†æ˜¯å½“çƒå¼€å§‹å¹³é™ä¸‹æ¥ï¼Œå½“èƒ½é‡ç¦»å¼€ç³»ç»Ÿæ—¶ï¼Œä¸€äº›çƒå°†å¼€å§‹è¶Šæ¥è¶Šé™æ­¢ã€‚è¿™äº›çŠ¶æ€ä¸€æ—¦å‘ç”Ÿä¸€æ¬¡å°±ç¨³å®šäº†ï¼Œä¸€æ—¦å‘ç”Ÿå°±ä¸ä¼šåœæ­¢ã€‚æœ€ç»ˆï¼Œå½“çƒåœæ­¢å¼¹è·³å¹¶ä¸”éƒ½å˜æˆé™æ­¢æ—¶ï¼Œæˆ‘ä»¬æœ‰ä¸€ä¸ªå®Œå…¨ç¨³å®šçš„çŠ¶æ€ï¼Œå…·æœ‰å¾ˆé«˜çš„æ¦‚ç‡ã€‚
- en: To give an example that applies to restricted Boltzmann machines, consider the
    task of learning a group of images of butterflies. We train our RBM on these images,
    and we want it to assign a low energy value to any image of a butterflies. But
    when given an image from a different set, say cars, it will give it a high energy
    value. Related objects, such as moths, bats, or birds, may have a more medium
    energy value.
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä»¥åº”ç”¨äºå—é™æ³¢å°”å…¹æ›¼æœºçš„ä¾‹å­ï¼Œè€ƒè™‘å­¦ä¹ ä¸€ç»„è´è¶å›¾åƒçš„ä»»åŠ¡ã€‚æˆ‘ä»¬åœ¨è¿™äº›å›¾åƒä¸Šè®­ç»ƒæˆ‘ä»¬çš„RBMï¼Œå¹¶ä¸”å¸Œæœ›å®ƒå¯¹ä»»ä½•è´è¶å›¾åƒåˆ†é…ä½èƒ½é‡å€¼ã€‚ä½†æ˜¯å½“ç»™å‡ºæ¥è‡ªä¸åŒé›†åˆçš„å›¾åƒï¼Œæ¯”å¦‚æ±½è½¦æ—¶ï¼Œå®ƒä¼šç»™å®ƒåˆ†é…ä¸€ä¸ªé«˜èƒ½é‡å€¼ã€‚ç›¸å…³çš„å¯¹è±¡ï¼Œå¦‚è›¾å­ã€è™è æˆ–é¸Ÿï¼Œå¯èƒ½å…·æœ‰ä¸­ç­‰èƒ½é‡å€¼ã€‚
- en: If we have an energy function defined, the probability of a given state is then
    given as follows:![Restricted Boltzmann machines](img/00162.jpeg)
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬å®šä¹‰äº†ä¸€ä¸ªèƒ½é‡å‡½æ•°ï¼Œé‚£ä¹ˆç»™å®šçŠ¶æ€çš„æ¦‚ç‡å°±å¦‚ä¸‹æ‰€ç¤ºï¼š![å—é™æ³¢å°”å…¹æ›¼æœº](img/00162.jpeg)
- en: Here, v is our state, E is our energy function, and Z is the partition function;
    the sum of all possible configurations of v is defined as follows:![Restricted
    Boltzmann machines](img/00163.jpeg)
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œvæ˜¯æˆ‘ä»¬çš„çŠ¶æ€ï¼ŒEæ˜¯æˆ‘ä»¬çš„èƒ½é‡å‡½æ•°ï¼ŒZæ˜¯åˆ†åŒºå‡½æ•°ï¼›vçš„æ‰€æœ‰å¯èƒ½é…ç½®çš„æ€»å’Œå®šä¹‰å¦‚ä¸‹ï¼š![å—é™æ³¢å°”å…¹æ›¼æœº](img/00163.jpeg)
- en: Hopfield networks and Boltzmann machines
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: éœæ™®è²å°”å¾·ç½‘ç»œå’Œæ³¢å°”å…¹æ›¼æœº
- en: Before we go further into restricted Boltzmann machines, let's briefly talk
    about Hopfield networks; this should help in giving us a bit more of an understanding
    about how we get to restricted Boltzmann machines. Hopfield networks are also
    energy-based models, but unlike a restricted Boltzmann machine, it has only visible
    nodes, and they are all interconnected. The activation of each node will always
    be either -1 or +1.![Hopfield networks and Boltzmann machines](img/00164.jpeg)
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘ä»¬è¿›ä¸€æ­¥è®¨è®ºå—é™æ³¢å°”å…¹æ›¼æœºä¹‹å‰ï¼Œè®©æˆ‘ä»¬ç®€è¦è°ˆè°ˆéœæ™®è²å°”å¾·ç½‘ç»œï¼›è¿™åº”è¯¥æœ‰åŠ©äºæˆ‘ä»¬å¯¹å¦‚ä½•åˆ°è¾¾å—é™æ³¢å°”å…¹æ›¼æœºæœ‰æ›´å¤šçš„ç†è§£ã€‚éœæ™®è²å°”å¾·ç½‘ç»œä¹Ÿæ˜¯åŸºäºèƒ½é‡çš„æ¨¡å‹ï¼Œä½†ä¸å—é™æ³¢å°”å…¹æ›¼æœºä¸åŒï¼Œå®ƒåªæœ‰å¯è§èŠ‚ç‚¹ï¼Œå¹¶ä¸”å®ƒä»¬éƒ½æ˜¯ç›¸äº’è¿æ¥çš„ã€‚æ¯ä¸ªèŠ‚ç‚¹çš„æ¿€æ´»å§‹ç»ˆä¸º-1æˆ–+1ã€‚![éœæ™®è²å°”å¾·ç½‘ç»œå’Œæ³¢å°”å…¹æ›¼æœº](img/00164.jpeg)
- en: Figure 2\. Hopfield network, all input nodes are interconnected
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å›¾2. éœæ™®è²å°”å¾·ç½‘ç»œï¼Œæ‰€æœ‰è¾“å…¥èŠ‚ç‚¹éƒ½ç›¸äº’è¿æ¥ã€‚
- en: When running a Hopfield network (or RBM), you have two options. The first option
    is that you can set the value of every visible node to the corresponding value
    of your data item you are triggering it on. Then you can trigger successive activations,
    where, at each activation, every node has its value updated based on the value
    of the other visible nodes it is connected to. The other option is to just initialize
    the visible nodes randomly and then trigger successive activations so it produces
    random examples of the data it has been trained on. This is often referred to
    as the network daydreaming.
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨è¿è¡Œéœæ™®è²å°”å¾·ç½‘ç»œï¼ˆæˆ–RBMï¼‰æ—¶ï¼Œæ‚¨æœ‰ä¸¤ä¸ªé€‰é¡¹ã€‚ç¬¬ä¸€ä¸ªé€‰é¡¹æ˜¯æ‚¨å¯ä»¥å°†æ¯ä¸ªå¯è§èŠ‚ç‚¹çš„å€¼è®¾ç½®ä¸ºæ‚¨æ­£åœ¨è§¦å‘çš„æ•°æ®é¡¹çš„ç›¸åº”å€¼ã€‚ç„¶åï¼Œæ‚¨å¯ä»¥è§¦å‘è¿ç»­çš„æ¿€æ´»ï¼Œåœ¨æ¯æ¬¡æ¿€æ´»æ—¶ï¼Œæ¯ä¸ªèŠ‚ç‚¹çš„å€¼éƒ½æ ¹æ®å…¶è¿æ¥åˆ°çš„å…¶ä»–å¯è§èŠ‚ç‚¹çš„å€¼è¿›è¡Œæ›´æ–°ã€‚å¦ä¸€ä¸ªé€‰é¡¹æ˜¯ä»…éšæœºåˆå§‹åŒ–å¯è§èŠ‚ç‚¹ï¼Œç„¶åè§¦å‘è¿ç»­çš„æ¿€æ´»ï¼Œä»¥äº§ç”Ÿå…¶å·²ç»è®­ç»ƒè¿‡çš„æ•°æ®çš„éšæœºç¤ºä¾‹ã€‚è¿™é€šå¸¸è¢«ç§°ä¸ºç½‘ç»œåšç™½æ—¥æ¢¦ã€‚
- en: The activation of each of these visible nodes at the next time step is defined
    as follows:![Hopfield networks and Boltzmann machines](img/00165.jpeg)
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸‹ä¸€ä¸ªæ—¶é—´æ­¥çš„æ¯ä¸ªå¯è§èŠ‚ç‚¹çš„æ¿€æ´»å®šä¹‰å¦‚ä¸‹ï¼š![éœæ™®è²å°”å¾·ç½‘ç»œå’Œæ³¢å°”å…¹æ›¼æœº](img/00165.jpeg)
- en: Here, W is a matrix defining the connection strength between each node v at
    time step t. A thresholding rule is then applied to a to get a new state for v:![Hopfield
    networks and Boltzmann machines](img/00166.jpeg)
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼ŒWæ˜¯ä¸€ä¸ªçŸ©é˜µï¼Œå®šä¹‰äº†æ—¶é—´æ­¥éª¤tæ—¶æ¯ä¸ªèŠ‚ç‚¹vä¹‹é—´çš„è¿æ¥å¼ºåº¦ã€‚ç„¶åå¯¹aåº”ç”¨é˜ˆå€¼è§„åˆ™ï¼Œå¾—åˆ°vçš„æ–°çŠ¶æ€ï¼š![éœæ™®è²å°”å¾·ç½‘ç»œå’Œæ³¢å°”å…¹æ›¼æœºå™¨](img/00166.jpeg)
- en: The weights W between nodes can be either positive or negative, which will lead
    nodes to attract or repel the other nodes in the network, when active. The Hopfield
    network also has a continuous variant, which simply involves replacing the thresholding
    function with the tanh function.
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: èŠ‚ç‚¹ä¹‹é—´çš„æƒé‡Wå¯ä»¥æ˜¯æ­£çš„ä¹Ÿå¯ä»¥æ˜¯è´Ÿçš„ï¼Œåœ¨æ¿€æ´»æ—¶ä¼šå¯¼è‡´èŠ‚ç‚¹ç›¸äº’å¸å¼•æˆ–æ’æ–¥ã€‚éœæ™®è²å°”å¾·ç½‘ç»œè¿˜æœ‰ä¸€ä¸ªè¿ç»­å˜ä½“ï¼Œå®ƒåªæ˜¯ç”¨tanhå‡½æ•°æ›¿æ¢äº†é˜ˆå€¼å‡½æ•°ã€‚
- en: The energy function for this network is as follows:![Hopfield networks and Boltzmann
    machines](img/00167.jpeg)
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¯¥ç½‘ç»œçš„èƒ½é‡å‡½æ•°å¦‚ä¸‹ï¼š![éœæ™®è²å°”å¾·ç½‘ç»œå’Œæ³¢å°”å…¹æ›¼æœºå™¨](img/00167.jpeg)
- en: In matrix notation, it is as follows:![Hopfield networks and Boltzmann machines](img/00168.jpeg)
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç”¨çŸ©é˜µè¡¨ç¤ºï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š![éœæ™®è²å°”å¾·ç½‘ç»œå’Œæ³¢å°”å…¹æ›¼æœºå™¨](img/00168.jpeg)
- en: The ![Hopfield networks and Boltzmann machines](img/00169.jpeg) in the equation
    is because we are going through every pair of i and j and so double-counting each
    connection (once when i=1 and j=2 then again when i=2 and j=1).
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ–¹ç¨‹ä¸­çš„![éœæ™®è²å°”å¾·ç½‘ç»œå’Œæ³¢å°”å…¹æ›¼æœºå™¨](img/00169.jpeg)æ˜¯å› ä¸ºæˆ‘ä»¬è¦éå†æ¯å¯¹iå’Œjï¼Œå› æ­¤é‡å¤è®¡ç®—æ¯ä¸ªè¿æ¥ï¼ˆå½“i=1ä¸”j=2æ—¶ï¼Œç„¶åå½“i=2ä¸”j=1æ—¶åˆè®¡ç®—ä¸€æ¬¡ï¼‰ã€‚
- en: 'The question that might arise here is: why have a model with only visible nodes?
    I will activate it with data I give it, then trigger some state updates. But what
    useful information does this new state give me? This is where the properties of
    energy-based models become interesting. Different configurations of W will vary
    the energy function associated with the states v. If we set the state of the network
    to something with a high energy function, that is an unstable state (think of
    the many bouncing balls); the network will over successive iterations move to
    a stable state.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿™é‡Œå¯èƒ½å‡ºç°çš„é—®é¢˜æ˜¯ï¼šä¸ºä»€ä¹ˆåªæœ‰å¯è§èŠ‚ç‚¹çš„æ¨¡å‹ï¼Ÿæˆ‘ä¼šç»™å®ƒæ¿€æ´»ï¼Œç„¶åè§¦å‘ä¸€äº›çŠ¶æ€æ›´æ–°ã€‚ä½†æ˜¯è¿™ä¸ªæ–°çŠ¶æ€ç»™æˆ‘æä¾›äº†ä»€ä¹ˆæœ‰ç”¨çš„ä¿¡æ¯å‘¢ï¼Ÿèƒ½é‡åŸºæ¨¡å‹çš„ç‰¹æ€§åœ¨è¿™é‡Œå˜å¾—æœ‰è¶£ã€‚ä¸åŒçš„Wé…ç½®å°†æ”¹å˜ä¸çŠ¶æ€vç›¸å…³çš„èƒ½é‡å‡½æ•°ã€‚å¦‚æœæˆ‘ä»¬å°†ç½‘ç»œçŠ¶æ€è®¾ç½®ä¸ºå…·æœ‰é«˜èƒ½é‡å‡½æ•°çš„ä¸œè¥¿ï¼Œå³ä¸ç¨³å®šçŠ¶æ€ï¼ˆæƒ³è±¡ä¸€ä¸‹è®¸å¤šå¼¹è·³çš„çƒï¼‰ï¼›ç½‘ç»œä¼šåœ¨è¿ç»­çš„è¿­ä»£ä¸­ç§»åŠ¨åˆ°ä¸€ä¸ªç¨³å®šçŠ¶æ€ã€‚
- en: If we train a Hopefield network on a dataset to learn a W with low energy for
    each item in the dataset, we can then make a corrupted sample from the data, say,
    by randomly swapping a few of the inputs between their minus one and plus one
    states. The corrupted samples may be in a high-energy state now because the corruption
    has made it unlikely to be a member of the original dataset. If we activate the
    visible nodes of the network on the corrupted sample, run a few more iterations
    of the network until it has reached a low-energy state; there is a good chance
    that it will have reconstructed the original uncorrupted pattern.
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬å¯¹æ•°æ®é›†è®­ç»ƒéœæ™®è²å°”å¾·ç½‘ç»œï¼Œå­¦ä¹ å¾—åˆ°ä¸€ä¸ªå¯¹æ•°æ®é›†ä¸­æ¯ä¸ªæ¡ç›®éƒ½æœ‰ä½èƒ½é‡çš„Wï¼Œç„¶åæˆ‘ä»¬å¯ä»¥ä»æ•°æ®ä¸­åˆ›å»ºä¸€ä¸ªæŸåçš„æ ·æœ¬ï¼Œæ¯”å¦‚ï¼Œé€šè¿‡éšæœºäº¤æ¢ä¸€äº›è¾“å…¥çš„æ­£è´ŸçŠ¶æ€ã€‚å› ä¸ºæŸåä½¿å¾—è¿™äº›æ ·æœ¬ä¸å¤ªå¯èƒ½æ˜¯åŸæ•°æ®é›†çš„æˆå‘˜ï¼Œæ‰€ä»¥è¿™äº›æŸåçš„æ ·æœ¬å¯èƒ½ç°åœ¨å¤„äºé«˜èƒ½é‡çŠ¶æ€ã€‚å¦‚æœæˆ‘ä»¬æ¿€æ´»ç½‘ç»œçš„å¯è§èŠ‚ç‚¹ä¸Šçš„æŸåæ ·æœ¬ï¼Œè¿è¡Œç½‘ç»œçš„æ›´å¤šè¿­ä»£ç›´åˆ°è¾¾åˆ°ä½èƒ½é‡çŠ¶æ€ï¼›é‚£ä¹ˆç½‘ç»œæœ‰å¾ˆå¤§çš„å¯èƒ½æ€§å·²ç»é‡æ„äº†åŸå§‹æœªæŸåçš„æ¨¡å¼ã€‚
- en: This leads to one use of the Hopfield networks being spelling correction; you
    can train it on a library of words, with the letters used in the words as inputs.
    Then if it is given a misspelled word, it may be able to find the correct original
    word. Another use of the Hopfield networks is as a content-addressable memory.
    One of the big differences between the computer memory and the human memory is
    that with computers, memories are stored with addresses. If a computer wants to
    retrieve a memory, it must know the exact place it stored it in. Human memory,
    on the other hand, can be given a partial section of that memory, the content
    of which can be used to recover the rest of it. For example, if I need to remember
    my pin number, I know the content I'm looking for and the properties of that content,
    a four digit number; my brain uses that to return the values.
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿™å¯¼è‡´ Hopfield ç½‘ç»œçš„ä¸€ä¸ªç”¨é€”æ˜¯æ‹¼å†™çº æ­£ï¼›ä½ å¯ä»¥åœ¨å•è¯åº“ä¸Šå¯¹å…¶è¿›è¡Œè®­ç»ƒï¼Œå…¶ä¸­åŒ…å«å•è¯ä¸­ä½¿ç”¨çš„å­—æ¯ä½œä¸ºè¾“å…¥ã€‚ç„¶åï¼Œå¦‚æœç»™å‡ºä¸€ä¸ªæ‹¼å†™é”™è¯¯çš„å•è¯ï¼Œå®ƒå¯èƒ½èƒ½å¤Ÿæ‰¾åˆ°æ­£ç¡®çš„åŸå§‹å•è¯ã€‚Hopfield
    ç½‘ç»œçš„å¦ä¸€ä¸ªç”¨é€”æ˜¯ä½œä¸ºå†…å®¹å¯»å€å†…å­˜ã€‚è®¡ç®—æœºå†…å­˜å’Œäººç±»å†…å­˜ä¹‹é—´çš„ä¸€ä¸ªé‡è¦åŒºåˆ«æ˜¯ï¼Œè®¡ç®—æœºå†…å­˜æ˜¯ç”¨åœ°å€å­˜å‚¨çš„ã€‚å¦‚æœè®¡ç®—æœºæƒ³è¦æ£€ç´¢å†…å­˜ï¼Œå®ƒå¿…é¡»çŸ¥é“å­˜å‚¨å®ƒçš„ç¡®åˆ‡ä½ç½®ã€‚å¦ä¸€æ–¹é¢ï¼Œäººç±»è®°å¿†å¯ä»¥ç»™å‡ºè¯¥è®°å¿†çš„éƒ¨åˆ†å†…å®¹ï¼Œè¯¥å†…å®¹çš„ç‰¹æ€§å¯ä»¥ç”¨æ¥æ¢å¤å…¶ä½™éƒ¨åˆ†ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘éœ€è¦è®°ä½æˆ‘çš„å¯†ç ï¼Œæˆ‘çŸ¥é“æˆ‘æ­£åœ¨å¯»æ‰¾çš„å†…å®¹ä»¥åŠè¯¥å†…å®¹çš„å±æ€§ï¼Œä¸€ä¸ªå››ä½æ•°ï¼›æˆ‘çš„å¤§è„‘åˆ©ç”¨è¿™ä¸€ç‚¹è¿”å›å€¼ã€‚
- en: Hopfield networks allow you to store content-addressable memories, which have
    led some people to suggest (speculatively) that the human memory system may function
    like a Hopfield network, with human dreaming being the attempt to learn the weights.
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hopfield ç½‘ç»œå…è®¸æ‚¨å­˜å‚¨å†…å®¹å¯»å€å†…å­˜ï¼Œè¿™å¯¼è‡´ä¸€äº›äººæ¨æµ‹äººç±»è®°å¿†ç³»ç»Ÿå¯èƒ½åƒ Hopfield ç½‘ç»œä¸€æ ·è¿ä½œï¼Œäººç±»çš„æ¢¦å¢ƒæ˜¯å­¦ä¹ æƒé‡çš„å°è¯•ã€‚
- en: The last use of a Hopfield network is that it can be used to solve optimization
    tasks, such as the traveling salesman task. The energy function can be defined
    to represent the cost of the task to be optimized, and the nodes of the network
    to represent the choices being optimized. Again, all that needs to be done is
    to minimize the energy function with respect to the weights of the network.
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hopfield ç½‘ç»œçš„æœ€åä¸€ä¸ªç”¨é€”æ˜¯ï¼Œå®ƒå¯ä»¥ç”¨äºè§£å†³ä¼˜åŒ–ä»»åŠ¡ï¼Œä¾‹å¦‚æ—…è¡Œæ¨é”€å‘˜ä»»åŠ¡ã€‚å¯ä»¥å®šä¹‰èƒ½é‡å‡½æ•°æ¥è¡¨ç¤ºè¦ä¼˜åŒ–çš„ä»»åŠ¡çš„æˆæœ¬ï¼Œç½‘ç»œçš„èŠ‚ç‚¹è¡¨ç¤ºè¦ä¼˜åŒ–çš„é€‰æ‹©ã€‚åŒæ ·ï¼Œåªéœ€æœ€å°åŒ–ç½‘ç»œæƒé‡çš„èƒ½é‡å‡½æ•°å³å¯ã€‚
- en: Boltzmann machine
  id: totrans-171
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Boltzmann æœºå™¨
- en: A Boltzmann machine is also known as a stochastic Hopfield network. In a Hopfield
    network, node activations are set based on the threshold; but in a Boltzmann machine,
    activation is stochastic. The value of a node in a Boltzmann machine is always
    set to either +1 or -1\. The probability of the node being in the state +1 is
    defined as follows:![Boltzmann machine](img/00170.jpeg)
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Boltzmann æœºå™¨ä¹Ÿè¢«ç§°ä¸ºéšæœº Hopfield ç½‘ç»œã€‚åœ¨ Hopfield ç½‘ç»œä¸­ï¼ŒèŠ‚ç‚¹æ¿€æ´»æ˜¯åŸºäºé˜ˆå€¼è®¾ç½®çš„ï¼›ä½†åœ¨ Boltzmann æœºå™¨ä¸­ï¼Œæ¿€æ´»æ˜¯éšæœºçš„ã€‚Boltzmann
    æœºå™¨ä¸­çš„èŠ‚ç‚¹å€¼å§‹ç»ˆè®¾ç½®ä¸º +1 æˆ– -1ã€‚èŠ‚ç‚¹å¤„äºçŠ¶æ€ +1 çš„æ¦‚ç‡å®šä¹‰å¦‚ä¸‹: ![Boltzmann æœºå™¨](img/00170.jpeg)'
- en: Here, *a*[*i*] is the activation for that node as defined for the Hopfield network.
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿™é‡Œï¼Œ*a*[*i*] æ˜¯é’ˆå¯¹ Hopfield ç½‘ç»œå®šä¹‰çš„è¯¥èŠ‚ç‚¹çš„æ¿€æ´»ã€‚
- en: 'To learn the weights of our Boltzmann machine or Hopfield network, we want
    to maximize the likelihood of the dataset, given the W, which is simply the product
    of the likelihood for each data item:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†å­¦ä¹ æˆ‘ä»¬çš„ Boltzmann æœºå™¨æˆ– Hopfield ç½‘ç»œçš„æƒé‡ï¼Œæˆ‘ä»¬å¸Œæœ›æœ€å¤§åŒ–ç»™å®š W çš„æ•°æ®é›†çš„å¯èƒ½æ€§ï¼Œè¿™ç®€å•åœ°æ˜¯æ¯ä¸ªæ•°æ®é¡¹çš„å¯èƒ½æ€§çš„ä¹˜ç§¯ï¼š
- en: '![Boltzmann machine](img/00171.jpeg)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
  zh: '![Boltzmann æœºå™¨](img/00171.jpeg)'
- en: 'Here, W is the weights matrix, and *x**^((n))* is the nth sample from the dataset
    x of size N. Let''s now replace ![Boltzmann machine](img/00172.jpeg) with the
    actual likelihood from our Boltzmann machine:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œï¼ŒW æ˜¯æƒé‡çŸ©é˜µï¼Œ*x**^((n))* æ˜¯å¤§å°ä¸º N çš„æ•°æ®é›† x çš„ç¬¬ n ä¸ªæ ·æœ¬ã€‚ç°åœ¨è®©æˆ‘ä»¬ç”¨æ¥è‡ªæˆ‘ä»¬çš„ Boltzmann æœºå™¨çš„å®é™…å¯èƒ½æ€§æ›¿æ¢
    ![Boltzmann æœºå™¨](img/00172.jpeg)ï¼š
- en: '![Boltzmann machine](img/00173.jpeg)'
  id: totrans-177
  prefs: []
  type: TYPE_IMG
  zh: '![Boltzmann æœºå™¨](img/00173.jpeg)'
- en: 'Here, *Z* is as shown in the following equation:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œï¼Œ*Z* å¦‚ä¸‹æ–¹ç¨‹æ‰€ç¤ºï¼š
- en: '![Boltzmann machine](img/00174.jpeg)'
  id: totrans-179
  prefs: []
  type: TYPE_IMG
  zh: '![Boltzmann æœºå™¨](img/00174.jpeg)'
- en: If you look at the original definition of our energy function and Z, then *x'*
    should be every possible configuration of *x* based on the probability distribution
    *p(x)*. We now have W as part of our model, so the distribution will change to
    ![Boltzmann machine](img/00175.jpeg). Unfortunately, ![Boltzmann machine](img/00176.jpeg)
    is, if not completely intractable, at the very least, far too computationally
    expensive to compute. We would need to take every possible configuration of x
    across all possible W.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨æŸ¥çœ‹æˆ‘ä»¬èƒ½é‡å‡½æ•°å’ŒZçš„åŸå§‹å®šä¹‰ï¼Œé‚£ä¹ˆ*x'*åº”è¯¥æ˜¯åŸºäºæ¦‚ç‡åˆ†å¸ƒ*p(x)*çš„æ¯ä¸ªå¯èƒ½é…ç½®çš„*x*ã€‚æˆ‘ä»¬ç°åœ¨çš„æ¨¡å‹ä¸­æœ‰Wçš„ä¸€éƒ¨åˆ†ï¼Œå› æ­¤åˆ†å¸ƒå°†æ›´æ”¹ä¸º![ç»å°”å…¹æ›¼æœº](img/00175.jpeg)ã€‚ä¸å¹¸çš„æ˜¯ï¼Œ![ç»å°”å…¹æ›¼æœº](img/00176.jpeg)å¦‚æœä¸æ˜¯å®Œå…¨æ£˜æ‰‹çš„ï¼Œè‡³å°‘æ˜¯è®¡ç®—æˆæœ¬å¤ªé«˜ï¼Œæ— æ³•è®¡ç®—çš„ã€‚æˆ‘ä»¬éœ€è¦åœ¨æ‰€æœ‰å¯èƒ½çš„Wçš„æ‰€æœ‰å¯èƒ½çš„xçš„é…ç½®ä¸­è¿›è¡Œè®¡ç®—ã€‚
- en: One approach to computing an intractable probability distribution such as this
    is what's called Monte Carlo sampling. This involves taking lots of samples from
    the distribution and using the average of these samples to approximate the true
    value. The more samples we take from the distribution, the more accurate it will
    tend to be. A hypothetical infinite number of samples would be exactly the quantity
    we want, while 1 would be a very poor approximation.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: è®¡ç®—è¿™ç§éš¾ä»¥å¤„ç†çš„æ¦‚ç‡åˆ†å¸ƒçš„ä¸€ç§æ–¹æ³•æ˜¯æ‰€è°“çš„è’™ç‰¹å¡ç½—é‡‡æ ·ã€‚è¿™æ¶‰åŠä»åˆ†å¸ƒä¸­å–å¤§é‡æ ·æœ¬ï¼Œå¹¶ä½¿ç”¨è¿™äº›æ ·æœ¬çš„å¹³å‡å€¼æ¥è¿‘ä¼¼çœŸå®å€¼ã€‚æˆ‘ä»¬ä»åˆ†å¸ƒä¸­å–çš„æ ·æœ¬è¶Šå¤šï¼Œå®ƒçš„å‡†ç¡®æ€§å°±è¶Šé«˜ã€‚å‡è®¾æ— é™æ•°é‡çš„æ ·æœ¬å°†å®Œå…¨ç¬¦åˆæˆ‘ä»¬æƒ³è¦çš„æ•°é‡ï¼Œè€Œ1å°†æ˜¯ä¸€ä¸ªéå¸¸å·®çš„è¿‘ä¼¼å€¼ã€‚
- en: 'Since the products of probabilities can get very small, we will instead use
    the log probability; also, let''s also include the definition of *Z*:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºæ¦‚ç‡çš„ä¹˜ç§¯å¯èƒ½å˜å¾—éå¸¸å°ï¼Œå› æ­¤æˆ‘ä»¬å°†ä½¿ç”¨å¯¹æ•°æ¦‚ç‡ï¼›å¦å¤–ï¼Œè®©æˆ‘ä»¬ä¹ŸåŒ…æ‹¬*Z*çš„å®šä¹‰ï¼š
- en: '![Boltzmann machine](img/00177.jpeg)'
  id: totrans-183
  prefs: []
  type: TYPE_IMG
  zh: '![ç»å°”å…¹æ›¼æœº](img/00177.jpeg)'
- en: 'Here, x'' is a sample of state of the network, as taken from the probability
    distribution ![Boltzmann machine](img/00175.jpeg) learned by the network. If we
    take the gradient of this with respect to a single weight between nodes i and
    j, it looks like this:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œï¼Œx'æ˜¯ä»ç½‘ç»œå­¦ä¹ çš„æ¦‚ç‡åˆ†å¸ƒ![ç»å°”å…¹æ›¼æœº](img/00175.jpeg)ä¸­è·å–çš„ç½‘ç»œçŠ¶æ€æ ·æœ¬ã€‚å¦‚æœæˆ‘ä»¬å¯¹èŠ‚ç‚¹iå’Œjä¹‹é—´çš„å•ä¸ªæƒé‡å–è¿™ä¸ªæ¢¯åº¦ï¼Œå®ƒçœ‹èµ·æ¥åƒè¿™æ ·ï¼š
- en: '![Boltzmann machine](img/00178.jpeg)'
  id: totrans-185
  prefs: []
  type: TYPE_IMG
  zh: '![ç»å°”å…¹æ›¼æœº](img/00178.jpeg)'
- en: 'Here, ![Boltzmann machine](img/00179.jpeg) across all N samples is simply the
    correlation between the nodes i and j. Another way to write this across all N
    samples, for each weight *i* and *j*, would be this:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œï¼Œ![ç»å°”å…¹æ›¼æœº](img/00179.jpeg)åœ¨æ‰€æœ‰Nä¸ªæ ·æœ¬ä¸­åªæ˜¯èŠ‚ç‚¹iå’Œjä¹‹é—´çš„ç›¸å…³æ€§ã€‚å¦ä¸€ç§å†™æ³•æ˜¯å¯¹æ‰€æœ‰Nä¸ªæ ·æœ¬ï¼Œå¯¹äºæ¯ä¸ªæƒé‡*i*å’Œ*j*ï¼Œå¯ä»¥å†™æˆè¿™æ ·ï¼š
- en: '![Boltzmann machine](img/00180.jpeg)'
  id: totrans-187
  prefs: []
  type: TYPE_IMG
  zh: '![ç»å°”å…¹æ›¼æœº](img/00180.jpeg)'
- en: This equation can be understood as being two phases of learning, known as positive
    and negative or, more poetically, waking and sleeping. In the positive phase,
    ![Boltzmann machine](img/00181.jpeg) increases the weights based on the data we
    are given. In the negative phase, ![Boltzmann machine](img/00182.jpeg), we draw
    samples from the model as per the weights we currently have, then move the weights
    away from that distribution. This can be thought of as reducing the probability
    of items generated by the model. We want our model to reflect the data as closely
    as possible, so we want to reduce the selection generated by our model. If our
    model was producing images exactly like the data, then the two terms would cancel
    each other out, and equilibrium would be reached.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªæ–¹ç¨‹å¯ä»¥ç†è§£ä¸ºå­¦ä¹ çš„ä¸¤ä¸ªé˜¶æ®µï¼Œè¢«ç§°ä¸ºæ­£ç›¸å’Œè´Ÿç›¸æˆ–è€…ï¼Œæ›´å…·è¯—æ„åœ°è¯´ï¼Œé†’å’Œç¡çœ ã€‚åœ¨æ­£ç›¸ä¸­ï¼Œ![ç»å°”å…¹æ›¼æœº](img/00181.jpeg)æ ¹æ®æˆ‘ä»¬æ‰€ç»™çš„æ•°æ®å¢åŠ æƒé‡ã€‚åœ¨è´Ÿç›¸ä¸­ï¼Œ![ç»å°”å…¹æ›¼æœº](img/00182.jpeg)ï¼Œæˆ‘ä»¬ä»æ¨¡å‹ä¸­æ ¹æ®å½“å‰æƒé‡æŠ½å–æ ·æœ¬ï¼Œç„¶åå°†æƒé‡è¿œç¦»è¯¥åˆ†å¸ƒã€‚è¿™å¯ä»¥è¢«è®¤ä¸ºæ˜¯å‡å°‘æ¨¡å‹ç”Ÿæˆçš„é¡¹ç›®çš„æ¦‚ç‡ã€‚æˆ‘ä»¬å¸Œæœ›æˆ‘ä»¬çš„æ¨¡å‹å°½å¯èƒ½åœ°åæ˜ æ•°æ®ï¼Œå› æ­¤æˆ‘ä»¬å¸Œæœ›å‡å°‘æ¨¡å‹ç”Ÿæˆçš„é€‰æ‹©ã€‚å¦‚æœæˆ‘ä»¬çš„æ¨¡å‹äº§ç”Ÿçš„å›¾åƒä¸æ•°æ®å®Œå…¨ç›¸åŒï¼Œé‚£ä¹ˆè¿™ä¸¤ä¸ªæœ¯è¯­å°†äº’ç›¸æŠµæ¶ˆï¼Œè¾¾åˆ°å¹³è¡¡ã€‚
- en: Boltzmann machines and Hopfield networks can be useful for tasks such as optimization
    and recommendation systems. They are very computationally expensive. Correlation
    must be measured between every single node, and then a range of Monte Carlo samples
    must be generated from the model for every training step. Also, the kinds of patterns
    it can learn are limited. If we are training on images to learn shapes, it cannot
    learn position invariant information. A butterfly on the left-hand side of an
    image is a completely different beast to a butterfly on the right-hand side of
    an image. In [Chapter 5](part0030_split_000.html#SJGS1-c1ed1b54ca0b4e9fbb9fe2b2431d634f
    "ChapterÂ 5.Â Image Recognition"), *Image Recognition*, we will take a look at convolutional
    neural networks, which offers a solution to this problem.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: ç»å°”å…¹æ›¼æœºå’Œéœæ™®è²å°”å¾·ç½‘ç»œå¯ç”¨äºä¼˜åŒ–å’Œæ¨èç³»ç»Ÿç­‰ä»»åŠ¡ã€‚å®ƒä»¬éœ€è¦å¤§é‡çš„è®¡ç®—èµ„æºã€‚å¿…é¡»æµ‹é‡æ¯ä¸ªèŠ‚ç‚¹ä¹‹é—´çš„ç›¸å…³æ€§ï¼Œç„¶åå¯¹æ¨¡å‹è¿›è¡Œæ¯ä¸€æ­¥è®­ç»ƒæ—¶çš„è’™ç‰¹å¡æ´›æ ·æœ¬çš„èŒƒå›´ã€‚æ­¤å¤–ï¼Œå®ƒå¯ä»¥å­¦ä¹ çš„æ¨¡å¼ç§ç±»æœ‰é™ã€‚å¦‚æœæˆ‘ä»¬åœ¨å›¾åƒä¸Šè®­ç»ƒä»¥å­¦ä¹ å½¢çŠ¶ï¼Œå®ƒæ— æ³•å­¦ä¹ ä½ç½®ä¸å˜çš„ä¿¡æ¯ã€‚å›¾åƒå·¦ä¾§çš„è´è¶ä¸å›¾åƒå³ä¾§çš„è´è¶å®Œå…¨ä¸åŒã€‚åœ¨[ç¬¬5ç« ](part0030_split_000.html#SJGS1-c1ed1b54ca0b4e9fbb9fe2b2431d634f
    "ç¬¬5ç«  å›¾åƒè¯†åˆ«")*å›¾åƒè¯†åˆ«*ä¸­ï¼Œæˆ‘ä»¬å°†çœ‹ä¸€ä¸‹å·ç§¯ç¥ç»ç½‘ç»œï¼Œå®ƒæä¾›äº†è¿™ä¸ªé—®é¢˜çš„è§£å†³æ–¹æ¡ˆã€‚
- en: Restricted Boltzmann machine
  id: totrans-190
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å—é™ç»å°”å…¹æ›¼æœº
- en: 'Restricted Boltzmann machines make two changes from the Boltzmann machines:
    the first is that we add in hidden nodes, each of which is connected to every
    visible node, but not to each other. The second is that we remove all connections
    between visible nodes. This has the effect of making each node in the visible
    layer conditionally independent of each other if we are given the hidden layer.
    Nodes in the hidden layer are also conditionally independent, given the visible
    layer. We will also now add bias terms to both the visible and hidden nodes. A
    Boltzmann machine can also be trained with a bias term for each node, but this
    was left out of the equations for ease of notation.'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: å—é™ç»å°”å…¹æ›¼æœºä¸ç»å°”å…¹æ›¼æœºç›¸æ¯”è¿›è¡Œäº†ä¸¤é¡¹æ”¹å˜ï¼šç¬¬ä¸€æ˜¯æ·»åŠ äº†éšè—èŠ‚ç‚¹ï¼Œæ¯ä¸ªèŠ‚ç‚¹éƒ½è¿æ¥åˆ°æ¯ä¸ªå¯è§èŠ‚ç‚¹ï¼Œä½†å½¼æ­¤ä¸è¿æ¥ã€‚ ç¬¬äºŒæ˜¯åˆ é™¤äº†å¯è§èŠ‚ç‚¹ä¹‹é—´çš„æ‰€æœ‰è¿æ¥ã€‚è¿™å¯¼è‡´åœ¨ç»™å®šéšè—å±‚çš„æƒ…å†µä¸‹ï¼Œå¯è§å±‚ä¸­çš„æ¯ä¸ªèŠ‚ç‚¹éƒ½æ˜¯æ¡ä»¶ç‹¬ç«‹çš„ã€‚ç»™å®šå¯è§å±‚åï¼Œéšè—å±‚ä¸­çš„èŠ‚ç‚¹ä¹Ÿæ˜¯æ¡ä»¶ç‹¬ç«‹çš„ã€‚æˆ‘ä»¬ç°åœ¨è¿˜å°†å‘å¯è§å’Œéšè—èŠ‚ç‚¹æ·»åŠ åç½®é¡¹ã€‚ç»å°”å…¹æ›¼æœºä¹Ÿå¯ä»¥åœ¨æ¯ä¸ªèŠ‚ç‚¹ä¸Šè®­ç»ƒæœ‰åç½®é¡¹ï¼Œä½†è¿™åœ¨ç­‰å¼ä¸­è¢«å¿½ç•¥äº†ä»¥ä¾¿ç®€åŒ–ç¬¦å·ã€‚
- en: Given that the data we have is only for the visible units, what we aim to do
    through training is find configurations of hidden units that lead to low-energy
    states when combined with the visible units. In our restricted Boltzmann machine,
    the state *x* is now the full configuration of both visible and hidden nodes.
    So, we will parameterize our energy function as E(v, h). It now looks like this:![Restricted
    Boltzmann machine](img/00183.jpeg)
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç”±äºæˆ‘ä»¬æ‹¥æœ‰çš„æ•°æ®åªé’ˆå¯¹å¯è§å•å…ƒï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯é€šè¿‡è®­ç»ƒæ‰¾åˆ°éšè—å•å…ƒçš„é…ç½®ï¼Œå½“ä¸å¯è§å•å…ƒç»“åˆæ—¶ï¼Œå¯ä»¥å¯¼è‡´ä½èƒ½æ€ã€‚åœ¨æˆ‘ä»¬çš„å—é™ç»å°”å…¹æ›¼æœºä¸­ï¼ŒçŠ¶æ€*x*ç°åœ¨æ˜¯å¯è§å’Œéšè—èŠ‚ç‚¹çš„å®Œæ•´é…ç½®ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å°†èƒ½é‡å‡½æ•°å‚æ•°åŒ–ä¸ºE(v,
    h)ã€‚å®ƒç°åœ¨çœ‹èµ·æ¥åƒè¿™æ ·ï¼š![å—é™ç»å°”å…¹æ›¼æœº](img/00183.jpeg)
- en: Here, a is the bias vector for the visible nodes, b is the bias vector for the
    hidden nodes, and W is the matrix of weights between the visible and hidden nodes.
    Here, ![Restricted Boltzmann machine](img/00184.jpeg) is the dot product of the
    two vectors, equivalent to ![Restricted Boltzmann machine](img/00185.jpeg). Now
    we need to take the gradients of our biases and weights with respect to this new
    energy function.
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œaæ˜¯å¯è§èŠ‚ç‚¹çš„åç½®å‘é‡ï¼Œbæ˜¯éšè—èŠ‚ç‚¹çš„åç½®å‘é‡ï¼ŒWæ˜¯å¯è§å’Œéšè—èŠ‚ç‚¹ä¹‹é—´çš„æƒé‡çŸ©é˜µã€‚æ­¤å¤„ï¼Œ![å—é™ç»å°”å…¹æ›¼æœº](img/00184.jpeg) æ˜¯è¿™ä¸¤ä¸ªå‘é‡çš„ç‚¹ç§¯ï¼Œç­‰ä»·äº![å—é™ç»å°”å…¹æ›¼æœº](img/00185.jpeg)ã€‚ç°åœ¨æˆ‘ä»¬éœ€è¦å¯¹æ–°èƒ½é‡å‡½æ•°è®¡ç®—å‡ºçš„åç½®å’Œæƒé‡è¿›è¡Œæ¢¯åº¦ä¸‹é™ã€‚
- en: 'Because of the conditional independence between layers, we now have this:'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç”±äºå±‚ä¹‹é—´çš„æ¡ä»¶ç‹¬ç«‹æ€§ï¼Œæˆ‘ä»¬ç°åœ¨æœ‰è¿™ä¸ªï¼š
- en: '![Restricted Boltzmann machine](img/00186.jpeg)'
  id: totrans-195
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_IMG
  zh: '![å—é™ç»å°”å…¹æ›¼æœº](img/00186.jpeg)'
- en: '![Restricted Boltzmann machine](img/00187.jpeg)'
  id: totrans-196
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_IMG
  zh: '![å—é™ç»å°”å…¹æ›¼æœº](img/00187.jpeg)'
- en: These two definitions will be used in the normalization constant, Z. Since we
    longer have connections between visible nodes, our ![Restricted Boltzmann machine](img/00188.jpeg)
    has changed a lot:![Restricted Boltzmann machine](img/00189.jpeg)
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿™ä¸¤ä¸ªå®šä¹‰å°†ç”¨äºå½’ä¸€åŒ–å¸¸æ•°Zã€‚ç”±äºæˆ‘ä»¬ä¸å†æœ‰å¯è§èŠ‚ç‚¹ä¹‹é—´çš„è¿æ¥ï¼Œæˆ‘ä»¬çš„![å—é™ç»å°”å…¹æ›¼æœº](img/00188.jpeg) å‘ç”Ÿäº†å¾ˆå¤§çš„å˜åŒ–ï¼š![å—é™ç»å°”å…¹æ›¼æœº](img/00189.jpeg)
- en: Here, i is going through each visible node and j through each hidden node. If
    we take the gradient with respect to the different parameters, then what you eventually
    end up with is this:![Restricted Boltzmann machine](img/00190.jpeg)![Restricted
    Boltzmann machine](img/00191.jpeg)![Restricted Boltzmann machine](img/00192.jpeg)
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œi éå†æ¯ä¸ªå¯è§èŠ‚ç‚¹ï¼Œj éå†æ¯ä¸ªéšè—èŠ‚ç‚¹ã€‚å¦‚æœæˆ‘ä»¬å¯¹ä¸åŒå‚æ•°å–æ¢¯åº¦ï¼Œé‚£ä¹ˆæœ€ç»ˆä½ ä¼šå¾—åˆ°è¿™ä¸ªï¼š![å—é™ç»å°”å…¹æ›¼æœº](img/00190.jpeg)![å—é™ç»å°”å…¹æ›¼æœº](img/00191.jpeg)![å—é™ç»å°”å…¹æ›¼æœº](img/00192.jpeg)
- en: As before, ![Restricted Boltzmann machine](img/00193.jpeg) is approximated by
    taking the Monte Carlo samples from the distribution. These final three equations
    give us the complete way to iteratively train all the parameters for a given dataset.
    Training will be a case of updating our parameters by some learning rate by these
    gradients.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ä»¥å‰ä¸€æ ·ï¼Œ![å—é™ç»å°”å…¹æ›¼æœº](img/00193.jpeg)æ˜¯é€šè¿‡ä»åˆ†å¸ƒä¸­å–è’™ç‰¹å¡æ´›æ ·æœ¬æ¥è¿‘ä¼¼çš„ã€‚è¿™æœ€åä¸‰ä¸ªæ–¹ç¨‹ç»™å‡ºäº†æˆ‘ä»¬è¿­ä»£åœ°è®­ç»ƒç»™å®šæ•°æ®é›†çš„æ‰€æœ‰å‚æ•°çš„å®Œæ•´æ–¹æ³•ã€‚è®­ç»ƒå°†æ˜¯é€šè¿‡è¿™äº›æ¢¯åº¦ä»¥æŸä¸ªå­¦ä¹ é€Ÿç‡æ›´æ–°æˆ‘ä»¬çš„å‚æ•°çš„æƒ…å†µã€‚
- en: It is worth restating on a conceptual level what is going on here. v denotes
    the visible variables, the data from the world on which we are learning. h denotes
    the hidden variables, the variables we will train to generate visible variables.
    The hidden variables do not explicitly represent anything, but through training
    and minimizing the energy in the system, they should eventually find important
    components of the distribution we are looking at. For example, if the visible
    variables are a list of movies, with a value of 1 if a person likes the movie
    and 0 if they do not, the hidden variables may come to represent genres of movie,
    such as horror or comedy, because people may have genre preferences, so this is
    an efficient way to encode people's tastes.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: ä»æ¦‚å¿µå±‚é¢ä¸Šå†æ¬¡è¯´æ˜è¿™é‡Œå‘ç”Ÿäº†ä»€ä¹ˆæ˜¯å€¼å¾—çš„ã€‚v è¡¨ç¤ºå¯è§å˜é‡ï¼Œå³æˆ‘ä»¬æ­£åœ¨å­¦ä¹ çš„æ¥è‡ªä¸–ç•Œçš„æ•°æ®ã€‚h è¡¨ç¤ºéšè—å˜é‡ï¼Œå³æˆ‘ä»¬å°†è®­ç»ƒä»¥ç”Ÿæˆå¯è§å˜é‡çš„å˜é‡ã€‚éšè—å˜é‡å¹¶ä¸æ˜ç¡®åœ°ä»£è¡¨ä»»ä½•ä¸œè¥¿ï¼Œä½†é€šè¿‡è®­ç»ƒå’Œæœ€å°åŒ–ç³»ç»Ÿä¸­çš„èƒ½é‡ï¼Œå®ƒä»¬æœ€ç»ˆåº”è¯¥æ‰¾åˆ°æˆ‘ä»¬æ­£åœ¨æŸ¥çœ‹çš„åˆ†å¸ƒçš„é‡è¦ç»„æˆéƒ¨åˆ†ã€‚ä¾‹å¦‚ï¼Œå¦‚æœå¯è§å˜é‡æ˜¯ä¸€ç³»åˆ—ç”µå½±ï¼Œå¦‚æœä¸€ä¸ªäººå–œæ¬¢è¿™éƒ¨ç”µå½±ï¼Œåˆ™å…¶å€¼ä¸º
    1ï¼Œå¦‚æœä¸å–œæ¬¢ï¼Œåˆ™ä¸º 0ï¼Œé‚£ä¹ˆéšè—å˜é‡å¯èƒ½ä¼šè¡¨ç¤ºç”µå½±çš„æµæ´¾ï¼Œå¦‚ææ€–ç‰‡æˆ–å–œå‰§ç‰‡ï¼Œå› ä¸ºäººä»¬å¯èƒ½æœ‰æµæ´¾åå¥½ï¼Œæ‰€ä»¥è¿™æ˜¯ä¸€ç§ç¼–ç äººä»¬å£å‘³çš„æœ‰æ•ˆæ–¹å¼ã€‚
- en: If we generate random samples of hidden variables and then activate the visible
    variables based on this, it should give us a plausible looking set of human tastes
    in movies. Likewise, if we set the visible variables to a random selection of
    movies over successive activations of the hidden and visible nodes, it should
    move us to find a more plausible selection.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬éšæœºç”Ÿæˆéšè—å˜é‡çš„æ ·æœ¬ï¼Œç„¶ååŸºäºæ­¤æ¿€æ´»å¯è§å˜é‡ï¼Œé‚£ä¹ˆå®ƒåº”è¯¥ç»™æˆ‘ä»¬ä¸€ä¸ªçœ‹èµ·æ¥åˆç†çš„ç”µå½±å£å‘³é›†ã€‚åŒæ ·ï¼Œå¦‚æœæˆ‘ä»¬å°†å¯è§å˜é‡è®¾ç½®ä¸ºåœ¨éšè—å’Œå¯è§èŠ‚ç‚¹çš„è¿ç»­æ¿€æ´»è¿‡ç¨‹ä¸­çš„éšæœºç”µå½±é€‰æ‹©ï¼Œé‚£ä¹ˆå®ƒåº”è¯¥ä½¿æˆ‘ä»¬æ‰¾åˆ°ä¸€ä¸ªæ›´åˆç†çš„é€‰æ‹©ã€‚
- en: Implementation in TensorFlow
  id: totrans-202
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åœ¨ TensorFlow ä¸­çš„å®ç°
- en: Now that we have gone through the math, let's see what an implementation of
    it looks like. For this, we will use TensorFlow. TensorFlow is a Google open source
    mathematical graph library that is popular for deep learning. It does not have
    built-in neural network concepts, such as network layers and nodes, which a higher-level
    library such as Keres does; it is closer to a library such as Theano. It has been
    chosen here because being able to work directly on the mathematical symbols underlying
    the network allows the user to get a better understanding of what they are doing.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å·²ç»é€šè¿‡äº†æ•°å­¦ï¼Œè®©æˆ‘ä»¬çœ‹çœ‹å®ƒçš„å®ç°æ˜¯ä»€ä¹ˆæ ·å­çš„ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ TensorFlowã€‚TensorFlow æ˜¯ä¸€ä¸ªè°·æ­Œå¼€æºæ•°å­¦å›¾å½¢åº“ï¼Œç”¨äºæ·±åº¦å­¦ä¹ å¾ˆå—æ¬¢è¿ã€‚å®ƒæ²¡æœ‰å†…ç½®çš„ç¥ç»ç½‘ç»œæ¦‚å¿µï¼Œæ¯”å¦‚ç½‘ç»œå±‚å’ŒèŠ‚ç‚¹ï¼Œè¿™æ˜¯ä¸€ä¸ªæ›´é«˜çº§åˆ«çš„åº“ï¼Œæ¯”å¦‚
    Keras æ‰æœ‰ï¼›å®ƒæ›´æ¥è¿‘äºåƒ Theano è¿™æ ·çš„åº“ã€‚ä¹‹æ‰€ä»¥é€‰æ‹©å®ƒï¼Œæ˜¯å› ä¸ºèƒ½å¤Ÿç›´æ¥å¤„ç†ç½‘ç»œåº•å±‚çš„æ•°å­¦ç¬¦å·ï¼Œä½¿ç”¨æˆ·èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£ä»–ä»¬åœ¨åšä»€ä¹ˆã€‚
- en: TensorFlow can be installed directly via `pip` using the command `pip install
    tensorflow` for the CPU version or `pip install tensorflow-gpu` if you have NVidea
    GPU-enabled machine.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow å¯ä»¥ç›´æ¥é€šè¿‡ `pip` å®‰è£…ï¼Œä½¿ç”¨å‘½ä»¤ `pip install tensorflow` å®‰è£… CPU ç‰ˆæœ¬ï¼Œæˆ–è€…å¦‚æœæ‚¨æœ‰ NVidea
    GPU å¯ç”¨çš„æœºå™¨ï¼Œåˆ™ä½¿ç”¨å‘½ä»¤ `pip install tensorflow-gpu` å®‰è£… GPU ç‰ˆæœ¬ã€‚
- en: We will build a small restricted Boltzmann machine and train it on the MNIST
    collection of handwritten digits. We will have a smaller number of hidden nodes
    than visible nodes, which will force the RBM to learn patterns in the input. The
    success of the training will be measured in the network's ability to reconstruct
    the image after putting it through the hidden layer; for this, we will use the
    mean squared error between the original and our reconstruction. The full code
    sample is in the GitHub repo [https://github.com/DanielSlater/PythonDeepLearningSamples](https://github.com/DanielSlater/PythonDeepLearningSamples)
    in the `restricted_boltzmann_machine.py` file.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†æ„å»ºä¸€ä¸ªå°å‹çš„å—é™ç»å°”å…¹æ›¼æœºï¼Œå¹¶å¯¹å…¶è¿›è¡Œ MNIST æ‰‹å†™æ•°å­—é›†çš„è®­ç»ƒã€‚æˆ‘ä»¬å°†æ¯”å¯è§èŠ‚ç‚¹å°‘çš„éšè—èŠ‚ç‚¹æ•°ï¼Œè¿™å°†è¿«ä½¿ RBM å­¦ä¹ è¾“å…¥ä¸­çš„æ¨¡å¼ã€‚è®­ç»ƒçš„æˆåŠŸå°†é€šè¿‡ç½‘ç»œåœ¨ç»è¿‡éšè—å±‚åé‡æ„å›¾åƒçš„èƒ½åŠ›æ¥è¡¡é‡ï¼›ä¸ºæ­¤ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨åŸå§‹å›¾åƒä¸æˆ‘ä»¬çš„é‡æ„ä¹‹é—´çš„å‡æ–¹è¯¯å·®ã€‚å®Œæ•´çš„ä»£ç ç¤ºä¾‹åœ¨
    GitHub ä»“åº“ [https://github.com/DanielSlater/PythonDeepLearningSamples](https://github.com/DanielSlater/PythonDeepLearningSamples)
    çš„ `restricted_boltzmann_machine.py` æ–‡ä»¶ä¸­ã€‚
- en: 'Since the MNIST dataset is used so ubiquitously, TensorFlow has a nice built-in
    way to download and cache the MNIST dataset. It can be done by simply calling
    the following code:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äº MNIST æ•°æ®é›†è¢«å¦‚æ­¤å¹¿æ³›åœ°ä½¿ç”¨ï¼ŒTensorFlow æœ‰ä¸€ç§å¾ˆå¥½çš„å†…ç½®æ–¹å¼æ¥ä¸‹è½½å’Œç¼“å­˜ MNIST æ•°æ®é›†ã€‚åªéœ€ç®€å•åœ°è°ƒç”¨ä»¥ä¸‹ä»£ç å³å¯å®Œæˆï¼š
- en: '[PRE0]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This will download all the MNIST data into `MNIST_data` into the `"MNIST_data/"`
    directory, if it is not already there. The `mnist` object has properties, `train
    and test`, which allow you to access the data in NumPy arrays. The `MNIST` images
    are all sized 28 by 28, which means 784 pixels per image. We will need one visible
    node in our RBM for each pixel:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°†æŠŠæ‰€æœ‰ MNIST æ•°æ®ä¸‹è½½åˆ° `"MNIST_data/"` ç›®å½•ä¸‹çš„ `MNIST_data` æ–‡ä»¶å¤¹ä¸­ï¼Œå¦‚æœè¿˜æ²¡æœ‰ã€‚`mnist` å¯¹è±¡æœ‰ `train`
    å’Œ `test` å±æ€§ï¼Œå…è®¸æ‚¨è®¿é—® NumPy æ•°ç»„ä¸­çš„æ•°æ®ã€‚MNIST å›¾åƒéƒ½æ˜¯ 28x28 å¤§å°çš„ï¼Œå³æ¯ä¸ªå›¾åƒæœ‰ 784 ä¸ªåƒç´ ã€‚æˆ‘ä»¬å°†ä¸ºæˆ‘ä»¬çš„ RBM
    éœ€è¦æ¯ä¸ªåƒç´ ä¸€ä¸ªå¯è§èŠ‚ç‚¹ï¼š
- en: '[PRE1]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'A placeholder object in TensorFlow represents values that will be passed in
    to the computational graph during usage. In this case, the `input_placeholder`
    object will hold the values of the `MNIST` images we give it. The `"float"` specifies
    the type of value we will be passing in, and the `shape` defines the dimensions.
    In this case, we want 784 values, one for each pixel, and the `None` dimension
    is for batching. Having a None dimension means that it can be of any size; so,
    this will allow us to send variable-sized batches of 784-length arrays:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow ä¸­çš„å ä½ç¬¦å¯¹è±¡è¡¨ç¤ºåœ¨ä½¿ç”¨æœŸé—´å°†ä¼ é€’åˆ°è®¡ç®—å›¾ä¸­çš„å€¼ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œ`input_placeholder` å¯¹è±¡å°†ä¿å­˜æˆ‘ä»¬ç»™å®ƒçš„ `MNIST`
    å›¾åƒçš„å€¼ã€‚`"float"` æŒ‡å®šäº†æˆ‘ä»¬å°†ä¼ é€’çš„å€¼çš„ç±»å‹ï¼Œ`shape` å®šä¹‰äº†ç»´åº¦ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬æƒ³è¦ 784 ä¸ªå€¼ï¼Œæ¯ä¸ªåƒç´ ä¸€ä¸ªï¼Œ`None` ç»´åº¦ç”¨äºæ‰¹å¤„ç†ã€‚æœ‰ä¸€ä¸ª
    None ç»´åº¦æ„å‘³ç€å®ƒå¯ä»¥æ˜¯ä»»ä½•å¤§å°ï¼›å› æ­¤ï¼Œè¿™å°†å…è®¸æˆ‘ä»¬å‘é€å¯å˜å¤§å°çš„ 784 é•¿åº¦çš„æ•°ç»„çš„æ‰¹æ¬¡ï¼š
- en: '[PRE2]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '`tf.variable` represents a variable on the computational graph. This is the
    *W* from our preceding equations. The argument passed to it is how the variable
    values should first be initialized. Here, we are initializing it from a normal
    distribution of size 784 by 300, the number of visible nodes to hidden nodes:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '`tf.variable` è¡¨ç¤ºè®¡ç®—å›¾ä¸Šçš„å˜é‡ã€‚è¿™æ˜¯å‰è¿°æ–¹ç¨‹ä¸­çš„ *W*ã€‚ä¼ é€’ç»™å®ƒçš„å‚æ•°æ˜¯å˜é‡å€¼åº”è¯¥å¦‚ä½•é¦–å…ˆåˆå§‹åŒ–çš„æ–¹å¼ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°†å…¶åˆå§‹åŒ–ä¸ºä¸€ä¸ªå¤§å°ä¸º
    784x300 çš„æ­£æ€åˆ†å¸ƒï¼Œå³å¯è§èŠ‚ç‚¹åˆ°éšè—èŠ‚ç‚¹çš„æ•°é‡ï¼š'
- en: '[PRE3]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'These variables will be the `a` and `b` from our preceding equation; they are
    initialised to all start with a value of 0\. Now we will program in the activations
    of our network:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›å˜é‡å°†æ˜¯æˆ‘ä»¬å‰è¿°æ–¹ç¨‹ä¸­çš„ `a` å’Œ `b`ï¼›å®ƒä»¬è¢«åˆå§‹åŒ–ä¸ºå…¨éƒ¨ä»å€¼ä¸º 0 å¼€å§‹ã€‚ç°åœ¨æˆ‘ä»¬å°†ç¼–å†™ç½‘ç»œçš„æ¿€æ´»ï¼š
- en: '[PRE4]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'This represents the activation of the hidden nodes, ![Implementation in TensorFlow](img/00194.jpeg),
    in the preceding equations. After applying the `sigmoid` function, this activation
    could be put into a binomial distribution so that all values in the hidden layer
    go to 0 or 1, with the probability given; but it turns out an RBM trains just
    as well as the raw probabilities. So, there''s no need to complicate the model
    by doing this:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä»£è¡¨äº†åœ¨å‰è¿°æ–¹ç¨‹ä¸­éšè—èŠ‚ç‚¹çš„æ¿€æ´»ï¼Œ![TensorFlow å®ç°](img/00194.jpeg)ã€‚åº”ç”¨ `sigmoid` å‡½æ•°åï¼Œè¿™ä¸ªæ¿€æ´»å¯ä»¥è¢«æ”¾å…¥äºŒé¡¹åˆ†å¸ƒä¸­ï¼Œä»¥ä¾¿éšè—å±‚ä¸­çš„æ‰€æœ‰å€¼éƒ½å˜ä¸º
    0 æˆ– 1ï¼Œæ¦‚ç‡ç”±ç»™å®šï¼›ä½†äº‹å®è¯æ˜ï¼ŒRBM çš„è®­ç»ƒä¸åŸå§‹æ¦‚ç‡ä¸€æ ·å¥½ã€‚å› æ­¤ï¼Œæ²¡æœ‰å¿…è¦é€šè¿‡è¿™ç§æ–¹å¼å¤æ‚åŒ–æ¨¡å‹ï¼š
- en: '[PRE5]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Now we have the reconstruction of the visible layer, ![Implementation in TensorFlow](img/00195.jpeg).
    As specified by the equation, we give it the `hidden_activation`, and from that,
    we get our sample from the visible layer:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬æœ‰äº†å¯è§å±‚çš„é‡æ„ï¼Œ![TensorFlow å®ç°](img/00195.jpeg)ã€‚æ ¹æ®æ–¹ç¨‹çš„è§„å®šï¼Œæˆ‘ä»¬ç»™å®ƒ `hidden_activation`ï¼Œä»ä¸­æˆ‘ä»¬å¾—åˆ°äº†å¯è§å±‚çš„æ ·æœ¬ï¼š
- en: '[PRE6]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'We now compute the final sample we need, the activation of the hidden nodes
    from our `visible_reconstruction`. This is equivalent to ![Implementation in TensorFlow](img/00196.jpeg)
    in the equations. We could keep going with successive iterations of hidden and
    visual activation to get a much more unbiased sample from the model. But it doing
    just one rotation works fine for training:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬è®¡ç®—æˆ‘ä»¬éœ€è¦çš„æœ€ç»ˆæ ·æœ¬ï¼Œæ¥è‡ªæˆ‘ä»¬çš„`visible_reconstruction`çš„éšè—èŠ‚ç‚¹çš„æ¿€æ´»ã€‚è¿™ç›¸å½“äºæ–¹ç¨‹ä¸­çš„ ![åœ¨TensorFlowä¸­çš„å®ç°](img/00196.jpeg)ã€‚æˆ‘ä»¬å¯ä»¥ç»§ç»­ä½¿ç”¨è¿ç»­è¿­ä»£çš„éšè—å’Œå¯è§†æ¿€æ´»æ¥ä»æ¨¡å‹ä¸­è·å–ä¸€ä¸ªæ›´åŠ æ— åçš„æ ·æœ¬ã€‚ä½†åªè¿›è¡Œä¸€æ¬¡æ—‹è½¬å°±è¶³å¤Ÿç”¨äºè®­ç»ƒï¼š
- en: '[PRE7]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Now we compute the positive and negative phases. The first phase is the correlation
    across samples from our mini-batch of the `input_placeholder`,![Implementation
    in TensorFlow](img/00197.jpeg) and the first `hidden_activation`, ![Implementation
    in TensorFlow](img/00194.jpeg). Then the negative phase gets the correlation between
    the `visible_reconstruction`, ![Implementation in TensorFlow](img/00195.jpeg)
    and the `final_hidden_activation`, ![Implementation in TensorFlow](img/00196.jpeg):'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬è®¡ç®—æ­£ç›¸ä½å’Œè´Ÿç›¸ä½ã€‚ç¬¬ä¸€é˜¶æ®µæ˜¯æˆ‘ä»¬çš„ `input_placeholder` ä¸­çš„æ ·æœ¬å’Œç¬¬ä¸€ä¸ª `hidden_activation` ä¹‹é—´çš„ç›¸å…³æ€§ï¼Œ![åœ¨TensorFlowä¸­çš„å®ç°](img/00197.jpeg)ã€‚ç„¶åï¼Œè´Ÿç›¸ä½è·å–
    `visible_reconstruction`ï¼Œ![åœ¨TensorFlowä¸­çš„å®ç°](img/00195.jpeg)å’Œ`final_hidden_activation`ä¹‹é—´çš„ç›¸å…³æ€§ï¼Œ![åœ¨TensorFlowä¸­çš„å®ç°](img/00196.jpeg)ï¼š
- en: '[PRE8]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Calling `assign_add` on our `weights` variable creates an operation that, when
    run, adds the given quantity to the variable. Here, 0.01 is our learning rate,
    and we scale the positive and negative phases by that:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘ä»¬çš„`weights`å˜é‡ä¸Šè°ƒç”¨`assign_add`ä¼šåˆ›å»ºä¸€ä¸ªæ“ä½œï¼Œå½“è¿è¡Œæ—¶ï¼Œä¼šå°†ç»™å®šçš„æ•°é‡æ·»åŠ åˆ°å˜é‡ä¸­ã€‚è¿™é‡Œï¼Œ0.01æ˜¯æˆ‘ä»¬çš„å­¦ä¹ ç‡ï¼Œæˆ‘ä»¬é€šè¿‡å®ƒæ¥ç¼©æ”¾æ­£ç›¸ä½å’Œè´Ÿç›¸ä½ï¼š
- en: '[PRE9]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Now we create the operations for scaling the hidden and visible biases. These
    are also scaled by our 0.01 learning rate:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬åˆ›å»ºç¼©æ”¾éšè—å’Œå¯è§†åç½®çš„æ“ä½œã€‚è¿™äº›ä¹Ÿä¼šè¢«æˆ‘ä»¬çš„0.01å­¦ä¹ ç‡ç¼©æ”¾ï¼š
- en: '[PRE10]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Calling `tf.group` creates a new operation than when called executes all the
    operation arguments together. We will always want to update all the weights in
    unison, so it makes sense to create a single operation for them:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: è°ƒç”¨`tf.group`åˆ›å»ºä¸€ä¸ªæ–°æ“ä½œï¼Œå½“è°ƒç”¨æ—¶ä¼šåŒæ—¶æ‰§è¡Œæ‰€æœ‰çš„æ“ä½œå‚æ•°ã€‚æˆ‘ä»¬æ€»æ˜¯å¸Œæœ›åŒæ—¶æ›´æ–°æ‰€æœ‰çš„æƒé‡ï¼Œæ‰€ä»¥åˆ›å»ºä¸€ä¸ªå•ç‹¬çš„æ“ä½œæ˜¯æœ‰æ„ä¹‰çš„ï¼š
- en: '[PRE11]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: This `loss_op` will give us feedback on how well we are training, using the
    MSE. Note that this is purely used for information; there is no backpropagation
    run against this signal. If we wanted to run this network as a pure autoencoder,
    we would create an optimizer here and activate it to minimize the `loss_op`:?
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ª`loss_op`å°†ä¸ºæˆ‘ä»¬æä¾›æœ‰å…³æˆ‘ä»¬çš„è®­ç»ƒæ•ˆæœçš„åé¦ˆï¼Œä½¿ç”¨MSEã€‚è¯·æ³¨æ„ï¼Œè¿™ä»…ç”¨äºä¿¡æ¯ï¼›ä¸ä¼šé’ˆå¯¹æ­¤ä¿¡å·è¿›è¡Œåå‘ä¼ æ’­ã€‚å¦‚æœæˆ‘ä»¬æƒ³å°†è¿™ä¸ªç½‘ç»œä½œä¸ºä¸€ä¸ªçº¯è‡ªåŠ¨ç¼–ç å™¨æ¥è¿è¡Œï¼Œæˆ‘ä»¬å°†åœ¨è¿™é‡Œåˆ›å»ºä¸€ä¸ªä¼˜åŒ–å™¨ï¼Œå¹¶æ¿€æ´»å®ƒä»¥æœ€å°åŒ–`loss_op`ï¼šï¼Ÿ
- en: '[PRE12]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Then we create a session object that will be used for running the computational
    graph. Calling `tf.initialize_all_variables()` is when everything gets initialized
    on to the graph. If you are running TensorFlow on the GPU, this is where the hardware
    is first interfaced with. Now that we have created every step for the RBM, let''s
    put it through a few epochs of running against MNIST and see how well it learns:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªå°†ç”¨äºè¿è¡Œè®¡ç®—å›¾çš„ä¼šè¯å¯¹è±¡ã€‚è°ƒç”¨`tf.initialize_all_variables()`æ—¶ï¼Œæ‰€æœ‰å†…å®¹éƒ½ä¼šåˆå§‹åŒ–åˆ°å›¾ä¸­ã€‚å¦‚æœä½ åœ¨GPUä¸Šè¿è¡ŒTensorFlowï¼Œè¿™æ˜¯ç¡¬ä»¶é¦–å…ˆè¢«æ¥å£åŒ–çš„åœ°æ–¹ã€‚ç°åœ¨æˆ‘ä»¬å·²ç»ä¸ºRBMåˆ›å»ºäº†æ¯ä¸€æ­¥ï¼Œè®©æˆ‘ä»¬ç»å†å‡ ä¸ªæ—¶ä»£çš„MNISTè¿è¡Œï¼Œå¹¶çœ‹çœ‹å®ƒå­¦åˆ°äº†å¤šå°‘ï¼š
- en: '[PRE13]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Every time we call `mnist.train.next_batch(100)`, 100 images are retrieved
    from the `mnist` dataset. At the end of each epoch, the `mnist.train.epochs_completed`
    is incremented by 1, and all the training data is reshuffled. If you run this,
    you may see results something like this:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯æ¬¡æˆ‘ä»¬è°ƒç”¨`mnist.train.next_batch(100)`ï¼Œå°±ä¼šä»`mnist`æ•°æ®é›†ä¸­æ£€ç´¢100å¼ å›¾ç‰‡ã€‚åœ¨æ¯ä¸ªæ—¶ä»£ç»“æŸæ—¶ï¼Œ`mnist.train.epochs_completed`ä¼šå¢åŠ 1ï¼Œæ‰€æœ‰è®­ç»ƒæ•°æ®éƒ½ä¼šé‡æ–°æ´—ç‰Œã€‚å¦‚æœä½ è¿è¡Œè¿™ä¸ªï¼Œä½ å¯èƒ½ä¼šçœ‹åˆ°ç±»ä¼¼è¿™æ ·çš„ç»“æœï¼š
- en: '[PRE14]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'We can now see what an image reconstruction looks like by running the following
    command on the `mnist` data:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å¯ä»¥é€šè¿‡åœ¨`mnist`æ•°æ®ä¸Šè¿è¡Œä»¥ä¸‹å‘½ä»¤æ¥çœ‹çœ‹å›¾åƒé‡æ„æ˜¯ä»€ä¹ˆæ ·çš„ï¼š
- en: '[PRE15]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Here are some examples of what the reconstructed images with 300 hidden nodes
    look like:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæœ‰ä¸€äº›ä½¿ç”¨300ä¸ªéšè—èŠ‚ç‚¹çš„é‡å»ºå›¾åƒçš„ç¤ºä¾‹ï¼š
- en: '![Implementation in TensorFlow](img/00198.jpeg)'
  id: totrans-239
  prefs: []
  type: TYPE_IMG
  zh: '![åœ¨TensorFlowä¸­çš„å®ç°](img/00198.jpeg)'
- en: Figure 3\. Reconstructions of digits using restricted Boltzmann machines with
    different numbers of hidden nodes
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾3. ä½¿ç”¨ä¸åŒæ•°é‡çš„éšè—èŠ‚ç‚¹å¯¹å—é™ç»å°”å…¹æ›¼æœºè¿›è¡Œæ•°å­—çš„é‡æ„
- en: As you can see, with 300 hidden nodes, less than half the number of pixels,
    it can still do an almost perfect reconstruction of the image, with only a little
    blurring around the edges. But as the number of hidden nodes decreases, so does
    the quality of the reconstruction. Going down to just 10 hidden nodes, the reconstructions
    can produce images that, to the human eye, look like the wrong digit, such as
    the 2 and 3 in Figure 3.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£å¦‚æ‚¨æ‰€è§ï¼Œä½¿ç”¨300ä¸ªéšè—èŠ‚ç‚¹ï¼Œä¸åˆ°åƒç´ æ•°é‡çš„ä¸€åŠï¼Œå®ƒä»ç„¶å¯ä»¥å‡ ä¹å®Œç¾åœ°é‡å»ºå›¾åƒï¼Œåªæœ‰è¾¹ç¼˜å‘¨å›´æœ‰ä¸€ç‚¹æ¨¡ç³Šã€‚ä½†æ˜¯éšç€éšè—èŠ‚ç‚¹æ•°é‡çš„å‡å°‘ï¼Œé‡å»ºçš„è´¨é‡ä¹Ÿä¼šé™ä½ã€‚å°†éšè—èŠ‚ç‚¹å‡å°‘åˆ°åªæœ‰10ä¸ªæ—¶ï¼Œé‡å»ºçš„å›¾åƒå¯èƒ½ä¼šäº§ç”Ÿå¯¹äºäººçœ¼æ¥è¯´çœ‹èµ·æ¥åƒæ˜¯é”™è¯¯çš„æ•°å­—ï¼Œä¾‹å¦‚å›¾3ä¸­çš„2å’Œ3ã€‚
- en: Deep belief networks
  id: totrans-242
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ·±ä¿¡åº¦ç½‘ç»œ
- en: 'If we imagine our RBM is learning a set of latent variables that generated
    our visible data and we were feeling inquisitive, we might wonder: can we then
    learn a second layer of latent variables that generated the latent variables for
    the hidden layer? The answer is yes, we can stack RBMs on top of previously trained
    RBMs to be able to learn second, third, fourth, and so on, order information about
    the visible data. These successive layers of RBMs allow the network to learn increasingly
    invariant representations of the underlying structure:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬æƒ³è±¡æˆ‘ä»¬çš„RBMæ­£åœ¨å­¦ä¹ ä¸€ç»„ç”Ÿæˆæˆ‘ä»¬å¯è§æ•°æ®çš„æ½œåœ¨å˜é‡ï¼Œå¹¶ä¸”æˆ‘ä»¬æ„Ÿåˆ°å¥½å¥‡ï¼Œæˆ‘ä»¬å¯èƒ½ä¼šæƒ³çŸ¥é“ï¼šæˆ‘ä»¬æ˜¯å¦å¯ä»¥å­¦ä¹ ç¬¬äºŒå±‚ç”Ÿæˆéšè—å±‚æ½œåœ¨å˜é‡çš„æ½œåœ¨å˜é‡ï¼Ÿç­”æ¡ˆæ˜¯è‚¯å®šçš„ï¼Œæˆ‘ä»¬å¯ä»¥å°†å…ˆå‰è®­ç»ƒçš„RBMå †å åœ¨ä¸€èµ·ï¼Œä»¥ä¾¿å­¦ä¹ æœ‰å…³å¯è§æ•°æ®çš„äºŒé˜¶ã€ä¸‰é˜¶ã€å››é˜¶ç­‰ä¿¡æ¯ã€‚è¿™äº›è¿ç»­çš„RBMå±‚ä½¿ç½‘ç»œèƒ½å¤Ÿå­¦ä¹ è¶Šæ¥è¶Šä¸å˜çš„è¡¨ç¤ºåº•å±‚ç»“æ„ï¼š
- en: '![Deep belief networks](img/00199.jpeg)'
  id: totrans-244
  prefs: []
  type: TYPE_IMG
  zh: '![æ·±ä¿¡åº¦ç½‘ç»œ](img/00199.jpeg)'
- en: Figure 4 Deep belief network, containing many chained RBMs
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾4 æ·±ä¿¡åº¦ç½‘ç»œï¼ŒåŒ…å«è®¸å¤šé“¾æ¥çš„RBM
- en: These stacked RBMs are known as deep belief networks and were the deep networks
    used by Geoffrey Hinton in his 2002 paper *Training Products of Experts by Minimizing
    Contrastive Divergence*, to first produce the record-breaking results on MNIST.
    The exact technique he found useful was to train successive RBMs on data with
    only a slight reduction in the size of the layers. Once a layer was trained to
    the point where the reconstruction error was no longer improving, its weights
    were frozen, and a new RBM was stacked on top and again trained until error rate
    convergence. Once the full network was trained, a final supervised layer was put
    at the end in order to map the final RBM's hidden layer to the labels of the data.
    Then the weights of the whole network were used to construct a standard deep feed-forward
    neutral network, allowing those precalculated weights of the deep belief network
    to be updated by backpropagation.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›å †å çš„RBMè¢«ç§°ä¸ºæ·±åº¦ä¿¡åº¦ç½‘ç»œï¼Œæ˜¯Geoffrey Hintonåœ¨ä»–çš„2002å¹´è®ºæ–‡ã€Šé€šè¿‡æœ€å°åŒ–å¯¹æ¯”æ•£åº¦è®­ç»ƒä¸“å®¶äº§å“ã€‹ä¸­é¦–æ¬¡åœ¨MNISTä¸Šå–å¾—çªç ´æ€§æˆæœæ—¶ä½¿ç”¨çš„æ·±åº¦ç½‘ç»œã€‚ä»–å‘ç°æœ‰ç”¨çš„ç¡®åˆ‡æŠ€æœ¯æ˜¯åœ¨æ•°æ®ä¸Šè®­ç»ƒè¿ç»­çš„RBMï¼Œæ¯ä¸€å±‚çš„å°ºå¯¸éƒ½åªç¨å¾®å‡å°ã€‚ä¸€æ—¦ä¸€ä¸ªå±‚è®­ç»ƒåˆ°é‡å»ºè¯¯å·®ä¸å†æ”¹å–„çš„ç¨‹åº¦ï¼Œå®ƒçš„æƒé‡å°±è¢«å†»ç»“ï¼Œç„¶ååœ¨å…¶ä¸Šå †å ä¸€ä¸ªæ–°çš„RBMï¼Œå¹¶å†æ¬¡è®­ç»ƒç›´åˆ°è¯¯å·®ç‡æ”¶æ•›ã€‚ä¸€æ—¦æ•´ä¸ªç½‘ç»œè®­ç»ƒå®Œæ¯•ï¼Œæœ€åæ·»åŠ ä¸€ä¸ªç›‘ç£å±‚ï¼Œä»¥å°†æœ€ç»ˆRBMçš„éšè—å±‚æ˜ å°„åˆ°æ•°æ®çš„æ ‡ç­¾ã€‚ç„¶åä½¿ç”¨æ•´ä¸ªç½‘ç»œçš„æƒé‡æ„å»ºæ ‡å‡†çš„æ·±åº¦å‰é¦ˆç¥ç»ç½‘ç»œï¼Œä½¿å¾—è¿™äº›é¢„å…ˆè®¡ç®—çš„æ·±åº¦ä¿¡åº¦ç½‘ç»œçš„æƒé‡èƒ½å¤Ÿé€šè¿‡åå‘ä¼ æ’­è¿›è¡Œæ›´æ–°ã€‚
- en: At first, these had great results, but over time, the techniques for training
    standard feed-forward networks have improved, and RBMs are no longer considered
    the best for image or speech recognition. They also have the problem that because
    of their two-phase nature, they can be a lot slower to train. But they are still
    very popular for things such as recommender systems and pure unsupervised learning.
    Also, from a theoretical point of view, using the energy-based model to learn
    deep representations is a very interesting approach and leaves the door open for
    many extensions that can be built on top of this approach.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: èµ·åˆï¼Œè¿™äº›æ–¹æ³•æ•ˆæœå¾ˆå¥½ï¼Œä½†éšç€æ—¶é—´çš„æ¨ç§»ï¼Œç”¨äºè®­ç»ƒæ ‡å‡†å‰é¦ˆç½‘ç»œçš„æŠ€æœ¯å·²ç»æ”¹è¿›ï¼ŒRBMsä¸å†è¢«è®¤ä¸ºæ˜¯å›¾åƒæˆ–è¯­éŸ³è¯†åˆ«çš„æœ€ä½³æ–¹æ³•ã€‚å®ƒä»¬è¿˜å­˜åœ¨ä¸€ä¸ªé—®é¢˜ï¼Œå°±æ˜¯ç”±äºå…¶ä¸¤é˜¶æ®µæ€§è´¨ï¼Œå®ƒä»¬çš„è®­ç»ƒé€Ÿåº¦å¯èƒ½ä¼šæ…¢å¾—å¤šã€‚ä½†æ˜¯å®ƒä»¬åœ¨è¯¸å¦‚æ¨èç³»ç»Ÿå’Œçº¯æ— ç›‘ç£å­¦ä¹ ç­‰æ–¹é¢ä»ç„¶éå¸¸å—æ¬¢è¿ã€‚æ­¤å¤–ï¼Œä»ç†è®ºä¸Šè®²ï¼Œä½¿ç”¨èƒ½é‡æ¨¡å‹æ¥å­¦ä¹ æ·±åº¦è¡¨ç¤ºæ˜¯ä¸€ç§éå¸¸æœ‰è¶£çš„æ–¹æ³•ï¼Œå¹¶ä¸”ä¸ºè®¸å¤šå¯ä»¥å»ºç«‹åœ¨è¯¥æ–¹æ³•ä¹‹ä¸Šçš„æ‰©å±•ç•™ä¸‹äº†å¤§é—¨ã€‚
- en: Summary
  id: totrans-248
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ‘˜è¦
- en: 'We have seen in this chapter two of the most powerful techniques at the core
    of many practical deep learning implementations: autoencoders and restricted Boltzmann
    machines.'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬çœ‹åˆ°äº†è®¸å¤šå®é™…æ·±åº¦å­¦ä¹ å®ç°æ ¸å¿ƒçš„ä¸¤ç§æœ€å¼ºå¤§çš„æŠ€æœ¯ï¼šè‡ªåŠ¨ç¼–ç å™¨å’Œå—é™ç»å°”å…¹æ›¼æœºã€‚
- en: For both of them, we started with the shallow example of one hidden layer, and
    we explored how we can stack them together to form a deep neural network able
    to automatically learn high-level and hierarchical features without requiring
    explicit human knowledge.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºå®ƒä»¬ä¸¤ä¸ªï¼Œæˆ‘ä»¬éƒ½ä»ä¸€ä¸ªéšè—å±‚çš„æµ…å±‚ç¤ºä¾‹å¼€å§‹ï¼Œå¹¶ä¸”æ¢ç´¢äº†å¦‚ä½•å°†å®ƒä»¬å †å åœ¨ä¸€èµ·å½¢æˆä¸€ä¸ªæ·±åº¦ç¥ç»ç½‘ç»œï¼Œèƒ½å¤Ÿè‡ªåŠ¨å­¦ä¹ é«˜å±‚æ¬¡å’Œåˆ†å±‚æ¬¡çš„ç‰¹å¾ï¼Œè€Œä¸éœ€è¦æ˜¾å¼çš„äººç±»çŸ¥è¯†ã€‚
- en: They both serve similar purposes, but there is a little substantial difference.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒä»¬éƒ½æœ‰ç±»ä¼¼çš„ç›®çš„ï¼Œä½†æœ‰ä¸€ç‚¹å°å°çš„å®è´¨æ€§å·®åˆ«ã€‚
- en: Autoencoders can be seen as a compression filter that we use to compress the
    data in order to preserve only the most informative part of it and be able to
    deterministically reconstruct an approximation of the original data. Autoencoders
    are an elegant solution to dimensionality reduction and non-linear compression
    bypassing the limitations of the principal component analysis (PCA) technique.
    The advantages of autoencoders are that they can be used as preprocessing steps
    for further classification tasks, where the output of each hidden layer is one
    of the possible levels of informative representations of the data, or a denoised
    and recovered version of it. Another great advantage is to exploit the reconstruction
    error as a measure of dissimilarity of a single point from the rest of the group.
    Such a technique is widely used for anomaly detection problems, where the relationships
    from what we observe and the internal representations are constant and deterministic.
    In the case of time-variant relationships or depending upon an observable dimension,
    we could group and train different networks in order to be adaptive, but once
    trained, the network assumes those relationships to not be affected by random
    variations.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: è‡ªåŠ¨ç¼–ç å™¨å¯ä»¥è¢«çœ‹ä½œæ˜¯æˆ‘ä»¬ç”¨æ¥å‹ç¼©æ•°æ®çš„å‹ç¼©è¿‡æ»¤å™¨ï¼Œä»¥ä¿ç•™å…¶ä¸­æœ€å…·ä¿¡æ¯é‡çš„éƒ¨åˆ†ï¼Œå¹¶èƒ½å¤Ÿç¡®å®šæ€§åœ°é‡æ„åŸå§‹æ•°æ®çš„è¿‘ä¼¼ã€‚è‡ªåŠ¨ç¼–ç å™¨æ˜¯å¯¹ç»´åº¦çº¦ç®€å’Œéçº¿æ€§å‹ç¼©çš„ä¼˜é›…è§£å†³æ–¹æ¡ˆï¼Œç»•è¿‡äº†ä¸»æˆåˆ†åˆ†æï¼ˆPCAï¼‰æŠ€æœ¯çš„é™åˆ¶ã€‚è‡ªåŠ¨ç¼–ç å™¨çš„ä¼˜ç‚¹æ˜¯ï¼Œå®ƒä»¬å¯ä»¥ç”¨ä½œè¿›ä¸€æ­¥åˆ†ç±»ä»»åŠ¡çš„é¢„å¤„ç†æ­¥éª¤ï¼Œå…¶ä¸­æ¯ä¸ªéšè—å±‚çš„è¾“å‡ºæ˜¯æ•°æ®ä¿¡æ¯è¡¨ç¤ºçš„å¯èƒ½çº§åˆ«ä¹‹ä¸€ï¼Œæˆ–è€…æ˜¯å…¶å»å™ªå’Œæ¢å¤ç‰ˆæœ¬ã€‚å¦ä¸€ä¸ªå·¨å¤§çš„ä¼˜ç‚¹æ˜¯åˆ©ç”¨é‡æ„è¯¯å·®ä½œä¸ºä¸€ä¸ªå•ç‚¹ä¸å…¶ä½™ç»„çš„ä¸ç›¸ä¼¼æ€§çš„åº¦é‡ã€‚è¿™æ ·çš„æŠ€æœ¯å¹¿æ³›ç”¨äºå¼‚å¸¸æ£€æµ‹é—®é¢˜ï¼Œå…¶ä¸­æˆ‘ä»¬è§‚å¯Ÿåˆ°çš„å†…å®¹ä¸å†…éƒ¨è¡¨ç¤ºä¹‹é—´çš„å…³ç³»æ˜¯æ’å®šçš„å’Œç¡®å®šæ€§çš„ã€‚åœ¨æ—¶é—´å˜åŒ–å…³ç³»æˆ–å–å†³äºå¯è§‚å¯Ÿç»´åº¦çš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¯ä»¥åˆ†ç»„å’Œè®­ç»ƒä¸åŒçš„ç½‘ç»œï¼Œä»¥ä¾¿é€‚åº”ï¼Œä½†ä¸€æ—¦è®­ç»ƒå®Œæˆï¼Œç½‘ç»œå°±å‡è®¾è¿™äº›å…³ç³»ä¸å—éšæœºå˜åŒ–çš„å½±å“ã€‚
- en: 'On the other hand, RBM uses a stochastic approach to sample and adjust weights
    to minimize the reconstruction error. The intuition could be that there might
    exist some visible random variables and some hidden latent attributes, and the
    goal is to find how the two sets are connected to each other. To give an example,
    in the case of movie rating, we can have some hidden attributes, such as film
    genre, and some random observations, such as the rating and/or review. In such
    topology, we can also see the bias term as a way of adjusting the different inherent
    popularities of each movie. If we asked our users to rate which movie they like
    from a set made of *Harry Potter*, *Avatar*, *Lord of The Ring*, *Gladiator*,
    and *Titanic*, we might get a resulting network where two of the latent units
    could represent science fiction movies and Oscar-winning movies:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: å¦ä¸€æ–¹é¢ï¼ŒRBM ä½¿ç”¨éšæœºæ–¹æ³•å¯¹æ ·æœ¬è¿›è¡Œé‡‡æ ·å’Œè°ƒæ•´æƒé‡ï¼Œä»¥æœ€å°åŒ–é‡æ„è¯¯å·®ã€‚ç›´è§‰å¯èƒ½æ˜¯å­˜åœ¨ä¸€äº›å¯è§çš„éšæœºå˜é‡å’Œä¸€äº›éšè—çš„æ½œåœ¨å±æ€§ï¼Œç›®æ ‡æ˜¯æ‰¾å‡ºè¿™ä¸¤ç»„ä¹‹é—´çš„è”ç³»ã€‚ä¸¾ä¸ªä¾‹å­ï¼Œåœ¨ç”µå½±è¯„åˆ†çš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¯ä»¥æœ‰ä¸€äº›éšè—çš„å±æ€§ï¼Œæ¯”å¦‚ç”µå½±ç±»å‹ï¼Œä»¥åŠä¸€äº›éšæœºçš„è§‚å¯Ÿï¼Œæ¯”å¦‚è¯„åˆ†å’Œ/æˆ–è¯„è®ºã€‚åœ¨è¿™æ ·çš„æ‹“æ‰‘ç»“æ„ä¸­ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥å°†åå·®é¡¹çœ‹ä½œæ˜¯è°ƒæ•´æ¯éƒ¨ç”µå½±ä¸åŒå†…åœ¨æµè¡Œåº¦çš„ä¸€ç§æ–¹å¼ã€‚å¦‚æœæˆ‘ä»¬è®©ç”¨æˆ·ä»ç”±*å“ˆåˆ©Â·æ³¢ç‰¹*ã€*é˜¿å‡¡è¾¾*ã€*æŒ‡ç¯ç‹*ã€*è§’æ–—å£«*å’Œ*æ³°å¦å°¼å…‹å·*ç»„æˆçš„é›†åˆä¸­è¯„ä»·ä»–ä»¬å–œæ¬¢å“ªéƒ¨ç”µå½±ï¼Œæˆ‘ä»¬å¯èƒ½ä¼šå¾—åˆ°ä¸€ä¸ªç»“æœç½‘ç»œï¼Œå…¶ä¸­ä¸¤ä¸ªæ½œåœ¨å•å…ƒå¯èƒ½ä»£è¡¨ç§‘å¹»ç”µå½±å’Œå¥¥æ–¯å¡è·å¥–ç”µå½±ï¼š
- en: '![Summary](img/00200.jpeg)'
  id: totrans-254
  prefs: []
  type: TYPE_IMG
  zh: '![æ¦‚è¦](img/00200.jpeg)'
- en: Example of possible RBM where only the links with a weight significantly different
    from 0 are drawn.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: å¯èƒ½çš„ RBM ç¤ºä¾‹ï¼Œä»…ç»˜åˆ¶ä¸æƒé‡æ˜æ˜¾ä¸åŒäº 0 çš„é“¾æ¥ã€‚
- en: Although the attributes of SF and Oscar-winning are deterministic (effectively,
    they are attributes of the movie), the ratings of the users are influenced by
    that in a probabilistic way. The learned weights are the parameters that characterize
    the probability distribution of the movie rating (for example, Harry Potter with
    five stars), given that the user likes a particular genre (for example, science
    fiction).
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶ç§‘å¹»å’Œå¥¥æ–¯å¡è·å¥–çš„å±æ€§æ˜¯ç¡®å®šæ€§çš„ï¼ˆå®é™…ä¸Šï¼Œå®ƒä»¬æ˜¯ç”µå½±çš„å±æ€§ï¼‰ï¼Œä½†ç”¨æˆ·çš„è¯„çº§å—åˆ°æ¦‚ç‡æ–¹å¼çš„å½±å“ã€‚å­¦ä¹ åˆ°çš„æƒé‡æ˜¯è¡¨å¾ç”µå½±è¯„åˆ†çš„æ¦‚ç‡åˆ†å¸ƒçš„å‚æ•°ï¼ˆä¾‹å¦‚ï¼Œå“ˆåˆ©Â·æ³¢ç‰¹è·å¾—äº”æ˜Ÿï¼‰ï¼Œå‡è®¾ç”¨æˆ·å–œæ¬¢ç‰¹å®šçš„ç±»å‹ï¼ˆä¾‹å¦‚ï¼Œç§‘å¹»ï¼‰ã€‚
- en: In such a scenario, where the relationships are not deterministic, we want to
    prefer using RBM to using an autoencoder.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ç§å…³ç³»ä¸ç¡®å®šçš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬æ›´å€¾å‘äºä½¿ç”¨å—é™ç»å°”å…¹æ›¼æœºï¼ˆRBMï¼‰è€Œä¸æ˜¯è‡ªç¼–ç å™¨ã€‚
- en: In conclusion, unsupervised features learning is a very powerful methodology
    to enrich feature engineering with the minimum required knowledge and human interaction.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: æ€»çš„æ¥è¯´ï¼Œæ— ç›‘ç£ç‰¹å¾å­¦ä¹ æ˜¯ä¸€ç§éå¸¸å¼ºå¤§çš„æ–¹æ³•ï¼Œå¯ä»¥ç”¨æœ€å°‘çš„çŸ¥è¯†å’Œäººä¸ºå¹²é¢„æ¥ä¸°å¯Œç‰¹å¾å·¥ç¨‹ã€‚
- en: Standing to a few benchmarks ([Lee, Pham and Ng, 2009] and [Le, Zhou and Ng,
    2011]) performed in order to measure the accuracy of different feature learning
    techniques, it was proved that unsupervised feature learning improved accuracy
    with respect to the current state of the art.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: æ ¹æ®ä¸€äº›åŸºå‡†æµ‹è¯•ï¼ˆ[Lee, Pham and Ng, 2009] å’Œ [Le, Zhou and Ng, 2011]ï¼‰çš„ç»“æœï¼Œç”¨äºè¡¡é‡ä¸åŒç‰¹å¾å­¦ä¹ æŠ€æœ¯å‡†ç¡®æ€§çš„ï¼Œå·²ç»è¯æ˜æ— ç›‘ç£ç‰¹å¾å­¦ä¹ ç›¸å¯¹äºç›®å‰çš„æœ€æ–°æŠ€æœ¯æœ‰æ‰€æé«˜ã€‚
- en: There are a few open challenges though. If you do have some knowledge, it is
    always good not to discard it. We could embed that knowledge in the form of priors
    during the initialization step, where we might handcraft the network topology
    and initial state accordingly.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸è¿‡ï¼Œè¿˜å­˜åœ¨ä¸€äº›æŒ‘æˆ˜ã€‚å¦‚æœæ‚¨æœ‰ä¸€äº›çŸ¥è¯†ï¼Œæœ€å¥½ä¸è¦å°†å…¶ä¸¢å¼ƒã€‚æˆ‘ä»¬å¯ä»¥åœ¨åˆå§‹åŒ–é˜¶æ®µä»¥å…ˆéªŒçš„å½¢å¼åµŒå…¥è¿™äº›çŸ¥è¯†ï¼Œåœ¨è¿™ä¸€é˜¶æ®µæˆ‘ä»¬å¯ä»¥æ‰‹å·¥è®¾è®¡ç½‘ç»œæ‹“æ‰‘å’Œåˆå§‹çŠ¶æ€ã€‚
- en: Moreover, since neural networks are already hard to explain and are mostly approached
    as black box, having an understanding of at least the input features could help.
    In our unsupervised feature learning, we want to consume raw data directly. Hence,
    understanding how the model works becomes even harder.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤å¤–ï¼Œç”±äºç¥ç»ç½‘ç»œæœ¬èº«å·²ç»å¾ˆéš¾è§£é‡Šï¼Œå¹¶ä¸”å¤§å¤šæ•°æ—¶å€™è¢«è§†ä¸ºé»‘åŒ£å­ï¼Œå› æ­¤è‡³å°‘äº†è§£è¾“å…¥ç‰¹å¾å¯èƒ½æœ‰æ‰€å¸®åŠ©ã€‚åœ¨æˆ‘ä»¬çš„æ— ç›‘ç£ç‰¹å¾å­¦ä¹ ä¸­ï¼Œæˆ‘ä»¬å¸Œæœ›ç›´æ¥ä½¿ç”¨åŸå§‹æ•°æ®ã€‚å› æ­¤ï¼Œç†è§£æ¨¡å‹çš„å·¥ä½œåŸç†å˜å¾—æ›´åŠ å›°éš¾ã€‚
- en: We will not address those issues in this book. We believe that it is too early
    to make some conclusions and that further evolutions of deep learning and the
    way people and businesses approach those applications will converge to a steady
    trustworthiness.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åœ¨æœ¬ä¹¦ä¸­ä¸ä¼šæ¶‰åŠè¿™äº›é—®é¢˜ã€‚æˆ‘ä»¬è®¤ä¸ºç°åœ¨ä¸‹ç»“è®ºè¿˜ä¸ºæ—¶è¿‡æ—©ï¼Œæ·±åº¦å­¦ä¹ çš„è¿›ä¸€æ­¥å‘å±•ä»¥åŠäººä»¬å’Œä¼ä¸šå¤„ç†è¿™äº›åº”ç”¨çš„æ–¹å¼å°†ä¼šè¶‹äºç¨³å®šå’Œå¯é ã€‚
