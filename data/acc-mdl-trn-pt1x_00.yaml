- en: Preface
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 前言
- en: Hello there! I’m a system analyst and academic professor specializing in **High-Performance
    Computing** (**HPC**). Yes, you read it right! I’m not a data scientist. So, you
    are probably wondering why on Earth I decided to write a book about machine learning.
    Don’t worry; I will explain.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 你好！我是一名专注于**高性能计算**（**HPC**）的系统分析师和学术教授。是的，你没看错！我不是数据科学家。那么，你可能会想知道我为什么决定写一本关于机器学习的书。别担心，我会解释的。
- en: HPC systems comprise powerful computing resources tightly integrated to solve
    complex problems. The main goal of HPC is to employ resources, techniques, and
    methods to accelerate the execution of highly intensive computing tasks. Traditionally,
    HPC environments have been used to execute scientific applications from biology,
    physics, chemistry, and many other areas.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: HPC系统由强大的计算资源紧密集成，用于解决复杂问题。HPC的主要目标是利用资源、技术和方法加速高强度计算任务的执行。传统上，HPC环境已被用于执行来自生物学、物理学、化学等多个领域的科学应用程序。
- en: 'But this has changed in the past few years. Nowadays, HPC systems run tasks
    beyond scientific applications. In fact, the most prominent non-scientific workload
    executed in HPC environments is precisely the subject of this book: the building
    process of complex neural network models.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 但在过去几年中，情况发生了变化。如今，HPC系统不仅仅运行科学应用程序的任务。事实上，在HPC环境中执行的最显著的非科学工作负载恰恰是本书的主题：复杂神经网络模型的构建过程。
- en: As a data scientist, you know better than anyone else how long it could take
    to train complex models and how many times you need to retrain the model to evaluate
    different scenarios. For this reason, the usage of HPC systems to accelerate **Artificial
    Intelligence** (**AI**) applications (not only for training but also for inference)
    is a growth-demanding area.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 作为数据科学家，您比任何人都知道训练复杂模型可能需要多长时间，以及需要多少次重新训练模型以评估不同场景。因此，使用HPC系统加速人工智能（AI）应用程序（不仅用于训练还用于推断）是一个需求增长的领域。
- en: This close relationship between AI and HPC sparked my interest in diving into
    the fields of machine learning and AI. By doing this, I could better understand
    how HPC has been applied to accelerate these applications.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: AI与HPC之间的密切关系引发了我对深入研究机器学习和AI领域的兴趣。通过这样做，我能更好地理解HPC如何应用于加速这些应用程序。
- en: So, here we are. I wrote this book to share what I have learned about this topic.
    My mission here is to give you the necessary knowledge to train your model faster
    by employing optimization techniques and methods using single or multiple computing
    resources.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，在这里我们是。我写这本书是为了分享我在这个主题上学到的东西。我的使命是通过使用单个或多个计算资源，为您提供训练模型更快的必要知识，并采用优化技术和方法。
- en: 'By accelerating the training process, you can concentrate on what really matters:
    building stunning models!'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 通过加速训练过程，你可以专注于真正重要的事情：构建令人惊叹的模型！
- en: Who this book is for
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本书适合谁
- en: This book is for intermediate-level data scientists, engineers, and developers
    who want to know how to use PyTorch to accelerate the training process of their
    machine learning models. Although they are not the primary audience for this material,
    system analysts responsible for administrating and providing infrastructure for
    AI workloads will also find valuable information in this book.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本书适合中级数据科学家、工程师和开发人员，他们希望了解如何使用PyTorch加速他们的机器学习模型的训练过程。尽管他们不是本材料的主要受众，负责管理和提供AI工作负载基础设施的系统分析师也会在本书中找到有价值的信息。
- en: Basic knowledge of machine learning, PyTorch, and Python is required to get
    the most out of this material. However, there is no obligation to have a prior
    understanding of distributed computing, accelerators, or multicore processors.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 要充分利用本材料，需要具备机器学习、PyTorch和Python的基础知识。然而，并不要求具备分布式计算、加速器或多核处理器的先前理解。
- en: What this book covers
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本书内容涵盖了什么
- en: '[*Chapter 1*](B20959_01.xhtml#_idTextAnchor016), *Deconstructing the Training
    Process*, provides an overview of how the training process works under the hood,
    describing the training algorithm and covering the phases executed by this process.
    This chapter also explains how factors such as hyperparameters, operations, and
    neural network parameters impact the training process’s computational burden.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第1章*](B20959_01.xhtml#_idTextAnchor016)，*分解训练过程*，提供了训练过程在底层如何工作的概述，描述了训练算法并涵盖了该过程执行的阶段。本章还解释了超参数、操作和神经网络参数等因素如何影响训练过程的计算负担。'
- en: '[*Chapter 2*](B20959_02.xhtml#_idTextAnchor028), *Training Models Faster*,
    provides an overview of the possible approaches to accelerate the training process.
    This chapter discusses how to modify the application and environment layers of
    the software stack to reduce the training time. Moreover, it explains vertical
    and horizontal scalability as another option to improve performance by increasing
    the number of resources.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第二章*](B20959_02.xhtml#_idTextAnchor028)，*加速训练模型*，提供了加速训练过程可能的方法概述。本章讨论了如何修改软件堆栈的应用和环境层以减少训练时间。此外，它还解释了通过增加资源数量来提高性能的垂直和水平可伸缩性作为另一选项。'
- en: '[*Chapter 3*](B20959_03.xhtml#_idTextAnchor044), *Compiling the Model*, provides
    an overview of the novel Compile API introduced on PyTorch 2.0\. This chapter
    covers the differences between eager and graph modes and describes how to use
    the Compile API to accelerate the model-building process. This chapter also explains
    the compiling workflow and components involved in the compiling process.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第三章*](B20959_03.xhtml#_idTextAnchor044)，*编译模型*，提供了PyTorch 2.0引入的新型编译API的概述。本章涵盖了急切模式和图模式之间的区别，并描述了如何使用编译API加速模型构建过程。此外，本章还解释了编译工作流程及涉及编译过程的各个组件。'
- en: '[*Chapter 4*](B20959_04.xhtml#_idTextAnchor060), *Using Specialized Libraries*,
    provides an overview of the libraries used by PyTorch to execute specialized tasks.
    This chapter describes how to install and configure OpenMP to deal with multithreading
    and IPEX to optimize the training process on an Intel CPU.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第四章*](B20959_04.xhtml#_idTextAnchor060)，*使用专用库*，提供了PyTorch用于执行专门任务的库的概述。本章描述了如何安装和配置OpenMP来处理多线程和IPEX以优化在Intel
    CPU上的训练过程。'
- en: '[*Chapter 5*](B20959_05.xhtml#_idTextAnchor072), *Building an Efficient Data
    Pipeline*, provides an overview of how to build an efficient data pipeline to
    keep the GPU working as much as possible. Besides explaining the steps executed
    on the data pipeline, this chapter describes how to accelerate the data-loading
    process by optimizing GPU data transfer and increasing the number of workers on
    the data pipeline.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第五章*](B20959_05.xhtml#_idTextAnchor072)，*构建高效数据管道*，提供了如何构建高效数据管道以使GPU尽可能长时间工作的概述。除了解释数据管道上执行的步骤外，本章还描述了如何通过优化GPU数据传输并增加数据管道中的工作进程数来加速数据加载过程。'
- en: '[*Chapter 6*](B20959_06.xhtml#_idTextAnchor085), *Simplifying the Model*, provides
    an overview of how to simplify a model by reducing the number of parameters of
    the neural network without sacrificing the model’s quality. This chapter describes
    techniques used to reduce the model complexity, such as model pruning and compression,
    and explains how to use the Microsoft NNI toolkit to simplify a model easily.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第六章*](B20959_06.xhtml#_idTextAnchor085)，*简化模型*，提供了如何通过减少神经网络参数的数量来简化模型而不牺牲模型质量的概述。本章描述了用于减少模型复杂性的技术，如模型修剪和压缩，并解释了如何使用Microsoft
    NNI工具包轻松简化模型。'
- en: '[*Chapter 7*](B20959_07.xhtml#_idTextAnchor098), *Adopting Mixed Precision*,
    provides an overview of how to adopt a mixed precision strategy to burst the model
    training process without penalizing the model’s accuracy. This chapter briefly
    explains numeric representation in computer systems and describes how to employ
    PyTorch’s automatic mixed precision approach.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第七章*](B20959_07.xhtml#_idTextAnchor098)，*采用混合精度*，提供了如何采用混合精度策略来加速模型训练过程而不影响模型准确性的概述。本章简要解释了计算机系统中的数值表示，并描述了如何使用PyTorch的自动混合精度方法。'
- en: '[*Chapter 8*](B20959_08.xhtml#_idTextAnchor117), *Distributed Training at a
    Glance*, provides an overview of the basic concepts of distributed training. This
    chapter presents the most adopted parallel strategies and describes the basic
    workflow to implement distributed training on PyTorch.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第八章*](B20959_08.xhtml#_idTextAnchor117)，*一瞥分布式训练*，提供了分布式训练基本概念的概述。本章介绍了最常用的并行策略，并描述了在PyTorch上实施分布式训练的基本工作流程。'
- en: '[*Chapter 9*](B20959_09.xhtml#_idTextAnchor132), *Training with Multiple CPUs*,
    provides an overview of how to code and execute distributed training in multiple
    CPUs on a single machine using a general approach and Intel oneCCL to optimize
    the execution on Intel platforms.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第九章*](B20959_09.xhtml#_idTextAnchor132)，*多CPU训练*，提供了如何在单台机器上使用通用方法和Intel
    oneCCL来编写和执行多CPU分布式训练的概述。'
- en: '[*Chapter 10*](B20959_10.xhtml#_idTextAnchor149), *Training with Multiple GPUs*,
    provides an overview of how to code and execute distributed training in a multi-GPU
    environment on a single machine. This chapter presents the main characteristics
    of a multi-GPU environment and explains how to code and launch distributed training
    on multiple GPUs using NCCL, the default communication backend for NVIDIA GPUs.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第10章*](B20959_10.xhtml#_idTextAnchor149)，*使用多个GPU进行训练*，提供了如何在单台机器的多GPU环境中编码和执行分布式训练的概述。本章介绍了多GPU环境的主要特征，并解释了如何使用NCCL在多个GPU上编码和启动分布式训练，NCCL是NVIDIA
    GPU的默认通信后端。'
- en: '[*Chapter 11*](B20959_11.xhtml#_idTextAnchor167), *Training with Multiple Machines*,
    provides an overview of how to code and execute distributed training in multiple
    GPUs on multiple machines. Besides an introductory explanation of computing clusters,
    this chapter shows how to code and launch distributed training among multiple
    machines using Open MPI as the launcher and NCCL as the communication backend.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第11章*](B20959_11.xhtml#_idTextAnchor167)，*使用多台机器进行训练*，提供了如何在多个GPU和多台机器上进行分布式训练的概述。除了对计算集群的简介解释外，本章还展示了如何使用Open
    MPI作为启动器和NCCL作为通信后端，在多台机器之间编码和启动分布式训练。'
- en: To get the most out of this book
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 要充分利用本书
- en: You will need to have an understanding of the basics of machine learning, PyTorch,
    and Python.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要了解机器学习、PyTorch和Python的基础知识。
- en: '| **Software/hardware covered in** **the book** | **Operating** **system requirements**
    |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| **书中涵盖的软件/硬件** | **操作系统要求** |'
- en: '| PyTorch 2.X | Windows, Linux, or macOS |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| PyTorch 2.X | Windows、Linux或macOS |'
- en: If you are using the digital version of this book, we advise you to type the
    code yourself or access the code from the book’s GitHub repository (a link is
    available in the next section). Doing so will help you avoid any potential errors
    related to the copying and pasting of code.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您使用本书的数字版本，建议您自己键入代码或者从本书的GitHub存储库中获取代码（下一节提供链接）。这样做将有助于避免与复制粘贴代码相关的任何潜在错误。
- en: Download the example code files
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 下载示例代码文件
- en: You can download the example code files for this book from GitHub at [https://github.com/PacktPublishing/Accelerate-Model-Training-with-PyTorch-2.X](https://github.com/PacktPublishing/Accelerate-Model-Training-with-PyTorch-2.X).
    If there’s an update to the code, it will be updated in the GitHub repository.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从GitHub下载本书的示例代码文件，网址为[https://github.com/PacktPublishing/Accelerate-Model-Training-with-PyTorch-2.X](https://github.com/PacktPublishing/Accelerate-Model-Training-with-PyTorch-2.X)。如果代码有更新，将在GitHub存储库中更新。
- en: We also have other code bundles from our rich catalog of books and videos available
    at [https://github.com/PacktPublishing/](https://github.com/PacktPublishing/).
    Check them out!
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还提供其他来自我们丰富书籍和视频目录的代码包，请查阅[https://github.com/PacktPublishing/](https://github.com/PacktPublishing/)。
- en: Conventions used
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用的约定
- en: There are a number of text conventions used throughout this book.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中使用了许多文本约定。
- en: '`Code in text`: Indicates code words in text, database table names, folder
    names, filenames, file extensions, pathnames, dummy URLs, user input, and Twitter
    handles. Here is an example: “The `ipex.optimize` function returns an optimized
    version of the model.”'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '`文本中的代码`：表示文本中的代码字词、数据库表名、文件夹名、文件名、文件扩展名、路径名、虚拟URL、用户输入和Twitter句柄。以下是一个例子：“`ipex.optimize`函数返回模型的优化版本。”'
- en: 'A block of code is set as follows:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 代码块设置如下：
- en: '[PRE0]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'When we wish to draw your attention to a particular part of a code block, the
    relevant lines or items are set in bold:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们希望引起您对代码块特定部分的注意时，相关行或项目以粗体显示：
- en: '[PRE1]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Any command-line input or output is written as follows:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 任何命令行输入或输出如下所示：
- en: '[PRE2]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '**Bold**: Indicates a new term, an important word, or words that you see onscreen.
    For instance, words in menus or dialog boxes appear in **bold**. Here is an example:
    “**OpenMP** is a library used for parallelizing tasks by harnessing all the power
    of multicore processors by using the multithreading technique.”'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**粗体**：表示一个新术语、一个重要单词或者在屏幕上显示的单词。例如，菜单或对话框中的单词会以**粗体**显示。以下是一个例子：“**OpenMP**是一个库，用于通过使用多线程技术利用多核处理器的全部性能来并行化任务。”'
- en: Tips or important notes
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 提示或重要注释
- en: Appear like this.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 像这样显示。
- en: Get in touch
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 联系我们
- en: Feedback from our readers is always welcome.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们随时欢迎读者的反馈。
- en: '**General feedback**: If you have questions about any aspect of this book,
    email us at [customercare@packtpub.com](mailto:customercare@packtpub.com) and
    mention the book title in the subject of your message.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '**总体反馈**：如果您对本书的任何方面有疑问，请发送电子邮件至[customercare@packtpub.com](mailto:customercare@packtpub.com)，并在邮件主题中提及书名。'
- en: '**Errata**: Although we have taken every care to ensure the accuracy of our
    content, mistakes do happen. If you have found a mistake in this book, we would
    be grateful if you would report this to us. Please visit [www.packtpub.com/support/errata](http://www.packtpub.com/support/errata)
    and fill in the form.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**勘误**：尽管我们已经尽最大努力确保内容的准确性，但错误不可避免。如果您在本书中发现错误，我们将不胜感激您向我们报告。请访问[www.packtpub.com/support/errata](http://www.packtpub.com/support/errata)并填写表格。'
- en: '**Piracy**: If you come across any illegal copies of our works in any form
    on the internet, we would be grateful if you would provide us with the location
    address or website name. Please contact us at [copyright@packt.com](mailto:copyright@packt.com)
    with a link to the material.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**盗版**：如果您在互联网上发现我们作品的任何形式的非法拷贝，请向我们提供位置地址或网站名称。请通过[copyright@packt.com](mailto:copyright@packt.com)与我们联系，并提供链接至该材料的链接。'
- en: '**If you are interested in becoming an author**: If there is a topic that you
    have expertise in and you are interested in either writing or contributing to
    a book, please visit [authors.packtpub.com](http://authors.packtpub.com).'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '**如果您有兴趣成为作者**：如果您在某个专题上有专业知识，并且有意撰写或为一本书作贡献，请访问[authors.packtpub.com](http://authors.packtpub.com)。'
- en: Share Your Thoughts
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分享您的想法
- en: Once you’ve read *Accelerate Model Training with PyTorch 2.X*, we’d love to
    hear your thoughts! Please [click here to go straight to the Amazon review page](https://packt.link/r/1-805-12010-7)
    for this book and share your feedback.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您阅读了*Accelerate Model Training with PyTorch 2.X*，我们很想听听您的想法！请[点击此处直接访问亚马逊评论页面](https://packt.link/r/1-805-12010-7)并分享您的反馈。
- en: Your review is important to us and the tech community and will help us make
    sure we’re delivering excellent quality content.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 您的评论对我们和技术社区都很重要，将帮助我们确保我们提供的内容质量优秀。
- en: Download a free PDF copy of this book
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 下载本书的免费PDF副本
- en: Thanks for purchasing this book!
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢您购买本书！
- en: Do you like to read on the go but are unable to carry your print books everywhere?
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 您喜欢随时随地阅读，但无法随身携带印刷书籍吗？
- en: Is your eBook purchase not compatible with the device of your choice?
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 您的电子书购买是否与您选择的设备兼容？
- en: Don’t worry, now with every Packt book you get a DRM-free PDF version of that
    book at no cost.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 别担心，现在每本Packt图书您都可以免费获取一个无DRM的PDF版本。
- en: Read anywhere, any place, on any device. Search, copy, and paste code from your
    favorite technical books directly into your application.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 随时随地、任何地点、任何设备阅读。直接从您喜爱的技术书籍中搜索、复制和粘贴代码到您的应用程序中。
- en: The perks don’t stop there, you can get exclusive access to discounts, newsletters,
    and great free content in your inbox daily
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这些好处并不止于此，您还可以独家获取折扣、新闻通讯和每天收到的优质免费内容
- en: 'Follow these simple steps to get the benefits:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 遵循以下简单步骤获取这些好处：
- en: Scan the QR code or visit the link below
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 扫描下方的二维码或访问以下链接
- en: '![](img/B20959_QR_Free_PDF.jpg)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B20959_QR_Free_PDF.jpg)'
- en: '[https://packt.link/free-ebook/978-1-80512-010-0](https://packt.link/free-ebook/978-1-80512-010-0)'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.link/free-ebook/978-1-80512-010-0](https://packt.link/free-ebook/978-1-80512-010-0)'
- en: Submit your proof of purchase
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提交您的购书证明
- en: That’s it! We’ll send your free PDF and other benefits to your email directly
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 就是这样！我们将免费的PDF文件和其他好处直接发送到您的电子邮件中
