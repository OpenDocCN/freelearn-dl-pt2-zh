- en: Setting Up the IoT and AI Environment
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: 设置IoT和AI环境
- en: The **Internet of Things** (**IoT**) and **artificial intelligence** (**AI**)
    are leading to a dramatic impact on people's lives. Industries such as medicine
    are being revolutionized by wearable sensors that can monitor patients after they
    leave the hospital. **Machine learning** (**ML**) used on industrial devices is
    leading to better monitoring and less downtime with techniques such as anomaly
    detection, predictive maintenance, and prescriptive actions.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '**物联网**（**IoT**）和**人工智能**（**AI**）正在对人们的生活产生重大影响。像医疗这样的行业正在通过可穿戴传感器的革命性进展来监测病人出院后的情况。在工业设备上使用的**机器学习**（**ML**）通过异常检测、预测性维护和指导性行动等技术，实现了更好的监控和更少的停机时间。'
- en: Building an IoT device capable of delivering results relies on gathering the
    right information. This book gives recipes that support the end-to-end IoT/ML life
    cycle. The next chapter has recipes for making sure that devices have the right
    sensors and the data is the best it can be for ML outcomes. Tools such as explanatory
    factor analysis and data collection design are used.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 构建能够提供结果的IoT设备依赖于收集正确信息。本书提供支持端到端IoT/ML生命周期的配方。下一章提供了确保设备配备正确传感器和数据最佳化以支持ML结果的配方。工具如解释性因子分析和数据收集设计被广泛使用。
- en: 'This chapter will cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Choosing a device
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Choosing a device
- en: Setting up Databricks
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置Databricks
- en: 'The following recipes will be covered:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 将涵盖以下配方：
- en: Setting up IoT Hub
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置IoT Hub
- en: Setting up an IoT Edge device
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置IoT Edge设备
- en: Deploying ML modules to Edge devices
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将ML模块部署到Edge设备
- en: Setting up Kafka
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置Kafka
- en: Installing ML libraries on Databricks
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Databricks上安装ML库
- en: Choosing a device
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Choosing a device
- en: Before starting with the classic recipe-by-recipe formatting of a cookbook,
    we'll start by covering a couple of base topics. Choosing the right hardware sets
    the stage for AI. Working with IoT means working with constraints. Using ML in
    the cloud is often a cost-effective solution as long as the data is small. Image,
    video, and sound data will often bog down networks. Worse yet, if you are using
    a cellular network, it can be highly expensive. The adage *there is no money in
    hardware* refers to the fact that most of the money made from IoT comes from the
    selling of services, not from producing expensive devices.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始经典的食谱格式化烹饪书之前，我们将从涵盖几个基础主题开始。选择合适的硬件为AI铺平道路。在IoT中工作意味着要处理各种限制。在云端使用ML通常是一种经济高效的解决方案，只要数据量不大。图像、视频和音频数据通常会拖慢网络速度。更糟的是，如果使用蜂窝网络，成本可能会非常高昂。谚语*在硬件上没有钱*指的是大多数IoT赚钱来自销售服务，而不是生产昂贵设备。
- en: Dev kits
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Dev kits
- en: 'Often, companies have their devices designed by electrical engineers. This
    is a cost-effective option. Custom boards do not have extra components, such as
    unnecessary Bluetooth or extra USB ports. However, predicting CPU and RAM requirements
    of an ML model at board design time is difficult. Starter kits can be useful tools
    to use until the hardware requirements are understood. The following boards are
    among the most widely adopted boards on the market:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，公司会让电气工程师设计他们的设备，这是一种经济高效的选择。定制板不会有额外的组件，比如不必要的蓝牙或额外的USB端口。然而，在板设计时预测ML模型的CPU和RAM需求是困难的。入门套件可以是在了解硬件需求之前使用的有用工具。以下板块是市场上被广泛采用的：
- en: Manifold 2-C with NVIDIA TX2
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Manifold 2-C与NVIDIA TX2
- en: The i.MX series
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: i.MX系列
- en: LattePanda
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LattePanda
- en: Raspberry Pi Class
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 树莓派类
- en: Arduino
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Arduino
- en: ESP8266
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ESP8266
- en: They are often used as a scale of functionality. A Raspberry Pi Class device,
    for example, would struggle with custom vision applications but would do great
    for audio or general ML applications. One determining factor for many data scientists
    is the programming language. The ESP8266 and Arduino need to be programmed in
    a low-level language such as C or C++, while devices such as Raspberry Pi Class
    or above can be programmed in any language.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 它们通常被用作功能的标尺。例如，树莓派类设备在自定义视觉应用方面可能会有些吃力，但在音频或通用ML应用方面表现良好。许多数据科学家的一个决定性因素是编程语言。ESP8266和Arduino需要用低级语言如C或C++进行编程，而像树莓派类及以上的设备可以使用任何语言。
- en: Different devices come at different prices and functionalities. Devices that
    are Raspberry Pi Class or above can handle ML running on the Edge, reducing cloud
    cost but increasing the cost of the device. Deciding on whether you are billing
    your customers with a one-time price for the device or a subscription model may
    help you determine what type of device you need.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 不同的设备具有不同的价格和功能。类似树莓派或更高级别的设备可以处理边缘ML运行，减少云成本但增加设备成本。决定是对设备收取一次性价格还是订阅模式可能有助于确定需要的设备类型。
- en: Manifold 2-C with NVIDIA TX2
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Manifold 2-C with NVIDIA TX2
- en: 'The NVIDIA Jetson is one of the best choices for running complex ML models
    such as real-time video on the Edge. The NVIDIA Jetson comes with a built-in NVIDIA
    GPU. The Manifold version of the product is designed to fit onto a DJI drone and
    perform tasks such as image recognition or self-flying. The only downside to running
    NVIDIA Jetson is its use of the ARM64 architecture. ARM64 does not work well with
    TensorFlow, although other libraries such as PyTorch work fine on ARM64\. The
    Manifold retails for $500, which makes it a high-price option, but this is often
    necessary when doing real-time ML on the Edge:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: NVIDIA Jetson是运行复杂ML模型（如边缘实时视频）的最佳选择之一。NVIDIA Jetson配备内置的NVIDIA GPU。该产品的Manifold版本设计用于安装在DJI无人机上，并执行图像识别或自主飞行等任务。运行NVIDIA
    Jetson的唯一不利之处是其使用的ARM64架构。ARM64在TensorFlow上表现不佳，尽管其他库如PyTorch在ARM64上运行良好。Manifold的零售价为$500，这使其成为高价位选择，但在边缘实时ML方面通常是必要的：
- en: '| **Price** | **Typical Models** | **Use Cases** |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| **价格** | **典型模型** | **使用案例** |'
- en: '| $500 | Re-enforcement learning, computer vision | Self-flying drones, robotics
    |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| $500 | 强化学习，计算机视觉 | 自主飞行无人机，机器人技术 |'
- en: '**The i.MX series**'
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**i.MX系列**'
- en: 'The i.MX series of chips is open source and boasts impressive RAM and CPU capabilities.
    The open design helps engineers build boards easily. The i.MX series uses Freescale
    semiconductors. Freescale semiconductors have guaranteed production life runs
    of 10 through 15 years, which means the board design will be stable for years.
    The i.MX 6 can range from $200 to $300 in cost and can handle CPU-intensive tasks
    easily, such as object recognition in live streaming video:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: i.MX系列芯片是开源的，具有强大的RAM和CPU能力。开放设计有助于工程师轻松构建板卡。i.MX系列使用Freescale半导体。Freescale半导体保证10到15年的生产周期，这意味着板卡设计在未来数年内将保持稳定。i.MX
    6的成本可在$200到$300之间，并且可以轻松处理CPU密集型任务，例如实时流视频中的目标识别：
- en: '| **Price** | **Typical Models** | **Use Cases** |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| **价格** | **典型模型** | **使用案例** |'
- en: '| $200+ | Computer vision, NLP | Sentiment analysis, face recognition, object
    recognition, voice recognition |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| $200+ | 计算机视觉，自然语言处理 | 情感分析，人脸识别，物体识别，语音识别 |'
- en: '**LattePanda **'
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**LattePanda**'
- en: '**Single Board Computers** (**SBCs**) such as the LattePanda are capable of
    running heavy sensor workloads. These devices can often run Windows or Linux.
    Like the i.MX series, they are capable of running object recognition on the device;
    however, the frame rate for recognizing objects can be slow:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**单板计算机**（**SBCs**）如LattePanda能够运行大量传感器工作负载。这些设备通常可以运行Windows或Linux。像i.MX系列一样，它们能够在设备上运行目标识别；然而，识别对象的帧率可能较慢：'
- en: '| **Price** | **Typical Models** | **Use Cases** |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| **价格** | **典型模型** | **使用案例** |'
- en: '| $100+ | Face detection, voice recognition, high-speed Edge models | Audio-enabled
    kiosk, high-frequency heart monitoring  |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| $100+ | 人脸检测，语音识别，高速边缘模型 | 启用音频的信息亭，高频率心脏监测 |'
- en: '**Raspberry Pi Class**'
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**树莓派类型**'
- en: 'Raspberry Pis are a standard starter kit for IoT. With their $35 price tag,
    they give you a lot of capability for the cost: they can run ML on the Edge with
    containers. They have a Linux or IoT Core operating system, which allows the easy
    plugging and playing of components and a community of developers building similar
    platform tools. Although Raspberry Pi Class devices are capable of handling most
    ML tasks, they tend to have performance issues on some of the more intensive tasks,
    such as video recognition:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 树莓派是物联网的标准入门套件。以$35的价格标签，它们为成本提供了很多功能：它们可以在边缘上通过容器运行ML。它们具有Linux或IoT Core操作系统，可以轻松插拔组件，并有开发者社区构建类似的平台工具。尽管树莓派类型设备能够处理大多数ML任务，但在某些更具挑战性的任务（如视频识别）上可能存在性能问题：
- en: '| **Price** | **Typical Models** | **Use Cases** |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| **价格** | **典型模型** | **使用案例** |'
- en: '| $35 | Decision trees, artificial neural networks, anomaly detection | Smart
    home, industrial IoT |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| $35 | 决策树，人工神经网络，异常检测 | 智能家居，工业物联网 |'
- en: '**Arduino**'
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**Arduino**'
- en: 'At $15, the Arduino is a cost-effective solution. Arduino is supported by a
    large community and uses the Arduino language, a set of C/C++ functions. If you
    need to run ML models on an Arduino device, it is possible to package ML models
    built on popular frameworks such as PyTorch into the **Embedded Learning Library**
    (**ELL**). The ELL allows ML models to be deployed on the device without needing
    the overhead of a large operating system. Porting ML models using ELL or TensorFlow
    Lite can be challenging due to the limited memory and compute capacity of the
    Arduino:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在$15处，Arduino是一种经济实惠的解决方案。Arduino得到了大型社区的支持，使用Arduino语言，一组C/C++函数。如果需要在Arduino设备上运行ML模型，则可以将建立在诸如PyTorch等流行框架上的ML模型打包到**嵌入式学习库**（**ELL**）中。ELL允许在设备上部署ML模型，而无需大型操作系统的开销。由于Arduino的内存和计算能力有限，使用ELL或TensorFlow
    Lite移植ML模型可能具有挑战性：
- en: '| **Price** | **Typical Models** | **Use Cases** |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| **价格** | **典型模型** | **使用案例** |'
- en: '| $15 | Linear regression | Sensor reading classification |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| $15 | 线性回归 | 传感器读数分类 |'
- en: '**ESP8266 **'
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**ESP8266**'
- en: 'At under $5, devices such as the ESP8266 and smaller represent a class of devices
    that take data in and transmit it to the cloud for ML evaluations. Besides being
    inexpensive, they are also often low-power devices, so they can be powered by
    solar power, network power, or a long-life battery:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在低于$5的情况下，诸如ESP8266和更小的设备代表了一类设备，它们接收数据并将其传输到云端进行ML评估。除了价格低廉外，它们通常也是低功耗设备，因此可以通过太阳能、网络电源或长寿命电池供电：
- en: '| **Price** | **Typical Models** | **Use Cases** |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| **价格** | **典型模型** | **使用案例** |'
- en: '| $5 or below | In the cloud only | In the cloud only |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| $5或更低 | 仅在云中 | 仅在云中 |'
- en: Setting up Databricks
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置Databricks
- en: Processing large amounts of data is not possible on a single computer. That
    is where distributed systems such as Spark (made by Databricks) come in. Spark
    allows you to parallelize large workloads over many computers.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在单台计算机上处理大量数据是不可能的。这就是像Spark（由Databricks制作）这样的分布式系统的用武之地。Spark允许您在许多计算机上并行处理大量工作负载。
- en: 'Spark was developed to help solve the **Netflix Prize**, which had a $1 million
    prize for the team that made the best recommendation engine. Spark uses distributed
    computing to wrangle large and complex datasets. There are distributed Python
    equivalent libraries, such as Koalas, which is a distributed equivalent of pandas.
    Spark also supports analytics and feature engineering that requires a large amount
    of compute and memory, such as graph theory problems. Spark has two modes: a batch
    mode for training large datasets and a streaming mode for scoring data in near
    real time.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: Spark的开发是为了帮助解决**Netflix Prize**，该奖项为开发最佳推荐引擎的团队提供了100万美元的奖金。Spark使用分布式计算来处理大型和复杂的数据集。还有分布式Python等效库，如Koalas，它是pandas的分布式等效版本。Spark还支持需要大量计算和内存的分析和特征工程，如图理论问题。Spark有两种模式：用于训练大型数据集的批处理模式和用于几乎实时评分数据的流处理模式。
- en: IoT data tends to be large and imbalanced. A device may have 10 years of data
    showing it is running in normal conditions and only a few records showing it needs
    to be shut down immediately to prevent damage. The value of Databricks in IoT
    is twofold. The first is working with data and training models. Working with data
    at the terabyte and petabyte scale can overwhelm a single machine. Databricks
    solves this with its ability to scale out. The second is its streaming capabilities.
    ML models can be run in the cloud in near real time. Messages can then be pushed
    back down to the device.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: IoT数据通常是庞大且不平衡的。设备可能有10年的数据表明它在正常条件下运行，只有少数记录表明需要立即关闭以防止损坏。Databricks在IoT中的价值是双重的。首先是处理数据和训练模型。在TB和PB级别上处理数据可能会超出单个机器的能力。Databricks通过其可扩展性来解决这个问题。其次是其流处理能力。ML模型可以在云中几乎实时地运行。然后可以将消息推送回设备。
- en: Setting up Databricks is fairly straightforward. You can either go to your cloud
    provider and sign up for an account in the portal or sign up for the free community
    edition. If you are taking your product to production, then you should definitely
    sign up with Azure, AWS, or Google Cloud.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 设置Databricks非常简单。您可以访问您的云服务提供商，在门户中注册帐户或注册免费社区版。如果您要将产品投入生产，则应该选择Azure、AWS或Google
    Cloud。
- en: IoT and ML are fundamentally a big data problem. A device may send telemetry
    for years before it sends telemetry that would indicate an issue with the device.
    Searching through millions or billions of records to find the few records that
    are needed can be challenging from a data management perspective. Therefore, optimal
    data storage is key.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: IoT 和 ML 从根本上讲是一个大数据问题。设备可能在数年间发送遥测数据，直到发送表明设备存在问题的遥测数据为止。从数据管理的角度来看，搜索数百万或数十亿条记录以找到所需的少数记录可能是具有挑战性的。因此，优化的数据存储是关键。
- en: Storing data
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 存储数据
- en: Today, there are tools that make it easy to work with large amounts of data.
    There are a few things to remember though. There are optimal ways of storing data
    at scale that can make dealing with large datasets easier.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 如今有一些工具可以帮助处理大量数据变得更加容易。但需要记住几件事情。有一些优化的数据存储方式可以使处理大数据集更加容易。
- en: Working with data, the type of large datasets that come from IoT devices can
    be prohibitively expensive for many companies. Storing data in Delta Lake, for
    example, can give the user a 340-times performance boost over accessing the data
    over JSON. The next three sections will introduce three storage methods that can
    cut down a data analytics job from weeks to hours.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 处理数据时，来自 IoT 设备的大型数据集类型可能对许多公司来说成本过高。例如，将数据存储在 Delta Lake 中可以比通过 JSON 访问数据提供
    340 倍的性能提升。接下来的三节将介绍三种可以将数据分析工作从数周缩短到数小时的存储方法。
- en: Parquet
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Parquet
- en: Parquet is one of the most common file formats in big data. Parquet's columnar
    storage format allows it to store highly compressed data. Its advantage is that
    it takes up less space on the hard disk and takes up less network bandwidth, making
    it ideal for loading into a DataFrame. Parquet ingestion into Spark has been benchmarked
    at 34 times the speed of JSON.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: Parquet 是大数据中最常见的文件格式之一。Parquet 的列式存储格式使其能够存储高度压缩的数据。其优势在于占用硬盘空间少，网络带宽消耗小，非常适合加载到
    DataFrame 中。Parquet 在 Spark 中的数据导入速度比 JSON 快 34 倍。
- en: Avro
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Avro
- en: The Avro format is a popular storage format for IoT. While it does not have
    the high compression ratio that Parquet does, it is less compute expensive to
    store data because it uses a row-level data storage schema. Avro is a common format
    for streaming data such as IoT Hub or Kafka.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: Avro 格式是 IoT 中常用的存储格式。虽然它没有 Parquet 那样的高压缩比，但由于使用了行级数据存储模式，存储数据的计算成本较低。Avro
    是流数据（如 IoT Hub 或 Kafka）的常见格式。
- en: Delta Lake
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Delta Lake
- en: Delta Lake is an open source project released by Databricks in 2019\. It stores
    files in Parquet. In addition, it is able to keep track of data check-ins, enabling
    the data scientist to look at data as it existed at a given time. This can be
    useful when trying to determine why accuracy in a particular ML model drifted.
    It also keeps metadata about the data, giving it a 10-times performance increase
    over standard Parquet for analytics workloads.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: Delta Lake 是由 Databricks 在 2019 年发布的开源项目。它将文件存储在 Parquet 中。此外，它还能够跟踪数据的检入，使数据科学家能够查看特定时间点的数据。这在尝试确定特定
    ML 模型精度下降原因时非常有用。它还保存有关数据的元数据，使其在分析工作负载中比标准 Parquet 提供 10 倍的性能提升。
- en: While considerations are given to both choosing a device and setting up Databricks,
    the rest of this chapter will follow a modular, recipe-based format.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然在选择设备和设置 Databricks 时都需要考虑，但本章的其余部分将采用模块化、基于配方的格式。
- en: Setting up IoT Hub
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置 IoT Hub
- en: Developing IoT solutions can be complicated. There are many issues to deal with,
    such as ML, Edge deployments, security, monitoring device state, and ingesting
    telemetry in the cloud. Cloud providers such as Azure provide a ready-made solution
    that can have components such as data storage and cloud-to-device messages built
    in.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 开发 IoT 解决方案可能会很复杂。需要处理的问题包括 ML、边缘部署、安全性、监控设备状态以及云中遥测数据的摄取等。云服务提供商（如 Azure）提供了一个现成的解决方案，其中可能包括数据存储和云到设备消息等组件。
- en: In this recipe, we are going to set up IoT Hub in Azure for an IoT Edge device
    that will be doing ML calculations on the Edge.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在本配方中，我们将在 Azure 中为 IoT Edge 设备设置 IoT Hub，该设备将在边缘上进行 ML 计算。
- en: Getting ready
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: Before using IoT Hub, you need to have a device and an Azure subscription. There
    is a free trial subscription available if you do not already have one. You will
    also need some sort of device.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用 IoT Hub 之前，您需要拥有一个设备和一个 Azure 订阅。如果您还没有订阅，可以使用免费试用订阅。您还需要某种类型的设备。
- en: How to do it...
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做…
- en: 'To set up IoT Hub, the first thing you will need is a resource group. Resource
    groups are like folders on Windows or macOS. They allow you to place all of the
    resources for a particular project in the same location. The resource groups icon
    is in the Favorites menu in the left panel of the Azure portal:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 要设置 IoT Hub，首先需要一个资源组。资源组类似于 Windows 或 macOS 上的文件夹。它们允许您将特定项目的所有资源放置在同一位置。资源组图标位于
    Azure 门户左侧面板的收藏夹菜单中：
- en: '![](img/d9a7380d-b380-4781-80fc-e449e6630727.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d9a7380d-b380-4781-80fc-e449e6630727.png)'
- en: 'The following is what we need to do:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 需要执行以下操作：
- en: Select **Create a resource**. From there, the wizard will take you through the
    steps to create a resource group.
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择 **创建资源**。然后，向导将指导您完成创建资源组的步骤。
- en: Then, click on the **+** icon at the top to create an IoT Hub instance.
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，点击顶部的 **+** 图标创建 IoT Hub 实例。
- en: In the search box, type in `IoT Hub`. The wizard will take you through how to
    set up IoT Hub.
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在搜索框中键入 `IoT Hub`。然后，向导将指导您如何设置 IoT Hub。
- en: One important thing to note on the Scale page is you will want to select the S1
    or higher pricing tier. The S1 tier gives you bidirectional communication with
    the device and also enables you to use advanced features such as dice twins and
    the ability to push ML models to Edge devices.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在规模页面上需要注意的一点是，您需要选择 S1 或更高的定价层。S1 层使您可以与设备进行双向通信，并且还能使用高级功能，例如设备双和将 ML 模型推送到边缘设备的能力。
- en: How it works...
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理...
- en: IoT Hub is a platform developed specifically for IoT. Issues that affect IoT,
    such as unreliable communication, are handled through mechanisms such as **Advanced
    Message Queuing Protocol** (**AMQP**) and **Message Queuing Telemetry Transport**
    (**MQTT**). IoT Hub has a rich ecosystem of tools to help IoT developers, such
    as device twins, cloud-to-device messages, a device security center, Kubernetes
    integration, and a marketplace for Edge modules.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: IoT Hub 是专为 IoT 开发的平台。解决影响 IoT 的问题，例如不可靠的通信，通过诸如**高级消息队列协议**（**AMQP**）和**消息队列遥测传输**（**MQTT**）等机制进行处理。IoT
    Hub 拥有丰富的工具生态系统，可帮助 IoT 开发人员，如设备双生，云到设备消息，设备安全中心，Kubernetes 集成以及边缘模块市场。
- en: Setting up an IoT Edge device
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置 IoT Edge 设备
- en: In this recipe, we're going to set up an IoT Edge device that can communicate
    with IoT Hub and also receive new ML containers that it can use to perform ML
    evaluations on the device.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在本示例中，我们将设置一个能够与 IoT Hub 通信并接收新的 ML 容器的 IoT Edge 设备，以便在设备上执行 ML 评估。
- en: IoT Edge devices have advantages over traditional IoT devices. The main advantage
    is their ability to update **over the air** (**OTA**). By using containers, models
    can be deployed easily without having to worry about bricking the device.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: IoT Edge 设备比传统 IoT 设备有优势。主要优势在于它们能够通过**空中更新**（**OTA**）进行更新。通过使用容器，可以轻松部署模型，而无需担心设备砖化的问题。
- en: Getting ready
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: Before you create an IoT Edge device, make sure that your device is supported
    by IoT Edge. Some device architectures, such as ARM64, are not. Next, make sure
    your IoT Hub instance from the previous recipe is up and running. The IoT Edge
    runtime must be installed on your device. For the sake of this tutorial, we will
    assume that the user has a Raspberry Pi Class device.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建 IoT Edge 设备之前，请确保您的设备受 IoT Edge 支持。某些设备架构（例如 ARM64）不受支持。接下来，请确保您在前一个示例中的
    IoT Hub 实例正在运行。必须在设备上安装 IoT Edge 运行时。为了本教程的目的，我们将假设用户有一个 Raspberry Pi Class 设备。
- en: How to do it...
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: To set up an IoT Edge device, you will need to set up both the cloud and device
    side. The IoT device needs a place in the cloud to send its information. This
    recipe has two parts. The first part is configuring the IoT Edge device in IoT
    Hub. The second is configuring the device to talk to the cloud.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 要设置 IoT Edge 设备，您需要同时设置云端和设备端。IoT 设备需要在云端有一个位置来发送其信息。本示例有两个部分。第一部分是在 IoT Hub
    中配置 IoT Edge 设备。第二部分是配置设备与云端通信。
- en: Configuring an IoT Edge device (cloud side)
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 配置 IoT Edge 设备（云端）
- en: 'The steps are as follows:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 步骤如下：
- en: In the IoT Hub blade, select IoT Edge.
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 IoT Hub 刀片中，选择 IoT Edge。
- en: Click on the + Add an IoT Edge device button. This will take you to the Add
    IoT Edge device wizard.
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击“+ 添加 IoT Edge 设备”按钮。这将带您进入添加 IoT Edge 设备向导。
- en: Give your device a unique device ID and select Save.
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 给您的设备一个独特的设备 ID，并选择保存。
- en: 'A new device will be displayed in the middle of the screen. Click on that device
    and copy its primary connection string:'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 屏幕中央将显示一个新设备。点击该设备并复制其主连接字符串：
- en: '![](img/5beb674a-0e7a-4427-91bb-843769b22c21.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5beb674a-0e7a-4427-91bb-843769b22c21.png)'
- en: The next section explains getting a device to talk to the cloud. To do this,
    you will need the device connection string. The device connection string can be
    found in the device properties section. Click on the device you want the connection
    string from and copy the connection string.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的部分解释了如何使设备与云端通信。为此，您将需要设备连接字符串。设备连接字符串可以在设备属性部分找到。点击您想要获取连接字符串的设备，并复制连接字符串。
- en: Configuring an IoT Edge device (device side)
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 配置 IoT Edge 设备（设备端）：
- en: 'The first thing to do is to install Moby. Moby is a scaled-down version of
    Docker. Docker allows you to push Edge modules down to the device. These models
    can be data-collected modules from sensors and they can also be ML modules. The
    steps are as follows:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 首先要做的是安装 Moby。Moby 是 Docker 的精简版本。Docker 允许您将 Edge 模块推送到设备上。这些模型可以是从传感器收集数据的模块，也可以是
    ML 模块。步骤如下：
- en: 'Download and install the Moby engine on the device:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载并安装 Moby 引擎到设备上：
- en: '[PRE0]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Download and install the Moby CLI:'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载并安装 Moby CLI：
- en: '[PRE1]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Fix the installation:'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 修复安装问题：
- en: '[PRE2]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Install the IoT Edge security manager:'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装 IoT Edge 安全管理器：
- en: '[PRE3]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Install the security daemon:'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装安全守护程序：
- en: '[PRE4]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Fix the installation:'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 修复安装问题：
- en: '[PRE5]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Edit the config file for the Edge device. If you do not have `nano` already
    installed on your device, you may need to install it. `nano` is a command line-based
    text editor that will work over SSH:'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编辑 Edge 设备的配置文件。如果您的设备上尚未安装 `nano`，可能需要先安装它。`nano` 是基于命令行的文本编辑器，可通过 SSH 进行工作：
- en: '[PRE6]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'In the `nano` text editor, find the device connection string. Then, paste the
    device connection string you copied from the IoT Hub portal into the `"<ADD DEVICE
    CONNECTION STRING HERE>"` section:'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `nano` 文本编辑器中查找设备连接字符串。然后，将您从 IoT Hub 门户复制的设备连接字符串粘贴到 `"<ADD DEVICE CONNECTION
    STRING HERE>"` 部分：
- en: '[PRE7]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: From there, you need to save and exit `nano`. To do this, press *Ctrl* + *X*.
    The terminal will have a saving confirmation message. Press *Y* to confirm and
    save. Then, it is time to restart the service on the device to pick up the changes.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，您需要保存并退出 `nano`。为此，请按下 *Ctrl* + *X*。终端将显示保存确认消息。按 *Y* 确认并保存。然后，是时候重新启动设备上的服务以应用更改了。
- en: 'Restart the Edge service using the following command:'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令重新启动 Edge 服务：
- en: '[PRE8]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: How it works...
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理如下...
- en: In this recipe, we've created a device in the cloud that has a specific key
    for that device. This is part of a security measure where each device has its
    own unique key for a device. If a device becomes compromised, it can be shut off.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在此教程中，我们创建了一个在云中具有特定密钥的设备。这是安全措施的一部分，每个设备都有自己的唯一密钥。如果设备被 compromise，可以关闭它。
- en: We then added the IoT Edge SDK to the device and connected it to the cloud.
    At this point, the device is fully connected to the cloud and is ready to receive
    ML models and send its telemetry to the cloud. The next step is to deploy Edge
    modules to the device. These Edge modules are dockerized containers that can access
    sensors on the device and send telemetry to the cloud or run a trained model.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们将 IoT Edge SDK 添加到设备上，并将其连接到云端。在这一点上，设备已完全连接到云端，并准备好接收 ML 模型并将其遥测发送到云端。下一步是将
    Edge 模块部署到设备上。这些 Edge 模块是 docker 化的容器，可以访问设备上的传感器，并将遥测发送到云端或运行经过训练的模型。
- en: Deploying ML modules to Edge devices
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将 ML 模块部署到 Edge 设备：
- en: Docker is the primary method of deployment for IoT devices. Docker allows you
    to create and test containers locally and deploy them to edge devices. Docker
    files can be specially scripted to deploy in various chip architectures such as
    x86 and ARM. In this recipe, we're going to walk through creating an IoT Edge
    module with ML libraries deployed from the cloud.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: Docker 是 IoT 设备部署的主要方法。Docker 允许您在本地创建和测试容器，并将其部署到边缘设备上。Docker 文件可以根据不同的芯片架构（如
    x86 和 ARM）进行特别脚本化部署。在此教程中，我们将演示如何从云端创建一个带有 ML 库的 IoT Edge 模块。
- en: Getting ready
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作：
- en: 'To create an IoT Edge module, first install Visual Studio Code. After Visual
    Studio Code is up and running, install the Azure IoT Edge extension. This can
    be done by finding the extension icon (![](img/e57c7d0a-92db-4095-8c30-1d7183f655af.png))
    in the side panel of Visual Studio Code. In the extension search bar, search for
    `azure iot edge` and install the extension:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建 IoT Edge 模块，首先安装 Visual Studio Code。安装并运行 Visual Studio Code 后，安装 Azure
    IoT Edge 扩展。可以通过在 Visual Studio Code 侧边栏中找到扩展图标（![](img/e57c7d0a-92db-4095-8c30-1d7183f655af.png)）来完成。在扩展搜索栏中搜索
    `azure iot edge` 并安装扩展：
- en: '![](img/63e44cac-c335-4db1-9e70-d5527db04355.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![](img/63e44cac-c335-4db1-9e70-d5527db04355.png)'
- en: After installing the extension, Visual Studio Code now has a wizard that can
    create an IoT Edge deployment. With a few modifications, it can be configured
    to deploy an ML model.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 安装完扩展程序后，Visual Studio Code 现在有一个向导，可以创建 IoT Edge 部署。通过少量修改，可以配置它以部署 ML 模型。
- en: How to do it...
  id: totrans-124
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'The steps for this recipe are as follows:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 此配方的步骤如下：
- en: 'In Visual Studio Code, press *Ctrl* + *Shift* + *P* to bring up the command
    window and find Azure IoT Edge: New IoT Edge Solution:'
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '在 Visual Studio Code 中，按下*Ctrl* + *Shift* + *P*以打开命令窗口，并找到 Azure IoT Edge:
    New IoT Edge Solution:'
- en: '![](img/066bcfb0-0ffe-43ab-960b-51ca2cb63773.png)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![](img/066bcfb0-0ffe-43ab-960b-51ca2cb63773.png)'
- en: Select a location for your code.
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择代码的位置。
- en: Enter a solution name.
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入解决方案名称。
- en: Choose a language. For the purpose of this book, we will be using Python as
    our language.
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择一种语言。为了本书的目的，我们将使用 Python 作为我们的语言。
- en: Create a module name.
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个模块名称。
- en: Select a local port for running your code locally.
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择本地端口以在本地运行代码。
- en: How it works...
  id: totrans-133
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理...
- en: 'After completing the wizard, you should see something in your Visual Studio
    Code explorer that looks like the following:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 完成向导后，您应该在 Visual Studio Code 的资源管理器中看到类似以下内容：
- en: '![](img/2eecdf1a-3d54-44af-b3c9-ad05b5783620.png)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2eecdf1a-3d54-44af-b3c9-ad05b5783620.png)'
- en: Let's explore what was created for you. The main entry point for the project
    is `main.py`. `main.py` has a sample to help make the development time faster.
    To deploy `main.py`, you will use the `deployment.template.json` file. Right-clicking
    on `deployment.template.json` brings up a menu that has an option to create a deployment
    manifest. In the `modules` folder, there is a sample module with three Docker
    files for ARM32, AMD64, and AMD64 in debug mode. These are the currently supported
    chip set architectures. `Dockerfile.arm32v7` is the architecture that is supported
    on Raspberry Pi v3.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们探索为您创建的内容。项目的主入口点是 `main.py`。`main.py` 中有一个示例，可以帮助加快开发时间。要部署 `main.py`，您将使用
    `deployment.template.json` 文件。右键单击 `deployment.template.json` 将弹出一个菜单，其中包含创建部署清单的选项。在
    `modules` 文件夹中，有一个包含三个 Docker 文件的示例模块，用于 ARM32、AMD64 和调试模式下的 AMD64。这些是当前支持的芯片架构。`Dockerfile.arm32v7`
    是支持树莓派 v3 的架构。
- en: 'To make sure you build ARM32 containers and not AMD64 containers, go into the
    `module.json` file and remove any references to other Docker files. For example,
    the following has three Docker references:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保构建 ARM32 容器而不是 AMD64 容器，请进入 `module.json` 文件并删除任何其他 Docker 文件的引用。例如，以下内容有三个
    Docker 引用：
- en: '[PRE9]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'After removing two Docker references that are not used, the new file should
    now look as follows:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 删除两个未使用的 Docker 引用后，新文件现在应如下所示：
- en: '[PRE10]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: There's more...
  id: totrans-141
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'To install TensorFlow, which is an ML library, Keras, which is an abstraction
    layer on top of TensorFlow that makes it easier to program, and `h5py`, which
    is a serialization layer that allows you to serialize and deserialize TensorFlow
    models, go to the target Docker container, then go into the `requirements.txt`
    file and install the libraries by inserting the following:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 要安装 TensorFlow（这是一个 ML 库）、Keras（这是一个在 TensorFlow 之上的抽象层，使编程更加简单）和 `h5py`（这是一个序列化层，允许您序列化和反序列化
    TensorFlow 模型），请进入目标 Docker 容器，然后进入 `requirements.txt` 文件，并插入以下内容来安装库：
- en: '[PRE11]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Setting up Kafka
  id: totrans-144
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置 Kafka
- en: Kafka is an open source project that is inexpensive at scale, can execute ML
    models with millisecond latency, and has a multi-topic pub/sub model. There are
    several ways to set up Kafka. It is an open source project, so you can download
    the Kafka project and run Zookeeper and Kafka locally. Confluent, the parent company
    of Kafka, has a paid service that offers many additional features, such as dashboards
    and KSQL. They are available in Azure, AWS, and Google Cloud as a managed service
    and also, you can run Kafka as a dockerized container for development use.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka 是一个开源项目，在规模上非常经济实惠，可以以毫秒级延迟执行 ML 模型，并具有多主题发布/订阅模型。有几种设置 Kafka 的方式。它是一个开源项目，因此您可以下载
    Kafka 项目并在本地运行 Zookeeper 和 Kafka。Kafka 的母公司 Confluent 提供了一个付费服务，提供许多额外的功能，如仪表板和
    KSQL。它们在 Azure、AWS 和 Google Cloud 中作为托管服务提供，您也可以将 Kafka 作为 Docker 容器来进行开发使用。
- en: One downside about using Kafka is that there is a lot of additional overhead
    to do to make it a good IoT project. Kafka, for example, is not secure by default.
    Security is handled through a series of plugins both on the device side through
    x.509 certificates and on the cloud side through **Lightweight Directory Access
    Protocol** (**LDAP**), Ranger, or Kerberos plugins. Deploying ML models is also
    not trivial. Any ML libraries need to be converted into something a Java compiler
    can use. TensorFlow has TensorFlow for Java but many ML libraries are not available
    in Java.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Kafka的一个缺点是需要大量额外的开销来使其成为一个良好的物联网项目。例如，Kafka默认情况下不安全。安全性通过一系列插件处理，包括设备端通过x.509证书以及云端通过**轻量级目录访问协议**（**LDAP**）、Ranger或Kerberos插件。部署ML模型也并非易事。任何ML库都需要转换为Java编译器可用的形式。TensorFlow有适用于Java的TensorFlow，但许多ML库在Java中不可用。
- en: Getting ready
  id: totrans-147
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备就绪
- en: In this example, we will be using Confluent Kafka in `docker-compose`. You will
    need to have Git, Docker, and `docker-compose` installed on your computer to run
    this recipe. To add ML models to Kafka streams, you will need to use a platform
    that runs on Java, such as H2O or TensorFlow.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在本示例中，我们将在`docker-compose`中使用Confluent Kafka。您需要在计算机上安装Git、Docker和`docker-compose`才能运行此食谱。要将ML模型添加到Kafka流中，您需要使用在Java上运行的平台，例如H2O或TensorFlow。
- en: How to do it...
  id: totrans-149
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实现...
- en: 'The steps for this recipe are as follows:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 此食谱的步骤如下：
- en: 'Clone the repo:'
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 克隆存储库：
- en: '[PRE12]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Run `docker-compose`:'
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行`docker-compose`：
- en: '[PRE13]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Confluent Kafka comes with many containers. After waiting about 10 minutes for
    the containers to finish launching, go to a browser and navigate to `localhost:9091`
    to see Kafka Control Center.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: Confluent Kafka带有许多容器。等待大约10分钟使容器完成启动后，打开浏览器，访问`localhost:9091`以查看Kafka控制中心。
- en: How it works...
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理...
- en: Kafka uses a journal to record data coming from end users into topics. These
    topics can then be read by consumers of the data. What has made Kafka a popular
    tool among the IoT community is its advanced features. Multiple streams can be
    combined, and streams can be turned into a key/value-based table where the most
    recent stream updates the table. But most importantly for the purpose of this
    book, ML algorithms can be run on streaming data with latency times in milliseconds.
    This recipe shows how to push data into Kafka and then create a Java project to
    manipulate the data in real time.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka使用日志来记录来自最终用户的数据流入主题。这些主题可以被数据的消费者读取。使Kafka在物联网社区中成为流行工具的原因是其先进的特性。多个流可以合并，并且流可以转换为基于键/值的表格，其中最新的流更新表格。但更重要的是，对于本书的目的，ML算法可以在毫秒级延迟的流数据上运行。本示例展示了如何将数据推送到Kafka，然后创建一个Java项目以实时处理数据。
- en: There's more...
  id: totrans-158
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 这还不是全部...
- en: 'Streaming data into Kafka is fairly easy. There are producers that send device-to-cloud
    messages and consumers that receive cloud-to-device messages. In the following
    example, we are going to implement a producer:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据流入Kafka相当简单。有生产者发送设备到云的消息和消费者接收云到设备的消息。在以下示例中，我们将实现一个生产者：
- en: 'Download an example project:'
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载示例项目：
- en: '[PRE14]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Install the requirements:'
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装必要的依赖：
- en: '[PRE15]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Run the `weather.py` file:'
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行`weather.py`文件：
- en: '[PRE16]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: You should now be able to look at your Kafka Control Center and see data flowing
    in. The Kafka Streams API is a real-time platform that can perform ML computations
    with millisecond latency. The Streams API has the concepts of KTables and KStreams.
    KStreams are data streaming into Kafka on various topics. KTables are streams
    turned into tables where the data is updated every time there is a new record
    associated with its primary key. This allows multiple streams to be joined together
    similarly to how tables in a database are joined together, giving Kafka the ability
    to not only deal with a single device at a time but also to take device data from
    multiple sources where we combine streams together.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您应该能够查看Kafka控制中心，并看到数据正在流入。Kafka Streams API是一个实时平台，可以以毫秒级延迟执行ML计算。Streams
    API具有KTables和KStreams的概念。KStreams是流入Kafka的各种主题的数据流。KTables是流转换成表格，其中数据每次有与其主键关联的新记录时更新。这允许将多个流类似于数据库中的表进行联接，使Kafka能够不仅处理单个设备，还能够从多个源获取设备数据并将流组合在一起。
- en: 'To use the Streams API, you must first install Java and Maven on your computer.
    In addition, you will need to install an **integrated development environment**
    (**IDE**) for developing in Java, such as IntelliJ. Once you have installed all
    the prerequisites, run the Maven archetype to generate the code needed to start
    a Kafka Streams API project:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 Streams API，您必须首先在计算机上安装 Java 和 Maven。此外，您还需要安装用于 Java 开发的集成开发环境，例如 IntelliJ。安装完所有先决条件后，运行
    Maven 原型以生成启动 Kafka Streams API 项目所需的代码：
- en: '[PRE17]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Open the newly created project in IntelliJ and you will be all set to code against
    the Kafka Streams API. The motto of Confluent, the maker of Kafka, is: *It's just
    Java*. What they mean by that is once you are in the Streams API, you can write
    Java code to do whatever you want. This could be to send out WebSocket information
    to a website or to run ML models. If it can be done in Java, then you can do it
    in the KStreams event loop. There are frameworks such as `deeplearning4j` that
    can take Keras models trained in Python and run them in Java.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 在 IntelliJ 中打开新创建的项目，您就可以开始编写针对 Kafka Streams API 的代码了。Confluent，Kafka 的制造商的座右铭是：“*It's
    just Java*”。他们的意思是，一旦您进入 Streams API，您可以编写 Java 代码来做任何您想做的事情。这可能是向网站发送 WebSocket
    信息或运行 ML 模型。如果可以用 Java 做到，那么在 KStreams 事件循环中也可以做到。有一些框架，如`deeplearning4j`，可以接受在
    Python 中训练的 Keras 模型，并在 Java 中运行它们。
- en: Installing ML libraries on Databricks
  id: totrans-170
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 Databricks 上安装 ML 库
- en: Databricks is a unified big data and analytics platform. It is great for training
    ML models and working with the kind of large-scale data that is often found in
    IoT. There are extensions such as Delta Lake that allow researchers the ability
    to view data as it existed at certain periods of time so that they can do analysis
    when models drift. There are also tools such as MLflow that allow the data scientist
    to compare multiple models against each other. In this recipe, we are going to
    install various ML packages such as TensorFlow, PyTorch, and GraphFrames on Databricks.
    Most ML packages can be installed via PyPI. The format used to install TensorFlow,
    for example, will work on various ML frameworks such as OpenAI Gym, Sonnet, Keras,
    and MXNet. Some tools are available in Databricks that are not available in Python.
    For those, we use the pattern explored by GraphX and GraphFrame where packages
    are installed through Java extensions.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: Databricks 是一个统一的大数据和分析平台。它非常适合训练 ML 模型并处理 IoT 中常见的大规模数据。有一些扩展如 Delta Lake 允许研究人员查看数据在特定时间段的存在方式，以便在模型漂移时进行分析。还有像
    MLflow 这样的工具，允许数据科学家比较多个模型之间的差异。在这个示例中，我们将在 Databricks 上安装各种 ML 包，如 TensorFlow、PyTorch
    和 GraphFrames。大多数 ML 包可以通过 PyPI 安装。例如，用于安装 TensorFlow 的格式可用于 OpenAI Gym、Sonnet、Keras
    和 MXNet 等各种 ML 框架。Databricks 中有一些在 Python 中不可用的工具。对于这些工具，我们使用 GraphX 和 GraphFrame
    探索的模式，通过 Java 扩展安装包。
- en: Getting ready
  id: totrans-172
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: Before we start, it's important to know how the components work with each other.
    Let's start with workspaces. The workspace area is where you can share results
    between data scientists and engineers through the use of Databricks notebooks.
    Notebooks can interoperate with the filesystem in Databricks to store Parquet
    or Delta Lake files. The workspaces section also stores files such as Python libraries
    and JAR files. In the workspaces section, you can create folders to store shared
    files. I typically create a `packages` folder to store the Python and JAR files.
    Before we install the Python packages, let's first examine what a cluster is by
    going to the cluster section.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始之前，了解各组件如何互相配合是很重要的。让我们从工作空间开始。工作空间区域是您可以通过 Databricks 笔记本与数据科学家和工程师共享结果的地方。笔记本可以与
    Databricks 中的文件系统进行互操作，以存储 Parquet 或 Delta Lake 文件。工作空间部分还存储诸如 Python 库和 JAR 文件等文件。在工作空间部分，您可以创建文件夹来存储共享文件。我通常创建一个`packages`文件夹来存储
    Python 和 JAR 文件。在安装 Python 包之前，让我们首先通过转到集群部分来检查集群是什么。
- en: In your Databricks instance, go to the Clusters menu. You can create a cluster
    or use a cluster that has already been created. With clusters, you specify the
    amount of compute needed. Spark can work over large datasets but also work with
    GPUs for ML-optimized workloads. Some clusters have ML tools such as Conda preinstalled
    and others allow you to install your own libraries.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在您的 Databricks 实例中，转到“Clusters”菜单。您可以创建一个集群或使用已创建的集群。对于集群，您可以指定所需的计算量。Spark
    可以处理大型数据集，也可以用于 ML 优化工作负载的 GPU。一些集群预装了诸如 Conda 等 ML 工具，其他允许您安装自己的库。
- en: How to do it...
  id: totrans-175
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: Traditional ML notebooks can have issues with different versions of ML packages
    installed. Databricks circumvents this by allowing users to set up resources that
    have a set of preinstalled packages. In this recipe, we're going to install various
    ML packages into Databricks. These packages can then be assigned to all new clusters
    going forward or specific clusters. This gives data scientists the flexibility
    to work with new versions of ML packages but still support older ML models they
    have developed. We will look at this recipe in three parts.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 传统的机器学习笔记本可能存在与安装的机器学习包不同版本的问题。Databricks 通过允许用户设置预安装包资源来规避这些问题。在这个示例中，我们将把各种机器学习包安装到
    Databricks 中。这些包可以分配给所有新的集群或特定的集群。这使得数据科学家可以灵活地使用新版本的机器学习包，同时支持他们开发的旧版机器学习模型。我们将在三个部分中介绍这个示例。
- en: Importing TensorFlow
  id: totrans-177
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 导入 TensorFlow
- en: 'Perhaps the easiest way to import a Python library such as TensorFlow is to
    use PyPI. Simply go to [https://pypi.org/](https://pypi.org/) and search for TensorFlow.
    This will give you the information needed and the ability to look at different
    versions. The installation steps are as follows:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 或许最简单的导入 Python 库（如 TensorFlow）的方法是使用 PyPI。只需访问 [https://pypi.org/](https://pypi.org/)
    并搜索 TensorFlow。这将为您提供所需的信息，并能查看不同的版本。安装步骤如下：
- en: Go to [https://pypi.org/](https://pypi.org/) and search for TensorFlow.
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 前往 [https://pypi.org/](https://pypi.org/) 并搜索 TensorFlow。
- en: 'Copy the name and version number you want in this format: `tensorflow==1.14.0`.'
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 复制您想要的名称和版本号，格式为 `tensorflow==1.14.0`。
- en: 'In the Workspace tab of Databricks, right-click anywhere and from the dropdown,
    click on Create and then Library:'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 Databricks 的 Workspace 选项卡中，右键单击任何位置，然后从下拉菜单中选择创建，然后选择库：
- en: '![](img/57243eac-fd03-4a75-ac64-625d01977cda.png)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![](img/57243eac-fd03-4a75-ac64-625d01977cda.png)'
- en: 'On the Create Library page, select PyPI as the library source:'
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在创建库页面上，选择 PyPI 作为库源：
- en: '![](img/8cc95df7-7d95-47d4-8a38-7732c795b64b.png)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8cc95df7-7d95-47d4-8a38-7732c795b64b.png)'
- en: Copy the name of the library and the version number and paste that into the
    Package section.
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 复制库的名称和版本号，然后粘贴到“包”部分。
- en: Click Create.
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击创建。
- en: If you have already created a cluster, you can attach TensorFlow to it. You
    can also have TensorFlow installed on all clusters.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您已经创建了集群，可以将 TensorFlow 附加到它上面。您也可以在所有集群上安装 TensorFlow。
- en: Installing PyTorch
  id: totrans-188
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 安装 PyTorch
- en: 'PyTorch is a popular ML library written in native Python and has built-in support
    for GPUs. Installing PyTorch is very similar to installing TensorFlow. You can
    install it via PyPI in the Create | Library menu choice. In the PyPI import library
    menu, put in the current version of PyPI (`torch==1.1.0.post2`). The installation
    steps are as follows:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch 是一个流行的原生 Python 编写的机器学习库，内置支持 GPU。安装 PyTorch 非常类似于安装 TensorFlow。您可以在创建
    | 库菜单中通过 PyPI 安装它。在 PyPI 导入库菜单中，输入当前版本的 PyPI (`torch==1.1.0.post2`)。安装步骤如下：
- en: Go to [https://pypi.org/](https://pypi.org/) and search for PyTorch.
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 前往 [https://pypi.org/](https://pypi.org/) 并搜索 PyTorch。
- en: 'Copy the name and version number you want in this format: `torch==1.1.0.post2`.'
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 复制您想要的名称和版本号，格式为 `torch==1.1.0.post2`。
- en: In the Workspace tab of Databricks, right-click anywhere and from the dropdown,
    click on Create and then Library.
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 Databricks 的 Workspace 选项卡中，右键单击任何位置，然后从下拉菜单中选择创建，然后选择库。
- en: Select PyPI as the library source.
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择 PyPI 作为库源。
- en: Copy the name of the library and the version number and paste that into the
    Package section.
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 复制库的名称和版本号，然后粘贴到“包”部分。
- en: Click Create.
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击创建。
- en: If you have already created a cluster, you can attach PyTorch to it. You can
    also install PyTorch on all clusters.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您已经创建了集群，可以将 PyTorch 附加到它上面。您也可以在所有集群上安装 PyTorch。
- en: Installing GraphX and GraphFrames
  id: totrans-197
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 安装 GraphX 和 GraphFrames
- en: 'Spark has some distributed libraries that are not available anywhere else in
    data science. GraphFrames is one of them. In graph theory, you can perform actions
    such as finding the shortest path, network flow, homophily, centrality, and influence.
    Because GraphFrames is built on GraphX, which is a Java library, you need to install
    the Java library, and then to use the Python wrapper, you will need to `pip` install
    the Python library that accesses the Java JAR file. The installation steps are
    as follows:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: Spark 有一些分布式库，在数据科学中无法找到。GraphFrames 就是其中之一。在图论中，您可以执行诸如寻找最短路径、网络流、同源性、中心度和影响力等操作。因为
    GraphFrames 是建立在 Java 库 GraphX 上的，所以您需要安装 Java 库，然后使用 Python 封装器，您需要 `pip` 安装访问
    Java JAR 文件的 Python 库。安装步骤如下：
- en: Download a JAR file from [https://spark-packages.org/package/graphframes/graphframes](https://spark-packages.org/package/graphframes/graphframes).
    You'll need to find a version that matches the version of Spark that you are running
    in your cluster.
  id: totrans-199
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 [https://spark-packages.org/package/graphframes/graphframes](https://spark-packages.org/package/graphframes/graphframes)
    下载一个 JAR 文件。你需要找到一个与你集群中运行的 Spark 版本匹配的版本。
- en: In the Workspace tab of Databricks, right-click anywhere and from the dropdown,
    click on Create and then Library.
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 Databricks 的 Workspace 标签页中，右键点击任意位置，从下拉菜单中选择 Create，然后选择 Library。
- en: Drag and drop the JAR file into the space titled Drop JAR here.
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 JAR 文件拖放到名为 Drop JAR here 的空间中。
- en: Click Create.
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击 Create。
- en: Then, import another library.
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，导入另一个库。
- en: In the Workspace tab of Databricks, right-click anywhere and from the dropdown,
    click on Create and then Library.
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 Databricks 的 Workspace 标签页中，右键点击任意位置，从下拉菜单中选择 Create，然后选择 Library。
- en: Select PyPI as the library source and enter `graphframes` in the Package section.
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择 PyPI 作为库源，并在 Package 部分输入 `graphframes`。
- en: Click Create.
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击 Create。
- en: To test your installation, you can download a sample notebook and data files
    here: [https://github.com/Microshak/Databricks/tree/master/Graph](https://github.com/Microshak/Databricks/tree/master/Graph).
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 为了测试你的安装，你可以在这里下载一个示例笔记本和数据文件：[https://github.com/Microshak/Databricks/tree/master/Graph](https://github.com/Microshak/Databricks/tree/master/Graph)。
- en: How it works...
  id: totrans-208
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理如下...
- en: Being designed for both data engineers and data scientists, Databricks supports
    multi-versions of software and multi-languages. It does this by allowing the installation
    of different versions of ML packages by allowing the user to configure each cluster
    separately. TensorFlow is installed implicitly on the streaming cluster. Another
    cluster has the popular Conda environment installed. Finally, the test environment
    does not have TensorFlow installed.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: Databricks 专为数据工程师和数据科学家设计，支持多版本软件和多语言。通过允许用户分别为每个集群配置不同版本的 ML 包来实现此目的。TensorFlow
    隐式安装在流处理集群上。另一个集群安装了流行的 Conda 环境。最后，测试环境没有安装 TensorFlow。
