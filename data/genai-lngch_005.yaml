- en: 4 Querying with Tools
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4 使用工具查询
- en: Join our book community on Discord
  id: totrans-1
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参加我们在Discord上的书籍社区
- en: '[https://packt.link/EarlyAccessCommunity](https://packt.link/EarlyAccessCommunity)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.link/EarlyAccessCommunity](https://packt.link/EarlyAccessCommunity)'
- en: '![Qr code Description automatically generated](img/file26.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![自动生成的QR码描述](img/file26.png)'
- en: 'In today''s fast-paced business and research landscape, keeping up with the
    ever-increasing volume of information can be a daunting task. For engineers and
    researchers in fields like computer science and artificial intelligence staying
    updated with the latest developments is crucial. However, reading and comprehending
    numerous papers can be time-consuming and labor-intensive. This is where automation
    comes into play. In this chapter, we’ll describe an approach to automate the summarization
    of research papers and answering questions, making it easier for researchers to
    digest and stay informed. By leveraging language models and a series of questions,
    the summarization we’ll develop can summarize the core assertions, implications,
    and mechanics of a paper in a concise and simplified format. This can not only
    save time and effort while researching a topic, but it also ensures we can effectively
    navigate the accelerated pace of scientific progress. We’ll also have a play around
    with functions in OpenAI models, and their application to information extraction.
    We’ll see how they work (or not yet) for an application as parsers of curriculum
    vitae (CVs). This function syntax is specific to OpenAI’s API and has many applications,
    however, LangChain provides a platform that allows the creation of tools for any
    large language models (LLMs), which enhance their capabilities. These tools enable
    LLMs to interact with APIs, access real-time information, and perform various
    tasks such as retrieval search, database queries, writing emails, or even making
    phone calls. We’ll implement a question-answering app with Retrieval Augmented
    Generation (RAG). This is a technique to update large language models (LLMs) like
    GPT by injecting relevant data into the context. Finally, we’ll discuss different
    strategies of decision making in agents. We’ll implement two strategies, plan-and-execute
    (or plan-and-solve) and one-shot-agent, and we’ll integrate them into a visual
    interface as a visual app in the browser (using Streamlit) for question answering.The
    main sections are:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在当今快节奏的商业和研究环境中，跟上不断增长的信息量可以是一项艰巨的任务。对于计算机科学和人工智能等领域的工程师和研究人员来说，了解最新发展是至关重要的。然而，阅读和理解大量论文可能是耗时和需大量精力的。这就是自动化发挥作用的地方。在本章中，我们将描述一种自动化总结研究论文和回答问题的方法，使研究人员更容易理解和保持知情。通过利用语言模型和一系列问题，我们将开发的总结可以简洁和简化地概括论文的核心论点、含义和机制。这不仅可以节省研究主题的时间和精力，还可以确保我们能有效地驾驭科学进步的加速步伐。我们还会尝试一下OpenAI模型的功能，并将其应用于信息提取。我们将看到它们如何（或者尚未）用于解析简历（CVs）。这个函数语法是特定于OpenAI的API，并有许多应用，然而，LangChain提供了一个平台，允许创建任何大型语言模型（LLMs）的工具，增强它们的功能。这些工具使LLMs能够与API交互，访问实时信息，并执行各种任务，如检索搜索、数据库查询、撰写电子邮件，甚至打电话。我们将使用检索增强生成（RAG）实现问答应用程序。这是一种通过向上下文注入相关数据来更新大型语言模型（LLMs）如GPT的技术。最后，我们将讨论代理决策的不同策略。我们将实现两种策略，即计划和执行（或计划和解决）和一次性代理，并将它们集成到一种视觉界面中，作为浏览器中的视觉应用程序（使用Streamlit）以回答问题。主要章节包括：
- en: What are hallucinations?
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是幻觉？
- en: How to summarize long documents?
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何总结长篇文件？
- en: Extracting information from documents
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从文件中提取信息
- en: Answer questions with tools
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用工具回答问题
- en: Reasoning strategies
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 推理策略
- en: We'll begin the chapter by discussing the problem of reliability of LLMs.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从讨论LLM可靠性问题开始这一章节。
- en: What are hallucinations?
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是幻觉？
- en: The rapid development of generative language models, such as GPT-3, Llama, and
    Claude 2, has brought attention to their limitations and potential risks. One
    major concern are hallucinations, where the models generate output that is nonsensical,
    incoherent, or unfaithful to the provided input. Hallucination poses performance
    and safety risks in real-world applications, such as medical or machine translation.
    There’s another aspect to hallucinations, which is the case, where LLMs generate
    text that includes sensitive personal information, such as email addresses, phone
    numbers, and physical addresses. This poses significant privacy concerns as it
    suggests that language models can memorize and recover such private data from
    their training corpus, despite not being present in the source input.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 生成语言模型的快速发展，如GPT-3、Llama和Claude 2，引起了人们对其局限性和潜在风险的关注。一个主要关注点是幻觉，即模型生成的输出是荒谬的、不连贯的或不忠实于提供的输入。幻觉在现实世界的应用中会带来性能和安全风险，比如医疗或机器翻译。幻觉的另一个方面是，LLM生成包含敏感个人信息的文本，比如电子邮件地址、电话号码和实际地址。这引起了重大的隐私问题，因为它表明语言模型可以从其训练语料库中记忆和恢复这些私人数据，尽管它们不存在于源输入中。
- en: '**Hallucination** in the context of LLMs refers to the phenomenon where generated
    text is unfaithful to the intended content or nonsensical. This term draws a parallel
    to psychological hallucinations, which involve perceiving something that does
    not exist. In NLG, hallucinated text may appear fluent and natural grounded in
    the provided context, but lacks specificity or verifiability. **Faithfulness**,
    where the generated content stays consistent and truthful to the source, is considered
    an antonym of hallucination.'
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**幻觉**在LLM的背景下指的是生成的文本与预期内容不忠实或荒谬的现象。这个术语类比于心理幻觉，后者涉及感知不存在的东西。在NLG中，幻觉文本可能在所提供的上下文中看起来流畅和自然，但缺乏具体性或可验证性。**忠实性**，即生成的内容保持与源的一致性和真实性，被认为是幻觉的反义词。'
- en: ''
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Intrinsic hallucinations** occur when the generated output contradicts the
    source content, while **extrinsic hallucinations** involve generating information
    that cannot be verified or supported by the source material. Extrinsic hallucinations
    can sometimes include factually correct external information, but their unverifiability
    raises concerns from a factual safety perspective.'
  id: totrans-15
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**内在幻觉**发生在生成的输出与源内容相矛盾时，而**外在幻觉**涉及生成无法通过源材料验证或支持的信息。外在幻觉有时可能包括事实上正确的外部信息，但它们的不可验证性引起了来自事实安全角度的担忧。'
- en: 'Efforts to address hallucination are ongoing, but there is a need for a comprehensive
    understanding across different tasks to develop effective mitigation methods.Hallucinations
    in LLMs can be caused by various factors:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 努力解决幻觉问题正在进行中，但需要在不同任务之间有一个全面的理解，以开发有效的缓解方法。LLM中的幻觉可能由各种因素引起：
- en: Imperfect representation learning by the encoder.
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编码器的不完美表示学习。
- en: Erroneous decoding, including attending to the wrong part of the source input
    and the choice of decoding strategy.
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 错误解码，包括注意到源输入的错误部分和解码策略的选择。
- en: Exposure bias, which is the discrepancy between training and inference time.
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 曝光偏差，即训练和推理时间之间的差异。
- en: Parametric knowledge bias, where pre-trained models prioritize their own knowledge
    over the input, leading to the generation of excessive information.
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 参数化知识偏差，其中预训练模型优先考虑自己的知识而不是输入，导致生成过多的信息。
- en: '**Hallucination mitigation methods** can be categorized into two groups: Data-Related
    Methods and Modeling and Inference Methods (after “Survey of Hallucination in
    Natural Language Generation”, Ziwei Ji and others, 2022):'
  id: totrans-21
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**幻觉缓解方法**可以分为两组：数据相关方法和建模与推理方法（见“自然语言生成中幻觉的调查”，季子威等，2022年）：'
- en: ''
  id: totrans-22
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Data-Related Methods:**'
  id: totrans-23
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**数据相关方法：**'
- en: ''
  id: totrans-24
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Building a Faithful Dataset: Constructing datasets with clean and faithful
    targets from scratch or rewriting real sentences while ensuring semantic consistency.'
  id: totrans-25
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 构建一个忠实的数据集：从零开始构建具有清洁和忠实目标的数据集，或者在确保语义一致性的同时重写真实句子。
- en: ''
  id: totrans-26
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Cleaning Data Automatically: Identifying and filtering irrelevant or contradictory
    information in the existing corpus to reduce semantic noise.'
  id: totrans-27
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 自动清理数据：识别和过滤现有语料库中的不相关或矛盾信息，以减少语义噪声。
- en: ''
  id: totrans-28
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Information Augmentation: Augmenting inputs with external information, such
    as retrieved knowledge or synthesized data, to improve semantic understanding
    and address source-target divergence.'
  id: totrans-29
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 信息增强：使用外部信息（如检索到的知识或合成数据）来增强输入，以提高语义理解并解决源目标差异。
- en: ''
  id: totrans-30
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Modeling and Inference Methods:**'
  id: totrans-31
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**建模和推理方法：**'
- en: ''
  id: totrans-32
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Architecture: Modifying encoder architecture to enhance semantic interpretation,
    attention mechanisms to prioritize source information, and decoder structures
    to reduce hallucination and enforce implicit or explicit constraints.'
  id: totrans-33
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 架构：修改编码器架构以增强语义解释，注意机制以优先处理源信息，解码器结构以减少幻觉并强制实施隐式或显式约束。
- en: ''
  id: totrans-34
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Training: Incorporating planning, reinforcement learning (RL), multi-task learning,
    and controllable generation techniques to mitigate hallucination by improving
    alignment, optimizing reward functions, and balancing faithfulness and diversity.'
  id: totrans-35
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 训练：结合规划、强化学习（RL）、多任务学习和可控生成技术，通过改善对齐、优化奖励函数和平衡忠实度与多样性来减轻幻觉。
- en: ''
  id: totrans-36
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Post-Processing: Correcting hallucinations in the output through generate-then-refine
    strategies or refining the results specifically for faithfulness using post-processing
    correction methods.'
  id: totrans-37
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 后处理：通过生成-再精化策略来纠正输出中的幻觉，或使用后处理校正方法专门优化结果的忠实度。
- en: 'A result of hallucinations, where automatic fact checking can be applied, is
    the danger of spreading incorrect information or misuse for political purposes.
    **Misinformation**, including **disinformation**, deceptive news, and rumors,
    poses a significant threat to society, especially with the ease of content creation
    and dissemination through social media. The threats to society include distrust
    in science, public health narratives, social polarization, and democratic processes.
    Journalism and archival studies have extensively studied the issue, and fact-checking
    initiatives have grown in response. Organizations dedicated to fact-checking provide
    training and resources to independent fact-checkers and journalists, allowing
    for the scaling of expert fact-checking efforts. Addressing misinformation is
    crucial to preserving the integrity of information and combating its detrimental
    impact on society.In the literature, this kind of problem is called textual entailment,
    where models predict the directional truth relation between a text pair (i.e.
    “sentence t entails h” if, typically, a human reading t would infer that h is
    most likely true). In this chapter, we’ll focus on **automatic fact-checking**
    through information augmentation and post-processing. Facts can be retrieved either
    from LLMs or using external tools. In the former case, pre-trained language models
    can take the place of the knowledge base and retrieval modules, leveraging their
    vast knowledge to answer open-domain questions and using prompts to retrieve specific
    facts. We can see the general idea in this diagram (source: https://github.com/Cartus/Automated-Fact-Checking-Resources
    by Zhijiang Guo):'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 幻觉的结果是，自动事实核查可以应用的地方，是错误信息的传播危险或政治目的的滥用。 **错误信息**，包括**误导信息**、欺骗性新闻和谣言，对社会构成了重大威胁，尤其是在内容的创建和传播变得更加容易的社交媒体环境中。社会所面临的威胁包括对科学、公共卫生叙事、社会极化和民主进程的不信任。新闻业和档案学已经广泛研究了这个问题，事实核查倡议也在回应中不断增长。致力于事实核查的组织为独立事实核查人员和记者提供培训和资源，从而扩大专家事实核查工作的规模。解决错误信息问题对于维护信息的完整性并通过打击其对社会的有害影响至关重要。在文献中，这种问题被称为文本蕴含，即模型预测文本对之间的方向性真实关系（即如果，通常，一个阅读t的人会推断h最有可能是真实的）。在本章中，我们将重点关注通过信息增强和后处理进行**自动事实核查**。事实可以从LLMs或使用外部工具中检索。在前一种情况下，预训练语言模型可以取代知识库和检索模块的位置，利用其广泛的知识来回答开放领域问题，并使用提示来检索特定事实。我们可以在这个图表中看到这个总体观念（来源：https://github.com/Cartus/Automated-Fact-Checking-Resources
    by Zhijiang Guo）：
- en: '![Figure 4.1: Automatic fact-checking pipeline in three stages.](img/file27.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![图4.1：三个阶段的自动事实核查流程。](img/file27.png)'
- en: 'Figure 4.1: Automatic fact-checking pipeline in three stages.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.1：三个阶段的自动事实核查流程。
- en: 'We can distinguish three stages:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以区分三个阶段：
- en: Claim detection - identify claims that require verification
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 主张检测 - 确定需要验证的主张
- en: Retrieval - retrieve evidence to find sources supporting or refuting the claim
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检索 - 检索证据以查找支持或反驳主张的来源
- en: Claim verification - assess the veracity of the claim based on the evidence
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 主张验证 - 根据证据评估主张的真实性
- en: 'Starting with 24-layer BERT-Large in 2018, language models have been pre-trained
    on large knowledge bases such as Wikipedia, and therefore would be able to answer
    knowledge questions from Wikipedia or - since their training set increasingly
    includes other sources - the internet, textbooks, arxiv, and Github. Querying
    for facts works with simple prompts such as masking prompts. For example, in order
    to answer the question “Where is Microsoft’s headquarter?”, the question would
    be rewritten as “Microsoft’s headquarter is in [MASK]” and fed into a language
    model for the answer. In this approach, the activations in the final Interestingly,
    if an LLM that has not received the source text (unconditional LLM) yields a smaller
    loss in generating targets than an LLM that has received the source text (conditioned
    LLM), this indicates that the generated token is hallucinatory (Fillippova, 2020).
    The ratio of hallucinated tokens to the total number of target tokens can serve
    as a measure of the degree of hallucination in the generated output. In LangChain,
    we have a chain available for fact checking with prompt-chaining, where a model
    actively questions the assumptions that went into a statement. In this self-checking
    chain, `LLMCheckerChain`, the model is prompted sequentially times, first to make
    the assumptions explicit - this looks like this:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 从2018年开始，从24层BERT-Large开始，语言模型已经在诸如维基百科之类的大型知识库上进行预训练，因此能够回答来自维基百科或因为其训练集越来越包括其他来源
    - 互联网、教科书、arxiv和Github的知识问题。使用简单的掩蔽提示即可查询事实。例如，为了回答问题“微软的总部在哪里？”，该问题将被重写为“微软的总部在[MASK]”，然后输入到语言模型中获取答案。在这种方法中，最终激活函数引起的东西有趣的是，如果一个没有接收源文本（无条件LLM）的LLM产生比接收源文本（有条件LLM）的LLM更小的生成目标损失，这表明所生成的令牌具有幻觉性（Fillippova,2020）。幻象令牌占目标令牌总数的比率可以作为所生成输出中幻象程度的度量标准。在LangChain中，我们有一个链可用于事实检查和提示链，其中模型积极质疑陈述中涉及的假设。在这种自我检查的链中，`LLMCheckerChain`，模型被提示按顺序进行多次操作，首先将假设明确表达出来，看起来像这样：
- en: '[PRE0]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Please note that this is a string template, where the elements in curly brackets
    will be replaced by variables. Next, these assumptions are fed back to the model
    in order to check them one by one with a prompt like this:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这是一个字符串模板，其中花括号中的元素将被变量替换。接下来，这些假设将被反馈给模型，以便通过这样的提示逐个检查它们：
- en: '[PRE1]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Finally, the model is tasked to make a final judgment:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，模型被要求做出最终判断：
- en: '[PRE2]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The `LLMCheckerChain` does this all by itself as this example shows:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '`LLMCheckerChain`可以自己完成所有这些操作，正如这个例子所示：'
- en: '[PRE3]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The model can return different results to this question, some of which are
    wrong, and some of which it would correctly identify as false. When I was trying
    this out, I got results such as the blue whale, the North American beaver, or
    the extinct Giant Moa. I think this is the right answer:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 模型可以返回不同的结果给该问题，其中的一些是错误的，而一些会被正确地标识为假的。当我尝试这个东西时，我得到了像蓝鲸、北美海狸或已灭绝的巨型恐鸟之类的结果。我认为这是正确的答案：
- en: '[PRE4]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: So, while this doesn’t guarantee correct answers, it can put a stop to some
    incorrect results.As for augmented retrieval (or RAG), we’ve seen the approach
    in this chapter, in the section about question answering. Fact-checking approaches
    involve decomposing claims into smaller checkable queries, which can be formulated
    as question-answering tasks. Tools designed for searching domain datasets can
    assist fact-checkers in finding evidence effectively. Off-the-shelf search engines
    like Google and Bing can also retrieve both topically and evidentially relevant
    content to capture the veracity of a statement accurately. In the next section,
    we’ll apply this approach to return results based on web searches and other tools.
    In the next section, we’ll implement a chain to summarize documents. We can ask
    any question to be answered from these documents.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，虽然这不能保证正确的答案，但它可以阻止一些错误的结果。至于扩展检索（或RAG），我们在本章的问题回答部分中已经看到了这种方法。事实检查方法涉及将声明分解为更小的可检查查询，这些查询可以被构造为问题回答任务。专为搜索领域数据集而设计的工具可以帮助事实检查员有效地查找证据。现成的搜索引擎如Google和Bing也可以检索涵盖主题和证据的相关内容，以准确捕捉声明的真实性。在下一节中，我们将应用这种方法来返回基于网络搜索和其他工具的结果。在下一节中，我们将实现一个链来总结文档。我们可以问任何问题以从这些文档中得到答案。
- en: How to summarize long documents?
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何总结长文档？
- en: 'In this section, we’ll discuss automating the process of summarizing long texts
    and research papers. In today''s fast-paced business and research landscape, keeping
    up with the ever-increasing volume of information can be a daunting task. For
    engineers and researchers in fields like computer science and artificial intelligence
    staying updated with the latest developments is crucial. However, reading and
    comprehending numerous papers can be time-consuming and labor-intensive. This
    is where automation comes into play. As engineers, we are driven by their desire
    to build and innovate, avoid repetitive tasks by automating them through the creation
    of pipelines and processes. This approach, often mistaken for laziness, allows
    engineers to focus on more complex challenges and utilize their skills more efficiently.Here,
    we’ll build an automation tool that can quickly summarize the content of long
    texts in a more digestible format. This tool is intended to help researchers keep
    up with the volume of papers being published daily, particularly in fast-moving
    fields such as artificial intelligence. By automating the summarization process,
    researchers can save time and effort, while also ensuring that they stay informed
    about the latest developments in their field. The tool will be based on LangChain
    and utilize large language models (LLMs) to summarize the core assertions, implications,
    and mechanics of a paper in a more concise and simplified manner. It can also
    answer specific questions about the paper, making it a valuable resource for literature
    reviews and accelerating scientific research. The author plans to further develop
    the tool to allow automatic processing of multiple documents and customization
    for specific research domains. Overall, the approach aims to benefit researchers
    by providing a more efficient and accessible way to stay updated with the latest
    research.LangChain supports a map reduce approach for processing documents using
    LLMs, which allows for efficient processing and analysis of documents. When reading
    in large texts, and splitting them into documents (chunks) that are suitable for
    the token context length of the LLM, a chain can be applied to each document individually
    and then combine the outputs into a single document. The core assertion is that
    the map reduce process involves two steps:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论自动化长文本和研究论文摘要的过程。在当今快节奏的商业和研究环境中，跟上不断增长的信息量可能是一项令人望而生畏的任务。对于计算机科学和人工智能等领域的工程师和研究人员，保持最新发展的状态至关重要。然而，阅读和理解大量的论文可能是耗时费力的。这就是自动化发挥作用的地方。作为工程师，我们的愿望是构建和创新，通过创建管道和进程来自动化避免重复的任务。这种方法经常被误解为懒惰，其实它允许工程师集中精力解决更复杂的挑战，并更有效地利用他们的技能。在这里，我们将搭建一个自动化工具，可以快速概括长文本的内容，以更易消化的格式呈现。此工具旨在帮助研究人员跟上每天发表的论文数量，特别是在人工智能等快速发展的领域。通过自动化摘要过程，研究人员可以节省时间和精力，同时也确保他们了解其领域的最新发展。该工具将基于LangChain，并利用大型语言模型（LLMs）以更简明和简化的方式概述论文的核心主张、含义和机制。它还可以回答有关论文的特定问题，使其成为文献综述和加速科学研究的有价值资源。作者计划进一步开发该工具，以便自动处理多个文档并针对特定研究领域进行定制。总体而言，这种方法旨在通过提供更高效、更易于访问的方式来让研究人员受益于最新研究。LangChain支持使用LLMs处理文档的Map
    Reduce方法，以实现文档的高效处理和分析。当阅读大型文本并将其拆分为适合LLM令牌上下文长度的文档（块）时，可以将链逐个应用于每个文档，然后将输出组合成一个文档。核心主张是Map
    Reduce过程涉及两个步骤：
- en: Map step - the LLM chain is applied to each document individually, treating
    the output as a new document, and
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 映射步骤——将LLM链分别应用于每个文档，将输出视为新文档，然后
- en: Reduce step - all the new documents are passed to a separate combine documents
    chain to obtain a single output.
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 减少步骤——所有新文档都将传递到一个独立的组合文档链中，以获取单个输出。
- en: 'This is illustrated in the figure here:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 图中所示：
- en: '![Figure 4.2: Map reduce chain in LangChain (source: LangChain documentation).](img/file28.jpg)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![图4.2：LangChain中的Map Reduce链（来源：LangChain文档）](img/file28.jpg)'
- en: 'Figure 4.2: Map reduce chain in LangChain (source: LangChain documentation).'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.2：LangChain中的映射减少链（来源：LangChain文档）。
- en: 'The implications of this approach are that it allows for parallel processing
    of documents and enables the use of LLMs for reasoning, generating, or analyzing
    the individual documents as well as combining their outputs. The mechanics of
    the process involve compressing or collapsing the mapped documents to ensure they
    fit within the combine documents chain, which may also involve utilizing LLMs.
    The compression step can be performed recursively if needed. Here’s a simple example
    of loading a PDF document and summarizing it:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法的影响是它允许对文档进行并行处理，并且能够使用 LLM 进行推理、生成或分析单个文档以及组合它们的输出。该过程的机制涉及压缩或折叠映射文档，以确保它们适合于组合文档链，这也可能涉及到利用
    LLM。如果需要，压缩步骤可以递归执行。下面是加载 PDF 文档并对其进行摘要的简单示例：
- en: '[PRE5]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The variable `pdf_file_path` is a string with the path of a PDF file.The default
    prompt for both the map and reduce steps is this:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 变量`pdf_file_path`是一个包含 PDF 文件路径的字符串。映射和减少步骤的默认提示是这样的：
- en: '[PRE6]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'We can specify any prompt for each step. In the text summarization application
    developed for this chapter on Github, we can see how to pass other prompts. On
    LangChainHub, we can see the qa-with sources prompt, which takes a reduce/combine
    prompt like this:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以为每一步指定任何提示。在为本章开发的文本摘要应用中，我们可以看到如何传递其他提示。在 LangChainHub 上，我们可以看到 qa-with
    sources 提示，它采用了这样一个 reduce/combine 提示：
- en: '[PRE7]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: In this prompt, we would formulate a concrete question, but equally we could
    give the LLM a more abstract instruction to extract assumption and implications.
    The text would be the summaries from the map steps. An instruction like that would
    help against hallucinations.Other examples of instructions could be translating
    the document into a different language or rephrasing in a certain style.Once we
    start doing a lot of calls, especially here in the map step, we’ll see costs increasing.
    We are doing a lot of calls and using a lot of tokens in total. Time to give this
    some visibility!
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个提示中，我们会提出一个具体的问题，但同样我们也可以给 LLM 一个更抽象的指令，提取假设和含义。文本将会是从映射步骤中得到的摘要。这样的指令会有助于避免幻觉。其他指令的示例可能是将文档翻译成不同的语言或以某种风格重新表述。一旦我们开始做很多调用，特别是在映射步骤中，我们会看到成本增加。我们在做很多调用，并且总共使用了很多标记。是时候给这个问题一些关注了！
- en: Token usage
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 标记使用情况
- en: 'When using models, especially in long loops such as with map operations, it’s
    important to track the token usage and understand how much money you are spending.
    For any serious usage of generative AI, we need to understand the capabilities,
    pricing options, and use cases for different language models. OpenAI provides
    different models namely GPT-4, ChatGPT, and InstructGPT that cater to various
    natural language processing needs. GPT-4 is a powerful language model suitable
    for solving complex problems with natural language processing. It offers flexible
    pricing options based on the size and number of tokens used.ChatGPT models, like
    GPT-3.5-Turbo, specialize in dialogue applications such as chatbots and virtual
    assistants. They excel in generating responses with accuracy and fluency. The
    pricing for ChatGPT models is based on the number of tokens used.InstructGPT models
    are designed for single-turn instruction following and are optimized for quick
    and accurate response generation. Different models within the InstructGPT family,
    such as Ada and Davinci, offer varying levels of speed and power. Ada is the fastest
    model, suitable for applications where speed is crucial, while Davinci is the
    most powerful model, capable of handling complex instructions. The pricing for
    InstructGPT models depends on the model''s capabilities and ranges from low-cost
    options like Ada to more expensive options like Davinci.OpenAI''s DALL·E, Whisper,
    and API services for image generation, speech transcription, translation, and
    access to language models. DALL·E is an AI-powered image generation model that
    can be seamlessly integrated into apps for generating and editing novel images
    and art. OpenAI offers three tiers of resolution, allowing users to choose the
    level of detail they need. Higher resolutions offer more complexity and detail,
    while lower resolutions provide a more abstract representation. The price per
    image varies based on the resolution.Whisper is an AI tool that can transcribe
    speech into text and translate multiple languages into English. It helps capture
    conversations, facilitates communication, and improves understanding across languages.
    The cost for using Whisper is based on a per-minute rate.OpenAI''s API provides
    access to powerful language models like GPT-3, enabling developers to create advanced
    applications. When signing up for the API, users are given an initial token usage
    limit, representing the number of tokens available to interact with the language
    model within a specific timeframe. As users'' track record and usage increase,
    OpenAI may increase the token usage limit, granting more access to the model.
    Users can also request a quota increase if they require more tokens for their
    applications.We can track the token usage in OpenAI models by hooking into the
    OpenAI callback:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用模型时，特别是在长循环中，比如使用映射操作时，跟踪标记使用情况并了解你花费了多少钱是很重要的。对于任何严肃的生成式人工智能使用，我们需要了解不同语言模型的能力、定价选项和用例。OpenAI提供了不同的模型，包括GPT-4、ChatGPT和InstructGPT，以满足各种自然语言处理需求。GPT-4是一个强大的语言模型，适用于解决自然语言处理中的复杂问题。它提供了基于使用的标记大小和数量的灵活定价选项。ChatGPT模型，如GPT-3.5-Turbo，专注于对话应用，如聊天机器人和虚拟助手。它们在生成准确和流畅的响应方面表现出色。ChatGPT模型的定价基于使用的标记数量。InstructGPT模型专为单轮指令遵循而设计，并针对快速和准确的响应生成进行了优化。InstructGPT家族中的不同模型，如Ada和Davinci，提供不同水平的速度和功率。Ada是最快的模型，适用于速度至关重要的应用，而Davinci是最强大的模型，能够处理复杂的指令。InstructGPT模型的定价取决于模型的能力，从像Ada这样的低成本选项到像Davinci这样的更昂贵的选项。OpenAI的DALL·E、Whisper和API服务用于图像生成、语音转录、翻译和访问语言模型。DALL·E是一种AI驱动的图像生成模型，可以无缝集成到应用程序中，用于生成和编辑新颖的图像和艺术品。OpenAI提供了三个分辨率层次，允许用户选择他们所需的细节级别。更高的分辨率提供更复杂和更详细的图像，而较低的分辨率提供更抽象的表示。每张图像的价格根据分辨率而变化。Whisper是一个能够将语音转录为文本并将多种语言翻译成英语的AI工具。它有助于捕捉对话，促进交流，并提高跨语言理解。使用Whisper的成本基于每分钟的费率。OpenAI的API提供了对强大语言模型的访问，如GPT-3，使开发人员能够创建高级应用程序。当注册API时，用户会获得一个初始的标记使用限制，表示在特定时间范围内与语言模型进行交互的标记数量。随着用户的记录和使用增加，OpenAI可能会增加标记使用限制，为模型提供更多访问权限。如果用户需要更多标记来支持其应用程序，他们也可以请求配额增加。我们可以通过连接到OpenAI回调来跟踪OpenAI模型中的标记使用：
- en: '[PRE8]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'In this example, the line with `llm_chain` could be any usage of an OpenAI
    model. We should see an output with the costs and tokens.There are two other ways
    of getting the token usage. Alternative to the OpenAI Callback, the `generate()`
    method of the `llm` class returns a response of type `LLMResult` instead of string. This
    includes token usages and finish reason, for example (from the LangChain docs):'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，带有 `llm_chain` 的那一行可以是任何 OpenAI 模型的用法。 我们应该看到成本和令牌的输出。还有其他两种获得令牌使用情况的方法。
    除了 OpenAI 回调外，`llm` 类的 `generate()` 方法返回 `LLMResult` 类型的响应而不是字符串。 这包括令牌使用情况和完成原因，例如
    (来自 LangChain 文档)：
- en: '[PRE9]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The result looks like this:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 结果看起来像这样：
- en: '[PRE10]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Finally, the chat completions response format in the OpenAI API includes a
    usage object with token information, for example it could look like this (excerpt):'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，OpenAI API 中的聊天完成响应格式包括一个使用对象，其中包含令牌信息，例如可能看起来像这样的 (节选)：
- en: '[PRE11]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Next, we’ll look at how to extract certain pieces of information from documents
    using OpenAI functions with LangChain.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将看一下如何使用 OpenAI 函数和 LangChain 从文档中提取特定的信息。
- en: Extracting information from documents
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从文档中提取信息
- en: 'In June 2023, OpenAI announced updates to OpenAI''s API, including new capabilities
    for function calling, which opens up an enhanced functionality. Developers can
    now describe functions to the gpt-4-0613 and gpt-3.5-turbo-0613 models and have
    the models intelligently generate a JSON object containing arguments to call those
    functions. This feature aims to enhance the connection between GPT models and
    external tools and APIs, providing a reliable way to retrieve structured data
    from the models.Function calling enables developers to create chatbots that can
    answer questions using external tools or OpenAI plugins. It also allows for converting
    natural language queries into API calls or database queries, and extracting structured
    data from text. The mechanics of the update involve using new API parameters,
    namely `functions`, in the `/v1/chat/completions` endpoint. The functions parameter
    is defined through a name, description, parameters, and the function to call itself.
    Developers can describe functions to the model using JSON Schema and specify the
    desired function to be called. In LangChain, we can use these function calls in
    OpenAI for information extraction or for calling plugins. For information extraction,
    we can specific entities and their properties from a text and their properties
    from a document in an extraction chain with OpenAI chat models. For example, this
    can help identifying the people mentioned in the text. By using the OpenAI functions
    parameter and specifying a schema, it ensures that the model outputs the desired
    entities and properties with their appropriate types.The implications of this
    approach are that it allows for precise extraction of entities by defining a schema
    with the desired properties and their types. It also enables specifying which
    properties are required and which are optional.The default format for the schema
    is a dictionary, but we can also define properties and their types in Pydantic
    providing control and flexibility in the extraction process.Here’s an example
    for a desired schema for information in a Curricum Vitae (CV):'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 2023 年 6 月，OpenAI 宣布更新 OpenAI API，包括对函数调用的新功能，这将提供增强的功能。 开发人员现在可以向 gpt-4-0613
    和 gpt-3.5-turbo-0613 模型描述功能，并让模型智能生成包含调用这些功能的参数的 JSON 对象。此功能旨在增强 GPT 模型与外部工具和
    API 之间的连接，提供了一种可靠的方式来从模型中检索结构化数据。函数调用使开发人员能够创建使用外部工具或 OpenAI 插件回答问题的聊天机器人。 它还允许将自然语言查询转换为
    API 调用或数据库查询，并从文本中提取结构化数据。 更新的机制涉及使用新的 API 参数，即 `/v1/chat/completions` 终点的 `functions`。
    通过名称、描述、参数和要调用的功能本身对来定义函数。开发人员可以使用 JSON Schema 向模型描述功能，并指定要调用的所需功能。在 LangChain
    中，我们可以使用 OpenAI 中的这些函数调用进行信息提取或调用插件。 在信息提取中，我们可以使用 OpenAI 聊天模型中的提取链来指定实体及其属性从文本和文档中提取实体及其属性。
    例如，这有助于识别文本中提到的人。 通过使用 OpenAI 函数参数并指定模式，可以确保模型输出所需的实体和属性及其适当的类型。这种方法的意义在于它允许通过定义具有所需属性和类型的模式精确提取实体。
    它还能够指定哪些属性是必需的，哪些是可选的。模式的默认格式是字典，但我们还可以在 Pydantic 中定义属性及其类型，以控制和灵活提取过程。这是一个期望的用于
    Curricum Vitae（简历）中信息的模式示例：
- en: '[PRE12]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: We can use this for information extraction from a CV. Here’s an example CV from
    [https://github.com/xitanggg/open-resume](https://github.com/xitanggg/open-resume)
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以利用它来从简历中提取信息。这是来自[https://github.com/xitanggg/open-resume](https://github.com/xitanggg/open-resume)的示例简历。
- en: '![Figure 4.3: Extract of an example CV.](img/file29.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.3: 示例简历摘录](img/file29.png)'
- en: 'Figure 4.3: Extract of an example CV.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '图 4.3: 示例简历摘录'
- en: 'We are going to try to parse the information from this resume. Utilizing the
    `create_extraction_chain_pydantic()` function in LangChain, we can provide our
    schema as input, and an output will be an instantiated object that adheres to
    it. In its most simple terms, we can try this code snippet:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将尝试从这份简历中解析信息。利用LangChain中的`create_extraction_chain_pydantic()`函数，我们可以将我们的模式作为输入，并且输出将是一个符合该模式的实例化对象。简而言之，我们可以尝试以下代码片段：
- en: '[PRE13]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'We should be getting an output like this:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该会得到这样的输出：
- en: '[PRE14]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: It’s far from perfect - only one work experience gets parsed out. But it’s a
    good start given the little effort we’ve put in so far. Please see the example
    on Github for the full example. We could add more functionality, for example to
    guess personality or leadership capability.OpenAI injects these function calls
    into the system message in a certain syntax, which their models have been optimized
    for. This implies that functions count against the context limit and are correspondingly
    billed as input tokens. LangChain natively has functionality to inject function
    calls as prompts. This means we can use model providers other than OpenAI for
    function calls within LLM apps. We’ll look at this now, and we’ll build this into
    an interactive web-app with Streamlit.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 它离完美还差得远 - 只有一个工作经验被解析出来。但考虑到我们迄今为止所付出的少量工作，这是个不错的开始。请在Github上查看完整示例。我们可以添加更多功能，例如猜测个性或领导能力。OpenAI以特定语法将这些函数调用注入系统消息中，他们的模型已经针对此进行了优化。这意味着函数计入上下文限制，并相应地计入输入标记。LangChain本身具有将函数调用注入为提示的功能。这意味着我们可以在LLM应用程序中使用除OpenAI之外的模型提供者进行函数调用。我们现在将着眼于这一点，并将其构建成一个交互式Web应用程序与Streamlit。
- en: Answer questions with tools
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用工具回答问题
- en: LLMs are trained on general corpus data and may not be as effective for tasks
    that require domain-specific knowledge. On their own LLMs can’t interact with
    the environment and access external data sources, however, LangChain provides
    a platform for creating tools that access real-time information, and perform tasks
    such as weather forecasting, making reservations, suggesting recipes, and managing
    tasks. Tools within the framework of agents and chains allow for the development
    of applications powered by LLMs that are data-aware and agentic, and opens up
    a wide range of approaches to solving problems with LLMs, expanding their use
    cases and making them more versatile and powerful.One important aspect of tools
    is their capability to work within specific domains or process specific inputs.
    For example, an LLM lacks inherent mathematical capabilities. However, a mathematical
    tool like a calculator can accept mathematical expressions or equations as an
    input and calculate the outcome. The LLM combined with such a mathematical tool
    perform calculations and provide accurate answers.Generally, this combination
    of retrieval methods and LLMs is called **Retrieval Augmented Generation** (**RAG**),
    and addresses the limitations of LLMs by retrieving relevant data from external
    sources and injecting it into the context. This retrieved data serves as additional
    information to augment the prompts given to the LLMs.By grounding LLMs with use-case
    specific information through RAG, the quality and accuracy of responses are improved.
    Through retrieval of relevant data, RAG helps in reducing hallucinations responses
    from LLMs.For example, an LLM used in a healthcare application could retrieve
    relevant medical information from external sources such as medical literature
    or databases during inference. This retrieved data can then be incorporated into
    the context to enhance the generated responses and ensure they are accurate and
    aligned with domain-specific knowledge. The benefits of implementing RAG in this
    scenario are twofold. Firstly, it allows for incorporating up-to-date information
    into responses despite the model's training data cutoff date. This ensures that
    users receive accurate and relevant information even for recent events or evolving
    topics.Secondly, RAG enhances ChatGPT's ability to provide more detailed and contextual
    answers by leveraging external sources of information. By retrieving specific
    context from sources like news articles or websites related to a particular topic,
    the responses will be more accurate.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs是在一般语料库数据上进行训练的，可能对需要特定领域知识的任务效果不佳。单独使用LLMs不能与环境交互，并访问外部数据源，然而，LangChain提供了一个平台，用于创建访问实时信息并执行诸如天气预报、预订、建议菜谱和管理任务等任务的工具。代理和链中的工具允许开发由LLMs驱动的数据感知和代理性应用程序，并且为解决问题的各种方法提供了广泛的应用范围，扩展了它们的用例并使它们更加多样和强大。工具的一个重要方面是它们可以在特定领域内或处理特定的输入。例如，LLM缺乏固有的数学能力。然而，像计算器这样的数学工具可以接受数学表达式或方程作为输入并计算结果。LLM和这样的数学工具结合起来进行计算并提供准确答案。通常，这种检索方法和LLMs的组合被称为**检索增强生成**（**RAG**），并通过从外部源中检索相关数据并将其注入到背景中来解决LLMs的局限性。这些检索的数据作为增强提示给LLMs的附加信息。通过通过RAG用特定用例的信息根植LLMs，改善了响应的质量和准确性。通过检索相关数据，RAG有助于减少LLMs的错觉响应。例如，将LLM用于医疗应用程序，可以在推断期间从外部来源检索相关医学信息，如医学文献或数据库。然后，这些检索的数据可以被合并到上下文中，以增强生成的响应，并确保它们与特定领域的知识一致和准确。在这种情况下，实施RAG的好处是双重的。首先，即使模型的训练数据截止日期过去，它也允许将最新信息纳入响应中。这确保用户甚至对于最新事件或不断发展的主题都可以收到准确和相关的信息。其次，RAG通过利用来自新闻文章或与特定主题相关的网站等来源的具体上下文，增强了ChatGPT提供更详细和上下文的答案的能力。通过检索特定上下文的信息，响应将更加准确。
- en: 'RAG (Retrieval Augmented Generation) works by retrieving information from data
    sources to supplement the prompt given to the language model, providing the model
    with the needed context to generate accurate responses. RAG involves several steps:'
  id: totrans-93
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: RAG（检索增强生成）通过从数据源中检索信息，以补充提供给语言模型的提示，为模型提供所需的背景信息以生成准确的响应。RAG涉及几个步骤：
- en: '**Prompt**: The user provides a prompt to the chatbot, describing their expectations
    for the output.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**提示**: 用户向聊天机器人提供提示，描述他们对输出的期望。'
- en: '**Research**: A contextual search is performed and retrieves relevant information
    from various data sources. This could involve querying a database, searching indexed
    documents based on keywords, or invoking APIs to retrieve data from external sources.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**研究**：执行上下文搜索，并从各种数据源中检索相关信息。这可能涉及查询数据库，基于关键字搜索索引文档，或调用 API 从外部源检索数据。'
- en: '**Update Resource**: The retrieved context is injected into the original prompt,
    augmenting it with additional factual information related to the user''s query.
    This enhanced prompt improves accuracy as it provides access to factual data.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**更新资源**：检索到的上下文被注入到原始提示中，通过提供访问事实数据，增强提示，提高准确性。'
- en: '**Narrate**: Based on this augmented input, the LLM generates a response that
    includes factually correct information and sends it back to the chatbot for delivery
    to the user.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**叙述**：基于这个增强输入，LLM 生成包含事实正确信息的响应，并将其发送回聊天机器人以传递给用户。'
- en: 'Therefore, by combining external data sources and injecting relevant context
    into prompts, RAG enhances LLMs'' ability to generate responses that are accurate,
    up-to-date, and aligned with specific domains or topics of interest.An illustration
    of augmenting LLMs through tools and reasoning is shown here (source: https://github.com/billxbf/ReWOO,
    implementation for the paper “Decoupling Reasoning from Observations for Efficient
    Augmented Language Models Resources” by Binfeng Xu and others, May 2023):'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '因此，通过结合外部数据源并将相关上下文注入提示中，RAG 增强了 LLM 生成准确、最新并与特定领域或主题对齐的响应的能力。图示了通过工具和推理增强
    LLM 的过程（来源：https://github.com/billxbf/ReWOO，由 Binfeng Xu 等人于 2023 年 5 月编写的论文 “Decoupling
    Reasoning from Observations for Efficient Augmented Language Models Resources”
    的实现）:'
- en: '![Figure 4.4: Tool-augmented LM paradigm, leveraging foreseeable reasoning ability
    of language models to improve system parameter and prompt efficiency](img/file30.jpg)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.4：工具增强的语言模型范例，利用语言模型的可预见推理能力来提高系统参数和提示效率](img/file30.jpg)'
- en: 'Figure 4.4: Tool-augmented LM paradigm, leveraging foreseeable reasoning ability
    of language models to improve system parameter and prompt efficiency'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.4：工具增强的语言模型范例，利用语言模型的可预见推理能力来提高系统参数和提示效率
- en: 'Let’s see this in action!We have quite a few tools available in LangChain,
    and - if that’s not enough - it’s not hard to roll out our own tools. Let’s set
    up an agent with a few tools:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看这个实例！LangChain 中有很多可用的工具，而且 - 如果这还不够 - 自己开发工具也不难。让我们设置一个带有几个工具的代理：
- en: '[PRE15]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'It’s an important detail to know that an `AgentExecutor` is a chain, and therefore
    - if we wanted we could integrate it into a larger chain if we wanted. We could
    have initialized this chain using a different syntax like this:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 了解一个重要的细节是 `AgentExecutor` 是一个链，因此 - 如果我们想的话 - 我们可以将其集成到更大的链中。我们可以使用不同的语法初始化这个链，就像这样：
- en: '[PRE16]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'In this syntax, we would pass the tools as chain configurations. MRKL stands
    for Modular Reasoning, Knowledge and Language. The Zero-Shot Agent is the most
    general-purpose action agent in the MRKL framework.Please notice the parameter
    `streaming` in the `ChatOpenAI` constructor, which is set to `True`. This makes
    for a better use experience, since it means that the text response will be updated
    as it comes in, rather than once all the text has been completed. Currently only
    the OpenAI, ChatOpenAI, and ChatAnthropic implementations support streaming. All
    the tools mentioned have their specific purpose that’s part of the description,
    which is passed to the language model. These tools here are plugged into the agent:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种语法中，我们将工具传递为链配置。MRKL 代表模块化推理、知识和语言。零射击代理是 MRKL 框架中最通用的行动代理。请注意 `ChatOpenAI`
    构造函数中的参数 `streaming` 设置为 `True`。这样做可以提供更好的使用体验，因为它意味着文本响应将随着其到来而更新，而不是一次性完成所有文本。目前只有
    OpenAI、ChatOpenAI 和 ChatAnthropic 实现支持流式处理。所有提到的工具都有其特定的用途，这是描述的一部分，传递给语言模型。这些工具是插入到代理中的：
- en: DuckDuckGo - a search engine that focuses on privacy; an added advantage is
    that it doesn’t require developer signup
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DuckDuckGo - 一个注重隐私的搜索引擎；它的一个额外优势是不需要开发者注册。
- en: Wolfram Alpha - an integration that combines natural language understanding
    with math capabilities, for questions like “What is 2x+5 = -3x + 7?”
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wolfram Alpha - 一个结合了自然语言理解和数学能力的集成，用于像“2x+5 = -3x + 7？”这样的问题。
- en: Arxiv - search in academic pre-print publications; this is useful for research-oriented
    questions
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Arxiv - 搜索学术预印出版物；这对于研究导向的问题很有用。
- en: Wikipedia - for any question about entities of significant notoriety
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wikipedia - 有关任何有重要名声的实体的问题
- en: Please note that in order to use Wolfram Alpha, you have to set up an account
    and set the `WOLFRAM_ALPHA_APPID` environment variable with the developer token
    you create at [https://developer.wolframalpha.com/](https://developer.wolframalpha.com/)There
    are lot of other search tools integrated in LangChain apart from DuckDuckGo that
    let you utilize Google or Bing search engines or work with meta search engines.
    There’s an Open-Meteo - integration for weather information, however, this information
    is also available through search.Let’s make our agent available as a streamlit
    app.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，要使用 Wolfram Alpha，您必须设置一个帐户，并设置 `WOLFRAM_ALPHA_APPID` 环境变量，其中包含您在 [https://developer.wolframalpha.com/](https://developer.wolframalpha.com/)
    创建的开发者令牌。除了 DuckDuckGo 之外，LangChain 还集成了很多其他搜索工具，可以利用 Google 或 Bing 搜索引擎，或者使用元搜索引擎。还有一个用于天气信息的
    Open-Meteo 集成，但是这些信息也可以通过搜索获得。让我们将我们的 agent 设计为一个 streamlit 应用。
- en: '**Streamlit** is an open-source app framework for Machine Learning and Data
    Science teams. It allows users to create beautiful web apps in minutes using Python.'
  id: totrans-111
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**Streamlit**是一个面向机器学习和数据科学团队的开源应用程序框架。它允许用户使用Python在几分钟内创建美观的网络应用程序。'
- en: 'Let’s write the code for this using the `load_agent()` function we’ve just
    defined:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用我们刚刚定义的`load_agent()`函数编写代码：
- en: '[PRE17]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Please notice that we are using the callback handler in the call to the chain,
    which means that we’ll see responses as they come back from the model. We can
    start the app locally from the terminal like this:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们在调用链中使用回调处理程序，这意味着我们将在返回结果时立即看到响应。我们可以在终端上像这样本地启动应用：
- en: '[PRE18]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Deployment of Streamlit applications can be local or on a server. Alternatively,
    you can deploy this on the Streamlit Community Cloud or on Hugging Face Spaces.
  id: totrans-116
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Streamlit 应用程序的部署可以在本地或服务器上进行。或者，您可以在 Streamlit Community Cloud 上或 Hugging Face
    Spaces 上部署此应用程序。
- en: 'For **Streamlit Community Cloud** do this:'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于**Streamlit Community Cloud**，请执行以下操作：
- en: 1\. Create a Github repository
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1\. 创建一个 Github 存储库
- en: 2\. Go to Streamlit Community Cloud, click on "New app" and select the new repo
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 2\. 前往 Streamlit Community Cloud，点击“New app”，然后选择新的存储库
- en: 3\. Click "Deploy!"
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 3\. 点击“部署！”
- en: 'As for **Hugging Face Spaces** it works like this:'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 至于**Hugging Face Spaces**，它的工作原理如下：
- en: 1\. Create a Github repo
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1\. 创建一个 Github 仓库
- en: 2\. Create a Hugging Face account at https://huggingface.co/
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 2\. 在 https://huggingface.co/ 上创建一个 Hugging Face 账户
- en: 3\. Go to “Spaces” and click “Create new Space”. In the form, fill in a name,
    type of space as “Streamlit”, and choose the new repo.
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 3\. 前往“Spaces”，然后点击“Create new Space”。在表单中，填写一个名称，将空间类型设置为“Streamlit”，并选择新的存储库。
- en: 'Here’s a screenshot from the app looks:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 这是应用程序的截图：
- en: '![Figure 4.5: Question answering app in Streamlit.](img/file31.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![Figure 4.5: 在 Streamlit 中的问答应用程序。](img/file31.png)'
- en: 'Figure 4.5: Question answering app in Streamlit.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 'Figure 4.5: 在 Streamlit 中的问答应用程序。'
- en: 'The search works quite well, although depending on the tools used it might
    still come up with the wrong results. For the question about the mammal with the
    largest egg, using DuckDuckGo it comes back with a result that discusses eggs
    in birds and mammals, and sometimes concludes that the ostrich is the mammal with
    the largest egg, although Platypus also comes back sometimes. Here’s the log output
    (shortened) for the correct reasoning:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 搜索结果相当不错，尽管具体取决于所使用的工具，可能仍然会出现错误结果。对于关于拥有最大蛋的哺乳动物的问题，使用DuckDuckGo搜索会返回一篇讨论鸟类和哺乳动物蛋的文章，并有时得出鸵鸟是拥有最大蛋的哺乳动物的结论，尽管鸭嘴兽有时也会出现。以下是正确推理的日志输出（缩写版）：
- en: '[PRE19]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: You can see that with a powerful framework for automation and problem solving
    at your behest, you can compress work that can take hundreds of hours into minutes.
    You can play around with different research questions to see how the tools are
    used. The actual implementation in the repository for the book allows you to try
    out different tools, and has an option for self-verification.Retrieval Augmented
    Generation (RAG) with LLMs can significantly improve the accuracy and quality
    of responses by injecting relevant data from outside sources into the context.
    By grounding LLMs with use-case-specific knowledge, we can reduce hallucinations,
    and make them more useful in real-world scenarios. RAG is more cost-effective
    and efficient than retraining the models. You can see a very advanced example
    of augmented information retrieval with LangChain in the BlockAGI project, which
    is inspired by BabyAGI and AutoGPT, at [https://github.com/blockpipe/BlockAGI](https://github.com/blockpipe/BlockAGI)In
    the following sections, we’ll compare the main types of agents by their decision
    making strategies.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到，拥有一个强大的自动化和问题解决框架，你可以将需要数百小时才能完成的工作压缩到几分钟之内。你可以尝试不同的研究问题，以了解工具的使用方式。书籍仓库中的实际实现允许您尝试不同的工具，并提供了自验证选项。检索增强生成（RAG）与LLMs可以通过将来自外部来源的相关数据注入上下文中，显著提高响应的准确性和质量。通过用特定用例的知识基础来奠定LLMs的基础，我们可以减少幻觉，并使它们在真实世界情景中更有用。RAG比重新训练模型更具成本效益和效率。您可以在BlockAGI项目中看到使用LangChain的增强信息检索的非常高级的示例，该项目受到BabyAGI和AutoGPT的启发，网址为[https://github.com/blockpipe/BlockAGI](https://github.com/blockpipe/BlockAGI)。在接下来的几节中，我们将通过它们的决策制定策略来比较主要类型的代理。
- en: Reasoning strategies
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 推理策略
- en: 'The current generation of generative models like LLMs excel at finding patterns
    in real-world data, such as visual and audio information, and unstructured texts,
    however, they struggle with symbol manipulation operations required for tasks
    that involve structured knowledge representation and reasoning. Reasoning problems
    pose challenges for LLMs, and there are different reasoning strategies that can
    complement the pattern completion abilities inherent in neural networks that are
    generative models. By focusing on enabling symbol-manipulation operations on extracted
    information, these hybrid systems can enhance the capabilities of language models.**Modular
    Reasoning, Knowledge, and Language** (**MRKL**) is a framework that combines language
    models and tools to perform reasoning tasks. In LangChain this consists of three
    parts:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 当前一代的生成模型，如LLMs，擅长发现现实世界数据的模式，例如视觉和音频信息，以及非结构化文本，但是它们在涉及结构化知识表示和推理的任务所需的符号操作方面存在困难。推理问题对LLMs构成挑战，并且有不同的推理策略可以补充神经网络作为生成模型固有的模式完成能力。通过专注于在提取的信息上实现符号操作，这些混合系统可以增强语言模型的能力。**模块化推理，知识和语言**（**MRKL**）是一个结合语言模型和工具来执行推理任务的框架。在LangChain中，这包括三个部分：
- en: tools,
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 工具，
- en: an `LLMChain`, and
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个`LLMChain`，以及
- en: the agent itself.
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 代理本身。
- en: 'The tools are the available resources that the agent can use, such as search
    engines or databases. The LLMChain is responsible for generating text prompts
    and parsing the output to determine the next action. The agent class uses the
    output of the LLMChain to decide which action to take.We’ve discussed tool use
    strategies in *Chapter 2*, *Introduction to LangChain*. We can see the reasoning
    with observation pattern in this diagram:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 工具是代理可以使用的可用资源，如搜索引擎或数据库。LLMChain负责生成文本提示并解析输出以确定下一步操作。代理类使用LLMChain的输出来决定采取哪些行动。我们在*第2章*，*LangChain简介*中讨论了工具使用策略。我们可以在此图表中看到观察模式的推理：
- en: '![Figure 4.6: Reasoning with observation (source: https://arxiv.org/abs/2305.18323;
    Binfeng Xu and others, May 2023).](img/file32.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![图4.6：推理观察（来源：https://arxiv.org/abs/2305.18323；许滨峰等人，2023年5月）。](img/file32.png)'
- en: 'Figure 4.6: Reasoning with observation (source: https://arxiv.org/abs/2305.18323;
    Binfeng Xu and others, May 2023).'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.6：推理观察（来源：https://arxiv.org/abs/2305.18323；许滨峰等人，2023年5月）。
- en: '**Observation-dependent reasoning** involves making judgments, predictions,
    or choices based on the current state of knowledge or the evidence fetched through
    observation. In each iteration, the agent is providing a context and examples
    to a language model (LLM). A user''s task is first combined with the context and
    examples and given to the LLM to initiate reasoning. The LLM generates a thought
    and an action, and then waits for an observation from tools. The observation is
    added to the prompt to initiate the next call to the LLM. In LangChain, this is
    an **action agent** (also: **Zero-Shot Agent**, `ZERO_SHOT_REACT_DESCRIPTION`),
    which is the default setting when you create an agent.As mentioned, plans can
    also be made ahead of any actions. This strategy, in LangChain called the **plan-and-execute
    agent**, is illustrated in the diagram here:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '**依赖观察的推理**包括基于当前知识状态或通过观察获取的证据做出判断、预测或选择。在每次迭代中，代理向语言模型（LLM）提供上下文和示例。用户的任务首先与上下文和示例结合，然后交给LLM启动推理。LLM生成一个思考和一个动作，然后等待来自工具的观察。观察结果添加到提示中以启动下一次对LLM的调用。在LangChain中，这是一个**行动代理**（也称为**零-shot
    代理**， `ZERO_SHOT_REACT_DESCRIPTION`），这是创建代理时的默认设置。正如提到的，计划也可以在任何操作之前制定。在LangChain中称为**计划和执行代理**的策略在这里示例化：'
- en: '![Figure 4.7: Decoupling Reasoning from Observations (source: https://arxiv.org/abs/2305.18323;
    Binfeng Xu and others, May 2023).](img/file33.png)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.7: 从观察中分离推理（来源：https://arxiv.org/abs/2305.18323；许彬锋等人，2023年5月）。](img/file33.png)'
- en: 'Figure 4.7: Decoupling Reasoning from Observations (source: https://arxiv.org/abs/2305.18323;
    Binfeng Xu and others, May 2023).'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '图 4.7: 从观察中分离推理（来源：https://arxiv.org/abs/2305.18323；许彬锋等人，2023年5月）。'
- en: 'The planner (an LLM), which can be fine-tuned for planning and tool usage,
    produces a list of plans (P) and calls a worker (in LangChain: the agent) to gather
    evidence (E) through using tools. P and E are combined with the task, and then
    fed into the Solver (an LLM) for the final answer. We can write a pseudo algorithm
    like this:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 规划器（一个LLM）可以针对规划和工具使用进行微调，产生一个计划列表（P）并调用一个工作者（在LangChain中：代理）通过使用工具来收集证据（E）。P和E与任务结合，然后传递给求解器（一个LLM）得出最终答案。我们可以编写一个伪算法如下：
- en: Plan out all the steps (Planner)
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 规划所有步骤（规划器）
- en: 'For step in steps:'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于步骤中的每一步：
- en: Determine the proper tools to accomplish the step
  id: totrans-145
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确定完成步骤所需的适当工具
- en: 'The Planner and the Solver can be distinct language models. This opens up the
    possibility of using smaller, specialized models for Planner and Solver, and using
    fewer tokens for each of the calls.We can implement plan-and-solve in our research
    app, let’s do it!First, let’s add a `strategy` variable to the `load_agent()`
    function. It can take two values, either “plan-and-solve” or “one-shot-react”.
    For “one-shot-react”, the logic stays the same. For “plan-and-solve”, we’ll define
    a planner and an executor, which we’ll use to create a `PlanAndExecute` agent
    executor:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 规划器和求解器可以是不同的语言模型。这样就可以使用更小、更专业的规划器和求解器模型，并针对每次调用使用更少的标记。我们可以在我们的研究应用程序中实现计划和求解，让我们做吧！首先，让我们向`load_agent()`函数添加一个`strategy`变量。它可以取两个值，即“plan-and-solve”或“one-shot-react”。对于“one-shot-react”，逻辑保持不变。对于“plan-and-solve”，我们将定义一个规划器和一个执行器，我们将使用它们来创建一个`PlanAndExecute`代理执行器：
- en: '[PRE20]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'For the sake of brevity, I’ve omitted imports that we had already earlier.Let’s
    define a new variable that’s set through a radio button in Streamlit. We’ll pass
    this variable over to the `load_agent()` function:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简洁起见，我省略了我们之前已有的导入操作。让我们定义一个通过 Streamlit 中的单选按钮设置的新变量。我们将把这个变量传递给`load_agent()`函数：
- en: '[PRE21]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'You might have noticed that the `load_agent()` take a list of strings, `tool_names`.
    This can be chosen in the user interface (UI) as well:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能注意到`load_agent()`接受一个字符串列表`tool_names`。这也可以在用户界面（UI）中选择：
- en: '[PRE22]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Finally, still in the app, the agent is loaded like this:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在应用程序中，代理如下加载：
- en: '[PRE23]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'We can see the UI here:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在这里看到UI：
- en: '![Figure 4.8: Implementing plan-and-execute in our research app.](img/file34.png)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.8: 在我们的研究应用程序中实现计划和执行。](img/file34.png)'
- en: 'Figure 4.8: Implementing plan-and-execute in our research app.'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '图 4.8: 在我们的研究应用程序中实现计划和执行。'
- en: 'Please have a look at the app and see the different steps for the question
    “What is a plan and solve agent in the context of large language models?”. Just
    briefly, the first step, the plan looks as follows:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 请查看应用程序，并查看关于“在大型语言模型的背景下什么是计划和求解代理”的不同步骤。简单地说，第一步，计划如下：
- en: 'Define large language models: Large language models are AI models that are
    trained on vast amounts of text data and can generate human-like text based on
    the input they receive.'
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义大型语言模型：大型语言模型是经过大量文本数据训练的人工智能模型，可以根据其接收到的输入生成类似人类的文本。
- en: 'Understand the concept of a plan in the context of large language models: In
    the context of large language models, a plan refers to a structured outline or
    set of steps that the model generates to solve a problem or answer a question.'
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在大型语言模型的背景下理解计划的概念：在大型语言模型的背景下，计划是指模型生成的解决问题或回答问题的结构化大纲或一组步骤。
- en: 'Understand the concept of a solve agent in the context of large language models:
    A solve agent is a component of a large language model that is responsible for
    generating plans to solve problems or answer questions.'
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在大型语言模型的背景下理解求解代理的概念：求解代理是大型语言模型的组成部分，负责生成解决问题或回答问题的计划。
- en: 'Recognize the importance of plans and solve agents in large language models:
    Plans and solve agents help organize the model''s thinking process and provide
    a structured approach to problem-solving or question-answering tasks.'
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 认识到计划和求解代理在大型语言模型中的重要性：计划和求解代理有助于组织模型的思维过程，并为解决问题或回答问题的任务提供了结构化方法。
- en: 'Given the above steps taken, please respond to the user''s original question:
    In the context of large language models, a plan is a structured outline or set
    of steps generated by a solve agent to solve a problem or answer a question. A
    solve agent is a component of a large language model that is responsible for generating
    these plans.'
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 给出以上所采取的步骤后，请回答用户的原始问题：在大型语言模型的背景下，计划是由求解代理生成的结构化大纲或一组步骤，用于解决问题或回答问题。求解代理是大型语言模型的组成部分，负责生成这些计划。
- en: 'Accordingly, the first step is to perform a look up of LLMs:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，第一步是执行LLMs的查找：
- en: '[PRE24]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: We didn’t discuss another aspect of this, which is the prompting strategy used
    in these steps. For example, different prompting strategies offer ways to address
    challenges in complex reasoning problems for LLMs. One approach is **few-shot
    chain-of-thought** (**CoT**) prompting, where LLMs are guided through step-by-step
    reasoning demonstrations. For example, in arithmetic reasoning, an LLM can be
    shown demonstration examples of solving equations to aid its understanding of
    the process.Another strategy is **zero-shot-CoT** prompting, which eliminates
    the need for manual demonstrations. Instead, a generic prompt like "Let's think
    step by step" is appended to the problem statement provided to the LLM. This allows
    the model to generate reasoning steps without prior explicit examples. In arithmetic
    reasoning, the problem statement could be augmented with this prompt and fed into
    an LLM.**Plan-and-Solve (PS) prompting**, involves dividing a complex task into
    smaller subtasks and executing them step by step according to a plan. For instance,
    in math reasoning problems like solving equations or word problems involving multiple
    steps, PS prompting enables an LLM to devise a plan for approaching each sub step,
    such as extracting relevant variables and calculating intermediate results.To
    further enhance the quality of reasoning steps and instructions, **PS+** prompting
    is introduced. It includes more detailed instructions, such as emphasizing the
    extraction of relevant variables and considering calculation and commonsense.
    PS+ prompting ensures that the LLMs have a better understanding of the problem
    and can generate accurate reasoning steps. For example, in arithmetic reasoning,
    PS+ prompting can guide the LLM to identify key variables, perform calculations
    correctly, and apply commonsense knowledge during the reasoning process.This concludes
    our discussion of reasoning strategies. All strategies have their problems with
    can manifest as calculation errors, missing-step errors, and semantic misunderstandings.
    However, they help improve the quality of generated reasoning steps, increase
    accuracy in problem-solving tasks, and enhance LLMs' ability to handle various
    types of reasoning problems.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 我们没有讨论这个问题的另一个方面，即在这些步骤中使用的提示策略。例如，不同的提示策略提供了解决LLM复杂推理问题挑战的方法。一种方法是**few-shot
    chain-of-thought**（**CoT**）提示，其中LLM通过逐步推理演示进行引导。例如，在算术推理中，可以向LLM展示解方程的示例演示，以帮助其理解过程。另一种策略是**zero-shot-CoT**提示，它消除了手动演示的需要。而是，将类似“让我们逐步思考”这样的通用提示附加到提供给LLM的问题陈述中。这使模型能够在没有先前明确示例的情况下生成推理步骤。在算术推理中，问题陈述可以附加这个提示并输入LLM。**Plan-and-Solve
    (PS)提示**，涉及将复杂任务分解为较小的子任务，并根据计划逐步执行它们。例如，在解方程或涉及多个步骤的单词问题的数学推理问题中，PS提示使LLM能够为接近每个子步骤制定计划，如提取相关变量和计算中间结果。为了进一步提高推理步骤和指导的质量，引入了**PS+**提示。它包括更详细的说明，如强调提取相关变量并考虑计算和常识。PS+提示确保LLM更好地理解问题并能够生成准确的推理步骤。例如，在算术推理中，PS+提示可以指导LLM识别关键变量，正确执行计算，并在推理过程中应用常识知识。这结束了我们对推理策略的讨论。所有策略都存在问题，可能表现为计算错误、缺少步骤错误和语义误解。然而，它们有助于提高生成的推理步骤的质量，增加问题解决任务的准确性，并增强LLM处理各种类型推理问题的能力。
- en: Summary
  id: totrans-166
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we’ve talked about the problem of hallucinations, automatic
    fact-checking, and how to make LLMs more reliable. Of particular emphasis were
    tools and prompting strategies. We’ve first looked at and implemented prompting
    strategies to break down and summarize documents. This can be very helpful for
    digesting large research articles or analyses. Once we get into making a lot of
    chained calls to LLMs, this can mean we incur a lot of costs. Therefore, I’ve
    dedicated a section to token usage.Tools provide creative solutions to problems
    and open up new possibilities for LLMs in various domains. For example, a tool
    could be developed to enable an LLM to perform advanced retrieval search, query
    a database for specific information, automate email writing, or even handle phone
    calls.The OpenAI API implements functions, which we can use, among other things,
    for information extraction in documents. We’ve implemented a very simple version
    of a CV parser as an example of this functionality.Tools and function calling
    is not unique to OpenAI, however. With Streamlit, we can implement different agents
    that call tools. We’ve implemented an app that can help answer research questions
    by relying on external tools such as search engines or Wikipedia.We’ve then looked
    at different strategies employed by the agents to make decisions. The main distinction
    is the point of decision making. We’ve implemented a plan-and-solve and a one-shot
    agent into a Streamlit app.I hope this goes to show that in a few lines we can
    implement apps that can be very impressive in a few cases. It’s important to be
    clear, however, that the apps developed in this chapter have limitations. They
    can help you significantly increase your efficiency, however, you - as the human
    - have to apply judgment and improve the writing to make sure it’s coherent and
    makes sense.Let’s see if you remember some of the key takeaways from this chapter!
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们谈到了幻觉问题，自动事实核查以及如何使LLMs更加可靠。工具和提示策略特别受到强调。我们首先查看并实施了提示策略，以分解和总结文档。这对于消化大型研究文章或分析非常有帮助。一旦我们开始大量调用LLMs，这就意味着我们会产生很多成本。因此，我专门为令牌使用分配了一节。工具为LLMs在各个领域提供了创造性的解决方案，并开辟了新的可能性。例如，可以开发一个工具，使LLM能够执行高级检索搜索，查询数据库以获取特定信息，自动编写电子邮件，甚至处理电话。OpenAI
    API实现了我们可以使用的功能，其中包括在文档中进行信息提取等。我们已经实现了一个非常简单的CV解析器版本，作为此功能的示例。但是，工具和函数调用并不是OpenAI的特有功能。通过Streamlit，我们可以实现调用工具的不同代理。我们已经实现了一个应用程序，可以通过依赖外部工具（如搜索引擎或维基百科）来回答研究问题。然后，我们查看了代理使用的不同策略来做出决策。主要区别在于决策点。我们将一个计划和解决代理实施到了Streamlit应用程序中。我希望这能表明，在几行代码中，我们可以实现在几种情况下非常令人印象深刻的应用程序。然而，重要的是要明确，本章中开发的应用程序具有局限性。它们可以帮助您显著提高效率，但是您
    - 作为人类 - 必须运用判断力并改进写作，以确保其连贯和合理。让我们看看您是否记得本章的一些关键要点！
- en: Questions
  id: totrans-168
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: 'Please have a look to see if you can come up with the answers to these questions
    from memory. I’d recommend you go back to the corresponding sections of this chapter,
    if you are unsure about any of them:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 请看一下，看看你能否从记忆中得出这些问题的答案。如果对任何一个不确定，请返回本章的相应部分：
- en: What is a hallucination?
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是幻觉？
- en: How does automated fact-checking work?
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 自动事实核查是如何工作的？
- en: What can we do in LangChain to make sure the output is valid?
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 LangChain 中，我们可以采取什么措施来确保输出有效？
- en: What is map-reduce in LangChain?
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: LangChain 中的map-reduce是什么？
- en: How can we count the tokens we are using (and why should we)?
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们如何统计我们使用的令牌数量（以及为什么应该这样做）？
- en: What does RAG stand for and what are the advantages of using it?
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: RAG 代表什么，使用它有什么优势？
- en: What tools are available in LangChain?
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: LangChain 中有哪些工具可用？
- en: Please define plan-and-solve agents
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 请定义计划和解决代理
- en: Please define one-shot agents
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 请定义一次性代理
- en: How can we implement text input fields and radio buttons in Streamlit?
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们如何在 Streamlit 中实现文本输入字段和单选按钮？
