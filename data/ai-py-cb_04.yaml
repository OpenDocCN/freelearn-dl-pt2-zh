- en: Probabilistic Modeling
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: 概率建模
- en: This chapter is about uncertainty and probabilistic approaches. State-of-the-art
    machine learning systems have two significant shortcomings.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章讨论不确定性和概率方法。现代机器学习系统存在两个显著的缺点。
- en: First of all, they can be overconfident (or sometimes underconfident) in their
    prediction. In practice, given noisy data, even if we observe the best practice
    of cross-validating with unseen datasets, this confidence might not be warranted. Especially
    in regulated or sensitive environments, such as in financial services, healthcare,
    security, and intelligence, we need to be very careful about our predictions and
    how accurate they are.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，它们在预测中可能过于自信（有时过于不自信）。在实践中，鉴于嘈杂的数据，即使我们观察到使用未见数据集进行交叉验证的最佳实践，这种信心也可能不合理。特别是在受监管或敏感环境中，如金融服务、医疗保健、安全和情报领域，我们需要非常谨慎地对待我们的预测及其准确性。
- en: Secondly, the more complex a machine learning system is, the more data we need
    to fit our model, and the more severe the risk of overfitting.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，机器学习系统越复杂，我们需要更多的数据来拟合我们的模型，过拟合的风险也越严重。
- en: Probabilistic models are models that produce probabilistic inferences using
    stochastic sampling techniques. By parametrizing distributions and inherent uncertainties,
    we can overcome these problems and obtain accuracies that would otherwise take
    more data without these assumptions.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 概率模型是使用随机采样技术产生概率推断的模型。通过参数化分布和固有的不确定性，我们可以克服这些问题，并获得否则需要更多数据才能获得的准确性。
- en: In this chapter, we'll build a stock-price prediction model with different plug-in
    methods for confidence estimation. We'll then cover estimating customer lifetime,
    a common problem in businesses that serve customers.We'll also look at diagnosing
    a disease, and we'll quantify credit risk, taking into account different types
    of uncertainty.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用不同的插件方法建立股票价格预测模型，并进行置信度估计。然后，我们将涵盖估计客户生命周期，这是为服务客户的企业所共有的问题。我们还将研究诊断疾病，并量化信用风险，考虑不同类型的不确定性。
- en: 'This chapter covers the following recipes:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖以下配方：
- en: Predicting stock prices with confidence
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以信心预测股票价格
- en: Estimating customer lifetime value
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 估算客户生命周期价值
- en: Diagnosing a disease
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 诊断疾病
- en: Stopping credit defaults
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阻止信用违约
- en: Technical requirements
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'In this chapter, we mainly use the following:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们主要使用以下内容：
- en: scikit-learn, as before
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如前所述的 scikit-learn
- en: Keras, as before
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如前所述的 Keras
- en: Lifetimes ([https://lifetimes.readthedocs.io/](https://lifetimes.readthedocs.io/)),
    a library for customer lifetime value
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lifetimes ([https://lifetimes.readthedocs.io/](https://lifetimes.readthedocs.io/))，用于客户生命周期价值的库
- en: '`tensorflow-probability` (**tfp**; [https://www.tensorflow.org/probability](https://www.tensorflow.org/probability))'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tensorflow-probability` (**tfp**; [https://www.tensorflow.org/probability](https://www.tensorflow.org/probability))'
- en: You'll find the code for this chapter on GitHub at [https://github.com/PacktPublishing/Artificial-Intelligence-with-Python-Cookbook/tree/master/chapter04](https://github.com/PacktPublishing/Artificial-Intelligence-with-Python-Cookbook/tree/master/chapter04).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在 GitHub 上找到本章的代码，链接为 [https://github.com/PacktPublishing/Artificial-Intelligence-with-Python-Cookbook/tree/master/chapter04](https://github.com/PacktPublishing/Artificial-Intelligence-with-Python-Cookbook/tree/master/chapter04)。
- en: Predicting stock prices with confidence
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 以信心预测股票价格
- en: 'The efficient market hypothesis postulates that at any given time, stock prices
    integrate all information about a stock, and therefore, the market cannot be consistently
    outperformed with superior strategy or, more generally, better information. However,
    it can be argued that current practice in investment banking, where machine learning
    and statistics are built into algorithmic trading systems, contradicts this. But
    these algorithms can fail, as seen in the 2010 flash crash or when systemic risks
    are underestimated, as discussed by Roger Lowenstein in his book *When Genius
    Failed: The Rise and Fall of Long-Term Capital Management*.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 有效市场假说假定在任何给定时间，股票价格集成了关于股票的所有信息，因此市场不能通过优越的策略或更一般地说更好的信息持续超越。然而，可以争论说当前在投资银行实践中，机器学习和统计被构建到算法交易系统中，这与之相矛盾。但这些算法可能会失败，正如2010年的闪电崩盘或系统风险被低估时所见，Roger
    Lowenstein 在他的书 *当天才失败时：长期资本管理的兴衰* 中讨论过。
- en: In this recipe, we'll build a simple stock prediction pipeline in scikit-learn,
    and we'll produce probability estimates using different methods. We'll then evaluate
    our different approaches.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将在scikit-learn中构建一个简单的股票预测管道，并使用不同的方法生成概率估计。然后，我们将评估我们的不同方法。
- en: Getting ready
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备好
- en: We'll retrieve historical stock prices using the `yfinance` library.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用`yfinance`库检索历史股票价格。
- en: 'Here''s how we install it:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们安装它的方式：
- en: '[PRE0]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '`yfinance` will help us to download historical stock prices.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '`yfinance` 将帮助我们下载历史股票价格。'
- en: How to do it...
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做到...
- en: 'In a practical setting, we''d want to answer the following question: given
    the level of prices, are they going to rise or to fall, and how much?'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际情况中，我们希望回答以下问题：在价格水平给定的情况下，它们会上涨还是下跌，以及幅度如何？
- en: 'In order to make progress toward this goal, we''ll proceed with the following
    steps:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 为了朝着这个目标取得进展，我们将按以下步骤进行：
- en: Download stock prices.
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载股票价格。
- en: Create a featurization function.
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个特征化函数。
- en: Write an evaluation function.
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编写一个评估函数。
- en: Train models to predict stocks and compare performance.
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练模型来预测股票并比较性能。
- en: 'Particularly, we''ll compare the following methods for generating confidence
    values:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 特别地，我们将比较以下生成置信度值的方法：
- en: Platt scaling
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Platt缩放
- en: Naive Bayes
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 朴素贝叶斯
- en: Isotonic regression
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 保序回归
- en: We'll discuss these methods and their background in the *How it works...* section.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将讨论这些方法及其背景在*它是如何工作...*部分。
- en: Let's give it a go!
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们试一下！
- en: '**Download stock prices**: We''ll download Microsoft''s prices:'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**下载股票价格**：我们将下载微软的价格：'
- en: '[PRE1]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Now we have our stock prices available as the `pandas` DataFrame `hist`.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有我们的股票价格作为`pandas` DataFrame `hist`可用。
- en: '**Create a featurization function**: So, let''s start with a function that
    will give us a dataset for training and prediction given a window size and a shift;
    basically, how many descriptors we want for each price and how far we look into the
    future:'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**创建一个特征化函数**：所以，让我们从一个函数开始，这个函数将为我们提供一个训练和预测的数据集，给定一个窗口大小和一个移动；基本上，我们想要为每个价格获取多少描述符，并且我们要看多远的未来：'
- en: '[PRE2]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We''ll then use our new function, `generate_data()`, to generate our training
    and testing datasets:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将使用我们的新函数`generate_data()`生成我们的训练和测试数据集：
- en: '[PRE3]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'This is a common pattern, of course, and we''ve seen this a few times by now
    in recipes leading up to this: we generate our dataset, and then split it into
    training and validation sets, where the training set is used (as the name suggests)
    for training, and the validation set is used for checking how well our algorithm
    works (in particular, whether we''ve overfitted).'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，这是一个常见的模式，我们在前面的示例中已经见过几次了：我们生成我们的数据集，然后将其拆分为训练和验证集，其中训练集用于训练（正如其名称所示），验证集用于检查我们的算法的工作效果（特别是我们是否过度拟合）。
- en: 'Our datasets are approximately normally distributed. Here''s what our target
    looks like in training:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的数据集大致符合正态分布。这是我们在训练中目标的样子：
- en: '![](img/a83b4d6a-f269-4d16-bb44-df809c3b2699.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a83b4d6a-f269-4d16-bb44-df809c3b2699.png)'
- en: We can see that there's a skew to the left, in the sense that more values are
    below zero (about 49%) than above (about 43%). This means that in training, prices
    go down rather than up.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到有一个向左的偏斜，即比零更多的值在下方（大约49%）而不是在上方（大约43%）。这意味着在训练中，价格会下降而不是上涨。
- en: 'We are not done with our dataset yet, however; we need to do one more transformation.
    Our scenario is that we want to apply this model to help us decide whether to
    buy a stock on the chance that prices are going up. We are going to separate three
    different classes:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的数据集还没有完成，但是我们需要进行另一次转换。我们的场景是，我们想应用这个模型来帮助我们决定是否购买股票，假设价格会上涨。我们将分离三个不同的类别：
- en: Prices go up by *x*.
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 价格上涨了 *x*。
- en: Prices stay the same.
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 价格保持不变。
- en: Prices go down by *x*.
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 价格下降了 *x*。
- en: 'In the following code block, we apply this cutoff by `x` given the `threshold`
    parameter:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的代码块中，我们根据`threshold`参数应用了`x`给定的截止值：
- en: '[PRE4]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: After this, we have the thresholded *y* values for training and testing (validation).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在此之后，我们对训练和测试（验证）的阈值化 *y* 值进行了处理。
- en: '**Write an evaluation function**: This is to measure our performance at predicting
    stock prices with a given model. For the evaluation, we need a helper function
    to convert from integer encoding into one-hot encoding.'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**编写一个评估函数**：这是为了衡量我们在使用给定模型预测股票价格时的性能。对于评估，我们需要一个帮助函数，将整数编码转换为一位有效编码。'
- en: 'In the evaluation, we calculate and print the **Area Under the Curve** (**AUC**)
    as the performance measure. We create a function, `measure_perf()`, which measures
    performance and prints out relevant metrics, given a model such as this:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在评估中，我们计算并打印**曲线下面积**（**AUC**）作为性能指标。我们创建了一个函数，`measure_perf()`，用于测量性能并打印相关指标，给定像这样的模型：
- en: '[PRE5]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: We can use our new method now to evaluate the performance after training our
    models.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以使用我们的新方法来评估模型训练后的性能。
- en: '**Train models to predict sto****cks and compare performance**: We''ll now
    compare the following methods to generate probabilistic outcomes from our three
    models, the first two of which we can implement quickly:'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**训练模型以预测股票并比较性能**：我们现在将比较以下方法，以从我们的三个模型中生成概率结果，前两种我们可以快速实现：'
- en: '[PRE6]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'For Naive Bayes, we try different variants: categorical Naive Bayes and complement
    Naive Bayes:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 对于朴素贝叶斯，我们尝试不同的变体：分类朴素贝叶斯和补集朴素贝叶斯：
- en: '[PRE7]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: We find that neither Platt scaling (logistic regression) nor isotonic regression
    can deal well with our dataset. Naive Bayes regression doesn't get much better
    than 50%, which is nothing that we'd want to bet our money on, even if it's slightly
    better than random choice. However, the complement Naive Bayes classifier performs
    much better, at 59% AUC.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们发现，无论是Platt缩放（逻辑回归）还是等渗回归都无法很好地处理我们的数据集。朴素贝叶斯回归不比随机选择好多少，这让我们不愿意拿来押注，即使稍微比随机选择好一点。然而，补集朴素贝叶斯分类器的表现要好得多，达到了59%的AUC。
- en: How it works...
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理...
- en: We've seen that we can create a predictor for stock prices. We've broken this
    down into creating data, and validating and training a model. In the end, we found
    a method that would give us hope that we could actually use it in practice.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到，我们可以创建一个股票价格预测器。我们将这个过程分解为创建数据、验证和训练模型。最终，我们找到了一种方法，可以让我们对其实际使用抱有希望。
- en: Let's go through our data generation first, and then over our different methods.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先生成数据，然后再使用我们的不同方法。
- en: Featurization
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 特征化
- en: This is central to any work in artificial intelligence. Before doing any work
    or the first we look at our dataset, we should ask ourselves what we choose as
    the unit of our observational units, and how are we going to describe our points
    in a way that's meaningful and can be captured by an algorithm. This is something
    that becomes automatic with experience.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这对于任何人工智能工作都是至关重要的。在处理任何工作或首次查看数据集之前，我们应该问自己我们选择什么作为我们观察单位的单元，并且我们如何以有意义且可以被算法捕捉的方式描述我们的数据点。这是一种随着经验变得自动化的事情。
- en: In our `generate_data()` function, we extract a dataset for training and testing
    from stock price history data. We are focused on predicting individual prices,
    so our observational unit is a single stock price. For each price, we need to
    extract features, other prices running up to it. We extract prices across a time
    period that can help us predict future values. To be more precise, we don't use
    prices directly; we have to normalize them first, so it's better to refer to them
    as price levels rather than prices.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的`generate_data()`函数中，我们从股票价格历史数据中提取了用于训练和测试的数据集。我们专注于预测单个价格，因此我们的观察单元是单个股票价格。对于每个价格，我们需要提取特征，即其他价格。我们跨越时间段提取价格，这可以帮助我们预测未来的值。更准确地说，我们不直接使用价格；我们必须先对其进行归一化，因此最好将其称为价格水平而不是价格。
- en: Using our method, we parametrize our data for predictions with different time
    horizons and a number of points. The price level is extracted over a window, a
    period of days (features). Finally, a price level, some days later, is to be predicted
    (targets). The time period and the shift are our two additional parameters: `window_size` and
    `shift`. This function returns *x*, the history of stock prices with their window,
    and *y*, the stock prices in the future to be predicted.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 使用我们的方法，我们为预测参数化我们的数据，不同的时间视野和一些点。价格水平是在一个窗口内提取的，一段时间内的天数（特征）。最后，将来的价格水平将被预测（目标）。时间段和偏移是我们的两个额外参数：`window_size`
    和 `shift`。该函数返回*x*，包含其窗口内的股票价格历史，以及*y*，未来要预测的股票价格。
- en: There are more concerns that we have to address. We've already seen a few methods
    for data treatment in time series, in the *Forecasting CO2 time series *recipe in [Chapter
    2](bca59029-1915-4856-b47d-6041d7b10a0a.xhtml), *Advanced Topics in Supervised
    Machine Learning*. In particular, stationarity and normalization are concerns
    that are shared in this recipe as well (you might want to flip back and have a
    look at the explanation there).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 还有更多问题需要解决。我们已经看到了在时间序列数据处理中的一些方法，在《预测 CO2 时间序列》这一章节的《高级监督学习主题》中。特别是在这个配方中，平稳性和标准化也是需要考虑的问题（你可能想要翻回去看看那里的解释）。
- en: Features are normalized to a mean of 0 and then differenced (each value in a
    window to the previous values) as a percentage change. The differencing step is
    done to introduce a measure of stationarity. Particularly, the target is expressed
    as the percentage change with respect to the last value in the window, the features.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 特征被标准化为平均值为0，然后作为百分比变化差异（每个窗口中的每个值到前一个值的差异）。差异步骤是为了引入平稳性度量。特别地，目标被表达为相对于窗口中最后一个值的百分比变化，即特征。
- en: We'll look next at Platt scaling, which is one of the simplest ways of scaling
    model predictions to get probabilistic outcomes.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来我们将看一下 Platt 缩放，这是一种将模型预测缩放为概率输出的最简单方法之一。
- en: Platt scaling
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Platt 缩放
- en: 'Platt scaling (John Platt, 1999, *Probabilistic outputs for support vector
    machines and comparisons to regularized likelihood methods*)is the first method
    of scaling model outcomes that we''ve used. Simply stated, it''s applying logistic
    regression on top of our classifier predictions. The logistic regression can be
    expressed as follows (equation 1):'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: Platt 缩放（John Platt，1999年，*支持向量机的概率输出及其与正则化似然方法的比较*）是我们使用的第一种模型结果缩放方法。简单来说，它是在我们的分类器预测之上应用逻辑回归。逻辑回归可以表达为以下形式（方程式
    1）：
- en: '![](img/a8bb44b8-5c40-4b62-ba68-40e22e58ecd1.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a8bb44b8-5c40-4b62-ba68-40e22e58ecd1.png)'
- en: Here, *A* and *B* are learned by a maximum likelihood method.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的 *A* 和 *B* 是通过最大似然方法学习得到的。
- en: 'We are searching for *A* and *B*, as follows:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在寻找 *A* 和 *B*，如下所示：
- en: '![](img/60701421-a469-4223-bf9c-e64e0301f5b1.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](img/60701421-a469-4223-bf9c-e64e0301f5b1.png)'
- en: Here *p* refers to the preceding equation 1.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的 *p* 指的是前述的方程式 1。
- en: 'As a gradient descent, we can iteratively apply the following two steps:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 作为梯度下降，我们可以迭代应用以下两个步骤之一：
- en: Calculate the gradient as the differential of the likelihood function.
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算梯度作为似然函数的微分。
- en: Update the parameters according to the gradient scaled by the learning rate.
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据学习速率缩放的梯度来更新参数。
- en: In the next subsection, we'll look at an alternative method of probabilistic
    calibration using isotonic regression.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的小节中，我们将探讨使用保序回归进行概率校准的替代方法。
- en: Isotonic regression
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 保序回归
- en: Isotonic regression (Zadrozny and Elkan, 2001, *Learning and Making Decisions
    When Costs and Probabilities are Both Unknown*) is regression using an isotonic
    function – that is, a function that is monotonically increasing or non-decreasing,
    as a function approximation while minimizing the mean squared error.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 保序回归（Zadrozny 和 Elkan，2001年，*当成本和概率均未知时的学习和决策*）是使用保序函数进行回归的方法，即作为函数逼近时，最小化均方误差的同时保持单调递增或非减。
- en: 'We can express this as follows:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以表达为以下形式：
- en: '![](img/0e701b1b-264f-4b03-9367-131f6e8f1b33.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0e701b1b-264f-4b03-9367-131f6e8f1b33.png)'
- en: Here *m* is our isotonic function, *x* and *y* are features and target, and *f* is
    our classifier.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 这里 *m* 是我们的保序函数，*x* 和 *y* 是特征和目标，*f* 是我们的分类器。
- en: Next, we'll look at one of the simplest probabilistic models, Naive Bayes.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将看一个最简单的概率模型之一，朴素贝叶斯。
- en: Naive Bayes
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 朴素贝叶斯
- en: The Naive Bayes classifier is based on the Bayes theorem.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 朴素贝叶斯分类器基于贝叶斯定理。
- en: 'The Bayes theorem is about the conditional probability of an event *A* occurring
    given *B*:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯定理是关于条件概率的定理，表示事件 *A* 发生在 *B* 给定的条件下：
- en: '![](img/aa00e9f2-b71b-4673-b893-29dc19e48fbf.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](img/aa00e9f2-b71b-4673-b893-29dc19e48fbf.png)'
- en: '*P(A)* is the probability of observing *A* (marginal probability of *A*). Given
    the formulation, *P(B)*, in the denominator, can''t be 0\. The reasoning behind
    this is worth reading up on.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '*P(A)* 是观察到 *A* 的概率（*A* 的边际概率）。考虑到公式中的 *P(B)* 在分母中，不能为零。这背后的推理值得一读。'
- en: 'A Naive Bayes classifier is about the probability of classes given features.
    We can plug class *k* and feature *x* into the Bayes theorem, which looks like
    this:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 朴素贝叶斯分类器涉及到给定特征的类别概率。我们可以将类别 *k* 和特征 *x* 插入到贝叶斯定理中，如下所示：
- en: '![](img/fff2a6b5-c15b-49ad-87f3-890449aab260.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fff2a6b5-c15b-49ad-87f3-890449aab260.png)'
- en: 'It is called naive because it assumes that features are independent of each
    other, so the nominator can be simplified as follows:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 它被称为朴素是因为它假设特征彼此独立，因此提名者可以简化如下：
- en: '![](img/f2891568-24e6-4a7d-bb8a-476583733bd5.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f2891568-24e6-4a7d-bb8a-476583733bd5.png)'
- en: In the next section, we'll look at additional material.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分中，我们将查看额外的材料。
- en: See also
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 请参阅
- en: 'Here are some resources that you can go through:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些资源供您参考：
- en: For Platt scaling, refer to *Probabilistic Outputs for Support Vector Machines
    and Comparisons to Regularized Likelihood Methods* by John Platt, (1999).
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于Platt缩放，请参阅John Platt的*支持向量机的概率输出及与正则化似然方法的比较*（1999年）。
- en: For isotonic regression, as in our application for probability estimates in
    classification, please refer to *Transforming classifier scores into accurate multi-class probability estimates* by
    Zadrozny, B. and Elkan, C., (2002).
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于同位素回归，在我们应用于分类中的概率估计，请参阅Zadrozny, B.和Elkan, C.的*将分类器分数转换为准确的多类别概率估计*（2002年）。
- en: For a comparison between the two, refer to *Predicting Good Probabilities with
    Supervised Learning* by A. Niculescu-Mizil & R. Caruana, ICML, (2005). Refer to
    Rennie, J. D. and others, *Tackling the Poor Assumptions of Naive Bayes Text Classifiers* (2003),
    on the complement Naive Bayes algorithm.
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于两者的比较，请参阅A. Niculescu-Mizil & R. Caruana在ICML（2005年）上的*使用监督学习预测良好概率*。关于朴素贝叶斯算法，请参阅Rennie,
    J. D.等人的*Tackling the Poor Assumptions of Naive Bayes Text Classifiers*（2003年）。
- en: The scikit-learn documentation gives an overview of confidence calibration ([https://scikit-learn.org/stable/auto_examples/calibration/plot_calibration_curve.html#sphx-glr-auto-examples-calibration-plot-calibration-curve-py](https://scikit-learn.org/stable/auto_examples/calibration/plot_calibration_curve.html#sphx-glr-auto-examples-calibration-plot-calibration-curve-py)).
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: scikit-learn文档概述了置信度校准（[https://scikit-learn.org/stable/auto_examples/calibration/plot_calibration_curve.html#sphx-glr-auto-examples-calibration-plot-calibration-curve-py](https://scikit-learn.org/stable/auto_examples/calibration/plot_calibration_curve.html#sphx-glr-auto-examples-calibration-plot-calibration-curve-py)）。
- en: For an approach applied to deep learning models, see the ICLR 2018 paper by
    Lee and others, *Training Confidence-Calibrated Classifiers for Detecting Out-of-Distribution
    Samples* ([https://arxiv.org/abs/1711.09325](https://arxiv.org/abs/1711.09325)).
    Their code is available on GitHub at [https://github.com/alinlab/Confident_classifier](https://github.com/alinlab/Confident_classifier).
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于应用于深度学习模型的方法，请参阅Lee等人在ICLR 2018年的论文，*训练置信度校准的分类器以检测分布外样本*（[https://arxiv.org/abs/1711.09325](https://arxiv.org/abs/1711.09325)）。他们的代码可在GitHub上找到：[https://github.com/alinlab/Confident_classifier](https://github.com/alinlab/Confident_classifier)。
- en: 'You can find more examples of probabilistic analyses of time series with different
    frameworks at the following links:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在以下链接找到更多关于不同框架下时间序列概率分析的示例：
- en: '**bayesloop**: Analyzing stock-market fluctuations – [http://docs.bayesloop.com/en/stable/examples/stockmarketfluctuations.html](http://docs.bayesloop.com/en/stable/examples/stockmarketfluctuations.html)'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**bayesloop**：分析股市波动 – [http://docs.bayesloop.com/en/stable/examples/stockmarketfluctuations.html](http://docs.bayesloop.com/en/stable/examples/stockmarketfluctuations.html)'
- en: '**Tensorflow Probability**: Different methods – [https://www.tensorflow.org/probability/examples/Structural_Time_Series_Modeling_Case_Studies_Atmospheric_CO2_and_Electricity_Demand](https://www.tensorflow.org/probability/examples/Structural_Time_Series_Modeling_Case_Studies_Atmospheric_CO2_and_Electricity_Demand)'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Tensorflow Probability**：不同方法 – [https://www.tensorflow.org/probability/examples/Structural_Time_Series_Modeling_Case_Studies_Atmospheric_CO2_and_Electricity_Demand](https://www.tensorflow.org/probability/examples/Structural_Time_Series_Modeling_Case_Studies_Atmospheric_CO2_and_Electricity_Demand)'
- en: '**Pyro**: Gaussian process time-series modeling – [https://pyro.ai/examples/timeseries.html](https://pyro.ai/examples/timeseries.html)'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Pyro**：高斯过程时间序列建模 – [https://pyro.ai/examples/timeseries.html](https://pyro.ai/examples/timeseries.html)'
- en: Estimating customer lifetime value
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 估算客户生命周期价值
- en: In this recipe, we will learn how to compute lifetime values and the value a
    customer provides to this company. This is important for the marketing budget
    – for example, in lead acquisition or ads spent based on customer segments. We'll
    do this by modeling separately changes in customer purchase patterns over time and
    purchase values.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在本示例中，我们将学习如何计算生命周期价值以及顾客为公司提供的价值。这对于营销预算非常重要，例如基于客户细分的潜在获取或广告支出。我们将通过分别对时间内客户购买模式的变化和购买价值进行建模来实现这一点。
- en: Getting ready
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备就绪
- en: 'We''ll need the `lifetimes` package for this recipe. Let''s install it as shown
    in the following code:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要`lifetimes`包来完成这个配方。让我们按照以下代码安装它：
- en: '[PRE8]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Now we can get started.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以开始了。
- en: How to do it...
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: Datasets used for customer lifetime values can be either transactional or summarized
    by the customer.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 用于客户生命周期价值的数据集可以是交易性的，也可以是客户汇总的。
- en: 'The summary data should include the following statistics:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 摘要数据应包括以下统计信息：
- en: '**T**: The transaction period; the elapsed time since the first purchase by
    the customer'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**T**：交易期间；客户第一次购买后经过的时间'
- en: '**Frequency**: The number of purchases by a customer within the observation
    period'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**频率**：观察期内客户的购买次数'
- en: '**Monetary value**: The average value of purchases'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**货币价值**：购买的平均价值'
- en: '**Recency**: The age of the customer at the time of the last purchase'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**最近**：客户在最后一次购买时的年龄'
- en: Let's start with the first step!
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从第一步开始！
- en: 'We''ll first fit the **BetaGeo** (**BD**)/**Negative Binomial Distribution**
    (**NBD**) model to a summary dataset of customer transactions:'
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们首先将**BetaGeo**（**BD**）/**负二项分布**（**NBD**）模型拟合到客户交易摘要数据集上：
- en: '[PRE9]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The Gamma-Gamma model for purchase values can''t handle customers who don''t
    have repeat purchases, so we''ll exclude those before we fit it:'
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Gamma-Gamma模型用于购买价值不能处理没有重复购买的客户，因此在拟合之前我们将排除这些客户：
- en: '[PRE10]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We can then combine the predictions of the model that predicts the number of
    future transactions (`bgf`) and the model that predicts average purchase values
    (`ggf`) using another of the Lifetimes library''s methods. It includes a parameter
    for discounting future values. We''ll include a discount that corresponds to an
    annualized 12.7%. We''ll print five customers'' lifetime values:'
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们可以使用Lifetimes库的另一个方法结合预测模型（预测未来交易数量的模型`bgf`和预测平均购买价值的模型`ggf`）。它包括一个对未来价值进行折现的参数。我们将包括对应年化12.7%的折现。我们将打印五个客户的生命周期价值：
- en: '[PRE11]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The output shows us the customer lifetime values:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示了客户生命周期价值：
- en: '[PRE12]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Now we know who our best customers are, and therefore where to invest our time
    and resources!
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道谁是我们最好的客户，因此知道在哪里投资我们的时间和资源！
- en: Let's go over some of the methods in this recipe.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看这个配方中的一些方法。
- en: How it works...
  id: totrans-138
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理...
- en: In this recipe, we've estimated lifetime values of customers based on their
    purchase patterns.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个配方中，我们根据他们的购买模式估计了客户的生命周期价值。
- en: 'Each customer has a value to the company. This is important for the marketing
    budget – for example, in lead acquisition or ads spent based on customer segments.
    The actual customer lifetime value is known after a customer has left the company;
    however, we can instead build two different probabilistic forecasting models for
    each customer:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 每个客户对公司有一个价值。这对于市场预算非常重要 - 例如，基于客户细分的潜在获取或广告支出。实际的客户生命周期价值在客户离开公司后才知道；然而，我们可以为每个客户建立两个不同的概率预测模型：
- en: Modeling the likelihood of buying more products
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 建模购买更多产品的可能性
- en: Modeling the average value (revenue) of purchases
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 建模平均值（收入）的购买
- en: We model purchase frequency – or, more precisely, changes in customer purchase
    patterns over time – using the BG/NBD model, and purchase values using the Gamma-Gamma
    model. Both of these models exploit non-linear associations between variables.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用BG/NBD模型建模购买频率 - 或者更精确地说，随时间变化的客户购买模式 - 并使用Gamma-Gamma模型建模购买价值。这两个模型都利用了变量之间的非线性关系。
- en: 'Finally, we can combine the predictions to obtain lifetime values according
    to the following formula:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以按照以下公式结合预测以获取生命周期价值：
- en: '![](img/e18afcc8-4047-44c4-83dd-b21beccf43d3.png)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e18afcc8-4047-44c4-83dd-b21beccf43d3.png)'
- en: Let's go over the two submodels that we've used here.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们在这里使用的两个子模型。
- en: The BG/NBD model
  id: totrans-147
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: BG/NBD模型
- en: This takes into account the purchasing frequency of customers and the dropout
    probability of customers.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 这考虑了客户的购买频率和客户的退出概率。
- en: 'It comes with the following assumptions:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 它包含以下假设：
- en: Purchases for each customer follow a Poisson distribution with a lambda parameter.
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个客户的购买都遵循带有λ参数的泊松分布。
- en: Customer churn probability *p* after each transaction follows a beta distribution.
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每次交易后，客户的流失概率*p*遵循贝塔分布。
- en: Transaction rates and the dropout probabilities are independent across customers.
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 交易率和客户之间的退出概率是独立的。
- en: The lambda and *p* parameters can be estimated according to maximum likelihood
    estimation.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 可以根据最大似然估计来估计λ和*p*参数。
- en: The Gamma-Gamma model
  id: totrans-154
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 伽玛-伽玛模型
- en: 'This model is used to estimate the mean transaction value over the customer''s
    lifetime, *E(M)*, for which we have an imperfect estimate, as follows:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型用于估计客户终身的平均交易价值，*E(M)*，我们对其有一个不完美的估计，如下所示：
- en: '![](img/d60eaf2c-0e51-4eb8-8cab-4b42a4ba63cd.png)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d60eaf2c-0e51-4eb8-8cab-4b42a4ba63cd.png)'
- en: Here, *x* is the (unknown) total number of purchases over a customer's lifetime,
    and *z* is the value of each purchase.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*x*是客户终身内（未知的）总购买次数，*z*是每次购买的价值。
- en: We assume *z* to be sampled from gamma distributions, and therefore, the model
    fit involves finding the shape and scale parameters at the individual level.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 我们假设*z*是从伽玛分布中抽样的，因此，模型的拟合涉及在个体水平上找到形状和比例参数。
- en: See also
  id: totrans-159
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参见
- en: This recipe was relatively short because of the excellent work that's been put
    into the Lifetimes library, which makes a lot of the needed functionality plug-and-play.
    An extended explanation of this analysis can be found in the Lifetimes documentation
    ([https://lifetimes.readthedocs.io/en/latest/Quickstart.html](https://lifetimes.readthedocs.io/en/latest/Quickstart.html)).
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 这个示例比较短，因为Lifetimes库已经做了很多必要功能的插件和播放。关于这种分析的扩展解释可以在Lifetimes文档中找到（[https://lifetimes.readthedocs.io/en/latest/Quickstart.html](https://lifetimes.readthedocs.io/en/latest/Quickstart.html)）。
- en: 'The Lifetimes library comes with a range of models (called **fitters**), which
    you might want to look into. You can find more details about the two methods in
    this recipe in Fader and others, *Counting your Customers the Easy Way: An Alternative
    to the Pareto/NBD Model*, 2005, and Batislam and others, *Empirical validation
    and comparison of models for customer base analysis*, *2007*. You can find the
    details of the Gamma-Gamma model in Fader and Hardi''s report, *Gamma-Gamma Model
    of Monetary Value* (2013).'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 'Lifetimes库提供了一系列模型（称为**fitters**），您可能想要深入了解。关于本示例中两种方法的更多详细信息，请参阅Fader等人的*Counting
    your Customers the Easy Way: An Alternative to the Pareto/NBD Model*, 2005年以及Batislam等人的*Empirical
    validation and comparison of models for customer base analysis*, *2007年*。您可以在Fader和Hardi的报告*Gamma-Gamma
    Model of Monetary Value*（2013年）中找到关于伽玛-伽玛模型的详细信息。'
- en: The Google Cloud Platform GitHub repo shows a model comparison for estimation
    of customer lifetime values ([https://github.com/GoogleCloudPlatform/tensorflow-lifetime-value](https://github.com/GoogleCloudPlatform/tensorflow-lifetime-value))
    that includes Lifetimes, a TensorFlow neural network, and AutoML. You can find
    a very similar dataset of online retail in the UCI machine learning archive ([http://archive.ics.uci.edu/ml/datasets/Online+Retail](http://archive.ics.uci.edu/ml/datasets/Online+Retail)).
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: Google Cloud Platform GitHub 仓库展示了一个客户终身价值估算的模型比较（[https://github.com/GoogleCloudPlatform/tensorflow-lifetime-value](https://github.com/GoogleCloudPlatform/tensorflow-lifetime-value)），包括Lifetimes，一个TensorFlow神经网络和AutoML。你可以在UCI机器学习存档中找到一个非常类似的在线零售数据集（[http://archive.ics.uci.edu/ml/datasets/Online+Retail](http://archive.ics.uci.edu/ml/datasets/Online+Retail)）。
- en: Lifelines is a library for survival regression by the same author as Lifetimes, Cameron
    Davidson-Pilon ([https://lifelines.readthedocs.io/en/latest/Survival%20Regression.html](https://lifelines.readthedocs.io/en/latest/Survival%20Regression.html)).
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: Lifelines是一个由Lifetimes的作者Cameron Davidson-Pilon编写的生存回归库（[https://lifelines.readthedocs.io/en/latest/Survival%20Regression.html](https://lifelines.readthedocs.io/en/latest/Survival%20Regression.html)）。
- en: Diagnosing a disease
  id: totrans-164
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 诊断疾病
- en: For probabilistic modeling, experimental libraries abound. Running probabilistic
    networks can be much slower than algorithmic (non-algorithmic) approaches, which
    until not long ago rendered them impractical for anything but very small datasets.
    In fact, most of the tutorials and examples relate to toy datasets.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 对于概率建模，实验性库不胜枚举。运行概率网络可能比算法（非算法）方法慢得多，直到不久前，它们几乎对除了非常小的数据集外的任何事物都不实用。事实上，大多数教程和示例都是关于玩具数据集的。
- en: However, this has changed in recent years due to faster hardware and variational
    inference. With TensorFlow Probability, it is often straightforward to define
    architectures, losses, and layers, even with probabilistic sampling with full
    GPU support, and state-of-the-art implementations that support fast training.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，由于硬件更快和变分推断的进步，在近年来这种情况发生了变化。利用TensorFlow Probability，即使进行了概率抽样并且完全支持GPU，也通常可以简单地定义架构、损失和层，并支持最新的实现来进行快速训练。
- en: In this recipe, we'll implement an application in healthcare – we'll diagnose
    a disease.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将实现一个在医疗保健领域的应用程序 - 我们将诊断一种疾病。
- en: Getting ready
  id: totrans-168
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: We already have scikit-learn and TensorFlow installed from previous chapters.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经在之前的章节中安装了scikit-learn和TensorFlow。
- en: 'For this recipe, we''ll need `tensorflow-probability` as well:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个示例，我们还需要安装 `tensorflow-probability`。
- en: '[PRE13]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Now that `tensorflow-probability` is installed, we'll use it extensively in
    the next section.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 现在安装了 `tensorflow-probability`，我们将在下一节中广泛使用它。
- en: How to do it...
  id: totrans-173
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 怎样做…
- en: 'We''ll break this down into several steps:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将把这个过程分解为几个步骤：
- en: Downloading and preparing the data
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载并准备数据
- en: Creating a neural network
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建神经网络
- en: Model training
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型训练
- en: Validation
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 验证
- en: 'We''ll start with getting the dataset into Python:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从 Python 中获取数据集的步骤开始：
- en: '**Downloading and preparing the data**: We''ll download a dataset of symptoms
    and heart disease diagnoses collected at the Hungarian Institute of Cardiology,
    Budapest, by the group of Andras Janosi ([https://www.openml.org/d/1565/](https://www.openml.org/d/1565/)),
    then preprocess it, construct a neural network in Keras, and probabilistically
    diagnose based on symptoms.'
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**下载并准备数据**：我们将下载在匈牙利心脏病学院由 Andras Janosi 团队收集的症状和心脏病诊断数据集（[https://www.openml.org/d/1565/](https://www.openml.org/d/1565/)），然后在
    Keras 中构建神经网络，并根据症状进行概率诊断。'
- en: 'We will download it from OpenML as we have before. You can see a complete description
    there. The target originally encodes different statuses, where 0 is healthy, and
    the others indicate a disease. We''ll therefore separate between healthy and not-healthy,
    and treat this as a binary classification problem. We apply a standard scaler
    so that we can feed z-scores to the neural network. All of this should be familiar
    from several earlier recipes in [Chapter 1](87098651-b37f-4b05-b0ee-878193f28b95.xhtml),
    *Getting Started with Artificial Intelligence in Python*, [Chapter 2](bca59029-1915-4856-b47d-6041d7b10a0a.xhtml),
    *Advanced Topics in Supervised Machine Learning*, [Chapter 3](424f3988-2d11-4098-9c52-beb685a6ed27.xhtml),
    *Patterns, Outliers, and Recommendations*, and [Chapter 4](562919eb-c6f4-48d8-adc7-fabd55d93599.xhtml), *Probabilistic
    Modeling*:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 如之前一样，我们将从 OpenML 下载数据集。您可以在那里看到完整的描述。原始目标编码了不同的状态，其中 0 表示健康，其他数字表示疾病。因此，我们将在健康和非健康之间分开，并将其视为二元分类问题。我们应用标准缩放器，以便将
    z 分数馈送给神经网络。所有这些在 [Chapter 1](87098651-b37f-4b05-b0ee-878193f28b95.xhtml)、*Getting
    Started with Artificial Intelligence in Python*、[Chapter 2](bca59029-1915-4856-b47d-6041d7b10a0a.xhtml)、*Advanced
    Topics in Supervised Machine Learning*、[Chapter 3](424f3988-2d11-4098-9c52-beb685a6ed27.xhtml)、*Patterns,
    Outliers, and Recommendations* 和 [Chapter 4](562919eb-c6f4-48d8-adc7-fabd55d93599.xhtml)、*Probabilistic
    Modeling* 等几个早期的章节中应该是熟悉的：
- en: '[PRE14]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Now, we have preprocessed and split our dataset into training and test.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经预处理并将数据集拆分为训练集和测试集。
- en: '**Creating a neural network**: The network construction itself is straightforward,
    and looks very much like any of the other Keras networks that we''ve seen. The
    difference is a `DistributionLambda` layer at the end, which we will explain in
    the next section:'
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**创建神经网络**：网络的构建本身很简单，看起来与我们之前见过的任何 Keras 网络非常相似。不同之处在于末端有一个 `DistributionLambda`
    层，我们将在下一节中解释它：'
- en: '[PRE15]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: It is important to notice that instead of finishing off with a final layer, `Dense(2,
    activation = 'softmax'`, as we would do in binary classification tasks, we'll
    reduce the outputs to the number of parameters our probability distribution needs,
    which is just one in the case of the Bernoulli distribution, which takes a single
    parameter, which is the expected average of the binary outcome.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，我们不像在二元分类任务中那样最后以 `Dense(2, activation='softmax'` 层结束，而是将输出减少到我们概率分布需要的参数数量，对于伯努利分布而言，仅需一个参数，即二进制结果的期望平均值。
- en: We are using a relatively small model of only 181 parameters. We'll explain
    the loss function in the *How it works...* section.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用的是一个只有 181 个参数的相对较小的模型。在 *How it works...* 节中，我们将解释损失函数。
- en: '**Model training**: Now, we can train our model. We''ll plot our training loss
    in `tensorboard` and we''ll enable early stopping:'
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**模型训练**：现在，我们可以训练我们的模型。我们将在 `tensorboard` 中绘制训练损失，并启用早停：'
- en: '[PRE16]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'This will run for 2,000 epochs, and it might take a while to complete. From
    TensorBoard, we can see the training loss over epochs:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 该网络将运行 2,000 个周期，完成可能需要一段时间。从 TensorBoard 中，我们可以看到各周期的训练损失：
- en: '![](img/46376b8d-def4-4e29-9cf0-ad2ed75dc10a.png)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
  zh: '![](img/46376b8d-def4-4e29-9cf0-ad2ed75dc10a.png)'
- en: '**Validating the model**: We can now sample from the model. Each network prediction
    gives us a mean and variance. We can have a look at a single prediction. We''ve
    arbitrarily chosen prediction number `10`:'
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**验证模型**：现在我们可以从模型中进行抽样。每个网络预测都给出了均值和方差。我们可以查看单个预测。我们任意选择了第 `10` 个预测：'
- en: '[PRE17]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'This prediction looks as follows:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 此预测如下所示：
- en: '![](img/20c9ac30-31f5-488f-9051-d9dfa731f699.png)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![](img/20c9ac30-31f5-488f-9051-d9dfa731f699.png)'
- en: 'So, each prediction is a sample from a Bernoulli process. We can convert each
    of these predictions into class probabilities with the cumulative distribution
    function:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，每个预测都是来自伯努利过程的样本。我们可以使用累积分布函数将每个预测转换为类别概率：
- en: '[PRE18]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Now, we can calculate the area under the curve and other metrics against the
    test targets:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以计算曲线下面积以及其他与测试目标相关的指标：
- en: '[PRE19]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 85% AUC sounds good. But we are working in healthcare, so we need to check recall
    (also called sensitivity) and precision; in other words, do we detect all of the
    ill patients, and if we diagnose someone, are they actually ill? If we miss someone,
    they could die of an untreated condition. If we find everyone as ill, it would
    put a strain on resources.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 85% 的AUC听起来不错。但我们在医疗领域工作，因此我们需要检查召回率（也称为敏感性）和精度；换句话说，我们是否检测到了所有患病的患者，并且如果我们诊断某人，他们是否确实患病？如果我们漏掉某人，他们可能会死于未治疗的情况。如果我们将所有人都诊断为患病，将会给资源带来压力。
- en: 'In the following code segment, we''ll look in more detail at the results that
    we get:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下代码段中，我们将更详细地查看我们得到的结果：
- en: '[PRE20]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: This visualizes our results in order to give us a better understanding of the
    trade-off between precision and recall.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 这通过可视化我们的结果来更好地理解精度和召回率之间的权衡。
- en: 'We get the following graph:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到以下图表：
- en: '![](img/5440ee66-781b-476e-b79b-b87c8bd9a71d.png)'
  id: totrans-205
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5440ee66-781b-476e-b79b-b87c8bd9a71d.png)'
- en: This curve visualizes the trade-off inherent in our model, between recall and
    precision. Given different cutoffs on our confidence (or class probability), we
    can make a call about whether someone is ill or not. If we want to find everyone
    (`recall=100%`), precision drops down to below 40%. On the other hand, if we want
    to be always right (`precision=100%`) when we diagnose someone as ill, then we'd
    miss everyone (`recall=0%`).
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 这条曲线展示了我们模型固有的召回率和精度之间的权衡。在我们的置信度（或类别概率）上采用不同的截断时，我们可以判断某人是否患病。如果我们想要找到所有人（`召回率=100%`），精度会下降到40%以下。另一方面，如果我们希望在诊断某人患病时始终正确（`精度=100%`），那么我们将会错过所有人（`召回率=0%`）。
- en: It's now a question of the cost of, respectively, missing people or diagnosing
    too many, to make a decision on a cutoff for saying someone is ill. Given the
    importance of treating people, perhaps there's a sweet spot around 90% recall
    and around 65% precision.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 现在的问题是，分别错过人员或诊断过多的成本，以便对是否某人患病做出决定。考虑到治疗人员的重要性，也许在召回率约为90%和精度约为65%左右之间存在一个最佳点。
- en: How it works...
  id: totrans-208
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理是这样的...
- en: We've trained a neural network for probabilistic predictions diagnosing a disease.
    Let's take this apart a bit, and go through what we've used here.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 我们训练了一个神经网络来进行概率预测，用于诊断疾病。让我们分析一下这个过程，并了解我们在这里使用的内容。
- en: Aleatoric uncertainty
  id: totrans-210
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 随机不确定性
- en: TensorFlow Probability comes with layer types for modeling different types of
    uncertainty. Aleatoric uncertainty refers to the stochastic variability of our
    outcomes given the same input – in other words, we can learn the spread in our
    data.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow Probability 提供了多种用于建模不同类型不确定性的层。**随机不确定性**指的是在给定相同输入的情况下，结果的随机变化性——换句话说，我们可以学习数据中的分布情况。
- en: We can implement this in Keras and TensorFlow Probability by parameterizing a
    distribution describing predictions, rather than predicting the input directly.
    Basically, `DistributionLambda` draws from the distribution (in our case, Bernoulli).
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过在Keras和TensorFlow Probability中参数化描述预测的分布，而不是直接预测输入来实现这一点。基本上，`DistributionLambda`从分布中抽取样本（在我们的情况下是伯努利分布）。
- en: Negative log-likelihood
  id: totrans-213
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 负对数似然
- en: We use negative log-likelihood as our loss. This loss is often used in maximum
    likelihood estimation.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用负对数似然作为我们的损失函数。这种损失函数通常用于最大似然估计。
- en: 'What we defined was this:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 我们定义的是这样的：
- en: '[PRE21]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The loss function takes two values: `y`, the target, and a probability distribution
    that provides the `log_prob()` method. This method returns the log of the probability
    density at `y`. Since high values are good, we want to invert the function with
    the negative.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 损失函数接受两个值：`y`，目标值，以及提供`log_prob()`方法的概率分布。该方法返回`y`处概率密度的对数。由于高值代表好结果，我们希望通过取负值来反转该函数。
- en: Bernoulli distribution
  id: totrans-218
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 伯努利分布
- en: The Bernoulli distribution (sometimes called coin-flip distribution) is a discrete
    distribution of an event with two outcomes occurring with probabilities *p* and
    *q = 1 - p*. There's a single parameter to it, which is *p*. We could have chosen
    other modeling options, such as the categorical distribution on top of a softmax
    activation layer.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 伯努利分布（有时称为硬币翻转分布）是一个具有两个结果的离散事件分布，其发生概率为*p*和*q = 1 - p*。它有一个单一的参数*p*。我们也可以选择其他建模选项，例如在softmax激活层之上的分类分布。
- en: Metrics
  id: totrans-220
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 指标
- en: Finally, we touched on recall and precision.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们涉及了召回率和精确率。
- en: 'They are defined as follows:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 它们的定义如下：
- en: '![](img/0b9e83c0-a59c-42a3-a9d6-546132b1b346.png)'
  id: totrans-223
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0b9e83c0-a59c-42a3-a9d6-546132b1b346.png)'
- en: We've seen **True Positives** (**tp**), **False Positives** (**fp**), and **False
    Negatives** (**fn**) before. As a reminder, true positives refer to correct predictions,
    false positives refer to values incorrectly predicted as positive, and false negatives
    refer to those incorrectly predicted as negatives.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前见过**真阳性**（**tp**）、**假阳性**（**fp**）和**假阴性**（**fn**）。作为提醒，真阳性指的是正确的预测，假阳性指的是错误地预测为正面的值，假阴性指的是错误地预测为负面的值。
- en: See also
  id: totrans-225
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参阅
- en: In this recipe, you've seen how to use a probabilistic model for a health application.
    There are many other datasets and many different ways of doing probabilistic inference. Please
    see TensorFlow Probability as one of the frameworks in probabilistic modeling
    that has the most traction ([https://www.tensorflow.org/probability](https://www.tensorflow.org/probability)).
    It comes with a wide range of tutorials.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个配方中，您已经看到如何为健康应用程序使用概率模型。有许多其他数据集和执行概率推断的不同方式。请查看TensorFlow Probability作为最具影响力的概率建模框架之一（[https://www.tensorflow.org/probability](https://www.tensorflow.org/probability)）。它提供了广泛的教程。
- en: Stopping credit defaults
  id: totrans-227
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 停止信用违约
- en: For a company that extends credit to its customers, in order to be profitable,
    the most important criterion for approving applications is whether they can pay
    back their debts. This is determined by a process called credit scoring that is
    based on the financial history and socio-economic information of the customer.
    Traditionally, for credit scoring, scorecards have been used, although in recent
    years, these simple models have given way to more sophisticated machine learning
    models. Scorecards are basically checklists of different items of information,
    each associated with points that are all added up in the end and compared to a
    pass mark.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 对于向客户提供信用延伸的公司，为了盈利，批准申请的最重要标准是他们是否能够偿还债务。这由一个称为信用评分的过程决定，它基于客户的财务历史和社会经济信息。传统上，用于信用评分的是评分卡，尽管近年来，这些简单模型已被更复杂的机器学习模型所取代。评分卡基本上是不同信息项目的检查表，每个项目与分数相关联，最终所有分数相加并与及格分数进行比较。
- en: We'll use a relatively small dataset of credit card applications; however, it
    can still give us some insights into how to do credit scoring with neural network
    models. We'll implement a model that includes a distribution of weights as well
    as a distribution over outputs. This is called epistemic, aleatoric uncertainty,
    and will give us even better information about how trustworthy predictions are.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用一个相对较小的信用卡申请数据集；然而，它仍然可以为我们提供一些关于如何使用神经网络模型进行信用评分的见解。我们将实现一个包含权重分布和输出分布的模型。这被称为认知不确定性和随机不确定性，将为我们提供更可靠的预测信息。
- en: Getting ready
  id: totrans-230
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'We''ll be using `tensorflow-probability`. Just in case you skipped the previous
    recipe, *Diagnosi**ng a disease*, here''s how to install it:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用`tensorflow-probability`。以防您跳过了前面的配方*诊断疾病*，这里是如何安装它：
- en: '[PRE22]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Now, we should be ready with Keras and `tensorflow-probability`.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们应该准备好使用Keras和`tensorflow-probability`了。
- en: How to do it...
  id: totrans-234
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Let''s get the dataset and preprocess it, then we create the model, train the
    model, and validate it:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们获取数据集并进行预处理，然后创建模型，训练模型并验证它：
- en: '**Download and prepare the dataset**: The dataset that we''ll use for this
    recipe was published in 2009 (I-Cheng Yeh and Che-hui Lien, *The comparisons of
    data mining techniques for the predictive accuracy of probability of default of
    credit card clients*), and originally hosted on the UCI machine learning repository
    at [https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients](https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients).'
  id: totrans-236
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**下载和准备数据集**：我们将在这个示例中使用的数据集是在2009年发布的（I-Cheng Yeh 和 Che-hui Lien，《信用卡客户违约概率数据挖掘技术的比较》，），最初托管在UCI机器学习库上，网址为[https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients](https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients)。'
- en: 'We''ll download the data with `openml` using scikit-learn''s utility function:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用scikit-learn的实用函数通过`openml`下载数据：
- en: '[PRE23]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: This gives us features about customer demographics and their application.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 这给我们提供了关于客户人口统计信息及其申请的特征。
- en: We'll use a very standard process of preprocessing that we've seen many times
    before in this book and that we'll largely breeze through. We could have examined
    the features more, or done some more work on transformations and feature engineering,
    but this is beside the point of this recipe.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用一个非常标准的预处理过程，这在本书中我们已经看过很多次，并且我们将轻松处理。我们本可以更深入地检查特征，或者在转换和特征工程上做更多工作，但这与本示例无关。
- en: 'All the features register as numeric, so we only apply standard scaling. Here''s
    the preprocessing, and then we''ll separate it into training and test datasets:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 所有特征都注册为数值，因此我们只应用标准缩放。这里是预处理步骤，然后我们将其分为训练和测试数据集：
- en: '[PRE24]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Now that that's done, let's create the model.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，工作完成了，让我们创建模型。
- en: '**Create a model**: First, we need the priors and posteriors. This is done
    by directly following the online TensorFlow Probability tutorial ([http://www.github.com/tensorflow/probability/blob/master/tensorflow_probability/examples/jupyter_notebooks/Probabilistic_Layers_Regression.ipynb](http://www.github.com/tensorflow/probability/blob/master/tensorflow_probability/examples/jupyter_notebooks/Probabilistic_Layers_Regression.ipynb)),
    and is appropriate for normal distributions:'
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**创建模型**：首先，我们需要先验和后验分布。这是通过直接按照在线TensorFlow概率教程（[http://www.github.com/tensorflow/probability/blob/master/tensorflow_probability/examples/jupyter_notebooks/Probabilistic_Layers_Regression.ipynb](http://www.github.com/tensorflow/probability/blob/master/tensorflow_probability/examples/jupyter_notebooks/Probabilistic_Layers_Regression.ipynb)）进行的，适用于正态分布：'
- en: '[PRE25]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Please note `DenseVariational`.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意`DenseVariational`。
- en: 'Now to the main model, where we''ll use the priors and posteriors. You''ll
    recognize `DistributionLambda`. We''ve replaced `Binomial` from the previous recipe,
    *Diagnosing a disease*, with `Normal`, which will give us an estimate of the variance
    of predictions:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 现在来看主模型，在这里我们将使用先验和后验分布。你会认出`DistributionLambda`。我们从之前的示例中替换了`Binomial`，*诊断疾病*，用`Normal`，这将给我们一个预测方差的估计：
- en: '[PRE26]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: After fitting, we apply the model to our test dataset and obtain predictions
    for it.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 拟合后，我们将模型应用于测试数据集并对其进行预测。
- en: '**Validation**: Let''s check how good our model is:'
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**验证**：让我们检查一下我们的模型表现如何：'
- en: '[PRE27]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'We get around 70% AUC. Since this summary figure often doesn''t tell a full
    story, let''s look at the confusion matrix as well:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到了约70%的AUC。由于这个摘要数字通常不能完全揭示全部情况，让我们也看看混淆矩阵：
- en: '[PRE28]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'This code gives us the following confusion matrix:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码给出了以下混淆矩阵：
- en: '![](img/a86f57ab-7e5c-4bb5-a0cb-177fd684d89a.png)'
  id: totrans-255
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a86f57ab-7e5c-4bb5-a0cb-177fd684d89a.png)'
- en: This confusion matrix tabulates predictions of default against the actual defaults.
    In the diagonal of the points, false-false and true-true are the correct predictions
    (true positives and true negatives). We can see that the number of correct predictions
    are higher than the false predictions, so that's comforting.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 这个混淆矩阵列出了对实际违约的预测。在点对角线上，假-假和真-真是正确的预测（真正例和真反例）。我们可以看到，正确预测的数量比错误预测高，这让人感到安慰。
- en: However, the most interesting point is that variances of predictions correlate
    with errors!
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，最有趣的一点是预测的方差与误差相关！
- en: '[PRE29]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: We get a rank correlation of about 60% between absolute errors and the variance
    of predictions.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到了绝对误差与预测方差之间约60%的秩相关。
- en: 'This gives us a confidence estimate that can be very useful in practice. We
    find that the variance is higher for test points where the error is high and that
    it is lower where we expect the error to be lower. We can look at absolute errors
    and variance in a scatter plot:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 这给了我们一个非常有用的实践信心估计。我们发现，对于测试点，误差较高的方差较大，而在预期误差较低的地方，方差较小。我们可以在散点图中查看绝对误差和方差：
- en: '![](img/36e28a66-27ca-4cdd-81cc-05a0c5dc6be3.png)'
  id: totrans-261
  prefs: []
  type: TYPE_IMG
  zh: '![](img/36e28a66-27ca-4cdd-81cc-05a0c5dc6be3.png)'
- en: This concludes our recipe. This recipe is as an exercise for you to try better
    preprocessing, tweaking the model more, or switching the distributions.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 这就结束了我们的配方。这个配方作为一个练习，让你尝试更好的预处理，调整模型，或者切换分布。
- en: How it works...
  id: totrans-263
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它的工作原理...
- en: Models for credit scoring often use logistic regression models, which we've
    encountered in the *Predicting stock prices with confidence* recipe in this chapter.
    Alternatively, boosted models or interpretable decision trees are also in use.
    Given the ability to do online learning and to represent residual uncertainties,
    `tensorflow-probability` offers itself as another practical alternative.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 信用评分模型通常使用 logistic 回归模型，我们在本章中的*预测股票价格和置信度*配方中遇到过。另外，提升模型或可解释的决策树也在使用中。鉴于在线学习的能力和表示残差不确定性的能力，`tensorflow-probability`
    提供了另一个实用的选择。
- en: In this recipe, we've created a probabilistic credit default prediction model
    that works with epistemic uncertainty. It's time to explain what that means.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个配方中，我们创建了一个与认知不确定性一起工作的概率性信用违约预测模型。现在是时候解释这意味着什么了。
- en: Epistemic uncertainty
  id: totrans-266
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 认知不确定性
- en: This is the uncertainty related to incomplete information – in other words,
    the uncertainty inherent in the model. We come across epistemic uncertainty all
    the time with noisy real-world datasets.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 这是与不完整信息相关的不确定性 - 换句话说，模型固有的不确定性。在与嘈杂的现实世界数据集中经常遇到认知不确定性。
- en: In TensorFlow Probability, this can be modeled as weight uncertainty. In this
    recipe, we've used a Bayesian neural network, where weights are a probability
    distribution rather than scalar estimates. This weight uncertainty translates
    to uncertainty in predictions, which is what we want to see.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 在 TensorFlow Probability 中，这可以建模为权重不确定性。在这个配方中，我们使用了贝叶斯神经网络，其中权重是概率分布而不是标量估计。这种权重不确定性转化为预测中的不确定性，这正是我们想要看到的。
- en: As our final network layer, we included stochasticity from a normal distribution
    to model aleatoric uncertainty. Instead, we could have assumed that this variability
    was known.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 作为我们最终的网络层，我们加入了来自正态分布的随机性，以模拟阿莱托里克不确定性。相反，我们也可以假设这种变异性是已知的。
- en: See also
  id: totrans-270
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参阅
- en: There are other routes to explore as well, such as libraries or additional material,
    which we will list here.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 还有其他探索途径，比如库或额外的材料，我们将在这里列出。
- en: 'You can find similar problems online, such as the following:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 在线可以找到类似的问题，比如以下内容：
- en: 'Credit scoring by predicting financial distress: [https://www.kaggle.com/c/GiveMeSomeCredit/data](https://www.kaggle.com/c/GiveMeSomeCredit/data).'
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过预测财务困境进行信用评分：[https://www.kaggle.com/c/GiveMeSomeCredit/data](https://www.kaggle.com/c/GiveMeSomeCredit/data).
- en: Lending Club provides a huge dataset of loan applications: [https://www.lendingclub.com/info/download-data.action](https://www.lendingclub.com/info/download-data.action).
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lending Club 提供了大量的贷款申请数据集：[https://www.lendingclub.com/info/download-data.action](https://www.lendingclub.com/info/download-data.action).
- en: 'Claim severity prediction for insurance: [https://www.kaggle.com/c/allstate-claims-severity/data](https://www.kaggle.com/c/allstate-claims-severity/data).'
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 保险索赔的索赔严重性预测：[https://www.kaggle.com/c/allstate-claims-severity/data](https://www.kaggle.com/c/allstate-claims-severity/data).
- en: We couldn't use these here because of copyright restrictions.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 由于版权限制，我们不能在这里使用这些内容。
- en: 'As for libraries, we recommend you have a look at these:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 至于库，我们建议您看看这些：
- en: risk-slim is a Python library for customizable risk scores: [https://github.com/ustunb/risk-slim](https://github.com/ustunb/risk-slim).
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: risk-slim 是一个用于定制风险评分的 Python 库：[https://github.com/ustunb/risk-slim](https://github.com/ustunb/risk-slim).
- en: 'scorecardpy is a library for scorecard development: [https://github.com/ShichenXie/scorecardpy](https://github.com/ShichenXie/scorecardpy).'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: scorecardpy 是一个用于评分卡开发的库：[https://github.com/ShichenXie/scorecardpy](https://github.com/ShichenXie/scorecardpy).
- en: As for tutorials, the Open Risk Manual offers open resources for credit scoring
    in Python: [https://www.openriskmanual.org/wiki/Credit_Scoring_with_Python](https://www.openriskmanual.org/wiki/Credit_Scoring_with_Python).
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 至于教程，Open Risk Manual 提供了关于使用 Python 进行信用评分的开放资源：[https://www.openriskmanual.org/wiki/Credit_Scoring_with_Python](https://www.openriskmanual.org/wiki/Credit_Scoring_with_Python).
- en: NumPyro provides a tutorial about Bayesian regression for divorce rates: [http://pyro.ai/numpyro/bayesian_regression.html#Regression-Model-to-Predict-Divorce-Rate](http://pyro.ai/numpyro/bayesian_regression.html#Regression-Model-to-Predict-Divorce-Rate).
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: NumPyro为离婚率提供了贝叶斯回归的教程：[http://pyro.ai/numpyro/bayesian_regression.html#Regression-Model-to-Predict-Divorce-Rate](http://pyro.ai/numpyro/bayesian_regression.html#Regression-Model-to-Predict-Divorce-Rate)。
