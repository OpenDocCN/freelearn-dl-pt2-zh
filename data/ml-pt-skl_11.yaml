- en: '11'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '11'
- en: Implementing a Multilayer Artificial Neural Network from Scratch
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从头开始实现多层人工神经网络
- en: As you may know, deep learning is getting a lot of attention from the press
    and is, without doubt, the hottest topic in the machine learning field. Deep learning
    can be understood as a subfield of machine learning that is concerned with training
    artificial **neural networks** (**NNs**) with many layers efficiently. In this
    chapter, you will learn the basic concepts of artificial NNs so that you are well
    equipped for the following chapters, which will introduce advanced Python-based
    deep learning libraries and **deep neural network** (**DNN**) architectures that
    are particularly well suited for image and text analyses.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经知道，深度学习在媒体上受到了很多关注，毫无疑问，它是机器学习领域最热门的话题。深度学习可以理解为机器学习的一个子领域，其关注点是如何高效地训练具有多层的人工**神经网络**（**NNs**）。在本章中，你将学习人工神经网络的基本概念，以便在接下来的章节中，我们将介绍专门用于图像和文本分析的基于Python的高级深度学习库和**深度神经网络**（**DNN**）架构。
- en: 'The topics that we will cover in this chapter are as follows:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖的主题如下：
- en: Gaining a conceptual understanding of multilayer NNs
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对多层神经网络（Multilayer NNs）的概念性理解
- en: Implementing the fundamental backpropagation algorithm for NN training from
    scratch
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从头开始实现神经网络训练的基本反向传播算法
- en: Training a basic multilayer NN for image classification
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为图像分类训练基本的多层神经网络
- en: Modeling complex functions with artificial neural networks
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用人工神经网络对复杂函数建模
- en: At the beginning of this book, we started our journey through machine learning
    algorithms with artificial neurons in *Chapter 2*, *Training Simple Machine Learning
    Algorithms for Classification*. Artificial neurons represent the building blocks
    of the multilayer artificial NNs that we will discuss in this chapter.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的开头，我们从人工神经元开始了机器学习算法的旅程，这在《第2章》，《训练简单的分类机器学习算法》中有所介绍。人工神经元代表了我们将在本章讨论的多层人工神经网络的构建模块。
- en: The basic concept behind artificial NNs was built upon hypotheses and models
    of how the human brain works to solve complex problem tasks. Although artificial
    NNs have gained a lot of popularity in recent years, early studies of NNs go back
    to the 1940s, when Warren McCulloch and Walter Pitts first described how neurons
    could work. (*A logical calculus of the ideas immanent in nervous activity*, by
    *W. S. McCulloch* and *W. Pitts*, *The Bulletin of Mathematical Biophysics*, 5(4):115–133,
    1943.)
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 人工神经网络的基本概念建立在关于人脑如何解决复杂问题任务的假设和模型之上。尽管人工神经网络近年来越来越受欢迎，但早期对神经网络的研究可以追溯到1940年代，当时Warren
    McCulloch和Walter Pitts首次描述了神经元的工作方式，《神经活动中所含的思想的逻辑演算》，作者为W. S. McCulloch和W. Pitts，发表于《数理生物物理学公报》（*The
    Bulletin of Mathematical Biophysics*），5（4）：115–133，1943年。
- en: 'However, in the decades that followed the first implementation of the **McCulloch-Pitts
    neuron** model—Rosenblatt’s perceptron in the 1950s—many researchers and machine
    learning practitioners slowly began to lose interest in NNs since no one had a
    good solution for training an NN with multiple layers. Eventually, interest in
    NNs was rekindled in 1986 when D.E. Rumelhart, G.E. Hinton, and R.J. Williams
    were involved in the (re)discovery and popularization of the backpropagation algorithm
    to train NNs more efficiently, which we will discuss in more detail later in this
    chapter (*Learning representations by backpropagating errors*, by *D.E. Rumelhart*,
    *G.E. Hinton*, and *R.J. Williams*, *Nature*, 323 (6088): 533–536, 1986). Readers
    who are interested in the history of **artificial intelligence** (**AI**), machine
    learning, and NNs are also encouraged to read the Wikipedia article on the so-called
    *AI winters*, which are the periods of time where a large portion of the research
    community lost interest in the study of NNs ([https://en.wikipedia.org/wiki/AI_winter](https://en.wikipedia.org/wiki/AI_winter)).'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在第一个**麦卡洛克-皮茨神经元**模型——罗森布拉特在1950年代提出的感知器——实现后的几十年间，许多研究人员和机器学习从业者逐渐失去了对神经网络的兴趣，因为没有人能有效地训练具有多层的神经网络。直到1986年，D.E.
    Rumelhart、G.E. Hinton和R.J. Williams参与了反向传播算法的（重新）发现和推广，有效地训练神经网络，这一算法将在本章后面更详细地讨论《通过反向传播错误学习表示》，作者为D.E.
    Rumelhart、G.E. Hinton和R.J. Williams，发表于《自然》（*Nature*），323（6088）：533–536，1986年。对**人工智能**（**AI**）、机器学习和神经网络历史感兴趣的读者也建议阅读所谓的*AI寒冬*的维基百科文章，这些是研究社区失去对神经网络研究兴趣的时期（[https://en.wikipedia.org/wiki/AI_winter](https://en.wikipedia.org/wiki/AI_winter)）。
- en: However, NNs are more popular today than ever thanks to the many breakthroughs
    that have been made in the previous decade, which resulted in what we now call
    deep learning algorithms and architectures—NNs that are composed of many layers.
    NNs are a hot topic not only in academic research but also in big technology companies,
    such as Facebook, Microsoft, Amazon, Uber, Google, and many more that invest heavily
    in artificial NNs and deep learning research.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如今神经网络（NNs）比以往任何时候都更受欢迎，这要归功于上一个十年取得的许多突破，这导致了我们现在所称的深度学习算法和架构——由许多层组成的NNs。NNs不仅在学术研究中是热门话题，而且在大型技术公司（如Facebook、Microsoft、Amazon、Uber、Google等）中也是如此，这些公司在人工神经网络和深度学习研究上投入了大量资源。
- en: 'As of today, complex NNs powered by deep learning algorithms are considered
    state-of-the-art solutions for complex problem solving such as image and voice
    recognition. Some of the recent applications include:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，由深度学习算法驱动的复杂神经网络被认为是解决诸如图像和语音识别等复杂问题的最先进解决方案。一些最近的应用包括：
- en: Predicting COVID-19 resource needs from a series of X-rays ([https://arxiv.org/abs/2101.04909](https://arxiv.org/abs/2101.04909))
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测 COVID-19 资源需求的 X 射线序列（[https://arxiv.org/abs/2101.04909](https://arxiv.org/abs/2101.04909)）
- en: Modeling virus mutations ([https://science.sciencemag.org/content/371/6526/284](https://science.sciencemag.org/content/371/6526/284))
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 建模病毒突变（[https://science.sciencemag.org/content/371/6526/284](https://science.sciencemag.org/content/371/6526/284)）
- en: Leveraging data from social media platforms to manage extreme weather events
    ([https://onlinelibrary.wiley.com/doi/abs/10.1111/1468-5973.12311](https://onlinelibrary.wiley.com/doi/abs/10.1111/1468-5973.12311))
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用社交媒体平台的数据来管理极端天气事件（[https://onlinelibrary.wiley.com/doi/abs/10.1111/1468-5973.12311](https://onlinelibrary.wiley.com/doi/abs/10.1111/1468-5973.12311)）
- en: Improving photo descriptions for people who are blind or visually impaired ([https://tech.fb.com/how-facebook-is-using-ai-to-improve-photo-descriptions-for-people-who-are-blind-or-visually-impaired/](https://tech.fb.com/how-facebook-is-using-ai-to-improve-photo-descriptions-for-people-who-are-blind-or-visually-impaired/))
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 改进对盲人或视觉障碍人士的照片描述（[https://tech.fb.com/how-facebook-is-using-ai-to-improve-photo-descriptions-for-people-who-are-blind-or-visually-impaired/](https://tech.fb.com/how-facebook-is-using-ai-to-improve-photo-descriptions-for-people-who-are-blind-or-visually-impaired/)）
- en: Single-layer neural network recap
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 单层神经网络概述
- en: 'This chapter is all about multilayer NNs, how they work, and how to train them
    to solve complex problems. However, before we dig deeper into a particular multilayer
    NN architecture, let’s briefly reiterate some of the concepts of single-layer
    NNs that we introduced in *Chapter 2*, namely, the **ADAptive LInear NEuron**
    (**Adaline**) algorithm, which is shown in *Figure 11.1*:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 本章讨论的是多层神经网络，它们的工作原理以及如何训练它们来解决复杂问题。然而，在深入研究特定的多层神经网络架构之前，让我们简要重申我们在 *第2章* 中介绍的单层神经网络概念，即
    **ADAptive LInear NEuron**（Adaline）算法，如 *图 11.1* 所示：
- en: '![Diagram  Description automatically generated](img/B17582_11_01.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![自动生成的图表说明](img/B17582_11_01.png)'
- en: 'Figure 11.1: The Adaline algorithm'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.1：Adaline 算法
- en: 'In *Chapter 2*, we implemented the Adaline algorithm to perform binary classification,
    and we used the gradient descent optimization algorithm to learn the weight coefficients
    of the model. In every epoch (pass over the training dataset), we updated the
    weight vector **w** and bias unit *b* using the following update rule:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *第2章* 中，我们实现了 Adaline 算法来进行二元分类，并使用梯度下降优化算法来学习模型的权重系数。在每个 epoch（训练数据集的一次遍历）中，我们使用以下更新规则更新权重向量
    **w** 和偏置单元 *b*：
- en: '![](img/B17582_11_001.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17582_11_001.png)'
- en: where ![](img/B17582_11_002.png) and ![](img/B17582_11_003.png) for the bias
    unit and each weight *w*[j] in the weight vector **w**.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 ![](img/B17582_11_002.png) 和 ![](img/B17582_11_003.png) 分别代表偏置单元和权重向量 **w**
    中的每个权重 *w*[j]。
- en: In other words, we computed the gradient based on the whole training dataset
    and updated the weights of the model by taking a step in the opposite direction
    of the loss gradient ![](img/B17582_11_004.png). (For simplicity, we will focus
    on the weights and omit the bias unit in the following paragraphs; however, as
    you remember from *Chapter 2*, the same concepts apply.) In order to find the
    optimal weights of the model, we optimized an objective function that we defined
    as the **mean of squared errors** (**MSE**) loss function *L*(**w**). Furthermore,
    we multiplied the gradient by a factor, the **learning rate** ![](img/B17582_02_036.png),
    which we had to choose carefully to balance the speed of learning against the
    risk of overshooting the global minimum of the loss function.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，我们基于整个训练数据集计算梯度，并通过在损失梯度的反方向上迈出一步来更新模型的权重 ![](img/B17582_11_004.png)。（为简单起见，我们将专注于权重并在以下段落中省略偏置单元；然而，正如你从
    *第2章* 中记得的那样，相同的概念也适用。）为了找到模型的最优权重，我们优化了一个我们定义为**均方误差**（**MSE**）损失函数 *L*(**w**)
    的目标函数。此外，我们将梯度乘以一个因子，**学习率** ![](img/B17582_02_036.png)，我们需要仔细选择以在学习速度与超过损失函数全局最小值的风险之间取得平衡。
- en: 'In gradient descent optimization, we updated all weights simultaneously after
    each epoch, and we defined the partial derivative for each weight *w*[j] in the
    weight vector, **w**, as follows:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在梯度下降优化中，我们在每个迭代后同时更新所有权重，并且我们定义了权重向量中每个权重 *w*[j] 的偏导数，**w**，如下所示：
- en: '![](img/B17582_11_006.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17582_11_006.png)'
- en: Here, *y*^(^i^) is the target class label of a particular sample *x*^(^i^),
    and *a*^(^i^) is the activation of the neuron, which is a linear function in the
    special case of Adaline.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*y*^(^i^) 是特定样本 *x*^(^i^) 的目标类标签，*a*^(^i^) 是神经元的激活，对于Adaline的特殊情况，它是一个线性函数。
- en: 'Furthermore, we defined the activation function ![](img/B17582_11_007.png)
    as follows:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们如下定义了激活函数 ![](img/B17582_11_007.png)：
- en: '![](img/B17582_11_008.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17582_11_008.png)'
- en: 'Here, the net input, *z*, is a linear combination of the weights that are connecting
    the input layer to the output layer:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，净输入 *z* 是连接输入层与输出层的权重的线性组合：
- en: '![](img/B17582_11_009.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17582_11_009.png)'
- en: 'While we used the activation ![](img/B17582_11_007.png) to compute the gradient
    update, we implemented a threshold function to squash the continuous-valued output
    into binary class labels for prediction:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们使用激活函数 ![](img/B17582_11_007.png) 来计算梯度更新时，我们实现了一个阈值函数，将连续值输出压缩为用于预测的二进制类标签：
- en: '![](img/B17582_11_011.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17582_11_011.png)'
- en: '**Single-layer naming convention**'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**单层命名约定**'
- en: Note that although Adaline consists of two layers, one input layer and one output
    layer, it is called a single-layer network because of its single link between
    the input and output layers.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，尽管Adaline由两层组成，即一个输入层和一个输出层，但由于其输入层和输出层之间的单一连接，它被称为单层网络。
- en: Also, we learned about a certain *trick* to accelerate the model learning, the
    so-called **stochastic gradient descent** (**SGD**) optimization. SGD approximates
    the loss from a single training sample (online learning) or a small subset of
    training examples (mini-batch learning). We will make use of this concept later
    in this chapter when we implement and train a **multilayer perceptron** (**MLP**).
    Apart from faster learning—due to the more frequent weight updates compared to
    gradient descent—its noisy nature is also regarded as beneficial when training
    multilayer NNs with nonlinear activation functions, which do not have a convex
    loss function. Here, the added noise can help to escape local loss minima, but
    we will discuss this topic in more detail later in this chapter.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，我们了解了一种加速模型学习的特定*技巧*，即所谓的**随机梯度下降**（**SGD**）优化。 SGD从单个训练样本（在线学习）或一小部分训练示例（小批量学习）中近似损失。
    在本章后面，当我们实现和训练**多层感知机**（**MLP**）时，我们将使用这个概念。 除了由于梯度下降比梯度下降更频繁地更新权重导致更快的学习之外，其嘈杂的本质在训练具有非线性激活函数的多层神经网络时也被认为是有益的。
    这里，添加的噪声可以帮助逃离局部损失最小值，但我们将在本章后面更详细地讨论这个主题。
- en: Introducing the multilayer neural network architecture
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 引入多层神经网络架构
- en: In this section, you will learn how to connect multiple single neurons to a
    multilayer feedforward NN; this special type of *fully connected* network is also
    called **MLP**.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，您将学习如何将多个单神经元连接到多层前馈神经网络；这种特殊类型的*全连接*网络也称为**MLP**。
- en: '*Figure 11.2* illustrates the concept of an MLP consisting of two layers:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '*图11.2*说明了由两层组成的MLP的概念：'
- en: '![Diagram, engineering drawing  Description automatically generated](img/B17582_11_02.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![图表，工程图纸  描述自动生成](img/B17582_11_02.png)'
- en: 'Figure 11.2: A two-layer MLP'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '图11.2: 一个两层MLP'
- en: Next to the data input, the MLP depicted in *Figure 11.2* has one hidden layer
    and one output layer. The units in the hidden layer are fully connected to the
    input features, and the output layer is fully connected to the hidden layer. If
    such a network has more than one hidden layer, we also call it a **deep NN**.
    (Note that in some contexts, the inputs are also regarded as a layer. However,
    in this case, it would make the Adaline model, which is a single-layer neural
    network, a two-layer neural network, which may be counterintuitive.)
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 除了数据输入之外，*图11.2*中描述的MLP具有一个隐藏层和一个输出层。隐藏层中的单元与输入特征完全连接，输出层与隐藏层完全连接。如果这样的网络有多个隐藏层，我们也称其为**深度神经网络**。（请注意，在某些情况下，输入也被视为一层。然而，在这种情况下，将Adaline模型，即单层神经网络，视为两层神经网络可能会令人困惑。）
- en: '**Adding additional hidden layers**'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**添加额外的隐藏层**'
- en: We can add any number of hidden layers to the MLP to create deeper network architectures.
    Practically, we can think of the number of layers and units in an NN as additional
    hyperparameters that we want to optimize for a given problem task using the cross-validation
    technique, which we discussed in *Chapter 6*, *Learning Best Practices for Model
    Evaluation and Hyperparameter Tuning*.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在MLP中添加任意数量的隐藏层，以创建更深的网络结构。实际上，我们可以将NN中的层数和单位数视为额外的超参数，我们希望使用交叉验证技术为给定的问题任务进行优化，这些内容我们在*第6章*中讨论了*学习模型评估和超参数调整的最佳实践*。
- en: However, the loss gradients for updating the network’s parameters, which we
    will calculate later via backpropagation, will become increasingly small as more
    layers are added to a network. This vanishing gradient problem makes model learning
    more challenging. Therefore, special algorithms have been developed to help train
    such DNN structures; this is known as **deep learning**, which we will discuss
    in more detail in the following chapters.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，随着网络添加更多层，用于更新网络参数的损失梯度（稍后我们将通过反向传播计算）将变得越来越小。这种梯度消失问题使得模型学习更具挑战性。因此，已经开发了特殊算法来帮助训练这种DNN结构；这就是**深度学习**，我们将在接下来的章节中更详细地讨论。
- en: As shown in *Figure 11.2*, we denote the *i*th activation unit in the *l*th
    layer as ![](img/B17582_11_012.png). To make the math and code implementations
    a bit more intuitive, we will not use numerical indices to refer to layers, but
    we will use the *in* superscript for the input features, the *h* superscript for
    the hidden layer, and the *out* superscript for the output layer. For instance,
    ![](img/B17582_11_013.png) refers to the *i*th input feature value, ![](img/B17582_11_014.png)
    refers to the *i*th unit in the hidden layer, and ![](img/B17582_11_015.png) refers
    to the *i*th unit in the output layer. Note that the **b**’s in *Figure 11.2*
    denote the bias units. In fact, **b**^(^h^) and **b**^(^(out)^) are vectors with
    the number of elements being equal to the number of nodes in the layer they correspond
    to. For example, **b**^(^h^) stores *d* bias units, where *d* is the number of
    nodes in the hidden layer. If this sounds confusing, don’t worry. Looking at the
    code implementation later, where we initialize weight matrices and bias unit vectors,
    will help clarify these concepts.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 如*图11.2*所示，我们将第*l*层中的第*i*个激活单元表示为 ![](img/B17582_11_012.png)。为了使数学和代码实现更直观，我们将不使用数字索引来引用层，而是使用*in*上标表示输入特征，*h*上标表示隐藏层，*out*上标表示输出层。例如，![](img/B17582_11_013.png)
    表示第*i*个输入特征值，![](img/B17582_11_014.png) 表示隐藏层中的第*i*个单元，![](img/B17582_11_015.png)
    表示输出层中的第*i*个单元。请注意，*图11.2*中的**b**代表偏置单元。事实上，**b**^(^h^)和**b**^(^(out)^)是具有与其对应层中节点数相等的元素数量的向量。例如，**b**^(^h^)存储*d*个偏置单元，其中*d*是隐藏层中的节点数。如果这听起来令人困惑，不用担心。稍后查看代码实现，我们初始化权重矩阵和偏置单元向量将有助于澄清这些概念。
- en: Each node in layer *l* is connected to all nodes in layer *l* + 1 via a weight
    coefficient. For example, the connection between the *k*th unit in layer *l* to
    the *j*th unit in layer *l* + 1 will be written as ![](img/B17582_11_016.png).
    Referring back to *Figure 11.2*, we denote the weight matrix that connects the
    input to the hidden layer as **W**^(^h^), and we write the matrix that connects
    the hidden layer to the output layer as **W**^(^(out)^).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 每个 *l* 层中的节点通过权重系数与 *l* + 1 层中的所有节点相连。例如，层 *l* 中第 *k* 个单元到层 *l* + 1 中第 *j* 个单元的连接将被写为
    ![](img/B17582_11_016.png)。回顾 *图 11.2*，我们将连接输入到隐藏层的权重矩阵称为 **W**^(^h^)，并将连接隐藏层到输出层的矩阵称为
    **W**^(^(out)^)。
- en: While one unit in the output layer would suffice for a binary classification
    task, we saw a more general form of an NN in the preceding figure, which allows
    us to perform multiclass classification via a generalization of the **one-versus-all**
    (**OvA**) technique. To better understand how this works, remember the **one-hot**
    representation of categorical variables that we introduced in *Chapter 4*, *Building
    Good Training Datasets – Data Preprocessing*.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然输出层的一个单元足以完成二元分类任务，但在前述图中我们看到了更一般的神经网络形式，它允许我们通过**一对所有**（**OvA**）技术的泛化来进行多类别分类。为了更好地理解其工作原理，请记住我们在第四章
    *构建良好的训练数据集 – 数据预处理* 中介绍的分类变量的**独热编码**表示。
- en: 'For example, we can encode the three class labels in the familiar Iris dataset
    (0=*Setosa*, 1=*Versicolor*, 2=*Virginica*) as follows:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们可以将经典的鸢尾花数据集中的三类标签（0=*山鸢尾*，1=*变色鸢尾*，2=*维吉尼亚鸢尾*）进行如下编码：
- en: '![](img/B17582_11_017.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17582_11_017.png)'
- en: This one-hot vector representation allows us to tackle classification tasks
    with an arbitrary number of unique class labels present in the training dataset.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这种独热向量表示使我们能够处理训练数据集中任意数量的独特类标签的分类任务。
- en: If you are new to NN representations, the indexing notation (subscripts and
    superscripts) may look a little bit confusing at first. What may seem overly complicated
    at first will make much more sense in later sections when we vectorize the NN
    representation. As introduced earlier, we summarize the weights that connect the
    input and hidden layers by a *d*×*m* dimensional matrix **W**^(^h^), where *d*
    is the number of hidden units and *m* is the number of input units.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对神经网络表示还不熟悉，索引符号（下标和上标）可能一开始看起来有点令人困惑。但是，在后面的章节中，当我们对神经网络表示进行向量化时，这些看似过于复杂的内容将会变得更加合理。正如之前介绍的那样，我们通过一个
    *d*×*m* 维度的矩阵 **W**^(^h^) 来总结连接输入和隐藏层的权重，其中 *d* 是隐藏单元的数量，*m* 是输入单元的数量。
- en: Activating a neural network via forward propagation
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过前向传播激活神经网络
- en: 'In this section, we will describe the process of **forward propagation** to
    calculate the output of an MLP model. To understand how it fits into the context
    of learning an MLP model, let’s summarize the MLP learning procedure in three
    simple steps:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将描述**前向传播**的过程，以计算MLP模型的输出。为了理解它如何融入到学习MLP模型的背景中，让我们简要总结MLP学习过程的三个简单步骤：
- en: Starting at the input layer, we forward propagate the patterns of the training
    data through the network to generate an output.
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从输入层开始，我们通过网络将训练数据的模式进行前向传播，生成一个输出。
- en: Based on the network’s output, we calculate the loss that we want to minimize
    using a loss function that we will describe later.
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据网络的输出，我们使用稍后将描述的损失函数计算我们希望最小化的损失。
- en: We backpropagate the loss, find its derivative with respect to each weight and
    bias unit in the network, and update the model.
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们通过反向传播损失，找到其对网络中每个权重和偏置单元的导数，并更新模型。
- en: Finally, after we repeat these three steps for multiple epochs and learn the
    weight and bias parameters of the MLP, we use forward propagation to calculate
    the network output and apply a threshold function to obtain the predicted class
    labels in the one-hot representation, which we described in the previous section.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在我们对多个时期重复执行这三个步骤并学习MLP的权重和偏置参数之后，我们使用前向传播来计算网络输出，并应用阈值函数以获得在独热表示中的预测类标签，这是我们在前一节中描述过的。
- en: 'Now, let’s walk through the individual steps of forward propagation to generate
    an output from the patterns in the training data. Since each unit in the hidden
    layer is connected to all units in the input layers, we first calculate the activation
    unit of the hidden layer ![](img/B17582_11_018.png) as follows:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们逐步进行前向传播的各个步骤，从训练数据模式中生成输出。由于隐藏层中的每个单元都与输入层中的所有单元连接，我们首先计算隐藏层激活单元 ![](img/B17582_11_018.png)
    如下所示：
- en: '![](img/B17582_11_019.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![图 说明](img/B17582_11_019.png)'
- en: 'Here, ![](img/B17582_11_020.png) is the net input and ![](img/B17582_11_007.png)
    is the activation function, which has to be differentiable to learn the weights
    that connect the neurons using a gradient-based approach. To be able to solve
    complex problems such as image classification, we need nonlinear activation functions
    in our MLP model, for example, the sigmoid (logistic) activation function that
    we remember from the section about logistic regression in *Chapter 3*, *A Tour
    of Machine Learning Classifiers Using Scikit-Learn*:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，![](img/B17582_11_020.png) 是净输入，![](img/B17582_11_007.png) 是激活函数，必须是可微的，以便使用基于梯度的方法学习连接神经元的权重。为了能够解决复杂问题，如图像分类，我们在
    MLP 模型中需要非线性激活函数，例如我们在第 3 章“使用 Scikit-Learn 的机器学习分类器之旅”中记得的 sigmoid（logistic）激活函数：
- en: '![](img/B17582_03_009.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![图 说明](img/B17582_03_009.png)'
- en: 'As you may recall, the sigmoid function is an *S*-shaped curve that maps the
    net input *z* onto a logistic distribution in the range 0 to 1, which cuts the
    *y* axis at *z* = 0, as shown in *Figure 11.3*:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您可能记得的那样，Sigmoid 函数是一条*S*形曲线，将净输入 *z* 映射到 0 到 1 的 logistic 分布范围内，在 *Figure
    11.3* 中显示 *y* 轴在 *z* = 0 处切割：
- en: '![Diagram  Description automatically generated with low confidence](img/B17582_11_03.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![图 说明：自动低置信度生成](img/B17582_11_03.png)'
- en: 'Figure 11.3: The sigmoid activation function'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.3：Sigmoid 激活函数
- en: MLP is a typical example of a feedforward artificial NN. The term **feedforward**
    refers to the fact that each layer serves as the input to the next layer without
    loops, in contrast to recurrent NNs—an architecture that we will discuss later
    in this chapter and discuss in more detail in *Chapter 15*, *Modeling Sequential
    Data Using Recurrent Neural Networks*. The term *multilayer perceptron* may sound
    a little bit confusing since the artificial neurons in this network architecture
    are typically sigmoid units, not perceptrons. We can think of the neurons in the
    MLP as logistic regression units that return values in the continuous range between
    0 and 1.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: MLP 是前馈人工神经网络的典型例子。术语 **feedforward** 指的是每一层作为下一层的输入，没有循环，与递归神经网络形成对比——这是我们将在本章稍后讨论的架构，并在第
    15 章“使用递归神经网络建模顺序数据”中进行更详细的讨论。术语 *multilayer perceptron* 可能听起来有点混淆，因为这种网络架构中的人工神经元通常是
    sigmoid 单元，而不是感知器。我们可以将 MLP 中的神经元视为 logistic 回归单元，返回在 0 到 1 的连续范围内的值。
- en: 'For purposes of code efficiency and readability, we will now write the activation
    in a more compact form using the concepts of basic linear algebra, which will
    allow us to vectorize our code implementation via NumPy rather than writing multiple
    nested and computationally expensive Python `for` loops:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 为了代码的效率和可读性，我们将使用基本线性代数的概念，通过 NumPy 将激活写成更紧凑的形式，而不是编写多个嵌套和计算昂贵的 Python `for`
    循环。
- en: '![](img/B17582_11_023.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![图 说明](img/B17582_11_023.png)'
- en: Here, **z**^(^h^) is our 1×*m* dimensional feature vector. **W**^(^h^) is a
    *d*×*m* dimensional weight matrix where *d* is the number of units in the hidden
    layer; consequently, the transposed matrix **W**^(^h^)^T is *m*×*d* dimensional.
    The bias vector **b**^(^h^) consists of *d* bias units (one bias unit per hidden
    node).
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，**z**^(^h^) 是我们的 1×*m* 维特征向量。**W**^(^h^) 是一个 *d*×*m* 维权重矩阵，其中 *d* 是隐藏层中的单元数；因此，转置矩阵
    **W**^(^h^)^T 是 *m*×*d* 维的。偏置向量 **b**^(^h^) 包含 *d* 个偏置单元（每个隐藏节点一个偏置单元）。
- en: After matrix-vector multiplication, we obtain the 1×*d* dimensional net input
    vector **z**^(^h^) to calculate the activation **a**^(^h^) (where ![](img/B17582_11_024.png)).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在矩阵-向量乘法之后，我们得到 1×*d* 维的净输入向量 **z**^(^h^)，用于计算激活 **a**^(^h^)（其中 ![](img/B17582_11_024.png)）。
- en: 'Furthermore, we can generalize this computation to all *n* examples in the
    training dataset:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们可以将这一计算推广到训练数据集中的所有 *n* 个示例：
- en: '**Z**^(^h^) = **X**^(^(in)^)**W**^(^h^)^T + **b**^(^h^)'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '**Z**^(^h^) = **X**^(^(in)^)**W**^(^h^)^T + **b**^(^h^)'
- en: 'Here, **X**^(^(in)^) is now an *n*×*m* matrix, and the matrix multiplication
    will result in an *n*×*d* dimensional net input matrix, **Z**^(^h^). Finally,
    we apply the activation function ![](img/B17582_11_007.png) to each value in the
    net input matrix to get the *n*×*d* activation matrix in the next layer (here,
    the output layer):'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，**X**^(^(in)^)现在是一个*n*×*m*矩阵，矩阵乘法将得到一个*n*×*d*维度的净输入矩阵**Z**^(^h^)。最后，我们对净输入矩阵中的每个值应用激活函数
    ![](img/B17582_11_007.png)，以获得下一层（这里是输出层）的*n*×*d*激活矩阵：
- en: '![](img/B17582_11_026.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17582_11_026.png)'
- en: 'Similarly, we can write the activation of the output layer in vectorized form
    for multiple examples:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 同样地，我们可以为多个示例的输出层激活以向量化形式编写：
- en: '**Z**^(^(out)^) = **A**^(^h^)**W**^(^(out)^)^T + **b**^(^(out)^)'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '**Z**^(^(out)^) = **A**^(^h^)**W**^(^(out)^)^T + **b**^(^(out)^)'
- en: Here, we multiply the transpose of the *t*×*d* matrix **W**^(^(out)^) (*t* is
    the number of output units) by the *n*×*d* dimensional matrix, **A**^(^h^), and
    add the *t* dimensional bias vector **b**^(^(out)^) to obtain the *n*×*t* dimensional
    matrix, **Z**^(^(out)^). (The columns in this matrix represent the outputs for
    each sample.)
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将*t*×*d*矩阵**W**^(^(out)^)的转置（*t*是输出单元的数量）乘以*n*×*d*维度矩阵**A**^(^h^)，并加上*t*维度偏置向量**b**^(^(out)^)，以获得*n*×*t*维度矩阵**Z**^(^(out)^)（该矩阵中的列表示每个样本的输出）。
- en: 'Lastly, we apply the sigmoid activation function to obtain the continuous-valued
    output of our network:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们应用sigmoid激活函数来获得网络的连续值输出：
- en: '![](img/B17582_11_027.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17582_11_027.png)'
- en: Similar to **Z**^(^(out)^), **A**^(^(out)^) is an *n*×*t* dimensional matrix.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于**Z**^(^(out)^)，**A**^(^(out)^)是一个*n*×*t*维度的矩阵。
- en: Classifying handwritten digits
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分类手写数字
- en: In the previous section, we covered a lot of the theory around NNs, which can
    be a little bit overwhelming if you are new to this topic. Before we continue
    with the discussion of the algorithm for learning the weights of the MLP model,
    backpropagation, let’s take a short break from the theory and see an NN in action.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一节中，我们涵盖了关于NN的大量理论，如果您对此主题还不熟悉，可能会有点压倒性。在我们继续讨论MLP模型学习权重算法——反向传播之前，让我们从理论中稍作休息，看看NN的实际应用。
- en: '**Additional resources on backpropagation**'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '**反向传播的额外资源**'
- en: 'The NN theory can be quite complex; thus, we want to provide readers with additional
    resources that cover some of the topics we discuss in this chapter in more detail
    or from a different perspective:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: NN理论可能非常复杂；因此，我们希望为读者提供更详细或不同视角覆盖本章讨论主题的其他资源：
- en: '*Chapter 6*, *Deep Feedforward Networks*, *Deep Learning*, by *I. Goodfellow*,
    *Y. Bengio*, and *A. Courville*, MIT Press, 2016 (manuscripts freely accessible
    at [http://www.deeplearningbook.org](http://www.deeplearningbook.org)).'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*第6章*，*深度前馈网络*，*深度学习*，由*I. Goodfellow*、*Y. Bengio*和*A. Courville*著，MIT Press，2016年（手稿可在[http://www.deeplearningbook.org](http://www.deeplearningbook.org)免费获取）。'
- en: '*Pattern Recognition and Machine Learning*, by *C. M. Bishop*, Springer New
    York, 2006.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Pattern Recognition and Machine Learning*，由*C. M. Bishop*著，Springer New York出版，2006年。'
- en: 'Lecture video slides from Sebastian Raschka’s deep learning course:'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sebastian Raschka深度学习课程的讲座视频幻灯片：
- en: '[https://sebastianraschka.com/blog/2021/dl-course.html#l08-multinomial-logistic-regression--softmax-regression](https://sebastianraschka.com/blog/2021/dl-course.html#l08-multinomial-logistic-regression--softmax-regression)'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[https://sebastianraschka.com/blog/2021/dl-course.html#l08-multinomial-logistic-regression--softmax-regression](https://sebastianraschka.com/blog/2021/dl-course.html#l08-multinomial-logistic-regression--softmax-regression)'
- en: '[https://sebastianraschka.com/blog/2021/dl-course.html#l09-multilayer-perceptrons-and-backpropration](https://sebastianraschka.com/blog/2021/dl-course.html#l09-multilayer-perceptrons-and-backpropration)'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[https://sebastianraschka.com/blog/2021/dl-course.html#l09-multilayer-perceptrons-and-backpropration](https://sebastianraschka.com/blog/2021/dl-course.html#l09-multilayer-perceptrons-and-backpropration)'
- en: 'In this section, we will implement and train our first multilayer NN to classify
    handwritten digits from the popular **Mixed National Institute of Standards and
    Technology** (**MNIST**) dataset that has been constructed by Yann LeCun and others
    and serves as a popular benchmark dataset for machine learning algorithms (*Gradient-Based
    Learning Applied to Document Recognition* by *Y. LeCun*, *L. Bottou*, *Y. Bengio*,
    and *P. Haffner*, *Proceedings of the IEEE*, 86(11): 2278-2324, 1998).'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '在本节中，我们将实现并训练我们的第一个多层NN来分类来自流行的**混合国家标准技术研究所**（**MNIST**）数据集的手写数字，该数据集由Yann
    LeCun和其他人构建，并作为机器学习算法的流行基准数据集（*基于梯度的学习应用于文档识别*，由*Y. LeCun*、*L. Bottou*、*Y. Bengio*和*P.
    Haffner*著，*IEEE会议论文集*，86(11): 2278-2324，1998年）。'
- en: Obtaining and preparing the MNIST dataset
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 获取和准备 MNIST 数据集
- en: 'The MNIST dataset is publicly available at [http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/)
    and consists of the following four parts:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: MNIST 数据集公开可用于 [http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/)，包括以下四个部分：
- en: '**Training dataset images**: `train-images-idx3-ubyte.gz` (9.9 MB, 47 MB unzipped,
    and 60,000 examples)'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**训练数据集图片**：`train-images-idx3-ubyte.gz`（9.9 MB，解压后 47 MB，共 60,000 个示例）'
- en: '**Training dataset labels**: `train-labels-idx1-ubyte.gz` (29 KB, 60 KB unzipped,
    and 60,000 labels)'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**训练数据集标签**：`train-labels-idx1-ubyte.gz`（29 KB，解压后 60 KB，共 60,000 个标签）'
- en: '**Test dataset images**: `t10k-images-idx3-ubyte.gz` (1.6 MB, 7.8 MB unzipped,
    and 10,000 examples)'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**测试数据集图片**：`t10k-images-idx3-ubyte.gz`（1.6 MB，解压后 7.8 MB，共 10,000 个示例）'
- en: '**Test dataset labels**: `t10k-labels-idx1-ubyte.gz` (5 KB, 10 KB unzipped,
    and 10,000 labels)'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**测试数据集标签**：`t10k-labels-idx1-ubyte.gz`（5 KB，解压后 10 KB，共 10,000 个标签）'
- en: The MNIST dataset was constructed from two datasets of the US **National Institute
    of Standards and Technology** (**NIST**). The training dataset consists of handwritten
    digits from 250 different people, 50 percent high school students, and 50 percent
    employees from the Census Bureau. Note that the test dataset contains handwritten
    digits from different people following the same split.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: MNIST 数据集由美国**国家标准与技术研究院**（**NIST**）的两个数据集构成。训练数据集包括来自 250 个不同人的手写数字，其中 50%
    是高中学生，另外 50% 是人口普查局的员工。请注意，测试数据集包含了不同人群的手写数字，遵循相同的拆分。
- en: 'Instead of downloading the abovementioned dataset files and preprocessing them
    into NumPy arrays ourselves, we will use scikit-learn’s new `fetch_openml` function,
    which allows us to load the MNIST dataset more conveniently:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不需要自己下载上述数据集文件并将它们预处理为 NumPy 数组，而是可以使用 scikit-learn 的新`fetch_openml`函数更方便地加载
    MNIST 数据集：
- en: '[PRE0]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'In scikit-learn, the `fetch_openml` function downloads the MNIST dataset from
    OpenML ([https://www.openml.org/d/554](https://www.openml.org/d/554)) as pandas
    `DataFrame` and Series objects, which is why we use the `.values` attribute to
    obtain the underlying NumPy arrays. (If you are using a scikit-learn version older
    than 1.0, `fetch_openml` downloads NumPy arrays directly so you can omit using
    the `.values` attribute.) The *n*×*m* dimensional `X` array consists of 70,000
    images with 784 pixels each, and the `y` array stores the corresponding 70,000
    class labels, which we can confirm by checking the dimensions of the arrays as
    follows:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在 scikit-learn 中，`fetch_openml` 函数从 OpenML ([https://www.openml.org/d/554](https://www.openml.org/d/554))
    下载 MNIST 数据集作为 pandas 的 `DataFrame` 和 Series 对象，因此我们使用 `.values` 属性来获取底层的 NumPy
    数组。（如果你使用的是 scikit-learn 版本低于 1.0，`fetch_openml` 直接下载 NumPy 数组，因此可以省略使用 `.values`
    属性。）`X` 数组的 *n*×*m* 维度由 70,000 张图片组成，每张图片有 784 个像素，`y` 数组存储了对应的 70,000 个类别标签，我们可以通过检查数组的维度来确认：
- en: '[PRE1]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The images in the MNIST dataset consist of 28×28 pixels, and each pixel is represented
    by a grayscale intensity value. Here, `fetch_openml` already unrolled the 28×28 pixels
    into one-dimensional row vectors, which represent the rows in our `X` array (784
    per row or image) above. The second array (`y`) returned by the `fetch_openml`
    function contains the corresponding target variable, the class labels (integers
    0-9) of the handwritten digits.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: MNIST 数据集中的图像由 28×28 像素组成，每个像素由灰度强度值表示。在这里，`fetch_openml` 已经将 28×28 像素展开为一维行向量，这些向量表示我们
    `X` 数组中的行（每行或每张图像有 784 个像素）。`fetch_openml` 函数返回的第二个数组 `y` 包含手写数字的相应目标变量，即类别标签（整数
    0-9）。
- en: 'Next, let’s normalize the pixels values in MNIST to the range –1 to 1 (originally
    0 to 255) via the following code line:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们通过以下代码行将 MNIST 中的像素值归一化到范围 -1 到 1（原始范围为 0 到 255）：
- en: '[PRE2]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The reason behind this is that gradient-based optimization is much more stable
    under these conditions, as discussed in *Chapter 2*. Note that we scaled the images
    on a pixel-by-pixel basis, which is different from the feature-scaling approach
    that we took in previous chapters.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 这样做的原因是在这些条件下，基于梯度的优化更加稳定，正如 *第 2 章* 中所讨论的。请注意，我们是基于像素的缩放，这与我们在前几章中采取的特征缩放方法不同。
- en: Previously, we derived scaling parameters from the training dataset and used
    these to scale each column in the training dataset and test dataset. However,
    when working with image pixels, centering them at zero and rescaling them to a
    [–1, 1] range is also common and usually works well in practice.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前从训练数据集中推导出了缩放参数，并将其用于缩放训练数据集和测试数据集中的每一列。然而，当处理图像像素时，通常将它们居中在零点并重新缩放到 [-1,
    1] 范围内，这也是常见且通常能很好地工作。
- en: 'To get an idea of how those images in MNIST look, let’s visualize examples
    of the digits 0-9 after reshaping the 784-pixel vectors from our feature matrix
    into the original 28×28 image that we can plot via Matplotlib’s `imshow` function:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解MNIST中这些图像的样子，让我们通过Matplotlib的`imshow`函数将我们特征矩阵中的784像素向量重塑为原始的28×28图像，并进行可视化：
- en: '[PRE3]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We should now see a plot of the 2×5 subfigures showing a representative image
    of each unique digit:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们应该看到一个由2×5个子图组成的图，显示每个唯一数字的代表性图像：
- en: '![A picture containing graphical user interface  Description automatically
    generated](img/B17582_11_04.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![包含图形用户界面的图片，自动生成的描述](img/B17582_11_04.png)'
- en: 'Figure 11.4: A plot showing one randomly chosen handwritten digit from each
    class'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.4：显示每个类别中随机选择的一个手写数字的图
- en: 'In addition, let’s also plot multiple examples of the same digit to see how
    different the handwriting for each really is:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，让我们也绘制同一数字的多个示例，以查看每个数字的手写风格有多不同：
- en: '[PRE4]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'After executing the code, we should now see the first 25 variants of the digit
    7:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 执行完代码后，我们现在应该看到数字7的前25个变体：
- en: '![A picture containing calendar  Description automatically generated](img/B17582_11_05.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![包含日历的图片，自动生成的描述](img/B17582_11_05.png)'
- en: 'Figure 11.5: Different variants of the handwritten digit 7'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.5：手写数字7的不同变体
- en: 'Finally, let’s divide the dataset into training, validation, and test subsets.
    The following code will split the dataset such that 55,000 images are used for
    training, 5,000 images for validation, and 10,000 images for testing:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们将数据集分为训练、验证和测试子集。以下代码将分割数据集，使得55,000张图像用于训练，5,000张图像用于验证，以及10,000张图像用于测试：
- en: '[PRE5]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Implementing a multilayer perceptron
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实现多层感知器
- en: In this subsection, we will now implement an MLP from scratch to classify the
    images in the MNIST dataset. To keep things simple, we will implement an MLP with
    only one hidden layer. Since the approach may seem a little bit complicated at
    first, you are encouraged to download the sample code for this chapter from the
    Packt Publishing website or from GitHub ([https://github.com/rasbt/machine-learning-book](https://github.com/rasbt/machine-learning-book))
    so that you can view this MLP implementation annotated with comments and syntax
    highlighting for better readability.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在本小节中，我们现在将从头开始实现一个MLP来对MNIST数据集中的图像进行分类。为了保持简单，我们将只实现一个只有一个隐藏层的MLP。由于这种方法一开始可能看起来有点复杂，建议你从Packt
    Publishing的网站或GitHub ([https://github.com/rasbt/machine-learning-book](https://github.com/rasbt/machine-learning-book))下载本章的示例代码，以便查看带有注释和语法高亮的MLP实现，以提高可读性。
- en: 'If you are not running the code from the accompanying Jupyter Notebook file
    or don’t have access to the internet, copy the `NeuralNetMLP` code from this chapter
    into a Python script file in your current working directory (for example, `neuralnet.py)`,
    which you can then import into your current Python session via the following command:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你没有从附带的Jupyter Notebook文件运行代码，或者无法访问互联网，可以将本章中的`NeuralNetMLP`代码复制到你当前工作目录下的Python脚本文件中（例如`neuralnet.py`），然后通过以下命令将其导入到当前的Python会话中：
- en: '[PRE6]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The code will contain parts that we have not talked about yet, such as the backpropagation
    algorithm. Do not worry if not all the code makes immediate sense to you; we will
    follow up on certain parts later in this chapter. However, going over the code
    at this stage can make it easier to follow the theory later.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 代码将包含一些我们尚未讨论的部分，例如反向传播算法。如果代码中的某些部分目前对你来说并不完全理解，不必担心；我们稍后会对某些部分进行跟进。然而，在这个阶段检查代码可以使后续的理论更容易理解。
- en: 'So, let’s look at the following implementation of an MLP, starting with the
    two helper functions to compute the logistic sigmoid activation and to convert
    integer class label arrays to one-hot encoded labels:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，让我们来看下面的多层感知器的实现，从计算逻辑sigmoid激活和将整数类标签数组转换为独热编码标签的两个辅助函数开始：
- en: '[PRE7]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Below, we implement the main class for our MLP, which we call `NeuralNetMLP`.
    There are three class methods, `.__init__()`, `.forward()`, and `.backward()`,
    that we will discuss one by one, starting with the `__init__` constructor:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 下面，我们实现了我们的多层感知器的主类，我们称之为`NeuralNetMLP`。有三个类方法，`. __init__()`, `.forward()`,
    和 `.backward()`，我们将逐一讨论，从`__init__`构造函数开始：
- en: '[PRE8]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The `__init__` constructor instantiates the weight matrices and bias vectors
    for the hidden and the output layer. Next, let’s see how these are used in the
    `forward` method to make predictions:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '`__init__` 构造函数实例化了隐藏层和输出层的权重矩阵和偏置向量。接下来，让我们看看这些如何在 `forward` 方法中用于进行预测：'
- en: '[PRE9]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The `forward` method takes in one or more training examples and returns the
    predictions. In fact, it returns both the activation values from the hidden layer
    and the output layer, `a_h` and `a_out`. While `a_out` represents the class-membership
    probabilities that we can convert to class labels, which we care about, we also
    need the activation values from the hidden layer, `a_h`, to optimize the model
    parameters; that is, the weight and bias units of the hidden and output layers.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '`forward` 方法接收一个或多个训练样本，并返回预测结果。实际上，它同时返回隐藏层和输出层的激活值，`a_h` 和 `a_out`。而 `a_out`
    表示类成员概率，我们可以将其转换为类标签，这是我们关心的内容，同时我们还需要隐藏层的激活值 `a_h` 来优化模型参数，即隐藏层和输出层的权重和偏置单元。'
- en: 'Finally, let’s talk about the `backward` method, which updates the weight and
    bias parameters of the neural network:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们谈谈 `backward` 方法，它更新神经网络的权重和偏置参数：
- en: '[PRE10]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The `backward` method implements the so-called *backpropagation* algorithm,
    which calculates the gradients of the loss with respect to the weight and bias
    parameters. Similar to Adaline, these gradients are then used to update these
    parameters via gradient descent. Note that multilayer NNs are more complex than
    their single-layer siblings, and we will go over the mathematical concepts of
    how to compute the gradients in a later section after discussing the code. For
    now, just consider the `backward` method as a way for computing gradients that
    are used for the gradient descent updates. For simplicity, the loss function this
    derivation is based on is the same MSE loss that we used in Adaline. In later
    chapters, we will look at alternative loss functions, such as multi-category cross-entropy
    loss, which is a generalization of the binary logistic regression loss to multiple
    classes.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '`backward` 方法实现了所谓的*反向传播*算法，计算损失相对于权重和偏置参数的梯度。与 Adaline 类似，这些梯度然后用于通过梯度下降更新这些参数。请注意，多层神经网络比它们的单层兄弟更复杂，我们将在后面的部分讨论代码后讨论如何计算梯度的数学概念。现在，只需将
    `backward` 方法视为计算梯度以用于梯度下降更新的一种方法。为简单起见，此推导基于的损失函数与 Adaline 中使用的相同的 MSE 损失函数相同。在后续章节中，我们将看到替代损失函数，例如多类别交叉熵损失，它是二元逻辑回归损失向多个类别的泛化。'
- en: Looking at this code implementation of the `NeuralNetMLP` class, you may have
    noticed that this object-oriented implementation differs from the familiar scikit-learn
    API that is centered around the `.fit()` and `.predict()` methods. Instead, the
    main methods of the `NeuralNetMLP` class are the `.forward()` and `.backward()`
    methods. One of the reasons behind this is that it makes a complex neural network
    a bit easier to understand in terms of how the information flows through the networks.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 查看 `NeuralNetMLP` 类的此代码实现，您可能已经注意到，这种面向对象的实现与围绕 `.fit()` 和 `.predict()` 方法为中心的熟悉
    scikit-learn API 有所不同。相反，`NeuralNetMLP` 类的主要方法是 `.forward()` 和 `.backward()` 方法。其背后的一个原因是，这样做可以使复杂的神经网络在信息流通过网络方面更容易理解一些。
- en: Another reason is that this implementation is relatively similar to how more
    advanced deep learning libraries such as PyTorch operate, which we will introduce
    and use in the upcoming chapters to implement more complex neural networks.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个原因是，这种实现与诸如 PyTorch 等更高级深度学习库的运行方式相对类似，我们将在接下来的章节中介绍并使用这些库来实现更复杂的神经网络。
- en: 'After we have implemented the `NeuralNetMLP` class, we use the following code
    to instantiate a new `NeuralNetMLP` object:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们实现了 `NeuralNetMLP` 类之后，我们使用以下代码来实例化一个新的 `NeuralNetMLP` 对象：
- en: '[PRE11]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The `model` accepts MNIST images reshaped into 784-dimensional vectors (in the
    format of `X_train`, `X_valid`, or `X_test`, which we defined previously) for
    the 10 integer classes (digits 0-9). The hidden layer consists of 50 nodes. Also,
    as you may be able to tell from looking at the previously defined `.forward()`
    method, we use a sigmoid activation function after the first hidden layer and
    output layer to keep things simple. In later chapters, we will learn about alternative
    activation functions for both the hidden and output layers.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '`model`接受将 MNIST 图像重塑为 784 维向量（格式为`X_train`、`X_valid`或`X_test`，我们之前定义过）的输入，用于
    10 个整数类（数字 0-9）。隐藏层由 50 个节点组成。另外，如您可以从先前定义的`.forward()`方法中看到的那样，我们在第一个隐藏层和输出层之后使用了
    sigmoid 激活函数，以保持简单。在后面的章节中，我们将学习关于隐藏层和输出层的替代激活函数。'
- en: '*Figure 11.6* summarizes the neural network architecture that we instantiated
    above:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 11.6* 总结了我们上面实例化的神经网络架构：'
- en: '![Diagram  Description automatically generated](img/B17582_11_06.png)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![自动生成的图表描述](img/B17582_11_06.png)'
- en: 'Figure 11.6: The NN architecture for labeling handwritten digits'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.6：用于标记手写数字的 NN 架构
- en: In the next subsection, we are going to implement the training function that
    we can use to train the network on mini-batches of the data via backpropagation.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一小节中，我们将实现训练函数，通过反向传播在小批量数据上训练网络。
- en: Coding the neural network training loop
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 编写神经网络训练循环
- en: Now that we have implemented the `NeuralNetMLP` class in the previous subsection
    and initiated a model, the next step is to train the model. We will tackle this
    in multiple steps. First, we will define some helper functions for data loading.
    Second, we will embed these functions into the training loop that iterates over
    the dataset in multiple epochs.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经在前一小节中实现了`NeuralNetMLP`类并初始化了一个模型，下一步是训练模型。我们将分步骤完成此过程。首先，我们将为数据加载定义一些辅助函数。其次，我们将这些函数嵌入到遍历多个时期的训练循环中。
- en: 'The first function we are going to define is a mini-batch generator, which
    takes in our dataset and divides it into mini-batches of a desired size for stochastic
    gradient descent training. The code is as follows:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 我们要定义的第一个函数是小批量生成器，它接受我们的数据集并将其分成用于随机梯度下降训练的所需大小的小批量。代码如下：
- en: '[PRE12]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Before we move on to the next functions, let’s confirm that the mini-batch
    generator works as intended and produces mini-batches of the desired size. The
    following code will attempt to iterate through the dataset, and then we will print
    the dimension of the mini-batches. Note that in the following code examples, we
    will remove the `break` statements. The code is as follows:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续下一个函数之前，让我们确认小批量生成器按预期工作，并生成所需大小的小批量。以下代码将尝试遍历数据集，然后我们将打印小批量的维度。请注意，在以下代码示例中，我们将删除`break`语句。代码如下：
- en: '[PRE13]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: As we can see, the network returns mini-batches of size 100 as intended.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，网络按预期返回大小为 100 的小批量。
- en: 'Next, we have to define our loss function and performance metric that we can
    use to monitor the training process and evaluate the model. The MSE loss and accuracy
    function can be implemented as follows:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们必须定义损失函数和性能度量，以便监控训练过程并评估模型。可以实现 MSE 损失和准确率函数如下：
- en: '[PRE14]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Let’s test the preceding function and compute the initial validation set MSE
    and accuracy of the model we instantiated in the previous section:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们测试前述函数并计算我们在上一节中实例化的模型的初始验证集 MSE 和准确率：
- en: '[PRE15]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: In this code example, note that `model.forward()` returns the hidden and output
    layer activations. Remember that we have 10 output nodes (one corresponding to
    each unique class label). Hence, when computing the MSE, we first converted the
    class labels into one-hot encoded class labels in the `mse_loss()` function. In
    practice, it does not make a difference whether we average over the row or the
    columns of the squared-difference matrix first, so we simply call `np.mean()`
    without any axis specification so that it returns a scalar.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在此代码示例中，请注意`model.forward()`返回隐藏层和输出层的激活。请记住，我们有 10 个输出节点（每个对应一个唯一的类标签）。因此，在计算
    MSE 时，我们首先在`mse_loss()`函数中将类标签转换为独热编码的类标签。在实践中，首先对平方差矩阵的行或列求平均值没有区别，因此我们只需调用`np.mean()`而不指定任何轴，这样它将返回一个标量。
- en: The output layer activations, since we used the logistic sigmoid function, are
    values in the range [0, 1]. For each input, the output layer produces 10 values
    in the range [0, 1], so we used the `np.argmax()` function to select the index
    position of the largest value, which yields the predicted class label. We then
    compared the true labels with the predicted class labels to compute the accuracy
    via the `accuracy()` function we defined. As we can see from the preceding output,
    the accuracy is not very high. However, given that we have a balanced dataset
    with 10 classes, a prediction accuracy of approximately 10 percent is what we
    would expect for an untrained model producing random predictions.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们使用了逻辑 sigmoid 函数，输出层的激活值处于 [0, 1] 范围内。对于每个输入，输出层产生的是在 [0, 1] 范围内的 10 个值，因此我们使用了
    `np.argmax()` 函数来选择最大值的索引位置，这个索引位置即预测的类别标签。然后，我们将真实标签与预测的类别标签进行比较，通过我们定义的 `accuracy()`
    函数来计算准确率。从前面的输出可以看出，准确率并不是很高。然而，考虑到我们有一个包含 10 个类别的平衡数据集，一个未经训练的模型产生随机预测的情况下，大约
    10% 的预测准确率是可以预期的。
- en: 'Using the previous code, we can compute the performance on, for example, the
    whole training set if we provide `y_train` as input to targets and the predicted
    labels from feeding the model with `X_train`. However, in practice, our computer
    memory is usually a limiting factor for how much data the model can ingest in
    one forward pass (due to the large matrix multiplications). Hence, we are defining
    our MSE and accuracy computation based on our previous mini-batch generator. The
    following function will compute the MSE and accuracy incrementally by iterating
    over the dataset one mini-batch at a time to be more memory-efficient:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 使用前面的代码，例如，如果我们将 `y_train` 提供为目标的输入，并将模型输入 `X_train` 进行预测，我们可以计算整个训练集的性能。然而，在实践中，由于计算机内存通常限制了模型一次正向传递可以接收多少数据（由于大矩阵乘法），因此我们根据我们之前的小批量生成器定义了我们的
    MSE 和准确率计算。以下函数将逐个小批量地迭代整个数据集来更加高效地使用内存计算 MSE 和准确率：
- en: '[PRE16]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Before we implement the training loop, let’s test the function and compute
    the initial training set MSE and accuracy of the model we instantiated in the
    previous section and make sure it works as intended:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们实现训练循环之前，让我们测试这个函数，并计算前面部分中实例化的模型的初始训练集均方误差（MSE）和准确率，并确保其按预期工作：
- en: '[PRE17]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: As we can see from the results, our generator approach produces the same results
    as the previously defined MSE and accuracy functions, except for a small rounding
    error in the MSE (0.27 versus 0.28), which is negligible for our purposes.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 从结果中可以看出，我们的生成器方法产生了与先前定义的 MSE 和准确率函数相同的结果，除了 MSE 中的小舍入误差（0.27 对比 0.28），对我们的目的来说可以忽略不计。
- en: 'Let’s now get to the main part and implement the code to train our model:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们来到主要部分，实现训练我们的模型的代码：
- en: '[PRE18]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'On a high level, the `train()` function iterates over multiple epochs, and
    in each epoch, it used the previously defined `minibatch_generator()` function
    to iterate over the whole training set in mini-batches for stochastic gradient
    descent training. Inside the mini-batch generator `for` loop, we obtain the outputs
    from the model, `a_h` and `a_out`, via its `.forward()` method. Then, we compute
    the loss gradients via the model’s `.backward()` method—the theory will be explained
    in a later section. Using the loss gradients, we update the weights by adding
    the negative gradient multiplied by the learning rate. This is the same concept
    that we discussed earlier for Adaline. For example, to update the model weights
    of the hidden layer, we defined the following line:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 从高层次上来看，`train()` 函数迭代多个 epoch，在每个 epoch 中，它使用之前定义的 `minibatch_generator()`
    函数以小批量进行随机梯度下降训练整个训练集。在小批量生成器的 `for` 循环内部，我们通过模型的 `.forward()` 方法获取模型的输出 `a_h`
    和 `a_out`。然后，我们通过模型的 `.backward()` 方法计算损失梯度——这个理论将在后面的部分中解释。利用损失梯度，我们通过学习率乘以负梯度来更新权重。这与我们之前为
    Adaline 讨论的概念相同。例如，要更新隐藏层的模型权重，我们定义了以下行：
- en: '[PRE19]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'For a single weight, *w*[j], this corresponds to the following partial derivative-based
    update:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 对于单个权重 *w*[j]，这对应于以下基于偏导数的更新：
- en: '![](img/B17582_11_028.png)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17582_11_028.png)'
- en: Finally, the last portion of the previous code computes the losses and prediction
    accuracies on the training and test sets to track the training progress.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，前面代码的最后部分计算了训练集和测试集上的损失和预测准确率，以跟踪训练进展。
- en: 'Let’s now execute this function to train our model for 50 epochs, which may
    take a few minutes to finish:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们执行此函数，训练我们的模型 50 个时期，可能需要几分钟才能完成：
- en: '[PRE20]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'During training, we should see the following output:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练过程中，我们应该看到以下输出：
- en: '[PRE21]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The reason why we print all this output is that, in NN training, it is really
    useful to compare training and validation accuracy. This helps us judge whether
    the network model performs well, given the architecture and hyperparameters. For
    example, if we observe a low training and validation accuracy, there is likely
    an issue with the training dataset, or the hyperparameters’ settings are not ideal.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 打印所有这些输出的原因是，在神经网络训练中，比较训练和验证精度真的很有用。这有助于我们判断网络模型在给定架构和超参数情况下的表现是否良好。例如，如果我们观察到低训练和验证精度，则训练数据集可能存在问题，或者超参数设置不理想。
- en: In general, training (deep) NNs is relatively expensive compared with the other
    models we’ve discussed so far. Thus, we want to stop it early in certain circumstances
    and start over with different hyperparameter settings. On the other hand, if we
    find that it increasingly tends to overfit the training data (noticeable by an
    increasing gap between training and validation dataset performance), we may want
    to stop the training early, as well.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，训练（深度）神经网络相对于我们到目前为止讨论的其他模型来说成本相对较高。因此，在某些情况下，我们希望及早停止，并使用不同的超参数设置重新开始。另一方面，如果我们发现它越来越倾向于过拟合训练数据（通过训练和验证数据集性能之间逐渐增加的差距可察觉），我们也可能希望提前停止训练。
- en: In the next subsection, we will discuss the performance of our NN model in more
    detail.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一小节中，我们将更详细地讨论我们的神经网络模型的性能。
- en: Evaluating the neural network performance
  id: totrans-175
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 评估神经网络性能
- en: Before we discuss backpropagation, the training procedure of NNs, in more detail
    in the next section, let’s look at the performance of the model that we trained
    in the previous subsection.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们在下一节更详细讨论神经网络的反向传播（NNs）训练过程之前，让我们先看看我们在前一小节中训练的模型的性能。
- en: 'In `train()`, we collected the training loss and the training and validation
    accuracy for each epoch so that we can visualize the results using Matplotlib.
    Let’s look at the training MSE loss first:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在`train()`中，我们收集了每个时期的训练损失以及训练和验证精度，以便可以使用 Matplotlib 可视化结果。让我们先看一下训练 MSE 损失：
- en: '[PRE22]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The preceding code plots the loss over the 50 epochs, as shown in *Figure 11.7*:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 前述代码绘制了 50 个时期内的损失，如*图 11.7*所示：
- en: '![Shape, square  Description automatically generated](img/B17582_11_07.png)'
  id: totrans-180
  prefs: []
  type: TYPE_IMG
  zh: '![形状，正方形 由自动生成的描述](img/B17582_11_07.png)'
- en: 'Figure 11.7: A plot of the MSE by the number of training epochs'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.7：MSE 与训练时期数量的图表
- en: As we can see, the loss decreased substantially during the first 10 epochs and
    seems to slowly converge in the last 10 epochs. However, the small slope between
    epoch 40 and epoch 50 indicates that the loss would further decrease with training
    over additional epochs.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，在前 10 个时期内损失大幅减少，并在后 10 个时期内缓慢收敛。然而，在第 40 到第 50 个时期之间的小斜率表明，随着额外的时期训练，损失还将进一步减少。
- en: 'Next, let’s take a look at the training and validation accuracy:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们来看看训练和验证精度：
- en: '[PRE23]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The preceding code examples plot those accuracy values over the 50 training
    epochs, as shown in *Figure 11.8*:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 前述代码示例绘制了这些准确率值在 50 个训练时期内的情况，如*图 11.8*所示：
- en: '![A picture containing graphical user interface  Description automatically
    generated](img/B17582_11_08.png)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
  zh: '![包含图形用户界面的图片 由自动生成的描述](img/B17582_11_08.png)'
- en: 'Figure 11.8: Classification accuracy by the number of training epochs'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.8：训练时期分类准确率
- en: The plot reveals that the gap between training and validation accuracy increases
    as we train for more epochs. At approximately the 25th epoch, the training and
    validation accuracy values are almost equal, and then, the network starts to slightly
    overfit the training data.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 绘图显示，随着训练的进行，训练和验证精度之间的差距逐渐增大。在大约第 25 个时期，训练和验证精度几乎相等，然后网络开始略微过拟合训练数据。
- en: '**Reducing overfitting**'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '**减少过拟合**'
- en: One way to decrease the effect of overfitting is to increase the regularization
    strength via L2 regularization, which we introduced in *Chapter 3*, *A Tour of
    Machine Learning Classifiers Using Scikit-Learn*. Another useful technique for
    tackling overfitting in NNs is dropout, which will be covered in *Chapter 14*,
    *Classifying Images with Deep Convolutional Neural Networks*.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 减少过拟合效果的一种方法是通过L2正则化增加正则化强度，我们在 *第3章*，*使用Scikit-Learn进行机器学习分类器的简介* 中介绍过。在NN中应对过拟合的另一种有用技术是dropout，在
    *第14章*，*使用深度卷积神经网络对图像进行分类* 中将进行介绍。
- en: 'Finally, let’s evaluate the generalization performance of the model by calculating
    the prediction accuracy on the test dataset:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们通过计算在测试数据集上的预测准确率来评估模型的泛化性能：
- en: '[PRE24]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: We can see that the test accuracy is very close to the validation set accuracy
    corresponding to the last epoch (94.74%), which we reported during the training
    in the last subsection. Moreover, the respective training accuracy is only minimally
    higher at 95.59%, reaffirming that our model only slightly overfits the training
    data.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到测试准确率非常接近验证集准确率，对应于最后一个epoch（94.74%），我们在上一个小节的训练中报告过。此外，相应的训练准确率仅略高于95.59%，再次确认我们的模型仅轻微过拟合训练数据。
- en: To further fine-tune the model, we could change the number of hidden units,
    the learning rate, or use various other tricks that have been developed over the
    years but are beyond the scope of this book. In *Chapter 14*, *Classifying Images
    with Deep Convolutional Neural Networks*, you will learn about a different NN
    architecture that is known for its good performance on image datasets.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 要进一步微调模型，我们可以改变隐藏单元的数量、学习率，或者使用多年来开发的其他各种技巧，但这超出了本书的范围。在 *第14章*，*使用深度卷积神经网络对图像进行分类*，您将了解到一种不同的NN架构，以其在图像数据集上的良好性能而闻名。
- en: Also, the chapter will introduce additional performance-enhancing tricks such
    as adaptive learning rates, more sophisticated SGD-based optimization algorithms,
    batch normalization, and dropout.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，本章还将介绍其他增强性能的技巧，如自适应学习率、更复杂的基于SGD的优化算法、批归一化和dropout。
- en: 'Other common tricks that are beyond the scope of the following chapters include:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 其他常见的技巧超出了以下章节的范围：
- en: Adding skip-connections, which are the main contribution of residual NNs (*Deep
    residual learning for image recognition* by *K. He*, *X. Zhang*, *S. Ren*, and
    *J. Sun*, *Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition*,
    pp. 770-778, 2016)
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 添加跳跃连接，这是残差神经网络的主要贡献（*深度残差学习用于图像识别*，作者 *K. He*, *X. Zhang*, *S. Ren* 和 *J. Sun*，*IEEE计算机视觉与模式识别会议论文集*，2016年，第770-778页）
- en: Using learning rate schedulers that change the learning rate during training
    (*Cyclical learning rates for training neural networks* by *L.N. Smith*, *2017
    IEEE Winter Conference on Applications of Computer Vision (WACV)*, pp. 464-472,
    2017)
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用学习率调度程序，在训练过程中改变学习率（*用于训练神经网络的循环学习率*，作者 *L.N. Smith*，*2017 IEEE冬季计算机视觉应用会议*，2017年，第464-472页）
- en: Attaching loss functions to earlier layers in the networks as it’s being done
    in the popular Inception v3 architecture (*Rethinking the Inception architecture
    for computer vision by C. Szegedy*, *V. Vanhoucke*, *S. Ioffe*, *J. Shlens*, and
    *Z. Wojna*, *Proceedings of the IEEE Conference on Computer Vision and Pattern
    Recognition*, pp. 2818-2826, 2016)
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将损失函数附加到网络中较早的层中，就像在流行的Inception v3架构中所做的那样（*重新思考Inception架构用于计算机视觉*，作者 *C.
    Szegedy*, *V. Vanhoucke*, *S. Ioffe*, *J. Shlens* 和 *Z. Wojna*，*IEEE计算机视觉与模式识别会议论文集*，2016年，第2818-2826页）
- en: 'Lastly, let’s take a look at some of the images that our MLP struggles with
    by extracting and plotting the first 25 misclassified samples from the test set:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们看一些我们的多层感知器在测试集中提取和绘制的前25个错误分类样本的图片：
- en: '[PRE25]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'We should now see a 5×5 subplot matrix where the first number in the subtitles
    indicates the plot index, the second number represents the true class label (`True`),
    and the third number stands for the predicted class label (`Predicted`):'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们应该看到一个5×5的子图矩阵，其中副标题中的第一个数字表示图表索引，第二个数字代表真实类标签（`True`），第三个数字表示预测类标签（`Predicted`）：
- en: '![A picture containing text, electronics, keyboard  Description automatically
    generated](img/B17582_11_09.png)'
  id: totrans-203
  prefs: []
  type: TYPE_IMG
  zh: '![包含文本、电子设备、键盘的图片 描述已自动生成](img/B17582_11_09.png)'
- en: 'Figure 11.9: Handwritten digits that the model fails to classify correctly'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.9：模型无法正确分类的手写数字
- en: As we can see in *Figure 11.9*, among others, the network finds 7s challenging
    when they include a horizontal line as in examples 19 and 20\. Looking back at
    an earlier figure in this chapter where we plotted different training examples
    of the number 7, we can hypothesize that the handwritten digit 7 with a horizontal
    line is underrepresented in our dataset and is often misclassified.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在*图11.9*中所看到的，网络在包含水平线的7时会感到挑战，例如第19和第20个例子。回顾本章早期的一个图中，我们绘制了数字7的不同训练示例，我们可以假设，带有水平线的手写数字7在我们的数据集中很少出现，并且经常被错误分类。
- en: Training an artificial neural network
  id: totrans-206
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练人工神经网络
- en: Now that we have seen an NN in action and have gained a basic understanding
    of how it works by looking over the code, let’s dig a little bit deeper into some
    of the concepts, such as the loss computation and the backpropagation algorithm
    that we implemented to learn the model parameters.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经看到了一个神经网络的运行，并通过查看代码获得了对其工作方式的基本理解，让我们深入挖掘一些概念，如损失计算和我们实现的反向传播算法，以学习模型参数。
- en: Computing the loss function
  id: totrans-208
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 计算损失函数
- en: As mentioned previously, we used an MSE loss (as in Adaline) to train the multilayer
    NN as it makes the derivation of the gradients a bit easier to follow. In later
    chapters, we will discuss other loss functions, such as the multi-category cross-entropy
    loss (a generalization of the binary logistic regression loss), which is a more
    common choice for training NN classifiers.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，我们使用了MSE损失（如Adaline中的损失）来训练多层NN，因为这样做可以更容易地推导出梯度。在后续章节中，我们将讨论其他损失函数，如多类别交叉熵损失（二元逻辑回归损失的一般化），这是训练NN分类器更常见的选择。
- en: 'In the previous section, we implemented an MLP for multiclass classification
    that returns an output vector of *t* elements that we need to compare to the *t*×1
    dimensional target vector in the one-hot encoding representation. If we predict
    the class label of an input image with class label 2, using this MLP, the activation
    of the third layer and the target may look like this:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的部分，我们实现了一个用于多类分类的MLP，它返回一个*t*元素的输出向量，我们需要将其与一个*t*×1维的目标向量（使用独热编码表示）进行比较。如果我们使用这个MLP来预测一个输入图像的类标签为2，则第三层的激活和目标可能如下所示：
- en: '![](img/B17582_11_029.png)'
  id: totrans-211
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17582_11_029.png)'
- en: 'Thus, our MSE loss either has to sum or average over the *t* activation units
    in our network in addition to averaging over the *n* examples in the dataset or
    mini-batch:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们的MSE损失不仅必须在网络中的*t*个激活单元上求和或平均，还必须在数据集或小批量中的*n*个示例上进行平均：
- en: '![](img/B17582_11_030.png)'
  id: totrans-213
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17582_11_030.png)'
- en: Here, again, the superscript [*i*] is the index of a particular example in our
    training dataset.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，再次提到，上标[*i*]是我们训练数据集中特定示例的索引。
- en: 'Remember that our goal is to minimize the loss function *L*(**W**); thus, we
    need to calculate the partial derivative of the parameters **W** with respect
    to each weight for every layer in the network:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，我们的目标是最小化损失函数*L*(**W**)，因此我们需要计算网络中每一层的参数**W**相对于每个权重的偏导数：
- en: '![](img/B17582_11_031.png)'
  id: totrans-216
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17582_11_031.png)'
- en: In the next section, we will talk about the backpropagation algorithm, which
    allows us to calculate those partial derivatives to minimize the loss function.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分中，我们将讨论反向传播算法，它允许我们计算这些偏导数以最小化损失函数。
- en: 'Note that **W** consists of multiple matrices. In an MLP with one hidden layer,
    we have the weight matrix, **W**^(^h^), which connects the input to the hidden
    layer, and **W**^(^(out)^), which connects the hidden layer to the output layer.
    A visualization of the three-dimensional tensor **W** is provided in *Figure 11.10*:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，**W**由多个矩阵组成。在一个具有一个隐藏层的MLP中，我们有连接输入到隐藏层的权重矩阵**W**^(^h^)，以及连接隐藏层到输出层的权重矩阵**W**^(^(out)^)。三维张量**W**的可视化如*图11.10*所示：
- en: '![Diagram, engineering drawing  Description automatically generated](img/B17582_11_10.png)'
  id: totrans-219
  prefs: []
  type: TYPE_IMG
  zh: '![图示，工程图 自动生成的说明](img/B17582_11_10.png)'
- en: 'Figure 11.10: A visualization of a three-dimensional tensor'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.10：三维张量的可视化
- en: In this simplified figure, it may seem that both **W**^(^h^) and **W**^(^(out)^)
    have the same number of rows and columns, which is typically not the case unless
    we initialize an MLP with the same number of hidden units, output units, and input
    features.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个简化的图中，似乎**W**^(^h^)和**W**^(^(out)^)的行数和列数相同，但通常情况下并非如此，除非我们初始化一个具有相同隐藏单元数、输出单元数和输入特征的MLP。
- en: If this sounds confusing, stay tuned for the next section, where we will discuss
    the dimensionality of **W**^(^h^) and **W**^(^(out)^) in more detail in the context
    of the backpropagation algorithm. Also, you are encouraged to read through the
    code of `NeuralNetMLP` again, which is annotated with helpful comments about the
    dimensionality of the different matrices and vector transformations.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这听起来让人困惑，那么请继续关注下一节内容，在那里我们将更详细地讨论在反向传播算法的背景下 **W**^(^h^) 和 **W**^(^(out)^)
    的维度问题。此外，你被鼓励再次阅读 `NeuralNetMLP` 的代码，其中有关不同矩阵和向量转换维度的注释。
- en: Developing your understanding of backpropagation
  id: totrans-223
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 发展你对反向传播的理解
- en: 'Although backpropagation was introduced to the neural network community more
    than 30 years ago (*Learning representations by backpropagating errors*, by *D.E.
    Rumelhart*, *G.E. Hinton*, and *R.J. Williams*, *Nature*, 323: 6088, pages 533–536,
    1986), it remains one of the most widely used algorithms for training artificial
    NNs very efficiently. If you are interested in additional references regarding
    the history of backpropagation, Juergen Schmidhuber wrote a nice survey article,
    *Who Invented Backpropagation?*, which you can find online at [http://people.idsia.ch/~juergen/who-invented-backpropagation.html](http://people.idsia.ch/~juergen/who-invented-backpropagation.html).'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '虽然反向传播是30多年前被引入神经网络社区的（*由 D.E. Rumelhart、G.E. Hinton 和 R.J. Williams 所著，《自然》323:
    6088, 页码 533–536, 1986），但它仍然是训练人工神经网络非常高效的最广泛使用的算法之一。如果你对反向传播的历史有兴趣，Juergen Schmidhuber
    写了一篇很好的调查文章，《谁发明了反向传播？》，你可以在这里找到：[http://people.idsia.ch/~juergen/who-invented-backpropagation.html](http://people.idsia.ch/~juergen/who-invented-backpropagation.html)。'
- en: This section will provide both a short, clear summary and the bigger picture
    of how this fascinating algorithm works before we dive into more mathematical
    details. In essence, we can think of backpropagation as a very computationally
    efficient approach to compute the partial derivatives of a complex, non-convex
    loss function in multilayer NNs. Here, our goal is to use those derivatives to
    learn the weight coefficients for parameterizing such a multilayer artificial
    NN. The challenge in the parameterization of NNs is that we are typically dealing
    with a very large number of model parameters in a high-dimensional feature space.
    In contrast to loss functions of single-layer NNs such as Adaline or logistic
    regression, which we have seen in previous chapters, the error surface of an NN
    loss function is not convex or smooth with respect to the parameters. There are
    many bumps in this high-dimensional loss surface (local minima) that we have to
    overcome in order to find the global minimum of the loss function.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入更多数学细节之前，本节将提供一个简短而清晰的总结，并展示这一迷人算法的整体图景。本质上，我们可以将反向传播视为一种非常高效的方法，用于计算多层神经网络中复杂非凸损失函数的偏导数。在这里，我们的目标是利用这些导数来学习参数化这样的多层人工神经网络的权重系数。在神经网络参数化中的挑战是，我们通常处理的是高维特征空间中的大量模型参数。与单层神经网络如
    Adaline 或 logistic 回归的损失函数不同，这些神经网络损失函数的误差表面对参数不是凸的或光滑的。在这种高维损失表面上有许多隆起（局部最小值），我们必须克服这些隆起，以找到损失函数的全局最小值。
- en: 'You may recall the concept of the chain rule from your introductory calculus
    classes. The chain rule is an approach to compute the derivative of a complex,
    nested function, such as *f*(*g*(*x*)), as follows:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能还记得在你的初级微积分课程中提到过链式法则的概念。链式法则是计算复杂的嵌套函数（例如 *f*(*g*(*x*))) 导数的一种方法，如下所示：
- en: '![](img/B17582_11_032.png)'
  id: totrans-227
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17582_11_032.png)'
- en: 'Similarly, we can use the chain rule for an arbitrarily long function composition.
    For example, let’s assume that we have five different functions, *f*(*x*), *g*(*x*),
    *h*(*x*), *u*(*x*), and *v*(*x*), and let *F* be the function composition: *F*(*x*) = *f*(*g*(*h*(*u*(*v*(*x*))))).
    Applying the chain rule, we can compute the derivative of this function as follows:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 同样地，我们可以对任意长的函数组合使用链式法则。例如，假设我们有五个不同的函数 *f*(*x*), *g*(*x*), *h*(*x*), *u*(*x*),
    和 *v*(*x*)，并且 *F* 是函数的组合：*F*(*x*) = *f*(*g*(*h*(*u*(*v*(*x*)))))。应用链式法则，我们可以计算这个函数的导数如下：
- en: '![](img/B17582_11_033.png)'
  id: totrans-229
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17582_11_033.png)'
- en: In the context of computer algebra, a set of techniques, known as **automatic
    differentiation**, has been developed to solve such problems very efficiently.
    If you are interested in learning more about automatic differentiation in machine
    learning applications, read A.G. Baydin and B.A. Pearlmutter’s article, *Automatic
    Differentiation of Algorithms for Machine Learning*, arXiv preprint arXiv:1404.7456,
    2014, which is freely available on arXiv at [http://arxiv.org/pdf/1404.7456.pdf](http://arxiv.org/pdf/1404.7456.pdf).
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 在计算代数的背景下，开发了一套称为**自动微分**的技术来非常高效地解决此类问题。如果您有兴趣了解机器学习应用中的自动微分更多信息，请阅读A.G. Baydin和B.A.
    Pearlmutter的文章，*Automatic Differentiation of Algorithms for Machine Learning*，arXiv预印本arXiv:1404.7456，2014年，可以在arXiv上免费获取，网址为[http://arxiv.org/pdf/1404.7456.pdf](http://arxiv.org/pdf/1404.7456.pdf)。
- en: Automatic differentiation comes with two modes, the forward and reverse modes;
    backpropagation is simply a special case of reverse-mode automatic differentiation.
    The key point is that applying the chain rule in forward mode could be quite expensive
    since we would have to multiply large matrices for each layer (Jacobians) that
    we would eventually multiply by a vector to obtain the output.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 自动微分有两种模式，前向模式和反向模式；反向传播只是反向模式自动微分的一个特例。关键点在于，在前向模式中应用链式法则可能非常昂贵，因为我们需要为每一层（雅可比矩阵）乘以一个大矩阵，最终将其乘以一个向量以获得输出。
- en: The trick of reverse mode is that we traverse the chain rule from right to left.
    We multiply a matrix by a vector, which yields another vector that is multiplied
    by the next matrix, and so on. Matrix-vector multiplication is computationally
    much cheaper than matrix-matrix multiplication, which is why backpropagation is
    one of the most popular algorithms used in NN training.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 反向模式的诀窍在于，我们从右到左遍历链式法则。我们将一个矩阵乘以一个向量，得到另一个乘以下一个矩阵的向量，依此类推。矩阵向量乘法在计算上比矩阵矩阵乘法便宜得多，这就是为什么反向传播是NN训练中最流行的算法之一。
- en: '**A basic calculus refresher**'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: '**基础微积分复习**'
- en: To fully understand backpropagation, we need to borrow certain concepts from
    differential calculus, which is outside the scope of this book. However, you can
    refer to a review chapter of the most fundamental concepts, which you might find
    useful in this context. It discusses function derivatives, partial derivatives,
    gradients, and the Jacobian. This text is freely accessible at [https://sebastianraschka.com/pdf/books/dlb/appendix_d_calculus.pdf](https://sebastianraschka.com/pdf/books/dlb/appendix_d_calculus.pdf).
    If you are unfamiliar with calculus or need a brief refresher, consider reading
    this text as an additional supporting resource before reading the next section.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 要完全理解反向传播，我们需要借鉴微分学的某些概念，这超出了本书的范围。但是，您可以参考一些最基本概念的复习章节，这在这种情况下可能会对您有所帮助。它讨论了函数导数、偏导数、梯度和雅可比矩阵。这本文在[https://sebastianraschka.com/pdf/books/dlb/appendix_d_calculus.pdf](https://sebastianraschka.com/pdf/books/dlb/appendix_d_calculus.pdf)上免费获取。如果您对微积分不熟悉或需要简要复习，请在阅读下一节之前考虑阅读此文作为额外支持资源。
- en: Training neural networks via backpropagation
  id: totrans-235
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过反向传播训练神经网络
- en: In this section, we will go through the math of backpropagation to understand
    how you can learn the weights in an NN very efficiently. Depending on how comfortable
    you are with mathematical representations, the following equations may seem relatively
    complicated at first.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分中，我们将通过反向传播的数学来理解如何高效学习神经网络中的权重。根据您对数学表示的熟悉程度，以下方程可能一开始看起来相对复杂。
- en: 'In a previous section, we saw how to calculate the loss as the difference between
    the activation of the last layer and the target class label. Now, we will see
    how the backpropagation algorithm works to update the weights in our MLP model
    from a mathematical perspective, which we implemented in the `.backward()` method
    of the `NeuralNetMLP()` class. As we recall from the beginning of this chapter,
    we first need to apply forward propagation to obtain the activation of the output
    layer, which we formulated as follows:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们看到了如何计算损失，即最后一层的激活与目标类别标签之间的差异。现在，我们将看看反向传播算法如何从数学角度上更新我们的MLP模型中的权重，我们在`NeuralNetMLP()`类的`.backward()`方法中实现了这一点。正如我们在本章开头所提到的，我们首先需要应用前向传播来获取输出层的激活，我们将其表述如下：
- en: '![](img/B17582_11_034.png)'
  id: totrans-238
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17582_11_034.png)'
- en: 'Concisely, we just forward-propagate the input features through the connections
    in the network, as shown by the arrows in *Figure 11.11* for a network with two
    input features, three hidden nodes, and two output nodes:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，我们只需将输入特征通过网络中的连接进行前向传播，如*图11.11*中显示的箭头所示，用于具有两个输入特征、三个隐藏节点和两个输出节点的网络：
- en: '![Diagram  Description automatically generated](img/B17582_11_11.png)'
  id: totrans-240
  prefs: []
  type: TYPE_IMG
  zh: '![图表 说明自动生成](img/B17582_11_11.png)'
- en: 'Figure 11.11: Forward-propagating the input features of an NN'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.11：前向传播NN的输入特征
- en: 'In backpropagation, we propagate the error from right to left. We can think
    of this as an application of the chain rule to the computation of the forward
    pass to compute the gradient of the loss with respect to the model weights (and
    bias units). For simplicity, we will illustrate this process for the partial derivative
    used to update the first weight in the weight matrix of the output layer. The
    paths of the computation we backpropagate are highlighted via the bold arrows
    below:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 在反向传播中，我们从右到左传播误差。我们可以将这看作是链式法则应用于计算前向传递以计算损失相对于模型权重（和偏置单元）的梯度。为简单起见，我们将用于更新输出层权重矩阵中第一个权重的偏导数的此过程进行说明。我们反向传播的计算路径通过下面的粗体箭头突出显示：
- en: '![Diagram  Description automatically generated](img/B17582_11_12.png)'
  id: totrans-243
  prefs: []
  type: TYPE_IMG
  zh: '![图表 说明自动生成](img/B17582_11_12.png)'
- en: 'Figure 11.12: Backpropagating the error of an NN'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.12：反向传播NN的误差
- en: 'If we include the net inputs *z* explicitly, the partial derivative computation
    shown in the previous figure expands as follows:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们明确包含净输入*z*，则在上一个图中显示的偏导数计算扩展如下：
- en: '![](img/B17582_11_035.png)'
  id: totrans-246
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17582_11_035.png)'
- en: To compute this partial derivative, which is used to update ![](img/B17582_11_036.png),
    we can compute the three individual partial derivative terms and multiply the
    results. For simplicity, we will omit averaging over the individual examples in
    the mini-batch, so we drop the ![](img/B17582_11_037.png) averaging term from
    the following equations.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 要计算这个偏导数，用于更新![](img/B17582_11_036.png)，我们可以计算三个单独的偏导数项并将结果相乘。为简单起见，我们将省略在小批量中对各个示例的平均，因此从以下方程中删除![](img/B17582_11_037.png)的平均项。
- en: 'Let’s start with ![](img/B17582_11_038.png), which is the partial derivative
    of the MSE loss (which simplifies to the squared error if we omit the mini-batch
    dimension) with respect to the predicted output score of the first output node:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从![](img/B17582_11_038.png)开始，这是MSE损失的偏导数（如果我们省略小批量维度，则简化为平方误差）相对于第一个输出节点的预测输出分数：
- en: '![](img/B17582_11_039.png)'
  id: totrans-249
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17582_11_039.png)'
- en: 'The next term is the derivative of the logistic sigmoid activation function
    that we used in the output layer:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个项是我们在输出层中使用的logistic sigmoid激活函数的导数：
- en: '![](img/B17582_11_040.png)'
  id: totrans-251
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17582_11_040.png)'
- en: 'Lastly, we compute the derivative of the net input with respect to the weight:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们计算净输入相对于权重的导数：
- en: '![](img/B17582_11_041.png)'
  id: totrans-253
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17582_11_041.png)'
- en: 'Putting all of it together, we get the following:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 将所有这些放在一起，我们得到以下内容：
- en: '![](img/B17582_11_042.png)'
  id: totrans-255
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17582_11_042.png)'
- en: 'We then use this value to update the weight via the familiar stochastic gradient
    descent update with a learning rate of ![](img/B17582_02_036.png):'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们使用此值通过学习率为![](img/B17582_02_036.png)的熟悉随机梯度下降更新权重：
- en: '![](img/B17582_11_044.png)'
  id: totrans-257
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17582_11_044.png)'
- en: 'In our code implementation of `NeuralNetMLP()`, we implemented the computation
    ![](img/B17582_11_045.png) in vectorized form in the `.backward()` method as follows:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的`NeuralNetMLP()`代码实现中，我们以向量化形式在`.backward()`方法中实现了![](img/B17582_11_045.png)的计算：
- en: '[PRE26]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '![](img/B17582_11_046.png)'
  id: totrans-260
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17582_11_046.png)'
- en: This is because ![](img/B17582_11_047.png) terms are involved in computing the
    partial derivatives (or gradients) of the hidden layer weights as well; hence,
    we can reuse ![](img/B17582_11_047.png).
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 这是因为在计算隐藏层权重的偏导数（或梯度）时涉及到![](img/B17582_11_047.png)项；因此，我们可以重复使用![](img/B17582_11_047.png)。
- en: 'Speaking of hidden layer weights, *Figure 11.13* illustrates how to compute
    the partial derivative of the loss with respect to the first weight of the hidden
    layer:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 谈到隐藏层权重，*图11.13*说明了如何计算与隐藏层第一个权重相关的损失的偏导数：
- en: '![A picture containing text, clock  Description automatically generated](img/B17582_11_13.png)'
  id: totrans-263
  prefs: []
  type: TYPE_IMG
  zh: '![包含文本、时钟的图片 说明自动生成](img/B17582_11_13.png)'
- en: 'Figure 11.13: Computing the partial derivatives of the loss with respect to
    the first hidden layer weight'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.13：计算与第一个隐藏层权重相关的损失的偏导数
- en: 'It is important to highlight that since the weight ![](img/B17582_11_049.png)
    is connected to both output nodes, we have to use the *multi-variable* chain rule
    to sum the two paths highlighted with bold arrows. As before, we can expand it
    to include the net inputs *z* and then solve the individual terms:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 值得强调的是，由于权重 ![](img/B17582_11_049.png) 连接到两个输出节点，我们必须使用*多变量*链式法则来求和用粗箭头突出显示的两条路径。像以前一样，我们可以扩展它以包括净输入
    *z*，然后解决各个术语：
- en: '![](img/B17582_11_050.png)'
  id: totrans-266
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17582_11_050.png)'
- en: 'Notice that if we reuse ![](img/B17582_11_047.png) computed previously, this
    equation can be simplified as follows:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，如果我们重复使用先前计算的 ![](img/B17582_11_047.png)，则可以将此方程简化如下：
- en: '![](img/B17582_11_052.png)'
  id: totrans-268
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17582_11_052.png)'
- en: The preceding terms can be individually solved relatively easily, as we have
    done previously, because there are no new derivatives involved. For example, ![](img/B17582_11_053.png)
    is the derivative of the sigmoid activation, that is, ![](img/B17582_11_054.png),
    and so forth. We’ll leave solving the individual parts as an optional exercise
    for you.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 由于之前已经单独解决了前述术语，因此相对容易解决，因为没有涉及新的导数。例如，![](img/B17582_11_053.png)是S形激活函数的导数，即![](img/B17582_11_054.png)，等等。我们将留给您作为可选练习来解决各个部分。
- en: About convergence in neural networks
  id: totrans-270
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关于神经网络中的收敛问题
- en: You might be wondering why we did not use regular gradient descent but instead
    used mini-batch learning to train our NN for the handwritten digit classification
    earlier. You may recall our discussion on SGD that we used to implement online
    learning. In online learning, we compute the gradient based on a single training
    example (*k* = 1) at a time to perform the weight update. Although this is a stochastic
    approach, it often leads to very accurate solutions with a much faster convergence
    than regular gradient descent. Mini-batch learning is a special form of SGD where
    we compute the gradient based on a subset *k* of the *n* training examples with
    1 < *k* < *n*. Mini-batch learning has an advantage over online learning in that
    we can make use of our vectorized implementations to improve computational efficiency.
    However, we can update the weights much faster than in regular gradient descent.
    Intuitively, you can think of mini-batch learning as predicting the voter turnout
    of a presidential election from a poll by asking only a representative subset
    of the population rather than asking the entire population (which would be equal
    to running the actual election).
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 也许你会想知道，为什么我们没有使用常规梯度下降，而是使用小批量学习来训练我们的手写数字分类NN。你可能还记得我们使用的在线学习SGD的讨论。在在线学习中，我们每次基于单个训练示例(*k*
    = 1)计算梯度以执行权重更新。虽然这是一种随机方法，但通常比常规梯度下降快得多地收敛到非常准确的解决方案。小批量学习是SGD的一种特殊形式，在这种形式中，我们基于*n*个训练示例中的子集*k*计算梯度，其中1
    < *k* < *n*。小批量学习比在线学习的优势在于，我们可以利用矢量化实现来提高计算效率。然而，我们可以比常规梯度下降更新权重得更快。直觉上，你可以将小批量学习视为预测总统选举中选民投票率的一种方式，通过询问人口的代表性子集，而不是询问整个人口（这等同于进行实际选举）。
- en: 'Multilayer NNs are much harder to train than simpler algorithms such as Adaline,
    logistic regression, or support vector machines. In multilayer NNs, we typically
    have hundreds, thousands, or even billions of weights that we need to optimize.
    Unfortunately, the output function has a rough surface, and the optimization algorithm
    can easily become trapped in local minima, as shown in *Figure 11.14*:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 多层神经网络比诸如Adaline、逻辑回归或支持向量机等简单算法难训练得多。在多层神经网络中，我们通常需要优化成百上千甚至数十亿个权重。不幸的是，输出函数的曲面粗糙，优化算法很容易陷入局部最小值，如*图11.14*所示：
- en: '![Diagram  Description automatically generated](img/B17582_11_14.png)'
  id: totrans-273
  prefs: []
  type: TYPE_IMG
  zh: '![Diagram  Description automatically generated](img/B17582_11_14.png)'
- en: 'Figure 11.14: Optimization algorithms can become trapped in local minima'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.14：优化算法可能陷入局部最小值
- en: Note that this representation is extremely simplified since our NN has many
    dimensions; it makes it impossible to visualize the actual loss surface for the
    human eye. Here, we only show the loss surface for a single weight on the *x*
    axis. However, the main message is that we do not want our algorithm to get trapped
    in local minima. By increasing the learning rate, we can more readily escape such
    local minima. On the other hand, we also increase the chance of overshooting the
    global optimum if the learning rate is too large. Since we initialize the weights
    randomly, we start with a solution to the optimization problem that is typically
    hopelessly wrong.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，由于我们的神经网络具有多个维度，这种表示极为简化，使得人眼无法可视化实际的损失曲面。在这里，我们只展示了单个权重在*x*轴上的损失曲面。然而，主要信息是我们不希望我们的算法陷入局部最小值。通过增加学习率，我们可以更容易地逃离这种局部最小值。另一方面，如果学习率过大，也会增加超越全局最优解的风险。由于我们随机初始化权重，因此我们从根本上开始解决优化问题的解通常是完全错误的。
- en: A few last words about the neural network implementation
  id: totrans-276
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关于神经网络实现的最后几句话
- en: You may be wondering why we went through all of this theory just to implement
    a simple multilayer artificial network that can classify handwritten digits instead
    of using an open source Python machine learning library. In fact, we will introduce
    more complex NN models in the next chapters, which we will train using the open
    source PyTorch library ([https://pytorch.org](https://pytorch.org)).
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能会想知道为什么我们要通过所有这些理论来实现一个简单的多层人工网络，而不是使用开源的Python机器学习库。实际上，在接下来的章节中，我们将介绍更复杂的神经网络模型，我们将使用开源的PyTorch库进行训练（[https://pytorch.org](https://pytorch.org)）。
- en: Although the from-scratch implementation in this chapter seems a bit tedious
    at first, it was a good exercise for understanding the basics behind backpropagation
    and NN training. A basic understanding of algorithms is crucial for applying machine
    learning techniques appropriately and successfully.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然本章中的从零开始实现起初看起来有些乏味，但对理解反向传播和神经网络训练背后的基础知识是一个很好的练习。对算法的基本理解对适当和成功地应用机器学习技术至关重要。
- en: Now that you have learned how feedforward NNs work, we are ready to explore
    more sophisticated DNNs using PyTorch, which allows us to construct NNs more efficiently,
    as we will see in *Chapter 12*, *Parallelizing Neural Network Training with PyTorch*.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经了解了前馈神经网络的工作原理，我们准备使用PyTorch探索更复杂的深度神经网络，这使得我们可以更高效地构建神经网络，正如我们将在*第12章*，*使用PyTorch并行化神经网络训练*中看到的。
- en: PyTorch, which was originally released in September 2016, has gained a lot of
    popularity among machine learning researchers, who use it to construct DNNs because
    of its ability to optimize mathematical expressions for computations on multidimensional
    arrays utilizing **graphics processing units** (**GPUs**).
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch最初发布于2016年9月，已经在机器学习研究人员中广受欢迎，他们使用它构建深度神经网络，因为它能够优化在多维数组上计算的数学表达式，利用**图形处理单元**（**GPU**）。
- en: Lastly, we should note that scikit-learn also includes a basic MLP implementation,
    `MLPClassifier`, which you can find at [https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html).
    While this implementation is great and very convenient for training basic MLPs,
    we strongly recommend specialized deep learning libraries, such as PyTorch, for
    implementing and training multilayer NNs.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们应该注意，scikit-learn还包括一个基本的MLP实现，`MLPClassifier`，您可以在[https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)找到。虽然这种实现非常方便用于训练基本的MLP，但我们强烈推荐使用专门的深度学习库，如PyTorch，来实现和训练多层神经网络。
- en: Summary
  id: totrans-282
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, you have learned the basic concepts behind multilayer artificial
    NNs, which are currently the hottest topic in machine learning research. In *Chapter
    2*, *Training Simple Machine Learning Algorithms for Classification*, we started
    our journey with simple single-layer NN structures and now we have connected multiple
    neurons to a powerful NN architecture to solve complex problems such as handwritten
    digit recognition. We demystified the popular backpropagation algorithm, which
    is one of the building blocks of many NN models that are used in deep learning.
    After learning about the backpropagation algorithm in this chapter, we are well
    equipped for exploring more complex DNN architectures. In the remaining chapters,
    we will cover more advanced deep learning concepts and PyTorch, an open source
    library that allows us to implement and train multilayer NNs more efficiently.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你已经学习了多层人工神经网络背后的基本概念，这是当前机器学习研究中最热门的话题。在*第二章*中，*训练简单的机器学习算法进行分类*，我们从简单的单层神经网络结构开始我们的旅程，现在我们已经将多个神经元连接到一个强大的神经网络架构中，以解决如手写数字识别等复杂问题。我们揭开了流行的反向传播算法的神秘面纱，这是许多深度学习模型的基石之一。在本章学习了反向传播算法之后，我们已经准备好探索更复杂的深度神经网络架构。在接下来的章节中，我们将涵盖更高级的深度学习概念以及PyTorch，这是一个开源库，可以更有效地实现和训练多层神经网络。
- en: Join our book’s Discord space
  id: totrans-284
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入我们书籍的Discord空间
- en: 'Join the book’s Discord workspace for a monthly *Ask me Anything* session with
    the authors:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 加入本书作者的Discord工作区，每月进行*问我任何事*会话：
- en: '[https://packt.link/MLwPyTorch](https://packt.link/MLwPyTorch)'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.link/MLwPyTorch](https://packt.link/MLwPyTorch)'
- en: '![](img/QR_Code874410888448293359.png)'
  id: totrans-287
  prefs: []
  type: TYPE_IMG
  zh: '![](img/QR_Code874410888448293359.png)'
