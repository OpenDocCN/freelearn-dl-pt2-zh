- en: Machine Learning for IoT
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: IoT的机器学习
- en: Machine learning has dramatically altered what manufacturers are able to do
    with IoT. Today, there are numerous industries that have specific IoT needs. For
    example, the **internet of medical things** (**IoMT**) has devices such as outpatient
    heart monitors that can be worn at home. These devices often require large amounts
    of data to be sent over the network or large compute capacity on the edge to process
    heart-related events. Another example is **agricultural IoT** (**AIoT**) devices
    that are often placed in locations where there is no Wi-Fi or cellular network.
    Prescriptions or models are pushed down to these semi-connected devices. Many
    of these devices require that decisions be made on the edge. When connectivity
    is finally established using technology such as LoRAWAN or TV, white space models
    are downloaded to the devices.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习已经极大地改变了制造商在物联网（IoT）中的应用。今天，有许多行业有特定的物联网需求。例如，**医疗物联网**（**IoMT**）拥有像家中可穿戴的门诊心脏监测器这样的设备。这些设备通常需要在网络上传输大量数据或在边缘进行大量的计算以处理与心脏相关的事件。另一个例子是**农业物联网**（**AIoT**）设备，通常放置在没有Wi-Fi或蜂窝网络的地方。处方或模型被推送到这些半连接设备上。这些设备中的许多需要在边缘做出决策。当使用LoRAWAN或电视白色空间等技术最终建立连接时，模型被下载到设备上。
- en: In this chapter, we are going to discuss using machine learning models such
    as logistic regression and decision trees to solve common IoT issues such as classifying
    medical results, detecting unsafe drivers, and classifying chemical readings.
    We are also going to look at techniques for working with constrained devices,
    and we are going to look at using unsupervised learning to gain insights on devices
    with little data, such as prototypes.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论使用逻辑回归和决策树等机器学习模型来解决常见的物联网问题，如分类医疗结果、检测不安全驾驶员和分类化学读数。我们还将探讨处理受限设备的技术，并研究使用无监督学习获取对原型等数据较少设备的见解的技术。
- en: 'This chapter contains the following recipes:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章包含以下内容：
- en: Analyzing chemical sensors with anomaly detection
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用异常检测分析化学传感器
- en: Logistic regression with IoMT
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用IoMT的逻辑回归
- en: Classifying chemical sensors with decision trees
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用决策树对化学传感器进行分类
- en: Simple predictive maintenance with XGBoost
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用XGBoost进行简单的预测性维护
- en: Detecting unsafe drivers
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检测不安全的驾驶员
- en: Face detection on constrained devices
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 受限设备上的人脸检测
- en: Analyzing chemical sensors with anomaly detection
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用异常检测分析化学传感器
- en: Accurate predictive models require a large number of devices in the field to
    have failed so that they have enough fail data to use for predictions. For some
    well-crafted industrial devices, failures on this scale can take years. Anomaly
    detection can identify devices that are not behaving like the other devices in
    the fleet. It can also be used to wade through thousands of similar messages and
    pinpoint the messages that are not like the others.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 准确的预测模型需要大量的设备在现场失败，以便它们有足够的故障数据用于预测。对于一些精心制作的工业设备来说，这种规模的故障可能需要多年时间。异常检测可以识别不像其他设备的设备。它还可以用于筛选成千上万条类似消息，并确定不同于其他消息的消息。
- en: Anomaly detection in machine learning can be **unsupervised**, **supervised**,
    or **semi-supervised**. Usually, it starts by using an unsupervised machine learning
    algorithm to cluster data into patterns of behavior or groups. This presents a
    series of data in buckets. When the machines are examined, some of the buckets
    identify behavior while some identify an issue with the device. The device may
    have exhibited different patterns of behavior in a resting state, an in-use state,
    a cold state, or something that represents a state that needs to be investigated.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习中的异常检测可以是**无监督**的，**监督**的，或**半监督**的。通常，它从使用无监督机器学习算法将数据聚类为行为模式或群组开始。这将数据呈现为桶。当机器被检查时，一些桶识别出行为，而一些桶则识别出设备存在问题。设备可能在静止状态、使用状态、冷态或需要调查的状态中表现出不同的行为模式。
- en: This recipe presumes the use of a dataset where not much is known about the
    data. The process of anomaly detection is used as part of the discovery process
    and is often used with prototypes.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 此配方假定使用的数据集中对数据了解不多。异常检测过程被用作发现过程的一部分，并且通常与原型一起使用。
- en: Getting ready
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: Anomaly detection is one of the easiest machine learning models to implement.
    In this recipe, we are going to use a dataset drawn from chemical sensors that
    are detecting either neutral, banana, or wine. To get ready, you will need to
    import the `numpy`, `sklearn` and `matplotlib` libraries.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 异常检测是最容易实现的机器学习模型之一。在这个示例中，我们将使用从化学传感器获取的数据集，检测中性、香蕉或葡萄酒。为了准备好，您需要导入 `numpy`、`sklearn`
    和 `matplotlib` 库。
- en: How to do it...
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'The following steps need to be observed to complete this recipe:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 完成这个示例需要遵循以下步骤：
- en: 'Import the required libraries:'
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入所需的库：
- en: '[PRE0]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Upload the data file to a DataFrame:'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据文件上传到 DataFrame：
- en: '[PRE1]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'View the dataset to see if the grouping of data correlates to the number of
    clusters:'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看数据集以查看数据分组是否与簇的数量相关：
- en: '[PRE2]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The output is as follows:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![](img/544d4537-bf2d-494c-8706-9b2ba46bddf3.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](img/544d4537-bf2d-494c-8706-9b2ba46bddf3.png)'
- en: The preceding chart shows three different groups of data. Tight clusters represent
    data with well-defined boundaries. If we adjust the number of clusters to `10`,
    we may be able to get better separation of different groups. These cluster segments
    help us identify different segments of data. This, in turn, may help us determine
    optimal sensor placement for a prototype or perform feature engineering in a machine
    learning model.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 上述图表显示了三组不同的数据。紧密聚集的簇代表具有明确定义边界的数据。如果我们将簇的数量调整为 `10`，可能会更好地分离不同的群组。这些簇段帮助我们识别数据的不同段落。这反过来可能帮助我们确定原型的最佳传感器放置或在机器学习模型中进行特征工程。
- en: How it works...
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理...
- en: In this recipe, we are using `numpy` for data manipulation, `sklearn` for the
    machine learning algorithm, and `matplotlib` for viewing the results. Next, we
    pull the tab-separated file into a Spark dataframe. In this step, we convert the
    data into a pandas DataFrame. Then we run the k-means algorithm with three clusters,
    which gives the chart as the output.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们使用 `numpy` 进行数据操作，`sklearn` 进行机器学习算法，`matplotlib` 查看结果。接下来，我们将制表符分隔的文件转换为
    Spark 数据框架。在这一步中，我们将数据转换为 pandas DataFrame。然后我们使用三个簇运行 k-means 算法，输出图表。
- en: K-means is an algorithm that helps group data into clusters. K-means is a popular
    clustering algorithm for examining data without labels. K-means first randomly
    initializes cluster centroids. In our example, it had three cluster centroids.
    It then assigns the centroids to the nearest data points. Next, it moves each
    centroid to the spot that is in the middle of its respective cluster. It repeats
    these steps until it achieves an appropriate division of data points.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: K-means 是一种将数据分组成簇的算法。K-means 是一种流行的聚类算法，用于在没有标签的情况下检查数据。K-means 首先随机初始化簇的质心。在我们的例子中，它有三个簇的质心。然后将这些质心分配给最近的数据点。接下来，它将每个质心移动到其相应簇的中间位置。它重复这些步骤直到达到适当的数据点分割。
- en: There's more...
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'In the chart, you may have noticed outliers. These are very important to note
    when looking at prototypes. Outliers can represent power fluctuations within a
    machine, bad sensor placement, or a number of other issues. The following example
    shows a simple standard deviation calculation on our data. From here, we are able
    to see two values that fall outside three standard deviations from the mean:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在图表中，您可能已经注意到异常值。在查看原型时，这些异常值非常重要。异常值可以代表机器内部的电力波动、传感器安置不当或其他问题。以下示例显示了我们数据的简单标准差计算。从这里，我们能够看到两个超出均值三个标准差的值：
- en: '[PRE3]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Logistic regression with the IoMT
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用IoMT的逻辑回归
- en: In this recipe, we're going to talk about using logistic regression to classify
    data from mammography machines. Recently, the IoMT has expanded greatly. Many
    devices are being worn by patients when they go home from their doctor, providing
    an in-home medical monitoring solution, while others are in hospitals, giving
    the doctors additional feedback on medical tests being run. In many cases, machine
    learning algorithms are able to spot diseases and issues that doctors may miss,
    or give them additional recommendations. In this recipe, we are going to work
    with a breast cancer dataset and determine whether a mammogram record is malignant
    or benign.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将讨论使用逻辑回归来对乳腺X光数据进行分类。最近，IoMT 大大扩展。许多设备被患者佩戴，当他们离开医生时提供家庭医疗监测解决方案，同时其他设备则在医院内，为医生提供运行的医疗测试的额外反馈。在许多情况下，机器学习算法能够发现医生可能忽略的疾病和问题，或为他们提供额外的建议。在这个示例中，我们将使用乳腺癌数据集，并确定乳腺X光记录是恶性还是良性。
- en: Getting ready
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备就绪
- en: The dataset, along with the Databricks notebooks, is available in the GitHub
    repository. The dataset is unwieldy. It has bad columns with a high degree of
    correlation, which is another way of saying some sensors are duplicates, and there
    are unused columns and extraneous data. For the sake of readability, there will
    be two notebooks in the GitHub repository. The first does all of the data manipulation
    and puts the data into a data table. The second notebook does the machine learning.
    We will focus this recipe on the data manipulation notebook. At the end of the
    recipe, we will talk about two other notebooks to show an example of MLflow.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集与 Databricks 笔记本一起，可以在 GitHub 仓库中找到。 数据集笨重。 它有高度相关的坏列，这是说一些传感器是重复的，还有未使用的列和多余的数据。
    为了便于阅读，在 GitHub 仓库中将有两个笔记本。 第一个笔记本执行所有数据操作，并将数据放入数据表中。 第二个笔记本进行机器学习。 我们将重点介绍数据操作笔记本。
    在配方结束时，我们将讨论另外两个笔记本，以展示 MLflow 的示例。
- en: One other thing you will need in this recipe is an MLflow workspace. To set
    up an MLflow workspace, you will need to go into Databricks and create the workspace
    for this experiment. We will write the results of our experiment there.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在本配方中，您还需要一个 MLflow 工作区。 要设置 MLflow 工作区，您需要进入 Databricks 并为此实验创建工作区。 我们将在那里写入我们实验的结果。
- en: How to do it...
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实现...
- en: 'Follow these steps to complete this recipe:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '按照以下步骤完成本配方:'
- en: 'Import the required libraries:'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '导入所需的库:'
- en: '[PRE4]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Import the data:'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '导入数据:'
- en: '[PRE5]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Split the data:'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '分割数据:'
- en: '[PRE6]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Create the formula:'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '创建公式:'
- en: '[PRE7]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Train the model:'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '训练模型:'
- en: '[PRE8]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Test our model:'
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '测试我们的模型:'
- en: '[PRE9]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Evaluate the model:'
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '评估模型:'
- en: '[PRE10]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The output shows the `precision`, `recall`, and `f1-score` of malignant (`M`)
    and benign (`B`):'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '输出显示了恶性 (`M`) 和良性 (`B`) 的 `精确度`、`召回率` 和 `f1-score`:'
- en: '![](img/172496b3-10f8-4f30-90d2-17161861a437.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](img/172496b3-10f8-4f30-90d2-17161861a437.png)'
- en: 'Evaluate the confusion matrix:'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '评估混淆矩阵:'
- en: '[PRE11]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The output is as follows:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '输出如下:'
- en: '![](img/a1a59574-ec79-4f3b-9000-7e11e38b0a3a.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a1a59574-ec79-4f3b-9000-7e11e38b0a3a.png)'
- en: 'The results show that out of 171 records in our testing set, 112 were true
    negatives and 49 were true positives, meaning that out of 171 records it was able
    to correctly identify 161 records. 10 of those predictions were wrong: 5 false
    negatives and 5 false positives.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '结果显示，在我们的测试集中共有 171 条记录，其中 112 条是真负样本，49 条是真正样本，这意味着在 171 条记录中，它能够正确识别出 161
    条记录。 其中 10 条预测是错误的: 5 条假负样本和 5 条假正样本。'
- en: How it works...
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In this recipe, we used logistic regression. Logistic regression is a technique
    that can be used for traditional statistics as well as machine learning. Due to
    its simplicity and power, many data scientists use logistic regression as their
    first model and use it as a benchmark to beat. Logistic regression is a binary
    classifier, meaning it can classify something as `true` or `false`. In our case,
    the classifications are benign or malignant.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在本配方中，我们使用了逻辑回归。 逻辑回归是一种可用于传统统计学以及机器学习的技术。 由于其简单性和强大性，许多数据科学家将逻辑回归作为他们的第一个模型，并将其用作超越的基准。
    逻辑回归是一个二元分类器，意味着它可以将某些东西分类为 `true` 或 `false`。 在我们的情况下，分类是良性或恶性。
- en: 'First, we import `koalas` for data manipulation and `sklearn` for our model
    and analysis. Next, we import data from our data table and put it into a Pandas
    DataFrame. Then we split the data into testing and training datasets. Next, we
    create a formula that will describe for the model the data columns being used.
    Next, we give the model the formula, the training dataset, and the algorithm it
    will use. We then output a model that we can use to evaluate new data. We now
    create a DataFrame called `predictions_nominal`, which we can use to compare against
    our testing results dataset. The classification report gives us `precision`, `recall`,
    and `f1-score`:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '首先，我们导入 `koalas` 进行数据操作，以及 `sklearn` 用于我们的模型和分析。 接下来，我们从我们的数据表中导入数据并将其放入 Pandas
    DataFrame 中。 然后，我们将数据分割为测试和训练数据集。 接下来，我们创建一个描述模型所使用的数据列的公式。 接下来，我们向模型提供公式、训练数据集以及它将使用的算法。
    然后，我们输出一个可以用来评估新数据的模型。 现在我们创建一个名为 `predictions_nominal` 的 DataFrame，我们可以用它来与我们的测试结果数据集进行比较。
    分类报告给出了 `精确度`、`召回率` 和 `f1-score`:'
- en: '**Precision**: The ratio of correctly reported positive predictions to the
    expected positive predictions'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**精确度**: 正确报告的正预测与预期的正预测之比'
- en: '**Recall**: The ratio of correctly reported positive predictions compared to
    the total population'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**召回率**: 正确报告的正预测与总体人口的比率'
- en: '**F-score**: A blended score of precision and recall'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**F分数**: 精度和召回率的混合分数'
- en: 'Next, we can look at the results of the model and determine how accurately
    it predicted the real values. Some factors that we will examine are as follows:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们可以查看模型的结果，并确定其如何准确预测真实值。我们将检查的一些因素如下：
- en: '**True Negatives: **The predicted negatives that were actually negative in
    the test set'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**真阴性：**测试集中实际为负的预测负例'
- en: '**False Positives**: The number that the trained model predicted would be positive
    in the training set but were not'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**假阳性**：训练模型在训练集中预测为正但实际不是'
- en: '**False Negatives**: The number of false negatives predicted in the test set
    that were actually positives'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**假阴性**：测试集中实际上是正例但被预测为负例的假负例'
- en: '**True Positives**: The amount the model actually got correct'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**真阳性**：模型实际上正确获取的数量'
- en: There's more...
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'We will record the outcome in MLflow to be compared against other algorithms.
    We will also save other parameters, such as the main formula used and the family
    of predictions:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将记录MLflow中的结果以与其他算法进行比较。我们还将保存其他参数，如使用的主要公式和预测族：
- en: '[PRE12]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Classifying chemical sensors with decision trees
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用决策树分类化学传感器
- en: In this recipe, we are going to use chemical sensor data from **Metal-Oxide**
    (**MOx**) sensors to determine whether there is wine in the air. This type of
    sensor is commonly used to determine whether food or chemical particulates are
    in the air. Chemical sensors can detect gasses that would be poisonous to people
    or food spillage at a warehouse.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在本篇文章中，我们将使用**金属氧化物**（**MOx**）传感器的化学传感器数据来确定空气中是否有葡萄酒。这种类型的传感器通常用于确定空气中是否存在食品或化学颗粒。化学传感器可以检测对人类有害或仓库内食品泄漏的气体。
- en: How to do it...
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实现...
- en: 'Follow these steps to complete this recipe:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤完成这个配方：
- en: 'Import the libraries:'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入库：
- en: '[PRE13]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Import the data:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入数据：
- en: '[PRE14]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Encode the values:'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编码数值：
- en: '[PRE15]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Test/train the split data:'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 测试/训练分割数据：
- en: '[PRE16]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Train and predict:'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练和预测：
- en: '[PRE17]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Evaluate the accuracy:'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 评估准确性：
- en: '[PRE18]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: How it works...
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理...
- en: As always, we import the libraries we need for this project. Next, we import
    data from our Spark data table into a Pandas DataFrame. One-hot encoding can change
    categorical values, such as our example of *Wine* and *No Wine*, into encoded
    values that machine learning algorithms can use better. In *step 4*, we take our
    feature columns and our one-hot encoded column and perform a split, splitting
    them into a testing and training set. In *step 5*, we create a decision tree classifier,
    use the `X_train` and `y_train` data to train the model, and then use the `X_test` data
    to create a `y_prediction` dataset. In other words, in the end, we will have a
    set of predictions called `y_pred` based on the predictions the dataset had on
    the `X_test` set. In *step 6*, we evaluate the accuracy of the model and the **area
    under the curve** (**AUC**).
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 和往常一样，我们导入这个项目所需的库。接下来，我们将Spark数据表中的数据导入到Pandas DataFrame中。独热编码可以将分类值（例如我们的*葡萄酒*和*无葡萄酒*示例）更改为机器学习算法更好使用的编码值。在*步骤4*中，我们将特征列和我们的独热编码列分割成一个测试和训练集。在*步骤5*中，我们创建一个决策树分类器，使用`X_train`和`y_train`数据来训练模型，然后使用`X_test`数据创建一个`y_prediction`数据集。换句话说，最后，我们将根据数据集在`X_test`集上的预测得到一组名为`y_pred`的预测。在*步骤6*中，我们评估模型的准确性和**曲线下面积**（**AUC**）。
- en: 'Decision tree classifiers are used when the data is complex. In the same way,
    you can use a decision tree to follow a set of logical rules using yes/no questions,
    as shown in the following diagram:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 当数据复杂时，决策树分类器被用来使用一系列逻辑规则进行分类。您可以像下图所示使用决策树跟随一组是/否问题：
- en: '![](img/94bdd679-d272-412c-bdc5-6cca165ac814.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![](img/94bdd679-d272-412c-bdc5-6cca165ac814.png)'
- en: 'A machine learning algorithm can train a decision tree model to use numeric
    data, as shown in the following diagram:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习算法可以训练决策树模型使用数值数据，如下图所示：
- en: '![](img/a5d63031-bd06-4991-8043-f43b70f72d32.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a5d63031-bd06-4991-8043-f43b70f72d32.png)'
- en: The machine learning algorithm trains the model to accurately pick the best
    path given the available data.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习算法训练模型以准确选择给定可用数据的最佳路径。
- en: There's more...
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'The `sklearn` decision tree classifier has two hyperparameters that we can
    tune: **criterion** and **max depth**. Hyperparameters are often changed to see
    if accuracy can be increased. The criterion is either gini or entropy. Both of
    these criteria evaluate impurities in the child nodes. The next one is max depth.
    The max depth of the decision tree can affect over- and underfitting.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '`sklearn` 决策树分类器有两个超参数可以调整：**准则**和**最大深度**。通常会更改超参数以提高准确性。准则可以是基尼系数或信息熵。这两个准则评估子节点中的不纯度。接下来是最大深度。决策树的最大深度会影响欠拟合和过拟合。'
- en: '**Underfitting versus overfitting**'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '**欠拟合与过拟合**'
- en: Models that underfit are inaccurate and poorly represent the data they were
    trained on.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 欠拟合的模型不准确，无法有效地表示它们所训练的数据。
- en: Models that overfit are unable to generalize from the data trained on. It misses
    similar data to the training set because it only works on exactly the same data
    it was trained on.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 过拟合的模型无法从训练数据中进行泛化。它会错过与训练集相似的数据，因为它只适用于与其训练时完全相同的数据。
- en: Simple predictive maintenance with XGBoost
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用XGBoost进行简单预测维护
- en: Every device has an end of life or will require maintenance from time to time.
    Predictive maintenance is one of the most commonly used machine learning algorithms
    in IoT. The next chapter will cover predictive maintenance in depth, looking at
    sequential data and how that data changes with seasonality. This recipe will look
    at predictive maintenance from the simpler perspective of classification.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 每个设备都有寿命终止或需要定期维护。预测维护是物联网中最常用的机器学习算法之一。下一章将深入探讨预测维护，重点关注序列数据及其如何随季节性变化的情况。本配方将从分类的简单视角来看待预测维护。
- en: In this recipe, we are going to use the NASA *Turbofan engine degradation simulation*
    dataset. We are going to be looking at having three classifications. Green means
    the engine does not need maintenance; yellow, the engine needs maintenance within
    the next 14 maintenance cycles; or red, the engine needs maintenance within the
    next cycle. For an algorithm, we are going to use **extreme gradient boosting**
    (**XGBoost**). XGBoost has become popular in recent years because it tends to
    win more Kaggle competitions than other algorithms.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在此配方中，我们将使用NASA *涡轮风扇引擎退化模拟* 数据集。我们将看到三种分类情况。绿色表示引擎不需要维护；黄色表示引擎在接下来的14个维护周期内需要维护；红色表示引擎在下一个周期内需要维护。作为算法，我们将使用**极限梯度提升**（**XGBoost**）。近年来，XGBoost因其在Kaggle竞赛中的表现优异而变得流行。
- en: Getting ready
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: To get ready you will need the NASA *Turbofan engine degradation simulation*
    dataset. The data, along with a Spark notebook, can be found in the companion
    GitHub repository for this book or on the NASA website. Next, you will need to
    make sure you install XGBoost as a library in Databricks.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 要做好准备，您需要NASA *涡轮风扇引擎退化模拟* 数据集。此数据以及一个Spark笔记本可以在本书的伴随GitHub仓库或NASA网站上找到。接下来，您需要确保在Databricks中安装XGBoost作为库。
- en: How to do it...
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实现...
- en: 'The steps for this recipe are as follows:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 此配方的步骤如下：
- en: 'Import the libraries:'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入库：
- en: '[PRE19]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Import the data:'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入数据：
- en: '[PRE20]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Create a table view on the data:'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在数据上创建表视图：
- en: '[PRE21]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Transform the data:'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 转换数据：
- en: '[PRE22]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Test, train, and split the data:'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 测试、训练和拆分数据：
- en: '[PRE23]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Prepare the model:'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 准备模型：
- en: '[PRE24]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Train the model:'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练模型：
- en: '[PRE25]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Evaluate the model:'
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 评估模型：
- en: '[PRE26]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Store the results:'
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 存储结果：
- en: '[PRE27]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: How it works...
  id: totrans-128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它的工作原理...
- en: First, we import `pandas`, `pyspark`, and `numpy` for data wrangling, `xgboost`
    for our algorithm, `sklearn` for scoring our results, and finally `mlflow` and
    `pickle` for saving those results. In *step 2*, we specify a schema in Spark.
    The inferred schema feature of Databricks can often get the schema wrong. Often
    we need to specify data types. In the next step, we create a temp view of the
    data so that we can use the SQL tools in Databricks. In *step 4*, we use the magic `%sql`
    tag at the top of the page to change the language to SQL. We then create a table
    call, `engine`, that has the engine data plus a new column that gives `0` if the
    engine has more than 14 cycles left, `1` if it has only one cycle left, and `2`
    if it has 14 cycles left. We then switch back to the default Python language and
    split the data into test and training datasets. In *step 6*, we specify the columns
    in the model as well as the hyperparameters. From here we train the model. We
    then test our model and print the precision score. Next, we will store the results
    in MLflow. In [Chapter 4](a40f2c07-0e51-46c6-a3cf-66d5c46477c4.xhtml), *Deep Learning
    for Predictive Maintenance*, we will conduct other experiments against this dataset
    to see which one performs best.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们导入`pandas`、`pyspark`和`numpy`进行数据处理，`xgboost`作为我们的算法，`sklearn`用于评分结果，最后使用`mlflow`和`pickle`保存这些结果。在*步骤
    2* 中，我们在Spark中指定了一个模式。Databricks的推断模式功能通常会出现模式错误。通常我们需要指定数据类型。在接下来的步骤中，我们创建了数据的临时视图，以便在Databricks中使用SQL工具。在*步骤
    4* 中，我们在页面顶部使用魔术标签 `%sql` 将语言切换为SQL。然后，我们创建了一个名为`engine`的表，该表包含引擎数据及一个新列，如果引擎剩余循环大于14，则给出`0`，如果只剩一个循环，则给出`1`，如果剩余14个循环，则给出`2`。然后我们切换回默认的Python语言，并将数据拆分为测试和训练数据集。在*步骤
    6* 中，我们指定了模型中的列以及超参数。从这里开始训练模型。然后我们测试我们的模型并打印精确度分数。接下来，我们将结果存储在MLflow中。在[第 4 章](a40f2c07-0e51-46c6-a3cf-66d5c46477c4.xhtml)，*预测性维护的深度学习*，我们将对此数据集进行其他实验，以查看哪种表现最佳。
- en: 'XGBoost has a large number of parameters you can tune. These tuning parameters
    can be the number of threads that algorithms are allowed to use, and tree parameters
    that help increase accuracy or prevent over and underfitting. Some of these include:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: XGBoost有大量可以调整的参数。这些调整参数可以是允许算法使用的线程数，以及帮助提高准确性或防止过拟合和欠拟合的树参数。其中一些包括：
- en: '`learning_rate`: The learning rate is the step size of the algorithm to update
    its nodes. It helps prevent overfitting but can also negatively affect how long
    it takes to complete the training.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`learning_rate`: 学习率是算法更新节点的步长。它有助于防止过拟合，但也可能会对训练完成所需的时间产生负面影响。'
- en: '`max_depth`: A deep tree tends to overfit and a shallow tree tends to underfit.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_depth`: 深度树倾向于过拟合，浅树倾向于欠拟合。'
- en: '`predictor`: This is a flag to tell the program to do its computations on either
    the CPU or GPU. GPUs can dramatically increase performance time but not all computers
    have a GPU.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`predictor`: 这是一个标志，告诉程序在CPU或GPU上进行计算。GPU可以显著提高性能，但并非所有计算机都配备GPU。'
- en: There are a dozen more parameters that can be tuned in XGBoost.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 还有十几个可以在XGBoost中调整的参数。
- en: XGBoosted decision trees under the hood take weak learners or shallow trees
    and combine them into a strong learner using a dimension scoring system. It is
    similar to getting a bad diagnosis from a doctor and getting a second and third
    opinion. The first doctor could be wrong but it is less likely that all three
    doctors are wrong.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: XGBoost决策树在内部采用弱学习器或浅树，并使用维度评分系统将它们组合成强学习器。这类似于从医生那里得到不良诊断，然后寻求第二和第三意见。第一个医生可能是错的，但不太可能三个医生都错。
- en: Detecting unsafe drivers
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检测不安全的驾驶员
- en: Computer vision in machine learning has allowed us to tell if there are accidents
    on roads or unsafe work environments and can be used in conjunction with complex
    systems such as smart sales assistants. Computer vision has opened up many possibilities
    in IoT. Computer vision is also one of the most challenging from a cost perspective.
    In the next two recipes, we are going to discuss two different ways of using computer
    vision. The first one takes in large amounts of images generated from IoT devices
    and performs predictions and analysis on them using the high-performance distributed
    Databricks format. In the next recipe, we are going to use a technique for performing
    machine learning on edge devices with a small amount of compute using a low compute
    algorithm.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习中的计算机视觉使我们能够判断道路上是否有事故或者不安全的工作环境，并且可以与复杂系统（如智能销售助手）结合使用。计算机视觉在物联网中开辟了许多可能性。从成本的角度来看，计算机视觉也是最具挑战性的之一。在接下来的两个示例中，我们将讨论两种不同的使用计算机视觉的方式。第一种方法是接收大量从物联网设备生成的图像，并使用高性能分布式Databricks格式对其进行预测和分析。在下一个示例中，我们将使用一种在边缘设备上执行机器学习的技术，使用低计算量的算法。
- en: Getting ready
  id: totrans-138
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: To get ready, you will need Databricks. In the example of this recipe, we are
    going to pull images from Azure Blob Storage.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 准备工作，您将需要Databricks。在这个示例中，我们将从Azure Blob Storage中提取图像。
- en: How to do it...
  id: totrans-140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做…
- en: 'The steps for this recipe are as follows:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 此示例的步骤如下：
- en: 'Import the libraries and configurations:'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入库和配置：
- en: '[PRE28]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Read the data:'
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 读取数据：
- en: '[PRE29]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Query the data:'
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查询数据：
- en: '[PRE30]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Create testing and training datasets:'
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建测试和训练数据集：
- en: '[PRE31]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Build a pipeline:'
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建管道：
- en: '[PRE32]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Train the model:'
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练模型：
- en: '[PRE33]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Evaluate the model:'
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 评估模型：
- en: '[PRE34]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Record the results:'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 记录结果：
- en: '[PRE35]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: How it works...
  id: totrans-158
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: First, we are defining where the files are located. For this recipe, we are
    using Azure Blob Storage, but any storage system, such as S3 or HDFS, would work
    as well. Replace the `storage_account_name` and `storage_account_access_key` fields
    with the keys of your Blob Storage account. Read both *safe* and *unsafe* images
    in from our storage account into a Spark image DataFrame. In our example, we have
    placed safe images in one folder and unsafe images in another. Query the image
    DataFrame to see if it got the images. Create safe and unsafe test and training
    sets. We then union our datasets into a training set and a testing set. Next,
    we create a machine learning pipeline. We use the ResNet-50 algorithm as a featurizer.
    Next, we use logistic regression as our classifier. We then put it into a pipeline
    and train our model. Next, we take our pipeline and run our training DataFrame
    through it to come out with a trained model. We then evaluate the accuracy of
    our model. Finally, we store the results in MLflow so that we can compare it against
    other models.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们定义文件的位置。对于这个示例，我们使用Azure Blob Storage，但是任何存储系统，比如S3或HDFS，也同样适用。用你的Blob
    Storage账户的密钥替换`storage_account_name`和`storage_account_access_key`字段。从我们的存储账户中读取*安全*和*不安全*的图像到一个Spark图像DataFrame中。在我们的示例中，我们将安全图像放在一个文件夹中，不安全图像放在另一个文件夹中。查询图像DataFrame以查看是否成功获取了图像。创建安全和不安全的测试和训练集。然后，将我们的数据集合并成一个训练集和一个测试集。接下来，创建一个机器学习管道。我们使用ResNet-50算法作为特征提取器。然后，我们使用逻辑回归作为分类器。将它放入管道中并训练我们的模型。接下来，将我们的管道运行我们的训练DataFrame，得出一个经过训练的模型。然后，评估我们模型的准确性。最后，将结果存储在MLflow中，以便与其他模型进行比较。
- en: There are many image classification models that have been developed, such as
    ResNet-50 and Inception v3\. In our example, we used ResNet-50, which is a type
    of tuned convolutional neural network. ResNet-50 is a powerful machine learning
    model for image featurization. In machine learning, there is the *no free lunch
    theorem*, which states that no one model will outperform the rest. For this reason,
    data scientists will test different algorithms. This can simply be done by changing
    a parameter such as a metric name.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多图像分类模型已经开发出来，比如ResNet-50和Inception v3。在我们的例子中，我们使用了ResNet-50，这是一种调整过的卷积神经网络。ResNet-50是一种强大的用于图像特征提取的机器学习模型。在机器学习中，有*无免费午餐定理*，它指出没有一个模型会在所有情况下表现最好。因此，数据科学家会测试不同的算法。可以通过改变参数如指标名称来简单地完成这一过程。
- en: We also used a Spark ML pipeline. Pipelines allow data scientists to declare
    different steps of a process and implement them independently. In our case, we
    used ResNet-50 to featurize the image. ResNet-50 outputs a vector of features
    that can be classified by a classifier. In our case, we use logistic regression,
    but we could have used XGBoost or a different neural network.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还使用了Spark ML流水线。流水线允许数据科学家声明处理过程的不同步骤，并独立实现它们。在我们的例子中，我们使用ResNet-50对图像进行特征化。ResNet-50输出一个特征向量，可以通过分类器进行分类。在我们的情况下，我们使用逻辑回归，但也可以使用XGBoost或其他神经网络。
- en: There's more...
  id: totrans-162
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'To change our pipeline to use Inception instead of `ResNet50`, we simply need
    to change the model:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 要将我们的流水线更改为使用Inception而不是`ResNet50`，我们只需更改模型：
- en: '[PRE36]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Using `Inception v3`, we are able to test the accuracy of different models
    on the image set:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`Inception v3`，我们能够在图像集上测试不同模型的准确性：
- en: '[PRE37]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'We could use an array of models and record the results in MLflow:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用一系列模型，并在MLflow中记录结果：
- en: '[PRE38]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Face detection on constrained devices
  id: totrans-169
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 受限设备上的面部检测
- en: Deep neural networks tend to outperform other classification techniques. However,
    with IoT devices, there is not a large amount of RAM, compute, or storage. On
    constrained devices, RAM and storage are often in MB and not in GB, making traditional
    classifiers not possible. Some video classification services in the cloud charge
    over $10,000 per device for live streaming video. OpenCV's Haar classifiers have
    the same underlying principles as a convolutional neural network but at a fraction
    of the compute and storage. OpenCV is available in multiple languages and runs
    on some of the most constrained devices.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 深度神经网络往往优于其他分类技术。然而，在物联网设备上，RAM、计算能力或存储量并不是很大。在受限设备上，RAM和存储通常以MB为单位，而不是GB，使得传统的分类器不可行。一些云端视频分类服务每个设备的实时视频收费超过10,000美元。OpenCV的Haar分类器具有与卷积神经网络相同的基本原理，但计算和存储量只是其一小部分。OpenCV支持多种语言，并可以在一些受限制的设备上运行。
- en: In this recipe, we are going to set up a Haar Cascade to detect if a person
    is close to the camera. This is often used in Kiosk and other interactive smart
    devices. The Haar Cascade can be run at a high rate of speed and when it finds
    a face that is close to the machine it can send that image via a cloud service
    or a different onboard machine learning model.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在本示例中，我们将设置一个Haar级联，以便检测人物是否靠近摄像头。这通常用于Kiosk和其他交互式智能设备。Haar级联可以以高速运行，当发现接近设备的人脸时，可以通过云服务或其他设备上的机器学习模型发送该图像。
- en: Getting ready
  id: totrans-172
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'The first thing we need to do is install the OpenCV framework:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要做的第一件事是安装OpenCV框架：
- en: '[PRE39]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Next, we download the model. The model can be downloaded from the OpenCV GitHub
    page or the book's GitHub page. The file is `haarcascade_frontalface_default.xml`.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们下载模型。模型可以从OpenCV GitHub页面或书籍的GitHub页面下载。文件是`haarcascade_frontalface_default.xml`。
- en: Next, we create a new folder by importing the `haarcascade_frontalface_default.xml`
    file and creating a Python file for the code. Finally, if the device does not
    have a camera attached to it, attach one. In the following recipe, we are going
    to implement a Haar Cascade using OpenCV.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们通过导入`haarcascade_frontalface_default.xml`文件并创建一个Python文件来创建一个新文件夹，以用于代码。最后，如果设备没有连接摄像头，请连接一个。在接下来的示例中，我们将使用OpenCV实现Haar级联。
- en: How to do it...
  id: totrans-177
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'The steps for this recipe are as follows:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 此示例的步骤如下：
- en: 'Import the libraries and settings:'
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入库和设置：
- en: '[PRE40]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Initialize the camera:'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化摄像头：
- en: '[PRE41]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Capture and transform the image:'
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 捕获和转换图像：
- en: '[PRE42]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Classify the image:'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对图像进行分类：
- en: '[PRE43]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Debug the images:'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 调试图像：
- en: '[PRE44]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Detect the face:'
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检测面部：
- en: '[PRE45]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: How it works...
  id: totrans-191
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理...
- en: First, import the libraries and set the settings. In the next step, we import
    the `opencv` and `python` libraries and we also import `time` so we can wait if
    the camera is not ready. Next, we set some debugging flags so we can test the
    output visually if we are debugging. Then we import the Haar Cascade XML file
    into our classifier. Finally, we open the first video camera attached to the machine.
    In *step 2*, we wait for the camera to become ready. This is often not a problem
    when developing the software as the system has already recognized the camera.
    Then we set this program to run automatically; the camera may not be available
    for up to a minute when the system is restarted. We are also starting an infinite
    loop of processing the camera images. In the next step, we capture and transform
    the image into black and white. Next, we run the classifier. The `detectMultiScale`
    classifier allows faces of different sizes to be detected. The `minNeighbors` parameter
    specifies how many collaborating neighbors the detection needs before detecting
    a face. Making the `minNeighbors` parameter small could result in a false positive.
    Setting it too large may not detect a face at all. Finally, there is the minimum
    size in pixels that the face needs to be. To debug the code and make sure the
    camera is working accurately we have put in some debug code that outputs the video
    and a bounding box to the attached monitor. On a deployed device, this adds a
    considerable load. But for testing, this can reveal issues and allow tuning. If
    a face has been detected, then you are ready to perform tasks such as onboard
    sentiment analysis or send it to an external service such as the Azure Face API
    to identify people through a face ID.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，导入库并设置设置。接下来，我们导入 `opencv` 和 `python` 库，同时也导入 `time` 以便在摄像头未就绪时等待。然后，我们设置一些调试标志，以便在调试时可以视觉化测试输出。接着，我们将
    Haar Cascade XML 文件导入分类器。最后，我们打开连接到机器的第一个视频摄像头。在 *第 2 步* 中，我们等待摄像头就绪。在开发软件时，这通常不是问题，因为系统已经识别了摄像头。然后，我们将此程序设置为自动运行；当系统重新启动时，摄像头可能最多需要一分钟才能可用。我们还启动了一个无限循环来处理摄像头图像。在接下来的步骤中，我们捕获并将图像转换为黑白。接着，我们运行分类器。`detectMultiScale`
    分类器可以检测不同尺寸的人脸。`minNeighbors` 参数指定在检测到一个人脸之前需要多少个相邻的协作检测。将 `minNeighbors` 参数设置得太小可能会导致误报。设置得太大可能根本无法检测到人脸。最后，还有人脸需要的最小像素大小。为了调试代码并确保摄像头工作准确，我们添加了一些调试代码，将视频和边界框输出到连接的监视器上。在部署设备上，这会增加相当大的负载。但是在测试中，这可以显示问题并允许进行调优。如果检测到人脸，则可以执行任务，如本地情感分析或将其发送到外部服务（如
    Azure Face API）以通过人脸 ID 识别人员。
- en: A Haar Cascade is a highly efficient face detection classifier. Under the hood,
    it takes rectangular sections of the image and compares them against another part
    of the image to come up with something that has the characteristics of a face.
    In our recipe, we used the camera on the device, transformed it, and then used
    the Haar Cascade to classify it.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: Haar Cascade 是高效的人脸检测分类器。在幕后，它会取图像的矩形部分，并将其与图像的另一部分进行比较，从而得出具有人脸特征的东西。在我们的示例中，我们使用设备上的摄像头，对其进行转换，然后使用
    Haar Cascade 进行分类。
