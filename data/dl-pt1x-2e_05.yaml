- en: Diving Deep into Neural Networks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深入探讨神经网络
- en: In this chapter, we will explore the different modules of deep learning architectures
    that are used to solve real-world problems. In the previous chapter, we used low-level
    operations of PyTorch to build modules such as a network architecture, a loss
    function, and an optimizer. In this chapter, we will explore some of the important
    components of neural networks required to solve real-world problems, along with
    how PyTorch abstracts away a lot of complexity by providing a lot of high-level
    functions. Toward the end of the chapter, we will build algorithms that solve
    real-world problems, such as regression, binary classification, and multi-class
    classification.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探索用于解决实际问题的深度学习架构的不同模块。在前一章中，我们使用PyTorch的低级操作来构建模块，如网络架构、损失函数和优化器。在本章中，我们将探讨神经网络的重要组件以及PyTorch通过提供大量高级功能来抽象掉许多复杂性。在本章的最后，我们将构建解决实际问题的算法，如回归、二分类和多类分类。
- en: 'In this chapter, we will go through the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论以下主题：
- en: Diving into the various building blocks of neural networks
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深入探讨神经网络的各种构建模块
- en: Non-linear activations
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非线性激活
- en: PyTorch non-linear activations
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PyTorch非线性激活
- en: Image classification using deep learning
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用深度学习进行图像分类
- en: Diving into the building blocks of neural networks
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深入了解神经网络的构建模块
- en: 'As we learned in the previous chapter, training a deep learning algorithm requires
    the following steps:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在前一章中学到的，训练深度学习算法需要以下步骤：
- en: Building a data pipeline
  id: totrans-9
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建数据管道
- en: Building a network architecture
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建网络架构
- en: Evaluating the architecture using a loss function
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用损失函数评估架构
- en: Optimizing the network architecture weights using an optimization algorithm
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用优化算法优化网络架构权重
- en: In the previous chapter, the network was composed of a simple linear model built
    using PyTorch numerical operations. Though building a neural architecture for
    a dummy problem using numerical operations is easier, it quickly becomes complicated
    when we try to build architectures required to solve complex problems in different
    areas, such as computer vision and **natural language processing** (**NLP**).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一章中，网络由使用PyTorch数值操作构建的简单线性模型组成。虽然使用数值操作构建一个虚拟问题的神经架构更容易，但是当我们尝试构建解决不同领域（如计算机视觉和**自然语言处理**（**NLP**））复杂问题所需的架构时，情况很快变得复杂起来。
- en: 'Most of the deep learning frameworks, such as PyTorch, TensorFlow, and Apache
    MXNet, provide higher-level functionalities that abstract a lot of this complexity.
    These higher-level functionalities are called **layers** across the deep learning
    frameworks. They accept input data, apply transformations like the ones we saw
    in the previous chapter, and output the data. To solve real-world problems, deep
    learning architectures consist of a number of layers ranging from 1 to 150, or
    sometimes more than that. Abstracting low-level operations and training deep learning
    algorithms would look like the following diagram:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数深度学习框架，如PyTorch、TensorFlow和Apache MXNet，提供了抽象了许多复杂性的高级功能。这些高级功能在深度学习框架中被称为**层**。它们接受输入数据，应用类似于我们在前一章看到的转换，并输出数据。为了解决现实世界的问题，深度学习架构由1到150个或更多层组成。抽象化低级操作和训练深度学习算法看起来像以下的图示：
- en: '![](img/ed4b0c80-1533-41b5-a9db-2277ca598964.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ed4b0c80-1533-41b5-a9db-2277ca598964.png)'
- en: Any deep learning training involves getting data, building an architecture (which, in
    general, means putting a bunch of layers together), evaluating the accuracy of
    the model using a loss function, and then optimizing the algorithm by optimizing
    the weights of our network. Before looking at solving some real-world problems,
    we will come to understand higher-level abstractions provided by PyTorch for building
    layers, loss functions, and optimizers.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 任何深度学习训练都涉及获取数据，构建架构（通常意味着组合一堆层），使用损失函数评估模型的准确性，然后通过优化网络权重来优化算法。在探讨解决一些实际问题之前，我们将了解PyTorch提供的用于构建层、损失函数和优化器的高级抽象。
- en: Layers – the fundamental blocks of neural networks
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 层 - 神经网络的基本组件
- en: 'Throughout the rest of the chapter, we will come across different types of
    layers. To begin, let''s try to understand one of the most important layers, the
    linear layer, which does exactly what our network architecture from the previous
    chapter does. The linear layer applies a linear transformation:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的其余部分，我们将遇到不同类型的层。首先，让我们试着理解最重要的层之一，线性层，它正是我们在上一章网络架构中所做的事情。线性层应用线性变换：
- en: '![](img/d2a33a05-36e5-470b-ad68-5bceb4bb555f.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d2a33a05-36e5-470b-ad68-5bceb4bb555f.png)'
- en: 'What makes it powerful is the fact that the entire function that we wrote in
    the previous chapter can be written in a single line of code, as follows:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 它之所以强大，是因为我们在上一章中编写的整个函数可以用一行代码来表示，如下所示：
- en: '[PRE0]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The `linear_layer` function, in the preceding code, will accept a tensor of
    size 5 and outputs a tensor of size 3 after applying linear transformation. Let''s
    look at a simple example of how to do that:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述代码中，`linear_layer`函数将接受一个大小为5的张量，并在应用线性变换后输出一个大小为3的张量。让我们看一个如何做到这一点的简单示例：
- en: '[PRE1]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We can access the trainable parameters of the layer using the weights:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过权重访问层的可训练参数：
- en: '[PRE2]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'This will give the following output:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这将得到以下输出：
- en: '![](img/12c92313-c6e1-4dd2-898c-49259174fd6d.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](img/12c92313-c6e1-4dd2-898c-49259174fd6d.png)'
- en: 'In the same way, we can access the trainable parameters of the layer using
    the `bias` attributes:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 以同样的方式，我们可以使用`bias`属性访问层的可训练参数：
- en: '[PRE3]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'This will give the following output:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这将得到以下输出：
- en: '![](img/b714e1e0-402d-41ac-8e0d-2dd5d0208f13.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b714e1e0-402d-41ac-8e0d-2dd5d0208f13.png)'
- en: 'Linear layers are called by different names, such as **dense** or **fully connected**
    layers, across different frameworks. Deep learning architectures used for solving
    real-world use cases generally contain more than one layer. In PyTorch, we can
    do it in a simple approach by passing the output of one layer to another layer:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在不同框架中，线性层有不同的称呼，如**稠密**或**全连接**层。用于解决真实用例的深度学习架构通常包含多个层。在PyTorch中，我们可以通过将一个层的输出传递给另一个层来简单实现：
- en: '[PRE4]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'This will give the following output:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这将得到以下输出：
- en: '![](img/90faf1d2-6128-4d96-9db1-288c87a33548.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](img/90faf1d2-6128-4d96-9db1-288c87a33548.png)'
- en: Each layer will have its own learnable parameters. The idea behind using multiple
    layers is that each layer will learn some kind of pattern that the later layers
    will build on. There is a problem with adding just linear layers together, as
    they fail to learn anything new beyond a simple representation of a linear layer.
    Let's see, through a simple example, why it does not make sense to stack multiple
    linear layers together.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 每一层都有其自己的可学习参数。使用多层的想法是，每一层将学习某种模式，后续层将在此基础上构建。但是仅将线性层堆叠在一起存在问题，因为它们无法学习超出简单线性层表示的任何新内容。让我们通过一个简单的例子来看看，为什么将多个线性层堆叠在一起是没有意义的。
- en: 'Let''s say we have two linear layers with the following weights:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有两个线性层，具有以下权重：
- en: '| **Layers** | **Weight1** |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| **层** | **权重1** |'
- en: '| Layer1 | 3.0 |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| 层1 | 3.0 |'
- en: '| Layer2 | 2.0 |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| 层2 | 2.0 |'
- en: 'The preceding architecture with two different layers can be simply represented
    as a single layer with a different layer. Hence, just stacking multiple linear
    layers will not help our algorithms to learn anything new. Sometimes, this can
    be unclear, so we can visualize the architecture with the following mathematical
    formulas:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 具有两个不同层的上述架构可以简单地表示为具有不同层的单层。因此，仅仅堆叠多个线性层不会帮助我们的算法学到任何新内容。有时，这可能不太清晰，因此我们可以用以下数学公式来可视化架构：
- en: '![](img/f0e265b2-53da-4c84-bcf9-6c568a2be009.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f0e265b2-53da-4c84-bcf9-6c568a2be009.png)'
- en: To solve this problem, we have different non-linearity functions that help in
    learning different relationships, rather than only focusing on linear relationships.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，我们有不同的非线性函数，可以帮助学习不同的关系，而不仅仅是线性关系。
- en: There are many different non-linear functions available in deep learning. PyTorch
    provides these non-linear functionalities as layers and we will be able to use
    them the same way we used the linear layer.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在深度学习中有许多不同的非线性函数。PyTorch将这些非线性功能提供为层，我们可以像使用线性层一样使用它们。
- en: 'Some of the popular non-linear functions are as follows:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 一些流行的非线性函数如下：
- en: Sigmoid
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sigmoid
- en: Tanh
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tanh
- en: ReLU
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ReLU
- en: Leaky ReLU
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Leaky ReLU
- en: Non-linear activations
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 非线性激活函数
- en: Non-linear activations are functions that take inputs and then apply a mathematical
    transformation and produce an output. There are several non-linear operations
    that we come across in practice. We will go through some of the popular non-linear
    activation functions.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 非线性激活函数是将输入进行数学转换并产生输出的函数。在实践中，我们会遇到几种非线性操作。我们将介绍一些流行的非线性激活函数。
- en: Sigmoid
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Sigmoid
- en: 'The sigmoid activation function has a simple mathematical form, as follows:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: Sigmoid 激活函数有一个简单的数学形式，如下所示：
- en: '![](img/b2eb43b2-87c7-4245-883c-3898cd47c06b.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b2eb43b2-87c7-4245-883c-3898cd47c06b.png)'
- en: 'The sigmoid function intuitively takes a real-valued number and outputs a number
    in the range between 0 and 1\. For a large negative number, it returns close to
    0 and for a large positive number, it returns close to 1\. The following plot
    represents different sigmoid function outputs:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: Sigmoid 函数直观地将实数取值并输出一个在 0 到 1 之间的数。对于较大的负数，它接近于 0；对于较大的正数，它接近于 1。以下图表示不同 sigmoid
    函数的输出：
- en: '![](img/8ee76a76-bb32-4261-b9e8-f0424a3d61da.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8ee76a76-bb32-4261-b9e8-f0424a3d61da.png)'
- en: The sigmoid function has been historically used across different architectures,
    but in recent times, it has gone out of popularity as it has one major drawback.
    When the output of the sigmoid function is close to 0 or 1, the gradients for
    the layers before the sigmoid function are close to 0 and, hence, the learnable
    parameters of the previous layer get gradients close to 0 and the weights do not
    get adjusted often, resulting in dead neurons.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 历史上，sigmoid 函数在不同架构中被广泛使用，但近年来，它已经不再流行，因为它有一个主要缺点。当 sigmoid 函数的输出接近 0 或 1 时，前面层的梯度接近于
    0，因此前一层的可学习参数的梯度也接近于 0，权重很少被调整，导致死神经元。
- en: Tanh
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Tanh
- en: 'The tanh non-linearity function squashes a real-valued number in the range
    of -1 and 1\. The tanh also faces the same issue of saturating gradients when
    tanh outputs extreme values close to -1 and 1\. However, it is preferred to sigmoid,
    as the output of tanh is zero-centered:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: Tanh 非线性函数将一个实数压扁到 -1 和 1 的范围内。当 tanh 输出接近 -1 和 1 的极端值时，也会面临梯度饱和的问题。但与 sigmoid
    不同的是，tanh 的输出是以零为中心的：
- en: '![](img/d26c7062-fb82-4cf8-9999-73a93a483eac.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d26c7062-fb82-4cf8-9999-73a93a483eac.png)'
- en: ReLU
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ReLU
- en: 'ReLU has become more popular in recent years; we can find either its usage
    or one of its variants'' usages in almost any modern architecture. It has a simple
    mathematical formulation:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，ReLU 变得越来越流行；我们几乎可以在任何现代架构中找到其使用或其变体的使用。它有一个简单的数学表达式：
- en: '![](img/492e8a00-e58c-41ff-a641-3ed489af1375.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](img/492e8a00-e58c-41ff-a641-3ed489af1375.png)'
- en: 'Simply put, ReLU squashes any input that is negative to 0 and leaves positive
    numbers as they are. We can visualize the ReLU function as follows:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 简单来说，ReLU 将任何负数输入压扁为 0，并保留正数不变。我们可以将 ReLU 函数可视化如下：
- en: '![](img/1f30c721-5738-431b-86f0-901db482758c.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1f30c721-5738-431b-86f0-901db482758c.png)'
- en: 'Some of the pros and cons of using ReLU are as follows:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 ReLU 的一些优缺点如下：
- en: It helps the optimizer to find the right set of weights sooner. More technically,
    it makes the convergence of stochastic gradient descent faster.
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它帮助优化器更快地找到正确的权重集。更具技术性地说，它加快了随机梯度下降的收敛速度。
- en: It is computationally inexpensive, as we are just thresholding and not calculating
    anything, as we did for the sigmoid and tangent functions.
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它在计算上廉价，因为我们只是进行阈值处理，而不像 sigmoid 和 tanh 函数那样进行任何计算。
- en: 'ReLU has one disadvantage: when a large gradient passes through it during backward
    propagation, it often becomes non-responsive; these are called **dead neutrons**,
    which can be controlled by carefully choosing the learning rate. We will discuss
    how to choose learning rates when we discuss the different ways to adjust the
    learning rate in [Chapter 4](bfebc11a-90af-4c67-ab9a-3118061abaf3.xhtml), *Deep
    Learning for Computer Vision*.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ReLU 有一个缺点：在反向传播过程中，当大梯度通过时，它经常变得不响应；这些被称为**死神经元**，可以通过仔细选择学习率来控制。我们将在讨论不同调整学习率方法时讨论如何选择学习率，在
    [第 4 章](bfebc11a-90af-4c67-ab9a-3118061abaf3.xhtml)，《计算机视觉的深度学习》中。
- en: Leaky ReLU
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Leaky ReLU
- en: Leaky ReLU is an attempt to solve a dying problem where, instead of saturating
    to 0, we saturate to a very small number such as 0.001\. For some use cases, this
    activation function provides a superior performance to others, but it is not consistent.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: Leaky ReLU 是解决“死亡问题”的一种尝试，而不是饱和到 0，而是饱和到一个非常小的数，例如 0.001。对于某些用例，此激活函数提供了比其他激活函数更好的性能，但不是一致的。
- en: PyTorch non-linear activations
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: PyTorch非线性激活
- en: 'PyTorch has most of the common non-linear activation functions implemented
    for us already and it can be used like any other layer. Let''s look at a quick
    example of how to use the ReLU function in PyTorch:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch已经为我们实现了大多数常见的非线性激活函数，并且可以像任何其他层一样使用。让我们快速看一下如何在PyTorch中使用ReLU函数的示例：
- en: '[PRE5]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'This will result in the following output:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 这将导致以下输出：
- en: '![](img/b21f9cf1-b94d-41d2-8a31-f993a2af681e.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b21f9cf1-b94d-41d2-8a31-f993a2af681e.png)'
- en: In the preceding example, we take a tensor with two positive values and two
    negative values and apply a ReLU on it, which thresholds the negative numbers
    to 0 and retains the positive numbers as they are.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的例子中，我们取一个具有两个正值和两个负值的张量，并对其应用ReLU函数，将负数阈值设置为0，并保留正数。
- en: Now we have covered most of the details required for building a network architecture,
    let's build a deep learning architecture that can be used to solve real-world
    problems. In the previous chapter, we used a simple approach so that we could
    focus only on how a deep learning algorithm works. We will not be using that style
    to build our architecture anymore; rather, we will be building the architecture
    in the way it is supposed to be built in PyTorch.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经涵盖了构建网络架构所需的大部分细节，让我们构建一个可以用来解决实际问题的深度学习架构。在前一章中，我们使用了一种简单的方法，这样我们可以专注于深度学习算法的工作方式。我们不再使用那种风格来构建我们的架构；相反，我们将按照PyTorch中预期的方式构建架构。
- en: The PyTorch way of building deep learning algorithms
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: PyTorch构建深度学习算法的方式
- en: 'All networks in PyTorch are implemented as classes, subclassing a PyTorch class
    called `nn.Module`, and should implement the `__init__` and `forward` methods.
    Inside the `init` function, we initialize any layers, such as the linear layer,
    which we covered in the previous section. In the `forward` method, we pass our
    input data into the layers that we initialized in our `init` method and return
    our final output. The non-linear functions are often directly used in the `forward`
    function and some use it in the `init` method too. The following code snippet
    shows how a deep learning architecture is implemented in PyTorch:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch中的所有网络都是作为类实现的，子类化一个名为`nn.Module`的PyTorch类，并应该实现`__init__`和`forward`方法。在`init`函数中，我们初始化任何层，例如我们在前一节中介绍的线性层。在`forward`方法中，我们将输入数据传递到我们在`init`方法中初始化的层中，并返回最终输出。非线性函数通常直接在`forward`函数中使用，有些也在`init`方法中使用。以下代码片段显示了如何在PyTorch中实现深度学习架构：
- en: '[PRE6]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: If you are new to Python, some of the preceding code could be difficult to understand,
    but all it is doing is inheriting a parent class and implementing two methods
    in it. In Python, we subclass by passing the parent class as an argument to the
    class name. The `init` method acts as a constructor in Python and `super` is used
    to pass on arguments of the child class to the parent class, which in our case
    is `nn.Module`.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您是Python新手，则可能难以理解前面的一些代码，但它所做的只是继承一个父类并在其中实现两种方法。在Python中，我们通过将父类作为参数传递给类名来进行子类化。`init`方法在Python中充当构造函数，`super`用于将子类的参数传递给父类，而在我们的情况下是`nn.Module`。
- en: Model architecture for different machine learning problems
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 不同机器学习问题的模型架构
- en: 'The kind of problem we are solving will decide mostly what layers we will use,
    starting from a linear layer to **long short-term memory** (**LSTM**) for sequential
    data. Based on the type of the problem you are trying to solve, your last layer
    is determined. There are three problems that we generally solve using any machine
    learning or deep learning algorithms. Let''s look at what the last layer would
    look like:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在解决的问题类型将主要决定我们将使用哪些层，从线性层到用于顺序数据的**长短期记忆**（**LSTM**）层。根据您尝试解决的问题类型，确定您的最后一层。通常有三种问题我们使用任何机器学习或深度学习算法来解决。让我们看看最后一层会是什么样子：
- en: For a regression problem, such as predicting the price of a t-shirt to sell,
    we would use the last layer as a linear layer with an output of 1, which outputs
    a continuous value.
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于回归问题，例如预测T恤销售价格，我们将使用最后一层作为输出为1的线性层，输出连续值。
- en: To classify a given image as a t-shirt or shirt, you would use a sigmoid activation
    function, as it outputs values either closer to 1 or 0, which is generally called
    a **binary classification problem**.
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要将给定图像分类为T恤或衬衫，您将使用Sigmoid激活函数，因为它输出接近于1或0的值，这通常称为**二元分类问题**。
- en: For multi-class classification, where we have to classify whether a given image
    is a t-shirt, a jeans, a shirt, or a dress, we would use a softmax layer at the
    end of our network. Let's try to understand intuitively what softmax does without
    going into the math of it. It takes inputs from the previous linear layer, for
    example, and outputs the probabilities for a given number of examples. In our
    example, it would be trained to predict four probabilities for each type of image.
    Remember, all these probabilities always add up to 1.
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于多类别分类问题，例如分类一幅图像是T恤、牛仔裤、衬衫还是连衣裙，我们会在网络末端使用softmax层。让我们尝试直观理解softmax的作用，而不深入讨论其数学原理。它从前一层的线性层获取输入，并为一定数量的示例输出概率。在我们的例子中，它将被训练以预测每种类型图像的四个概率。请记住，所有这些概率总是加起来等于1。
- en: Loss functions
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 损失函数
- en: Once we have defined our network architecture, we are left with two important
    steps. One is calculating how good our network is at performing a particular task
    of regression, classification, and the next is optimizing the weight.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们定义了网络架构，我们还剩下两个重要步骤。一个是计算我们的网络在执行回归、分类等特定任务时的表现如何，另一个是优化权重。
- en: The optimizer (gradient descent) generally accepts a scalar value, so our loss
    function should generate a scalar value that has to be minimized during our training.
    Certain use cases, such as predicting where an obstacle is on the road and classifying
    it as a pedestrian or not, would require two or more loss functions. Even in such
    scenarios, we need to combine the losses into a single scalar for the optimizer
    to minimize. We will discuss examples of combining multiple losses into a single
    scalar in detail with a real-world example in [Chapter 8](aeec9e18-7c1d-4ae2-b362-ea7a9d94dd22.xhtml), *Transfer
    Learning with Modern Network Architectures*.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 优化器（梯度下降）通常接受一个标量值，因此我们的损失函数应生成一个标量值，在训练过程中需要最小化它。在某些情况下，比如预测道路上障碍物的位置并将其分类为行人或其他物体，可能需要使用两个或更多个损失函数。即使在这种情况下，我们也需要将这些损失组合成单个标量以便优化器进行最小化。我们将在[第8章](aeec9e18-7c1d-4ae2-b362-ea7a9d94dd22.xhtml)，*现代网络架构下的迁移学习*中详细讨论如何将多个损失组合成单个标量的实际示例。
- en: In the previous chapter, we defined our own loss function. PyTorch provides
    several implementations of commonly used loss functions. Let's take a look at
    the loss functions used for regression and classification.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一章中，我们定义了自己的损失函数。PyTorch提供了几种常用损失函数的实现。让我们看看用于回归和分类的损失函数。
- en: 'The commonly used loss function for regression problems is **mean square error**
    (**MSE**). It is the same loss function we implemented in our previous chapter.
    We can use the loss function implemented in PyTorch, as follows:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 对于回归问题，常用的损失函数是**均方误差**（**MSE**）。这是我们在前面章节中实现的相同损失函数。我们可以使用PyTorch中实现的损失函数，如下所示：
- en: '[PRE7]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'For classification, we use cross-entropy loss. Before looking at the math for
    cross-entropy, let''s understand what cross-entropy loss does. It calculates the
    loss of a classification network, predicting the probabilities, which should sum
    up to 1, like our softmax layer. Cross-entropy loss increases when the predicted
    probability diverges from the correct probability. For example, if our classification
    algorithm predicts 0.1 probability of the following image being a cat, but it
    is actually a panda, then the cross-entropy loss will be higher. If it predicts
    similar to the actual labels, then the cross-entropy loss will be lower:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 对于分类问题，我们使用交叉熵损失。在深入探讨交叉熵数学之前，让我们先了解一下交叉熵损失的作用。它计算分类网络的损失，预测的概率应该总和为1，就像我们的softmax层一样。当预测的概率与正确概率偏离时，交叉熵损失会增加。例如，如果我们的分类算法预测某图像是猫的概率为0.1，但实际上是熊猫，那么交叉熵损失将会较高。如果预测接近实际标签，则交叉熵损失会较低。
- en: '![](img/b768541b-eb8e-4c54-be93-bc7503bf92f7.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b768541b-eb8e-4c54-be93-bc7503bf92f7.png)'
- en: 'Let''s look at a sample implementation of how this actually happens in Python
    code:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一个Python代码中如何实际发生的示例实现：
- en: '[PRE8]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'To use cross-entropy loss in a classification problem, we really do not need
    to be worried about what happens inside—all we have to remember is that the loss
    will be high when our predictions are bad and low when predictions are good. PyTorch
    provides us with an implementation of the loss, which we can use, as follows:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 要在分类问题中使用交叉熵损失，我们真的不需要担心内部发生了什么——我们只需要记住，当我们的预测糟糕时，损失会很高，而当预测良好时，损失会很低。PyTorch为我们提供了损失的实现，我们可以使用，如下所示：
- en: '[PRE9]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Some of the other loss functions that come as part of PyTorch are as follows:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch 中的一些其他损失函数如下：
- en: '| L1 loss | Mostly used as a regularizer; we will discuss it further in [Chapter
    4](bfebc11a-90af-4c67-ab9a-3118061abaf3.xhtml), *Deep Learning for Computer Vision*
    |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| L1 损失 | 主要用作正则化项；我们将在[第四章](bfebc11a-90af-4c67-ab9a-3118061abaf3.xhtml)，*计算机视觉深度学习*中进一步讨论它
    |'
- en: '| MSE loss | Used as a loss function for regression problems |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| 均方误差损失 | 用作回归问题的损失函数 |'
- en: '| Cross-entropy loss | Used for binary and multi-class classification problems
    |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| 交叉熵损失 | 用于二元和多类分类问题 |'
- en: '| NLL Loss | Used for classification problems and allows us to use specific
    weights to handle imbalanced datasets |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| 负对数似然损失 | 用于分类问题，并允许我们使用特定的权重来处理不平衡数据集 |'
- en: '| NLL Loss2d | Used for pixel-wise classification, mostly for problems related
    to image segmentation |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| 二维负对数似然损失 | 用于像素级分类，主要用于与图像分割相关的问题 |'
- en: Optimizing network architecture
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 优化网络架构
- en: 'Once we have calculated the loss of our network, we will optimize the weights
    to reduce the loss, thus improving the accuracy of the algorithm. For the sake
    of simplicity, let''s see these optimizers as black boxes that take loss functions
    and all the learnable parameters and move them slightly to improve our performance.
    PyTorch provides most of the commonly used optimizers required in deep learning.
    If you want to explore what happens inside these optimizers and have a mathematical
    background, I would strongly recommend the following blogs:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦计算了网络的损失，我们将优化权重以减少损失，从而提高算法的准确性。为了简单起见，让我们将这些优化器看作黑盒子，它们接收损失函数和所有可学习参数，并微调它们以改善我们的性能。PyTorch
    提供了大部分深度学习中常用的优化器。如果您想探索这些优化器内部发生的事情，并且具有数学背景，我强烈推荐以下博客：
- en: '[http://ruder.io/optimizing-gradient-descent/](http://ruder.io/optimizing-gradient-descent/)'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://ruder.io/optimizing-gradient-descent/](http://ruder.io/optimizing-gradient-descent/)'
- en: '[https://medium.com/datadriveninvestor/overview-of-different-optimizers-for-neural-networks-e0ed119440c3](https://medium.com/datadriveninvestor/overview-of-different-optimizers-for-neural-networks-e0ed119440c3)'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://medium.com/datadriveninvestor/overview-of-different-optimizers-for-neural-networks-e0ed119440c3](https://medium.com/datadriveninvestor/overview-of-different-optimizers-for-neural-networks-e0ed119440c3)'
- en: 'Some of the optimizers that PyTorch provides are as follows:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch 提供的一些优化器如下：
- en: '`ASGD`'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ASGD`'
- en: '`Adadelta`'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Adadelta`'
- en: '`Adagrad`'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Adagrad`'
- en: '`Adam`'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Adam`'
- en: '`Adamax`'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Adamax`'
- en: '`LBFGS`'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`LBFGS`'
- en: '`RMSprop`'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RMSprop`'
- en: '`Rprop`'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Rprop`'
- en: '`SGD`'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`SGD`'
- en: '`SparseAdam`'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`SparseAdam`'
- en: 'We will get into the details of some of the algorithms in [Chapter 4](bfebc11a-90af-4c67-ab9a-3118061abaf3.xhtml),
    *Deep Learning for Computer Vision*, along with some of the advantages and trade-offs.
    Let''s walk through some of the important steps in creating any optimizer:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将详细讨论一些算法在[第四章](bfebc11a-90af-4c67-ab9a-3118061abaf3.xhtml)，*计算机视觉深度学习*中的细节，包括一些优点和权衡。让我们走过创建任何优化器中的一些重要步骤：
- en: '[PRE10]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'In the preceding example, we created an SGD optimizer that takes all the learnable
    parameters of your network as the first argument and a learning rate that determines
    what ratio of change can be made to the learnable parameters. In [Chapter 4](bfebc11a-90af-4c67-ab9a-3118061abaf3.xhtml),
    *Deep Learning for Computer Vision*, we will get into more details of learning
    rates and momentum, which is an important parameter of optimizers. Once you create
    an optimizer object, we need to call `zero_grad()` inside our loop, as the parameters
    will accumulate the gradients created during the previous optimizer call:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示例中，我们创建了一个 SGD 优化器，它以您网络的所有可学习参数作为第一个参数，并且一个学习率作为决定可学习参数变化比率的参数。在[第四章](bfebc11a-90af-4c67-ab9a-3118061abaf3.xhtml)，*计算机视觉深度学习*中，我们将更详细地讨论学习率和动量，这是优化器的一个重要参数。一旦创建了优化器对象，我们需要在循环内调用
    `zero_grad()`，因为参数将积累在前一个优化器调用中创建的梯度：
- en: '[PRE11]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Once we call backward on the loss function, which calculates the gradients (the
    quantity by which learnable parameters need to change), we call `optimizer.step()`,
    which makes the actual changes to our learnable parameter.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们在损失函数上调用 backward，它将计算梯度（可学习参数需要变化的量），我们再调用 `optimizer.step()`，这将实际地改变我们的可学习参数。
- en: Now we have covered most of the components required to help a computer see or
    recognize images. Let's build a complex deep learning model that can differentiate
    between dogs and cats to put all the theory into practice.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经涵盖了大多数需要帮助计算机看到或识别图像的组件。让我们构建一个复杂的深度学习模型，能够区分狗和猫，将所有理论付诸实践。
- en: Image classification using deep learning
  id: totrans-127
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用深度学习进行图像分类
- en: The most important step in solving any real-world problem is getting the data.
    In order to test our deep learning algorithms in this chapter, we will use a dataset
    provided in a GitHub repository from an user called `ardamavi`. We will use this
    dataset again in [Chapter 4](bfebc11a-90af-4c67-ab9a-3118061abaf3.xhtml), *Deep
    Learning for Computer Vision*, which will be on **convolution neural networks**
    (**CNNs**) and some of the advanced techniques that we can use to improve the
    performance of our image recognition models.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 解决任何实际问题的最重要步骤是获取数据。为了在本章中测试我们的深度学习算法，我们将使用由名为`ardamavi`的用户在GitHub仓库提供的数据集。我们将在[第四章](bfebc11a-90af-4c67-ab9a-3118061abaf3.xhtml)中再次使用此数据集，*计算机视觉的深度学习*，将涵盖**卷积神经网络**（**CNNs**）和一些可以用来提高图像识别模型性能的高级技术。
- en: 'You can download the data from the following link: [https://github.com/ardamavi/Dog-Cat-Classifier/tree/master/Data/Train_Data](https://github.com/ardamavi/Dog-Cat-Classifier/tree/master/Data/Train_Data).
    The dataset contains images of dogs and cats. The preprocessing of data and the
    creation of training, validation, and testing splits are some of the important
    steps that need to be performed before we can implement an algorithm.'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从以下链接下载数据：[https://github.com/ardamavi/Dog-Cat-Classifier/tree/master/Data/Train_Data](https://github.com/ardamavi/Dog-Cat-Classifier/tree/master/Data/Train_Data)。数据集包含猫和狗的图像。在实施算法之前，需要执行数据预处理和创建训练、验证和测试拆分等重要步骤。
- en: 'Most frameworks make it easier to read images and tag them to their labels
    when provided in the following format. That means that each class should have
    a separate folder of its images. Here, all cat images should be in the `cat` folder
    and dog images in the `dog` folder:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数框架使得在提供以下格式的图像和标签时更容易读取图像并对其进行标记。这意味着每个类别应该有其图像的单独文件夹。在这里，所有猫图像应该在`cat`文件夹中，而狗图像应该在`dog`文件夹中：
- en: '![](img/4bc4e6f1-acf8-44c1-8ae2-825002378119.png)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4bc4e6f1-acf8-44c1-8ae2-825002378119.png)'
- en: 'Python makes it easy to put the data into the right format. Let''s quickly
    take a look at the code and then we will go through the important parts of it:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: Python使得将数据放入正确格式变得很容易。让我们快速查看一下代码，然后我们将详细讨论其中的重要部分：
- en: '[PRE12]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Create a shuffled index that can be used to create a validation dataset:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个可以用来创建验证数据集的洗牌索引：
- en: '[PRE13]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Create a validation directory for holding training and validation images:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个验证目录来保存训练和验证图像：
- en: '[PRE14]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Copy a small subset of images into the validation folder:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 将少量图像副本复制到验证文件夹中：
- en: '[PRE15]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Copy a small subset of images into the training folder:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 将少量图像副本复制到训练文件夹中：
- en: '[PRE16]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: All the preceding code does is retrieve all the files and pick a sample of images
    for creating a testing and validation set. It segregates all the images into the
    two categories of cats and dogs. It is a common and important practice to create
    a separate validation set, as it is not fair to test our algorithms on the same
    data it is trained on. To create a dataset, we create a list of numbers that are
    in the range of the length of the images in a shuffled order. The shuffled numbers
    act as an index for us to pick a bunch of images to create our dataset. Let's
    go through each section of the code in detail.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 上述所有代码所做的就是检索所有文件并选择一些图像样本来创建测试和验证集。它将所有图像分成猫和狗两个类别。创建单独的验证集是一种常见且重要的做法，因为在训练的数据上测试算法是不公平的。为了创建数据集，我们创建一个以洗牌顺序排列的数字列表，该列表的范围是图像长度。洗牌的数字充当我们选择一堆图像来创建数据集的索引。让我们详细讨论代码的每个部分。
- en: 'We use the `glob` method to return all the files in the particular path:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`glob`方法返回特定路径中的所有文件：
- en: '[PRE17]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: When there are a huge number of images, we can also use `iglob`, which returns
    an iterator, instead of loading the names into memory. In our case, the volume
    of images we are working with is low and we can easily fit them into memory so
    it is not necessary.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 当图像数量庞大时，我们也可以使用`iglob`，它返回一个迭代器，而不是将名称加载到内存中。在我们的情况下，我们处理的图像体积较小，可以轻松放入内存，因此不是必需的。
- en: 'We can shuffle our files using the following code:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用以下代码对文件进行洗牌：
- en: '[PRE18]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The preceding code returns numbers in the range of 0 to 1,399 in a shuffled
    order, which we will use as an index for selecting a subset of images to create
    a dataset.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码以洗牌顺序返回0到1,399范围内的数字，我们将使用这些数字作为选择图像子集的索引来创建数据集。
- en: 'We can create testing and validation code, as follows:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以创建如下的测试和验证代码：
- en: '[PRE19]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The preceding code creates folders based on categories (cats and dogs) inside
    the `train` and `valid` directories.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码在`train`和`valid`目录内基于类别（猫和狗）创建了文件夹。
- en: 'We can shuffle an index with the following code:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以用以下代码对索引进行洗牌：
- en: '[PRE20]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: In the preceding code, we use our shuffled index to randomly pick 250 different
    images for our validation set. We do something similar for the training data to
    segregate the images in the `train` directory.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述代码中，我们使用打乱的索引随机选取了250张不同的图像作为验证集。对于训练数据，我们类似地对`train`目录中的图像进行分组。
- en: As we have the data in the format we need, let's quickly look at how to load
    the images as PyTorch tensors.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 现在数据格式已经就绪，让我们快速看看如何将图像加载为PyTorch张量。
- en: Loading data into PyTorch tensors
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将数据加载到PyTorch张量中
- en: 'The PyTorch `torchvision.datasets` package provides a utility class called
    `ImageFolder` that can be used to load images along with their associated labels
    when data is presented in the aforementioned format. It is a common practice to
    perform the following preprocessing steps:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch的`torchvision.datasets`包提供了一个名为`ImageFolder`的实用类，可以用来加载图像及其关联的标签，当数据以前述格式呈现时。通常的做法是执行以下预处理步骤：
- en: Resize all the images to the same size. Most deep learning architectures expect
    the images to be of the same size.
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将所有图像调整为相同的大小。大多数深度学习架构期望图像具有相同的大小。
- en: Normalize the dataset with the mean and standard deviation of the dataset.
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用数据集的均值和标准差进行归一化。
- en: Convert the image dataset to a PyTorch tensor.
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将图像数据集转换为PyTorch张量。
- en: 'PyTorch makes a lot of these preprocessing steps easier by providing a lot
    of utility functions in the `transforms` module. For our example, let''s apply
    three transformations:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch通过在`transforms`模块中提供许多实用函数，使得这些预处理步骤更加简单。对于我们的示例，让我们应用三个转换：
- en: Scale to a 256 x 256 image size
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缩放到256 x 256像素大小
- en: Convert to a PyTorch tensor
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 转换为PyTorch张量
- en: Normalize the data (we will talk about how we arrived at the mean and standard
    deviation in the next section)
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标准化数据（我们将在下一节讨论如何得到均值和标准差）
- en: 'The following code demonstrates how transformations can be applied and images
    are loaded using the `ImageFolder` class:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的代码演示了如何应用转换并使用`ImageFolder`类加载图像：
- en: '[PRE21]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The `train` object holds all the images and associated labels for the dataset.
    It contains two important attributes: one that gives a mapping between classes
    and the associated index used in the dataset and another one that gives a list
    of classes:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '`train`对象保存了数据集中的所有图像和相关标签。它包含两个重要属性：一个提供了类别与数据集中使用的相关索引之间的映射，另一个提供了类别列表：'
- en: '`train.class_to_idx - {''cat'': 0, ''dog'': 1}`'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`train.class_to_idx - {''cat'': 0, ''dog'': 1}`'
- en: '`train.classes - [''cat'', ''dog'']`'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`train.classes - [''cat'', ''dog'']`'
- en: 'It is often a best practice to visualize the data loaded into tensors. To visualize
    the tensors, we have to reshape the tensors and denormalize the values. The following
    function does that for us:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 可视化加载到张量中的数据通常是一种最佳实践。为了可视化张量，我们必须重塑张量并对值进行反归一化。以下函数为我们完成了这些操作：
- en: '[PRE22]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Now we can pass our tensor to the preceding `imshow` function, which converts
    it into an image:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以将张量传递给前面的`imshow`函数，将其转换为图像：
- en: '[PRE23]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The preceding code generates the following output:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码生成了以下输出：
- en: '![](img/760e81b6-5830-4c63-b683-7d3057befe04.png)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
  zh: '![](img/760e81b6-5830-4c63-b683-7d3057befe04.png)'
- en: Loading PyTorch tensors as batches
  id: totrans-176
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加载PyTorch张量作为批次
- en: 'It is a common practice in deep learning or machine learning to batch samples
    of images, as modern **graphics processing units** (**GPUs**) and CPUs are optimized
    to run operations faster on a batch of images. The batch size generally varies
    depending on the kind of GPU we use. Each GPU has its own memory, which can vary
    from 2 GB to 12 GB, and sometimes more for commercial GPUs. PyTorch provides the
    `DataLoader` class, which takes in a dataset and returns a batch of images. It
    abstracts a lot of complexities in batching, such as the usage of multi-workers
    for applying transformation. The following code converts the previous `train`
    and `valid` datasets into data loaders:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在深度学习或机器学习中，对图像样本进行批处理是常见的做法，因为现代**图形处理单元**（**GPU**）和CPU优化了对图像批次的快速操作。批大小通常取决于使用的GPU类型。每个GPU都有自己的内存，可以从2
    GB到12 GB不等，有时商业GPU的内存更多。PyTorch提供了`DataLoader`类，它接受数据集并返回图像批次，抽象了批处理中的许多复杂性，例如使用多个工作线程进行变换应用。以下代码将先前的`train`和`valid`数据集转换为数据加载器：
- en: '[PRE24]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The `DataLoader` class provides us with a lot of options and some of the most
    commonly used ones are as follows:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '`DataLoader`类为我们提供了许多选项，其中一些最常用的选项如下：'
- en: '`shuffle`: When true, this shuffles the images every time the data loader is
    called.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`shuffle`：当为true时，这会在每次数据加载器调用时重新排列图像。'
- en: '`num_workers`: This is responsible for parallelization. It is common practice
    to use a number of workers fewer than the number of cores available in your machine.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_workers`：这负责并行化。通常建议在您的机器上使用少于可用核心数的工作线程。'
- en: Building the network architecture
  id: totrans-182
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建网络架构
- en: For most real-world use cases, particularly in computer vision, we rarely build
    our own architecture. There are different architectures that can be quickly used
    to solve our real-world problems. For our example, we'll use a popular deep learning
    algorithm called **ResNet**, which won the first prize in 2015 in different competitions,
    such as ImageNet, related to computer vision.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 对于大多数实际用例，特别是在计算机视觉领域，我们很少自己构建架构。有不同的架构可以快速用来解决我们的实际问题。在我们的示例中，我们将使用一种名为**ResNet**的流行深度学习算法，该算法在2015年赢得了不同竞赛（如ImageNet）的第一名。
- en: 'For a simpler understanding, let''s assume that this algorithm is a bunch of
    different PyTorch layers carefully tied together and not focus on what happens
    inside this algorithm. We will see some of the key building blocks of the ResNet
    algorithm when we learn about CNNs. PyTorch makes it easier to use a lot of these
    popular algorithms by providing them off the shelf in the `torchvision.models`
    module. So, for this example, let''s quickly take a look at how to use this algorithm
    and then walk through each line of code:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更简单地理解，让我们假设这个算法是一堆不同的PyTorch层仔细地组合在一起，而不是关注这个算法内部发生了什么。当我们学习CNN时，我们将看到ResNet算法的一些关键构建块。PyTorch通过在`torchvision.models`模块中提供这些流行算法使得使用它们变得更加容易。因此，对于这个示例，让我们快速看一下如何使用这个算法，然后逐行走过每一行代码：
- en: '[PRE25]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The `models.resnet18(pertrained = True)` object creates an instance of the
    algorithm, which is a collection of PyTorch layers. We can take a quick look at
    what constitutes the ResNet algorithm by printing `pretrained_resnet`. A small
    portion of the algorithm looks like the following screenshot (I am not including
    the full algorithm as it could run for several pages):'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '`models.resnet18(pretrained = True)`对象创建了一个算法实例，它是一组PyTorch层。我们可以通过打印`pretrained_resnet`快速查看ResNet算法的构成。该算法的一个小部分如下截图所示（我没有包含完整的算法，因为它可能运行数页）：'
- en: '![](img/9b4f58df-36b3-4f70-979f-b3f8d1097a8d.png)'
  id: totrans-187
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9b4f58df-36b3-4f70-979f-b3f8d1097a8d.png)'
- en: As we can see, the ResNet architecture is a collection of layers, namely `Conv2d`,
    `BatchNorm2d`, and `MaxPool2d`, stitched in a particular way. All these algorithms
    will accept an argument called `pretrained`. When `pretrained` is `True`, the
    weights of the algorithm are already tuned for a particular ImageNet classification
    problem of predicting 1,000 different categories, which include cars, ships, fish,
    cats, and dogs. This algorithm is trained to predict the 1,000 ImageNet categories
    and the weights are adjusted to a certain point where the algorithm achieves state-of-the-art
    accuracy. These weights are stored and shared with the model that we are using
    for the use case. Algorithms tend to work better when started with fine-tuned
    weights, rather than when started with random weights. So, for our use case, we'll
    start with pretrained weights.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，ResNet架构是一组层，即`Conv2d`、`BatchNorm2d`和`MaxPool2d`，以特定的方式拼接在一起。所有这些算法都会接受一个名为`pretrained`的参数。当`pretrained`为`True`时，算法的权重已经调整到预测ImageNet分类问题（包括汽车、船、鱼、猫和狗）的1000个不同类别的特定点。这些权重被存储并与我们用于用例的模型共享。算法在使用经过微调的权重启动时通常会表现更好，而不是使用随机权重启动。因此，对于我们的用例，我们将从预训练权重开始。
- en: 'The ResNet algorithm cannot be used directly, as it is trained to predict one
    of the 1,000 categories. For our use case, we need to predict only one of the
    two categories of dogs and cats. To achieve this, we take the last layer of the
    ResNet model, which is a linear layer, and change the output features to `4`,
    as shown in the following code:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: ResNet算法不能直接使用，因为它是训练用于预测1000个类别中的一个。对于我们的用例，我们需要预测狗和猫中的其中一个类别。为了实现这一点，我们取ResNet模型的最后一层，这是一个线性层，并将输出特征更改为`4`，如下面的代码所示：
- en: '[PRE26]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'If you are running this algorithm on a GPU-based machine, then to make the
    algorithm run on a GPU, we call the `cuda` method on the model. It is strongly
    recommended that you run these programs on a GPU-powered machine; it is easy to
    spin a cloud instance with a GPU for less than a dollar. The last line in the
    following code snippet tells PyTorch to run the code on the GPU:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在基于GPU的机器上运行此算法，则为了使算法在GPU上运行，我们在模型上调用`cuda`方法。强烈建议您在支持GPU的机器上运行这些程序；可以轻松地为少于一美元的费用启动一个带GPU的云实例。以下代码片段的最后一行告诉PyTorch在GPU上运行代码：
- en: '[PRE27]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Training the model
  id: totrans-193
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练模型
- en: 'In the previous sections, we created some `DataLoader` instances and algorithms.
    Now let''s train the model. To do this, we need a loss function and an optimizer:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 在前几节中，我们创建了一些`DataLoader`实例和算法。现在让我们训练模型。为此，我们需要一个损失函数和一个优化器：
- en: '[PRE28]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: In the preceding code, we created our loss function based on `CrossEntropyLoss`
    and the optimizer based on `SGD`. The `StepLR` function helps in dynamically changing
    the learning rate. We will discuss different strategies available to tune the
    learning rate in [Chapter 4](bfebc11a-90af-4c67-ab9a-3118061abaf3.xhtml), *Deep
    Learning for Computer Vision*.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述代码中，我们基于`CrossEntropyLoss`创建了我们的损失函数，并基于`SGD`创建了优化器。`StepLR`函数有助于动态调整学习率。我们将讨论不同可用的策略来调整学习率，详见[第4章](bfebc11a-90af-4c67-ab9a-3118061abaf3.xhtml)，*计算机视觉的深度学习*。
- en: 'The following `train_my_model` function takes in a model and tunes the weights
    of our algorithm by running multiple epochs and reducing the loss:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的`train_my_model`函数接收一个模型，并通过运行多个epoch来调整算法的权重以减少损失：
- en: '[PRE29]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Each epoch has a training and validation phase:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 每个epoch都有训练和验证阶段：
- en: '[PRE30]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Iterate over the data:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 迭代数据：
- en: '[PRE31]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The function can be run as follows:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 函数可以按以下方式运行：
- en: '[PRE32]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The preceding function does the following:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 前述函数执行以下操作：
- en: It passes the images through the model and calculates the loss.
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它通过模型传递图像并计算损失。
- en: It backpropagates during the training phase. For the validation/testing phase,
    it does not adjust the weights.
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练阶段进行反向传播。在验证/测试阶段，不调整权重。
- en: The loss is accumulated across batches for each epoch.
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 损失在每个epoch中跨批次累积。
- en: The best model is stored and validation accuracy is printed.
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 存储了最佳模型并打印了验证准确率。
- en: The preceding model, after running for 20 epochs, results in a validation accuracy
    of 87%.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行了20个epoch后，上述模型的验证准确率达到了87%。
- en: In the coming chapters, we will learn more advanced techniques that will help
    us in training more accurate models in a much faster way. The preceding model
    took around 30 minutes to run on a Titan X GPU. We will cover different techniques
    that will help in training the model faster.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将学习更高级的技术，帮助我们以更快的方式训练更准确的模型。前面的模型在Titan X GPU上运行大约花费了30分钟。我们将涵盖不同的技术，有助于加快模型的训练速度。
- en: Summary
  id: totrans-212
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概要
- en: In this chapter, we explored the complete life cycle of a neural network in
    PyTorch, starting from constituting different types of layers, adding activations,
    calculating cross-entropy loss, and finally, optimizing network performance (that
    is, minimizing loss), by adjusting the weights of layers using the SGD optimizer.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了在PyTorch中神经网络的完整生命周期，从构建不同类型的层，添加激活函数，计算交叉熵损失，到最终优化网络性能（即通过SGD优化器调整层的权重）。
- en: We studied how to apply the popular ResNet architecture to binary or multi-class
    classification problems.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 我们研究了如何将流行的ResNet架构应用于二元或多类分类问题。
- en: While doing this, we tried to solve the real-world image classification problem
    of classifying a cat image as a cat and a dog image as a dog. This knowledge can
    be applied to classify different categories/classes of entities, such as classifying
    species of fish, identifying different kinds of dogs, categorizing plant seedlings,
    grouping together cervical cancer into Type 1, Type 2, and Type 3, and much more.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 在此过程中，我们试图解决真实世界的图像分类问题，将猫图像分类为猫，狗图像分类为狗。这些知识可以应用于分类不同类别/实体的类别，例如分类鱼的物种，识别不同品种的狗，分类植物苗，将宫颈癌分为类型1、类型2和类型3，以及更多。
- en: In the next chapter, we will go through the fundamentals of machine learning.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将深入学习机器学习的基础知识。
