- en: 7 Music and Text Generation with PyTorch
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 7 使用PyTorch进行音乐和文本生成
- en: Join our book community on Discord
  id: totrans-1
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 加入我们的书籍社区在Discord上
- en: '[https://packt.link/EarlyAccessCommunity](https://packt.link/EarlyAccessCommunity)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.link/EarlyAccessCommunity](https://packt.link/EarlyAccessCommunity)'
- en: '![img](img/file47.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![img](img/file47.png)'
- en: PyTorch is a fantastic tool for both researching deep learning models and developing
    deep learning-based applications. In the previous chapters, we looked at model
    architectures across various domains and model types. We used PyTorch to build
    these architectures from scratch and used pre-trained models from the PyTorch
    model zoo. We will switch gears from this chapter onward and dive deep into generative
    models.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch既是研究深度学习模型又是开发基于深度学习的应用程序的绝佳工具。在前几章中，我们探讨了跨多个领域和模型类型的模型架构。我们使用PyTorch从头开始构建了这些架构，并使用了PyTorch模型动物园中的预训练模型。从本章开始，我们将转变方向，深入探讨生成模型。
- en: In the previous chapters, most of our examples and exercises revolved around
    developing models for classification, which is a supervised learning task. However,
    deep learning models have also proven extremely effective when it comes to unsupervised
    learning tasks. Deep generative models are one such example. These models are
    trained using lots of unlabeled data. Once trained, the model can generate similar
    meaningful data. It does so by learning the underlying structure and patterns
    in the input data.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在前几章中，我们的大多数示例和练习都围绕开发分类模型展开，这是一个监督学习任务。然而，当涉及到无监督学习任务时，深度学习模型也被证明非常有效。深度生成模型就是其中一个例子。这些模型使用大量未标记的数据进行训练。训练完成后，模型可以生成类似的有意义数据。它通过学习输入数据的潜在结构和模式来实现这一点。
- en: In this chapter, we will develop text and music generators. For developing the
    text generator, we will utilize the transformer-based language model we trained
    in *Chapter 5*, *Hybrid Advanced Models*. We will extend the transformer model
    using PyTorch so that it works as a text generator. Furthermore, we will demonstrate
    how to use advanced pre-trained transformer models in PyTorch in order to set
    up a text generator in a few lines of code. Finally, we will build a music generator
    model that's been trained on an MIDI dataset from scratch using PyTorch.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将开发文本和音乐生成器。为了开发文本生成器，我们将利用我们在*第5章*《混合高级模型》中训练的基于Transformer的语言模型。我们将使用PyTorch扩展Transformer模型，使其成为文本生成器。此外，我们还将演示如何在PyTorch中使用先进的预训练Transformer模型来设置几行代码中的文本生成器。最后，我们将展示如何使用PyTorch从头开始训练一个基于MIDI数据集的音乐生成模型。
- en: 'By the end of this chapter, you should be able to create your own text and
    music generation models in PyTorch. You will also be able to apply different sampling
    or generation strategies to generate data from such models. This chapter covers
    the following topics:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章结束时，您应该能够在PyTorch中创建自己的文本和音乐生成模型。您还将能够应用不同的采样或生成策略，以从这些模型生成数据。本章涵盖以下主题：
- en: Building a transformer-based text generator with PyTorch
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用PyTorch构建基于Transformer的文本生成器
- en: Using a pre-trained GPT 2 model as a text generator
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用预训练的GPT 2模型作为文本生成器
- en: Generating MIDI music with LSTMs using PyTorch
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用PyTorch生成MIDI音乐的LSTMs
- en: Building a transformer-based text generator with PyTorch
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用PyTorch构建基于Transformer的文本生成器
- en: We built a transformer-based language model using PyTorch in the previous chapter.
    Because a language model models the probability of a certain word following a
    given sequence of words, we are more than half-way through in building our own
    text generator. In this section, we will learn how to extend this language model
    as a deep generative model that can generate arbitrary yet meaningful sentences,
    given an initial textual cue in the form of a sequence of words.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们使用PyTorch构建了基于Transformer的语言模型。因为语言模型建模了在给定一系列单词之后某个单词出现的概率，所以我们在构建自己的文本生成器时已经过了一半的路程。在本节中，我们将学习如何将这个语言模型扩展为一个深度生成模型，它可以在给定一系列初始文本提示的情况下生成任意但有意义的句子。
- en: Training the transformer-based language model
  id: totrans-13
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 训练基于Transformer的语言模型
- en: In the previous chapter, we trained a language model for 5 epochs. In this section,
    we will follow those exact same steps but will train the model for longer - 25
    epochs. The goal here is to obtain a better performing language model that can
    then generate realistic sentences. Please note that model training can take several
    hours. Hence, it is recommended to train it in the background; for example, overnight.
    In order to follow the steps for training the language model, please follow the
    complete code at GitHub [7.1] .
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一章中，我们对语言模型进行了5个epoch的训练。在本节中，我们将按照相同的步骤进行训练，但将模型训练更长时间 - 25个epoch。目标是获得一个表现更好的语言模型，可以生成更真实的句子。请注意，模型训练可能需要几个小时。因此，建议在后台进行训练，例如过夜。为了按照训练语言模型的步骤进行操作，请在
    GitHub [7.1] 上查看完整代码。
- en: 'Upon training for 25 epochs, we get the following output:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练了25个epoch之后，我们得到了以下输出：
- en: '![Figure 7 .1 – Language model training logs](img/file48.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![图 7 .1 – 语言模型训练日志](img/file48.png)'
- en: Figure 7 .1 – Language model training logs
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7 .1 – 语言模型训练日志
- en: Now that we have successfully trained the transformer model for 25 epochs, we
    can move on to the actual exercise, where we will extend this trained language
    model as a text generation model.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经成功地训练了25个epoch的Transformer模型，我们可以进入实际的练习阶段，在这里我们将扩展这个训练好的语言模型作为一个文本生成模型。
- en: Saving and loading the language model
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 保存和加载语言模型
- en: 'Here, we will simply save the best performing model checkpoint once the training
    is complete. We can then separately load this pre-trained model:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将在训练完成后简单保存表现最佳的模型检查点。然后，我们可以单独加载这个预训练模型：
- en: 'Once the model has been trained, it is ideal to save it locally so that you
    avoid having to retrain it from scratch. You can save it as follows:'
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦模型训练完成，最好将其保存在本地，以避免需要从头开始重新训练。可以按以下步骤保存：
- en: '[PRE0]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'We can now load the saved model so that we can extend this language model as
    a text generation model:'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以加载保存的模型，以便将这个语言模型扩展为文本生成模型：
- en: '[PRE1]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: In this section, we re-instantiated a transformer model object and then loaded
    the pre-trained model weights into this new model object. Next, we will use this
    model to generate text.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们重新实例化了一个Transformer模型对象，然后将预训练的模型权重加载到这个新的模型对象中。接下来，我们将使用这个模型来生成文本。
- en: Using the language model to generate text
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用语言模型生成文本
- en: 'Now that the model has been saved and loaded, we can extend the trained language
    model to generate text:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 现在模型已经保存和加载完毕，我们可以扩展训练好的语言模型来生成文本：
- en: 'First, we must define the target number of words we want to generate and provide
    an initial sequence of words as a cue to the model:'
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们必须定义我们想要生成的目标单词数量，并提供一个初始单词序列作为模型的线索：
- en: '[PRE2]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Finally, we can generate the words one by one in a loop. At each iteration,
    we can append the predicted word in that iteration to the input sequence. This
    extended sequence becomes the input to the model in the next iteration and so
    on. The random seed is added to ensure consistency. By changing the seed, we can
    generate different texts, as shown in the following code block:'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们可以在循环中逐个生成单词。在每次迭代中，我们可以将该迭代中预测的单词附加到输入序列中。这个扩展的序列成为下一个迭代中模型的输入，依此类推。添加随机种子是为了确保一致性。通过更改种子，我们可以生成不同的文本，如下面的代码块所示：
- en: '[PRE3]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'This should output the following:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该会输出以下内容：
- en: '![Figure 7 .2 – Transformer generated text](img/file49.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![图 7 .2 – Transformer 生成的文本](img/file49.png)'
- en: Figure 7 .2 – Transformer generated text
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7 .2 – Transformer 生成的文本
- en: As we can see, using PyTorch, we can train a language model (a transformer-based
    model, in this case) and then use it to generate text with a few additional lines
    of code. The generated text seems to make sense. The result of such text generators
    is limited by the amount of data the underlying language model is trained on,
    as well as how powerful the language model is. In this section, we have essentially
    built a text generator from scratch.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，使用 PyTorch，我们可以训练一个语言模型（在本例中是基于Transformer的模型），然后通过几行额外的代码来生成文本。生成的文本似乎是有意义的。这种文本生成器的结果受到底层语言模型训练数据量和语言模型强度的限制。在本节中，我们基本上是从头开始构建了一个文本生成器。
- en: In the next section, we will load the pre-trained language model and use it
    as a text generator. We will be using an advanced successor of the transformer
    model – the **generative pre-trained transformer** (**GPT**-2). We will demonstrate
    how to build an out-of-the-box advanced text generator using PyTorch in less than
    10 lines of code. We will also look at some strategies involved in generating
    text from a language model.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将加载预训练语言模型，并将其用作文本生成器。我们将使用变压器模型的高级继任者 – **生成式预训练变压器**（**GPT**-2）。我们将演示如何在不到10行代码的情况下，使用PyTorch构建一个即时高级文本生成器。我们还将探讨从语言模型生成文本涉及的一些策略。
- en: Using a pre-trained GPT-2 model as a text generator
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用预训练的GPT-2模型作为文本生成器
- en: Using the `transformers` library together with PyTorch, we can load most of
    the latest advanced transformer models for performing various tasks such as language
    modeling, text classification, machine translation, and so on. We demonstrated
    how to do so in *Chapter 5*, *Hybrid Advanced Models*.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`transformers`库和PyTorch，我们可以加载大多数最新的先进变压器模型，用于执行诸如语言建模、文本分类、机器翻译等各种任务。我们在*第5章*，*混合先进模型*中展示了如何做到这一点。
- en: In this section, we will load the pre-trained GPT-2-based language model. We
    will then extend this model so that we can use it as a text generator. Then, we
    will explore the various strategies we can follow to generate text from a pre-trained
    language model and use PyTorch to demonstrate those strategies.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将加载预训练的基于GPT-2的语言模型。然后，我们将扩展此模型，以便我们可以将其用作文本生成器。然后，我们将探索各种策略，以便从预训练的语言模型中生成文本，并使用PyTorch演示这些策略。
- en: Out-of-the-box text generation with GPT-2
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用GPT-2的即时文本生成
- en: 'In the form of an exercise, we will load a pre-trained GPT-2 language model
    using the transformers library and extend this language model as a text generation
    model to generate arbitrary yet meaningful texts. We will only show the important
    parts of the code for demonstration purposes. In order to access the full code,
    go to github [7.2] . Follow these steps:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 作为练习形式，我们将加载一个使用transformers库预训练的GPT-2语言模型，并将此语言模型扩展为文本生成模型以生成任意但有意义的文本。为了演示目的，我们仅显示代码的重要部分。要访问完整的代码，请转到github
    [7.2] 。按照以下步骤进行：
- en: 'First, we need to import the necessary libraries:'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们需要导入必要的库：
- en: '[PRE4]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: We will import the GPT-2 multi-head language model and corresponding tokenizer
    to generate the vocabulary.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将导入GPT-2多头语言模型和相应的分词器来生成词汇表。
- en: 'Next, we will instantiate `GPT2Tokenizer` and the language model. And then,
    we will provide an initial set of words as a cue to the model, as follows:'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将实例化`GPT2Tokenizer`和语言模型。然后，我们将提供一组初始单词作为模型的线索，如下所示：
- en: '[PRE5]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Finally, we will iteratively predict the next word for a given input sequence
    of words using the language model. At each iteration, the predicted word is appended
    to the input sequence of words for the next iteration:'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们将迭代地预测给定输入单词序列的下一个单词，使用语言模型。在每次迭代中，预测的单词将附加到下一次迭代的输入单词序列中：
- en: '[PRE6]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The output should be as follows:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 输出应该如下所示：
- en: '![Figure 7 .3 – GPT-2 generated text](img/file50.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![图7.3 – GPT-2生成的文本](img/file50.png)'
- en: Figure 7 .3 – GPT-2 generated text
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.3 – GPT-2生成的文本
- en: This way of generating text is also called **greedy search**. In the next section,
    we will look at greedy search in more detail and some other text generation strategies
    as well.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这种生成文本的方式也称为**贪婪搜索**。在接下来的部分，我们将更详细地讨论贪婪搜索以及其他一些文本生成策略。
- en: Text generation strategies using PyTorch
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用PyTorch的文本生成策略
- en: When we use a trained text generation model to generate text, we typically make
    predictions word by word. We then consolidate the resulting sequence of predicted
    words as predicted text. When we are in a loop iterating over word predictions,
    we need to specify a method of finding/predicting the next word given the previous
    *k* predictions. These methods are also known as text generation strategies, and
    we will discuss some well-known strategies in this section.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们使用训练过的文本生成模型生成文本时，通常是逐词预测。然后，我们将预测出的一系列单词序列合并为预测文本。当我们在循环中迭代单词预测时，我们需要指定一种方法来找到/预测给定前*k*个预测后的下一个单词。这些方法也被称为文本生成策略，我们将在本节讨论一些著名的策略。
- en: Greedy search
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 贪婪搜索
- en: 'The name *greedy* is justified by the fact that the model selects the word
    with the maximum probability at the current iteration, regardless of how many
    time steps further ahead they are. With this strategy, the model could potentially
    miss a highly probable word hiding (further ahead in time) behind a low probability
    word, merely because the model did not pursue the low probability word. The following
    diagram demonstrates the greedy search strategy by illustrating a hypothetical
    scenario of what might be happening under the hood in *step 3* of the previous
    exercise. At each time step, the text generation model outputs possible words,
    along with their probabilities:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '*贪婪*一词的正当性在于，该模型选择当前迭代中具有最大概率的单词，而不考虑它们在未来多少时间步骤后。通过这种策略，模型可能会错过一个概率高的单词，而选择了一个概率低的单词，因为模型没有追求概率低的单词。以下图表展示了贪婪搜索策略，用一个假设情景来说明在前一个练习的*第3步*中可能发生的情况。在每个时间步骤，文本生成模型输出可能的单词及其概率：'
- en: '![Figure 7 .4 – Greedy search](img/file51.jpg)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![图7 .4 – 贪婪搜索](img/file51.jpg)'
- en: Figure 7 .4 – Greedy search
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图7 .4 – 贪婪搜索
- en: As we can see, at each step, the word with the highest probability is picked
    up by the model under the greedy search strategy of text generation. Note the
    penultimate step, where the model predicts the words **system**, **people**, and
    **future** with roughly equal probabilities. With greedy search, **system** is
    selected as the next word due to it having a slightly higher probability than
    the rest. However, you could argue that **people** or **future** could have led
    to a better or more meaningful generated text.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，在每个步骤中，根据文本生成的贪婪搜索策略，模型会选择具有最高概率的单词。请注意倒数第二步，在这一步中，模型预测单词**system**、**people**和**future**的概率几乎相等。通过贪婪搜索，**system**被选为下一个单词，因为它的概率略高于其他单词。然而，你可以认为**people**或**future**可能会导致更好或更有意义的生成文本。
- en: This is the core limitation of the greedy search approach. Besides, greedy search
    also results in repetitive results due to a lack of randomness. If someone wants
    to use such a text generator artistically, greedy search is not the best approach,
    merely due to its monotonicity.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这是贪婪搜索方法的核心局限性。此外，贪婪搜索还因缺乏随机性而导致重复结果。如果有人想要艺术地使用这样的文本生成器，贪婪搜索并不是最佳选择，仅仅因为它的单调性。
- en: 'In the previous section, we manually wrote the text generation loop. Thanks
    to the `transformers` library, we can write the text generation step in three
    lines of code:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一节中，我们手动编写了文本生成循环。由于`transformers`库的帮助，我们可以用三行代码编写文本生成步骤：
- en: '[PRE7]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'This should output the following:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该输出如下内容：
- en: '![Figure 7 .5 – GPT-2 generated text (concise)](img/file52.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![图7 .5 – GPT-2生成的简明文本](img/file52.png)'
- en: Figure 7 .5 – GPT-2 generated text (concise)
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 图7 .5 – GPT-2生成的简明文本
- en: Notice that the generated sentence shown in Figure 7 .5 has one less token (full-stop)
    than the sentence that was generated in *Figure 7* *.3*. This difference is because
    in the latter code, the `max_length` argument includes the cue words. So, if we
    have one cue word, only nine new words would be predicted, as is the case here
    .
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，图7 .5中生成的句子比图7 .3中生成的句子少一个标记（句号）。这一差异是因为在后者的代码中，`max_length`参数包括了提示词。因此，如果我们有一个提示词，那么仅会预测出九个新单词，正如在这里的情况一样。
- en: Beam search
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 光束搜索
- en: Greedy search is not the only way of generating texts. **Beam search** is a
    development of the greedy search method wherein we maintain a list of potential
    candidate sequences based on the overall predicted sequence probability, rather
    than just the next word probability. The number of candidate sequences to be pursued
    is the number of beams along the tree of word predictions.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 生成文本不仅仅是贪婪搜索的一种方式。**束搜索**是贪婪搜索方法的发展，其中我们维护一个基于整体预测序列概率的潜在候选序列列表，而不仅仅是下一个单词的概率。要追求的候选序列数量即为单词预测树中的光束数。
- en: 'The following diagram demonstrates how beam search with a beam size of three
    would be used to produce three candidate sequences (ordered as per the overall
    sequence probability) of five words each:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表展示了如何使用光束搜索和光束大小为3来生成五个单词的三个候选序列（按照整体序列概率排序）：
- en: '![Figure 7 .6 – Beam search](img/file53.jpg)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![图7 .6 – 光束搜索](img/file53.jpg)'
- en: Figure 7 .6 – Beam search
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 图7 .6 – 光束搜索
- en: At each iteration in this beam search example, the three most likely candidate
    sequences are maintained. As we proceed further in the sequence, the possible
    number of candidate sequences increases exponentially. However, we are only interested
    in the top three sequences. This way, we do not miss potentially better sequences
    as we might with greedy search.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个束搜索示例的每次迭代中，会保留三个最有可能的候选序列。随着序列的推进，可能的候选序列数呈指数增长。然而，我们只关注前三个序列。这样，我们不会像贪婪搜索那样错过潜在更好的序列。
- en: 'In PyTorch, we can use beam search out of the box in one line of code. The
    following code demonstrates beam search-based text generation with three beams
    generating the three most likely sentences, each containing five words:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在 PyTorch 中，我们可以使用一行代码轻松使用束搜索。以下代码演示了基于束搜索的文本生成，使用三个束生成三个最有可能的句子，每个句子包含五个单词：
- en: '[PRE8]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'This gives us the following output:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 这给我们以下输出：
- en: '![Figure 7 .7 – Beam search results](img/file54.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![图 7 .7 – 束搜索结果](img/file54.png)'
- en: Figure 7 .7 – Beam search results
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7 .7 – 束搜索结果
- en: The problem of repetitiveness or monotonicity still remains with the beam search.
    Different runs would result in the same set of results as it deterministically
    looks for the sequence with the maximum overall probabilities. In the next section,
    we will look at some of the ways we can make the generated text more unpredictable
    or creative.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 使用束搜索仍然存在重复性或单调性问题。不同的运行会得到相同的结果集，因为它确定性地寻找具有最大总体概率的序列。在接下来的部分中，我们将探讨一些方法，使生成的文本更加不可预测或创造性。
- en: Top-k and top-p sampling
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Top-k 和 top-p 抽样
- en: Instead of always picking the next word with the highest probability, we can
    randomly sample the next word out of the possible set of next words based on their
    relative probabilities. For example, in *Figure 7* *.6*, the words **be**, **know**,
    and **show** have probabilities of **0.7**, **0.2**, and **0.1**, respectively.
    Instead of always picking **be** against **know** and **show**, we can randomly
    sample any one of these three words based on their probabilities. If we repeat
    this exercise 10 times to generate 10 separate texts, **be** will be chosen roughly
    seven times and **know** and **show** will be chosen two and one times, respectively.
    This gives us far too many different possible combinations of words that beam
    or greedy search would never generate.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以随机抽样下一个单词，而不总是选择具有最高概率的下一个单词，基于它们相对概率的可能集合。例如，在 *图 7 .6* 中，单词**be**，**know**和**show**的概率分别为0.7，0.2和0.1。我们可以基于它们的概率随机抽样其中任何一个单词。如果我们重复此过程10次以生成10个单独的文本，**be**将被选择大约七次，**know**和**show**将分别被选择两次和一次。这给了我们很多贪婪或束搜索永远无法生成的可能单词组合。
- en: Two of the most popular ways of generating texts using sampling techniques are
    known as **top-k** and **top-p** sampling. Under top-k sampling, we predefine
    a parameter, *k*, which is the number of candidate words that should be considered
    while sampling the next word. All the other words are discarded, and the probabilities
    are normalized among the top *k* words. In our previous example, if *k* is 2,
    then the word **show** will be discarded and the words **be** and **know** will
    have their probabilities (**0.7** and **0.2**, respectively) normalized to **0.78**
    and **0.22**, respectively.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 使用抽样技术生成文本的两种最流行方式称为**top-k**和**top-p**抽样。在 top-k 抽样中，我们预先定义一个参数*k*，它是在抽样下一个词时应考虑的候选词数。所有其他词都将被丢弃，并且在前*k*个词中的概率将被归一化。在我们的先前示例中，如果*k*为2，则单词**show**将被丢弃，单词**be**和**know**的概率（分别为0.7和0.2）将被归一化为0.78和0.22。
- en: 'The following code demonstrates the top-k text generation method:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码演示了 top-k 文本生成方法：
- en: '[PRE9]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'This should generate the following output:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该生成以下输出：
- en: '![Figure 7 .8 – Top-k search results](img/file55.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![图 7 .8 – Top-k 搜索结果](img/file55.png)'
- en: Figure 7 .8 – Top-k search results
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7 .8 – Top-k 搜索结果
- en: 'To sample from all possible words, instead of just the top-k words, we shall
    set the `top-k` argument to `0` in our code. As shown in the preceding screenshot,
    different runs produce different results as opposed to greedy search, which would
    result in the exact same result on each run, as shown in the following code :'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 要从所有可能的单词中抽样，而不仅仅是前*k*个单词，请在我们的代码中将`top-k`参数设置为`0`。如前面的屏幕截图所示，不同的运行产生不同的结果，而不是贪婪搜索，每次运行都会产生相同的结果，如以下代码所示：
- en: '[PRE10]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'This should output the following:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该输出以下内容：
- en: '![Figure 7 .9 – Repetitive greedy search results](img/file56.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![图7 .9 – 重复的贪婪搜索结果](img/file56.png)'
- en: Figure 7 .9 – Repetitive greedy search results
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 图7 .9 – 重复的贪婪搜索结果
- en: Under the top-p sampling strategy, instead of defining the top *k* words to
    look at, we can define a cumulative probability threshold (*p*) and then retain
    words whose probabilities add up to *p*. In our example, if *p* is between **0.7**
    and **0.9**, then we discard **know** and **show**, if *p* is between **0.9**
    and **1.0**, then we discard **show**, and if *p* is **1.0**, then we keep all
    three words; that is, **be**, **know**, and **show**.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在top-p抽样策略下，与其定义要查看的前*k*个词汇不同，我们可以定义一个累积概率阈值(*p*)，然后保留那些概率总和达到*p*的词汇。在我们的例子中，如果*p*介于**0.7**和**0.9**之间，则舍弃**know**和**show**；如果*p*介于**0.9**和**1.0**之间，则舍弃**show**；如果*p*为**1.0**，则保留所有三个词汇，即**be**，**know**和**show**。
- en: The top-k strategy can sometimes be unfair in scenarios where the probability
    distribution is flat. This is because it clips off words that are almost as probable
    as the ones that have been retained. In those cases, the top-p strategy would
    retain a larger pool of words to sample from and would retain a smaller pool of
    words in cases where the probability distribution is rather sharp.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在概率分布是平坦的情况下，top-k策略有时可能不公平。这是因为它剪切掉几乎与保留的词汇一样可能的词汇。在这些情况下，top-p策略将保留一个更大的词汇池供抽样，并在概率分布较为尖锐时保留较小的词汇池。
- en: 'The following code demonstrates the top-p sampling method:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码展示了top-p抽样方法的操作：
- en: '[PRE11]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'This should output the following:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该输出以下内容：
- en: '![Figure 7 .10 – Top-p search results](img/file57.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![图7 .10 – Top-p搜索结果](img/file57.png)'
- en: Figure 7 .10 – Top-p search results
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 图7 .10 – Top-p搜索结果
- en: We can set both top-k and top-p strategies together. In this example, we have
    set `top-k` to `0` to essentially disable the top-k strategy, and `p` is set to
    `0.75`. Once again, this results in different sentences across runs and can lead
    us to more creatively generated texts as opposed to greedy or beam search. There
    are many more text generation strategies available, and a lot of research is happening
    in this area. We encourage you to follow up on this further.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以同时设置top-k和top-p策略。在这个例子中，我们将`top-k`设置为`0`以基本上禁用top-k策略，而`p`设置为`0.75`。再次运行时，这会导致不同的句子，使我们能够生成更具创造性的文本，而不是贪婪或波束搜索。在这个领域有许多更多的文本生成策略可供选择，并且正在进行大量的研究。我们鼓励您进一步关注此问题。
- en: A great starting point is playing around with the available text generation
    strategies in the `transformers` library. You can read more about it from their
    blog post [7.3] .
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 一个很好的起点是在`transformers`库中玩转可用的文本生成策略。您可以从他们的博客文章[7.3]中了解更多信息。
- en: This concludes our exploration of using PyTorch to generate text. In the next
    section, we will perform a similar exercise but this time for music instead of
    text. The idea is to train an unsupervised model on a music dataset and use the
    trained model to generate melodies similar to those in the training dataset.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 这篇文章总结了我们使用PyTorch生成文本的探索。在下一节中，我们将执行类似的练习，但这次是针对音乐而不是文本。其思想是在音乐数据集上训练一个无监督模型，并使用训练好的模型生成类似训练数据集中的旋律。
- en: Generating MIDI music with LSTMs using PyTorch
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用PyTorch生成MIDI音乐的LSTM方法
- en: Moving on from text, in this section, we will use PyTorch to create a machine
    learning model that can compose classical-like music. We used transformers for
    generating text in the previous section. Here, we will use an LSTM model to process
    sequential music data. We will train the model on Mozart's classical music compositions.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 转向音乐，本节中我们将使用PyTorch创建一个可以生成类似古典音乐的机器学习模型。在上一节中，我们使用transformers生成文本。在这里，我们将使用LSTM模型处理序列音乐数据。我们将在莫扎特的古典音乐作品上训练模型。
- en: Each musical piece will essentially be broken down into a sequence of piano
    notes. We will be reading music data in the form of **Musical Instruments Digital
    Interface** (**MIDI**) files, which is a well-known and commonly used format for
    conveniently reading and writing musical data across devices and environments.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 每个音乐作品本质上将被分解为一系列钢琴音符。我们将以**音乐器件数字接口**（**MIDI**）文件的形式读取音乐数据，这是一种用于跨设备和环境方便读写音乐数据的常用格式。
- en: After converting the MIDI files into sequences of piano notes (which we call
    the piano roll), we will use them to train a next-piano-note detection system.
    In this system, we will build an LSTM-based classifier that will predict the next
    piano note for the given preceding sequence of piano notes, of which there are
    88 in total (as per the standard 88 piano keys).
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在将 MIDI 文件转换为钢琴音符序列（我们称之为钢琴卷轴）之后，我们将使用它们来训练一个下一个钢琴音符检测系统。在这个系统中，我们将构建一个基于 LSTM
    的分类器，用于预测给定钢琴音符前序列的下一个钢琴音符，总共有 88 个（符合标准的 88 个钢琴键）。
- en: We will now demonstrate the entire process of building the AI music composer
    in the form of an exercise. Our focus will be on the PyTorch code that's used
    for data loading, model training, and generating music samples. Please note that
    the model training process may take several hours and therefore it is recommended
    to run the training process in the background; for example, overnight. The code
    presented here has been curtailed in the interest of keeping the text short.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将展示构建 AI 音乐作曲家的整个过程，这是一个练习形式。我们的重点将放在用于数据加载、模型训练和生成音乐样本的 PyTorch 代码上。请注意，模型训练过程可能需要几个小时，因此建议在后台运行训练过程，例如过夜。出于保持文本简短的考虑，此处呈现的代码已被削减。
- en: Details of handling the MIDI music files are beyond the scope of this book,
    although you are encouraged to explore the full code, which is available at github
    [7.4] .
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 关于处理 MIDI 音乐文件的详细信息超出了本书的范围，尽管鼓励你探索完整的代码，该代码可在 github [7.4] 找到。
- en: Loading the MIDI music data
  id: totrans-108
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 加载 MIDI 音乐数据
- en: 'First, we will demonstrate how to load the music data that is available in
    MIDI format. We will briefly mention the code for handling MIDI data, and then
    illustrate how to make PyTorch dataloaders out of it. Let''s get started:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将演示如何加载以 MIDI 格式可用的音乐数据。我们将简要介绍处理 MIDI 数据的代码，然后说明如何将其转换为 PyTorch 数据加载器。让我们开始吧：
- en: 'As always, we will begin by importing the important libraries. Some of the
    new ones we''ll be using in this exercise are as follows:'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如往常一样，我们将从导入重要的库开始。在这个练习中，我们将使用一些新的库，具体如下：
- en: '[PRE12]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '`skimage` is used to visualize the sequences of the music samples that are
    generated by the model. `struct` and `io` are used for handling the process of
    converting MIDI music data into piano rolls.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '`skimage` 用于可视化模型生成的音乐样本序列。`struct` 和 `io` 用于处理将 MIDI 音乐数据转换为钢琴卷轴的过程。'
- en: 'Next, we will write the helper classes and functions for loading MIDI files
    and converting them into sequences of piano notes (matrices) that can be fed to
    the LSTM model. First, we define some MIDI constants in order to configure various
    music controls such as pitch, channels, start of sequence, end of sequence, and
    so on:'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将编写用于加载 MIDI 文件并将其转换为钢琴音符序列（矩阵）的辅助类和函数。首先，我们定义一些 MIDI 常量，以配置各种音乐控制，如音高、通道、序列开始、序列结束等：
- en: '[PRE13]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Then, we will define a series of classes that will handle MIDI data input and
    output streams, the MIDI data parser, and so on, as follows:'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将定义一系列类，用于处理 MIDI 数据的输入和输出流、MIDI 数据解析器等，如下所示：
- en: '[PRE14]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Having handled all the MIDI data I/O-related code, we are all set to instantiate
    our own PyTorch dataset class. Before we do that, we must define two crucial functions
    – one for converting the read MIDI file into a piano roll and one for padding
    the piano roll with empty notes. This will normalize the lengths of the musical
    pieces across the dataset:'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 处理完所有 MIDI 数据 I/O 相关的代码后，我们现在可以实例化我们自己的 PyTorch 数据集类了。在此之前，我们必须定义两个关键函数——一个用于将读取的
    MIDI 文件转换为钢琴卷轴，另一个用于用空音符填充钢琴卷轴。这将使数据集中的音乐片段长度标准化：
- en: '[PRE15]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Now, we can define our PyTorch dataset class, as follows:'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以定义我们的 PyTorch 数据集类，如下所示：
- en: '[PRE16]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Besides the dataset class, we must add another helper function to post-process
    the music sequences in a batch of training data into three separate lists. These
    will be input sequences, output sequences, and lengths of sequences, ordered by
    the lengths of the sequences in descending order:'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 除了数据集类之外，我们还必须添加另一个辅助函数，将训练数据批次中的音乐序列后处理为三个单独的列表。这些列表将是输入序列、输出序列和序列的长度，按序列长度降序排列：
- en: '[PRE17]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'For this exercise, we will be using a set of Mozart''s compositions. You can
    download the dataset from the piano-midi website [7.5] : . The downloaded folder
    consists of 21 MIDI files, which we will split into 18 training and three validation
    set files. The downloaded data is stored under `./mozart/train` and `./mozart/valid`.
    Once downloaded, we can read the data and instantiate our own training and validation
    dataset loaders:'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了这个练习，我们将使用一组莫扎特的作品。您可以从钢琴MIDI网站[7.5]下载数据集：。下载的文件夹包含21个MIDI文件，我们将它们分成18个训练集文件和3个验证集文件。下载的数据存储在`./mozart/train`和`./mozart/valid`下。下载完成后，我们可以读取数据并实例化我们自己的训练和验证数据集加载器：
- en: '[PRE18]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'This should give us the following output:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该会给我们以下输出：
- en: '![Figure 7 .11 – Sample music data dimensions](img/file58.jpg)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![图 7 .11 – 莫扎特作品数据示例维度](img/file58.jpg)'
- en: Figure 7 .11 – Sample music data dimensions
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7 .11 – 莫扎特作品数据示例维度
- en: 'As we can see, the first validation batch consists of three sequences of length
    1,587 (notes), where each sequence is encoded into an 88-size vector, with 88
    being the total number of piano keys. For those of you who are trained musicians,
    here is a music sheet equivalent of the first few notes of one of the validation
    set music files:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，第一个验证批次包含三个长度为1,587的序列（音符），每个序列编码为一个88大小的向量，其中88是钢琴键的总数。对于那些训练有素的音乐家，以下是验证集音乐文件的前几个音符的乐谱等价物：
- en: '![Figure 7 .12 – Music sheet of a Mozart composition](img/file59.jpg)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![图 7 .12 – 莫扎特作品的乐谱](img/file59.jpg)'
- en: Figure 7 .12 – Music sheet of a Mozart composition
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7 .12 – 莫扎特作品的乐谱
- en: 'Alternatively, we can visualize the sequence of notes as a matrix with 88 rows,
    one per piano key. The following is a visual matrix representation of the preceding
    melody (the first 300 notes out of 1,587):'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，我们可以将音符序列可视化为一个具有88行的矩阵，每行代表一个钢琴键。以下是前述旋律（1,587个音符中的前300个）的视觉矩阵表示：
- en: '![Figure 7 .13 – Matrix representation of a Mozart composition](img/file60.jpg)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![图 7 .13 – 莫扎特作品的矩阵表示](img/file60.jpg)'
- en: Figure 7 .13 – Matrix representation of a Mozart composition
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7 .13 – 莫扎特作品的矩阵表示
- en: '**Dataset citation**'
  id: totrans-134
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**数据集引用**'
- en: ''
  id: totrans-135
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'The MIDI, audio (MP3, OGG), and video files of Bernd Krueger are licensed under
    the CC BY-SA Germany License. Name: Bernd Krueger Source: [http://www.piano-midi.de](http://www.piano-midi.de).
    The distribution or public playback of these files is only allowed under identical
    license conditions. The scores are open source.'
  id: totrans-136
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Bernd Krueger的MIDI、音频（MP3、OGG）和视频文件受CC BY-SA Germany许可证的保护。姓名：Bernd Krueger
    来源：[http://www.piano-midi.de](http://www.piano-midi.de)。这些文件的分发或公共播放仅允许在相同的许可条件下进行。乐谱是开源的。
- en: We will now define the LSTM model and training routine.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将定义LSTM模型和训练例程。
- en: Defining the LSTM model and training routine
  id: totrans-138
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 定义LSTM模型和训练例程
- en: 'So far, we have managed to successfully load a MIDI dataset and use it to create
    our own training and validation data loaders. In this section, we will define
    the LSTM model architecture, as well as the training and evaluation routines that
    shall be run during the model training loop. Let''s get started:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已成功加载了一个MIDI数据集，并用它创建了自己的训练和验证数据加载器。在本节中，我们将定义LSTM模型架构以及在模型训练循环中运行的训练和评估过程。让我们开始吧：
- en: First, we must define the model architecture. As we mentioned earlier, we will
    use an LSTM model that consists of an encoder layer that encodes the 88-dimensional
    representation of the input data at each time step of the sequence into a 512-dimensional
    hidden layer representation. The encoder is followed by two LSTM layers, followed
    by a fully connected layer that finally softmaxes into the 88 classes.
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们必须定义模型架构。如前所述，我们将使用一个LSTM模型，该模型由编码器层组成，在序列的每个时间步骤将输入数据的88维表示编码为512维隐藏层表示。编码器之后是两个LSTM层，再接一个全连接层，最终通过softmax函数映射到88个类别。
- en: 'As per the different types of **recurrent neural networks** (**RNNs**) we discussed
    in *Chapter 4, Deep Recurrent Model Architectures*, this is a many-to-one sequence
    classification task, where the input is the entire sequence from time step *0*
    to time step *t* and the output is one of the 88 classes at time step *t+1*, as
    follows:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我们在*第4章 深度递归模型架构*中讨论的不同类型的**递归神经网络**（**RNNs**），这是一个多对一的序列分类任务，其中输入是从时间步 *0*
    到时间步 *t* 的整个序列，输出是时间步 *t+1* 处的88个类别之一，如下所示：
- en: '[PRE19]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Once the model architecture has been defined, we can specify the model training
    routine. We will use the Adam optimizer with gradient clipping to avoid overfitting.
    Another measure that''s already in place to counter overfitting is the use of
    a dropout layer, as specified in the previous step:'
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦模型架构被定义，我们就可以指定模型训练例程。我们将使用Adam优化器并进行梯度裁剪以避免过拟合。作为对抗过拟合的另一个措施，我们已经在先前的步骤中使用了一个dropout层：
- en: '[PRE20]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Similarly, we will define the model evaluation routine, where a forward pass
    is run on the model with its parameters remaining unchanged:'
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 同样地，我们将定义模型评估例程，其中模型的前向传播在其参数保持不变的情况下运行：
- en: '[PRE21]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Now, let's train and test the music generation model.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来训练和测试音乐生成模型。
- en: Training and testing the music generation model
  id: totrans-148
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 训练和测试音乐生成模型
- en: 'In this final section, we will actually train the LSTM model. We will then
    use the trained music generation model to generate a music sample that we can
    listen to and analyze. Let''s get started:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在最后的部分，我们将实际训练LSTM模型。然后，我们将使用训练好的音乐生成模型生成一段我们可以听并分析的音乐样本。让我们开始吧：
- en: 'We are all set to instantiate our model and start training it. We have used
    categorical cross-entropy as the loss function for this classification task. We
    are training the model with a learning rate of `0.01` for `10` epochs:'
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们已准备好实例化我们的模型并开始训练。对于这个分类任务，我们使用了分类交叉熵作为损失函数。我们将以学习率`0.01`进行`10`个epoch的模型训练：
- en: '[PRE22]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'This should output the following:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 这将输出以下内容：
- en: '![Figure 7 . 14 – Music LSTM training logs](img/file61.jpg)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![图 7 . 14 – 音乐LSTM训练日志](img/file61.jpg)'
- en: Figure 7 . 14 – Music LSTM training logs
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7 . 14 – 音乐LSTM训练日志
- en: Here comes the fun part. Once we have a next-musical-note-predictor, we can
    use it as a music generator. All we need to do is simply initiate the prediction
    process by providing an initial note as a cue. The model can then recursively
    make predictions for the next note at each time step, wherein the predictions
    at time step *t* are appended to the input sequence at time *t+1*.
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在是有趣的部分。一旦我们有了一个下一个音符预测器，我们就可以将其用作音乐生成器。我们所需做的就是通过提供一个初始音符作为线索来启动预测过程。模型然后可以在每个时间步骤递归地预测下一个音符，在此过程中，*t*时间步的预测将附加到*t+1*时间步的输入序列中。
- en: 'Here, we will write a music generation function that takes in the trained model
    object, the intended length of music to be generated, a starting note to the sequence,
    and temperature. Temperature is a standard mathematical operation over the `softmax`
    function at the classification layer. It is used to manipulate the distribution
    of softmax probabilities, either by broadening or shrinking the softmaxed probabilities
    distribution. The code is as follows:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将编写一个音乐生成函数，该函数接收训练好的模型对象、生成音乐的长度、序列的起始音符和温度作为输入。温度是在分类层上标准的数学操作。它用于操纵softmax概率分布，可以通过扩展或缩小softmax概率分布来调整softmax概率的分布。代码如下：
- en: '[PRE23]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Finally, we can use this function to create a brand-new music composition:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以使用此函数来创建全新的音乐作品：
- en: '[PRE24]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'This should create the musical piece and save it as a MIDI file in the current
    directory. We can open the file and play it to hear what the model has produced.
    Nonetheless, we can also view the visual matrix representation of the produced
    music:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 这将创建音乐作品并将其保存为当前目录下的MIDI文件。我们可以打开文件并播放它以听听模型产生了什么。此外，我们还可以查看所产生音乐的视觉矩阵表示：
- en: '[PRE25]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'This should give us the following output:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 这将给我们以下输出：
- en: '![Figure 7 .15 – Matrix representation of an AI generated music sample](img/file62.jpg)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![图 7 .15 – AI生成音乐示例的矩阵表示](img/file62.jpg)'
- en: Figure 7 .15 – Matrix representation of an AI generated music sample
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7 .15 – AI生成音乐示例的矩阵表示
- en: 'Furthermore, here is what the generated music would look like as a music sheet:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，以下是生成音乐作品作为乐谱的样子：
- en: '![Figure 7 .16 – Music sheet of an AI generated music sample](img/file63.jpg)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![图 7 .16 – AI生成音乐示例的乐谱](img/file63.jpg)'
- en: Figure 7 .16 – Music sheet of an AI generated music sample
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7 . 16 – AI生成音乐示例的乐谱
- en: Here, we can see that the generated melody seems to be not quite as melodious
    as Mozart's original compositions. Nonetheless, you can see consistencies in some
    key combinations that the model has learned. Moreover, the generated music quality
    can be enhanced by training the model on more data, as well as training it for
    more epochs.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到生成的旋律似乎不像莫扎特的原创作品那样悦耳动听。尽管如此，您可以看到模型已学会了一些关键组合的一致性。此外，通过在更多数据上训练模型并增加训练轮次，生成音乐的质量可以得到提升。
- en: This concludes our exercise on using machine learning to generate music. In
    this section, we have demonstrated how to use existing musical data to train a
    note predictor model from scratch and use the trained model to generate music.
    In fact, you can extend the idea of using generative models to generate samples
    of any kind of data. PyTorch is an extremely effective tool when it comes to such
    use cases, especially due to its straightforward APIs for data loading, model
    building/training/testing, and using trained models as data generators. You are
    encouraged to try out more such tasks on different use cases and data types.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 这就结束了我们关于使用机器学习生成音乐的练习。在本节中，我们演示了如何使用现有的音乐数据从头开始训练一个音符预测模型，并使用训练好的模型生成音乐。事实上，你可以将生成模型的思路扩展到生成任何类型数据的样本上。PyTorch在这类用例中非常有效，特别是由于其简单直观的数据加载、模型构建/训练/测试的API，以及将训练好的模型用作数据生成器的能力。我们鼓励你在不同的用例和数据类型上尝试更多类似的任务。
- en: Summary
  id: totrans-170
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we explored generative models using PyTorch. In the same artistic
    vein, in the next chapter, we shall learn how machine learning can be used to
    transfer the style of one image to another. With PyTorch at our disposal, we will
    use CNNs to learn artistic styles from various images and impose those styles
    on different images – a task better known as neural style transfer.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了使用PyTorch的生成模型。在同样的艺术风格中，在下一章中，我们将学习如何使用机器学习将一幅图像的风格转移到另一幅图像上。有了PyTorch的支持，我们将使用CNN从各种图像中学习艺术风格，并将这些风格应用于不同的图像上——这一任务更为人熟知的是神经风格转移。
