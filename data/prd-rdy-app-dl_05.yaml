- en: '4'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '4'
- en: Experiment Tracking, Model Management, and Dataset Versioning
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实验跟踪，模型管理和数据集版本控制
- en: In this chapter, we will introduce a set of useful tools for experiment tracking,
    model management, and dataset versioning, which allows you to effectively manage
    **deep learning** (**DL**) projects. The tools we will be discussing in this chapter
    can help us track many experiments and interpret the results more efficiently,
    which naturally leads to a reduction in operational costs and boosts the development
    cycle. By the end of the chapter, you will have hands-on experience with the most
    popular tools and be able to select the right set of tools for your project.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍一组用于实验跟踪、模型管理和数据集版本控制的实用工具，这些工具可以帮助您有效管理深度学习（DL）项目。本章讨论的工具可以帮助我们跟踪许多实验并更高效地解释结果，从而自然而然地减少运营成本并加速开发周期。通过本章，您将能够亲自体验最流行的工具，并能够为您的项目选择适当的工具集。
- en: 'In this chapter, we’re going to cover the following main topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主要内容：
- en: Overview of DL project tracking
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DL项目跟踪概述
- en: DL project tracking with Weights & Biases
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Weights & Biases进行DL项目跟踪
- en: DL project tracking with MLflow and DVC
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用MLflow和DVC进行DL项目跟踪
- en: Dataset versioning – beyond Weights & Biases, MLflow, and DVC
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据集版本控制 – 超越Weights & Biases, MLflow和DVC
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: You can download the supplemental material for this chapter from this book’s
    GitHub repository at [https://github.com/PacktPublishing/Production-Ready-Applied-Deep-Learning/tree/main/Chapter_4](https://github.com/PacktPublishing/Production-Ready-Applied-Deep-Learning/tree/main/Chapter_4).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从本书的GitHub仓库下载本章的补充材料，网址为[https://github.com/PacktPublishing/Production-Ready-Applied-Deep-Learning/tree/main/Chapter_4](https://github.com/PacktPublishing/Production-Ready-Applied-Deep-Learning/tree/main/Chapter_4)。
- en: Overview of DL project tracking
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: DL项目跟踪概述
- en: Training DL models is an iterative process that consumes a lot of time and resources.
    Therefore, keeping track of all experiments and consistently organizing them can
    prevent us from wasting our time on unnecessary operations such as training similar
    models repeatedly on the same set of data. In other words, having well-documented
    records of all model architectures and their hyperparameter sets, as well as the
    version of data used during experiments, can help us derive the right conclusion
    from the experiments, which naturally leads to the project being successful.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 训练DL模型是一个消耗大量时间和资源的迭代过程。因此，跟踪所有实验并始终有条理地组织它们可以防止我们浪费时间在无需重复训练相似模型的操作上。换句话说，有关所有模型架构及其超参数集合以及实验过程中使用的数据版本的详细记录可以帮助我们从实验中得出正确的结论，这自然而然地有助于项目的成功。
- en: Components of DL project tracking
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DL项目跟踪的组成部分
- en: The essential components of **DL project tracking** are **experiment tracking**,
    **model management**, and **dataset versioning**. Let’s look at each component
    in detail.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: DL项目跟踪的基本组成部分包括实验跟踪，模型管理和数据集版本控制。让我们详细看看每个组件。
- en: Experiment tracking
  id: totrans-14
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 实验跟踪
- en: 'The concept behind experiment tracking is simple: store the description and
    the motivations of each experiment so that we don’t run another set of experiments
    for the same purpose. Overall, effective experiment tracking will save us operational
    costs and allows us to derive the right conclusion from a minimal set of experimental
    results. One of the basic approaches for effective experiment tracking is adding
    a unique identifier to each experiment. The information we need to track for each
    experiment includes project dependencies, the definition of the model architecture,
    parameters used, and evaluation metrics. Experiment tracking also includes visualizing
    ongoing experiments in real time and being able to compare a set of experiments
    intuitively. For example, if we can check train and validation losses from every
    epoch as the model gets trained, we can identify overfitting quicker, saving some
    resources. Also, by comparing results and a set of changes made between two experiments,
    we can understand how the changes affect the model performance.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 实验跟踪背后的概念很简单：存储每个实验的描述和动机，以便我们不为了相同目的再次运行一组实验。总体而言，有效的实验跟踪将节省我们运营成本，并允许我们从最小的实验结果集中得出正确的结论。有效实验跟踪的基本方法之一是为每个实验添加唯一标识符。我们需要跟踪每个实验的信息包括项目依赖关系、模型架构定义、使用的参数和评估指标。实验跟踪还包括实时可视化进行中的实验，并能够直观地比较一组实验。例如，如果我们可以检查模型训练过程中每个时期的训练和验证损失，我们可以更快地识别过拟合，从而节省一些资源。此外，通过比较两个实验之间的结果和一组变化，我们可以理解这些变化如何影响模型性能。
- en: Model management
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型管理
- en: 'Model management goes beyond experiment tracking as it covers the full life
    cycle of a model: dataset information, artifacts (any data generated from training
    a model), the implementation of the model, evaluation metrics, and pipeline information
    (such as development, testing, staging, and production). Model management allows
    us to quickly pick up the model of interest and efficiently set up the environment
    in which the model can be used.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 模型管理不仅仅涵盖实验跟踪，还涵盖了模型的整个生命周期：数据集信息、工件（从训练模型生成的任何数据）、模型的实施、评估指标以及管道信息（如开发、测试、暂存和生产）。模型管理使我们能够快速选择感兴趣的模型，并有效地设置模型可用的环境。
- en: Dataset versioning
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据集版本控制
- en: The last component of DL project tracking is dataset versioning. In many projects,
    datasets change over time. Changes can come from data schemas (blueprints of how
    the data is organized), file locations, or even from filters applied to the dataset
    manipulating the meaning of the underlying data. Many datasets found in the industry
    are structured in a complex way and often stored in multiple locations in various
    data formats. Therefore, changes can be more dramatic and harder to track than
    you anticipated. As a result, keeping a record of the changes is critical in reproducing
    consistent results throughout the project.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: DL 项目跟踪的最后一个组成部分是数据集版本控制。在许多项目中，数据集会随时间改变。这些变化可能来自数据模式（数据组织的蓝图）、文件位置，甚至是应用于数据集的筛选器，从而操作底层数据的含义。工业中发现的许多数据集结构复杂，并且通常以多种数据格式存储在多个位置。因此，变化可能比预期的更加显著和难以跟踪。因此，在记录这些变化方面至关重要，以在整个项目中复制一致的结果。
- en: 'Dataset tracking can be summarized as follows: a set of data stored as an artifact
    should become a new version of the artifact whenever the underlying data is modified.
    Having said that, every artifact should have metadata that consists of important
    information about the dataset: when it is created, who created it, and how it
    is different from the previous version.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集跟踪可以总结如下：将存储为工件的一组数据，在基础数据修改时应成为工件的新版本。话虽如此，每个工件应具有元数据，其中包含关于数据集的重要信息：创建时间、创建者以及与上一版本的差异。
- en: 'For example, a dataset with dataset versioning should be formulated as follows.
    The dataset should have a timestamp in its name:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，应该如下制定具有数据集版本控制的数据集。数据集应在其名称中具有时间戳：
- en: '[PRE0]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'As mentioned previously, the metadata should contain key information about
    the dataset:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 正如前面所述，元数据应包含关于数据集的关键信息：
- en: '[PRE1]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Please note that the set of information that’s tracked by metadata may be different
    for each project.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，由元数据跟踪的信息集可能因项目而异。
- en: Tools for DL project tracking
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DL 项目跟踪工具
- en: DL tracking can be achieved in various ways, starting from simple notes in a
    text file, through spreadsheets, keeping the information in GitHub or dedicated
    web pages, to self-built platforms and external tools. Model and data artifacts
    can be stored as is, or more sophisticated methods can be applied to avoid redundancy
    and increase efficiency.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: DL跟踪可以通过多种方式实现，从简单的文本文件中的注释、电子表格，到在GitHub或专用网页上保存信息，再到自建平台和外部工具。模型和数据工件可以按原样存储，也可以应用更复杂的方法以避免冗余并提高效率。
- en: The field of DL project tracking is growing fast and is introducing new tools
    continuously. As a result, selecting the right tool for the underlying project
    is not an easy task. We must consider both business and technical constraints.
    While the pricing model is a basic one, the other constraints can possibly be
    introduced by the existing development settings; integrating the existing tools
    should be easy, and the infrastructure must be easy to maintain. It is also important
    to consider the engineering competence of the MLOps team. Having said that, the
    following list would be a good starting point when you’re selecting a tool for
    your project.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: DL项目跟踪领域正在快速增长，并不断引入新工具。因此，为底层项目选择合适的工具并不容易。我们必须考虑业务和技术限制。尽管定价模型是基本的，但其他限制可能由现有的开发设置引入；集成现有工具应该很容易，基础设施必须易于维护。还要考虑MLOps团队的工程能力。话虽如此，在选择项目工具时，以下列表将是一个很好的起点。
- en: 'TensorBoard ([https://www.tensorflow.org/tensorboard](https://www.tensorflow.org/tensorboard)):'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorBoard ([https://www.tensorflow.org/tensorboard](https://www.tensorflow.org/tensorboard))：
- en: An open source visualization tool developed by the TensorFlow team
  id: totrans-30
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow团队开发的一款开源可视化工具。
- en: A standard tool for tracking and visualizing the experimental results
  id: totrans-31
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于跟踪和可视化实验结果的标准工具。
- en: 'Weights & Biases ([https://wandb.ai](https://wandb.ai/site/experiment-tracking)):'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Weights & Biases ([https://wandb.ai](https://wandb.ai/site/experiment-tracking))：
- en: A cloud-based service with an effective and interactive dashboard for visualizing
    and organizing the experimental results
  id: totrans-33
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一款云端服务，提供有效的交互式仪表板，用于可视化和组织实验结果。
- en: The server can be run locally or hosted in a private cloud
  id: totrans-34
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务器可以在本地运行，也可以托管在私有云中。
- en: It provides an automated hyperparameter-tuning feature called Sweeps
  id: totrans-35
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供名为Sweeps的自动化超参数调整功能。
- en: Free for personal projects. Pricing is based on the tracking hours and storage
    space
  id: totrans-36
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 个人项目免费。定价基于跟踪小时数和存储空间。
- en: 'Neptune ([https://neptune.ai](https://neptune.ai/product)):'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Neptune ([https://neptune.ai](https://neptune.ai/product))：
- en: An online tool for monitoring and storing the artifacts from machine learning
    (ML) experiments
  id: totrans-38
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于监视和存储机器学习（ML）实验结果的在线工具。
- en: It can easily be integrated with the other ML tools
  id: totrans-39
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可轻松集成其他ML工具。
- en: It’s known for its powerful dashboard which summarizes the experiments in real
    time
  id: totrans-40
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以其强大的仪表板而闻名，实时总结实验结果。
- en: 'MLflow ([https://mlflow.org](https://mlflow.org/docs/latest/tracking.html)):'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MLflow ([https://mlflow.org](https://mlflow.org/docs/latest/tracking.html))：
- en: An open source platform that offers end-to-end ML life cycle management
  id: totrans-42
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个提供端到端ML生命周期管理的开源平台。
- en: It supports both Python and R-based systems. It is often used in combination
    with **Data Version Control** (**DVC**)
  id: totrans-43
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它支持基于Python和R的系统。通常与**数据版本控制**（**DVC**）结合使用。
- en: 'SageMaker Studio ([https://aws.amazon.com/sagemaker/studio/](https://aws.amazon.com/sagemaker/studio/)):'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SageMaker Studio ([https://aws.amazon.com/sagemaker/studio/](https://aws.amazon.com/sagemaker/studio/))：
- en: A web-based visual interface for managing ML experiments set up with SageMaker
  id: totrans-45
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个基于Web的可视化界面，用于管理与SageMaker设置的ML实验。
- en: The tool allows users to efficiently build, train, and deploy models by providing
    simple integrations to the other useful features of AWS
  id: totrans-46
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该工具允许用户通过提供与AWS的其他有用功能简单集成，高效地构建、训练和部署模型。
- en: 'Kubeflow ([https://www.kubeflow.org](https://www.kubeflow.org/)):'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubeflow ([https://www.kubeflow.org](https://www.kubeflow.org/))：
- en: An open source platform designed by Google for end-to-end ML orchestration and
    management
  id: totrans-48
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由Google设计的开源平台，用于端到端ML编排和管理。
- en: It is also designed for deploying ML systems to various development and production
    environments efficiently
  id: totrans-49
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 也设计用于将ML系统高效地部署到各种开发和生产环境中。
- en: 'Valohai ([https://valohai.com](https://valohai.com/product/)):'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Valohai ([https://valohai.com](https://valohai.com/product/))：
- en: A DL management platform designed for automatic machine orchestration, version
    control, and data pipeline management
  id: totrans-51
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一款专为自动化机器编排、版本控制和数据管道管理而设计的DL管理平台。
- en: It is not free software as it’s designed for an enterprise
  id: totrans-52
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它并非免费软件，而是专为企业设计的
- en: It is gaining popularity for being technology agnostic and having a responsive
    support team
  id: totrans-53
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它因技术不限和响应迅速的支持团队而日益受欢迎
- en: 'Out of the various tools, we will cover the two most commonly used settings:
    Weights & Biases and MLflow combined with DVC.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在各种工具中，我们将介绍两种最常用的设置：Weights & Biases 和 MLflow 结合 DVC。
- en: Things to remember
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 需记住的事项
- en: a. The essential components of DL tracking are experiment tracking, model management,
    and dataset versioning. Recent DL tracking tools often have user-friendly dashboards
    that summarize the experimental results.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: a. DL 跟踪的基本组件包括实验跟踪、模型管理和数据集版本控制。近期的 DL 跟踪工具通常具有用户友好的仪表板，总结实验结果。
- en: b. The field is growing and there are many tools with different advantages.
    Selecting the right tool involves understanding both business and technical constraints.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: b. 该领域正在快速发展，并且有许多具有不同优势的工具。选择合适的工具需要理解业务和技术约束。
- en: First, let’s look at DL project tracking with **Weights & Biases** (**W&B**).
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们看看使用 **Weights & Biases** (**W&B**) 进行 DL 项目跟踪。
- en: DL project tracking with Weights & Biases
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Weights & Biases 进行 DL 项目跟踪
- en: W&B is an experiment management platform that provides versioning for models
    and data.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: W&B 是一个实验管理平台，为模型和数据提供版本控制。
- en: 'W&B provides an interactive dashboard that can be embedded in Jupyter notebooks
    or used as a standalone web page. The simple Python API opens up the possibility
    for simple integration as well. Furthermore, its features focus on simplifying
    DL experiment management: logging and monitoring model and data versions, hyperparameter
    values, evaluation metrics, artifacts, and other related information.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: W&B 提供了一个交互式仪表板，可以嵌入到 Jupyter 笔记本中或用作独立的网页。简单的 Python API 也为简单集成打开了可能性。此外，其功能侧重于简化
    DL 实验管理：记录和监控模型和数据版本、超参数值、评估指标、工件和其他相关信息。
- en: Another interesting feature of W&B is its built-in hyperparameter search feature
    called **Sweeps** ([https://docs.wandb.ai/guides/sweeps](https://docs.wandb.ai/guides/sweeps)).
    Sweeps can easily be set up using the Python API, and the results and models can
    be compared interactively on the W&B web page.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: W&B 的另一个有趣功能是其内置的超参数搜索功能称为 **Sweeps** ([https://docs.wandb.ai/guides/sweeps](https://docs.wandb.ai/guides/sweeps))。可以使用
    Python API 轻松设置 Sweeps，并在 W&B 网页上交互比较结果和模型。
- en: Finally, W&B automatically creates reports for you that summarize and organize
    a set of experiments intuitively ([https://docs.wandb.ai/guides/reports](https://docs.wandb.ai/guides/reports)).
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，W&B 会自动为您创建报告，直观地总结和组织一组实验（[https://docs.wandb.ai/guides/reports](https://docs.wandb.ai/guides/reports)）。
- en: 'Overall, the key functionalities of W&B can be summarized as follows:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，W&B 的关键功能可以总结如下：
- en: '**Experiment tracking and management**'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**实验跟踪和管理**'
- en: '**Artifact management**'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**工件管理**'
- en: '**Model evaluation**'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型评估**'
- en: '**Model optimization**'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型优化**'
- en: '**Collaborative analysis**'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**协同分析**'
- en: W&B is a subscription-based service, but personal accounts are free of charge.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: W&B 是一种订阅服务，但个人账户是免费的。
- en: Setting up W&B
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置 W&B
- en: W&B has a Python API that provides simple integration methods for many DL frameworks,
    including TensorFlow and PyTorch. The logged information, such as projects, teams,
    and the list of runs, is managed and visible online or on a self-hosted server.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: W&B 拥有 Python API，为多种 DL 框架（包括 TensorFlow 和 PyTorch）提供简单的集成方法。记录的信息，如项目、团队和运行列表，可在线管理和查看，或者在自托管服务器上进行管理。
- en: 'The first step of setting up W&B is to install the Python API and log into
    the W&B server. You must create an account beforehand through [https://wandb.ai](https://wandb.ai):'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 设置 W&B 的第一步是安装 Python API 并登录 W&B 服务器。您必须预先通过 [https://wandb.ai](https://wandb.ai)
    创建一个账户：
- en: '[PRE2]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Within your Python code, you can register a single experiment that will be
    called `run-1` through the following line of code:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在您的 Python 代码中，您可以通过以下代码注册一个称为 `run-1` 的单个实验：
- en: '[PRE3]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'More precisely, the `wandb.init` function creates a new `wandb.Run` instance
    named `run_1` within a project called `example-DL-Book`. If a name is not provided,
    W&B will generate a random two-word name for you. If the project name is empty,
    W&B will put your run into the `Uncategorized` project. All the parameters of
    `wandb.init` are listed at [https://docs.wandb.ai/ref/python/init](https://docs.wandb.ai/ref/python/init),
    but we would like to introduce the ones that you will mostly interact with:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 更具体地说，`wandb.init` 函数在名为 `example-DL-Book` 的项目中创建了一个名为 `run_1` 的新 `wandb.Run`
    实例。如果未提供名称，W&B 将为您生成一个随机的双字名称。如果项目名称为空，W&B 将将您的运行放入 `Uncategorized` 项目中。`wandb.init`
    的所有参数列在 [https://docs.wandb.ai/ref/python/init](https://docs.wandb.ai/ref/python/init)，但我们想介绍您最常与之交互的参数：
- en: '`id` sets a unique ID for your run'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`id` 为您的运行设置一个唯一的 ID'
- en: '`resume` allows you to resume an experiment without creating a new run'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resume` 允许您在不创建新运行的情况下恢复实验'
- en: '`job_type` allows you to assign your run to a specific type such as training,
    testing, validation, exploration, or any other name that can be used for grouping
    the runs'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`job_type` 允许您将运行分配给特定类型，例如训练、测试、验证、探索或任何其他可以用于分组运行的名称'
- en: '`tags` gives you additional flexibility for organizing your runs'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tags` 提供了额外的灵活性，用于组织您的运行'
- en: 'When the `wandb.init` function is triggered, information about the run will
    start appearing on the W&B dashboard. You can monitor the dashboard on the W&B
    web page or directly in the Jupyter notebook environment, as shown in the following
    screenshot:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 当触发 `wandb.init` 函数时，关于运行的信息将开始出现在 W&B 仪表板上。您可以在 W&B 网页或直接在 Jupyter 笔记本环境中监视仪表板，如下面的截图所示：
- en: '![Figure 4.1 – The W&B dashboard inside a Jupyter notebook environment'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 4.1 – Jupyter 笔记本环境中的 W&B 仪表板'
- en: '](img/B18522_02_01.jpg)'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18522_02_01.jpg)'
- en: Figure 4.1 – The W&B dashboard inside a Jupyter notebook environment
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.1 – Jupyter 笔记本环境中的 W&B 仪表板
- en: 'When the run is created, you can start logging information; the `wandb.log`
    function allows you to log any data you want. For example, you can log loss during
    training by adding `wandb.log({"custom_loss": custom_loss})` to the training loop.
    Similarly, you can log validation loss and any other details that you want to
    keep track of.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '创建运行后，您可以开始记录信息；`wandb.log` 函数允许您记录任何您想要的数据。例如，您可以通过在训练循环中添加 `wandb.log({"custom_loss":
    custom_loss})` 来记录损失。同样，您可以记录验证损失和任何其他您想要跟踪的详细信息。'
- en: Interestingly, W&B made this process even simpler by providing built-in logging
    functionalities for DL models. At the time of writing, you can find integrations
    for most frameworks, including Keras, PyTorch, PyTorch Lightning, TensorFlow,
    fast.ai, scikit-learn, SageMaker, Kubeflow, Docker, Databricks, and Ray Tune (for
    details, see [https://docs.wandb.ai/guides/integrations](https://docs.wandb.ai/guides/integrations)).
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，W&B 通过为 DL 模型提供内置的日志记录功能，使这个过程变得更加简单。在撰写本文时，您可以找到大多数框架的集成，包括 Keras、PyTorch、PyTorch
    Lightning、TensorFlow、fast.ai、scikit-learn、SageMaker、Kubeflow、Docker、Databricks
    和 Ray Tune（有关详细信息，请参见 [https://docs.wandb.ai/guides/integrations](https://docs.wandb.ai/guides/integrations)）。
- en: '`wandb.config` is an excellent place to track model hyperparameters. For any
    artifacts from experiments, you can use the `wandb.log_artifact` method (for more
    details, see [https://docs.wandb.ai/guides/artifacts](https://docs.wandb.ai/guides/artifacts)).
    When logging an artifact, you need to define a file path and then assign the name
    and type of your artifact, as shown in the following code snippet:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '`wandb.config` 是跟踪模型超参数的绝佳位置。对于来自实验的任何工件，您可以使用 `wandb.log_artifact` 方法（有关更多详细信息，请参见
    [https://docs.wandb.ai/guides/artifacts](https://docs.wandb.ai/guides/artifacts)）。在记录工件时，您需要定义文件路径，然后指定您的工件的名称和类型，如以下代码片段所示：'
- en: '[PRE4]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Then, you can reuse the artifact that’s been stored, as follows:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，您可以重复使用已存储的工件，如下所示：
- en: '[PRE5]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: So far, you have learned how to set up `wandb` for your project and log metrics
    and artifacts of your choice individually throughout training. Interestingly,
    `wandb` provides automatic logging for many DL frameworks. In this chapter, we
    will take a closer look at W&B integration for Keras and **PyTorch Lighting**
    (**PL**).
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，您已经学会了如何为您的项目设置 `wandb` 并在整个训练过程中单独记录您选择的指标和工件。有趣的是，`wandb` 为许多深度学习框架提供了自动日志记录。在本章中，我们将更详细地了解如何将
    W&B 集成到 Keras 和 **PyTorch Lightning** (**PL**) 中。
- en: Integrating W&B into a Keras project
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将 W&B 集成到 Keras 项目中
- en: 'In the case of Keras, integration can be achieved through the `WandbCallback`
    class. The complete version can be found in this book’s GitHub repository:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Keras 的情况下，可以通过 `WandbCallback` 类实现集成。完整版本可以在本书的 GitHub 存储库中找到：
- en: '[PRE6]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'As described in the previous section, key information about the models gets
    logged and becomes available on the W&B dashboard. You can monitor losses, evaluation
    metrics, and hyperparameters. *Figure 4.2* shows the sample plots that are generated
    automatically by W&B through the preceding code:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 如前一节所述，关于模型的关键信息被记录并在 W&B 仪表板上可用。您可以监视损失、评估指标和超参数。*图 4.2* 展示了由前述代码自动生成的示例图：
- en: '![Figure 4.2 – Sample plots generated by W&B from logged metrics'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 4.2 – Sample plots generated by W&B from logged metrics](img/B18522_04_02.jpg)'
- en: '](img/B18522_04_02.jpg)'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 4.2 – Sample plots generated by W&B from logged metrics](img/B18522_04_02.jpg)'
- en: Figure 4.2 – Sample plots generated by W&B from logged metrics
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.2 – W&B 根据记录的指标生成的示例图
- en: Integrating W&B into a PL project is similar to integrating W&B into a Keras
    project.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 将 W&B 集成到 PL 项目中类似于将其集成到 Keras 项目中。
- en: Integrating W&B into a PyTorch Lightning project
  id: totrans-101
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将 W&B 集成到 PyTorch Lightning 项目中
- en: 'For a project based on PL, W&B provides a custom logger and hides most of the
    boilerplate code. All you need to do is instantiate the `WandbLogger` class and
    pass it to the `Trainer` instance through `logger` parameter:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 对于基于 PL 的项目，W&B 提供了自定义记录器，并隐藏了大部分样板代码。您只需要实例化 `WandbLogger` 类，并通过 `logger` 参数将其传递给
    `Trainer` 实例：
- en: '[PRE7]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: A detailed explanation of the integration can be found at [https://pytorch-lightning.readthedocs.io/en/stable/extensions/generated/pytorch_lightning.loggers.WandbLogger.html](https://pytorch-lightning.readthedocs.io/en/stable/extensions/generated/pytorch_lightning.loggers.WandbLogger.html).
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 关于集成的详细说明可在 [https://pytorch-lightning.readthedocs.io/en/stable/extensions/generated/pytorch_lightning.loggers.WandbLogger.html](https://pytorch-lightning.readthedocs.io/en/stable/extensions/generated/pytorch_lightning.loggers.WandbLogger.html)
    找到。
- en: Things to remember
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 需记住的事项
- en: a. W&B is an experiment management platform that helps in tracking different
    versions of models and data. It also supports storing configurations, hyperparameters,
    data, and model artifacts while providing experiment tracking in real time.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: a. W&B 是一个实验管理平台，有助于跟踪模型和数据的不同版本。它还支持存储配置、超参数、数据和模型工件，并提供实时实验跟踪。
- en: b. W&B is easy to set up. It provides a built-in integration feature for many
    DL frameworks, including TensorFlow and PyTorch.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: b. W&B 安装简便。它为多个 DL 框架提供了内置的集成功能，包括 TensorFlow 和 PyTorch。
- en: c. W&B can be used to perform hyperparameter tuning/model optimization.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: c. 可以使用 W&B 进行超参数调优/模型优化。
- en: While W&B has been dominating the field of DL project tracking, the combination
    of MLflow and DVC is another popular setup for a DL project.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 W&B 在 DL 项目跟踪领域占据主导地位，但 MLflow 和 DVC 的组合是另一种流行的 DL 项目设置。
- en: DL project tracking with MLflow and DVC
  id: totrans-110
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 MLflow 和 DVC 进行 DL 项目跟踪
- en: 'MLflow is a popular framework that supports tracking technical dependencies,
    model parameters, metrics, and artifacts. The key components of MLflow are as
    follows:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: MLflow 是一个流行的框架，支持跟踪技术依赖项、模型参数、指标和工件。MLflow 的关键组件如下：
- en: '**Tracking**: It keeps a track of result changes every time the model runs'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**跟踪**：每次模型运行时跟踪结果变化'
- en: '**Projects**: It packages model code in a reproducible way'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**项目**：它以可重现的方式打包模型代码'
- en: '**Models**: It organizes model artifacts for future convenient deployments'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型**：它为未来便捷的部署组织模型工件'
- en: '**Model Registry**: It manages a full life cycle of an MLflow model'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型注册表**：它管理 MLflow 模型的完整生命周期'
- en: '**Plugins**: It can be easily integrated with other DL frameworks as it provides
    flexible plugins'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**插件**：由于提供了灵活的插件，可以轻松集成其他 DL 框架'
- en: As you may have already noticed, there are some similarities between W&B and
    MLflow. However, in the case of MLflow, every experiment is linked with a set
    of Git commits. Git does not prevent us from saving datasets, but it shows many
    limitations when the datasets are large, even with an extension built for large
    files (Git LFS). Thus, MLflow is commonly combined with DVC, an open source version
    control system that solves Git limitations.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您可能已经注意到的那样，W&B 和 MLflow 之间存在一些相似之处。然而，在 MLflow 的情况下，每个实验都与一组 Git 提交关联。Git
    并不会阻止我们保存数据集，但是在数据集较大时会显示出许多限制，即使使用了专为大文件构建的扩展（Git LFS）。因此，MLflow 通常与 DVC 结合使用，DVC
    是一个解决 Git 限制的开源版本控制系统。
- en: Setting up MLflow
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置 MLflow
- en: 'MLflow can be installed using `pip`:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用 `pip` 安装 MLflow：
- en: '[PRE8]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Similar to W&B, MLflow also provides a Python API that allows you to track
    hyperparameters (`log_param`), evaluation metrics (`log_metric`), and artifacts
    (`log_artifacts`):'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于 W&B，MLflow 还提供了一个 Python API，允许您跟踪超参数（`log_param`）、评估指标（`log_metric`）和工件（`log_artifacts`）：
- en: '[PRE9]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The experiment definition can be initialized and tagged with the following
    code:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 实验定义可以通过以下代码初始化并标记：
- en: '[PRE10]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'MLflow has provided a set of tutorials that introduce its APIs: [https://www.mlflow.org/docs/latest/tutorials-and-examples/tutorial.html](https://www.mlflow.org/docs/latest/tutorials-and-examples/tutorial.html).'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: MLflow 提供了一系列教程，介绍了其 API：[https://www.mlflow.org/docs/latest/tutorials-and-examples/tutorial.html](https://www.mlflow.org/docs/latest/tutorials-and-examples/tutorial.html)。
- en: Now that you are familiar with the basic usage of MLflow, we will describe how
    it can be integrated for Keras and PL projects.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经熟悉了 MLflow 的基本用法，我们将描述如何将其集成到 Keras 和 PL 项目中。
- en: Integrating MLflow into a Keras project
  id: totrans-127
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将 MLflow 集成到 Keras 项目中
- en: 'First, let’s take a look at Keras integration. Logging the details of a Keras
    model using MLflow can be achieved through the `log_model` function:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们看一下 Keras 的集成。通过 `log_model` 函数可以记录 Keras 模型的详细信息：
- en: '[PRE11]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The `mlflow.keras` and `mlflow.tensorflow` modules provide a set of APIs for
    logging various information about Keras and TensorFlow models, respectively. For
    additional details, please look at [https://www.mlflow.org/docs/latest/python_api/index.html](https://www.mlflow.org/docs/latest/python_api/index.html).
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '`mlflow.keras` 和 `mlflow.tensorflow` 模块提供了一组 API，用于记录关于 Keras 和 TensorFlow
    模型的各种信息。有关更多详细信息，请查看 [https://www.mlflow.org/docs/latest/python_api/index.html](https://www.mlflow.org/docs/latest/python_api/index.html)。'
- en: Integrating MLflow into a PyTorch Lightning project
  id: totrans-131
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将 MLflow 集成到 PyTorch Lightning 项目中
- en: 'Similar to how W&B supports PL projects, MLflow also provides an `MLFlowLogger`
    class. This can be passed to a `Trainer` instance for logging the model details
    in MLflow:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于 W&B 支持 PL 项目的方式，MLflow 也提供了一个 `MLFlowLogger` 类。这可以传递给 `Trainer` 实例，用于在 MLflow
    中记录模型详细信息：
- en: '[PRE12]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: In the preceding code, we have passed an instance of `MLFlowLogger` to replace
    the default logger of PL. The `tracking_uri` argument controls where the logged
    data goes.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述代码中，我们传递了一个 `MLFlowLogger` 实例来替换 PL 的默认记录器。`tracking_uri` 参数控制记录的数据去向。
- en: 'Other details about PyTorch integration can be found on the official website:
    [https://pytorch-lightning.readthedocs.io/en/stable/api/pytorch_lightning.loggers.mlflow.html](https://pytorch-lightning.readthedocs.io/en/stable/api/pytorch_lightning.loggers.mlflow.html).'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 关于 PyTorch 集成的其他详细信息可以在官方网站找到：[https://pytorch-lightning.readthedocs.io/en/stable/api/pytorch_lightning.loggers.mlflow.html](https://pytorch-lightning.readthedocs.io/en/stable/api/pytorch_lightning.loggers.mlflow.html)。
- en: Setting up MLflow with DVC
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 DVC 设置 MLflow
- en: 'To use DVC to manage large datasets, you need to install it using a package
    manager such as `pip`, `conda`, or `brew` (for macOS users):'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 DVC 管理大型数据集，需要使用诸如 `pip`、`conda` 或 `brew`（适用于 macOS 用户）之类的包管理器安装它：
- en: '[PRE13]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: All the installation options can be found at [https://dvc.org/doc/install](https://dvc.org/doc/install/).
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 所有的安装选项可以在 [https://dvc.org/doc/install](https://dvc.org/doc/install/) 找到。
- en: 'Managing datasets using DVC requires a set of commands to be executed in a
    specific order:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 DVC 管理数据集需要按特定顺序执行一组命令：
- en: 'The first step is to set up a Git repository with DVC:'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一步是使用 DVC 设置一个 Git 仓库：
- en: '[PRE14]'
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Now, we need to configure the remote storage for DVC:'
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们需要配置 DVC 的远程存储：
- en: '[PRE15]'
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Let’s create a sample data directory and fill it with some sample data:'
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们创建一个样本数据目录，并填充一些示例数据：
- en: '[PRE16]'
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'At this stage, we are ready to start tracking the dataset. We just need to
    add our file to DVC. This operation will create an additional file, `example_data.csv.dvc`.
    In addition, the `example_data.csv` file gets added to `.gitignore` automatically
    so that Git no longer tracks the original file:'
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这个阶段，我们已经准备好开始跟踪数据集了。我们只需要将文件添加到 DVC 中。此操作将创建一个额外的文件 `example_data.csv.dvc`。此外，`example_data.csv`
    文件会自动添加到 `.gitignore` 中，使得 Git 不再跟踪原始文件：
- en: '[PRE17]'
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Next, you need to commit and upload the `example_data.csv.dvc` and `.gitignore`
    files. We will tag our first dataset as `v1`:'
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，您需要提交并上传 `example_data.csv.dvc` 和 `.gitignore` 文件。我们将我们的第一个数据集标记为 `v1`：
- en: '[PRE18]'
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'After using the `dvc push` command, our data will be available on remote storage.
    This means we can remove the local version. To restore `example_data.csv`, you
    can simply call `dvc pull`:'
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `dvc push` 命令后，我们的数据将在远程存储中可用。这意味着我们可以删除本地版本。要恢复 `example_data.csv`，只需简单地调用
    `dvc pull`：
- en: '[PRE19]'
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'When `example_data.csv` is modified, we need to add and push again to update
    the version on remote storage. We will tag the modified dataset as `v2`:'
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当修改 `example_data.csv` 后，我们需要再次添加并推送以更新远程存储中的版本。我们将修改后的数据集标记为 `v2`：
- en: '[PRE20]'
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'After executing these commands, you will have two versions of the same dataset
    being tracked by Git and DVC: `v1` and `v2`.'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 执行这些命令后，您将通过Git和DVC跟踪同一数据集的两个版本：`v1`和`v2`。
- en: 'Next, let’s look at how MLflow can be combined with DVC:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们看看如何将MLflow与DVC结合使用：
- en: '[PRE21]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: In the preceding code snippet, `mlflow.log_artifact` was used to save information
    about specific columns for the experiment.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码片段中，使用了`mlflow.log_artifact`来保存有关实验特定列的信息。
- en: 'Overall, we can run multiple experiments through MLflow with different versions
    of the dataset tracked by DVC. Similar to W&B, MLflow also provides a web page
    where we can compare our experiments. All you need is to type the following command
    in the terminal:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，我们可以通过MLflow运行多个实验，使用DVC跟踪不同版本的数据集。与W&B类似，MLflow还提供一个网页，我们可以在其中比较我们的实验。您只需在终端中输入以下命令即可：
- en: '[PRE22]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'This command will start a web server hosting a web page on [http://127.0.0.1:5000](http://127.0.0.1:5000).
    The following screenshot shows the MLflow dashboard:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 这个命令将启动一个托管在[http://127.0.0.1:5000](http://127.0.0.1:5000)上的Web服务器，以下屏幕截图显示了MLflow仪表板：
- en: '![Figure 4.3 – The MLflow dashboard; new runs will be populated at the bottom
    of the page'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.3 – MLflow 仪表板；新运行将显示在页面底部'
- en: '](img/B18522_04_03.jpg)'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.3 – MLflow 仪表板；新运行将显示在页面底部'
- en: Figure 4.3 – The MLflow dashboard; new runs will be populated at the bottom
    of the page
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.3 – MLflow 仪表板；新运行将显示在页面底部
- en: Things to remember
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 记住的事情
- en: a. MLflow can track dependencies, model parameters, metrics, and artifacts.
    It is often combined with DVC for efficient dataset versioning.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: a. MLflow可以跟踪依赖关系、模型参数、指标和工件。通常与DVC结合使用，以实现高效的数据集版本控制。
- en: b. MLflow can easily be integrated with DL frameworks, including Keras, TensorFlow,
    and PyTorch.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: b. MLflow可以轻松集成到包括Keras、TensorFlow和PyTorch在内的DL框架中。
- en: c. MLflow provides an interactive visualization where multiple experiments can
    be analyzed at the same time.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: c. MLflow提供交互式可视化，可以同时分析多个实验。
- en: So far, we have learned how to manage DL projects in W&B and MLflow and DVC.
    In the next section, we will introduce popular tools for dataset versioning.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经学习了如何在W&B、MLflow和DVC中管理DL项目。在下一节中，我们将介绍用于数据集版本控制的流行工具。
- en: Dataset versioning – beyond Weights & Biases, MLflow, and DVC
  id: totrans-170
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据集版本控制 – 超越Weights & Biases、MLflow和DVC
- en: Throughout this chapter, we have seen how datasets can be managed by DL project-tracking
    tools. In the case of W&B, we can use artifacts, while in the case of MLflow and
    DVC, DVC runs on top of a Git repository to track different versions of datasets,
    thereby solving the limitations of Git.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们看到了如何通过DL项目跟踪工具管理数据集。在W&B的情况下，我们可以使用工件，而在MLflow和DVC的情况下，DVC运行在Git存储库之上，以跟踪数据集的不同版本，从而解决了Git的限制。
- en: 'Are there any other methods and/or tools that are useful for dataset versioning?
    The simple answer is yes, but again, the more precise answer depends on the context.
    To make the right choice, you must consider various aspects including cost, ease
    of use, and integration difficulty. In this section, we will mention a few tools
    that we believe are worth exploring if dataset versioning is one of the critical
    components of your project:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 是否还有其他对数据集版本控制有用的方法和/或工具？简单的答案是肯定的，但更精确的答案取决于具体的情况。为了做出正确的选择，您必须考虑多个方面，包括成本、易用性和集成难度。在本节中，我们将提及一些我们认为值得探索的工具，如果数据集版本控制是项目的关键组成部分：
- en: '**Neptune** ([https://docs.neptune.ai](https://docs.neptune.ai/)) is a metadata
    store for MLOps. Neptune artifacts allow versioning to be conducted on datasets
    that are stored locally or in cloud.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Neptune** ([https://docs.neptune.ai](https://docs.neptune.ai/)) 是一个用于MLOps的元数据存储。Neptune工件允许在本地或云中存储的数据集上进行版本控制。'
- en: '**Delta Lake** ([https://delta.io](https://delta.io/)) is an open source storage
    abstraction that runs on top of a data lake. Delta Lake works with Apache Spark
    APIs and uses distributed processing to improve throughput and efficiency.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Delta Lake** ([https://delta.io](https://delta.io/)) 是一个在数据湖顶层运行的开源存储抽象。Delta
    Lake与Apache Spark API配合使用，并使用分布式处理来提高吞吐量和效率。'
- en: Things to remember
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 记住的事情
- en: a. There are many data versioning tools on the market. To select the right tool,
    you must consider various aspects including cost, ease of use, and integration
    difficulty.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: a. 市场上有许多数据版本控制工具。要选择合适的工具，您必须考虑多个方面，包括成本、易用性和集成难度。
- en: b. Tools such as W&B, MLflow, DVC, Neptune, and Delta Lake can help you with
    dataset versioning.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: b. 诸如W&B、MLflow、DVC、Neptune和Delta Lake的工具可以帮助您进行数据集版本控制。
- en: With that, we have introduced popular tools for dataset versioning. The right
    tool differs project by project. Therefore, you must evaluate the pros and cons
    of each tool before integrating one into your project.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 至此，我们介绍了数据集版本控制的流行工具。适合的工具因项目而异。因此，在将任何工具集成到您的项目之前，您必须评估每个工具的利弊。
- en: Summary
  id: totrans-179
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: 'Since DL projects involve many iterations of training models and evaluation,
    efficiently managing experiments, models, and datasets can help the team reach
    its goal faster. In this chapter, we looked at the two most popular settings for
    DL project tracking: W&B and MLflow integrated with DVC. Both settings provide
    built-in support for Keras and PL, which are the two most popular DL frameworks.
    We have also spent some time describing tools that put more emphasis on dataset
    versioning: Neptune and Delta Lake. Please keep in mind that you must evaluate
    each tool thoroughly to select the right tool for your project.'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 由于深度学习项目涉及多次模型训练和评估迭代，有效管理实验、模型和数据集可以帮助团队更快地实现目标。在本章中，我们探讨了两种最流行的深度学习项目跟踪设置：W&B
    和与DVC集成的MLflow。这两种设置都内置支持Keras和PyTorch，这两个最流行的深度学习框架。我们还花了一些时间描述了更加强调数据集版本控制的工具：Neptune
    和 Delta Lake。请记住，您必须仔细评估每个工具，以选择适合您项目的正确工具。
- en: At this point, you are familiar with the frameworks and processes for building
    a proof of concept and training the necessary DL model. Starting from the next
    chapter, we will discuss how to scale up by moving individual components of the
    DL pipeline to the cloud.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 目前为止，您已经熟悉了构建概念验证和训练必要深度学习模型的框架和流程。从下一章开始，我们将讨论如何通过将深度学习管道的各个组件移至云端来实现规模化。
