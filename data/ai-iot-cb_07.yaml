- en: NLP and Bots for Self-Ordering Kiosks
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: 自然语言处理和自助订购亭的机器人
- en: Language understanding has improved dramatically over the past few years. New
    algorithms and hardware have come out that have dramatically changed the effectiveness
    of the feasibility of voice-activated systems. In addition, the ability for computers
    to accurately sound like a human has achieved near perfection. Another area where
    machine learning has made large strides in the past few years is **natural language
    processing** (**NLP**), or as some would call it, language understanding.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，语言理解已经取得了显著进展。新算法和硬件大大提高了语音激活系统的有效性和可行性。此外，计算机准确地模仿人类的能力已经接近完美。机器学习在近年来取得了重大进展的另一个领域是自然语言处理（**NLP**），或者有些人称之为语言理解。
- en: When you combine computer voice with language understanding, then new markets
    open up for voice-activated technologies such as smart kiosks and smart devices.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 将计算机语音与语言理解结合，就会为智能亭和智能设备等语音激活技术打开新的市场。
- en: 'We will cover the following recipes in this chapter:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍以下几个示例：
- en: Wake word detection
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 唤醒词检测
- en: Speech-to-text using Microsoft Speech API
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Microsoft Speech API 进行语音转文本
- en: Getting started with LUIS
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开始使用 LUIS
- en: Implementing smart bots
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实施智能机器人
- en: Creating a custom voice
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建自定义语音
- en: Enhancing bots with QnA Maker
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 QnA Maker 提升机器人功能
- en: Wake word detection
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 唤醒词检测
- en: Wake word detection is used to make sure that your voice-activated system does
    not behave in unexpected ways. Achieving high accuracy rates for audio is challenging.
    Background noises interfere with the main vocal commands. One way to achieve higher
    accuracy is to use an array microphone. Array microphones are used for background
    noise canceling. In this recipe, we are using the ROOBO array microphone and the
    Microsoft Speech Devices SDK. The ROOBO array microphone is ideal for voice kiosks
    because its form factor allows it to be put flat on a kiosk face.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 唤醒词检测用于确保您的语音激活系统不会出现意外行为。实现高准确率的音频是具有挑战性的。背景噪音会干扰主要的语音命令。实现更高准确率的一种方法是使用阵列麦克风。阵列麦克风用于消除背景噪音。在此示例中，我们使用
    ROOBO 阵列麦克风和 Microsoft Speech Devices SDK。ROOBO 阵列麦克风非常适合语音亭，因为其形状使其可以平放在亭面上。
- en: 'The ROOBO has an Android-based compute module attached to it. Android is a
    very common platform for kiosks because it is inexpensive and has a touch-first
    interface. For this recipe, we will be using the Android version of the Microsoft
    Speech Devices SDK. The Speech Devices SDK is different from the Speech SDK. The
    Speech Devices SDK will work with both array and circular microphones, while the
    Speech SDK is for using a single microphone. The following is a photo of a ROOBO
    array microphone:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: ROOBO 配备了一个基于 Android 的计算模块。Android 是亭子的常见平台，因为它价格低廉，并且具有触摸优先界面。在这个示例中，我们将使用
    Microsoft Speech Devices SDK 的 Android 版本。Speech Devices SDK 与 Speech SDK 不同。Speech
    Devices SDK 可以同时使用阵列和圆形麦克风，而 Speech SDK 则用于单麦克风使用。以下是 ROOBO 阵列麦克风的照片：
- en: '![](img/1e7f6646-cb71-49c5-9f6c-178901796d01.jpg)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1e7f6646-cb71-49c5-9f6c-178901796d01.jpg)'
- en: Getting ready
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'For this recipe, you are going to need an Azure subscription and a ROOBO linear
    array or circular microphone. On your PC, you will also need to download and install
    Android Studio and **Vysor** for working with the ROOBO. To set up the device,
    take the following steps:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个示例，您将需要一个 Azure 订阅和 ROOBO 线性阵列或圆形麦克风。在您的个人电脑上，您还需要下载并安装 Android Studio 和
    **Vysor**，以便与 ROOBO 一起使用。要设置设备，请执行以下步骤：
- en: Download and install Android Studio.
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载并安装 Android Studio。
- en: Download and install Vysor.
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载并安装 Vysor。
- en: 'Power on the device and connect it to your computer. There are two USB connectors:
    one labeled power and one labeled debug. Connect the power connector to a power
    source and the debug USB cable to your computer:'
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开设备并将其连接到您的计算机。有两个 USB 连接器：一个标有电源，一个标有调试。将电源连接器连接到电源源，将调试 USB 电缆连接到您的计算机：
- en: '![](img/99522e34-a31e-471c-ac73-b91daf52dff0.jpg)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](img/99522e34-a31e-471c-ac73-b91daf52dff0.jpg)'
- en: 'Open Vysor and select the device to view:'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开 Vysor 并选择要查看的设备：
- en: '![](img/8722eb4f-e4dc-4db9-97b1-b7eb554c466f.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8722eb4f-e4dc-4db9-97b1-b7eb554c466f.png)'
- en: 'Click on Settings:'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击设置：
- en: '![](img/962c9594-1e42-4f0f-abbf-7d4733f956d5.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](img/962c9594-1e42-4f0f-abbf-7d4733f956d5.png)'
- en: 'Now that we have completed the device setup, let us generate a wake word. To
    generate a wake word, take the following steps:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经完成了设备设置，让我们生成一个唤醒词。要生成唤醒词，请执行以下步骤：
- en: 'Go to [https://speech.microsoft.com/](https://speech.microsoft.com/) and click
    on Get started:'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 前往[https://speech.microsoft.com/](https://speech.microsoft.com/)，然后点击“开始使用”：
- en: '![](img/7f0b4907-85b7-4156-9655-c53f2c05265b.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7f0b4907-85b7-4156-9655-c53f2c05265b.png)'
- en: 'Select **New Project** and fill out the custom speech form, and then click
    **Create**:'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择**新项目**并填写自定义语音表单，然后点击**创建**：
- en: '![](img/59ebca06-8686-4233-9ac9-70b6db84ea5c.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](img/59ebca06-8686-4233-9ac9-70b6db84ea5c.png)'
- en: Click on Create Model.
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击“创建模型”。
- en: 'Fill in the form with the wake word you wish to train. Then, click Next:'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 填写希望训练的唤醒词表单。然后，点击“下一步”：
- en: '![](img/24bbf39f-8a67-45da-9a05-6e73371365d2.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](img/24bbf39f-8a67-45da-9a05-6e73371365d2.png)'
- en: 'Listen to and approve the pronunciations, then click Train:'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 听取并批准发音，然后点击“训练”：
- en: '![](img/32e05dea-e84e-456f-9f9b-6a242f3e6491.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](img/32e05dea-e84e-456f-9f9b-6a242f3e6491.png)'
- en: The model will take 20 minutes to train. When it is done, click Download.
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型将花费20分钟进行训练。完成后，点击下载。
- en: How to do it...
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实现…
- en: 'The steps for this recipe are as follows:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 此食谱的步骤如下：
- en: 'In Android Studio, create a new project using Java:'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Android Studio中，使用Java创建一个新项目：
- en: '![](img/870b985f-823b-424f-ba8b-007192b6c9a4.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](img/870b985f-823b-424f-ba8b-007192b6c9a4.png)'
- en: 'In the Gradle scripts section, change the `Gradle Voice Projects` folder and
    add the reference to the library:'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Gradle脚本部分，更改`Gradle Voice Projects`文件夹并添加对库的引用：
- en: '[PRE0]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'In the Gradle scripts section, in the Gradle build app section, add this line
    to the dependencies section:'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Gradle脚本部分，在Gradle构建应用程序部分，将此行添加到依赖项部分：
- en: '[PRE1]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Import the libraries needed for this project:'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入此项目所需的库：
- en: '[PRE2]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'In the main activity class, add the keys and location of the trained model.
    Also, add the microphone type; in this case, we are using a linear microphone:'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在主活动类中，添加训练模型的键和位置。此外，添加麦克风类型；在本例中，我们使用的是线性麦克风：
- en: '[PRE3]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Create the method that will display the result to the UI:'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建将结果显示到UI的方法：
- en: '[PRE4]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Set audio input by using the default microphone:'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用默认麦克风设置音频输入：
- en: '[PRE5]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Set the task listener for the on-complete event:'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置完成事件的任务监听器：
- en: '[PRE6]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Configure the speech settings, such as device geometry, speech region, and
    language:'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 配置语音设置，如设备几何形状、语音区域和语言：
- en: '[PRE7]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Set an on-complete task listener:'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置一个完成任务监听器：
- en: '[PRE8]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Set on-click buttons and a keyword listener:'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置点击按钮和关键字监听器：
- en: '[PRE9]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: How it works...
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理…
- en: The Microsoft Speech Devices SDK is designed to work with linear and circular
    microphone arrays. In this recipe, we created an Android application to give the
    user a UI associated with the voice. Android's touch-first interface is a common
    form factor for kiosks. We also created a wake word file in Azure's Speech Studio.
    We then retrieved the keys from our service.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: Microsoft Speech Devices SDK设计用于与线性和圆形麦克风阵列配合使用。在本篇食谱中，我们创建了一个Android应用程序，为用户提供与语音相关的用户界面。Android的触摸优先界面是亭子的常见形态因素。我们还在Azure的Speech
    Studio中创建了一个唤醒词文件。然后，我们从我们的服务中检索到了密钥。
- en: There's more...
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 更多信息…
- en: The Speech Devices SDK does more than create a wake word. It does speech recognition,
    language understanding, and translation. If your kiosk is going to be put in a
    place with background noise that could interfere with the main subject of your
    voice recognition, then an array microphone will be your best option.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: Speech Devices SDK不仅仅是创建唤醒词。它还包括语音识别、语言理解和翻译功能。如果您的亭子将被放置在可能会干扰语音识别主体的背景噪音环境中，那么阵列麦克风将是您最佳的选择。
- en: At the beginning of this recipe, we mentioned that the Speech Devices SDK also
    supports circular microphones. While array microphones are designed to point directly
    at the person talking, circular microphones are designed to be put perpendicular
    to the people talking. They can help determine the direction of the person speaking
    and are often used in a multi-speaker scenario, such as diarization.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在本篇食谱的开头，我们提到Speech Devices SDK也支持圆形麦克风。虽然阵列麦克风设计用于直接对准说话者，但圆形麦克风设计为垂直放置于说话人旁边。它们有助于确定说话人的方向，并且常用于多人说话情境，如日程安排。
- en: Speech-to-text using the Microsoft Speech API
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Microsoft Speech API进行语音识别：
- en: Microsoft Speech Services is an ecosystem of speech-to-text, text-to-speech,
    and translation features, among others. It supports multiple languages and has
    advanced features such as customizing the speech recognition to support accents,
    proper names (such as product names), background noise, and microphone quality.
    In this recipe, we will implement the Microsoft Speech SDK using Python.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: Microsoft Speech Services是一个语音转文本、文本转语音和翻译等功能的生态系统。它支持多种语言，并具有高级功能，如自定义语音识别以支持口音、专有名称（如产品名称）、背景噪音和麦克风质量。在本示例中，我们将使用Python实现Microsoft
    Speech SDK。
- en: Getting ready
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备就绪
- en: First, you will need to go into the Azure portal and create a speech service.
    You will then go to the Quick start section and copy down the key.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，您需要进入Azure门户并创建一个语音服务。然后，转到快速入门部分并复制下密钥。
- en: 'Then, install the Azure Speech SDK:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，安装Azure Speech SDK：
- en: '[PRE10]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: How to do it...
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实现...
- en: 'The steps for this recipe are as follows:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 本示例的步骤如下：
- en: 'Import the libraries:'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入库：
- en: '[PRE11]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Import the key that was generated in the *Getting ready* section:'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入在*准备就绪*部分生成的密钥：
- en: '[PRE12]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Initialize the speech service:'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化语音服务：
- en: '[PRE13]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Then, perform continuous speech recognition by using an infinite loop:'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，通过使用无限循环执行连续语音识别：
- en: '[PRE14]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Finally, clean up and disconnect the session:'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，清理并断开会话：
- en: '[PRE15]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: How it works...
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理...
- en: Cognitive Services takes individual words and uses machine learning to piece
    them together into meaningful sentences. The SDK takes care of finding the microphone,
    sending the audio to Cognitive Services, and returning the results.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 认知服务将单个词汇使用机器学习组合成有意义的句子。SDK负责找到麦克风，将音频发送到认知服务，并返回结果。
- en: In the next recipe, we are going to use language understanding to determine
    the meaning of the speech. After that, we are going to make a smart bot using
    Bot Framework, which builds upon the language understanding to give state and
    logic to the ordering kiosk. You can use speech as an input to that system.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个示例中，我们将使用语言理解来确定语音的含义。之后，我们将使用Bot Framework创建一个智能机器人，该框架建立在语言理解的基础上，为点餐自助服务点提供状态和逻辑。您可以将语音作为该系统的输入。
- en: The Microsoft Speech SDK allows you to account for accents, pronunciations,
    and sound quality through its custom speech service. You can also use Docker containers
    for environments with limited connectivity to the internet.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: Microsoft Speech SDK允许您通过其自定义语音服务考虑口音、发音和声音质量。您还可以在连接性受限的环境中使用Docker容器。
- en: Getting started with LUIS
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开始使用LUIS
- en: '**Language Understanding**, or **LUIS**, from Microsoft, is a service that
    takes text and extracts out of the text the entities, the things the sentence
    was about, the intents, and the actions of a sentence. Because having a narrow-focused
    domain helps reduce the error rate, the LUIS authorizing service helps users to
    create a pre-defined list of entities and intents for LUIS to parse.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '**语言理解**，或**LUIS**，来自Microsoft，是一项服务，它从文本中提取实体、句子所涉及的主题、意图和句子的动作。由于有一个狭窄的专注领域可以帮助减少错误率，LUIS授权服务帮助用户创建LUIS解析的预定义实体和意图列表。'
- en: Getting ready
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备就绪
- en: LUIS is a product of Azure's Cognitive Services. You will need to log in to
    the Azure portal and create a LUIS resource. Then, go to [https://preview.luis.ai](https://preview.luis.ai)
    and click on New App for Conversation. Then, fill out the form for the name, language,
    and prediction resource you set up.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: LUIS是Azure认知服务的一款产品。您需要登录Azure门户并创建LUIS资源。然后，转到[https://preview.luis.ai](https://preview.luis.ai)，点击新建用于对话的应用程序。然后，填写名称、语言和您设置的预测资源的表单。
- en: 'Then, click on Entities in the side menu and add, as in our restaurant ordering
    kiosk, `Cheese burger`, `French Fries`, `Diet Pepsi`, `Milk Shake`, `Chocolate`,
    `Vanilla`, and so on:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在侧边菜单中点击实体，并添加，如我们的餐厅点餐自助服务点的`奶酪汉堡`，`薯条`，`健怡可乐`，`奶昔`，`巧克力`，`香草`等等：
- en: '![](img/493f15ee-e9f7-46c2-8cbf-0b2ff081c5e7.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](img/493f15ee-e9f7-46c2-8cbf-0b2ff081c5e7.png)'
- en: 'Once you have enough entities added, you will need to add intents. Click on
    the intents, then add an intent. In our recipe, we are going to add a `Menu.Add
    item` intent. Then, we add some example sentences of how someone would order at
    a kiosk. We then click on the entities in the sentences and tag them:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您添加了足够的实体，您将需要添加意图。点击意图，然后添加一个意图。在我们的示例中，我们将添加一个`Menu.Add item`意图。然后，我们添加一些例句来展示某人如何在一个自助服务点点餐。然后，我们点击句子中的实体并对其进行标记：
- en: '![](img/8b69a802-ca77-4185-b4eb-80f0c138fc4f.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8b69a802-ca77-4185-b4eb-80f0c138fc4f.png)'
- en: When there is enough to represent the entire menu, click on the Train button
    at the upper right of the window. After it has completed training, click on the
    Publish button. After the publishing is completed, a notification will appear
    on the screen giving you the keys, endpoints, and a sample query you can put in
    your browser's URL bar to get a prediction.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 当有足够的内容来代表整个菜单时，点击窗口右上角的“训练”按钮。训练完成后，点击“发布”按钮。发布完成后，屏幕上将出现通知，提供密钥、端点和一个样本查询，您可以将其放入浏览器的
    URL 栏以获取预测。
- en: Then, create a new intent for other actions someone would take in an ordering
    kiosk, such as removing items from an order or changing orders. Copy that query
    string because we are going to use it later.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，为在点餐亭中采取的其他操作创建一个新的意图，例如从订单中删除项目或更改订单。复制该查询字符串，因为我们将稍后使用它。
- en: How to do it...
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'The steps for this recipe are as follows:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 此教程的步骤如下：
- en: 'Import the `requests` library to allow us to use a web service:'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`requests`库以允许我们使用 web 服务：
- en: '[PRE16]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Enter your order text:'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入您的订单文本：
- en: '[PRE17]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Send a message to LUIS:'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 发送消息给 LUIS：
- en: '[PRE18]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Get the intents and entities from the response:'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从响应中获取意图和实体：
- en: '[PRE19]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: How it works...
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理...
- en: LUIS is a system that breaks down sentences and extracts their objects (entities)
    and actions (intents). In our recipe, we created a set of entities and intents.
    LUIS is able to extract these entities and intents from sentences even if they
    are similar to the sample phrases we typed in but not exactly the same. For example,
    the phrase *A vanilla shake would be lovely* is not something that we trained
    our model on and yet LUIS is still able to understand that this is an order for
    a vanilla milkshake.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: LUIS 是一个能够分解句子并提取其对象（实体）和动作（意图）的系统。在我们的教程中，我们创建了一组实体和意图。即使句子与我们键入的示例短语相似但并非完全相同，LUIS
    也能够从中提取这些实体和意图。例如，短语*一杯香草奶昔将是可爱的*并不是我们模型训练的内容，但是 LUIS 仍然能够理解这是一个香草奶昔的订单。
- en: There's more...
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多内容...
- en: Sending text to LUIS and getting a JSON payload back is the tip of the iceberg
    for LUIS. LUIS is integrated with the Microsoft Speech SDK, meaning you can get
    entities and intents from using a microphone. You can use on-board speech recognition
    with devices such as smartphones and send just the text to LUIS. As is our *Wake
    word detection* recipe, you can use an array microphone to filter background noise
    or understand the directionality of the sound and have that integrated with LUIS.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 向 LUIS 发送文本并获取 JSON 负载仅仅是 LUIS 的冰山一角。LUIS 与 Microsoft Speech SDK 集成，这意味着您可以使用麦克风从中获取实体和意图。您可以在设备如智能手机上使用内置语音识别，并将文本发送至
    LUIS。就像我们的*唤醒词检测*教程一样，您可以使用阵列麦克风来过滤背景噪音或理解声音的方向性，并将其集成到 LUIS 中。
- en: Implementing smart bots
  id: totrans-110
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实施智能机器人
- en: In this recipe, we are going to use Microsoft Bot Framework to create smart
    bots. Smart bots implement a conversation between the user and the bot. These
    conversations trigger a series of actions. Bots keep track of the conversation
    state so that it knows where it is in the conversation. Bots also keep track of
    the user state, or to be more precise, they keep track of the variables the user
    has inputted.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个教程中，我们将使用 Microsoft Bot Framework 创建智能机器人。智能机器人实现用户与机器人之间的对话。这些对话触发一系列操作。机器人跟踪对话状态，以便知道它在对话中的位置。机器人还跟踪用户状态，更确切地说，它跟踪用户输入的变量。
- en: Bots have been used to input complex forms such as legal forms or financial
    documents. For our self-ordering kiosk scenario, we will be implementing a simple
    bot that allows someone to add food to their order. We will build upon the LUIS
    model we implemented in the previous recipe.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 机器人已被用于输入复杂表单，如法律文件或财务文件。对于我们的自助点餐亭场景，我们将实施一个简单的机器人，允许用户添加食物到他们的订单中。我们将在前一个教程中实现的
    LUIS 模型基础上进行构建。
- en: Getting ready
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: To test bots locally, you will need to download and install the Bot Framework
    Emulator from Microsoft. Installation instructions and links to documentation
    can be found on the GitHub page at [https://github.com/microsoft/BotFramework-Emulator](https://github.com/microsoft/BotFramework-Emulator).
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 要在本地测试机器人，您需要从 Microsoft 下载并安装 Bot Framework Emulator。安装说明和文档链接可以在 GitHub 页面[https://github.com/microsoft/BotFramework-Emulator](https://github.com/microsoft/BotFramework-Emulator)找到。
- en: 'Next, you will need to install the dependencies. For this project, we are using
    Python and we have a requirements file. To install the requirements, clone the
    GitHub repo for this book and navigate to the `Ch7/SmartBot` folder. Then, enter
    the following `pip install` script:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，您需要安装依赖项。对于此项目，我们使用Python，并且有一个要求文件。要安装这些要求，请克隆本书的 GitHub 存储库并导航到 `Ch7/SmartBot`
    文件夹。然后，输入以下 `pip install` 脚本：
- en: '[PRE20]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: This will install the Bot Framework components in addition to Flask, the web
    server platform that our bot will use, and `async.io`, an asynchronous library.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 这将安装 Bot Framework 组件以及 Flask（我们的机器人将使用的 Web 服务器平台）和 `async.io`（一个异步库）。
- en: How to do it...
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'The steps for this recipe are as follows:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 此处的步骤如下：
- en: 'Create an `app.py` file and import the libraries:'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个 `app.py` 文件并导入所需的库：
- en: '[PRE21]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Initialize the Flask web server:'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化 Flask Web 服务器：
- en: '[PRE22]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Initialize the event loop:'
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化事件循环：
- en: '[PRE23]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Initialize the bot memory and conversation state as well as the user state:'
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化机器人的记忆和对话状态以及用户状态：
- en: '[PRE24]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Set the URL routing:'
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置URL路由：
- en: '[PRE25]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Loop through the LUIS and Bot Framework logic:'
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 循环执行 LUIS 和 Bot Framework 逻辑：
- en: '[PRE26]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Create a `luisbot.py` file and in the `luisbot.py` file, import the libraries:'
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个 `luisbot.py` 文件，并在 `luisbot.py` 文件中导入所需的库：
- en: '[PRE27]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Create an `Order` data store. This will serve as a place to hold our information:'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个 `Order` 数据存储。这将作为保存信息的地方：
- en: '[PRE28]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Add a conversation state data class. This will hold the conversation state:'
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加一个对话状态数据类。这将保存对话状态：
- en: '[PRE29]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Create a `LuisBot` class and initialize the variables:'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个 `LuisBot` 类并初始化变量：
- en: '[PRE30]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'On each turn, record the current state:'
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在每次轮询中记录当前状态：
- en: '[PRE31]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Set `on_message_activity` to get the state and entities from LUIS:'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置 `on_message_activity` 来从 LUIS 获取状态和实体：
- en: '[PRE32]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Define the step logic. This will be the set of steps we need to take to complete
    an order:'
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义步骤逻辑。这将是我们完成订单所需的一组步骤：
- en: '[PRE33]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: How it works...
  id: totrans-146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理...
- en: Bot Framework is a bot building framework developed by Microsoft. It consists
    of activities and states. There are many different types of activities, such as
    messaging, events, and end of the conversation. For keeping track of the state,
    there are two variables, which are `UserState` and `ConversationState`. The user
    state captures information the user inputted. In our example, this is the food
    order. The conversation state allows the bot to ask questions in sequential order.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: Bot Framework 是由 Microsoft 开发的一个机器人构建框架。它包括活动和状态。有许多不同类型的活动，例如消息、事件和对话结束。为了跟踪状态，有两个变量，即
    `UserState` 和 `ConversationState`。用户状态用于记录用户输入的信息。在我们的示例中，这是食品订单。对话状态允许机器人按顺序询问问题。
- en: There's more...
  id: totrans-148
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: Bot Framework keeps track of the conversation state and user data but that is
    not limited to one conversation. You can, for example, use LUIS to determine that
    the intent may be of a different conversation. In our ordering scenario, you can
    allow users to start ordering and then allow them to ask for nutritional information
    or the current cost of their order. In addition, you can add text-to-speech to
    add a voice output for the kiosk.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: Bot Framework 跟踪对话状态和用户数据，但不限于一个对话。例如，您可以使用 LUIS 确定意图可能属于不同的对话。在我们的订购场景中，您可以允许用户开始订购，然后允许他们询问营养信息或订单的当前成本。此外，您还可以添加文本转语音以为自助售货亭添加语音输出。
- en: Creating a custom voice
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建自定义语音
- en: The state of voice technology has come a long way in recent years. A few years
    ago, synthetic voices were easy to recognize. They all had the same voice font,
    had a robotic sound, and were monotone, so they had trouble expressing emotion.
    Today, we can create custom voice fonts and add emphasis, speed, and sentiment
    to them. In this recipe, we will go over creating a custom voice font from your
    voice or some actor's voice.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，语音技术已经取得了长足的进步。几年前，合成语音很容易识别。它们都具有相同的语音字体，具有机器人的声音，是单调的，因此难以表达情感。如今，我们可以创建自定义语音字体，并为它们添加强调、速度和情感。在本文中，我们将介绍如何从您的声音或某位演员的声音创建自定义语音字体。
- en: Getting ready
  id: totrans-152
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'To create a custom voice font, we are going to use Microsoft''s Custom Voice
    service. To get started, go to [https://speech.microsoft.com/portal](https://speech.microsoft.com/portal)
    and click on Custom Voice. When on the Custom Voice page, click on New project:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建自定义语音字体，我们将使用 Microsoft 的自定义语音服务。要开始，请访问 [https://speech.microsoft.com/portal](https://speech.microsoft.com/portal)
    并单击自定义语音。在自定义语音页面上，单击新建项目：
- en: '![](img/ad50528e-6245-4426-ad58-0ac4b6ac02e0.png)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![图像](img/ad50528e-6245-4426-ad58-0ac4b6ac02e0.png)'
- en: Then, after giving your project a name and description, it is time to upload
    some audio files for training. As of the time of writing this book, the best voice
    system, **Neural Voice**, is in private preview. This means you will have to request
    access to use it. If you can access the Neural Voice feature, you will need 1
    hour of voice data. To achieve a slightly less high-fidelity voice font, you can
    use the standard voice training system. You can provide it with as low as 1 hour
    of audio samples but to achieve high quality, you will need 8 hours of audio.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 给你的项目起名字和描述后，是时候上传一些音频文件进行训练了。截至撰写本书时，最佳语音系统**神经语音**处于私人预览阶段。这意味着你需要申请访问权限才能使用它。如果你能访问神经语音功能，你将需要1小时的语音数据。为了获得略低保真度的语音合成，你可以使用标准的语音训练系统。你可以提供至少1小时的音频样本，但为了获得高质量的语音，你需要8小时的音频。
- en: 'After creating a new project, you will be in Microsoft Speech Studio. First,
    click on Data, and then Upload data. Then, select audio only, unless you have
    some pre-transcribed audio:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个新项目后，你将进入微软语音工作室。首先，点击数据，然后上传数据。然后，选择仅音频，除非你有一些预转录的音频：
- en: '![](img/e28b620d-819e-42d4-81b8-26596ee41db1.png)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e28b620d-819e-42d4-81b8-26596ee41db1.png)'
- en: 'Then, upload all of your `.mp3` files zipped into one file. Depending on the
    amount of audio you have, it may take several hours to process the audio. Then,
    select the Training tab and click on Train Model. You will have the option of
    three different training methods: Statistical parametric, Concatenative, and Neural:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，将所有你的`.mp3`文件压缩成一个文件。根据你的音频数量不同，处理音频可能需要几个小时。然后，选择训练选项卡，点击训练模型。你将有三种不同的训练方法可选：统计参数化，连接法和神经网络：
- en: '![](img/f7235709-b2ce-42d8-b5b6-80aef5fad1fc.png)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f7235709-b2ce-42d8-b5b6-80aef5fad1fc.png)'
- en: Choose the method that is the best one available to you. Statistical parametric
    is the lowest-quality option. It also requires the least amount of data. The next
    method, Concatenative, requires several hours of audio. Finally, the highest-quality
    option is Neural, for which training can take several hours.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 选择对你最适用的方法。统计参数化是最低质量的选项。它还需要最少的数据。接下来的方法，连接法，需要几个小时的音频。最后，质量最高的选项是神经网络，其训练可能需要几个小时。
- en: After training is complete, head over to the Testing tab and test your new voice.
    In the Testing tab, you can hear and download audio. You can use text to produce
    audio or **Speech Synthesis Markup Language** (**SSML**), which is an XML-based
    voice markup language. SSML allows you, if you are working with neural voices,
    to add sentiment such as cheerful and empathetic. In addition, it allows you to
    fine-tune pronunciation, emphasis, and speed.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 训练完成后，转到测试选项卡并测试你的新语音。在测试选项卡中，你可以听到和下载音频。你可以使用文本生成音频或**语音合成标记语言**（**SSML**），这是一种基于XML的语音标记语言。SSML允许你（如果你使用神经语音）添加情感，如愉快和共鸣。此外，它还允许你微调发音、重音和速度。
- en: After you have tested your custom voice, go over to the Deployment tab and deploy
    your voice. This can also take a while to process. Once it is done, go to the
    deployment information. You will need this information to send the request to
    Cognitive Services.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在测试完自定义语音后，转到部署选项卡并部署你的语音。这也可能需要一段时间进行处理。完成后，转到部署信息。你将需要这些信息发送请求给认知服务。
- en: How to do it...
  id: totrans-163
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 怎么做...
- en: 'The steps for this recipe are as follows:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 此处的步骤如下：
- en: 'Import the libraries:'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入库：
- en: '[PRE34]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Set the variables. These are the keys and variables that we retrieved in the
    *Getting ready* section:'
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置变量。这些是我们在*准备工作*部分中检索的键和变量：
- en: '[PRE35]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Generate a token:'
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成一个令牌：
- en: '[PRE36]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Send a request to the custom voice with the words we want it to create and
    return the response:'
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 发送请求给定制语音，以及我们希望它创建并返回响应的单词：
- en: '[PRE37]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'From the response, we save the `.wav` file and then play it:'
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从响应中保存`.wav`文件，然后播放它：
- en: '[PRE38]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: How it works...
  id: totrans-175
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理...
- en: In this recipe, we used Cognitive Service's custom speech-to-text feature. Custom
    speech-to-text both has pretrained voice fonts and allows you to create your own
    custom voice fonts. Behind the scenes, it takes the voice input, then uses speech-to-text
    to parse words from the text, and then uses the set of words and voice to create
    a custom voice. After the training is complete, you can expose an endpoint to
    retrieve the audio from the speech model.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个配方中，我们使用了认知服务的自定义语音转文本功能。自定义语音转文本既有预训练的语音字体，也允许您创建自己的自定义语音字体。在幕后，它接受语音输入，然后使用语音转文本从文本中解析单词，然后使用单词和语音集合创建自定义语音。培训完成后，您可以公开一个端点来从语音模型中检索音频。
- en: Enhancing bots with QnA Maker
  id: totrans-177
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用QnA Maker增强机器人
- en: Microsoft's QnA Maker is a tool that can take **frequently asked questions**
    (**FAQs**) and turn them into a set of questions and answers using language understanding,
    allowing users to ask questions differently to get an answer that matches up to
    the question. **QnA Maker** can take in a list of **tab-separated values** (**TSVs**),
    an FAQ web page, and a PDF, to name a few. In this recipe, we will use a TSV with
    questions and answers.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: Microsoft的QnA Maker是一个工具，可以将常见问题（FAQs）转换为一组问题和答案，使用语言理解技术，允许用户以不同的方式提问，以获得与问题相匹配的答案。QnA
    Maker可以处理一系列的数据源，包括以制表符分隔的值（TSVs）、FAQ网页和PDF等。在这个配方中，我们将使用包含问题和答案的TSV。
- en: QnA Maker solves the fuzzy logic of interpreting speech and determining the
    user's question. As part of the Cognitive Service speech ecosystem, it can be
    incorporated easily with Bot Framework and voice to give customers a rich interactive
    experience.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: QnA Maker解决了解释语音并确定用户问题的模糊逻辑。作为认知服务语音生态系统的一部分，它可以轻松与Bot Framework和语音集成，为客户提供丰富的互动体验。
- en: Getting ready
  id: totrans-180
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: Before using QnA Maker, you need a series of questions and answers. You can
    either point it at a website and have it parse the questions and answers or upload
    a TSV. For this recipe, we will use a TSV. There is a sample in the Git repo for
    this book.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用QnA Maker之前，您需要一系列问题和答案。您可以指向一个网站并让它解析问题和答案，或者上传一个TSV。对于这个配方，我们将使用一个TSV。在本书的Git存储库中有一个示例。
- en: To create a QnA Maker project, go to the QnA Maker portal at [https://www.qnamaker.ai/](https://www.qnamaker.ai/) and
    click on Create a Knowledge Base. It will take you through a five-step wizard
    to create a QnA bot. The first step deploys the resources in Azure. The second
    step has you choose a language and associate the bot with the new service you
    just created. You will then give your project a name and upload the files with
    questions and answers.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建一个QnA Maker项目，请访问[https://www.qnamaker.ai/](https://www.qnamaker.ai/)，并单击创建知识库。它将带您完成一个五步向导来创建一个QnA机器人。第一步部署资源到Azure中。第二步让您选择语言，并将机器人与刚刚创建的新服务关联起来。然后，您将为项目命名并上传包含问题和答案的文件。
- en: The most straightforward way of adding questions and answers is to use a TSV.
    There are a few fields you will need. These are `question`, `answer`, `source`,
    and `meta`. `meta` and `source` are fields you can use to query data. For example,
    in our nutrition FAQ, we may have several different ways of understanding and
    responding to a query about the calories in a burger.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 添加问题和答案的最直接方式是使用TSV。您需要几个字段，包括`question`、`answer`、`source`和`meta`。`meta`和`source`是您可以用来查询数据的字段。例如，在我们的营养常见问题解答中，我们可能有几种不同的方式来理解和回答关于汉堡热量的查询。
- en: 'After we upload and create the service, we can review what the system uploaded
    and add both questions and answers to existing data:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 在上传并创建服务后，我们可以查看系统上传的内容，并向现有数据添加问题和答案：
- en: '![](img/21109acb-2faa-4ebc-b232-69e7108f51c2.png)'
  id: totrans-185
  prefs: []
  type: TYPE_IMG
  zh: '![](img/21109acb-2faa-4ebc-b232-69e7108f51c2.png)'
- en: 'Next, we are going to click on the viewing options and select Show meta data.
    We are going to add audio we created with Speech Studio''s content creator. We
    introduced Speech Studio in the *Creating a* *custom voice* recipe. In the meta
    tag section, we are going to add the audio files we created with the content creator:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将点击查看选项，并选择显示元数据。我们将添加使用Speech Studio内容创建器创建的音频。我们在*创建自定义语音*配方中介绍了Speech
    Studio。在元标签部分，我们将添加我们使用内容创建器创建的音频文件：
- en: '![](img/2c5f0102-20cf-4ac2-91d6-b45b6ae76e7f.png)'
  id: totrans-187
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2c5f0102-20cf-4ac2-91d6-b45b6ae76e7f.png)'
- en: The next step is to select the **Save and Train** button and after your model
    has been saved, select the Test button and chat with your QnA Maker bot. Once
    you are satisfied with your QnA Maker bot, select the Publish button. After the
    training completes, QnA Maker will display `curl` commands to send a question
    to QnA Maker. From here, we will extract the keys needed to turn the request into
    a Python string.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是选择**保存和训练**按钮，保存模型后，选择测试按钮并与您的QnA Maker机器人聊天。一旦您对您的QnA Maker机器人满意，选择发布按钮。训练完成后，QnA
    Maker将显示`curl`命令以向QnA Maker发送问题。从这里，我们将提取所需的密钥以将请求转换为Python字符串。
- en: How to do it...
  id: totrans-189
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'The steps for this recipe are as follows:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 此示例的步骤如下：
- en: 'Import the libraries needed to send web requests and play sounds:'
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入所需的库以发送网络请求和播放声音：
- en: '[PRE39]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Set the variables. The key and project URL can be found in the *Getting ready*
    section:'
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置变量。密钥和项目URL可以在*准备就绪*部分找到：
- en: '[PRE40]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Generate the data in the correct format:'
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成正确格式的数据：
- en: '[PRE41]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Send a request to the speech services at the project URL:'
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 发送请求到项目URL上的语音服务：
- en: '[PRE42]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Extract the audio from the response and play it on the speakers:'
  id: totrans-199
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从响应中提取音频并在扬声器上播放：
- en: '[PRE43]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: How it works...
  id: totrans-201
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理...
- en: Under the hood, QnA Maker uses machine learning to train a model based on the
    question-answer pairs. It then parses the incoming text to determine which of
    the questions the customer was asking. In our kiosk example, QnA Maker is used
    to answer simple questions such as the nutritional value of the food and the location
    of the restaurant's information.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 在幕后，QnA Maker使用机器学习来基于问题-答案对训练模型。然后解析传入的文本，确定客户正在询问哪些问题。在我们的亭台示例中，QnA Maker用于回答诸如食物的营养价值和餐厅信息位置等简单问题。
- en: In this recipe, we are using the QnA Maker service to access the trained model.
    QnA Maker is accessed via `http post`. The results from QnA Maker are converted
    to sound files and played on the speakers.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们使用QnA Maker服务来访问训练好的模型。QnA Maker通过`http post`进行访问。来自QnA Maker的结果被转换为音频文件并在扬声器上播放。
- en: There's more...
  id: totrans-204
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: Chit-chat is incorporated in QnA Maker. To enable it, when you create a QnA
    Maker project, there is an option for chit-chat. Chit-chat allows users to enter
    a larger set of questions and have the bot make casual conversation. There are
    several personalities for chit-chat, such as professional and conversational.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: Chit-chat已经整合到QnA Maker中。要启用它，在创建QnA Maker项目时，有一个关于chit-chat的选项。Chit-chat允许用户输入更多的问题并与机器人进行非正式的对话。Chit-chat有几种个性，例如专业和对话。
