- en: Capstone Project – Playing Flappy Bird with DQN
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 毕业项目 – 使用 DQN 玩 Flappy Bird
- en: In this very last chapter, we will work on a capstone project—playing Flappy
    Bird using reinforcement learning. We will apply what we have learned throughout
    this book to build an intelligent bot. We will also focus on building **Deep Q-Networks**
    (**DQNs**), fine-tuning model parameters, and deploying the model. Let's see how
    long the bird can stay in the air.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在这最后一章中，我们将致力于一个毕业项目——使用强化学习玩 Flappy Bird。我们将应用我们在本书中学到的知识来构建一个智能机器人。我们还将专注于构建**深度
    Q 网络**（**DQNs**），微调模型参数并部署模型。让我们看看鸟能在空中停留多久。
- en: 'The capstone project will be built section by section in the following recipes:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一个章节将通过以下步骤逐步构建毕业项目：
- en: Setting up the game environment
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置游戏环境
- en: Building a Deep Q-Network to play Flappy Bird
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建一个深度 Q 网络来玩 Flappy Bird
- en: Training and tuning the network
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练和调整网络
- en: Deploying the model and playing the game
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署模型并玩游戏
- en: As a result, the code in each recipe is to be built on top of the previous recipes.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，每个食谱中的代码都将基于前面的食谱构建。
- en: Setting up the game environment
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置游戏环境
- en: To play Flappy Bird with a DQN, we first need to set up the environment.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 DQN 玩 Flappy Bird，我们首先需要设置环境。
- en: 'We’ll simulate the Flappy Bird game using Pygame. Pygame ([https://www.pygame.org](https://www.pygame.org/))
    contains a set of Python modules developed for creating video games. It also includes
    graphics and sound libraries needed in games. We can install the `Pygame` package
    as follows:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 Pygame 模拟 Flappy Bird 游戏。Pygame ([https://www.pygame.org](https://www.pygame.org/))
    包含一组为创建视频游戏而开发的 Python 模块。它还包括在游戏中需要的图形和声音库。我们可以按照以下方式安装 `Pygame` 包：
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Flappy Bird is a famous mobile game originally developed by Dong Nguyen. You
    can try it yourself, using your keyboard, at [https://flappybird.io/](https://flappybird.io/).
    The aim of the game is to remain alive as long as possible. The game ends when
    the bird touches the floor or a pipe. So, the bird needs to flap its wings at
    the right times to get through the random pipes and to avoid falling to the ground.
    Possible actions include flapping and not flapping. In the game environment, the
    reward is +0.1 for every step, with the following two exceptions:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: Flappy Bird 是由 Dong Nguyen 最初开发的一款著名移动游戏。你可以在 [https://flappybird.io/](https://flappybird.io/)
    使用键盘自己尝试。游戏的目标是尽可能长时间地保持存活。当鸟触碰到地面或管道时游戏结束。因此，鸟需要在正确的时机振翅通过随机的管道，避免落到地面上。可能的动作包括振翅和不振翅。在游戏环境中，每一步的奖励是
    +0.1，并有以下两个例外情况：
- en: -1 when a collision occurs
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当发生碰撞时为 -1
- en: +1 when the bird gets through the gap between two pipes. The original Flappy
    Bird game is scored based on the number of gaps passed through.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当鸟通过两个管道之间的间隙时为 +1。原始的 Flappy Bird 游戏根据通过的间隙数量进行评分。
- en: Getting ready
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'Download the assets of the game environment we need from [https://github.com/yanpanlau/Keras-FlappyBird/tree/master/assets/sprites](https://github.com/yanpanlau/Keras-FlappyBird/tree/master/assets/sprites).
    For simplicity, we''ll just use the images in the `sprites` folder. Specifically,
    we will need the following images:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 从 [https://github.com/yanpanlau/Keras-FlappyBird/tree/master/assets/sprites](https://github.com/yanpanlau/Keras-FlappyBird/tree/master/assets/sprites)
    下载我们需要的游戏环境资产。为简单起见，我们将只使用 `sprites` 文件夹中的图像。具体来说，我们需要以下图像：
- en: '`background-black.png`: The background image of the screen'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`background-black.png`: 屏幕的背景图像'
- en: '`base.png`: The image for the floor'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`base.png`: 地板的图像'
- en: '`pipe-green.png`: The image for the pipes that the bird needs to stay away
    from'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pipe-green.png`: 鸟需要避开的管道的图像'
- en: '`redbird-downflap.png`: The image for the bird when it''s flapping down'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`redbird-downflap.png`: 鸟向下振翅时的图像'
- en: '`redbird-midflap.png`: The image for the bird when it''s not flapping'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`redbird-midflap.png`: 鸟静止时的图像'
- en: '`redbird-upflap.png`: The image for the bird when it''s flapping up'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`redbird-upflap.png`: 鸟向上振翅时的图像'
- en: If you are interested, you can also use audio files to make the game more fun.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您感兴趣，还可以使用音频文件使游戏更有趣。
- en: How to do it...
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做…
- en: 'We''ll develop the Flappy Bird game environment using `Pygame` as follows:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 `Pygame` 开发 Flappy Bird 游戏环境，步骤如下：
- en: 'We start by developing a utility function that loads images and transforms
    them into the right format:'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们首先开发一个实用函数，加载图像并将其转换为正确的格式：
- en: '[PRE1]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Import all the necessary packages for the environment:'
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入环境所需的所有包：
- en: '[PRE2]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Initialize the game and clock and set 30 frames per second as the screen refresh
    frequency:'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化游戏和时钟，并将屏幕刷新频率设置为每秒 30 帧：
- en: '[PRE3]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Specify the screen size and create a screen accordingly, then add a caption
    to the screen:'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 指定屏幕大小并相应地创建屏幕，然后为屏幕添加标题：
- en: '[PRE4]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We then load necessary images (in the `sprites` folder) with the following
    function:'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，使用以下函数加载必要的图像（位于`sprites`文件夹中）：
- en: '[PRE5]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Get the game variables, including the size of the bird and the pipes, and set
    100 as the vertical gap between two pipes:'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取游戏变量，包括鸟和管道的大小，并设置两个管道之间的垂直间隙为100：
- en: '[PRE6]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The flapping movement of the bird rotates through up, middle, down, middle,
    up, and so on:'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 鸟的振动运动依次为向上、中间、向下、中间、向上等：
- en: '[PRE7]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: This is just to make the game more fun to watch.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这仅仅是为了使游戏更加有趣。
- en: 'After defining all constants, we start with the `__init__method` of the game
    environment''s `FlappyBird` class:'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在定义完所有常量后，我们从游戏环境的`FlappyBird`类的`__init__method`开始：
- en: '[PRE8]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We continue by defining the `gen_random_pipe` method, which generates a pair
    of pipes (one upper and one lower) in a given horizontal position and random vertical
    positions:'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们继续定义`gen_random_pipe`方法，该方法在给定的水平位置和随机垂直位置生成一对管道（一个上管道和一个下管道）：
- en: '[PRE9]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The upper and lower pipes are in the `y` position of `gap_y - pipe_height` and
    `gap_y + pipe_gap_size` respectively.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 上下两个管道的`y`位置分别为`gap_y - pipe_height`和`gap_y + pipe_gap_size`。
- en: 'The next method we develop is `check_collision,` which returns `True` if the
    bird collides with the base or a pipe:'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们接下来开发的方法是`check_collision`，如果鸟与基座或管道碰撞，则返回`True`：
- en: '[PRE10]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The last and the most import method we need is `next_step`, which performs
    an action and returns the updated image frame of the game, the reward received,
    and whether the episode is over or not:'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们最后需要的最重要的方法是`next_step`，它执行一个动作并返回游戏的更新图像帧、收到的奖励以及本轮游戏是否结束：
- en: '[PRE11]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: That's all for the Flappy Bird environment.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 至此，关于`Flappy Bird`环境的介绍就完成了。
- en: How it works...
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它的工作原理...
- en: In *Step 8*, we define the velocity of the pipe (to the left by 4 units as time
    goes by), the minimal and maximal vertical velocity of the bird (`-8` and `10`),
    its upward and downward acceleration (`-9` and `1`), its default vertical velocity
    (`0`), the starting index of the bird image (`0`), the initial score, the initial
    horizontal and vertical position of the bird, the position of the base, and the
    coordinates of the pipes that are randomly generated using the `gen_random_pipe`
    method.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在*第8步*中，我们定义了管道的速度（每过4个单位向左移动一次）、鸟的最小和最大垂直速度（分别为`-8`和`10`）、其向上和向下加速度（分别为`-9`和`1`）、其默认垂直速度（`0`）、鸟图像的起始索引（`0`）、初始得分、鸟的初始水平和垂直位置、基座的位置，以及使用`gen_random_pipe`方法随机生成的管道的坐标。
- en: In *Step 11*, by default, the reward for a step is `+0.1`. If the action is
    flap, we increase the bird’s vertical velocity by its upward acceleration. Then,
    we check whether the bird happens to get through a pair of pipes. If it does,
    the game score increases by 1 and the step reward becomes + 1\. We update the
    bird’s position, its image index, as well as the pipes' position. A new pair of
    pipes will be generated if the old pair is about to leave the left-hand side of
    the screen, and the old pair of pipes will be deleted once it goes offscreen.
    If a collision occurs, the episode will end and the reward will be -1; the game
    will also reset. Finally, we’ll display the updated frame on the game screen.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在*第11步*中，默认情况下，每个步骤的奖励为`+0.1`。如果动作是振翅，我们会增加鸟的垂直速度及其向上加速度。然后，我们检查鸟是否成功通过了一对管道。如果是，则游戏得分增加1，步骤奖励变为+1。我们更新鸟的位置、其图像索引以及管道的位置。如果旧的一对管道即将离开屏幕左侧，将生成新的一对管道，并在旧的一对管道离开屏幕后删除它。如果发生碰撞，本轮游戏将结束，奖励为-1；游戏也将重置。最后，我们会在游戏屏幕上显示更新的帧。
- en: Building a Deep Q-Network to play Flappy Bird
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建一个Deep Q-Network来玩Flappy Bird
- en: Now that the Flappy Bird environment is ready, we can start tackling it by building
    a DQN model.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 现在`Flappy Bird`环境已经准备就绪，我们可以开始通过构建DQN模型来解决它。
- en: 'As we have seen, a screen image is returned at each step after an action is
    taken. A CNN is one of the best neural network architectures to deal with image
    inputs. In a CNN, the convolutional layers are able to effectively extract features
    from images, which will be passed on to fully connected layers downstream. In
    our solution, we will use a CNN with three convolutional layers and one fully
    connected hidden layer. An example of CNN architecture is as follows:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所见，每次采取行动后都会返回一个屏幕图像。CNN是处理图像输入的最佳神经网络架构之一。在CNN中，卷积层能够有效地从图像中提取特征，这些特征将传递到下游的全连接层。在我们的解决方案中，我们将使用具有三个卷积层和一个全连接隐藏层的CNN。CNN架构示例如下：
- en: '![](img/ecfb19a6-6585-40eb-ade5-8f24dc904ebf.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ecfb19a6-6585-40eb-ade5-8f24dc904ebf.png)'
- en: How to do it...
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到...
- en: 'Let''s develop a CNN-based DQN model as follows:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开发一个基于CNN的DQN模型，步骤如下：
- en: 'Import the necessary modules:'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入必要的模块：
- en: '[PRE12]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'We start with the CNN model:'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们从CNN模型开始：
- en: '[PRE13]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Now develop a DQN with experience replay using the CNN model we just built:'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在使用我们刚刚构建的CNN模型开发一个带有经验回放的DQN：
- en: '[PRE14]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The `predict` method estimates the output Q-values, given an input state:'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`predict`方法根据输入状态估计输出Q值：'
- en: '[PRE15]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'An `update` method updates the weights of the neural network, given a training
    sample, and returns the current loss:'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`update`方法根据训练样本更新神经网络的权重，并返回当前损失：'
- en: '[PRE16]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The last part of the `DQN` class is the `replay` method, which performs experience
    replay given a collection of past experiences:'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`DQN`类的最后部分是`replay`方法，它在给定一系列过去经验时执行经验重播：'
- en: '[PRE17]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: That's it for the DQN class. In the next recipe, we will train the DQN model
    on a number of iterations.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是DQN类的全部内容。在下一个示例中，我们将对DQN模型进行若干次迭代的训练。
- en: How it works...
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理...
- en: In *Step 2*, we put together the backbone of the CNN-based DQN. It has three
    convolutional layers with various configurations. A ReLU activation function follows
    each convolutional layer. The resulting feature map from the last convolutional
    layer is then flattened and fed to a fully-connected hidden layer with 512 nodes,
    followed by the output layer.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤2*中，我们组装了基于CNN的DQN的骨干部分。它有三个具有不同配置的卷积层。每个卷积层后面跟着一个ReLU激活函数。然后将最后一个卷积层的特征图展平，并输入到一个具有512个节点的全连接隐藏层，然后是输出层。
- en: Note that we also set a boundary for the initial random value of the weights
    and a zero bias so that the model is more likely to converge faster.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们还设置了权重的初始随机值界限和零偏置，以便模型更容易收敛。
- en: '*Step 6* is for step-wise training with experience replay. If we have enough
    experiences, we randomly draw a `replay_size` set of experiences for training.
    We then convert each experience into a training sample composed of the predicted
    values and output target values, given an input state. The target values are computed
    as follows:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '*步骤6*是使用经验回放进行逐步训练。如果我们有足够的经验，我们会随机选择一个大小为`replay_size`的经验集合进行训练。然后，我们将每个经验转换为一个训练样本，该样本由给定输入状态的预测值和输出目标值组成。目标值计算如下：'
- en: 'Update the target Q value for the action using the reward and the new Q values,
    as in: [![](img/1a6a21ec-ee29-4f78-881a-3647f1e04b91.png)]'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用奖励和新的Q值更新动作的目标Q值，如下所示：[![](img/1a6a21ec-ee29-4f78-881a-3647f1e04b91.png)]
- en: If it is a terminal state, the target Q value is updated as `r`.
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果是终端状态，则目标Q值更新为`r`。
- en: And finally, we update the neural network using the selected batch of training
    samples.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们使用选定的训练样本批次来更新神经网络。
- en: Training and tuning the network
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练和调整网络
- en: In this recipe, we will train the DQN model to play Flappy Bird.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将训练DQN模型来玩Flappy Bird。
- en: 'In each step of the training, we take an action following the epsilon-greedy
    policy: under a certain probability (epsilon), we will take a random action, flapping
    or not flapping in our case; otherwise, we select the action with the highest
    value. We also adjust the value of epsilon for each step as we favor more exploration
    at the beginning and more exploitation when the DQN model is getting more mature.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练的每个步骤中，我们根据epsilon-greedy策略采取一个动作：在一定概率（epsilon）下，我们会随机采取一个动作，例如拍打或不拍打；否则，我们选择具有最高值的动作。我们还调整epsilon的值以便在DQN模型刚开始时更多地进行探索，在模型变得更加成熟时更多地进行利用。
- en: As we have seen, the observation for each step is a two-dimensional image of
    the screen. We need to transform the observation images into states. Simply using
    one image from a step will not provide enough information to guide the agent as
    to how to react. Hence, we form a state using images from four adjacent steps.
    We will first reshape the image into the expected size, then concatenate the image
    of the current frame with the three previous ones.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所见，每一步观察的观察是屏幕的二维图像。我们需要将观察图像转换为状态。仅使用一步中的一个图像将无法提供足够的信息来指导代理程序如何反应。因此，我们使用四个相邻步骤的图像来形成一个状态。我们首先将图像重新形状为预期大小，然后将当前帧的图像与前三个帧的图像连接起来。
- en: How to do it...
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'We train the DQN model as follows:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 我们按以下方式训练DQN模型：
- en: 'Import the necessary modules:'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入必要的模块：
- en: '[PRE18]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'We start by developing the epsilon-greedy policy:'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们从开发ε-greedy策略开始：
- en: '[PRE19]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'We specify the size of the preprocessed image, the batch size, the learning
    rate, the gamma , the number of actions, the initial and final epsilon, the number
    of iterations, and the size of the memory:'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们指定预处理图像的大小、批处理大小、学习率、γ值、动作数量、初始和最终ε值、迭代次数以及内存的大小：
- en: '[PRE20]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'We also save the trained model periodically, as it will be a very long process:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还定期保存训练好的模型，因为这是一个非常漫长的过程：
- en: '[PRE21]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Don't forget to create a folder named `trained_models`.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 不要忘记创建名为`trained_models`的文件夹。
- en: 'We specify the random feed for experimental reproducibility:'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们为实验的可重现性指定随机种子：
- en: '[PRE22]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'We create a DQN model accordingly:'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们相应地创建一个DQN模型：
- en: '[PRE23]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'We also create a memory queue:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还创建一个内存队列：
- en: '[PRE24]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: New samples will be appended to the queue, and the old ones will be removed
    as long as there are more than 50,000 samples in the queue.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 只要队列中的样本超过50,000个，就会附加新样本并移除旧样本。
- en: 'Next, we initialize a Flappy Bird environment:'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们初始化一个Flappy Bird环境：
- en: '[PRE25]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'We then obtain the initial image:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们获取初始图像：
- en: '[PRE26]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'As mentioned before, we should resize the raw image to `image_size * image_size`:'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 正如前面提到的，我们应该将原始图像调整为`image_size * image_size`：
- en: '[PRE27]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'If the `cv2` package is not installed, you can do so with the following command:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 如果尚未安装`cv2`包，您可以使用以下命令安装：
- en: '[PRE28]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Let''s preprocess the image accordingly:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们相应地预处理图像：
- en: '[PRE29]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Now, we construct a state by concatenating four images. Since we only have
    the first frame now, we simply replicate it four times:'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们通过连接四个图像来构造一个状态。因为现在我们只有第一帧图像，所以我们简单地将其复制四次：
- en: '[PRE30]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'We then work on the training loop for `n_iter` steps:'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们对`n_iter`步骤的训练循环进行操作：
- en: '[PRE31]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'After we run that section of code, we''ll see the following logs:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们运行这部分代码后，我们将看到以下日志：
- en: '[PRE32]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: The training will take a while. Of course, you can speed up training with the
    GPU.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 训练会花费一些时间。当然，您可以通过GPU加速训练。
- en: 'Finally, we save the last trained mode:'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们保存最后训练的模型：
- en: '[PRE33]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: How it works...
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理...
- en: 'In *Step 9*, for each training step, we perform the following tasks:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在*Step 9*中，对于每一个训练步骤，我们执行以下任务：
- en: Slightly decrease the epsilon, and create an epsilon-greedy policy accordingly.
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 稍微减小ε，并相应地创建ε-greedy策略。
- en: Take the action computed using the epsilon-greedy policy.
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用ε-greedy策略计算采取的行动。
- en: Preprocess the resulting image and construct the new state by appending the
    image to those from the previous three steps.
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对生成的图像进行预处理，并通过将其附加到之前三个步骤的图像中来构造新的状态。
- en: Record the experience in this step, including the state, the action, the next
    state, the reward received, and whether it ends or not.
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 记录本步骤的经验，包括状态、行动、下一个状态、接收的奖励以及是否结束。
- en: Update the model with experience replay.
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用经验重播更新模型。
- en: Print out the training status and update the state.
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 打印出训练状态并更新状态。
- en: Save the trained model periodically in order to avoid retraining from scratch.
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定期保存训练好的模型，以避免从头开始重新训练。
- en: Deploying the model and playing the game
  id: totrans-130
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署模型并玩游戏
- en: Now that we've trained the DQN model, let's apply it to play the Flappy Bird
    game.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经训练好了DQN模型，让我们将其应用于玩Flappy Bird游戏。
- en: Playing the game with the trained model is simple. We will just take the action
    associated with the highest value in each step. We will play a few episodes to
    see how it performs. Don’t forget to preprocess the raw screen image and construct
    the state.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 使用训练模型玩游戏很简单。我们只需在每一步中采取与最高值相关联的动作。我们将播放几个剧集来查看其表现。不要忘记预处理原始屏幕图像并构造状态。
- en: How to do it...
  id: totrans-133
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'We test the DQN model on new episodes as follows:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在新的剧集上测试DQN模型的表现如下：
- en: 'We first load the final model:'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们首先加载最终模型：
- en: '[PRE34]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'We run 100 episodes, and we perform the following for each episode:'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们运行100集，并对每一集执行以下操作：
- en: '[PRE35]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Hopefully, you will see something like the following image, where the bird
    gets through a series of pipes:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 希望您能看到类似以下图像的内容，鸟类通过一系列管道：
- en: '![](img/6864a7d8-989a-4840-9655-8f728aa78bd6.png)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6864a7d8-989a-4840-9655-8f728aa78bd6.png)'
- en: How it works...
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理是这样的...
- en: 'In *Step 2*, we perform the following tasks for each episode:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在*第2步*中，我们对每一集执行以下任务：
- en: Initialize a Flappy Bird environment.
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 初始化Flappy Bird环境。
- en: Observe the initial image and generate its state.
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 观察初始图像并生成其状态。
- en: Compute the Q-values, given the state, using the model and taking the action
    with the highest Q-value
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用模型计算给定状态的Q值，并选择具有最高Q值的动作。
- en: Observe the new image and whether the episode ends or not.
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 观察新图像以及集数是否结束。
- en: If the episode continues, compute the state of the next image and assign it
    to the current state.
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果集数继续，计算下一个图像的状态并将其分配给当前状态。
- en: Repeat until the episode ends.
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重复直到集数结束。
