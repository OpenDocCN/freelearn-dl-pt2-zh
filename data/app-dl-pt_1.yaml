- en: '*Chaper 1*'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第1章*'
- en: Introduction to Deep Learning and PyTorch
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度学习和PyTorch简介
- en: Learning Objectives
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 学习目标
- en: 'By the end of this chapter, you will be able to:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章结束时，您将能够：
- en: Explain what deep learning is, its importance, and how it fits into AI and ML
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解释深度学习是什么，其重要性以及它如何适用于AI和ML
- en: Identify the sort of data problems that can be solved using deep learning
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确定可以使用深度学习解决的数据问题类型
- en: Differentiate PyTorch from other machine learning libraries by understanding
    the advantages and disadvantages of the library
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过理解该库的优缺点，区分PyTorch与其他机器学习库
- en: Create a single-layer neural network using PyTorch
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用PyTorch创建单层神经网络
- en: In this chapter, we'll go through how deep learning resonates with artificial
    intelligence and machine learning. And with an introduction to PyTorch, we'll
    explore basic programming exercises to apply the knowledge on the PyTorch syntax.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨深度学习与人工智能以及机器学习的共鸣。通过对PyTorch的介绍，我们将探索基本的编程练习，以应用PyTorch语法上的知识。
- en: Introduction
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍
- en: Deep learning is a subset of machine learning that focuses on using deep neural
    networks to solve complex data problems. It has become increasingly popular nowadays,
    thanks to advances in software and hardware that allow the gathering and processing
    of large amounts of data (we are talking about millions and billions of entries),
    considering that neural networks are currently the only algorithms capable of
    reaching higher levels of accuracy by feeding more data to the model.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习是机器学习的一个子集，专注于使用深度神经网络来解决复杂的数据问题。由于软件和硬件的进步允许收集和处理大量数据（我们谈论的是数百万甚至数十亿条记录），因此深度学习如今变得越来越流行，考虑到神经网络目前是唯一能够通过向模型提供更多数据来达到更高准确度水平的算法。
- en: With this in mind, the need for faster processing times is inevitable. PyTorch
    was born back in 2017 and its main characteristic relies on the fact that it uses
    the power of GPUs to run data using tensors. This allows algorithms to run at
    very high speeds, and at the same time it provides its users with flexibility
    and a standard syntax to obtain the best results for many data problems.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这个想法，对于更快的处理时间的需求是不可避免的。PyTorch诞生于2017年，其主要特点在于利用GPU的力量来运行使用张量的数据。这使得算法能够以非常高的速度运行，并且同时为其用户提供了灵活性和标准的语法，以获得许多数据问题的最佳结果。
- en: This book focuses on demystifying neural networks using PyTorch, in order to
    eliminate some of the fear that has been built implicitly around the complexity
    of neural network architectures.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本书专注于使用PyTorch揭示神经网络的神秘，以消除隐含在神经网络架构复杂性周围的一些恐惧。
- en: Considering this, this chapter focuses on introducing both the topics of deep
    learning and PyTorch. Here, you will learn what deep learning is, how it fits
    into the world of machine learning and artificial intelligence, how it works in
    general terms, and finally, some of the most popular applications nowadays. Additionally,
    you will learn how PyTorch works, what some of its main modules and characteristics
    are, and some of the main advantages and disadvantages that it poses to its users.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这一点，本章专注于介绍深度学习和PyTorch的主题。在这里，您将学习深度学习是什么，它如何适用于机器学习和人工智能的世界，它在一般条件下的工作原理，以及一些当前最流行的应用。此外，您还将了解PyTorch的工作原理，其主要模块和特征，以及对其用户提出的主要优缺点。
- en: Understanding Deep Learning
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解深度学习
- en: In order to understand what deep learning is and why it has become so popular
    nowadays, it is important to first define what artificial intelligence and machine
    learning are, and how deep learning fits into that world.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解深度学习是什么，以及为什么它如今变得如此流行，首先定义人工智能和机器学习的概念是很重要的，以及深度学习如何融入这个世界。
- en: '![Figure 1.1: A diagram of artificial intelligence, machine learning, and deep
    learning'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.1: 人工智能、机器学习和深度学习的图表'
- en: '](img/C11865_01_01.jpg)'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C11865_01_01.jpg)'
- en: 'Figure 1.1: A diagram of artificial intelligence, machine learning, and deep
    learning'
  id: totrans-18
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: '图 1.1: 人工智能、机器学习和深度学习的图表'
- en: As seen in the preceding figure, **artificial intelligence** (**AI**) is a general
    category that encapsulates both machine learning and deep learning. It refers
    to any intelligence demonstrated by machines that ultimately leads to solving
    a problem. These techniques include following a set of rules or logic, or learning
    from previous data, among others. Considering this, an artificial intelligence
    solution may or may not possess the learning ability to achieve an optimal solution.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所示，**人工智能**（**AI**）是一个涵盖机器学习和深度学习的通用类别。它指的是机器展示的任何智能，最终导致解决问题。这些技术包括遵循一组规则或逻辑，或从先前的数据中学习，等等。考虑到这一点，人工智能解决方案可能具有或不具有学习能力以实现最优解。
- en: Artificial intelligence solutions that possess the ability to learn fall inside
    the machine learning subset. Put simply, **machine learning** is just one of the
    ways to achieve artificial intelligence, and it consists of algorithms that have
    the ability to learn without being explicitly programmed to do so. This means
    that the algorithms are capable of parsing data, learning from it, and making
    a decision (prediction) accordingly. This method of machine learning is called
    "supervised learning," and it basically means that the algorithm is fed both with
    the input data and the target values (the desired outcome).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 具有学习能力的人工智能解决方案属于机器学习的子集。简单来说，**机器学习**只是实现人工智能的一种方式，它由能够在没有明确编程的情况下学习的算法组成。这意味着算法能够解析数据、从中学习，并据此做出决策（预测）。这种机器学习方法称为“监督学习”，基本上意味着算法同时接收输入数据和目标值（期望的输出）。
- en: Another methodology of machine learning is called "unsupervised learning," and
    in contrast with the aforementioned, only the input data is fed without any relation
    to an output. The objective of the algorithm here is to understand the data at
    hand in order to find similarities.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种机器学习方法称为“无监督学习”，与前述方法相比，只输入数据，没有与输出相关的任何关系。这里算法的目标是理解手头的数据以寻找相似之处。
- en: Finally, **deep learning** is a subset of machine learning that uses multi-layer
    neural networks (large neural networks), inspired by the biological structure
    of the human brain, where neurons in a layer receive some input data, process
    it, and send the output to the following layer. These neural networks can consist
    of thousands of interconnected nodes (neurons), mostly organized in different
    layers, where one node is connected to several nodes in the previous layer from
    where it receives its input data, as well as being connected to several nodes
    in the following layer, to which it sends the output data after being processed.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，**深度学习**是机器学习的一个子集，使用多层神经网络（大型神经网络），灵感来自于人类大脑的生物结构，在一个层中的神经元接收一些输入数据，处理它，并将输出发送到下一层。这些神经网络可以由数千个互连的节点（神经元）组成，大多数以不同的层次组织，其中一个节点连接到前一层中的几个节点，接收其输入数据，同时连接到下一层中的几个节点，将经过处理的输出数据发送给它们。
- en: The structure and functioning of neural networks will be further explained in
    subsequent sections of this book.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络的结构和功能将在本书的后续部分进一步解释。
- en: Why Is Deep Learning Important? Why Has It Become Popular?
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 深度学习为什么重要？为什么变得流行？
- en: In general terms, its popularity is due to a matter of accuracy. Deep learning
    has achieved higher accuracy levels than ever before for very complex data problems.
    This ability to perform outstandingly well has reached levels where machines can
    outperform humans, which allows the model to not only optimize processes, but
    to improve their quality. Thanks to this, there have been advances in revolutionary
    fields where accuracy is vital for safety reasons, such as self-driven cars.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，深度学习之所以流行是因为准确性问题。深度学习在非常复杂的数据问题上实现了比以往任何时候都更高的准确性水平。这种出色表现的能力已经达到了机器可以胜过人类的水平，这不仅使模型能够优化流程，还能提高其质量。由于这一点，在对安全至关重要的革命性领域，如自动驾驶汽车，准确性的进步是显著的。
- en: 'And, even though neural networks were theorized decades ago, there are two
    main reasons why they have recently become popular:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管神经网络理论上几十年前就存在，但它们最近变得流行有两个主要原因：
- en: Neural networks require, and actually capitalize on, vast amounts of labeled
    data to achieve an optimal solution. This means that for the algorithm to create
    an outstanding model, it is required to have hundreds of thousands of entries
    (and even millions for some data problems), containing both the features and the
    target values.
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 神经网络需要大量标记数据才能达到最优解，并且实际上利用这些数据。这意味着为了算法能够创建出优秀的模型，需要拥有数十万条记录（对于某些数据问题甚至需要数百万条），其中包含特征和目标值。
- en: Note
  id: totrans-28
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: Labeled data refers to data that contains a set of features (characteristics
    that describe an instance) and a target value (the value to be achieved).
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 标记数据指的是包含一组特征（描述一个实例的特征）和目标值（要实现的值）的数据。
- en: '![](img/C11865_01_02.jpg)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](img/C11865_01_02.jpg)'
- en: 'Figure 1.2: Performance of deep learning against other algorithms in terms
    of quantity of data'
  id: totrans-31
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.2：深度学习在数据量方面与其他算法的性能比较
- en: This is possible nowadays thanks to advances in software that allow the gathering
    of such granularity, while advances in hardware allow for the processing of it.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这种现象现在得以实现，得益于软件方面的进步，允许收集如此详细的数据，同时硬件方面的进步则允许对其进行处理。
- en: Neural networks require considerable computing power to be able to process such
    amounts of data, as mentioned before. This is crucial as, otherwise, it would
    take weeks (or even longer) for a traditional network to be trained, and considering
    that the process of achieving the best possible model is based on trial-and-error,
    it is necessary to be able to run the training process as efficiently as possible.
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 神经网络需要大量的计算能力来处理这些数据，正如前面提到的。这是至关重要的，否则传统网络的训练时间将需要数周（甚至更长时间），考虑到实现最佳模型的过程是基于试错的，需要尽可能高效地运行训练过程。
- en: This can be achieved today through the use of GPUs that can cut down the training
    time of a neural network from weeks to hours.
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通过使用GPU，可以将神经网络的训练时间从几周缩短到几小时。
- en: Note
  id: totrans-35
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: Moreover, with the objective of accelerating deep learning in order to be able
    to make use of large amounts of training data and construct state-of-the-art models,
    FPGAs (Field-Programmable Gate Arrays) and TPUs (Tensor Processing Units) are
    being developed by major cloud computing providers, such as AWS, Microsoft Azure,
    and Google.
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 此外，为了加速深度学习以利用大量的训练数据并构建最先进的模型，主要的云计算提供商（如AWS、Microsoft Azure和Google）正在开发FPGA（现场可编程门阵列）和TPU（张量处理单元）。
- en: Applications of Deep Learning
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 深度学习的应用
- en: Deep learning is revolutionizing technology as we know it in that many developments
    based on its application are impacting our lives currently. Moreover, it is thought
    that within the next 5 to 10 years, the way in which many processes are handled
    will change drastically.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习正在彻底改变我们所知的技术，因为基于其应用的许多发展目前正在影响我们的生活。此外，据认为在接下来的5到10年内，许多处理过程的方式将发生根本性变化。
- en: Furthermore, deep learning can be applied to a wide variety of situations, ranging
    from medical and safety purposes, to more trivial tasks such as colorizing black
    and white images or translating text in real time.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，深度学习可以应用于广泛的情况，从医疗和安全用途到更琐碎的任务，如给黑白图像上色或实时翻译文本。
- en: 'Some of the applications of deep learning that are either under development
    or in use today can be found here:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是目前正在开发或正在使用的一些深度学习应用场景：
- en: '**Self-driving vehicles**: Several companies, such as Google, have been working
    on the development of partially or totally self-driving vehicles that learn to
    drive by using digital sensors to identify the objects around them.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自动驾驶车辆**：谷歌等多家公司正在开发部分或完全自动驾驶的车辆，这些车辆通过使用数字传感器来识别周围的物体学习驾驶。'
- en: '![Figure 1.3: Google’s self-driving car'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.3：Google 的自动驾驶汽车](img/C11865_01_03.jpg)'
- en: '](img/C11865_01_03.jpg)'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.3：Google 的自动驾驶汽车](img/C11865_01_03.jpg)'
- en: 'Figure 1.3: Google''s self-driving car'
  id: totrans-44
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.3：Google 的自动驾驶汽车
- en: '**Medical diagnosis**: Deep learning is redefining this industry by improving
    the diagnosis accuracy of terminal diseases such as brain and breast cancer. This
    is done by classifying images of new patients, based on labeled images from previous
    patients that did or did not have cancer.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**医学诊断**：深度学习正在重新定义这一行业，通过提高诊断脑部和乳腺癌等终末疾病的准确性。这是通过对新患者的图像进行分类来完成的，基于先前患者的标记图像，这些图像表明患者是否患有癌症。'
- en: '**Voice assistants**: This may be one of the most popular applications nowadays,
    due to the proliferation of different voice-activated intelligent assistants,
    such as Apple''s Siri, Google Home, and Amazon''s Alexa.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**语音助手**: 这可能是当今最流行的应用之一，因为不同的语音激活智能助手大量普及，例如苹果的 Siri、Google Home 和亚马逊的 Alexa。'
- en: '![Figure 1.4: Amazon’s Alexa intelligent assistant'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.4: 亚马逊 Alexa 智能助手'
- en: '](img/C11865_01_04.jpg)'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C11865_01_04.jpg)'
- en: 'Figure 1.4: Amazon''s Alexa intelligent assistant'
  id: totrans-49
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: '图 1.4: 亚马逊的 Alexa 智能助手'
- en: '**Automatic text generation**: This involves generating new text based on an
    input sentence. This is popularly used in email writing, where the email provider
    suggests the next couple of words to the user, based on the text written so far.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自动文本生成**: 这涉及基于输入的句子生成新的文本。在电子邮件撰写中，这被广泛应用，其中电子邮件提供商根据迄今为止写入的文本向用户建议接下来的几个词。'
- en: '![Figure 1.5: Gmail’s text generation feature'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.5: Gmail 文本生成功能'
- en: '](img/C11865_01_05.jpg)'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C11865_01_05.jpg)'
- en: 'Figure 1.5: Gmail''s text generation feature'
  id: totrans-53
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: '图 1.5: Gmail 的文本生成功能'
- en: '**Advertising**: Here, the main idea is to increase the return on investment
    of ads by targeting the right audiences or by creating more effective ads, among
    other methodologies.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**广告**: 这里的主要思想是通过针对正确的受众或创建更有效的广告等方法来增加广告投资的回报率。'
- en: '**Price forecasting**: For beginners, this is a typical example of what can
    be achieved through the use of machine learning algorithms. Price forecasting
    consists of training a model based on real data, including, for instance in the
    field of real state, property characteristics and their final price in order to
    be able to predict the prices of future entries based solely on property characteristics.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**价格预测**: 对于初学者来说，这是通过使用机器学习算法可以实现的典型示例。价格预测包括基于实际数据训练模型，包括在房地产领域中，物业特征及其最终价格，以便仅基于物业特征预测未来条目的价格。'
- en: PyTorch Introduction
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PyTorch 简介
- en: '![Figure 1.6: PyTorch library logo'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.6: PyTorch 图书馆标志'
- en: '](img/C11865_01_06.jpg)'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C11865_01_06.jpg)'
- en: 'Figure 1.6: PyTorch library logo'
  id: totrans-59
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: '图 1.6: PyTorch 图书馆标志'
- en: PyTorch is an open-source library developed mainly by Facebook's artificial
    intelligence research group as a Python version of Torch, first released to the
    public in January 2017\. It uses the power of **graphic processing units** (**GPUs**)
    to speed up the computation of tensors, which accelerates the training times of
    complex models.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch 是一个开源库，主要由 Facebook 的人工智能研究小组开发，作为 Torch 的 Python 版本，于 2017 年 1 月首次向公众发布。它利用**图形处理单元**（**GPU**）的强大能力来加速张量的计算，从而加快复杂模型的训练时间。
- en: The library has a C++ backend, combined with the deep learning framework of
    Torch, which allows much faster computations than native Python libraries with
    many deep learning features. On the other hand, its frontend is in Python, which
    has helped its popularity considering that data scientists new to the library
    can construct very complex neural networks effortlessly. And thanks to this integration
    with Python, it is possible to use PyTorch alongside other popular Python packages.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 该库具有 C++ 后端，与 Torch 深度学习框架结合，比起许多带有多个深度学习功能的本地 Python 库，可以实现更快的计算。另一方面，其前端是
    Python，这一点帮助了它的流行，因为新手数据科学家可以轻松构建非常复杂的神经网络。而且，由于与 Python 的集成，可以将 PyTorch 与其他流行的
    Python 包一起使用。
- en: Although the library is fairly new, it has gained popularity very quickly as
    it was developed using feedback from many experts in the field, which converted
    it into a library created for users. The many advantages and disadvantages of
    using it are discussed in the next section.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这个库相对较新，但由于使用了来自该领域许多专家的反馈，它迅速获得了广泛的流行，这使它成为了为用户而创建的库。在下一节中讨论了使用它的许多优缺点。
- en: Advantages
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 优势
- en: There are several libraries nowadays that can be used for developing deep learning
    solutions, so why use PyTorch? Because PyTorch is a dynamic library, which allows
    its users great flexibility to develop very complex architectures that can be
    adapted to each particular data problem.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 如今有几个库可用于开发深度学习解决方案，那么为什么选择 PyTorch？因为 PyTorch 是一个动态库，允许用户以非常灵活的方式开发可以适应每个特定数据问题的复杂架构。
- en: Due to this, it has been adopted by a great deal of researchers and artificial
    intelligence developers, which makes it a must for landing a job in the field
    of machine learning.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，它已被大量研究人员和人工智能开发人员采纳，这使得它成为机器学习领域求职必备。
- en: 'The key aspects to highlight are shown here:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 这里显示了需要强调的关键方面：
- en: '**Ease of use**: With respect to the API, PyTorch has a simple interface that
    makes it very easy to develop and run models. Many early adopters consider it
    to be more intuitive than other libraries, such as TensorFlow. It is Pythonic
    in nature, which means it is integrated with Python, as mentioned before, which
    makes it very intuitive and easy to use even though the library is new to many
    developers. This integration also allows the use of many Python packages, such
    as NumPy and SciPy, to extend its functionalities.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**易用性**：关于API，PyTorch具有简单的界面，使得开发和运行模型非常容易。许多早期采用者认为它比其他库（如TensorFlow）更直观。它具有Pythonic风格，这意味着它与Python集成，在许多开发者看来，即使对于许多开发者来说，这个库还是新的，但是也很直观，易于使用。这种集成还允许使用许多Python包，如NumPy和SciPy，以扩展其功能。'
- en: '**Speed**: PyTorch makes use of GPUs that allow GPU-accelerated tensor computations.
    This enables the library to train faster than other deep learning libraries. This
    is especially useful when different approximations have to be tested in order
    to achieve the best possible model, and speed is a crucial matter. Additionally,
    even though other libraries may also have the option to accelerate computations
    with GPUs, PyTorch achieves this operation by typing just a couple of simple lines
    of code.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**速度**：PyTorch利用GPU进行加速张量计算。这使得该库训练速度比其他深度学习库更快。当需要测试不同的近似值以获得最佳模型时，速度是至关重要的。此外，即使其他库也可能有使用GPU加速计算的选项，PyTorch只需输入几行简单的代码就可以完成此操作。'
- en: Note
  id: totrans-69
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: 'The following URL contains a speed benchmark on different deep learning frameworks
    (considering that the difference in training time is evident when dealing with
    very large amounts of training data):'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下面的URL包含了对不同深度学习框架的速度基准测试（考虑到在处理大量训练数据时，训练时间的差异显而易见）：
- en: '[https://github.com/u39kun/deep-learning-benchmark](https://github.com/u39kun/deep-learning-benchmark)'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[https://github.com/u39kun/deep-learning-benchmark](https://github.com/u39kun/deep-learning-benchmark)'
- en: '**Convenience**: PyTorch is flexible. It uses dynamic computational graphs
    that allow you to make changes to networks on the go. Additionally, it allows
    great flexibility when building the architecture as it is very easy to make adjustments
    to conventional architectures.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**便利性**：PyTorch非常灵活。它使用动态计算图，允许您在运行时更改网络。此外，它在构建架构时提供了极大的灵活性，因为很容易对传统架构进行调整。'
- en: '**Imperative**: PyTorch is also imperative. Each line of code is executed individually,
    allowing you to track the model in real time, as well as to debug the model in
    a much convenient way.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**命令式**：PyTorch还是命令式的。每行代码都是单独执行的，允许您实时跟踪模型，以及以更方便的方式调试模型。'
- en: '**Pretrained models**: Finally, it contains many pretrained models that are
    very easy to use and are a great starting point for some data problems.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预训练模型**：最后，它包含许多预训练模型，非常易于使用，是解决某些数据问题的绝佳起点。'
- en: Disadvantages
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 缺点
- en: 'Although the advantages are huge and many, there are still some disadvantages
    to consider, which are explained here:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然优点很多，但仍然有一些需要考虑的缺点，这里进行了解释：
- en: '**Small community**: The community of adapters of this library is very small
    in comparison to some of the other libraries, such as TensorFlow. However, having
    been available to the public for only two years, today it is the third most popular
    library for implementing deep learning solutions, and its community grows by the
    day.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**社区小**：与TensorFlow等其他库相比，这个库的适配者社区非常小。然而，尽管只有两年的时间向公众开放，PyTorch如今已经是实施深度学习解决方案的第三大流行库，并且其社区日益壮大。'
- en: '**Spotty documentation**: Considering that the library is new, the documentation
    is not as complete as some of the more mature libraries, such as TensorFlow. However,
    as the features and capabilities of the library increase, the documentation is
    being extended. Additionally, as the community continues to grow, there will be
    more information available on the internet.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文档不完善**：考虑到该库的新颖性，文档不如TensorFlow等更成熟的库完整。然而，随着库的功能和能力的增加，文档正在不断扩展。此外，随着社区的持续增长，互联网上将会有更多的信息可用。'
- en: '**Not production-ready**: Although many of the complaints about the library
    have focused on its inability to be deployed for production, after the launch
    of version 1.0, the library included production capabilities to be able to export
    finalized models and use them in production environments.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**不适用于生产环境**：尽管有关该库的许多投诉集中在其无法用于生产的能力上，但在版本 1.0 发布后，该库包含了生产能力，可以导出最终模型并在生产环境中使用。'
- en: What Are Tensors?
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 什么是张量？
- en: Similar to NumPy, PyTorch uses tensors to represent data, which are matrix-like
    structures of *n* dimensions, as shown in *Figure 1.7*, with the difference that
    tensors can run on the GPU, which helps to accelerate numerical computations.
    Moreover, it is important to mention that, for tensors, the dimension is known
    as the rank.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 与 NumPy 类似，PyTorch 使用张量来表示数据，这些张量是类似于矩阵的 *n* 维结构，如 *图 1.7* 所示，不同之处在于张量可以在 GPU
    上运行，这有助于加速数值计算。此外，值得一提的是，对于张量来说，维度被称为秩。
- en: '![Figure 1.7: Visual representation of tensors of different dimensions'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.7：不同维度张量的视觉表示'
- en: '](img/C11865_01_07.jpg)'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.7：不同维度张量的视觉表示'
- en: 'Figure 1.7: Visual representation of tensors of different dimensions'
  id: totrans-84
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.7：不同维度张量的视觉表示
- en: In contrast with a matrix, a tensor is a mathematical entity contained in a
    structure that can interact with other mathematical entities. When one tensor
    transforms another, the former also carries a transformation of its own.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 与矩阵相反，张量是包含在结构中可以与其他数学实体交互的数学实体。当一个张量转换另一个张量时，前者也携带自己的转换。
- en: This means that tensors are not just data structures, but rather containers
    that, when fed some data, can map in a multi-linear manner with other tensors.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着张量不仅仅是数据结构，而是容器，当提供一些数据时，它们可以与其他张量进行多线性映射。
- en: 'Exercise 1: Creating Tensors of Different Ranks Using PyTorch'
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 1：使用 PyTorch 创建不同秩的张量
- en: Note
  id: totrans-88
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: All exercises and activities will be primarily developed in a Jupyter notebook.
    It is recommended to keep a separate notebook for different assignments, unless
    advised not to.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 所有练习和活动将主要在 Jupyter 笔记本中开发。建议为不同的作业保留单独的笔记本，除非另有建议。
- en: In this exercise, we will use the PyTorch library to create tensors of one,
    two, and three ranks.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在此练习中，我们将使用 PyTorch 库创建一秩、二秩和三秩的张量。
- en: Note
  id: totrans-91
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: For the exercises and activities in this chapter, you will need to have Python
    3.6, Jupyter, Matplotlib, and PyTorch 1.0.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本章中的练习和活动，您需要安装 Python 3.6、Jupyter、Matplotlib 和 PyTorch 1.0。
- en: Note
  id: totrans-93
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: 'To clone the repository containing all the exercises and activities in this
    book, use the following commands in your CMD or terminal, after navigating to
    the desired path:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 要克隆包含本书中所有练习和活动的存储库，请在导航到所需路径后，在您的 CMD 或终端中使用以下命令：
- en: '[`git clone https://github.com/TrainingByPackt/Applied-Deep-Learning-with-PyTorch.git`](git
    clone https://github.com/TrainingByPackt/Applied-Deep-Learning-with-PyTorch.git
    )'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '[`git clone https://github.com/TrainingByPackt/Applied-Deep-Learning-with-PyTorch.git`](git
    clone https://github.com/TrainingByPackt/Applied-Deep-Learning-with-PyTorch.git
    )'
- en: Open a Jupyter notebook to implement this exercise.
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开 Jupyter 笔记本以实现此练习。
- en: 'Open your CMD or terminal, navigate to the desired path, and use the following
    command to open a Jupyter notebook: `jupyter notebook`.'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 打开您的 CMD 或终端，导航至所需路径，并使用以下命令打开 Jupyter 笔记本：`jupyter notebook`。
- en: Note
  id: totrans-98
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: This command may change depending on your operating system and its configurations.
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 此命令可能会根据您的操作系统及其配置而变化。
- en: 'Import the PyTorch library called `torch`:'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入名为 `torch` 的 PyTorch 库：
- en: '[PRE0]'
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Create tensors of the following ranks: 1, 2, and 3.'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建以下秩的张量：1、2 和 3。
- en: 'Use values between 0 and 1 to fill your tensors. The size of the tensors can
    be defined as you desire, given that the ranks are created correctly:'
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用介于 0 和 1 之间的值填充您的张量。可以根据您的需求定义张量的大小，只要创建正确的秩即可：
- en: '[PRE1]'
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'When using a GPU-enabled machine, use the following script to create the tensors:'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 当使用启用 GPU 的机器时，请使用以下脚本创建张量：
- en: '[PRE2]'
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Print the shape of each of the tensors using the `shape` property, just as
    you would do with NumPy arrays:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `shape` 属性打印每个张量的形状，就像您在 NumPy 数组中所做的那样：
- en: '[PRE3]'
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The final shape of each tensor should be as follows:'
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 每个张量的最终形状应如下：
- en: '[PRE4]'
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Congratulations! You have successfully created tensors of different ranks.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜！您已成功创建不同秩的张量。
- en: Key Elements of PyTorch
  id: totrans-112
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: PyTorch 的关键元素
- en: Like any other library, PyTorch has a variety of modules, libraries, and packages
    for developing different functionalities. In this section, the three most commonly
    used elements for building deep neural networks will be explained, along with
    a simple example of the syntax.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 像任何其他库一样，PyTorch有各种模块、库和包，用于开发不同的功能。在本节中，将解释构建深度神经网络所使用的三个最常用元素，并提供一个语法的简单示例。
- en: '**PyTorch autograd Library**'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '**PyTorch autograd库**'
- en: The `autograd` library consists of a technique called automatic differentiation.
    Its purpose is to numerically calculate the derivative of a function. This is
    crucial for a concept we will learn about in the next chapter called backward
    propagation, which is carried out while training a neural network.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '`autograd`库包含一种称为自动微分的技术。它的目的是数值计算函数的导数。这对我们将在下一章节学习的反向传播概念至关重要，这是在训练神经网络时执行的操作。'
- en: Note
  id: totrans-116
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: A detailed explanation on neural networks will be carried out in subsequent
    sections, explaining the different steps taken to train a model.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 后续章节将详细解释神经网络，包括训练模型所采取的不同步骤。
- en: 'To compute the gradients, simply call the `backward()` function, as shown here:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 要计算梯度，只需调用`backward()`函数，如下所示：
- en: '[PRE5]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: In the preceding code, two tensors were created. We use the `requires_grad`
    argument here to tell PyTorch to calculate the gradients of that tensor. However,
    when building your neural network, this argument is not required.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述代码中，创建了两个张量。我们在这里使用`requires_grad`参数告诉PyTorch计算该张量的梯度。然而，在构建您的神经网络时，此参数是不需要的。
- en: Next, a function was defined using the values of both tensors. Finally, the
    `backward()` function was used to calculate the gradients.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，使用两个张量的值定义了一个函数。最后，使用`backward()`函数计算了梯度。
- en: '**The PyTorch nn Module**'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '**PyTorch nn模块**'
- en: The `autograd` library alone can be used to build simple neural networks, considering
    that the trickier part (the calculation of gradients) has been taken care of.
    However, this methodology can be troublesome, hence the introduction of the nn
    module.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '`autograd`库本身可以用来构建简单的神经网络，考虑到更复杂的部分（梯度计算）已经处理好。然而，这种方法可能会有些麻烦，因此引入了nn模块。'
- en: The nn module is a complete PyTorch module used to create and train neural networks,
    which, through the use of different elements, allows for very simple and very
    complex developments. For instance, the `Sequential()` container allows the easy
    creation of network architectures that follow a sequence of predefined modules
    (or layers) without the need for much knowledge.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: nn模块是一个完整的PyTorch模块，用于创建和训练神经网络，通过使用不同的元素，可以进行非常简单和非常复杂的开发。例如，`Sequential()`容器允许轻松创建按预定义模块（或层）序列排列的网络架构，无需太多的知识。
- en: Note
  id: totrans-125
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The different layers that can be used for each neural network architecture will
    be further explained in subsequent chapters.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 可以在后续章节进一步解释可以用于每种神经网络架构的不同层。
- en: Moreover, this module also has the capability to define the loss function to
    evaluate the model, and many more advanced features that will be discussed in
    this book.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，该模块还具备定义损失函数以评估模型的能力，以及许多更高级的功能，本书将对其进行讨论。
- en: 'The process of building a neural network architecture as a sequence of predefined
    modules can be achieved in just a couple of lines, as shown here:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 将神经网络架构建立为一系列预定义模块的过程可以在几行代码中完成，如下所示：
- en: '[PRE6]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: First, the module is imported. Next, the model architecture is defined. `input_units`
    refers to the number of features that the input data contains, `hidden_units`
    refers to the number of nodes of the hidden layer, and `output_units` refers to
    the number of nodes of the output layer.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，导入模块。接下来，定义模型架构。`input_units`指的是输入数据包含的特征数，`hidden_units`指的是隐藏层节点数，`output_units`指的是输出层节点数。
- en: As can be seen, the architecture of the network contains one hidden layer, with
    a ReLU activation function and an output layer with a sigmoid activation function.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 可以看出，网络的架构包含一个隐藏层，具有ReLU激活函数，以及一个具有sigmoid激活函数的输出层。
- en: Finally, the loss function is defined as the **Mean Squared Error** (**MSE**).
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，将损失函数定义为**均方误差**（**MSE**）。
- en: Note
  id: totrans-133
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: To create models that do not follow a sequence of existing modules, custom nn
    modules are used. We'll introduce these later in the book.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 为了创建不遵循现有模块序列的模型，使用了自定义的nn模块。我们将在本书的后续部分介绍这些内容。
- en: '**The PyTorch optim Package**'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '**PyTorch优化包**'
- en: The `optim` package is used to define the optimizer that will be used to update
    the parameters in each iteration (which will be further explained in the following
    chapters), using the gradients calculated by the `autograd` module. Here, it is
    possible to choose from the optimization algorithms available, such as Adam, **Stochastic
    Gradient Descent** (**SGD**), and RMSprop, among others.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`optim`包定义优化器，该优化器将用于更新每次迭代中的参数（在接下来的章节中将进一步解释），使用`autograd`模块计算的梯度。在这里，可以从可用的优化算法中选择，例如Adam、**随机梯度下降**（**SGD**）和RMSprop等。
- en: 'To set the optimizer to be used, the following line of code suffices:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 要设置要使用的优化器，以下代码行足以：
- en: '[PRE7]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Here, the `model.parameters()` argument refers to the weights and biases from
    the model previously created, and `lr` refers to the learning rate, which was
    set as `0.01`.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`model.parameters()`参数指的是先前创建的模型的权重和偏差，而`lr`指的是学习率，设置为`0.01`。
- en: 'Next, the process of running the optimization for 100 iterations is shown here,
    which, as you can see, uses the model created by the nn module and the gradients
    calculated by the `autograd` library:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，显示运行100次迭代的优化过程，正如您所看到的，使用了nn模块创建的模型和由`autograd`库计算的梯度：
- en: '[PRE8]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: For each iteration, the model is called to obtain a prediction (`y_pred`). This
    prediction and the ground truth values (`y`) are fed to the loss functions in
    order to determine the ability of the model to approximate to the ground truth.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 每次迭代中，调用模型以获取预测值（`y_pred`）。将该预测值和地面真值（`y`）馈送到损失函数中，以确定模型逼近地面真值的能力。
- en: Next, the gradients are zeroed, and the gradients of the loss function are calculated
    using the `backward()` function.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，将梯度归零，并使用`backward()`函数计算损失函数的梯度。
- en: Finally, the `step()` function is called to update the weights and biases based
    on the optimization algorithm and the gradients calculated previously.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，调用`step()`函数来基于优化算法和先前计算的梯度更新权重和偏差。
- en: 'Activity 1: Creating a Single-Layer Neural Network'
  id: totrans-145
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动1：创建单层神经网络
- en: For this activity, we will create a single-layer neural network, which will
    be a starting point from which we will create deep neural networks in future activities.
    Let's look at the following scenario.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 对于此活动，我们将创建一个单层神经网络，这将是我们未来活动中创建深度神经网络的起点。让我们看看以下情景。
- en: 'You are applying for a job at a major technology firm and have passed all the
    screening interviews. The next step in the recruitment process is to display your
    programming machine learning skills in real time during an interview. They have
    asked you to build a single-layer neural network using PyTorch:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 您正在申请一家主要技术公司的工作，并且已经通过了所有筛选面试。招聘过程的下一步是在面试中实时展示您的编程机器学习技能。他们要求您使用PyTorch构建一个单层神经网络：
- en: Import the required libraries.
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入所需的库。
- en: Create dummy input data (`x`) of random values and dummy target data (`y`) that
    only contains 0s and 1s. Store the data in tensors. Tensor `x` should have a size
    of (100,5), while the size of `y` should be (100,1).
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建随机值的虚拟输入数据（`x`）和只包含0和1的虚拟目标数据（`y`）。将数据存储在张量中。张量`x`的大小应为（100,5），而`y`的大小应为（100,1）。
- en: Note
  id: totrans-150
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: PyTorch tensors can be manipulated like NumPy arrays.Use `torch.randn(number_instances`,
    number features) to create `x`.Use `torch.randint(low=0, high, size)` to create
    `y`. Take into account that `randint` is upper-bound exclusive. Make sure you
    convert the `y` tensor to a `FloatTensor` type, as this is the default type that
    the nn module handles. Use `.type(torch.FloatTensor)` for that purpose.
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: PyTorch张量可以像NumPy数组一样操作。使用`torch.randn(number_instances, number_features)`创建`x`。使用`torch.randint(low=0,
    high, size)`创建`y`。请注意，`randint`是上限独占的。确保将`y`张量转换为`FloatTensor`类型，因为这是nn模块处理的默认类型。为此，请使用`.type(torch.FloatTensor)`。
- en: Define the architecture of the model and store it in a variable named `model`.
    Remember to create a single-layer model.
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义模型的架构并将其存储在名为`model`的变量中。记得创建单层模型。
- en: Define the loss function to be used.
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义要使用的损失函数。
- en: Use the Mean Square Error loss function.
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用均方误差损失函数。
- en: Define the optimizer of your model.
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义模型的优化器。
- en: Use the Adam optimizer.
  id: totrans-156
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用Adam优化器。
- en: Run the optimization for 100 iterations. In each iteration, print and save the
    loss value.
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行100次迭代的优化。在每次迭代中，打印并保存损失值。
- en: Note
  id: totrans-158
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: Use the following line of code to append the loss value of each iteration step
    to a list previously created outside the for loop (losses):`losses.append(loss.item())`
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用以下代码行将每次迭代步骤的损失值附加到在for循环之外预先创建的列表（losses）中：`losses.append(loss.item())`
- en: 'Print the values of the final weights and bias. There should be a total of
    five weights (one for each feature of the input data) and one bias value:'
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印最终权重和偏置值的数值。应该有五个权重值（每个输入数据的特征一个）和一个偏置值：
- en: '[PRE9]'
  id: totrans-161
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Make a line plot to display the loss value for each iteration step.
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 制作一条线图显示每次迭代步骤的损失值。
- en: Note
  id: totrans-163
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The solution for this activity can be found on page 186.
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 此活动的解决方案可以在第186页找到。
- en: Summary
  id: totrans-165
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结
- en: The term artificial intelligence has become increasingly popular in the last
    couple of years. We have seen it in movies and we have seen it in real life, and
    it basically refers to any form of intelligence demonstrated by machines with
    the purpose of optimizing human tasks. A subcategory of AI that focuses on those
    algorithms that have the ability to learn from data, is called machine learning.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去几年中，人工智能这个词变得越来越流行。我们在电影中看到它，也在现实生活中看到它，它基本上指的是机器展示的任何形式的智能，目的是优化人类的任务。人工智能的一个子类专注于那些能够从数据中学习的算法，称为机器学习。
- en: In turn, deep learning is a subset of machine learning that was inspired by
    the biological structure of human brains. It uses deep neural networks to solve
    complex data problems through the use of vast amounts of data. And even though
    the theory was developed decades ago, it has been used recently thanks to advances
    in hardware and software, which allow for the collection and processing of millions
    of pieces of data.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习是机器学习的一个子集，灵感来源于人类大脑的生物结构。它使用深度神经网络通过大量数据解决复杂的数据问题。尽管理论几十年前就已经发展，但最近由于硬件和软件的进步，这些理论得以应用，使得可以收集和处理数百万条数据。
- en: With the popularity of deep learning solutions, many deep learning libraries
    have been developed. Among them, one of the most recent ones is PyTorch. PyTorch
    uses a C++ backend that helps speed up computations, while having a Python frontend
    to keep the library easy to use.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 随着深度学习解决方案的普及，已经开发了许多深度学习库。其中，最近的一个是PyTorch。PyTorch使用C++后端来加速计算，同时拥有Python前端，使得库易于使用。
- en: It uses tensors to store data, which are n-ranked matrix-like structures that
    can be run on GPUs to speed up processing. And it offers three main elements that
    are highly useful for creating complex neural network architectures with little
    effort.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 它使用张量来存储数据，这些张量是类似于n级矩阵的结构，可以在GPU上运行以加快处理速度。它提供了三个主要元素，对于以较少的工作量创建复杂的神经网络架构非常有用。
- en: The `autograd` library can compute the derivatives of a function, which are
    used as the gradients to optimize the weights and biases of a model. Moreover,
    the `nn` module helps you to easily define the model's architecture as a sequence
    of predefined modules, as well as to determine the loss function to be used to
    measure the model. Finally, the `optim` package is used to select the optimization
    algorithm to be used to update the parameters, considering the gradients calculated
    previously.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '`autograd`库可以计算函数的导数，这些导数被用作优化模型的权重和偏差的梯度。此外，`nn`模块帮助您轻松地将模型的架构定义为一系列预定义模块，并确定用于测量模型的损失函数。最后，`optim`包用于选择优化算法以更新先前计算的梯度。'
