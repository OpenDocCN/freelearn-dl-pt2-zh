- en: Convolutional Networks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 卷积网络
- en: Previously, we built several simple networks to solve regression and classification
    problems. These illustrated the basic code structure and concepts involved in
    building ANNs with PyTorch.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 之前，我们构建了几个简单的网络来解决回归和分类问题。这展示了使用PyTorch构建人工神经网络所涉及的基本代码结构和概念。
- en: 'In this chapter, we will extend simple linear models by adding layers and using
    convolutional layers to solve nonlinear problems found in real-world examples.
    Specifically, we will cover the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '在本章中，我们将通过增加层和使用卷积层来扩展简单的线性模型，解决实际示例中存在的非线性问题。具体来说，我们将涵盖以下主题:'
- en: Hyper-parameters and multilayered networks
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 超参数和多层网络
- en: Build a simple benchmarking function to train and test models
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建一个简单的基准函数来训练和测试模型
- en: Convolutional networks
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 卷积网络
- en: Hyper-parameters and multilayered networks
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 超参数和多层网络
- en: 'Now that you understand the process of building, training, and testing models,
    you will see that expanding these simple networks to increase performance is relatively
    straightforward. You will find that nearly all models we build consist, essentially,
    of the following six steps:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '现在您了解了构建、训练和测试模型的过程，您将会发现将这些简单网络扩展以提高性能是相对简单的。您会发现我们构建的几乎所有模型基本上都包含以下六个步骤:'
- en: Import data and create iterable data-loader objects for the training and test
    sets
  id: totrans-8
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入数据并为训练集和测试集创建可迭代的数据加载器对象
- en: Build and instantiate a model class
  id: totrans-9
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建并实例化一个模型类
- en: Instantiate a loss class
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例化一个损失类
- en: Instantiate an optimizer class
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例化一个优化器类
- en: Train the model
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练模型
- en: Test the model
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 测试模型
- en: 'Of course, once we complete these steps, we will want to improve our models
    by adjusting a set of hyper-parameters and repeating the steps. It should be mentioned
    that although we generally consider hyper-parameters things that are specifically
    set by a human, the setting of these hyper-parameters can be partially automated,
    as we shall see in the case of the learning rate. Here are the most common hyper-parameters:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，一旦我们完成这些步骤，我们会通过调整一组超参数来改进我们的模型并重复这些步骤。值得一提的是，尽管我们通常认为超参数是由人类明确设置的东西，但这些超参数的设置可以部分自动化，就像我们将在学习率的情况下看到的那样。以下是最常见的超参数：
- en: The learning rate of gradient descent
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 梯度下降的学习率
- en: The number of epochs to run the model
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行模型的epochs数量
- en: The type of nonlinear activation
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非线性激活函数的类型
- en: The depth of the network, that is, the number of hidden layers
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络的深度，即隐藏层的数量
- en: The width of the network, that is, the number of neurons in each layer
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络的宽度，即每层的神经元数量
- en: The connectivity of the network (for example, convolutional networks)
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络的连接性（例如，卷积网络）
- en: We have already worked with some of these hyper-parameters. We know the learning
    rate, if set too small, will take more time than necessary to find the optimum,
    and if set too large, will overshoot and behave erratically. The number of epochs
    is the number of complete passes over the training set. We would expect that as
    we increase the number of epochs, the accuracy will improve on each epoch, given
    limitations on the dataset and the algorithm used. At some point, the accuracy
    will plateau and training over more epochs is a waste of resources. If the accuracy
    decreases over the first few epochs, one of the most likely causes is that the
    learning rate is set too high.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经使用过一些超参数。我们知道学习率，如果设置得太小，将比必要的时间多花费，如果设置得太大，将会过度震荡并表现不稳定。Epochs的数量是对训练集的完全遍历次数。我们预期随着epochs的增加，每个epoch的准确率都会提高，考虑到数据集和算法的限制。在某个时刻，准确率将会稳定，再多的epochs训练将会是一种资源浪费。如果准确率在前几个epochs降低，最可能的原因之一是学习率设置得太高。
- en: Activation functions play a critical role in classification tasks and the effect
    of different types of activation can be somewhat subtle. It is generally agreed
    that the ReLU, or rectified linear function, performs best on the most common
    practice datasets. This is not to say that other activation functions, particularly
    the hyperbolic tangent or tanh function and variations on these, such as leaky
    ReLU, can produce better results under certain conditions.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 激活函数在分类任务中起着关键作用，不同类型的激活的效果可能有些微妙。一般认为ReLU，或修正线性函数，在最常见的实践数据集上表现最好。这不是说其他激活函数，特别是双曲正切函数或tanh函数以及这些函数的变体，如渗漏ReLU，在某些条件下不能产生更好的结果。
- en: As we increase the depth, or number of layers, we increase the learning power
    of the network, enabling it to capture more complex features of the training set.
    Obviously this increased ability is very much dependant on the size and complexity
    of the dataset and the task. With small datasets and relatively simple tasks,
    such as digit classification with MNIST, a very small number of layers (one or
    two) can give excellent results. Too many layers waste resources and tend to make
    the network overfit or behave erratically.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 随着深度或层数的增加，我们增强了网络的学习能力，使其能够捕获训练集更复杂的特征。显然，这种增强的能力在很大程度上取决于数据集的大小和复杂性以及任务本身。对于小数据集和相对简单的任务（例如使用MNIST进行数字分类），很少的层数（一到两层）就可以得到很好的结果。太多层会浪费资源，并且往往会使网络过拟合或表现不稳定。
- en: Much of this is true when we come to increasing the width, that is, the number
    of units in each layer. Increasing the width of a linear network is one of the
    most the most efficient ways to boost learning power. When it comes to convolutional
    networks, as we will see, not every unit is connected to every unit in the next
    forward layer; connectivity, that is, the number of input and output channels
    in each layer, is critical. We will look at convolutional networks shortly, but
    first we need to develop a framework to test and evaluate our models.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们来增加宽度，也就是每层单元的数量时，这些说法大多是正确的。增加线性网络的宽度是提升学习能力最有效的方法之一。至于卷积网络，正如我们将看到的那样，不是每个单元都连接到下一个前向层的每个单元；连通性，也就是每层的输入和输出通道数，是至关重要的。我们很快会看到卷积网络，但首先我们需要开发一个框架来测试和评估我们的模型。
- en: Benchmarking models
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对模型进行基准测试
- en: 'Benchmarking and evaluation are core to the success of any deep learning exploration.
    We will develop some simple code to evaluate two key performance measures: the
    accuracy and the training time. We will use the following model template:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 对任何深度学习探索的成功来说，基准测试和评估至关重要。我们将开发一些简单的代码来评估两个关键性能指标：准确率和训练时间。我们将使用以下模型模板：
- en: '![](img/790342c4-4149-482a-9d14-6ef55cd08597.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/790342c4-4149-482a-9d14-6ef55cd08597.png)'
- en: This model is the most common and basic linear template for solving MNIST. You
    can see we initialize each layer, in the`**init** `method, by creating a class
    variable that is assigned to a PyTorch `nn` object. Here, we initialize two linear
    functions and a ReLU function. The `nn.Linear` function takes an input size of
    `28*28` or `784`. This is the size of each of the training images. The output
    channels or the width of the network are set to `100`. This can be set to anything,
    and in general a higher number will give better performance within the constraints
    of computing resources and the tendency for wider networks to overfit training
    data.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型是解决MNIST问题的最常见和基本的线性模板。你可以看到，在`**init**`方法中，我们初始化每一层，通过创建一个赋给PyTorch `nn`对象的类变量。在这里，我们初始化了两个线性函数和一个ReLU函数。`nn.Linear`函数以`28*28`或`784`的输入大小开始。这是每个训练图像的尺寸。输出通道或网络的宽度设置为`100`。这可以设置为任何值，一般情况下，更高的数字将在计算资源的限制和更宽网络过拟合训练数据的倾向中提供更好的性能。
- en: In the `forward `method, we create an `out` variable. You can see that the out
    variable is passed through an ordered sequence consisting of a linear function,
    a ReLU function, and another linear function before being returned. This is a
    fairly typical network architecture, consisting of alternating linear and nonlinear
    layers.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在`forward`方法中，我们创建一个`out`变量。你可以看到，out变量经过一个线性函数、一个ReLU函数和另一个线性函数的有序序列处理后返回。这是一个相当典型的网络架构，由交替的线性和非线性层组成。
- en: 'Let''s now create two more models, replacing the ReLU function with the tanh
    and sigmoid activation functions. Here is the tanh version:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们创建另外两个模型，将ReLU函数替换为tanh和sigmoid激活函数。这是tanh版本的代码：
- en: '![](img/a95d92db-69da-4560-97c7-dde99e4ed630.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/a95d92db-69da-4560-97c7-dde99e4ed630.png)'
- en: You can see we simply changed the name and replaced the `nn.RelU()` function
    with `nn.Tanh()`. Create a third model in exactly the same way, replacing `nn.Tanh()`
    with `nn.Sigmoid()`. Don't forget to change the name in the super constructor
    and in the variable used to instantiate the model. Also remember to change the
    forward function accordingly.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到，我们只是更改了名称，并用`nn.Tanh()`函数替换了`nn.ReLU()`函数。以完全相同的方式创建第三个模型，用`nn.Tanh()`替换`nn.Sigmoid()`。不要忘记在超级构造函数中更改名称，并在用于实例化模型的变量中进行更改。还要相应地更改前向函数。
- en: 'Now, let''s create a simple `benchmark` function that we can use to run and
    record the accuracy and training time of each of these models:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们创建一个简单的 `benchmark` 函数，用来运行并记录每个模型的准确度和训练时间：
- en: '![](img/e8af116f-59a1-4f5e-89e3-a7ac588c5788.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e8af116f-59a1-4f5e-89e3-a7ac588c5788.png)'
- en: 'Hopefully, this is fairly self-explanatory. The `benchmark` function takes
    two required parameters: the data and the model to be evaluated. We set default
    values for epochs and the learning rate. We need to initialize the model so we
    can run it more than once at a time on the same model, otherwise the model parameters
    will accumulate, distorting our results. The running code is identical to the
    code used for the previous models. Finally, we print out the accuracy and the
    time taken to train. The training time calculated here is really only an approximate
    measure, since training time will be affected by whatever else is going on on
    in the processor, the amount of memory, and other factors beyond our control.
    We should only use this result as a relative indication of a model''s time performance.
    Finally, we need a function to calculate the accuracy, and this is defined as
    follows:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 希望这个解释清楚了。`benchmark` 函数接受两个必需的参数：数据和要评估的模型。我们为 epochs 和学习率设置了默认值。我们需要初始化模型，以便可以在同一模型上多次运行它，否则模型参数会累积，扭曲我们的结果。运行的代码与之前的模型使用的代码完全相同。最后，我们打印出准确度和训练时间。这里计算的训练时间实际上只是一个近似值，因为训练时间会受处理器上其他正在进行的操作、内存量和其他我们无法控制的因素的影响。我们只能将此结果用作模型时间性能的相对指标。最后，我们需要一个函数来计算准确率，定义如下：
- en: '![](img/8d96b16b-388a-492e-be3c-4b51dff43beb.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8d96b16b-388a-492e-be3c-4b51dff43beb.png)'
- en: 'Remember to load the training and test datasets and make them iterable exactly
    as we did before. Now, we can run our three models and compare them using something
    like the following:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 记得加载训练和测试数据集，并确保它们可以像之前一样被迭代。现在，我们可以运行我们的三个模型并使用类似以下方式进行比较：
- en: '![](img/1e57882e-d618-47be-9393-b92872fbf2db.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1e57882e-d618-47be-9393-b92872fbf2db.png)'
- en: We can see that both the `Tanh` and `ReLU` functions perform significantly better
    than `sigmoid`. For most networks, the `ReLU activation` function on hidden layers
    give the best results, both in terms of accuracy and the time it takes to train.
    The `ReLU` activation is not used on output layers. For the output layers, since
    we need to calculate the loss, we use the `softmax` function. This is the criterion
    for the loss class and, as before, we use `CrossEntropy Loss()`, which, if you
    remember, includes the `softmax` function.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，`Tanh` 和 `ReLU` 函数的性能显著优于 `sigmoid`。对于大多数网络来说，隐藏层上的 `ReLU` 激活函数在准确度和训练时间上都表现最好。`ReLU`
    激活函数不用于输出层。对于输出层，由于我们需要计算损失，我们使用 `softmax` 函数。这是损失类的标准，像之前一样，我们使用 `CrossEntropy
    Loss()`，其中包括 `softmax` 函数。
- en: 'There are several ways we can improve from here; one obvious way is simply
    to add more layers. This is typically done by adding alternating pairs of nonlinear
    and linear layers. In the following, we use `nn.Sequential` to organize our layers.
    In our forward layer, we simply have to call sequential objects, rather than every
    individual layer and function. This makes our code more compact and easier to
    read:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 从这里我们可以改进的几种方法；一个明显的方法就是简单地添加更多层。这通常是通过添加交替的非线性和线性层来完成的。在下面的例子中，我们使用 `nn.Sequential`
    来组织我们的层。在我们的前向层中，我们只需调用序列对象，而不是每个单独的层和函数。这使得我们的代码更加紧凑和易读：
- en: '![](img/fe2948dd-ad5b-46a7-9781-4144cdacec83.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fe2948dd-ad5b-46a7-9781-4144cdacec83.png)'
- en: 'Here, we add two more layers: a linear layer and a nonlinear `ReLU` layer.
    It is particularly important how we set the input and output sizes. In the first
    linear layer, the input size is `784`, this is the image size. The output of this
    layer, something we choose, is set to `100`. The input to the second linear layer,
    therefore, must be `100`. This is the width, the number of kernels and feature
    maps, of the output. The output of the second linear layer is something we choose,
    but the general idea is to decrease the size, since we are trying to filter down
    the features to just `10`, our target classes. For fun, create some models and
    try out different input and output sizes, remembering that the input to any layer
    must be the same size as the output of the previous layer. The following is the
    output of three models, where we print the output sizes of each of the hidden
    layers to give you an idea of what is possible:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们增加了两个更多的层：一个线性层和一个非线性的`ReLU`层。设置输入和输出大小尤为重要。在第一个线性层中，输入大小为`784`，这是图像的大小。该层的输出是我们选择的，设为`100`。因此，第二个线性层的输入必须是`100`。这是输出的宽度，卷积核和特征图的数量。第二个线性层的输出是我们选择的，但一般的想法是减少大小，因为我们试图将特征过滤到只有`10`个目标类别。为了好玩，创建一些模型，尝试不同的输入和输出大小，记住任何层的输入必须与上一层的输出大小相同。以下是三个模型的输出，我们打印每个隐藏层的输出大小，以便您了解可能的情况：
- en: '![](img/045fc1ee-c6ba-4054-a71c-3ea8e16b6f03.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](img/045fc1ee-c6ba-4054-a71c-3ea8e16b6f03.png)'
- en: We can continue to add as many layers and kernels as we desire, however this
    is not always a good idea. How we set up input and output sizes in a network is
    intimately connected to the size, shape, and complexity of the data. For simple
    datasets, such as MNIST, it is pretty clear that a few linear layers gets very
    good results. At some point, simply adding linear layers, and increasing the number
    of kernels will not capture the highly nonlinear features of complex datasets.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以根据需要添加尽可能多的层和卷积核，但这并不总是一个好主意。我们在网络中设置输入和输出大小的方式与数据的大小、形状和复杂性密切相关。对于简单的数据集，比如MNIST，几个线性层就能得到非常好的结果。但是，简单地添加线性层和增加卷积核的数量在捕捉复杂数据集的高度非线性特征时并不有效。
- en: Convolutional networks
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 卷积网络
- en: So far, we have used fully connected layers in our networks, where each input
    unit represents a pixel in an image. With convolutional networks, on the other
    hand, each input unit is assigned a small localized **receptive field**. The idea
    of the receptive field, like ANNs themselves, is modelled on the human brain.
    In 1958, it was discovered that neurons in the visual cortex of the brain respond
    to stimuli in a limited region of a field of vision. More intriguing is that sets
    of neurons respond exclusively to certain basic shapes. For example, a set of
    neurons may respond to horizontal lines, while others respond only to lines at
    other orientations. It was observed that sets of neurons could have the same receptive
    field, but respond to different shapes. It was also noticed that neurons were
    organized into layers with deeper layers responding to more complex patterns.
    This, it turns out, is a remarkably effective way for a computer to learn and
    categorize a set of images.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们在网络中使用了全连接层，其中每个输入单元表示图像中的一个像素。而使用卷积网络时，每个输入单元则被分配一个小的局部**感受野**。感受野的概念，就像人工神经网络本身一样，是模仿人脑的。1958年发现，大脑视皮层的神经元对视野中的受刺激有限区域作出反应。更有趣的是，一组神经元仅对某些基本形状作出反应。例如，一组神经元可能对水平线作出反应，而其他组则仅对其他方向的线作出反应。观察到，一组神经元可以具有相同的感受野，但对不同的形状作出反应。还观察到神经元组织成层，深层对更复杂的模式作出反应。这事实上是计算机学习和分类一组图像的一种非常有效的方式。
- en: A single convolutional layer
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 单个卷积层
- en: Convolutional layers are organized so the units in the first layer only respond
    to their respective receptive fields. Each unit in the next layer is connected
    only to a small region of the first layer, and each unit in the second hidden
    layer is connected to a limited region in the third layer, and so on. In this
    way, the network can be trained to assemble higher level features from the low-level
    features present in the previous layer.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积层组织得使第一层的单元仅对其相应的感受野作出反应。下一层的每个单元仅连接到第一层的一个小区域，第二个隐藏层的每个单元仅连接到第三层的有限区域，依此类推。通过这种方式，网络可以训练以从前一层中存在的低级特征组装出更高级别的特征。
- en: 'In practice, this works by using a **filter**, or **convolution kernel**, to
    scan an image to generate what is known as a **feature map**. The kernel is just
    a matrix that is the size of the receptive field. We can think of this as a camera
    scanning an image in discrete strides. We calculate a feature map matrix by an
    element-wise multiplication of the kernel matrix with the values in the receptive
    field of an image. The resultant matrix is then summed to compute a single number
    in the feature map. The values in the kernel matrix represent a feature we want
    to extract from the image. These are the parameters that we ultimately want the
    model to learn. Consider a simple example where we are attempting to detect horizontal
    and vertical lines in an image. To simplify things, we will use one input dimension;
    this is either black, represented by a **1**, or white, represented by a **0**.
    Remember that in practice these would be scaled and normalized floating-point
    numbers representing a grayscale or color value. Here, we set the kernel to 4
    x 4 pixels and we scan using a stride of **1**. A stride is simply the distance
    we move the kernel, so a stride of **1** moves the kernel one pixel:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，这是通过使用**滤波器**或**卷积核**来扫描图像以生成所谓的**特征图**来实现的。卷积核只是一个大小与接受域相同的矩阵。我们可以将其想象为相机以离散步幅扫描图像。我们通过卷积核矩阵与图像接受域中的值进行逐元素乘法来计算特征图矩阵。然后将结果矩阵求和以计算特征图中的单个数值。卷积核矩阵中的值代表我们希望从图像中提取的特征。这些是我们最终希望模型学习的参数。考虑一个简单的例子，我们试图在图像中检测水平和垂直线条。为简化问题，我们将使用一个输入维度；这可以是黑色，用**1**表示，或白色，用**0**表示。请记住，在实践中，这些将是表示灰度或颜色值的缩放和归一化的浮点数。在这里，我们将卷积核设置为4
    x 4像素，并使用步幅为**1**进行扫描。步幅简单地是我们移动卷积核的距离，因此步幅为**1**将卷积核移动一个像素：
- en: '![](img/f2284909-cad9-45c5-bed5-d11069caca26.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f2284909-cad9-45c5-bed5-d11069caca26.png)'
- en: One convolution is one complete scan of the image and each convolution generates
    a feature map. On each stride, we do an element-wise multiplication of the kernel
    with the receptive field of the image and we sum the resulting matrix.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 一个卷积是对图像的完整扫描，每个卷积生成一个特征图。在每个步幅上，我们对图像的接受域与卷积核进行逐元素乘法，并将结果矩阵求和。
- en: You will notice that as we move the kernel across the image, as shown in the
    preceding diagram, **stride 1** samples the top-left corner, **stride 2** samples
    the patch-one pixel to the left, **stride** **3** would sample one pixel to the
    left again, and so on. When we reach the end of the first row, we need to add
    a padding pixel, so set the value to **0** in order to sample the edges of the
    image. Padding input data with zeros is called **valid padding**. If we did not
    pad the image, the feature map would be smaller, in dimensions, than the original
    image. Padding is used to ensure that there is no loss of information from the
    original.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们在图像上移动卷积核时，如前图所示，**步幅 1** 采样左上角，**步幅 2** 采样左边一个像素，**步幅 3** 再次采样左边一个像素，依此类推。当我们到达第一行的末尾时，我们需要添加填充像素，因此将值设置为**0**以便采样图像的边缘。用零填充输入数据称为**有效填充**。如果我们没有对图像进行填充，特征图的维度将小于原始图像。填充用于确保不丢失原始信息。
- en: 'It is important to understand the relationship between input and output sizes,
    kernel size, padding, and stride. They can be expressed quite neatly in the following
    formula:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 理解输入和输出大小、卷积核大小、填充和步幅之间的关系非常重要。它们可以用以下公式来表达：
- en: '![](img/401dc8f1-0bee-460b-bc5d-f3e1698a6599.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](img/401dc8f1-0bee-460b-bc5d-f3e1698a6599.png)'
- en: Here, *O* *=* output size, *W* = input height or width, *K* = kernel size, *P*
    = padding, and *S* = stride. Note that the input height, or width, assumes these
    two are the same—that is, the input image is square, not rectangular. If the input
    image is a rectangle, we need to calculate output values separately for the width
    and height.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*O* *=* 输出大小，*W* = 输入高度或宽度，*K* = 卷积核大小，*P* = 填充，*S* = 步幅。请注意，输入高度或宽度假设这两者相同，即输入图像是方形的，而不是矩形的。如果输入图像是矩形的，则需要分别计算宽度和高度的输出值。
- en: 'The padding can be calculated as follows:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 填充可以如下计算：
- en: '![](img/c458dcce-9a0c-4160-a232-eef73b5344a3.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c458dcce-9a0c-4160-a232-eef73b5344a3.png)'
- en: Multiple kernels
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多个卷积核
- en: 'In each convolution, we can include multiple kernels. Each kernel in a convolution
    generates its own feature map. The number of kernels is the number of output channels,
    which is also the number of feature maps generated by the convolutional layer.
    We can generate further feature maps by using another kernel. As an exercise,
    calculate the feature map that would be generated by the following kernel:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个卷积中，我们可以包含多个内核。卷积中的每个内核生成自己的特征图。内核的数量是输出通道的数量，这也是卷积层生成的特征图数量。我们可以通过使用另一个内核生成更多的特征图。作为练习，请计算以下内核将生成的特征图：
- en: '![](img/e09d64cd-e011-4778-b7a6-8e366bf3ea6d.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e09d64cd-e011-4778-b7a6-8e366bf3ea6d.png)'
- en: By stacking kernels, or filters, and using kennels of different sizes and values,
    we can extract a variety of features from an image.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 通过堆叠内核或过滤器，并使用不同大小和值的内核，我们可以从图像中提取各种特征。
- en: Also, remember that each kernel is not restricted to one input dimension. For
    example, if we are processing an RGB color image, each kernel would have an input
    dimension of three. Since we are doing element-wise multiplication, the kernel
    must be the same size as the receptive field. When we have three dimensions, the
    kernel needs to have an input depth of three. So our greyscale 2 x 2 kernel becomes
    a 2 x 2 x 3 matrix for a color image. We still generate a single feature map on
    each convolution for each kernel. We are still able to do element-wise multiplication,
    since the kernel size is the same as the receptive field, except now when we do
    the summation, we sum across the three dimensions to get the single number required
    on each stride.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 同时，请记住每个内核不限于一个输入维度。例如，如果我们处理RGB彩色图像，则每个内核的输入维度为三。由于我们正在进行逐元素乘法，内核必须与感受野大小相同。当我们有三个维度时，内核需要具有三个输入深度。因此，我们的灰度2x2内核对于彩色图像来说变成了一个2x2x3矩阵。我们仍然为每个卷积生成单个特征图。我们仍然能够进行逐元素乘法，因为内核大小与感受野相同，只是现在在进行求和时，我们跨三个维度进行求和以获取每个步长所需的单个数字。
- en: As you can imagine, there are a large number of ways we can scan an image. We
    can change the size and value of the kernel, or we can change its stride, include
    padding and even include noncontiguous pixels.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你可以想象的那样，我们可以以多种方式扫描图像。我们可以更改内核的大小和值，或者更改其步幅，包括填充，甚至包括非连续像素。
- en: 'To get a better idea of some of the possibilities, check out vdumoulin''s excellent
    animations: [https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md](https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md).'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 要更好地了解一些可能性，请查看vdumoulin出色的动画：[https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md](https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md)。
- en: Multiple convolutional layers
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多个卷积层
- en: 'As with the fully connected linear layers, we can add multiple convolutional
    layers. As with linear layers, the same restrictions apply:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 与完全连接的线性层一样，我们可以添加多个卷积层。与线性层一样，同样的限制适用：
- en: Limitations on time and memory (computational load)
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 时间和内存限制（计算负载）
- en: Tendency to overfit a training set and not generalize to a test set
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 倾向于过拟合训练集而不是泛化到测试集
- en: Requires larger datasets to work effectively
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要更大的数据集才能有效工作
- en: The benefit of the appropriate addition of convolution layers is that, progressively,
    they are able to extract more complex, nonlinear features from datasets.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 适当添加卷积层的好处在于，逐步地，它们能够从数据集中提取更复杂、非线性的特征。
- en: Pooling layers
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 池化层
- en: Convolutional layers are typically stacked using **pooling layers**. The purpose
    of a pooling layer is to reduce the size, but not the depth, of the feature map
    generated by the preceding convolution. A pooling layer retains the RGB information
    but compresses the spatial information. The reason we do this is to enable kernels
    to focus selectively on certain nonlinear features. This means we can reduce the
    computational load by focusing on the parameters that have the strongest influence.
    Having fewer parameters also reduces the tendency to overfit.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 典型地，卷积层是通过**池化层**堆叠的。池化层的目的是减少前面卷积生成的特征图的尺寸，但不减少深度。池化层保留RGB信息，但压缩空间信息。我们这样做的原因是使内核能够有选择地专注于某些非线性特征。这意味着我们可以通过专注于具有最强影响力的参数来减少计算负载。具有较少参数还可以减少过拟合的倾向。
- en: 'There are three major reasons why pool layers are used to reduce dimensions
    of the output feature map:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 有三个主要原因导致使用池层来减少输出特征图的维数：
- en: Reduces computational load by discarding irrelevant features
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过丢弃不相关的特征来减少计算负载
- en: Smaller number of parameters, so less likely to overfit data
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参数数量较少，因此不太可能过拟合数据。
- en: Able to extract features that are transformed in some way, for example images
    of an object from different perspectives
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 能够提取经过某种方式转换的特征，例如来自不同视角的物体图像。
- en: Pooling layers are very similar to normal convolution layers in that they use
    a kernel matrix, or filter, to sample an image. The difference with pooling layers
    is that we downsample the input. Downsampling reduces the input dimensions. This
    can be achieved by either increasing the size of the kernel or increasing the
    stride, or both. Check the formula in the section on single convolutional layers
    to confirm this is true.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 池化层与普通卷积层非常相似，因为它们使用核矩阵或滤波器对图像进行采样。池化层的不同之处在于我们进行了降采样。降采样会减少输入维度。这可以通过增加核的大小或增加步幅或两者同时实现。请查看单卷积层部分的公式以确认这一点。
- en: Remember, in a convolution all we are doing is multiplying two tensors on each
    stride, over an image. Each subsequent stride in a convolution samples another
    part of the input. This sampling is achieved by element-wise multiplication of
    the kernel with the output of the previous convolution layer, encompassed by that
    particular stride. The result of this sampling is a single number. With a convolution
    layer, this single number is the sum of the element-wise multiplication. With
    a pooling layer, this single number is typically generated by either the average
    or the maximum of the element-wise multiplication. The terms **average pooling **and **max **pooling
    refer to these different pooling techniques.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，在卷积中，我们所做的只是在每个步幅上对图像上的两个张量进行乘法运算。卷积中的每个后续步幅采样输入的另一部分。这种采样是通过核与前一卷积层的输出之间的逐元素乘法实现的，包含在特定步幅内。这种采样的结果是一个单一数字。在卷积层中，这个单一数字是逐元素乘法的总和。在池化层中，这个单一数字通常是由逐元素乘法的平均值或最大值生成的。术语**平均池化**和**最大池化**指的是这些不同的池化技术。
- en: Building a single-layer CNN
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建单层CNN
- en: 'So now we should have enough theory to build a simple convolution network and
    understand how it works. Here is a model class template we can start with:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们应该有足够的理论来构建一个简单的卷积网络并理解其工作原理了。以下是我们可以开始使用的模型类模板：
- en: '![](img/daea6d68-3442-411a-864b-145fb4f88e86.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](img/daea6d68-3442-411a-864b-145fb4f88e86.png)'
- en: 'The basic convolutional unit we will be using is in PyTorch is the `nn.Conv2d`
    module. It is characterized by the following signature:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在PyTorch中使用的基本卷积单元是`nn.Conv2d`模块。其特征如下所示：
- en: '[PRE0]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The values of these parameters are constrained by the size of the input data
    and the formulae discussed in the last section. In this example, `in_channels`
    is set to `1`. This refers to the fact that our input image has one color dimension.
    If we were working with a three-channel color image, this would be set to `3`.
    `out_channel` is the number of kernels. We can set this to anything, but remember
    there are computational penalties, and improved performance is dependant on having
    larger, more complex datasets. For this example, we set the number of output channels
    to `16`. The number of output channels, or kernels, is essentially the number
    of low-level features we think might be indicative of the target class. We set
    the stride to `1` and the padding to `2`. This ensures the output size remains
    the same as the input; this can be verified by plugging these values into the
    output formula in the section on single convolutional layers.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 这些参数的值受限于输入数据的大小和上一节讨论的公式。在这个例子中，`in_channels`设置为`1`。这表示我们的输入图像有一个颜色维度。如果我们使用三通道彩色图像，则应将其设置为`3`。`out_channel`是卷积核的数量。我们可以将其设置为任何值，但要记住会有计算惩罚，并且改善性能取决于具有更大、更复杂数据集。在本例中，我们将输出通道数设置为`16`。输出通道数或卷积核实质上是我们认为可能是目标类别的低级特征的数量。我们将步幅设置为`1`，填充设置为`2`。这可以确保输出大小与输入大小相同；可以通过将这些值代入单卷积层部分的输出公式来验证。
- en: In the `__init__` method, you will notice we instantiate a convolutional layer,
    a `ReLU` activation function, a `MaxPool2d` layer, and a fully connected linear
    layer. The important thing here is to understand how we derive the values we pass
    to the `nn.Linear()` function. This is the output size of the MaxPool layer. We
    can calculate this using our output formula. We know that the output from the
    convolutional layer is the same as the input. Because the input image is square,
    we can use 28, the height or width, to represent the input, and consequently the
    output size of the convolutional layer. We also know that we have set a kernel
    size of `2`. By default, `MaxPool2d` assigns the stride to the kernel size and
    uses implied padding. For practical purposes, this means that when we use default
    values for stride and padding, we can simply divide the input, here 28, by the
    kernel size. Since our kernel size is 2, we can calculate an output size of 14\.
    Since we are using a fully connected linear layer, we need to flatten the width,
    height, and the number of channels. We have 32 channels, as set in the `out_channels`
    parameter of `nn.Conv2d`. Therefore, the input size is 16 X 14 X 14\. The output
    size is 10 because, as with the linear networks, we use the output to distinguish
    between the 10 classes.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在`__init__`方法中，您会注意到我们实例化了一个卷积层，一个`ReLU`激活函数，一个`MaxPool2d`层和一个全连接的线性层。这里重要的是理解我们如何推导传递给`nn.Linear()`函数的值。这是MaxPool层的输出大小。我们可以使用我们的输出公式来计算这个值。我们知道卷积层的输出与输入相同。因为输入图像是方形的，我们可以使用28来表示输入，因此也可以表示卷积层的输出大小。我们还知道我们设置了`2`的核大小。默认情况下，`MaxPool2d`将步幅分配给核大小，并使用隐含的填充。出于实际目的，这意味着当我们对步幅和填充使用默认值时，我们可以简单地通过核大小除以输入，这里是28。因为我们的核大小是2，我们可以计算出输出大小为14。因为我们使用了全连接的线性层，我们需要展平宽度、高度和通道数。我们有32个通道，如在`nn.Conv2d`的`out_channels`参数中设置的那样。因此，输入大小为16
    X 14 X 14。输出大小为10，因为像线性网络一样，我们使用输出来区分这10个类。
- en: 'The `forward` function of the model is fairly straightforward. We simply pass
    the `out` variable through the convolutional layer, the activation function, the
    pooling layer, and the fully connected linear layer. Notice that we need to resize
    the input for the linear layer. Assuming the batch size is `100`, the output of
    the pooling layer is a four-dimensional tensor: `100, 32, 14, 14`. Here, `out.view(out.size(0),
    -1)` reshapes this four-dimensional tensor to a two-dimensional tensor: `100,
    32*14*14`.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的`forward`函数非常简单。我们只需将`out`变量通过卷积层、激活函数、池化层和全连接的线性层。注意，我们需要为线性层调整输入大小。假设批量大小为`100`，池化层的输出是一个四维张量：`100,
    32, 14, 14`。在这里，`out.view(out.size(0), -1)`将这个四维张量重塑为一个二维张量：`100, 32*14*14`。
- en: 'To make this a little more concrete, let''s train our model and look at a few
    variables. We can use almost identical code to train the convolutional model.
    We do, however, need to change one line in our `benchmark()` function. Since convolution
    layers can accept multiple input dimensions, we do not need to flatten the width
    and height of the input. For the previous linear models, in our running code,
    we used the following to flatten the input:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使这更具体化，让我们训练我们的模型并查看一些变量。我们可以使用几乎相同的代码来训练卷积模型。但是，我们需要在我们的`benchmark()`函数中更改一行。由于卷积层可以接受多个输入维度，我们不需要展平输入的宽度和高度。对于以前的线性模型，在我们的运行代码中，我们使用以下内容来展平输入：
- en: '[PRE1]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'For our convolutional layer, we do not need to do this; we can simply pass
    the model the image, as in the following:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的卷积层，我们不需要这样做；我们可以简单地将图像传递给模型，如下所示：
- en: '[PRE2]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This line must also be changed in the `accuracy()` function we defined in the
    section on bench marking earlier in this chapter.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们之前在本章的`bench marking`部分定义的`accuracy()`函数中，我们还必须更改这一行。
- en: Building a multiple-layer CNN
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建多层CNN
- en: 'As you would expect, we can improve this result by adding another convolutional
    layer. When we are adding multiple layers, it is convenient to bundle each layer
    into a sequence. It is here that `nn.Sequential` comes in handy:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所期望的那样，我们可以通过添加另一个卷积层来改善这个结果。当我们添加多个层时，将每个层打包成一个序列是很方便的。这就是`nn.Sequential`发挥作用的地方：
- en: '![](img/5f49fd6a-83f1-471a-939b-0ada448115f9.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5f49fd6a-83f1-471a-939b-0ada448115f9.png)'
- en: We initialize two hidden layers and a fully connected linear output layer. Note
    the parameters passed to the `Conv2d` instances and the linear output. As before,
    we have one input dimension. From this, our convolutional layer outputs `16` feature
    maps or output channels.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我们初始化了两个隐藏层和一个全连接的线性输出层。注意传递给`Conv2d`实例和线性输出的参数。与以前一样，我们有一个输入维度。从这个维度，我们的卷积层输出`16`个特征图或输出通道。
- en: 'This diagram represents the two-layered convolutional network:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 这个图表代表了双层卷积网络：
- en: '![](img/d137b335-9748-4a3d-8627-bf7b083c8ee9.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d137b335-9748-4a3d-8627-bf7b083c8ee9.png)'
- en: This should make it clear how we calculate the output sizes, and in particular
    how we derive the input size for the linear output layer. We know, using the output
    formula, that the output size of the first convolutional layer, before max pooling,
    is the same as the input size, that is 28 x 28\. Since we are using 16 kernels
    or channels, generating 16 feature maps, the input to the max pooling layer is
    a 16 x 28 x 28 tensor. The max pooling layer, with a kernel size of 2, a stride
    of 2, and the default implicit padding means that we simply divide the feature
    map size by 2 to calculate the max pool out put size. This gives us an output
    size of 16 x 14 x 14\. This is the input size to the second convolutional layer.
    Once again, using the output formula, we can calculate that the second convolutional
    layer, before max pooling, generates 14 x 14 feature maps, the same size as its
    input. Since we set the number of kernels to 32, the input to the second max pooling
    layer is a 32 x 14 x 14 matrix. Our second max pooling layer is identical to the
    first, with the kernel size and stride set to 2 and default implicit padding.
    Once again, we can simply divide by 2 to calculate the output size, and therefore
    the input to the linear output layer. Finally, we need to flatten this matrix
    to one dimension. So the input size for the linear output layer is a single dimension
    of 32 * 7 * 7, or 1,568\. As usual, we need the output size of the final linear
    layer to be the number of classes, which in this case is 10.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该清楚地展示了我们如何计算输出大小，特别是我们如何推导线性输出层的输入大小。我们知道，使用输出公式，第一个卷积层在最大池化之前的输出大小与输入大小相同，即28
    x 28。由于我们使用了16个核或通道，生成了16个特征图，进入最大池化层的输入是一个16 x 28 x 28的张量。最大池化层使用2的核大小、步长2和默认的隐式填充，这意味着我们只需将特征图大小除以2即可计算最大池化输出大小。这给出了一个输出大小为16
    x 14 x 14。这是第二个卷积层的输入大小。再次使用输出公式，我们可以计算出第二个卷积层在最大池化之前生成了14 x 14的特征图，与其输入大小相同。由于我们将核的数量设置为32，进入第二个最大池化层的输入是一个32
    x 14 x 14的矩阵。我们的第二个最大池化层与第一个相同，核大小和步长设置为2，使用默认的隐式填充。再次，我们可以简单地除以2来计算输出大小，因此是线性输出层的输入。最后，我们需要将这个矩阵展平为一个维度。因此，线性输出层的输入大小是一个维度为32
    * 7 * 7，即1,568。和往常一样，我们需要最终线性层的输出大小是类的数量，本例中为10。
- en: 'We can inspect the model parameters to see that is exactly what is happening
    when we run the code:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以检查模型参数，看看在运行代码时确实发生了什么：
- en: '![](img/eaf08c21-d999-4be8-9a99-a0efaaa5fa74.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![](img/eaf08c21-d999-4be8-9a99-a0efaaa5fa74.png)'
- en: The model parameters consist of six tensors. The first tensor is the parameter
    for the first convolution layer. It consists of `16` kernels, `1` color dimension,
    and a kernel of size `5`. The next tensor is the bias and has a single dimension
    of size `16`. The third tensor in the list is the `32` kernels in the second convolutional
    layer, the `16` input channels, the depth, and the `5 x 5` kernel. In the final
    linear layer, we flattened these dimensions to `10 x 1568`.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 模型参数包括六个张量。第一个张量是第一个卷积层的参数。它包含`16`个核，`1`个颜色维度，以及大小为`5`的核。接下来的张量是偏置，具有大小为`16`的单个维度。列表中的第三个张量是第二个卷积层中的`32`个核，`16`个输入通道，深度和`5
    x 5`的核。在最后的线性层中，我们将这些维度展平为`10 x 1568`。
- en: Batch normalization
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 批归一化
- en: Batch normalization is used widely to improve the performance of neural networks.
    It works by stabilizing the distributions of layer input. This is achieved by
    adjusting the mean and variance of these input. It is fairly indicative of the
    nature of deep learning research that there is uncertainty among the researcher
    community as to why batch normalization is so effective. It was thought that this
    was because it reduces the so called **internal co-variate shift** (**ICS**).
    This refers to the change in distributions as a result of the preceding layers'
    parameter updates. The original motivation for batch normalization was to reduce
    this shift. However, a clear link between ICS and performance has not been conclusively
    found. More recent research has shown that batch normalization works by *smoothing*
    the optimization landscape. Basically, this means that gradient descent will work
    more efficiently. Details of this can be found in *How Does Batch Normalization
    Help Optimization*? by Santurkar et al., which is available at [https://arxiv.org/abs/1805.11604](https://arxiv.org/abs/1805.11604).
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 批量归一化被广泛用于提高神经网络的性能。它通过稳定化层输入的分布来工作。这是通过调整这些输入的均值和方差来实现的。在深度学习研究中，有关批量归一化如此有效的原因的研究者社区存在不确定性是相当典型的。曾经认为这是因为它减少了所谓的**内部协变量偏移**（**ICS**）。这指的是由于前面层参数更新的结果而导致的分布变化。批量归一化最初的动机是减少这种偏移。然而，ICS与性能之间的明确关联尚未得出结论性结果。更近期的研究表明，批量归一化通过*平滑化*优化的景观。基本上，这意味着梯度下降将更加有效。关于这一点的详细信息可以在Santurkar等人的文章*批量归一化如何帮助优化*中找到，可访问[https://arxiv.org/abs/1805.11604](https://arxiv.org/abs/1805.11604)。
- en: 'Batch normalization, implemented with the `nn.BatchNorm2d` function:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`nn.BatchNorm2d`函数实现的批量归一化：
- en: '![](img/6dbe5c56-c922-4935-9031-fd924e20e755.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6dbe5c56-c922-4935-9031-fd924e20e755.png)'
- en: 'This model is identical to the previous two-layer CNN with the addition of
    the batch normalization of the output of the convolutional layers. The following
    is a printout of the performance of the three convolutional networks we have built
    so far:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型与之前的双层CNN完全相同，只是在卷积层的输出上添加了批量归一化。以下是我们迄今为止构建的三个卷积网络的性能打印输出：
- en: '![](img/0f02eb2a-5cce-4b0a-9699-23bbb2857159.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0f02eb2a-5cce-4b0a-9699-23bbb2857159.png)'
- en: Summary
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we saw how we could improve the simple linear network developed
    in [Chapter 3](77e1b6da-e5d6-46a4-8a2c-ee1cfa686cc6.xhtml), *Computational Graphs
    and Linear Models*. We can add linear layers, increase the width of the network,
    increase the number of epochs we run the model, and tweak the learning rate. However,
    linear networks will not be able to capture the nonlinear features of datasets,
    and at some point their performance will plateau. Convolutional layers, on the
    other hand, use a kernel to learn nonlinear features. We saw that with two convolutional
    layers, performance on MNIST improved significantly.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们看到如何改进[第三章](77e1b6da-e5d6-46a4-8a2c-ee1cfa686cc6.xhtml)中开发的简单线性网络，*计算图和线性模型*。我们可以添加线性层，增加网络宽度，增加我们运行模型的时代数，并调整学习率。然而，线性网络将无法捕捉数据集的非线性特征，在某些时候它们的性能将会达到平台期。另一方面，卷积层使用内核来学习非线性特征。我们看到，使用两个卷积层，MNIST的性能显著提高。
- en: In the next chapter, we'll look at some different network architectures, including
    recurrent networks and long short-term networks.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将探讨一些不同的网络架构，包括循环网络和长短期网络。
