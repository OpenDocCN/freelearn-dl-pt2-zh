- en: 10 The Future of Generative Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 10 生成模型的未来
- en: Join our book community on Discord
  id: totrans-1
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 加入我们的书籍社区 Discord
- en: '[https://packt.link/EarlyAccessCommunity](https://packt.link/EarlyAccessCommunity)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.link/EarlyAccessCommunity](https://packt.link/EarlyAccessCommunity)'
- en: '![Qr code Description automatically generated](img/file65.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![自动生成的二维码描述](img/file65.png)'
- en: 'In this book, so far, we’ve discussed generative models for building applications.
    We’ve explored LLMs and image models for content creation, tool use, agent strategies,
    semantic search with retrieval augmented generation, and conditioning of models
    with prompts and fine-tuning. Further, we’ve implemented a few simple applications,
    for example, for developers and data scientists. In this chapter, we’ll discuss
    where this leaves us and where the future leads us.The pace of progress in AI
    has accelerated dramatically in the past year, with breakthroughs like DALL-E,
    Midjourney, and ChatGPT producing astounding results. These generative AI models
    can create photorealistic images, write essays and code, and have conversational
    abilities surpassing most humans. Venture funding for generative AI startups skyrocketed
    in 2022, almost matched the total investments from the previous five years combined.
    Recently, major players like Salesforce and Accenture have made big commitments
    to generative AI with multibillion dollar investments. Unique customization of
    foundation models for specific use cases is seen as the real value creation opportunity.
    But it remains uncertain which entities - big tech firms, startups, or foundation
    model developers - will capture most upside.On a technical level, generative models
    like ChatGPT often function as black boxes, with limited transparency into their
    decision-making processes. A lack of model interpretability makes it difficult
    to fully understand model behavior or to control outputs. There are also concerns
    around potential biases that could emerge from imperfect training data. On a practical
    level, generative models require extensive computational resources for training
    and deployment. For many organizations, acquiring the infrastructure to effectively
    utilize these AI systems remains a barrier.On the positive side, AI can democratize
    skills, allowing amateurs to produce professional quality output in design, writing,
    etc. Businesses can benefit from faster, cheaper, on-demand work. However, there
    are major concerns around job losses, especially for specialized middle-class
    roles like graphic designers, lawyers and doctors. Their work is being automated
    while low skilled workers learn to leverage AI as a superpower. More ominously,
    AI could be weaponized by militaries, terrorists, criminals and governments for
    propaganda and influence. Deepfakes produced in real-time will proliferate scams
    and erode trust. The path forward balances enthusiasm with practicality, prioritizing
    human dignity. By acknowledging risks, fostering open discussion, and enacting
    thoughtful policies, we can build an equitable future enabled by AI’s enlivening
    possibilities.The main sections of this chapter are:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本书中，到目前为止，我们已经讨论了用于构建应用程序的生成模型。我们探讨了LLM和图像模型用于内容创建，工具使用，代理策略，检索增强生成的语义搜索以及使用提示和微调来条件化模型。此外，我们还实现了一些简单的应用程序，例如为开发人员和数据科学家。在本章中，我们将讨论这给我们留下了什么，以及未来将引领我们何方。过去一年人工智能的进展速度急剧加快，像DALL-E，Midjourney和ChatGPT这样的突破带来了惊人的成果。这些生成式人工智能模型可以创建逼真的图像，撰写文章和代码，并具有超过大多数人类的对话能力。2022年，生成式人工智能初创公司的风险投资激增，几乎与过去五年的总投资额相匹配。最近，像Salesforce和Accenture这样的主要参与者已经做出了对生成式人工智能的数十亿美元的重大承诺。将基础模型根据特定用例进行独特定制被视为真正的价值创造机会。但尚不清楚哪些实体
    - 大型科技公司，初创公司或基础模型开发者 - 将获得最大的上升空间。从技术上讲，像ChatGPT这样的生成模型通常作为黑匣子运作，对其决策过程的透明度有限。模型可解释性的缺乏使得完全理解模型行为或控制输出变得困难。还存在关于可能由于不完善的训练数据而产生偏见的担忧。在实践层面上，生成模型需要大量的计算资源进行训练和部署。对于许多组织来说，获得有效利用这些人工智能系统的基础设施仍然是一项障碍。积极的一面是，人工智能可以使技能民主化，使业余人员能够以专业品质进行设计，写作等。企业可以从更快，更便宜，按需的工作中受益。然而，存在着关于工作岗位流失的重大担忧，特别是对于专业化的中产阶级角色，如平面设计师，律师和医生。他们的工作正在被自动化，而低技能工人则学会利用人工智能作为超能力。更不祥的是，人工智能可能会被军事，恐怖分子，罪犯和政府用于宣传和影响。实时产生的深度伪造品将推动欺诈活动并侵蚀信任。前进的道路在热情和实用性之间取得平衡，优先考虑人类尊严。通过承认风险，促进开放讨论并制定周到的政策，我们可以建立一个由人工智能活力可能性推动的公平未来。本章的主要部分包括：
- en: Current State of Generative AI
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当前生成式AI的状态
- en: Possible Future Capabilities
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可能的未来能力
- en: Societal Implications
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 社会影响
- en: Practical Implementation
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实际实施
- en: The Road Ahead
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 未来之路
- en: Let’s start from the current state of models and their capabilities.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从模型的当前状态和它们的能力开始。
- en: Current State of Generative AI
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 当前生成式AI的状态
- en: 'As discussed in this book, in recent years, generative AI models have attained
    new milestones in producing human-like content across modalities including text,
    images, audio and video. Leading models like OpenAI’s GPT-4 and DALL-E 2, Google’s
    Imagen and Parti, and Anthropic’s Claude display impressive fluency in language
    generation along with creative visual artistry.Between 2022 and 2023, models have
    progressed in strides. If generative models were previously capable to produce
    barely coherent text or grainy images, now we see high-quality 3D models, videos,
    and generate coherent and contextually relevant prose and dialogue, rivaling or
    even surpassing the fluency levels of humans. These AI models leverage gargantuan
    datasets and computational scale, enabling them to capture intricate linguistic
    patterns, display a nuanced understanding of knowledge about the world, translate
    texts, summarize content, answer natural language questions, create appealing
    visual art, and acquire the capability to describe images. Seemingly by magic,
    the AI generated outputs mimic human ingenuity — painting original art, writing
    poetry, producing human-level prose, and even engaging in sophisticated aggregation
    and synthesis of information from diverse sources. But let’s be a bit more nuanced.
    Generative Models come with weaknesses as well as strengths. Deficiencies still
    persist compared to human cognition, including the frequent generation of plausible
    yet incorrect or nonsensical statements. Hallucinations show a lack of grounding
    in reality, given that they are based on patterns in data rather than an understanding
    of the real world. Further, models exhibit difficulties performing mathematical,
    logical, or causal reasoning. They are easily confused by complex inferential
    questions, which could limit their applicability in certain fields of work. The
    black box problem of lack of explainability for predictions as well as the models
    themselves hampers troubleshooting efforts, and controlling model behaviors within
    desired parameters remains challenging. AI models may exhibit harmful unintended
    biases that pose significant ethical concerns—a problem greatly due to the biases
    present in the training data itself. This issue of bias not only skews output
    but can propagate and amplify societal disparities.Here is a table visualizing
    the key strengths and deficiencies of current LLMs compared to human cognition:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 正如本书中所讨论的，在过去几年里，生成式AI模型已经在跨模态包括文本、图像、音频和视频的人类样式内容上取得了新的里程碑。领先的模型如OpenAI的GPT-4和DALL-E
    2，Google的Imagen和Parti，以及Anthropic的Claude在语言生成方面表现出惊人的流畅性以及创造性的视觉艺术性。在2022年至2023年期间，模型取得了长足的进步。如果生成模型以前只能产生勉强连贯的文本或颗粒状的图像，现在我们看到了高质量的3D模型、视频，并生成连贯和上下文相关的散文和对话，与人类的流畅水平相媲美甚至超越。这些AI模型利用巨大的数据集和计算规模，使它们能够捕捉复杂的语言模式，展现对世界知识的细致理解，翻译文本，总结内容，回答自然语言问题，创作吸引人的视觉艺术，并获得描述图像的能力。看似神奇的是，AI生成的输出仿佛人类的智慧——绘制原创艺术品、写诗、产生人类水平的散文，甚至从各种来源复杂地聚合和合成信息。但让我们更加细致一些。生成模型除了优点外还有弱点。与人类认知相比，缺陷仍然存在，包括经常生成看似合理但错误或荒谬的陈述。幻觉显示出缺乏现实基础，因为它们基于数据中的模式而不是对真实世界的理解。此外，模型在进行数学、逻辑或因果推理方面存在困难。它们很容易被复杂的推理问题所困扰，这可能限制它们在某些工作领域的适用性。对于预测以及模型本身缺乏可解释性的黑匣子问题阻碍了故障排除工作，并且在所需参数内控制模型行为仍然具有挑战性。AI模型可能表现出有害的意外偏见，这引发了重大的道德关切——这个问题主要是由训练数据本身存在的偏见所致。这个偏见问题不仅会扭曲输出，还会传播和放大社会的不平等。以下是一张表，将当前LLM相对于人类认知的主要优势和不足之处可视化：
- en: '| **Strengths of LLMs** | **Deficiencies of LLMs** |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
  zh: '| **LLM的优势** | **LLM的不足之处** |'
- en: '| --- | --- |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Language Fluency - Ability to generate grammatically coherent, contextual
    prose and dialogue. GPT-4 produces human-level prose. | Factual Accuracy - LLMs
    frequently generate plausible but incorrect or nonsensical statements. Lack of
    grounding in reality. |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
  zh: '| 语言流畅性 - 能够生成语法连贯、上下文相关的散文和对话。GPT-4能够产生人类水平的散文。 | 事实准确性 - LLM经常生成看似合理但错误或荒谬的陈述。缺乏现实基础。
    |'
- en: '| Knowledge Synthesis - Sophisticated aggregation and presentation of information
    from diverse sources. | Logical Reasoning - Inability to perform mathematical,
    logical or causal reasoning. Easily confused by complex inferential questions.
    |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
  zh: '| 知识综合 - 多元来源信息的复杂聚合和展示。 | 逻辑推理 - 无法进行数学、逻辑或因果推理。容易被复杂的推理问题所困扰。 |'
- en: '| Creative Output - Imaginative and original text, art, music reflecting human
    ingenuity. Claude writes poetry, DALL-E 2 paints original art. | Controllability
    - Difficulty constraining model behaviors within desired parameters. Can exhibit
    harmful unintended biases. |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
  zh: '| 创造性输出 - 反映人类创造力的想象力和原创文本、艺术、音乐。克劳德写诗，DALL-E 2 绘制原创艺术。 | 可控性 - 难以限制模型行为在期望的参数内。可能展现出有害的意外偏见。
    |'
- en: '|  | Bias - Potential to propagate and amplify societal biases present in training
    data. Raises ethical concerns. |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '|  | 偏见 - 有可能传播和放大训练数据中存在的社会偏见。引发了伦理关切。 |'
- en: '|  | Transparency - Lack of explainability for model predictions. The "black
    box" problem limits troubleshooting. |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '|  | 透明度 - 对模型预测的可解释性缺乏。"黑盒子"问题限制了故障排除。 |'
- en: 'Figure 10.1: Strengths and Deficiencies of LLMs.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.1：LLM 的优势和不足。
- en: While generative AI capabilities have come a long way, their problematic areas
    need addressing for these technologies to effectively function in the future.
    Nonetheless, their profound potential indicates an exciting future if developed
    and regulated responsibly.The weaknesses of generative models define some of the
    technical challenges, as we’ll see now.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '尽管生成式人工智能的能力已经取得了长足的进步，但它们存在的问题领域需要解决，以便这些技术能够在未来有效地发挥作用。尽管如此，它们的深远潜力预示着一个令人兴奋的未来，如果能够负责任地开发和监管。生成模型的弱点定义了一些技术挑战，我们现在将看到。 '
- en: Technical Challenges
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 技术挑战
- en: 'While rapid progress has been made, significant technical obstacles remain
    to realize the full potential of generative AI safely and responsibly. As mentioned,
    generative AI models, despite their considerable advances, are grappling with
    significant technical challenges that need to be overcome to allow their full
    potential to be harnessed safely and responsibly. We’ve discussed some of these
    issues and potential solutions in previous chapters.This table shows a summary
    for a few of these challenges together with the technical approaches to tackle
    them:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管取得了快速进展，但要安全、负责任地实现生成式人工智能的全部潜力仍然存在重大技术障碍。正如前面提到的，尽管生成式人工智能模型取得了相当大的进步，但它们仍然面临着重大的技术挑战，需要克服这些挑战才能安全、负责任地发挥其全部潜力。我们已经在之前的章节中讨论了其中一些问题和潜在解决方案。这张表总结了其中一些挑战以及解决这些挑战的技术方法的概况：
- en: '| **Challenge** | **Description** | **Potential Solutions** |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| **挑战** | **描述** | **潜在解决方案** |'
- en: '| --- | --- | --- |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Realistic and Diverse Content Generation | Existing models struggle with
    logical consistency and factual plausibility. Generates repetitive, bland samples
    lacking human nuance. | Reinforcement learning from human feedback Data augmentation
    and synthesis techniquesModular domain knowledge |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| 真实多样的内容生成 | 现有模型在逻辑一致性和事实可信度方面存在困难。生成的样本重复、乏味，缺乏人类细微差别。 | 通过人类反馈进行强化学习数据增强和综合技术模块化领域知识
    |'
- en: '| Output Quality Control | Lack of mechanisms to reliably constrain properties
    of generated content. Models sporadically produce harmful, biased or nonsensical
    results. | Constrained optimization objectivesModeration systemsInterruption and
    correction techniques |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| 输出质量控制 | 缺乏可靠约束生成内容属性的机制。模型偶尔产生有害、偏见或荒谬的结果。 | 受限优化目标调节系统中断和校正技术 |'
- en: '| Avoiding Bias | Models inadvertently amplify societal biases present in training
    data. Developing techniques to curtail prejudice remains difficult. | Balanced
    and representative training dataBias mitigation algorithmsOngoing testing and
    audits |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| 避免偏见 | 模型无意中放大了训练数据中存在的社会偏见。开发技术来削减偏见仍然很困难。 | 平衡和代表性的训练数据偏见缓解算法持续的测试和审计 |'
- en: '| Factual Accuracy | Inability to reason about objective truths limits reliability
    for real-world applications. Grounding models in common sense and physics is an
    open problem. | Incorporating knowledge basesHybrid neuro-symbolic architecturesRetrieval
    augmented generation |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| 事实准确性 | 无法推理客观真相限制了其在现实世界应用中的可靠性。基于常识和物理学的模型是一个未解之谜。 | 整合知识库混合神经符号架构检索增强生成
    |'
- en: '| Explainability | The opaque behavior of large neural networks poses hurdles
    for troubleshooting failures or bias, necessitating explainable AI techniques.
    | Model introspection techniquesConcept attribution methodsSimplified model architectures
    |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| 可解释性 | 大型神经网络的不透明行为对故障排除或偏见构成障碍，因此需要可解释的人工智能技术。 | 模型内省技术概念归因方法简化模型架构 |'
- en: '| Data Privacy | Collecting and processing massive datasets raises challenges
    around consent, anonymization, access control and misuse of data. | Differential
    privacy and secure multi-party computationSynthetic data generationFederated learning
    |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| 数据隐私 | 收集和处理大规模数据集会带来关于同意、匿名化、访问控制和数据滥用的挑战。 | 差分隐私和安全多方计算合成数据生成联邦学习 |'
- en: '| Latency and Compute | Deploying huge models requires substantial computing
    resources, delaying real-time interactivity needed for many applications. | Model
    distillation into smaller form factorsOptimized inference enginesDedicated AI
    hardware accelerators |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| 延迟和计算 | 部署庞大的模型需要大量计算资源，延迟了许多应用所需的实时交互。 | 将模型压缩为更小的形式优化推断引擎专用的人工智能硬件加速器 |'
- en: '| Data Licenses | Organizations may need to obtain a commercial license to
    use existing datasets or to build bespoke datasets to train generative models.
    This can be a complex and time-consuming process. | Open-source and synthetic
    data |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| 数据许可证 | 组织可能需要获取商业许可证来使用现有数据集或构建定制数据集来训练生成模型。这可能是一个复杂和耗时的过程。 | 开源和合成数据 |'
- en: 'Figure 10.2: Technical Challenges and Potential Solutions.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.2：技术挑战和潜在解决方案。
- en: 'Primarily, the content generated by these models is often hindered by a lack
    of realism and diversity. While they have displayed impressive abilities to mimic
    human-like language and creativity, they still falter when it comes to producing
    content that is logically consistent and factually plausible. Their outputs often
    lack human nuance turning out to be quite repetitive and bland. Potential solutions
    include reinforcement learning from human feedback to improve coherence and nuance,
    controlled data augmentation and synthesis techniques, and architectures incorporating
    modular domain knowledge.Another critical hurdle is the control of output quality.
    Despite rigorous training and development, existing AI mechanisms fall short in
    reliably constraining properties of the generated content. This results in sporadic
    production of content that can be harmful, biased or outright nonsensical, posing
    a risk to their wider acceptance and application. Promising approaches involve
    constrained optimization objectives, human-in-the-loop moderation systems, and
    techniques to interrupt and correct model output during generation.Bias is indeed
    a major issue with these AI models as they frequently and inadvertently amplify
    societal prejudices present in their training data. Developing corrective techniques
    to curtail such biases remains a complicated issue. Strategies like balanced and
    representative training data, bias mitigation algorithms, and ongoing testing
    and audits for fairness seek to address this problem.The inability of these AI
    models to reason about objective truths noticeably limits their reliability for
    real-world applications. Grounding these models in common sense and physics represents
    an open problem that the AI community is still grappling with. Hybrid neuro-symbolic
    architectures, incorporation of knowledge bases, and retrieval augmented generation
    offer promising directions.The black box nature of AI presents another complex
    challenge: explainability. The opaque behavior of large neural networks poses
    hurdles for troubleshooting failures or bias, which emphasizes the need for more
    transparent AI techniques. Model introspection, concept attribution methods, and
    simplified model architectures could provide solutions.Furthermore, the issue
    of data privacy rises to prominence due to the collection and processing of extensive
    datasets. This aspect introduces challenges around consent, anonymization, access
    control and misuse of data. Techniques like differential privacy, secure multi-party
    computation, synthetic data generation, and federated learning may help address
    privacy risks.Last but not least, deploying these enormous models demands substantial
    computing resources, leading to significant latency and compute issues. This could
    delay the real-time interactivity required for many applications, indicating that
    efficiency improvements are key. Solutions involve model distillation into smaller
    form factors, optimized inference engines, and dedicated AI hardware accelerators.Looking
    ahead, generative AI systems are poised to become more powerful and multifaceted.
    Let’s see how!'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 主要的问题是，这些模型生成的内容通常受到缺乏现实感和多样性的限制。尽管它们展示了令人印象深刻的能力来模仿类似人类的语言和创造力，但在生成逻辑一致且事实可信的内容方面，它们仍然表现不佳。它们的输出往往缺乏人类的细微差别，结果变得相当重复和单调。潜在的解决方案包括从人类反馈中进行强化学习以提高连贯性和细微差别，受控数据增强和合成技术，以及结合模块化领域知识的架构。另一个关键障碍是控制输出质量。尽管经过严格的培训和开发，现有的AI机制在可靠地约束生成内容的属性方面仍然不足。这导致不时产生可能有害、带有偏见或完全荒谬的内容，这对它们的广泛接受和应用构成了风险。有希望的方法包括约束优化目标、人在循环调节系统，以及在生成过程中中断和更正模型输出的技术。偏见确实是这些AI模型的一个主要问题，因为它们经常无意中放大了埋藏在训练数据中的社会偏见。开发纠正这种偏见的技术仍然是一个复杂的问题。像平衡和代表性训练数据、偏见缓解算法，以及为公平性进行持续测试和审计的策略都旨在解决这个问题。这些AI模型无法推理客观事实的能力明显限制了它们在现实世界应用中的可靠性。将这些模型基于常识和物理学进行建模是AI社区仍在努力解决的一个悬而未决的问题。混合神经符号结构、知识库的整合，以及检索增强生成都提供了有希望的方向。AI的黑箱性质提出了另一个复杂的挑战：可解释性。大型神经网络的不透明行为为故障排除或偏见设置了障碍，这强调了对更透明的AI技术的需求。模型内省、概念归因方法以及简化模型架构可能提供解决方案。此外，由于对大量数据集的收集和处理，数据隐私问题变得突出起来。这一方面引入了关于同意、匿名化、访问控制和数据滥用的挑战。差分隐私、安全多方计算、合成数据生成和联邦学习等技术可能有助于解决隐私风险。最后但同样重要的是，部署这些庞大模型需要大量的计算资源，导致显著的延迟和计算问题。这可能会延迟许多应用所需的实时交互性，这表明提高效率是关键。解决方案包括将模型压缩成更小的形式因子、优化推理引擎和专用的AI硬件加速器。展望未来，生成式AI系统有望变得更加强大和多样化。让我们拭目以待！
- en: Possible Future Capabilities
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可能的未来能力
- en: 'The current doubling time in training compute of very large models is about
    8 months, outstripping scaling laws such as Moore’s Law (transistor density at
    cost increases at a rate of currently about 18 months) or Rock’s Law (costs of
    hardware like GPUs and TPUs halve every 4 years).This graph illustrates this trend
    in training compute of large models (Source: Epoch, *Parameter, Compute and Data
    Trends in Machine Learning*. Published online at epochai.org. Retrieved from:
    https://epochai.org/mlinputs/visualization):'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，非常大型模型的训练计算的加倍时间约为8个月，超过了莫尔定律（晶体管密度的成本每18个月增加一倍）或洛克定律（像GPU和TPU这样的硬件成本每4年减半）等缩放定律。这张图表明了大型模型训练计算的这一趋势（来源：Epoch，《机器学习中参数、计算和数据趋势》。在线发布在epochai.org。检索自：https://epochai.org/mlinputs/visualization）：
- en: '![Figure 10.3: Training FLOPs of notable AI systems.](img/file66.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![图10.3：显著AI系统的训练FLOPs。](img/file66.png)'
- en: 'Figure 10.3: Training FLOPs of notable AI systems.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.3：显著AI系统的训练FLOPs。
- en: As discussed in chapter 1, parameter sizes for large systems have been increasing
    at a similar rate as the training compute, which means that we could be seeing
    much larger and more expensive systems if this growth continues. Empirically derived
    scaling laws predict the performance of LLMs based on the training budget, dataset
    size, and the number of parameters. This could mean that highly powerful systems
    would be concentrated in the hands of Big Tech.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 正如第1章所讨论的，大型系统的参数规模正在以与训练计算相似的速度增长，这意味着如果这种增长持续下去，我们可能会看到更大更昂贵的系统。经验推导的缩放定律预测了基于训练预算、数据集大小和参数数量的LLM性能。这意味着高度强大的系统可能会集中在大型科技公司手中。
- en: The **KM scaling** law, proposed by Kaplan and colleagues, derived through empirical
    analysis and fitting of model performance with varied data sizes, model sizes,
    and training compute, presents power-law relationships, indicate a strong dependence,
    between model performance and factors such as model size, dataset size, and training
    compute.
  id: totrans-41
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**KM缩放**定律，由Kaplan和同事提出，通过对模型性能与不同数据大小、模型大小和训练计算的拟合进行经验分析，提出了幂律关系，表明了模型性能与模型大小、数据集大小和训练计算等因素之间的强烈依赖关系。'
- en: ''
  id: totrans-42
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The **Chinchilla scaling law**, developed by the Google DeepMind team, involved
    experiments with a wider range of model sizes and data sizes, and suggests an
    optimal allocation of compute budget to model size and data size, which can be
    determined by optimizing a specific loss function under a constraint.
  id: totrans-43
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**Chinchilla缩放定律**，由Google DeepMind团队开发，涉及对更广泛范围的模型大小和数据大小进行实验，并建议将计算预算最优地分配到模型大小和数据大小，这可以通过在约束条件下优化特定损失函数来确定。'
- en: 'However, future progress may depend more on data efficiency and model quality
    than sheer size. Though massive models grab headlines, computing power and energy
    constraints put a limit on unrestrained model growth. The future will see co-existence
    of massive, general models with smaller and accessible specialized niche models
    that provide faster and cheaper training, maintenance, and inference. It has already
    been shown that smaller specialized models can prove highly performant. We’ve
    recently seen models such as phi-1 (*Textbooks Are All You Need*, 2023, Gunasekar
    and colleagues), on the order of 1 billion parameters, that – despite its smaller
    scale – achieve high accuracy on evaluation benchmarks. The authors suggest that
    improving data quality can dramatically change the shape of scaling laws.More
    work has shown that models can be substantially smaller with only a modest drop
    in accuracy (*One Wide Feedforward is All You Need*, Pessoa Pires and others,
    2023), which supports the argument for a democratization of model training and
    access. Further, techniques such as transfer learning, distillation and prompting
    techniques can enable smaller models to leverage capabilities of large foundations
    without replicating their costs. In order to compensate for limitations, tools
    like search engines and calculators have been incorporated into agents and multi-step
    reasoning strategies, plugins, and extensions may be increasingly used to expand
    capabilities.AI training costs are dropping because of different factors – according
    to ARK Investment Management LLC, about 70% per year. A recently released AI training
    tools by Mosaic ML can train language models to GPT-3 level performance for roughly
    one-tenth the estimated $4.6 million just two years ago. This will enable experimentation,
    but advances will increasingly emerge from training regimes, data quality, and
    novel architectures rather than model size alone. After an arms race dominated
    by resource-rich big tech firms, responsible, economical innovation may become
    the priority.In a timeframe of 3-5 years (2025-2027), constraints around computing
    and talent availability could ease considerably, eroding the centralized moat.
    Specifically, if cloud computing costs decline as projected, and AI skills become
    more widespread through education and automated tools, self-training customized
    LLMs may become feasible for many companies. This could better serve needs for
    personalization and data privacy.Some abilities, however, such as in-context learning,
    are not predictable according to the scaling laws and only emerge in large models.
    It has been further speculated that enormous models trained on even more data
    may exhibit more behaviors and skills, where extreme scaling could eventually
    produce **artificial general intelligence** (**AGI**) – reasoning on par or beyond
    human intellect. However, from a neuroscience perspective, the threat of AGI taking
    over the world seems highly exaggerated at our present stage of technology (compare
    Jaan Aru and others, *The feasibility of artificial consciousness through the
    lens of neuroscience*; 2023):'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 未来的进展可能更多地取决于数据效率和模型质量，而不是纯粹的规模大小。尽管庞大的模型抓住了头条，但计算能力和能源限制限制了模型的不受限制的增长。未来将会看到庞大、通用模型与更小、可访问的专业化细分模型共存，这些模型提供更快、更便宜的培训、维护和推理。已经有研究表明，更小的专业化模型可以表现出很高的性能。我们最近看到了像phi-1（*只需教科书*，2023年，Gunasekar和同事）这样的模型，拥有10亿个参数数量级，尽管规模较小，但在评估基准上却能取得高精度。作者认为，提高数据质量可以极大地改变规模定律的形态。更多的工作表明，模型可以大大缩小，而精度只会略微降低（*只需一个宽度的前馈*，Pessoa
    Pires等人，2023年），这支持了对模型训练和访问的民主化的论点。此外，迁移学习、蒸馏和提示技术等技术可以使更小的模型利用大型基础的能力，而不需要复制它们的成本。为了弥补限制，像搜索引擎和计算器这样的工具已经被纳入到代理人和多步推理策略中，插件和扩展可能越来越多地用于扩展功能。由于不同因素的影响，AI培训成本正在下降——根据ARK投资管理有限责任公司的数据，约为每年70%。最近由Mosaic
    ML发布的AI培训工具可以将语言模型培训到与GPT-3相同水平的性能，成本大约只有两年前估计的460万美元的十分之一。这将促进实验，但进步将更多地来自培训制度、数据质量和新型架构，而不仅仅是模型的大小。在由资源丰富的大型科技公司主导的军备竞赛之后，负责任的、经济实惠的创新可能成为优先事项。在3-5年的时间范围内（2025-2027年），围绕计算和人才可用性的限制可能会大大缓解，削弱了中心化壕沟。具体来说，如果云计算成本如预期般下降，而且AI技能通过教育和自动化工具变得更加普及，那么自我训练定制的LLM可能对许多公司来说变得可行。这可以更好地满足个性化和数据隐私的需求。然而，有些能力，如上下文学习，根据规模定律是不可预测的，只会在大型模型中出现。进一步推测，即使在更多数据的基础上训练出巨大的模型，也可能表现出更多的行为和技能，极端的规模化最终可能会产生**人工通用智能**（**AGI**）——与或超出人类智力相当的推理。然而，从神经科学的角度来看，在我们当前的技术阶段，AGI接管世界的威胁似乎被夸大了（参见Jaan
    Aru等人，*通过神经科学的视角审视人工意识的可行性*；2023年）：
- en: '**Lack of embodied, embedded information**: LLMs today are trained purely on
    textual data rather than the rich multimodal inputs that allow humans to develop
    common sense reasoning about the physical world. This absence of grounded learning
    poses a major obstacle to developing human-level intelligence.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**缺乏具象、嵌入信息**：当前的大型语言模型仅在文本数据上接受训练，而不是像人类那样通过丰富的多模态输入来发展对物理世界的常识推理。这种缺乏扎根的学习给发展人类级别的智能带来了重大障碍。'
- en: '**Different architecture from biological brains**: The relatively simple stacked
    transformer architecture used in models like GPT-4 lacks the complex recurrent
    and hierarchical structures of the thalamocortical system thought to enable consciousness
    and general reasoning in humans.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**与生物大脑的不同架构**：类似GPT-4这样的模型中使用的相对简单的堆叠变压器架构缺乏被认为能够启动人类意识和一般推理的复杂经常性和层次性结构。'
- en: '**Narrow capabilities**: Existing models remain specialized for particular
    domains like text and fall short in flexibility, causal reasoning, planning, social
    skills, and general problem-solving intelligence. This could change either with
    increasing tool use or with fundamental changes to the models.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**狭窄的能力**：现有模型仍然专门针对特定领域，如文本，并在灵活性、因果推理、规划、社交技能和一般问题解决智能方面表现不佳。这种情况可能会随着工具使用的增加或模型的根本性变化而改变。'
- en: '**Minimal social abilities or intent**: Current AI systems have no innate motivations,
    social intelligence, or intent beyond their training objectives. Fears of malicious
    goals or desire for domination seem unfounded.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**社会能力或意图有限**：当前的人工智能系统没有固有动机、社交智能或超出培训目标的意图。对恶意目标或对统治的欲望的担忧似乎没有根据。'
- en: '**Limited real-world knowledge**: Despite ingesting huge datasets, the factual
    knowledge and common sense of large models remains very restricted compared to
    humans. This impedes applicability in the physical world.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**有限的现实世界知识**：尽管摄取了大量数据集，大型模型的事实知识和常识与人类相比仍然非常有限。这影响了在物理世界中的适用性。'
- en: '**Data-driven limitations**: Reliance on pattern recognition from training
    data rather than structured knowledge makes reliable generalization to novel situations
    difficult.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于数据驱动的局限性**：依赖于训练数据中的模式识别，而非结构化知识，使得可靠地推广到新颖情况变得困难。'
- en: Given these arguments, the risk of today’s AI precipitously evolving into malicious
    superintelligence seems highly improbable. That said, thoughtfully addressing
    longer-term safety research and ethics remains prudent as capabilities continue
    advancing. But fears of imminent world takeover are not substantiated by evidence
    from neuroscience or current model capabilities. Therefore, claims of inevitable,
    imminent AGI lack rigorous support.However, the sheer pace of advancement creates
    unease surrounding human obsolescence and job displacement, which could further
    divide economic classes. Unlike physical automation of the past, generative AI
    threatens cognitive job categories previously considered safe from automation.
    Managing this workforce transition ethically and equitably will require foresight
    and planning. There are also philosophical debates around whether AI should be
    creating art, literature or music that has historically reflected the human condition.
    Let’s think a bit more broadly about the societal impact!
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于这些论点，如今人工智能迅速演化为恶意超级智能的风险似乎高度不太可能。也就是说，随着能力不断提升，深思熟虑地处理长期安全研究和伦理问题仍然是明智之举。但是，当前神经科学或模型能力的证据并不支持对即将到来的人工智能普遍性的不可避免和迫在眉睫的主张。然而，快速进步的速度引发了人类淘汰和失业的担忧，这可能进一步分化经济阶级。与过去的物理自动化不同，生成式人工智能威胁到先前被认为免于自动化的认知工作类别。道德和公平地管理这种劳动力转型将需要远见和规划。还有关于人工智能是否应该创作反映人类状况的艺术、文学或音乐的哲学辩论。让我们更广泛地考虑社会影响吧！
- en: Societal Implications
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 社会影响
- en: The advent of highly capable generative AI will likely transform many aspects
    of society in coming years. As generative models continue to develop and add value
    to businesses and creative projects, generative AI will shape the future of technology
    and human interaction across domains. While their widespread adoption brings forth
    numerous benefits and opportunities for businesses and individuals, it is crucial
    to address the ethical and societal concerns that arise from increasing reliance
    on AI models in various fields.Generative AI offers immense potential benefits
    across personal, societal, and industrial realms if deployed thoughtfully. At
    a personal level, these models can enhance creativity and productivity, and increase
    accessibility to services like healthcare, education and finance. Democratizing
    access to knowledge resources, they can help students learn or aid professionals
    make decisions by synthesizing expertise. As virtual assistants, they provide
    instant, customized information to facilitate routine tasks. By automating rote
    tasks, they may free up human time for higher-value work, boosting economic output.
    Economically, the gains in productivity will most likely result in massive disruptions
    of certain job categories. New industries and jobs may emerge to support AI systems.
    Thoughtfully considering and addressing these changes is crucial. As models become
    better and running them becomes cheaper, this could trigger a massive expansion
    of generative AI and LLM applications to new areas. On top of the reduction in
    hardware costs, with every cumulative doubling of AI systems produced, costs may
    fall by 10-30% according to Wright’s Law. This cost curve reflects efficiencies
    like reuse of code, tools and techniques. A virtuous cycle arises as lower costs
    expand adoption, which drives further cost reductions. This will lead to a feedback
    cycle of more efficiency driving more use driving more efficiency.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 高度完善的生成式人工智能的出现很可能会在未来几年改变社会的许多方面。随着生成模型的不断发展和为企业和创意项目增加价值，生成式人工智能将塑造技术和人类交互在各个领域的未来。尽管它们的广泛应用为企业和个人带来了许多好处和机遇，但对于日益依赖各个领域的AI模型所引发的伦理和社会问题，有必要加以重视和解决。如果能够慎重部署，生成式人工智能在个人、社会和工业领域都能带来巨大的潜在好处。在个人层面，这些模型可以增强创造力和生产力，增加对健康、教育和金融等服务的可及性。它们能够使知识资源的获取民主化，通过综合专业知识帮助学生学习或为专业人士做决策。作为虚拟助手，它们能够提供即时定制的信息，以便完成例行任务。通过自动化机械任务，它们可能会释放出人类的时间，从而提高更高价值工作的经济产出。从经济上讲，生产力的提高很可能会导致某些工作类别的大规模中断。新兴产业和工作可能会出现来支持AI系统。认真考虑和解决这些变化是至关重要的。随着模型的不断改进和运行成本的降低，这可能会触发生成式人工智能和LLM应用在新领域大规模扩展。除了硬件成本的降低外，根据赖特定律，随着每次累计生产倍增，成本可能会以10-30%的速度下降。这种成本曲线反映了诸如代码、工具和技术的重复利用等效率。随着成本的降低扩大了采用率，进一步推动了成本的降低。这将导致一个反馈周期，更多的效率推动更多的使用驱动更多的效率。
- en: '**Wright’s Law**, also known as the **experience curve effect**, is an observation
    in economics and business that states that for many products, costs decline by
    a fixed percentage each time cumulative production doubles. Specifically, it states
    that costs tend to decrease by a fixed percentage (typically ranging from 10-30%)
    for each cumulative doubling of production.'
  id: totrans-54
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**赖特定律**，又称**经验曲线效应**，是经济学和商业领域的一项观察，它指出对于许多产品，成本在每次累计生产翻倍时都会以固定百分比下降。具体来说，它指出在每次累计生产翻倍时，成本
    tend to decrease by a fixed percentage（通常在10-30%范围内）。'
- en: ''
  id: totrans-55
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The law is named after Theodore Paul Wright, an American aircraft engineer who
    first observed this phenomenon in 1936 when analyzing trends in aircraft production
    costs. Wright noticed that every time the cumulative production of airframes doubled,
    the labor required to produce them decreased by 10-15%.
  id: totrans-56
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 该定律以西奥多·保罗·赖特命名，他是一位美国飞机工程师，于1936年在分析飞机生产成本趋势时首次观察到这一现象。赖特注意到，每当飞机机身的累计生产量翻倍时，生产所需的劳动力就会减少10-15%。
- en: ''
  id: totrans-57
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'This relationship can be expressed mathematically as:'
  id: totrans-58
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这种关系可以用数学方式表达为：
- en: ''
  id: totrans-59
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](img/file67.png)'
  id: totrans-60
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_IMG
  zh: '![](img/file67.png)'
- en: ''
  id: totrans-61
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Where *C*[1] represents the cost to produce the first unit, *C*[*x*] the cost
    to produce the xth unit, and b is the progress ratio, which has been estimated
    across numerous industries between 0.75 to 0.9.
  id: totrans-62
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 其中，*C*[1]代表生产第一单位的成本，*C*[*x*]代表生产第x单位的成本，b代表进步比率，该比率在许多行业估计在0.75到0.9之间。
- en: ''
  id: totrans-63
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The logic behind Wright’s Law is that as production increases, workers become
    more efficient in manufacturing a product through practice, standardized workflows,
    and developing better tools and processes. Companies also identify ways to optimize
    supply chains, logistics and resource utilization to reduce costs.
  id: totrans-64
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 沃特定律背后的逻辑是随着生产增加，工人通过实践、标准化工作流程和开发更好的工具和流程，在制造产品方面变得更加高效。公司还会找到优化供应链、物流和资源利用的方法，以降低成本。
- en: Industrially, the models bring extensive opportunities to augment human capabilities
    and remake workflows. In content production, generative AI can draft initial versions
    for marketing campaigns or journalistic pieces faster than humans, enabling greater
    creativity and customization. For developers, autogenerated code and rapid iterations
    accelerate software building. Researchers can quickly synthesize discoveries from
    papers to advance science.Generative AI also facilitates new levels of personalization
    at scale for consumers. Recommendations can be tailored down to the individual.
    Marketing across segments and geographies can be customized. Overall, these models
    can enhance productivity across sectors from industrial design to supply chains.As
    for the spread of the technology, two primary scenarios exist. In the first scenario,
    each company or individual trains their own tailored model using their proprietary
    data. However, this requires considerable AI/ML expertise to properly develop,
    train and deploy such systems - talent that remains scarce and expensive currently.
    The computational costs are also extremely high, with specialized hardware like
    clusters of GPUs costing substantial sums only feasible for large entities. There
    are further risks around data privacy compliance when models are trained on sensitive
    information. If these barriers around expertise, computing requirements and data
    privacy can be overcome, personalized LLMs fine-tuned to an organization’s particular
    goals and data could significantly enhance their productivity and efficiency by
    automating routine tasks and offering insights customized to the specific business.
    However, a downside is that models trained on small, private datasets may lack
    the generalization capability of those trained on much larger diverse public corpuses.Both
    centralized and self-service models can co-exist serving different use cases.
    In the near term, large tech firms have strengths in providing industry-specific
    fine-tuning services given their resources. But over time, more in-house training
    may emerge driven by customization and privacy needs.The pace of progress on reducing
    costs, spreading expertise, and addressing robustness challenges will determine
    how long any centralized advantage persists. Rapid innovations in these areas
    favor erosion of the moat, but platform effects around dominant frameworks, datasets
    and models could enable continued concentration among current leaders.If robust
    tools emerge to simplify and automate AI development, custom generative models
    may even be viable for local governments, community groups, and individuals to
    address hyper-local challenges. While centralized Big Tech firms benefit currently
    from economies of scale, distributed innovation from smaller entities could unlock
    generative AI’s full potential across all sectors of society.Finally, the emergence
    of generative AI intersects with broader shifts in how we produce and consume
    creative works. The internet has already fostered a remix culture where derivative
    works and collaborative content creation are commonplace. As AI models generate
    new artifacts by recombining existing materials, they align with remix culture
    principles of iterative, collective production.However, the scale at which generative
    models can synthesize and repurpose copyrighted content raises challenging legal
    questions. With models trained on vast datasets of books, articles, images and
    more, attributing rights and royalties could become incredibly complex. Current
    detection mechanisms are unable to find content authored by generative AI at above
    chance level. This speaks to wider debates surrounding authorship and copyright
    law.Let’s look at the different aspects, where generative models will have profound
    near-term impacts, starting with creative endeavors.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在工业上，这些模型带来了广泛的机会，可以增强人类的能力并改变工作流程。在内容生产中，生成式人工智能可以比人类更快地为营销活动或新闻报道起草初稿，从而促进更大的创造力和定制。对于开发人员，自动生成的代码和快速迭代可以加快软件构建的速度。研究人员可以快速从论文中综合出新的发现，推动科学的进步。生成式人工智能还可以以大规模进行个性化定制。推荐内容可以精细到个人。市场推广可以针对不同的细分市场和地理位置进行定制。总的来说，这些模型可以提高从工业设计到供应链等各个领域的生产率。至于这项技术的推广，存在两种主要的情景。在第一种情况下，每家公司或个人都会使用自己的专有数据来训练定制模型。然而，这需要相当的人工智能/机器学习专业知识才能正确地开发、训练和部署这样的系统——这样的专业人才目前依然稀缺且昂贵。计算成本也极其高昂，专门的硬件如大量昂贵的GPU集群只适用于大型实体。在模型以敏感信息进行训练时也存在进一步的数据隐私合规风险。如果这些围绕专业知识、计算要求和数据隐私的障碍能够克服，那么精细调整的LLM（大语言模型）可以显著提高组织的生产率和效率，通过自动化例行任务和提供适合特定业务的见解。然而，一个缺点是在小型私有数据集上训练的模型可能缺乏大规模公共语料库上训练的模型的泛化能力。集中式和自助式模型可以共存，为不同的用例提供服务。短期内，大型科技公司在提供行业特定的精细调整服务方面具有优势。但随着时间的推移，更多的内部训练可能会出现，这是由定制和隐私需求驱动的。降低成本、传播专业知识和解决健壮性挑战的进展速度将决定集中式优势的持续时间。在这些领域的快速创新有利于瓦解留下的障碍，但围绕主导性框架、数据集和模型的平台效应可能使当前领导者继续聚集。如果出现了简化和自动化人工智能开发的强大工具，定制的生成模型甚至可能对地方政府、社区组织和个人来应对超局部挑战具有可行性。尽管目前大型科技公司受益于规模经济，但由小型实体驱动的分布式创新可能会释放生成式人工智能在社会各个领域的全部潜力。最后，生成式人工智能的出现与我们如何生产和消费创意作品的更广泛变化相交。互联网已经培育出了一个混搭文化，其中衍生作品和协作内容的创建非常普遍。随着人工智能模型通过重新组合现有材料生成新的作品，它们符合混搭文化的迭代、集体生产原则。然而，生成模型可以合成和重新利用受版权保护的内容的规模提出了棘手的法律问题。利用广泛数据集训练的模型，包括书籍、文章、图像等，归因权和版税问题可能变得非常复杂。当前的检测机制无法以高于机会水平的准确率找到由生成式人工智能创作的内容。这反映出了围绕作者身份和版权法的更广泛争论。让我们来看看生成模型在不同方面将产生深远的近期影响，从创意努力开始。
- en: Creative industries and advertising
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 创意产业和广告
- en: The gaming and entertainment industries are leveraging generative AI to craft
    uniquely immersive user experiences. Major efficiency gains from automating creative
    tasks could increase leisure time spent online. Generative AI can enable machines
    to generate new and original content, such as art, music, and literature, by learning
    from patterns and examples. This has implications for creative industries, as
    it can enhance the creative process and potentially create new revenue streams.
    It also unlocks new scales of personalized, dynamic content creation for media,
    film, and advertising. However, generative content requires extensive quality
    control around accuracy and eliminating biases before full deployment.For media,
    film, and advertising, AI unlocks new scales of personalized, dynamic content
    creation. In journalism, automated article generation using massive datasets can
    free up reporters to focus on more complex investigative stories. **AI-generated
    content** (**AIGC**) is playing a growing role in transforming media production
    and delivery by enhancing efficiency and diversity. In journalism, text generation
    tools automate writing tasks traditionally done by human reporters, significantly
    boosting productivity while maintaining timeliness. Media outlets like Associated
    Press generate thousands of stories per year using AIGC. Robot reporters like
    Los Angeles Times’ Quakebot can swiftly produce articles on breaking news. Other
    applications include Bloomberg News’ Butletin service where chatbots create personalized
    one-sentence news summaries. AIGC also enables AI news anchors that co-present
    broadcasts with real anchors by mimicking human appearance and speech from text
    input. Chinese news agency Xinhua’s virtual presenter Xin Xiaowei is an example,
    presenting broadcasts from different angles for an immersive effect.AIGC is transforming
    movie creation from screenwriting to post-production. AI screenwriting tools analyze
    data to generate optimized scripts. Visual effects teams blend AI-enhanced digital
    environments and de-aging with live footage for immersive visuals. Deep fake technology
    recreates or revives characters convincingly.AI also powers automated subtitle
    generation, even predicting dialogue in silent films by training models on extensive
    audio samples. This expands accessibility via subtitles and recreates voiceovers
    synchronized to scenes. In post-production, AI color grading and editing tools
    like Colourlab.Ai and Descript simplify processes like color correction using
    algorithms.In advertising, AIGC unlocks new potential for efficient, customized
    advertising creativity and personalization. AI-generated content allows advertisers
    to create personalized, engaging ads tailored to individual consumers at scale.
    Platforms like Creative Advertising System (CAS) and Personalized Advertising
    Copy Intelligent Generation System (SGS-PAC) leverage data to automatically generate
    ads with messaging targeted to specific user needs and interests.AI also assists
    in advertising creativity and design – Tools like Vinci produce customized attractive
    posters from product images and slogans, while companies like Brandmark.io generate
    logo variations based on user preferences. GAN technologies automate product listing
    generation with keywords for effective peer-to-peer marketing. Synthetic ad production
    is also on the rise, enabling highly personalized, scalable campaigns that save
    time.In music, tools like Google’s Magenta, IBM’s Watson Beat, or Sony CSL’s Flow
    Machine can generate original melodies and compositions. AIVA similarly creates
    unique compositions from parameters tuned by users. LANDR’s AI mastering uses
    machine learning to process and improve digital audio quality for musicians.In
    visual arts, MidJourney uses neural networks to generate inspirational images
    that can kickstart painting projects. Artists have used its outputs to create
    prize-winning works. DeepDream’s algorithm imposes patterns on images, creating
    psychedelic art. GANs can generate abstract paintings converging on a desired
    style. AI painting conservation analyzes artwork to digitally repair damage and
    restore pieces.Animation tools like Adobe’s Character Animator or Anthropic’s
    Claude can help with the generation of customized characters, scenes and motion
    sequences opening animation potential for non-professionals. ControlNet adds constraints
    to steer diffusion models, increasing output variability. For all these applications,
    advanced AI expands creative possibilities through both generative content and
    data-driven insights. It is important to note however that generative content
    requires extensive quality control around accuracy and eliminating biases before
    full deployment. For advertising, ethical use of consumer data and human oversight
    remain important. In all cases, properly attributing contributions of human artists,
    developers and training data remains an ongoing challenge as adoption spreads.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 游戏和娱乐产业正在利用生成式人工智能来打造独特沉浸式的用户体验。通过自动化创意任务可以获得主要的效率提升，提高在线休闲时间。生成式人工智能可以使机器通过学习模式和示例来生成新的原创内容，如艺术、音乐和文学。这对创意产业有着重要影响，它可以增强创意过程，可能创造新的收入来源。它还为媒体、电影和广告开启了新的个性化、动态内容创作规模。然而，生成内容在全面部署之前需要有关准确性和消除偏见的广泛质量控制。在新闻业中，使用大规模数据集进行自动生成文章可以使记者专注于更复杂的调查报道。**人工智能生成内容**（AIGC）在转变媒体制作和发布中发挥越来越重要的作用，增强了效率和多样性。在新闻业中，文本生成工具能够自动完成人类记者传统上完成的写作任务，显著提高生产效率，同时保持及时性。像美联社一样的媒体机构每年使用AIGC生成成千上万的报道。洛杉矶时报的Quakebot等机器记者可以快速生成有关突发新闻的文章。其他应用包括彭博新闻的Butletin服务，其中聊天机器人创建个性化的一句新闻摘要。AIGC还使得可以使用AI虚拟主持人与真实主持人一起主持广播，通过模仿人类的外观和从文本输入获得语音，实现不同角度的广播效果。中国新闻机构新华社的虚拟主持人辛小薇就是一个例子，她可以以不同的角度播报新闻，产生沉浸式的效果。AIGC正在从剧本创作转变到后期制作，AI剧本写作工具分析数据以生成优化的剧本。视觉效果团队通过将AI增强的数字环境和年轻化与现场影像混合，实现沉浸式视觉效果。深度伪造技术可以逼真地重新制作或复活角色。AI还可以完成自动生成字幕的任务，甚至通过对大量音频样本进行模型训练来预测无声电影中的对话。通过字幕来扩大可访问性，并且还可以在场景中同步重新配音。在后期制作中，使用像Colourlab.Ai和Descript这样的AI调色和编辑工具可以简化色彩校正等流程。在广告方面，AIGC释放了高效、定制广告创意和个性化的新潜力。AI生成内容使广告商能够以大规模为个人消费者创建个性化、引人入胜的广告。像创意广告系统（CAS）和个性化广告文案智能生成系统（SGS-PAC）这样的平台利用数据自动生成针对特定用户需求和兴趣的广告。AI还协助广告创意和设计——像Vinci这样的工具可以根据用户的喜好从产品图像和口号生成定制的吸引人海报，而像Brandmark.io这样的公司则可以根据用户的偏好生成徽标变体。GAN技术可以自动化生成带关键词的产品清单，用于有效的点对点营销。合成广告生产也在上升，实现高度个性化、可扩展的宣传活动，节省时间。在音乐方面，像Google的Magenta、IBM的Watson
    Beat或索尼CSL的Flow Machine等工具可以生成原创的旋律和作曲。AIVA同样可以根据用户调试的参数创建独特的作曲。LANDR的AI母带使用机器学习来处理和改善音频质量。在视觉艺术中，MidJourney使用神经网络生成可以启动绘画项目的灵感图像。艺术家们已经使用其成果创作了多次获奖作品。DeepDream的算法在图像上施加模式，创造出迷幻艺术作品。GAN可以生成以期望风格为导
- en: Economic
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 经济
- en: 'The deployment of generative AI and other technologies could help accelerate
    productivity growth, partially compensating for declining employment growth and
    enabling overall economic growth. Assuming energy and computing can scale sustainably,
    the huge productivity gains from integrating generative AI into business processes
    seem likely to usher automation of many tasks over the next decade. However, this
    transition may disrupt labor markets, requiring adjustments. Research by McKinsey
    and Company estimates 30-50% of current work activities could be automated by
    2030-2060\. Generative AI could boost global productivity by $6-8 trillion annually
    by 2030, adding 15-40% onto previous estimates for AI’s economic impact. According
    to Tyna Eloundou and colleagues (*GPTs are GPTs: An Early Look at the Labor Market
    Impact Potential of Large Language Models*, 2023) around 80% of US workers have
    at least 10% of work tasks affected by LLMs, while 19% may have over 50% of tasks
    impacted. Effects span all wage levels, with higher-wage jobs facing more exposure.
    Just 15% of all US worker tasks could be done significantly faster with LLMs alone.
    But with LLM-powered software, this increases to 47-56% of all tasks, showing
    the big impact of complementary technologies.From a geographic perspective, external
    private investment in generative AI, mostly from tech giants and venture capital
    firms, is largely concentrated in North America, reflecting the continent’s current
    domination of the overall AI investment landscape. Generative AI–related companies
    based in the United States raised about $8 billion from 2020 to 2022, accounting
    for 75 percent of total investments in such companies during that period.Automation
    adoption is likely to be faster in developed economies, where higher wages will
    make it economically feasible sooner. The scale of work automation does not directly
    equate to job losses. Like other technologies, generative AI typically enables
    individual activities within occupations to be automated, not entire occupations.
    However, organizations may decide to realize the benefits of increased productivity
    by reducing employment in some job categories.Productivity growth, the main engine
    of GDP growth over the past 30 years, slowed down in the past decade. The deployment
    of generative AI and other technologies could help accelerate productivity growth,
    partially compensating for declining employment growth and enabling overall economic
    growth. Based on estimates by analysts at McKinsey and Company, the automation
    of individual work activities could provide the global economy with an annual
    productivity boost of 0.2 to 3.3 percent from 2023 to 2040 depending on the rate
    of automation adoption, however, only if individuals affected by the technology
    were to shift to other work activities that at least match their 2022 productivity
    levels.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 部署生成式人工智能和其他技术可能有助于加速生产率增长，部分弥补就业增长下降，并促进整体经济增长。假设能源和计算可持续扩展，通过将生成式人工智能整合到业务流程中所带来的巨大生产率提升，似乎可能在未来十年推动许多任务的自动化。然而，这一过渡可能会扰乱劳动力市场，需要进行调整。麦肯锡公司的研究估计，到2030-2060年，30-50％的当前工作活动可能会被自动化。生成式人工智能到2030年每年可能会为全球生产力增加6-8万亿美元，为人工智能经济影响的先前估计增加15-40％。根据Tyna
    Eloundou和同事的研究《GPTs是GPTs：对大型语言模型对劳动市场影响潜力的初步观察，2023年》，大约80％的美国工人至少有10％的工作任务受到LLMs的影响，而19％可能受到50％以上任务的影响。影响跨越所有工资水平，高薪工作面临更大的暴露。仅有15％的美国工人任务可以通过仅LLMs显着加快完成。但使用LLM技术，这一比例增加到所有任务的47-56％，显示了互补技术的巨大影响。从地理角度看，生成式人工智能的外部私人投资主要来自科技巨头和风险投资公司，主要集中在北美，反映了该大陆目前对整体人工智能投资格局的主导地位。总部位于美国的与生成式人工智能相关的公司在2020年至2022年期间筹集了约80亿美元，占此类公司在该期间总投资额的75％。自动化采用在发达经济体中可能会更快，由于高工资将使其更早经济上可行。工作自动化的规模并不直接等同于失业人数。与其他技术一样，生成式人工智能通常使职业中的个别活动自动化，而不是整个职业。然而，组织可能会决定通过减少某些职业类别的就业来实现提高生产率的好处。过去30年来GDP增长的主要引擎——生产率增长，在过去十年有所放缓。部署生成式人工智能和其他技术可能有助于加速生产率增长，部分弥补就业增长下降并促进整体经济增长。根据麦肯锡公司分析师的估算，从2023年到2040年，根据自动化采纳率的不同，个别工作活动的自动化可能会为全球经济每年提供0.2至3.3％的生产率提升，然而，前提是受到这项技术影响的人员转移到其他工作活动，并至少与他们2022年的生产力水平相匹配。
- en: Education
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 教育
- en: One potential near-future scenario is that the rise of personalized AI tutors
    and mentors could democratize access to education for high-demand skills aligned
    with an AI-driven economy. In the education sector, generative AI is already transforming
    how we teach and learn. Tools like ChatGPT can be used to automatically generate
    personalized lessons and customized content for individual students. This reduces
    instructor workloads substantially by automating repetitive teaching tasks. AI
    tutors provide real-time feedback on student writing assignments, freeing up teachers
    to focus on more complex skills. Virtual simulations powered by generative AI
    can also create engaging, tailored learning experiences adapted to different learners’
    needs and interests.However, risks around perpetuating biases and spreading misinformation
    need to be studied further as these technologies evolve. The accelerating pace
    of knowledge and the obsolescence of scientific findings means that training children’s
    curiosity-driven learning should focus on developing the cognitive mechanisms
    involved in initiating and sustaining curiosity, such as awareness of knowledge
    gaps and the use of appropriate strategies to resolve them.While AI tutors tailored
    to each student could enhance outcomes and engagement, poorer schools may be left
    behind, worsening inequality. Governments should promote equal access to prevent
    generative AI from becoming a privilege of the affluent. Democratizing opportunity
    for all students remains vital.If implemented thoughtfully, personalized AI-powered
    education could make crucial skills acquisition accessible to anyone motivated
    to learn. Interactive AI assistants that adapt courses to students’ strengths,
    needs and interests could make learning efficient, engaging and equitable. But
    challenges around access, biases, and socialization need addressing.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 一个潜在的近期情景是，个性化人工智能导师和导师的崛起可能使得与人工智能驱动的经济相关的高需求技能的教育民主化。在教育领域，生成式人工智能已经改变了我们的教学和学习方式。像ChatGPT这样的工具可以用来自动生成个性化课程和定制内容，以满足个别学生的需求。这通过自动化重复的教学任务大大减轻了教师的工作负担。人工智能导师可以即时反馈学生写作作业，让教师有更多时间专注于更复杂的技能。由生成式人工智能驱动的虚拟模拟也可以创建吸引人的、量身定制的学习体验，适应不同学习者的需求和兴趣。然而，随着这些技术的发展，需要进一步研究围绕持续存在偏见和传播错误信息的风险。知识的加速增长和科学发现的过时意味着，培养孩子的好奇心驱动的学习应该集中于发展涉及启动和维持好奇心的认知机制，例如对知识盲区的意识和使用适当策略解决这些问题。尽管针对每个学生定制的人工智能导师可能会提高结果和参与度，但贫困学校可能会落后，加剧不平等。政府应该促进平等获取，以防止生成式人工智能成为富裕阶层的特权。民主化机会对所有学生来说仍然至关重要。如果经过深思熟虑实施，个性化的人工智能驱动的教育可以使任何有动力学习的人获得至关重要的技能。交互式人工智能助手可以根据学生的优势、需求和兴趣调整课程，使学习高效、吸引人且公平。但是，关于获取、偏见和社会化的挑战需要解决。
- en: Jobs
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 工作
- en: 'Assuming energy and computing can scale sustainably, the huge productivity
    gains from integrating generative AI into business processes seem likely to usher
    automation of many tasks over the next decade. This transition may disrupt labor
    markets, requiring adjustments.Automation enabled by AI will likely displace many
    administrative, customer service, writing, legal, and creative jobs in the near
    term, while professions in agriculture and construction might be virtually unaffected.
    However, past industrial revolutions ultimately led to new types of jobs and industries,
    albeit with difficult workforce transitions. The same dynamic is likely to play
    out with AI automation over the long run. This will impact almost all occupations
    to some degree, though some will be affected more heavily. Generative AI’s ability
    to analyze and generate natural language content could significantly increase
    the automation potential for activities like communicating, collaborating and
    reporting across many white-collar occupations. However, the extent to which entire
    jobs are eliminated remains uncertain. Past technological innovations ultimately
    created new types of work, even if the transitions were difficult.According to
    research at McKinsey and company, about 75 percent of the value that generative
    AI use cases could deliver falls across four areas: Customer operations, marketing
    and sales, software engineering, and R&D. Prominent examples include generative
    AI’s ability to support interactions with customers, generate creative content
    for marketing and sales, and draft computer code based on natural-language prompts,
    among many other tasks.Language models and Generative AI carry the potential to
    disrupt and automate tasks within various industries that were traditionally performed
    by humans. As for different roles, these predictions seem credible:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 假设能源和计算能够可持续扩展，那么将生成式人工智能集成到业务流程中所带来的巨大生产力提升似乎很可能在未来十年内实现自动化许多任务。这个过渡可能会扰乱劳动力市场，需要进行调整。人工智能的自动化可能会在短期内取代许多行政、客户服务、写作、法律和创意类工作，而农业和建筑等行业的职业可能几乎不受影响。然而，过去的工业革命最终导致了新型的工作和产业，尽管存在困难的劳动力过渡。人工智能自动化也可能出现类似的动态。这将在一定程度上影响几乎所有职业，尽管某些职业受到的影响更大。生成式人工智能分析和生成自然语言内容的能力可能显著增加像沟通、协作和报告等许多白领职业的自动化潜力。然而，整个职位被消除的程度仍然不确定。过去的技术创新最终创造了新的工作类型，即使过渡过程艰难。根据麦肯锡公司的研究，生成式人工智能在以下四个领域可以带来大约75%的价值：客户运作、市场和销售、软件工程和研发。突出的例子包括生成式人工智能支持与客户的互动、为市场和销售生成创意内容以及根据自然语言提示起草计算机代码等任务。语言模型和生成式人工智能具有中断和自动化传统上由人类执行的各种行业任务的潜力。对于不同的职位，这些预测似乎是可信的：
- en: Junior software engineers may be augmented or replaced by AI coding assistants.
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 初级软件工程师可能会被人工智能编码助手增强或取代。
- en: Analysts and advisors utilizing data insights from AI Customer service agents
    replaced by conversational AI.
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析师和顾问使用来自人工智能的数据洞察力，客服代理人被对话式人工智能取代。
- en: Technical writers and journalists aided by AI content generation.
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 技术撰稿人和新闻工作者受到人工智能内容生成的帮助。
- en: Teachers leveraging AI for course prep and personalized tutoring.
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 教师利用人工智能进行课程准备和个性化辅导。
- en: Paralegals utilizing AI for summarization and document review.
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 法律助理使用人工智能进行摘要和文件审查。
- en: Graphic designers will be empowered by AI image generation, however, making
    image creation and manipulation available to many more people could also have
    an impact on wages.
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图形设计师将受到人工智能图像生成的赋能，然而，使图像的创建和操作对更多人开放，也可能对工资产生影响。
- en: However, demand will remain strong for senior software engineers to develop
    specialized AI solutions and systems.
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然而，对于高级软件工程师来开发专门的AI解决方案和系统的需求将继续保持强劲。
- en: Data scientists may pivot from building predictive models to focusing more on
    validating, debugging and maximizing value from AI systems.
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据科学家可能会从构建预测模型转向更加专注于验证、调试和最大化AI系统的价值。
- en: Programmers will increasingly code tools to assist AI development.
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 程序员将越来越多地编写工具来协助人工智能的开发。
- en: New roles like prompt engineering have started to emerge.
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 类似提示工程的新职位开始出现。
- en: AI can perform certain tasks that extend to tasks involving natural language
    processing, content creation, and even intricate creative work, efficiently and
    with fewer errors than humans. Less skilled individuals may be able to perform
    more highly skilled work, while highly skilled individuals may be left with fewer
    job opportunities. For example, paralegals use boilerplate documents and fill
    in the necessary information to cater to clients’ needs. AI, equipped with vast
    knowledge of legal documents, legislation, university courses, journals, news
    articles, and court cases, can perform this task even better than paralegals.
    The result is a potential decrease in the need for junior lawyers for drafting
    purposes, with paralegals using AI-powered software to communicate clients’ specific
    requirements.Software developers and data scientists alike can benefit from the
    potential of LLMs but must carefully consider its capabilities and limitations
    for optimal use. For junior developers and data scientists, LLMs can automate
    routine tasks, provide basic solutions, and reduce errors, accelerating learning
    by freeing up time for more complex work. However, relying solely on AI risks
    hindering deeper technical growth, so LLMs should be seen as supportive tools
    while actively developing hands-on expertise.Senior developers and data scientists
    possess domain knowledge and problem-solving abilities beyond current AI capabilities.
    While automating standard solutions may save some time, their expertise is essential
    for guiding AI tools, ensuring reliable and scalable outcomes.The surge in AI
    productivity means that companies are in high demand for AI talent, and the competition
    for hiring and retaining this talent is fierce. There will also be a growing need
    for cybersecurity professionals who can protect AI systems from attack. Additionally,
    as AI systems become more prevalent, there may be more work in areas such as AI
    ethics, regulation, and public policy. Hence, investing in attracting and nurturing
    such talent is significant for companies to remain relevant in this rapidly evolving
    landscape.Creators in all sectors will be affected. In music, AI is aiding musicians
    across the creative process, from composing lyrics and melodies to digitally mastering
    and enhancing audio. Generative art tools allow visual artists to experiment with
    customized paintings catered to their unique styles.A Goldman Sachs study from
    March 2023 suggested that administrative and legal roles are most at risk. They
    estimated that about two thirds of current jobs will be exposed to automation
    by AI, and concluded that generative AI tools could impact 300 million full-time
    jobs worldwide, more than 20% of the current workforce. The pace of adoption is
    a critical unknown. McKinsey analysts estimated that automation could absorb between
    60 to 70 percent of employee hours so that between 2030 and 2060 about half of
    today’s work activities could be automated. According to PwC, by the mid-2030s,
    up to 30% of jobs could be automatable. But real-world adoption depends on many
    hard-to-predict factors like regulation, social acceptance and retraining policies.Knowledge
    work sectors such as software and app development are already seeing the effects
    of this transformation. Generative AI has been employed to streamline tasks ranging
    from initial code generation to image editing and design. It reduces repetitive
    manual work for developers and designers, enabling them to focus their efforts
    on higher-value innovation. However, meticulous monitoring and iterative correction
    of errors in auto-generated outputs remains critical.The large-scale automation
    of work activities could result in a major shift in labor demand, leading to substantial
    changes in occupation and necessitating employees to acquire new skills. Because
    their capabilities are fundamentally engineered to do cognitive tasks, Generative
    AI is likely to have the biggest impact on knowledge work, particularly activities
    involving decision making and collaboration, which previously had the lowest potential
    for automation. While previously, automation’s impact was highest in lower-middle-income
    quintiles, Further, Generative AI could have the biggest impact on activities
    in high-wage jobs. A significant number of workers will need to substantially
    change the work they do, either in their existing occupations or in new ones.
    They will also need support in making transitions to new activities.Managing this
    turnover will require policy foresight to minimize hardship for displaced workers
    through retraining programs, job creation incentives and portable benefits. If
    worker transitions and other risks can be managed, generative AI could contribute
    substantively to economic growth and support a more sustainable, inclusive world,
    where people are liberated from repetitive work.If the efficiency gains from AI
    automation are reinvested well, new industries and jobs could be created in the
    long run. But smooth workforce transitions will require policy foresight and employee
    training in the interim. In summary, while certain jobs may be displaced by AI
    in the near term, especially routine cognitive tasks, it may automate certain
    activities rather than eliminate entire occupations. Technical experts like data
    scientists and programmers will remain key to developing AI tools and realizing
    their full business potential.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能能够执行一些任务，涵盖自然语言处理、内容创作，甚至是复杂的创造性工作，效率高，错误少于人类。技能较低的个体可能能够执行更高技能的工作，而技能较高的个体可能会面临较少的工作机会。例如，法律助理使用模板文件，并填写必要的信息以满足客户的需求。人工智能，配备了广泛的法律文件、立法、大学课程、期刊、新闻文章和法院案例的知识，可以比法律助理做得更好。结果是，对于起草目的，初级律师的需求可能会减少，法律助理使用人工智能软件来传达客户的具体要求。软件开发人员和数据科学家都可以从LLM的潜力中受益，但必须仔细考虑其能力和局限性，以实现最佳利用。对于初级开发人员和数据科学家来说，LLM可以自动化例行任务，提供基本解决方案，并减少错误，通过释放更多时间进行更复杂的工作来加速学习。然而，仅依赖人工智能可能会阻碍更深层次的技术增长，因此LLM应被视为支持性工具，同时积极发展实践经验。高级开发人员和数据科学家具有超出当前人工智能能力的领域知识和问题解决能力。虽然自动化标准解决方案可能会节省一些时间，但他们的专业知识对于指导人工智能工具，确保可靠和可扩展的结果至关重要。人工智能生产力的激增意味着公司对人工智能人才的需求量很大，对于招聘和留住这些人才的竞争非常激烈。还将需要越来越多的网络安全专业人员来保护人工智能系统免受攻击。此外，随着人工智能系统变得更加普及，可能会有更多的工作涉及人工智能伦理、监管和公共政策等领域。因此，投资吸引和培养这样的人才对于公司在这个快速发展的领域保持相关性至关重要。所有行业的创作者都将受到影响。在音乐方面，人工智能正在帮助音乐家进行整个创作过程，从创作歌词和旋律到数字化母带和增强音频。生成艺术工具允许视觉艺术家尝试定制绘画，以迎合他们独特的风格。2023年3月的高盛研究表明，行政和法律职位最容易受到影响。他们估计，约三分之二的现有工作将面临人工智能的自动化，并得出结论，生成性人工智能工具可能会影响全球3亿个全职工作岗位，占目前劳动力的20%以上。采用的速度是一个关键的未知数。麦肯锡分析师估计，自动化可能吸收60到70％的员工工时，因此在2030年至2060年之间，今天的工作活动中大约一半可能会被自动化。根据普华永道的数据，到2030年中期，高达30%的工作可能是可以自动化的。但是，真实世界的采用取决于许多难以预测的因素，如监管、社会接受和再培训政策。软件和应用程序开发等知识工作领域已经开始看到这一转变的影响。生成性人工智能已被用于简化从初始代码生成到图像编辑和设计的任务。它减少了开发人员和设计师的重复手工工作，使他们能够将精力集中在更高价值的创新上。然而，对于自动生成的输出进行细致的监控和迭代纠正错误仍然至关重要。大规模自动化工作活动可能会导致劳动力需求的重大转变，从而导致职业的实质性变化，迫使员工获得新的技能。由于它们的能力基本上是为了进行认知任务，生成性人工智能很可能会对知识工作产生最大的影响，特别是涉及决策和协作的活动，而以前这些活动的自动化潜力较低。以前，自动化的影响主要集中在中低收入五分位数的工作中，而生成性人工智能可能会对高薪工作中的活动产生最大的影响。许多工人将需要在现有职业或新职业中实质性地改变他们的工作。他们还需要支持来进行过渡到新的活动。管理这种转变将需要政策远见，通过再培训计划、创造就业激励措施和
- en: Law
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 法律
- en: Generative models like LLMs can automate routine legal tasks such as contract
    review, documentation generation, and brief preparation. They also enable faster,
    comprehensive legal research and analysis. Additional applications include explaining
    complex legal concepts in plain language and predicting litigation outcomes using
    case data. However, responsible and ethical use remains critical given considerations
    around transparency, fairness and accountability. Overall, properly implemented
    AI tools promise to boost legal productivity and access to justice, while requiring
    ongoing scrutiny regarding reliability and ethics.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 生成模型如LLMs可以自动化常规法律任务，如合同审查、文件生成和案件准备。它们还可以实现更快速、全面的法律研究和分析。额外的应用包括用通俗的语言解释复杂的法律概念，并使用案例数据预测诉讼结果。然而，鉴于透明度、公平性和问责制等考虑，负责任和道德的使用仍然至关重要。总体而言，正确实施的AI工具承诺提高法律生产力和司法准入，同时需要持续关注可靠性和伦理问题。
- en: Manufacturing
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 制造业
- en: In the automotive sector, they are employed to generate 3D environments for
    simulations and aid in the development of cars. Additionally, generative AI is
    utilized for road testing autonomous vehicles using synthetic data. These models
    can also process object information to comprehend the surrounding environment,
    understand human intent through dialogues, generate natural language responses
    to human input, and create manipulation plans to assist humans in various tasks.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在汽车行业，它们被用来为模拟生成3D环境，并帮助汽车的开发。此外，生成式人工智能也被用于使用合成数据对自动驾驶车辆进行道路测试。这些模型还可以处理对象信息以理解周围环境，通过对话理解人类意图，对人类输入生成自然语言响应，并创建操纵计划以协助人类完成各种任务。
- en: Medicine
  id: totrans-89
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 医学
- en: A model that can accurately predict physical properties from gene sequences
    would represent a major breakthrough in medicine and could have profound impacts
    on society. It could further accelerate drug discovery and precision medicine,
    enable earlier disease prediction and prevention, provide a deeper understanding
    of complex diseases, and improve gene therapies. However, it also raises major
    ethical concerns around genetic engineering and could exacerbate social inequalities.New
    techniques with neural networks are already employed to lower long-read DNA sequencing
    error rates (Baid and colleagues; *DeepConsensus improves the accuracy of sequences
    with a gap-aware sequence transformer*, September 2022), and according to a report
    by ARK Investment Management (2023), in the short-term, technology like this can
    make it already possible to deliver the first high-quality, whole long-read genome
    for less than $1,000\. This means that large-scale gene-to-expression models might
    not be far away either.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 一个能够从基因序列准确预测物理性质的模型将代表医学的重大突破，并可能对社会产生深远影响。它可以进一步加速药物发现和精准医学，实现更早的疾病预测和预防，提供对复杂疾病的更深入理解，并改善基因治疗。然而，这也引发了围绕基因工程的主要道德关切，并可能加剧社会不平等。新技术已经采用神经网络降低了长读取DNA测序的错误率（Baid和同事们；*DeepConsensus
    improves the accuracy of sequences with a gap-aware sequence transformer*，2022年9月），根据ARK投资管理公司（2023年）的报告，短期内，像这样的技术已经可以用不到1000美元的价格交付第一个高质量的完整长读取基因组。这意味着大规模的基因表达模型也许并不遥远。
- en: Military
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 军事
- en: Militaries worldwide are investing in research to develop lethal autonomous
    weapons systems (LAWS). Robots and drones can identify targets and deploy lethal
    force without any human supervision. Machines can process information and react
    faster than humans, removing emotion from lethal decisions. However, this raises
    significant moral questions. Allowing machines to determine if lives should be
    taken crosses a troubling threshold. Even with sophisticated AI, complex factors
    in war like proportionality and distinction between civilians and combatants require
    human judgment.If deployed, completely autonomous lethal weapons would represent
    an alarming step towards relinquishing control over life-and-death decisions.
    They could violate international humanitarian law or be used by despotic regimes
    to terrorize populations. Once unleashed fully independently, the actions of autonomous
    killer robots would be impossible to predict or restrain.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 世界各国军队正在投资研究开发致命自主武器系统（LAWS）。机器人和无人机可以在没有任何人类监督的情况下识别目标并使用致命武力。机器可以比人类更快地处理信息并做出反应，从而从致命决策中消除情感。然而，这引发了重大的道德问题。允许机器确定是否应该夺取生命跨越了一个令人不安的界限。即使使用了复杂的人工智能，战争中的复杂因素，如比例和区分平民和战斗人员，仍需要人类判断。如果部署，完全自主的致命武器将代表放弃对生死决策的控制迈出令人震惊的一步。它们可能违反国际人道主义法，或被专制政权用来恐吓人民。一旦完全独立释放，自主杀手机器人的行动将是不可预测或控制的。
- en: Misinformation and cybersecurity
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 虚假信息和网络安全
- en: AI presents a dual-edged sword against disinformation. While it enables scalable
    detection, automation makes it easier to spread sophisticated, personalized propaganda.
    AI could help or harm security depending on whether it is used responsibly. It
    increases vulnerabilities to misinformation along with cyberattacks using generative
    hacking and social engineering. There are significant threats associated with
    AI techniques like micro-targeting and deepfakes. Powerful AI can profile users
    psychologically to deliver personalized disinformation that facilitates concealed
    manipulation, escaping broad examination Big data and AI could be leveraged to
    exploit psychological vulnerabilities and infiltrate online forums to attack and
    spread conspiracy theories. Disinformation has transformed into a multifaceted
    phenomenon, involving biased information, manipulation, propaganda, and intent
    to influence political behavior. For example, during the COVID-19 pandemic, the
    spread of misinformation and infodemics has been a major challenge. AI has a potential
    to influence public opinion on topics like elections, war, or foreign powers.It
    can also generate fake audio/video content to damage reputations and sow confusion.
    State and non-state actors are weaponizing these capabilities for propaganda,
    to damage reputations and sow confusion. AI can be used by political parties,
    governments, criminal groups, and even the legal system, launch lawsuits, and
    extract money. This likely will have far-reaching consequences in various domains.
    A significant portion of internet users may be obtaining the information they
    need without accessing external websites. There is a danger of large corporations
    being the gatekeepers of information and controlling public opinion, effectively
    being able to restrict certain actions or viewpoints.Careful governance and digital
    literacy are essential to build resilience. Though no single fix exists, collective
    efforts promoting responsible AI development can help democratic societies address
    emerging threats.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: AI对抗虚假信息是一把双刃剑。虽然它能够进行大规模检测，但自动化使得传播复杂、个性化的宣传更容易。AI的使用是否负责任取决于它是帮助还是损害安全。它增加了对利用生成式黑客和社会工程学进行网络攻击的误解的脆弱性。与微观目标和深度伪造等AI技术相关的威胁是相当显著的。强大的AI可以心理剖析用户，以提供能够促进隐蔽的操纵、避免广泛检查的个性化的虚假信息。大数据和AI可以利用心理脆弱性，并渗透到在线论坛中攻击扩散阴谋论。虚假信息已经成为一个多方面的现象，涉及偏见信息、操纵、宣传和旨在影响政治行为等。例如，在COVID-19大流行期间，虚假信息和信息瘟疫的传播一直是一个重要挑战。AI在选举、战争或外部势力等话题上有影响公众舆论的潜力。它也可以生成虚假的音频/视频内容以损害声誉和造成混淆。国家和非国家行为者正在将这些能力用于宣传，以破坏声誉和造成混乱。政党、政府、犯罪团伙甚至司法系统都可以利用AI发起诉讼并提取资金。这可能会在各个领域产生深远的影响。大部分互联网用户可能获得所需的信息而无需访问外部网站。大型企业成为信息的守门人，控制公众舆论，实际上能够限制某些行动或观点，这是一个危险信号。建立认真的治理和数字素养非常重要，以建立韧性。虽然不存在单一解决方案，但促进负责任的AI开发的集体努力可以帮助民主社会应对新兴威胁。
- en: Practical Implementation Challenges
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实际实现挑战
- en: 'Realizing the potential of generative AI in a responsible manner involves addressing
    a number of practical legal, ethical and regulatory issues:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在负责任的情况下实现生成式AI的潜力涉及解决一些实际的法律、伦理和监管问题：
- en: '**Legal**: Copyright laws remain ambiguous regarding AI-generated content.
    Who owns the output - the model creator, training data contributors, or end users?
    Replicating copyrighted data in training also raises fair use debates that need
    clarification.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**法律**: 版权法律在AI生成的内容方面仍然存在模糊不清的问题。谁拥有输出——模型创造者、培训数据贡献者或终端用户？在培训中复制受版权保护的数据也引发了需要澄清的合理使用争议。'
- en: '**Data Protection**: Collecting, processing and storing the massive datasets
    required to train advanced models creates data privacy and security risks. Governance
    models ensuring consent, anonymity and safe access are vital.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据保护**: 收集、处理和存储训练高级模型所需的大量数据集会创建数据隐私和安全风险。确保同意、匿名和安全访问的治理模型至关重要。'
- en: '**Oversight and Regulations**: Calls are mounting for oversight to ensure non-discrimination,
    accuracy and accountability from advanced AI systems. But flexible policies balancing
    innovation and risk are needed rather than burdensome bureaucracy.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**监管和法规**: 要求对先进的AI系统进行监管，以确保不歧视、准确和有责任感。但是需要灵活的政策平衡创新和风险，而不是繁琐的官僚主义。'
- en: '**Ethics**: Frameworks guiding development toward beneficial outcomes are indispensible.
    Integrating ethics through design practices focused on transparency, explicability
    and human oversight helps build trust.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**伦理学**：引导发展朝着有益结果的框架至关重要。通过专注于透明度、可解释性和人类监督的设计实践，将伦理学融入其中有助于建立信任。'
- en: Overall, proactive collaboration between policymakers, researchers and civil
    society is essential to settle unresolved issues around rights, ethics and governance.
    With pragmatic guardrails in place, generative models can fulfill their promise
    while mitigating harm. But public interest must remain the compass guiding AI
    progress.There is a growing demand for algorithmic transparency. This means that
    tech companies and developers should reveal the source code and inner workings
    of their systems. However, there is resistance from these companies and developers
    who argue that disclosing proprietary information would harm their competitive
    advantage. Open-source models will continue to thrive and local legislation in
    EU and other countries will push for transparent use of AI.The consequence of
    AI bias includes potential harm to individuals or groups due to biased decisions
    made by AI systems. Incorporating ethics training into computer science curricula
    can help reduce biases in AI codes. By teaching developers how to build applications
    that are ethical by design applications, the probability of biases being embedded
    into the codes can be minimized. To stay on the right path, organizations need
    to prioritize transparency, accountability, and guardrails to prevent bias in
    their AI systems. AI bias prevention is a long-term priority for many organizations,
    however, without legislation driving it, it can take time to be introduced. Local
    legislation in EU countries, for example, such as the European Commission’s proposal
    for harmonized rules on AI regulation, will drive more ethical use of language
    and imagery.A current German law on fake news, which imposes a 24-hour timeframe
    for platforms to remove fake news and hate speech, is impractical for both large
    and small platforms. Additionally, the limited resources of smaller platforms
    make it unrealistic for them to police all content. Further, online platforms
    should not have the sole authority to determine what is considered truth, as this
    could lead to excessive censorship. More nuanced policies are needed that balance
    free speech, accountability, and feasibility for a diversity of technology platforms
    to comply. Relying solely on private companies to regulate online content raises
    concerns around lack of oversight and due process. Broader collaboration between
    government, civil society, academics, and industry can develop more effective
    frameworks to counter misinformation while protecting rights.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，政策制定者、研究人员和公民社会之间的积极合作对于解决围绕权利、伦理和治理尚未解决的问题至关重要。在设置务实的防护措施的同时，生成模型可以实现其承诺，同时减轻伤害。但公共利益必须保持是引导人工智能进步的指南针。对算法透明度的需求日益增长。这意味着科技公司和开发人员应该揭示其系统的源代码和内部运作方式。然而，这些公司和开发人员主张披露专有信息将损害其竞争优势，因此存在抵制的情况。开源模型将继续蓬勃发展，欧盟和其他国家的地方立法将推动人工智能的透明使用。人工智能偏见的后果包括因人工智能系统偏见决策而给个人或群体带来潜在伤害。将伦理学培训纳入计算机科学课程可以帮助减少人工智能代码中的偏见。通过教导开发人员如何构建符合伦理要求的应用程序，可以将代码中嵌入偏见的概率降到最低。为了走上正确的道路，组织需要优先考虑透明度、问责制和防护措施，以防止其人工智能系统出现偏见。人工智能偏见预防是许多组织的长期重点，然而，如果没有立法推动，引入它可能需要时间。例如，欧盟国家的地方立法，如欧洲委员会关于人工智能监管的协调规则的提议，将推动更加道德化的语言和形象使用。德国关于虚假新闻的当前法律规定了一个24小时的时间框架，要求平台删除虚假新闻和仇恨言论，这对于大型和小型平台都是不切实际的。此外，较小平台的有限资源使得它们无法监管所有内容是不现实的。此外，在线平台不应该拥有唯一的权威来确定什么是真实的，因为这可能导致过度审查。需要更加细致的政策来平衡言论自由、问责制和各种技术平台的可行性。仅依赖私营公司来监管在线内容引发了对监督和正当程序不足的担忧。政府、公民社会、学术界和工业界之间更广泛的合作可以制定更有效的框架来对抗虚假信息，同时保护权利。
- en: The Road Ahead
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 未来之路
- en: The forthcoming era of generative AI models offers a plethora of intriguing
    opportunities and unparalleled progression, yet it is interspersed with numerous
    uncertainties. As discussed in this book, many breakthroughs have been accomplished
    in the recent years but successive challenges continue to linger, mainly pertaining
    to precision, rationalizing ability, controllability and entrenched bias within
    these models. While grandiose claims of superintelligent AI on the horizon may
    seem hyperbolic, consistent trends predict sophisticated capabilities sprouting
    within a few decades. On an individual level, the proliferation of generative
    content raises valid concerns around misinformation, plagiarism in academia, and
    impersonation in online spaces. As these models become more adept at mimicking
    human expression, people may have difficulty discerning what is human-generated
    versus AI-generated, enabling new forms of deception. There are also fears about
    generative models exacerbating social media addiction due to their ability to
    produce endless customized content.From a societal perspective, the sheer pace
    of advancement creates unease surrounding human obsolescence and job displacement,
    which could further divide economic classes. Unlike physical automation of the
    past, generative AI threatens cognitive job categories previously considered safe
    from automation. Managing this workforce transition ethically and equitably will
    require foresight and planning. There are also philosophical debates around whether
    AI should be creating art, literature or music that has historically reflected
    the human condition.For corporations, effective governance frameworks have yet
    to be established around acceptable use cases. Generative models amplify risks
    of misuse, ranging from creating misinformation such as deepfakes to generating
    unsafe medical advice. Legal questions around content licensing and intellectual
    property arise. While these models can enhance business productivity, quality
    control and bias mitigation incur additional costs. While large tech firms currently
    dominate generative AI research and development, smaller entities may ultimately
    stand to gain the most from these technologies. As costs decline for computing,
    data storage, and AI talent, custom pre-training of specialized models could become
    feasible for small and mid-sized companies. Rather than relying on generic models
    from Big Tech, tailored generative AI fine-tuned on niche datasets could better
    serve unique needs. Startups and non-profits often excel at rapidly iterating
    to build cutting-edge solutions for specialized domains. Democratized access through
    cost reductions could enable such focused players to train performant models exceeding
    capabilities of generalized systems. Concerns have emerged about saturation as
    generative AI tools are relatively easy to build using foundation models. Customization
    of models and tools is will allow value creation, but it’s unclear who will capture
    most upsides. While current market hype is high, investors are tempering decisions
    given lower valuations and skepticism following the 2021 AI boom/bust cycle. The
    long-term market impact and winning generative AI business models have yet to
    unfold.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 即将到来的生成式 AI 模型时代提供了许多有趣的机会和空前的进展，然而也存在许多不确定性。正如本书所讨论的那样，近年来已经取得了许多突破，但仍然存在着一系列持续的挑战，主要涉及这些模型中的精度、推理能力、可控性和固有偏见。虽然未来可能会出现超级智能的
    AI 看起来有些言过其实，但持续的趋势预示着几十年内将出现先进的能力。在个人层面上，生成式内容的普及引起了关于错误信息、学术抄袭和网络空间中的冒充等问题的担忧。随着这些模型变得越来越擅长模仿人类表达，人们可能难以分辨哪些是人类生成的，哪些是
    AI 生成的，从而导致新形式的欺骗。还有人类过时和岗位流失的忧虑，这可能会进一步划分经济阶层。与过去的物理自动化不同，生成式 AI 威胁着曾被认为是免于自动化的认知工作类别。在管理这个工作转型的道德和公平方面，需要有远见和规划。此外，还存在关于
    AI 是否应该创作反映人类状况的艺术、文学或音乐的哲学辩论。对于企业来说，尚未建立起有效的治理框架来适应可接受的使用情况。生成式模型放大了滥用风险，范围从创建错误信息，如深度伪造，到生成不安全的医疗建议。涉及内容许可和知识产权的法律问题也随之产生。虽然这些模型可以增强企业生产力，但质量控制和偏见缓解都带来了额外的成本。尽管大型科技公司目前主导着生成式
    AI 的研究和开发，但规模较小的实体最终可能会从这些技术中受益最多。随着计算、数据存储和 AI 人才成本的降低，专门模型的定制化预训练可能会成为中小型公司的可行选择。与依赖于大型科技公司的通用模型不同，针对专业数据集调整过的定制化生成式
    AI 可以更好地满足独特需求。初创公司和非营利组织通常擅长快速迭代，为专业领域构建前沿解决方案。成本降低后，通过民主化的访问和使用，这些集中的参与者可以训练优秀的模型，超过通用系统的能力。随着生成式
    AI 工具相对容易地基于基础模型构建，已经出现了饱和的隐忧。模型和工具的定制化将会创造价值，但尚不清楚谁将获得最大的盈利。尽管目前市场炒作居高不下，但投资者仍在遵循2021年
    AI 崛起/崩溃周期所带来的低估值和怀疑态度。长期市场影响和获胜的生成式
- en: The **2021 AI boom/bust cycle** refers to a rapid acceleration in investment
    and growth in the AI startup space followed by a market cooldown and stabilization
    in 2022 as projections failed to materialize and valuations declined.
  id: totrans-104
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**2021 年 AI 繁荣 / 萧条周期** 指的是投资和增长在AI 创业公司领域的迅速加速，随后市场降温和稳定，因为预测未能实现而估值下降。'
- en: ''
  id: totrans-105
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Here’s a quick summary:'
  id: totrans-106
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 快速总结：
- en: ''
  id: totrans-107
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Boom Phase (2020-2021):'
  id: totrans-108
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 繁荣阶段（2020-2021）：
- en: ''
  id: totrans-109
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: There was huge interest and skyrocketing investment in AI startups offering
    innovative capabilities like computer vision, natural language processing, robotics,
    and machine learning platforms. Total funding for AI startups hit record levels
    in 2021, with over $73 billion invested globally according to Pitchbook. Hundreds
    of AI startups were founded and funded during this period.
  id: totrans-110
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: AI 创业公司提供了创新能力，如计算机视觉、自然语言处理、机器人技术和机器学习平台，因此受到了极大关注和投资。根据 Pitchbook 的数据，2021
    年AI 创业公司的总投资额达到创纪录的73亿美元，全球成立和获得投资的AI 创业公司数量超过几百家。
- en: ''
  id: totrans-111
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Bust Phase (2022):'
  id: totrans-112
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '破坏阶段（2022）：   '
- en: ''
  id: totrans-113
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In 2022, the market underwent a correction, with valuations of AI startups falling
    significantly from their 2021 highs. Several high-profile AI startups like Anthropic
    and Cohere faced valuation markdowns. Many investors became more cautious and
    selective with funding AI startups. Market corrections in the broader tech sector
    also contributed to the bust.
  id: totrans-114
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '在 2022 年，市场经历了一次修正，AI 创业公司的估值从 2021 年的最高点大幅下跌。许多知名的 AI 创业公司，如 Anthropic 和 Cohere，面临了估值的降价。许多投资者变得更加谨慎和选择性，对投资
    AI 创业公司更加审慎。更广泛的科技行业市场调整也促成了萧条。   '
- en: ''
  id: totrans-115
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Key Factors:'
  id: totrans-116
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 主要因素：
- en: ''
  id: totrans-117
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Excessive hype, unrealistic growth projections, historically high valuations
    in 2021, and broader economic conditions all contributed to the boom-bust cycle.
    The cycle followed a classic pattern seen previously in sectors like dot-com and
    blockchain.
  id: totrans-118
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 过度炒作、不切实际的增长预测、2021 年的历史性高估值以及更广泛的经济条件都促成了繁荣和萧条周期。该周期遵循了此前在互联网和区块链等行业中看到的经典模式。
- en: 'Looking decades ahead, perhaps the deepest challenges are ethical. As AI is
    entrusted with more consequential decisions, alignment with human values becomes
    critical. While accuracy, reasoning ability, controllability, and mitigating bias
    remain technical priorities, other priorities should include fortifying model
    robustness, promoting transparency and ensuring alignment with human values. In
    order to maximize benefits, companies need to ensure human oversight, diversity,
    and transparency in development. Policy makers may need to implement guardrails
    preventing misuse while providing workers with support to transition as activities
    shift. With responsible implementation, generative AI could propel growth, creativity
    and accessibility in a more prosperous society. Addressing potential risks early
    on and ensuring a just distribution of benefits designed to serve public welfare
    will cultivate a sense of trust among stakeholders, such as:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 未来几十年，最深刻的挑战可能是伦理问题。随着AI 被赋予了更加重要的决策权，使其与人类价值观保持一致变得至关重要。虽然准确性、推理能力、可控性和减少偏见仍然是技术上的优先任务，但其他重点应包括加强模型的韧性，促进透明度并确保与人类价值观的一致性。为了最大限度地发挥效益，公司需要确保开发中有人类监督、多样性和透明度。政策制定者可能需要实施防范滥用的保障措施，并为工人提供过渡支持。通过负责任的实施，生成式AI
    可以推动更繁荣的社会中的增长、创造和可访问性。及早解决潜在风险并确保公共福利设计的收益公正分配将在利益相关者中培养信任感，如：
- en: '**The Dynamics of Progress**: Fine-tuning the pace of transformation is critical
    to avoid any undesired repercussions. Moreover, excessively slow developments
    could stifle innovation, suggesting that determining an ideal pace through encompassing
    public discourse is crucial.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 进展的动态：微调变革的速度对于避免不希望的影响至关重要。此外，过度缓慢的发展可能会扼杀创新，因此确定一个理想步伐需要包容公众讨论是至关重要的。
- en: '**The Human-AI Symbiosis**: Rather than striving for outright automation, more
    advantageous systems would integrate and complement the creative prowess of humans
    with the productive efficiency of AI. Such a hybrid model will ensure optimal
    oversight.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人机共生：与其追求完全自动化，更有优势的系统会将人的创造力与AI 的生产效率相融合和互补。这种混合模型将确保最佳监督。
- en: '**Promoting Access and Inclusion**: Equitable access to resources, relevant
    education and myriad opportunities concerning AI is key to negating the amplification
    of disparities. Representativeness and diversity should be prioritized.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**促进获取和包容**：对人工智能资源、相关教育和各种机会的平等获取对于消除差距的扩大至关重要。代表性和多样性应该是优先考虑的。'
- en: '**Preventive Measures and Risk Management**: Constant evaluation of freshly
    emerging capabilities via interdisciplinary insights is necessary to evade future
    dangers. Excessive apprehensions, however, should not impede potential progress.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预防措施和风险管理**：通过跨学科的见解不断评估新出现的能力是必要的，以避免未来的危险。然而，过度的担忧不应该妨碍潜在的进步。'
- en: '**Upholding Democratic Norms**: Collaborative discussions, communal efforts
    and reaching compromise will inevitably prove more constructive in defining the
    future course of AI, as compared to unilateral decrees imposed by a solitary entity.
    Public interest must take precedence.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**捍卫民主规范**：相比于单方面强加的单一规定，协作讨论、共同努力和达成妥协无疑将更有益于界定人工智能未来的发展方向。公共利益必须优先考虑。'
- en: While future capabilities remain uncertain, proactive governance and democratization
    of access are essential to direct these technologies toward equitable, benevolent
    outcomes. Collaboration between researchers, policymakers and civil society around
    issues of transparency, accountability and ethics can help align emerging innovations
    with shared human values. The goal should be empowering human potential, not mere
    technological advancement.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然未来的能力仍然不确定，但积极的治理和对获取的民主化至关重要，以引导这些技术走向公平、善良的结果。研究人员、决策者和公民社会围绕透明度、问责制和伦理等问题的合作可以帮助将新兴创新与共同的人类价值观相一致。目标应该是赋予人类潜能，而不仅仅是技术进步。
