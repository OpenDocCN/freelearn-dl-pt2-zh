# 附录

# 第一章，人工神经网络基础

1.  神经网络中的各种层是什么？

输入、隐藏和输出。

1.  前向传播的输出是什么？

帮助计算损失值的预测。

1.  连续因变量的损失函数与二元或分类因变量的损失函数有何不同？

**均方误差** (**MSE**)通常用于连续因变量的损失函数，而二元交叉熵通常用于二元因变量。分类交叉熵用于分类因变量。

1.  什么是随机梯度下降？

这是通过调整权重以减少梯度来降低损失的过程。

1.  一个反向传播练习的目的是什么？

使用链式法则计算所有权重相对于损失的梯度。

1.  在反向传播期间如何更新所有层中的权重？

它使用公式 **W_new = W – alpha*(dL/dW)** 进行更新。

1.  在训练神经网络的每个 epoch 中执行了哪些功能？

对于每个 epoch 中的每个批次，您执行前向传播，计算损失，使用损失进行反向传播计算权重梯度，并更新权重。然后继续下一个批次，直到所有 epoch 完成。

1.  在 GPU 上训练网络比在 CPU 上训练更快的原因是什么？

在 GPU 硬件上可以并行执行更多的矩阵操作。

1.  训练神经网络时学习率的影响是什么？

学习率过高会导致权重爆炸，而学习率过小则根本不会改变权重。

1.  学习率参数的典型值是多少？

通常在**1e-2**到**1e-5**之间，但这取决于许多因素，例如正在使用的架构、数据集和优化器。

# 第二章，PyTorch 基础

1.  为什么在训练过程中应将整数输入转换为浮点值？

`nn.Linear`（以及几乎所有 torch 层）只接受浮点数作为输入。

1.  用于重塑张量对象的方法是什么？

`tensor.view(shape)`、`permute`、`flatten`、`squeeze`和`unsqueeze`。

1.  为什么使用张量对象计算速度比使用 NumPy 数组快？

只有张量对象才能并行运行在 GPU 上的能力。

1.  在神经网络类中，`init`魔术函数包含什么？

调用`super().__init__()`并指定神经网络层。

1.  为什么在执行反向传播之前要进行零梯度操作？

确保前一次计算的梯度被清除的原因是什么？

1.  哪些魔术函数构成数据集类？

`__len__`和`__getitem__`。

1.  如何在新数据点上进行预测？

通过在张量上调用模型，如同调用函数一样 – `model(x)`。

1.  如何获取神经网络的中间层值？

通过创建一个自定义方法，该方法可以仅执行到中间层的 `forward`，或者通过在 `forward` 方法本身中将中间层的值作为额外输出返回。

1.  `Sequential` 方法如何帮助简化神经网络架构的定义？

我们可以通过连接一系列的层来避免创建 `__init__` 和 `forward` 方法。

1.  在更新 `loss_history` 时，我们附加 `loss.item()` 而不是 `loss`。这样做有什么作用，为什么附加 `loss.item()` 而不只是 `loss` 是有用的？

`loss.item()` 将一个零维的 torch 张量转换成 Python 浮点数，占用更少的内存，存储在 CPU 上，并可被其他库（如绘图、统计等）使用。

1.  使用 `torch.save(model.state_dict())` 的优势是什么？

通过仅保存模型的状态字典而不是整个模型对象，可以显著减少所需的存储空间。此外，这种方法使得在不同设备和环境之间传输模型变得更加容易，促进了模型的部署和共享。由于状态字典是一个字典，模型（及其中间层）可以独立复制、更新、修改和存储。

# 第三章，使用 PyTorch 构建深度神经网络

1.  如果输入数据集中的输入值没有进行缩放会发生什么？

当输入值未缩放时，调整权重到最佳值需要更长时间，因为输入值变化范围很广。有可能模型根本无法学习。

1.  当训练神经网络时，背景为白色像素而内容为黑色像素时可能会出现什么问题？

数据的均值接近 1（1 表示白色，0 表示黑色）。这可能导致神经网络训练时间较长，因为初始阶段许多神经元被激活。网络需要在开始阶段学会忽略大部分白色内容。

1.  批量大小对模型的训练时间和内存有什么影响？

批量大小越大，训练该批次所需的时间和内存就越多。

1.  输入值范围对训练结束时权重分布的影响是什么？

如果输入值没有缩放到某个范围，某些权重可能导致过拟合或导致梯度消失/爆炸。

1.  批量归一化如何帮助提高准确性？

就像我们为了 ANN 更好的收敛而需要对输入进行缩放一样，批量归一化为其下一层的收敛性而缩放激活值。

1.  为什么在 dropout 层中，权重在训练和评估时表现不同？

在训练期间，通过 dropout 缩放权重，它随机将输入单元的一部分设置为零，有助于防止过拟合。在评估期间，通常关闭 dropout，这导致权重的行为与全网络容量被利用而不是缩放下的行为不同。

1.  我们如何知道模型是否在训练数据上过拟合？

验证损失将远高于训练损失。

1.  正则化如何帮助避免过拟合？

正则化技术帮助模型在受限环境中训练，从而迫使 ANN 以较少偏向的方式调整其权重。

1.  L1 和 L2 正则化在哪些方面有所不同？

L1 是权重绝对值的总和，而 L2 是权重平方的总和，加到损失值和典型损失中。

1.  如何通过**dropout**减少过拟合？

通过在 ANN 中丢弃一些连接，我们迫使单个神经元在每次迭代时从更少的数据和不同的输入子集学习。这迫使模型学习而不依赖于特定的神经元或固定的连接。

# 第四章，介绍卷积神经网络

1.  使用传统神经网络时，在第一章节中使用翻译图像的预测为何较低？

所有图像都居中在原始数据集中，因此 ANN 只学习了对居中图像的任务。

1.  卷积是如何进行的？

通过在输入信号上滑动一个小的过滤器或内核进行卷积，逐元素相乘并求和以产生每个位置的输出值。对输入信号的每个位置重复此过程，从而产生一个新的输出信号，表示原始输入信号中的模式或特征的存在。

1.  如何确定滤波器中的最佳权重值？

通过反向传播。

1.  卷积和池化的组合如何帮助解决图像翻译问题？

虽然卷积提供重要的图像特征，但池化提取图像块中最显著的特征。这使得池化成为一种强大的操作；即使通过少量像素进行平移，池化仍会返回预期的输出。

1.  靠近输入的卷积滤波器学习什么？

像边缘这样的低级特征。

1.  池化的功能有助于模型构建的哪些方面？

通过减少特征图大小来减少输入大小，并使模型具有平移不变性。

1.  为什么我们不能像对 Fashion-MNIST 数据集那样将输入图像展平，然后为真实世界图像训练模型？

如果图像尺寸稍大，连接两个层的参数数量将达到数百万，导致大量计算和潜在的不稳定训练。

1.  数据增强如何帮助提高图像翻译？

数据增强创建了通过少量像素平移的图像副本。因此，即使图像中的对象偏离中心，模型也被迫学习正确的类别。

1.  在哪种情况下我们会利用`collate_fn`来处理数据加载器？

当需要执行批级转换时，使用`__getitem__`执行起来会很困难/慢。

1.  变化训练数据点的数量对验证数据集的分类准确性有什么影响？

一般来说，数据集大小越大，模型的准确性越高。

# 第五章，图像分类的迁移学习

1.  VGG 和 ResNet 预训练架构是在什么上训练的？

ImageNet 数据集中的图像。

1.  为什么 VGG11 的准确率不如 VGG16？

VGG11 比 VGG16 拥有更少的层/块/参数。

1.  VGG11 中的数字 11 代表什么？

11 层组。每个组都有两个卷积层，后面是 ReLU 和 maxpool2d。

1.  “残差网络”中的“残差”一词是什么意思？

“残差”一词指的是残差学习的概念，其中有一条快捷连接跳过了一个或多个层，并直接将输入添加到后续层的输出中，有助于训练非常深的网络。

1.  残差网络的优势是什么？

它有助于防止梯度消失，并且通过允许梯度直接通过快捷连接传递到初始层来增加模型深度而不丢失准确性。

1.  书中讨论的各种流行的预训练模型及其各自的特点是什么？

AlexNet 是第一个成功的卷积神经网络。VGG 通过使其更深而改进了 AlexNet。Inception 引入了一个 Inception 层，其中包含多个不同大小的卷积滤波器和池化操作。ResNet 引入了跳跃连接，有助于创建更深的网络。

1.  在迁移学习期间，为什么应该使用与预训练模型训练中使用的相同均值和标准差来规范化图像？

模型是这样训练的，以期望输入图像被规范化为特定的均值和标准差。

1.  在模型中何时以及为什么要冻结某些参数？

我们在重新训练活动中冻结某些参数（通常称为模型的骨干），以使这些参数在反向传播期间不会更新。它们不需要更新，因为它们已经训练得很好，这也将加快训练时间。

1.  我们如何知道预训练模型中存在哪些模块？

`print(model)`

1.  如何训练一个能够同时预测分类和数值的模型？

通过使用多个预测头，并针对每个头部单独训练。

1.  如果我们执行与“实现年龄估计”和“性别分类”章节中编写的代码相同的代码，为什么年龄和性别预测代码对你自己的图像不一定总是有效？

图像如果与训练数据的分布不相似可能会产生意想不到的结果。图像可能来自不同的人口统计学/地理位置。

1.  我们如何进一步提高我们在“实现面部关键点预测”章节中讨论的面部关键点识别模型的准确性？

我们可以在训练过程中添加噪声、颜色和几何增强。

# 第六章，图像分类的实际方面

1.  如何获取类激活映射？

参考“生成 CAMs”部分中提供的八个步骤。

1.  在训练模型时，批量归一化和数据增强如何帮助？

它们有助于减少过拟合。批量归一化通过在每一层归一化传入的数据来稳定学习过程，而数据增强则增加了训练集的多样性。

1.  CNN 模型过拟合的常见原因是什么？

过多的 CNN 层，没有批量归一化，缺乏数据增强和缺乏丢弃。

1.  在数据科学家端使用训练和验证数据但在真实世界中不适用的各种情况是什么？

除了明显的情况如使用与训练期间不同的模型/库版本外，真实世界数据由于环境变化、传感器变化等多种因素可能与用于训练和验证模型的数据分布不同。此外，模型可能已经在训练数据上过拟合。

1.  我们何时利用 OpenCV 包，以及在何时使用 OpenCV 胜过深度学习的优势是什么？

在受限环境中工作时，我们知道图像的行为范围有限，因此我们更喜欢使用 OpenCV，因为编码解决方案的时间更快。在受限环境中，速度更重要时，也更喜欢使用它。

# 第七章，目标检测的基础知识

1.  区域提议技术如何生成提议？

它识别颜色、纹理、大小和形状相似的区域。

1.  如果图像中有多个对象，如何计算交并比（IoU）？

对于每个对象与真实情况的 IoU 是独立计算的，使用 IoU 指标，其中分子是对象与真实情况之间的交集面积，分母是对象与真实情况之间的并集面积。

1.  为什么 Fast R-CNN 比 R-CNN 更快？

对于所有提议，从 VGG 主干获取特征图是常见的。重复使用这个特征图减少了 Fast R-CNN 中的计算量，几乎比 R-CNN 再次为所有提议计算这些特征少了 90%。

1.  RoI 池化如何工作？

所有来自`selectivesearch`的裁剪图像都通过自适应最大池化核传递，以使最终输出的大小相同。

1.  在预测边界框修正后从特征图获取多层次有什么影响？

模型将难以捕捉特征之间的复杂关系，并且无法产生准确的边界框修正。

1.  当计算整体损失时，为什么我们必须为回归损失分配更高的权重？

分类损失是交叉熵，通常为`log(n)`阶，导致输出可以有很高的范围。然而，边界框回归损失在 0 到 1 之间。因此，必须将回归损失进行放大。

1.  非最大抑制（non-max suppression）如何工作？

通过结合相同类别且具有高 IoU 的框，我们消除了冗余的边界框预测。

# 第八章，高级物体检测

1.  Faster R-CNN 相对于 Fast R-CNN 为何更快？

我们不需要每次使用`selectivesearch`技术喂入大量不必要的提议。相反，Faster R-CNN 使用区域建议网络自动找到它们。

1.  YOLO 和 SSD 与 Faster R-CNN 相比为何更快？

我们不需要依赖新的提议网络。网络直接在一次运行中找到提议。

1.  为什么 YOLO 和 SSD 是单次检测器算法？

网络一次性预测所有提议和预测。

1.  物体性得分和类别得分之间有什么区别？

物体性得分标识物体是否存在，而类别得分预测具有非零物体性的锚框的类别。

# 第九章，图像分割

1.  在 U-Net 架构中，放大（upscaling）如何帮助？

放大（upscaling）帮助特征图增加尺寸，使得最终输出与输入尺寸相同。

1.  为什么我们需要在 U-Net 中使用完全卷积网络？

因为输入和输出都是图像，使用线性层预测图像形状的张量是困难的。

1.  RoI Align 如何改进 Mask R-CNN 中的 RoI 池化？

RoI Align 使用预测提议的偏移量来精细对齐特征图。

1.  U-Net 和 Mask R-CNN 在分割上的主要区别是什么？

U-Net 是完全卷积的，具有单一的端到端网络，而 Mask R-CNN 使用 Backbone、RPN 等小网络来执行不同的任务。Mask R-CNN 能够识别和分离多个相同类型的对象，但 U-Net 只能识别它们（不能将它们分隔为单独的实例）。

1.  什么是实例分割？

如果同一图像中有不同类别的多个对象，则每个对象称为实例。将图像分割应用于分别预测所有实例的像素级别称为实例分割。

# 第十章，物体检测和分割的应用

1.  将数据集转换为 Detectron2 特定格式的重要性是什么？

Detectron2 是一个可以同时训练/评估多种架构的框架。为了在同一代码中实现这种灵活性，重要的是对数据集施加特定的限制，以便框架可以操作数据集。因此，建议所有 Detectron2 数据集都采用 COCO 格式。

1.  直接对图像中的人数进行回归是困难的。VGG 架构成功进行人群计数的关键见解是什么？

我们将目标图像转换为热图，其中所有像素的强度之和等于图像中的人数。

1.  解释图像着色的自监督学习。

我们能够通过简单地将图像转换为黑白（BW）来创建给定图像的输入输出对。我们将 BW 图像视为输入，将彩色图像视为预期输出。

1.  我们如何将 3D 点云转换为与 YOLO 兼容的图像？

在每个时间点，我们从顶部视角查看 3D 点云，并使用红色通道编码最高点，绿色通道编码最高点的强度，蓝色通道编码点的密度。

1.  使用仅适用于图像的架构处理视频的简单方法是什么？

这样做的简单方法是将帧的维度视为批次维度，并汇总所有帧的特征向量以获得单个特征向量。

# 第十一章，自编码器和图像操作

1.  “自编码器”中的“编码器”是什么？

将图像转换为向量表示的神经网络。

1.  自编码器优化的损失函数是什么？

像素级均方误差直接将预测与输入进行比较。

1.  自编码器如何帮助将相似图像分组？

相似图像将返回相似的编码，更容易进行聚类。

1.  卷积自编码器何时有用？

当输入为图像时，使用卷积自编码器有助于图像去噪、图像重建、异常检测、图像数据漂移、质量控制等任务。

1.  如果从普通/卷积自编码器获得的嵌入向量空间中随机抽样，为什么会得到非直观的图像？

编码中值的范围不受限制，因此适当的输出高度依赖于正确的数值范围。一般而言，随机抽样假设平均值为 0，标准偏差为 1，这可能不是良好编码范围。

1.  变分自编码器优化的损失函数是什么？

像素级均方误差和编码器均值和标准偏差的 KL 散度。

1.  变分自编码器如何克服普通/卷积自编码器生成新图像的限制？

通过将预测的编码约束为正态分布，所有编码落入均值为 0，标准偏差为 1 的区域，易于抽样。

1.  在对抗攻击期间，为什么修改输入图像像素而不是权重值？

在对抗攻击中，我们无法控制神经网络。

1.  在神经风格迁移中，我们优化哪些损失？

生成图像的感知（VGG）损失与原始图像的损失以及生成图像和样式图像的 Gram 矩阵之间的风格损失有关。

1.  在计算风格和内容损失时，为什么考虑不同层的激活而不是原始图像？

使用更多中间层确保生成图像保留有关图像的更细节部分。此外，使用更多损失使梯度上升更稳定。

1.  在计算风格损失时，为什么要考虑 gram 矩阵损失而不是图像之间的差异？

gram 矩阵损失提供了图像风格的指示，即纹理、形状和颜色的排列方式，并忽略实际内容。这就是为什么它更适合风格损失的原因。

1.  在构建用于生成深度伪造模型时为什么要扭曲图像？

扭曲图像有助于充当正则化器。此外，它有助于生成所需数量的图像，有助于增加数据集。

# 第十二章，使用 GAN 生成图像

1.  如果生成器和判别器模型的学习率很高会发生什么？

模型的稳定性将会很低。

1.  在生成器和判别器训练得非常好的情况下，给定图像是真实的概率是多少？

0.5

1.  为什么我们使用 ConvTranspose2d 来生成图像？

我们不能使用线性层来放大/生成图像。ConvTranspose2d 是一种通过参数化/神经网络方式将图像上采样到更大分辨率的方法。

1.  在条件 GAN 中，为什么嵌入的嵌入大小比类数更高？

使用更多参数使模型具有更多学习每个类别重要特征的自由度。

1.  如何生成有胡须的男性图像？

通过使用条件 GAN。就像我们有男性和女性图像一样，我们可以在训练模型时有胡须的男性等类别的图像。

1.  为什么我们在生成器的最后一层使用 Tanh 激活函数而不是 ReLU 或 sigmoid？

标准化图像的像素范围是 `[-1,1]`，因此我们使用 Tanh。

1.  即使我们没有对生成的数据进行反标准化，我们仍然获得了逼真的图像，为什么？

即使像素值不在 `[0,255]` 范围内，相对值对于 `make_grid` 实用程序来说也足够进行反标准化输入。

1.  如果在训练 GAN 前不对应于图像裁剪面部会发生什么？

如果背景太多，GAN 可能会错误地生成背景和面部的信号，因此它可能会集中于生成更逼真的背景。

1.  当训练生成器时，为什么判别器的权重不会得到更新（因为 `generator_train_step` 函数涉及判别器网络）？

这是一个逐步过程。在更新生成器时，我们假设判别器能够做到最好。

1.  在训练判别器时为什么要获取真实和假图像的损失，而在训练生成器时只获取假图像的损失？

因为生成器创建的都是虚假图像。

# 第十三章，用于操作图像的高级 GAN

1.  如果像 U-Net 这样的监督学习算法可以生成由轮廓图生成图像，为什么我们还需要 Pix2Pix GAN？

U-Net 在训练期间仅使用像素级损失。在 U-Net 生成图像时，由于没有现实感的损失，我们需要 Pix2Pix。

1.  为什么我们需要优化 CycleGAN 中三种不同的损失函数？

在 CycleGAN 中，我们优化对抗损失、循环一致性损失和身份损失，以便在保留原始图像结构和外观的同时学习两个域之间更准确的映射。在*CycleGAN 工作原理*部分提供了详细答案。

1.  ProgressiveGAN 使用的技巧如何帮助构建 StyleGAN 模型？

ProgressiveGAN 每次帮助网络学习几个上采样层，这样当需要增加图像尺寸时，负责生成当前尺寸图像的网络就会更加优化。

1.  如何识别与给定自定义图像对应的潜在向量？

通过调整随机生成的噪声，使得生成图像与目标图像之间的均方误差尽可能小。

# 第十四章，结合计算机视觉和强化学习

1.  代理如何计算给定状态的值？

通过计算在该状态下的预期奖励。

1.  Q 表如何填充？

通过计算每个状态-动作对的预期奖励，即即时奖励和预期未来奖励的总和。这种计算在每个 episode 中都会得到改进，从而每次估计都会更加准确。

1.  在状态动作值计算中为什么有折扣因子？

由于不确定性，我们不确定未来可能会如何运作。因此，我们通过折扣的方式减少未来奖励的权重。

1.  为什么我们需要探索-利用策略？

仅利用会使模型停滞和可预测，因此模型应能够探索并找到未曾见过的步骤，这可能比模型已学到的更有回报。

1.  为什么我们需要使用深度 Q 学习？

我们让神经网络学习可能的奖励系统，而无需使用可能耗时或需要完全环境可见性的昂贵算法。

1.  使用深度 Q 学习如何计算给定状态-动作组合的值？

这只是神经网络的输出。输入是状态，网络预测给定状态中每个动作的预期奖励。

1.  一旦代理在 CartPole 环境中最大化了奖励，是否有可能以后学习到次优策略？

如果神经网络由于糟糕的 episode 而忘记了，有一小部分非零机会学习到一些次优内容。

# 第十五章，结合计算机视觉和自然语言处理技术

1.  自注意力的输入、计算步骤和输出是什么？

自注意力的输入是一系列向量。步骤包括计算每对向量之间的注意力分数，首先将向量转换为键向量和查询向量。这两个向量进行矩阵乘法，然后通过 softmax 函数获得注意力权重。然后使用注意力权重计算值向量的加权和。生成的上下文向量被结合并通常通过额外的层，如前馈神经网络，产生最终的输出。

1.  如何在视觉变压器中将图像转换为序列输入？

在视觉变压器中，首先将图像切割成固定大小的网格补丁，然后通过 Conv2D 层将其转换为向量序列。

1.  在 LayoutLM 模型中，BERT 变压器的输入是什么？

箱子中包含的文本和箱子的二维位置是模型的输入。

1.  BLIP 的三个目标是什么？

图像-文本匹配、图像驱动文本生成和图像-文本对比学习。

# 第十六章，计算机视觉中的基础模型

1.  如何使用 CLIP 将文本和图像表示在相同的领域中？

通过使用对比损失，我们强制来自相同来源的图像和文本的嵌入尽可能相似，同时确保不同来源的嵌入尽可能不同。

1.  在 Segment Anything 架构中，如何计算不同类型的令牌，如点令牌、边界框令牌和文本令牌？

通过使用一个接受点、框或文本的提示编码器模型，并使用分割意义对象的预训练任务来描述点下面的有意义对象、在框内部或由文本描述。

1.  扩散模型如何工作？

它们通过逐步去噪声图像，从完全噪声到部分噪声到无噪声来工作。在每个步骤中，模型确保生成的图像仅比当前图像稍好。

1.  什么使稳定扩散与普通扩散不同？

与普通扩散不同，在稳定扩散中，整个去噪训练发生在由变分自编码器编码/解码的潜空间中，使训练速度显著加快。

1.  稳定扩散和 SDXL 模型之间有什么区别？

SDXL 已经在大小为 1,024 的图像上进行了训练，而标准模型则在 512 像素空间中工作。

# 第十七章，稳定扩散的应用

1.  使用稳定扩散进行图像修复的关键概念是什么？

通过仅在掩码区域生成潜变量并在未掩码区域保留潜变量，我们确保在背景中保持空间一致性，同时根据需要修改前景。

1.  ControlNet 的关键概念是什么？

有两个关键概念。首先，我们通过复制稳定扩散 UNet2D 模型的下采样路径来创建一个 ControlNet 分支。该分支中所有模块的最后一层都是零卷积层，并且每个模块都作为跳跃连接添加到相应的上采样分支。其次，通过专门训练新分支以接受诸如 canny 之类的特殊图像，训练速度更快。

1.  SDXL-Turbo 比 SDXL 更快的关键因素是什么？

SDXL-Turbo 遵循一种师生训练范式，其中学生在一次去噪中学习几个步骤，使学生能够在更少的步骤中预测与老师相同的输出，即更快。

1.  DepthNet 背后的关键概念是什么？

修改稳定扩散模型 UNet2D，使其能接受五个通道而不是通常的四个，第五个通道是深度图。这允许准确预测深度图像。

# 第十八章，将模型移至生产环境

1.  REST API 是什么以及它的作用是什么？

这是一个程序通过 HTTP 方法在互联网上进行通信的接口。

1.  Docker 是什么，为什么它对部署深度学习应用程序如此重要？

Docker 是一个容器化平台，允许开发者将应用程序打包、发布和在封闭环境（称为容器）中运行。在深度学习部署中，这些容器非常方便，开发者不必担心在多台机器上下载/安装库，并且可以根据负载扩展容器的规模。

1.  在生产环境中，检测与训练过程中明显不同的异常或新颖图像的简单常见技术是什么？

首先，我们测量新图像特征向量与训练数据特征向量之间的距离。如果这个距离与验证数据中样本图像的距离相比过大，我们可以判断图像是否异常。

1.  如何加速图像大量向量（数百万个）的相似性搜索？

通过使用诸如 FAISS 等现有库。这些方法通常根据聚类等技术预先索引大量向量，以便在相似性搜索期间更快地检索可能的向量候选项。

# 在 Discord 上了解更多信息

加入我们社区的 Discord 空间，与作者和其他读者讨论：

[`packt.link/modcv`](https://packt.link/modcv)

![](img/QR_Code237402495622324343.png)
