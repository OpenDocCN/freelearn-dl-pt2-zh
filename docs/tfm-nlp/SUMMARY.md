+   [前言](tfm-nlp_00.md)
+   [第一章：什么是变压器？](tfm-nlp_01.md)
+   [第二章：起步使用 Transformer 模型的架构](tfm-nlp_02.md)
+   [第三章：微调 BERT 模型](tfm-nlp_03.md)
+   [第四章：从头开始预训练 RoBERTa 模型](tfm-nlp_04.md)
+   [第五章：使用转换器的下游 NLP 任务](tfm-nlp_05.md)
+   [第六章：使用 Transformer 进行机器翻译](tfm-nlp_06.md)
+   [第七章：超人类变压器与 GPT-3 引擎的崛起](tfm-nlp_07.md)
+   [第八章：将变压器应用于法律和金融文件以进行人工智能文本摘要](tfm-nlp_08.md)
+   [第九章：匹配标记器和数据集](tfm-nlp_09.md)
+   [第十章：基于 BERT 的变压器的语义角色标记](tfm-nlp_10.md)
+   [第十一章：让你的数据说话：故事、问题和答案](tfm-nlp_11.md)
+   [第十二章：检测客户情绪以进行预测](tfm-nlp_12.md)
+   [第十三章：用变压器分析假新闻](tfm-nlp_13.md)
+   [第十四章：解释黑匣子变压器模型](tfm-nlp_14.md)
+   [第十五章：从 NLP 到任务不可知的变压器模型](tfm-nlp_15.md)
+   [第十六章：变压器驱动副驾驶员的出现](tfm-nlp_16.md)
+   [附录 I — 变压器模型术语](tfm-nlp_17.md)
+   [附录 II —— 对变压器模型的硬件约束](tfm-nlp_18.md)
+   [附录 III — 使用 GPT-2 进行通用文本完成](tfm-nlp_19.md)
+   [附录 IV — 使用 GPT-2 进行自定义文本完成](tfm-nlp_20.md)
+   [附录 V — 问题的答案](tfm-nlp_21.md)