# å®ç°è‡ªç¼–ç å™¨

æœ¬ç« è®¨è®ºäº†åŠç›‘ç£å­¦ä¹ ç®—æ³•çš„æ¦‚å¿µï¼Œé€šè¿‡å¼•å…¥è‡ªç¼–ç å™¨ï¼Œç„¶åè¿›å…¥**å—é™ç»å°”å…¹æ›¼æœº**ï¼ˆ**RBMs**ï¼‰å’Œ**æ·±åº¦ä¿¡å¿µç½‘ç»œ**ï¼ˆ**DBNs**ï¼‰ï¼Œä»¥ç†è§£æ•°æ®çš„æ¦‚ç‡åˆ†å¸ƒã€‚æœ¬ç« å°†æ¦‚è¿°è¿™äº›ç®—æ³•å¦‚ä½•åº”ç”¨äºä¸€äº›å®é™…é—®é¢˜ã€‚è¿˜å°†æä¾›åœ¨ PyTorch ä¸­å®ç°çš„ç¼–ç ç¤ºä¾‹ã€‚

è‡ªç¼–ç å™¨æ˜¯ä¸€ç§æ— ç›‘ç£å­¦ä¹ æŠ€æœ¯ã€‚å®ƒå¯ä»¥æ¥æ”¶æ— æ ‡ç­¾çš„æ•°æ®é›†ï¼Œå¹¶é€šè¿‡å»ºæ¨¡æ¥é‡å»ºåŸå§‹è¾“å…¥ï¼Œå°†é—®é¢˜å»ºæ¨¡ä¸ºæ— ç›‘ç£å­¦ä¹ ï¼Œè€Œä¸æ˜¯ç›‘ç£å­¦ä¹ ã€‚è‡ªç¼–ç å™¨çš„ç›®æ ‡æ˜¯ä½¿è¾“å…¥ä¸è¾“å‡ºå°½å¯èƒ½ç›¸ä¼¼ã€‚

å…·ä½“æ¥è¯´ï¼Œæœ¬ç« å°†æ¶µç›–ä»¥ä¸‹ä¸»é¢˜ï¼š

+   è‡ªç¼–ç å™¨åŠå…¶åº”ç”¨æ¦‚è¿°

+   ç“¶é¢ˆå’ŒæŸå¤±å‡½æ•°

+   ä¸åŒç±»å‹çš„è‡ªç¼–ç å™¨

+   å—é™ç»å°”å…¹æ›¼æœº

+   æ·±åº¦ä¿¡å¿µç½‘ç»œ

# è‡ªç¼–ç å™¨çš„åº”ç”¨

è‡ªç¼–ç å™¨å±äºè¡¨å¾å­¦ä¹ ï¼Œç”¨äºæ‰¾åˆ°è¾“å…¥çš„å‹ç¼©è¡¨ç¤ºã€‚å®ƒä»¬ç”±ç¼–ç å™¨å’Œè§£ç å™¨ç»„æˆã€‚ä»¥ä¸‹å›¾ç¤ºæ˜¾ç¤ºäº†è‡ªç¼–ç å™¨çš„ç»“æ„ï¼š

![](img/693d5531-ef4e-45a0-aa19-a9c0854da1ec.png)

è‡ªç¼–ç å™¨çš„åº”ç”¨ç¤ºä¾‹åŒ…æ‹¬ä»¥ä¸‹å‡ ç§ï¼š

+   æ•°æ®å»å™ª

+   æ•°æ®å¯è§†åŒ–çš„é™ç»´

+   å›¾åƒç”Ÿæˆ

+   æ’å€¼æ–‡æœ¬

# ç“¶é¢ˆå’ŒæŸå¤±å‡½æ•°

è‡ªç¼–ç å™¨å¯¹ç½‘ç»œæ–½åŠ äº†ä¸€ä¸ªç“¶é¢ˆï¼Œå¼ºåˆ¶ä½¿åŸå§‹è¾“å…¥çš„çŸ¥è¯†è¡¨ç¤ºè¢«å‹ç¼©ã€‚å¦‚æœæ²¡æœ‰ç“¶é¢ˆçš„è¯ï¼Œç½‘ç»œå°†ç®€å•åœ°å­¦ä¼šè®°å¿†è¾“å…¥å€¼ã€‚å› æ­¤ï¼Œè¿™æ„å‘³ç€æ¨¡å‹åœ¨æœªè§æ•°æ®ä¸Šçš„æ³›åŒ–èƒ½åŠ›ä¸ä¼šå¾ˆå¥½ï¼š

![](img/a862aa43-423e-4616-b93e-6c317b509ee9.png)

ä¸ºäº†ä½¿æ¨¡å‹èƒ½å¤Ÿæ£€æµ‹åˆ°ä¿¡å·ï¼Œæˆ‘ä»¬éœ€è¦å®ƒå¯¹è¾“å…¥å…·æœ‰æ•æ„Ÿæ€§ï¼Œä½†ä¸èƒ½ç®€å•åœ°è®°ä½å®ƒä»¬ï¼Œè€Œåœ¨æœªè§æ•°æ®ä¸Šé¢„æµ‹æ•ˆæœä¸ä½³ã€‚ä¸ºäº†ç¡®å®šæœ€ä¼˜æƒè¡¡ï¼Œæˆ‘ä»¬éœ€è¦æ„å»ºä¸€ä¸ªæŸå¤±/æˆæœ¬å‡½æ•°ï¼š

![](img/8e2bfc83-5110-405d-9e0a-74b6c8312912.png)

æœ‰ä¸€äº›å¸¸ç”¨çš„è‡ªç¼–ç å™¨æ¶æ„ï¼Œç”¨äºæ–½åŠ è¿™ä¸¤ä¸ªçº¦æŸæ¡ä»¶ï¼Œå¹¶ç¡®ä¿åœ¨ä¸¤è€…ä¹‹é—´æœ‰æœ€ä¼˜çš„æƒè¡¡ã€‚

# ç¼–ç ç¤ºä¾‹ - æ ‡å‡†è‡ªç¼–ç å™¨

åœ¨æœ¬ä¾‹ä¸­ï¼Œæˆ‘ä»¬å°†å±•ç¤ºå¦‚ä½•åœ¨ PyTorch ä¸­ç¼–è¯‘ä¸€ä¸ªè‡ªç¼–ç å™¨æ¨¡å‹ï¼š

1.  é¦–å…ˆï¼Œå¯¼å…¥ç›¸å…³çš„åº“ï¼š

```py
import os
from torch import nn
from torch.autograd import Variable
from torch.utils.data import DataLoader
from torchvision import transforms
from torchvision.datasets import MNIST
from torchvision.utils import save_image
```

1.  ç°åœ¨ï¼Œå®šä¹‰æ¨¡å‹å‚æ•°ï¼š

```py
number_epochs = 10
batch_size = 128
learning_rate = 1e-4
```

1.  ç„¶åï¼Œåˆå§‹åŒ–ä¸€ä¸ªå‡½æ•°æ¥è½¬æ¢ MNIST æ•°æ®é›†ä¸­çš„å›¾åƒï¼š

```py
transform_image = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])

dataset = MNIST('./data', transform=transform_image)
data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)
```

1.  å®šä¹‰è‡ªç¼–ç å™¨ç±»ï¼Œç”¨äºæä¾›æ•°æ®å¹¶åˆå§‹åŒ–æ¨¡å‹ï¼š

```py
class autoencoder_model(nn.Module):
    def __init__(self):
        super(autoencoder_model, self).__init__()
        self.encoder = nn.Sequential(
            nn.Linear(28 * 28, 128),
            nn.ReLU(True),
            nn.Linear(128, 64),
            nn.ReLU(True), nn.Linear(64, 12), nn.ReLU(True), nn.Linear(12, 3))
        self.decoder = nn.Sequential(
            nn.Linear(3, 12),
           nn.ReLU(True),
            nn.Linear(12, 64),
            nn.ReLU(True),
            nn.Linear(64, 128),
            nn.ReLU(True), nn.Linear(128, 28 * 28), nn.Tanh())

    def forward(self, x):
        x = self.encoder(x)
        x = self.decoder(x)
        return x

model = autoencoder_model()
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(
model.parameters(), lr=learning_rate, weight_decay=1e-5)
```

1.  å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œå®ƒå°†åœ¨æ¯ä¸ª epoch åä»æ¨¡å‹è¾“å‡ºå›¾åƒï¼š

```py
def to_image(x):
    x = 0.5 * (x + 1)
    x = x.clamp(0, 1)
    x = x.view(x.size(0), 1, 28, 28)
    return x
```

1.  ç°åœ¨åœ¨æ¯ä¸ª epoch ä¸Šè¿è¡Œæ¨¡å‹å¹¶æŸ¥çœ‹é‡å»ºå›¾åƒçš„ç»“æœï¼š

```py
for epoch in range(number_epochs):
    for data in data_loader:
        image, i = data
        image = image.view(image.size(0), -1)
        image = Variable(image)

        # Forward pass
        output = model(image)
        loss = criterion(output, image)

        # Backward pass
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

    print('Epoch [{}/{}], Loss:{:.4f}'.format(epoch + 1, number_epochs, loss.data[0]))
    if epoch % 10 == 0:
        pic = to_image(output.cpu().data)
        save_image(pic, './mlp_img/image_{}.png'.format(epoch))

torch.save(model.state_dict(), './sim_autoencoder.pth')
```

è¿™å°†äº§ç”Ÿä»¥ä¸‹è¾“å‡ºï¼š

![](img/b9ecb6f8-ef83-48aa-8e49-e29b3a0f6bca.png)

ä»¥ä¸‹å›¾ç‰‡æ˜¾ç¤ºäº†æ¯ä¸ª epoch çš„è‡ªç¼–ç å™¨è¾“å‡ºï¼š

![](img/ab6c7350-99d9-4cb1-bde0-602292f98856.png)

éšç€ç»è¿‡çš„ epoch è¶Šæ¥è¶Šå¤šï¼Œå›¾åƒå˜å¾—è¶Šæ¥è¶Šæ¸…æ™°ï¼Œå› ä¸ºæ¨¡å‹ç»§ç»­å­¦ä¹ ã€‚

# å·ç§¯è‡ªç¼–ç å™¨

è‡ªç¼–ç å™¨å¯ä»¥ä½¿ç”¨å·ç§¯è€Œä¸æ˜¯å…¨è¿æ¥å±‚ã€‚è¿™å¯ä»¥é€šè¿‡ä½¿ç”¨ 3D å‘é‡è€Œä¸æ˜¯ 1D å‘é‡æ¥å®ç°ã€‚åœ¨å›¾åƒçš„èƒŒæ™¯ä¸‹ï¼Œå¯¹å›¾åƒè¿›è¡Œä¸‹é‡‡æ ·è¿«ä½¿è‡ªç¼–ç å™¨å­¦ä¹ å…¶å‹ç¼©ç‰ˆæœ¬ã€‚

# ç¼–ç ç¤ºä¾‹ â€“ å·ç§¯è‡ªç¼–ç å™¨

åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬å°†å±•ç¤ºå¦‚ä½•ç¼–è¯‘ä¸€ä¸ªå·ç§¯è‡ªç¼–ç å™¨ï¼š

1.  ä¸ä»¥å‰ä¸€æ ·ï¼Œæ‚¨ä» MNIST æ•°æ®é›†è·å–è®­ç»ƒå’Œæµ‹è¯•æ•°æ®é›†ï¼Œå¹¶å®šä¹‰æ¨¡å‹å‚æ•°ï¼š

```py
number_epochs = 10
batch_size = 128
learning_rate = 1e-4

transform_image = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])

dataset = MNIST('./data', transform=transform_image)
data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)
```

1.  ä»è¿™é‡Œå¼€å§‹ï¼Œå¯åŠ¨å·ç§¯è‡ªç¼–ç å™¨æ¨¡å‹ï¼š

```py
class conv_autoencoder(nn.Module):
    def __init__(self):
        super(conv_autoencoder, self).__init__()
        self.encoder = nn.Sequential(
            nn.Conv2d(1, 16, 3, stride=3, padding=1), 
            nn.ReLU(True),
            nn.MaxPool2d(2, stride=2), 
            nn.Conv2d(16, 8, 3, stride=2, padding=1), 
            nn.ReLU(True),
            nn.MaxPool2d(2, stride=1) 
        )
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(8, 16, 3, stride=2), 
            nn.ReLU(True),
            nn.ConvTranspose2d(16, 8, 5, stride=3, padding=1), 
            nn.ReLU(True),
            nn.ConvTranspose2d(8, 1, 2, stride=2, padding=1), 
            nn.Tanh()
        )

    def forward(self, x):
        x = self.encoder(x)
        x = self.decoder(x)
        return x

model = conv_autoencoder()
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)
```

1.  æœ€åï¼Œåœ¨æ¯ä¸ª epoch è¿è¡Œæ¨¡å‹åŒæ—¶ä¿å­˜è¾“å‡ºå›¾åƒä»¥ä¾›å‚è€ƒï¼š

```py
for epoch in range(number_epochs):
    for data in data_loader:
        img, i = data
        img = Variable(img)

        # Forward pass
        output = model(img)
        loss = criterion(output, img)

        # Backward pass
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
    # Print results
    print('epoch [{}/{}], loss:{:.4f}'
          .format(epoch+1, number_epochs, loss.data[0]))
    if epoch % 10 == 0:
        pic = to_image(output.cpu().data)
        save_image(pic, './dc_img/image_{}.png'.format(epoch))

torch.save(model.state_dict(), './convolutional_autoencoder.pth')
```

æˆ‘ä»¬å¯ä»¥åœ¨ä»£ç ä¸­æåˆ°çš„æ–‡ä»¶å¤¹ä¸­ï¼Œæ¯ä¸ª epoch åæŸ¥çœ‹ä¿å­˜çš„å›¾åƒã€‚

# å»å™ªè‡ªç¼–ç å™¨

å»å™ªç¼–ç å™¨æ•…æ„å‘ç½‘ç»œçš„è¾“å…¥æ·»åŠ å™ªå£°ã€‚è¿™äº›è‡ªç¼–ç å™¨å®è´¨ä¸Šåˆ›å»ºäº†æ•°æ®çš„æŸåå‰¯æœ¬ã€‚é€šè¿‡è¿™æ ·åšï¼Œè¿™æœ‰åŠ©äºç¼–ç å™¨å­¦ä¹ è¾“å…¥æ•°æ®ä¸­çš„æ½œåœ¨è¡¨ç¤ºï¼Œä½¿å…¶æ›´å…·æ™®é€‚æ€§ï¼š

![](img/7fb53730-c36b-4900-be3b-39f76e76f65e.png)

è¿™ä¸ªæŸåçš„å›¾åƒä¸å…¶ä»–æ ‡å‡†è‡ªç¼–ç å™¨ä¸€æ ·è¢«é€å…¥ç½‘ç»œï¼š

![](img/0c46e5ba-3ff4-4584-b559-6f772c705114.png)

æ­£å¦‚æˆ‘ä»¬æ‰€è§ï¼ŒåŸå§‹è¾“å…¥ä¸­æ·»åŠ äº†å™ªå£°ï¼Œç¼–ç å™¨å¯¹è¾“å…¥è¿›è¡Œç¼–ç å¹¶å°†å…¶å‘é€åˆ°è§£ç å™¨ï¼Œè§£ç å™¨ç„¶åå°†å˜ˆæ‚çš„è¾“å…¥è§£ç ä¸ºæ¸…ç†åçš„è¾“å‡ºã€‚å› æ­¤ï¼Œæˆ‘ä»¬å·²ç»çœ‹è¿‡è‡ªç¼–ç å™¨å¯ä»¥ç”¨äºçš„å„ç§åº”ç”¨ã€‚ç°åœ¨æˆ‘ä»¬å°†çœ‹çœ‹ä¸€ç§ç‰¹å®šç±»å‹çš„è‡ªç¼–ç å™¨ï¼Œå³**å˜åˆ†è‡ªç¼–ç å™¨**ï¼ˆ**VAE**ï¼‰ã€‚

# å˜åˆ†è‡ªç¼–ç å™¨

VAEs ä¸æˆ‘ä»¬è¿„ä»Šè€ƒè™‘è¿‡çš„æ ‡å‡†è‡ªç¼–ç å™¨ä¸åŒï¼Œå› ä¸ºå®ƒä»¬ä»¥æ¦‚ç‡æ–¹å¼æè¿°æ½œåœ¨ç©ºé—´ä¸­çš„è§‚å¯Ÿç»“æœï¼Œè€Œä¸æ˜¯ç¡®å®šæ€§æ–¹å¼ã€‚æ¯ä¸ªæ½œåœ¨å±æ€§çš„æ¦‚ç‡åˆ†å¸ƒè¢«è¾“å‡ºï¼Œè€Œä¸æ˜¯å•ä¸ªå€¼ã€‚

æ ‡å‡†è‡ªç¼–ç å™¨åœ¨ç°å®ä¸–ç•Œä¸­çš„åº”ç”¨æœ‰äº›å—é™ï¼Œå› ä¸ºå®ƒä»¬åªåœ¨æ‚¨æƒ³è¦å¤åˆ¶è¾“å…¥çš„æ•°æ®æ—¶æ‰çœŸæ­£æœ‰ç”¨ã€‚ç”±äº VAEs æ˜¯ç”Ÿæˆæ¨¡å‹ï¼Œå®ƒä»¬å¯ä»¥åº”ç”¨äºæ‚¨ä¸å¸Œæœ›è¾“å‡ºä¸è¾“å…¥ç›¸åŒçš„æ•°æ®çš„æƒ…å†µã€‚

è®©æˆ‘ä»¬åœ¨ç°å®ä¸–ç•Œçš„èƒŒæ™¯ä¸‹è€ƒè™‘è¿™ä¸ªé—®é¢˜ã€‚å½“åœ¨é¢éƒ¨æ•°æ®é›†ä¸Šè®­ç»ƒè‡ªç¼–ç å™¨æ¨¡å‹æ—¶ï¼Œæ‚¨å¸Œæœ›å®ƒèƒ½å­¦ä¹ æ½œåœ¨å±æ€§ï¼Œæ¯”å¦‚ä¸€ä¸ªäººæ˜¯å¦å¾®ç¬‘ï¼Œä»–ä»¬çš„è‚¤è‰²ï¼Œæ˜¯å¦æˆ´çœ¼é•œç­‰ç­‰ï¼š

![](img/4cc640bb-841f-438d-a6cc-79837d7e85dd.png)

æ­£å¦‚åœ¨å‰é¢çš„å›¾ä¸­æ‰€ç¤ºï¼Œæ ‡å‡†è‡ªç¼–ç å™¨å°†è¿™äº›æ½œåœ¨å±æ€§è¡¨ç¤ºä¸ºç¦»æ•£å€¼ã€‚

å¦‚æœæˆ‘ä»¬å…è®¸æ¯ä¸ªç‰¹å¾åœ¨å¯èƒ½å€¼çš„èŒƒå›´å†…è€Œä¸æ˜¯å•ä¸ªå€¼å†…ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ VAEs ä»¥æ¦‚ç‡æœ¯è¯­æè¿°å±æ€§ï¼š

![](img/76947b8a-b694-4db9-b32a-498f4972ba45.png)

å‰é¢çš„å›¾ç¤ºäº†æˆ‘ä»¬å¦‚ä½•å°†ä¸€ä¸ªäººæ˜¯å¦å¾®ç¬‘è¡¨ç¤ºä¸ºç¦»æ•£å€¼æˆ–æ¦‚ç‡åˆ†å¸ƒã€‚

æ¯ä¸ªæ½œåœ¨å±æ€§çš„åˆ†å¸ƒæ˜¯ä»å›¾åƒä¸­é‡‡æ ·çš„ï¼Œä»¥ç”Ÿæˆç”¨ä½œè§£ç å™¨æ¨¡å‹è¾“å…¥çš„å‘é‡ï¼š

![](img/07851c42-ae8a-4888-a8d8-39704d6948da.png)

å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œè¾“å‡ºä¸¤ä¸ªå‘é‡ï¼š

![](img/d6e926bd-3db3-4433-969d-9237af0bf3a0.png)

å…¶ä¸­ä¸€ä¸ªæè¿°å¹³å‡å€¼ï¼Œå¦ä¸€ä¸ªæè¿°åˆ†å¸ƒçš„æ–¹å·®ã€‚

# è®­ç»ƒ VAE

åœ¨è®­ç»ƒæœŸé—´ï¼Œæˆ‘ä»¬ä½¿ç”¨åå‘ä¼ æ’­è®¡ç®—ç½‘ç»œä¸­æ¯ä¸ªå‚æ•°ä¸æ•´ä½“æŸå¤±çš„å…³ç³»ã€‚

æ ‡å‡†è‡ªåŠ¨ç¼–ç å™¨ä½¿ç”¨åå‘ä¼ æ’­æ¥åœ¨ç½‘ç»œæƒé‡ä¸Šé‡å»ºæŸå¤±å€¼ã€‚ç”±äº VAE ä¸­çš„é‡‡æ ·æ“ä½œä¸å¯å¾®ï¼Œä¸èƒ½ä»é‡æ„è¯¯å·®ä¸­ä¼ æ’­æ¢¯åº¦ã€‚ä»¥ä¸‹å›¾è¡¨è¿›ä¸€æ­¥è§£é‡Šäº†è¿™ä¸€ç‚¹ï¼š

![](img/12949e89-c9f1-491d-a822-7e82befa9fa2.png)

ä¸ºäº†å…‹æœè¿™ä¸€é™åˆ¶ï¼Œå¯ä»¥ä½¿ç”¨é‡å‚æ•°åŒ–æŠ€å·§ã€‚é‡å‚æ•°åŒ–æŠ€å·§ä»å•ä½æ­£æ€åˆ†å¸ƒä¸­é‡‡æ ·Îµï¼Œå°†å…¶å¹³ç§»è‡³æ½œåœ¨å±æ€§çš„å‡å€¼ğœ‡ï¼Œå¹¶æŒ‰æ½œåœ¨å±æ€§çš„æ–¹å·®ğœè¿›è¡Œç¼©æ”¾ï¼š

![](img/6376b4ec-ebd3-4464-adcd-4c39f59e1313.png)

è¿™å°†é‡‡æ ·è¿‡ç¨‹ä»æ¢¯åº¦æµä¸­ç§»é™¤ï¼Œå› ä¸ºç°åœ¨å®ƒä½äºç½‘ç»œä¹‹å¤–ã€‚å› æ­¤ï¼Œé‡‡æ ·è¿‡ç¨‹ä¸ä¾èµ–äºç½‘ç»œä¸­çš„ä»»ä½•ä¸œè¥¿ã€‚ç°åœ¨æˆ‘ä»¬å¯ä»¥ä¼˜åŒ–åˆ†å¸ƒçš„å‚æ•°ï¼ŒåŒæ—¶ä¿æŒä»ä¸­éšæœºé‡‡æ ·çš„èƒ½åŠ›ï¼š

![](img/0727f2d1-a7f3-4436-a031-7c6a717b2192.png)

æˆ‘ä»¬å¯ä»¥é€šè¿‡å‡å€¼ğœ‡å’Œåæ–¹å·®çŸ©é˜µâˆ‘å¯¹å…¶è¿›è¡Œå˜æ¢ï¼Œå› ä¸ºæ¯ä¸ªå±æ€§çš„åˆ†å¸ƒæ˜¯é«˜æ–¯åˆ†å¸ƒï¼š

![](img/08421e67-3535-434a-9586-d98bf7e661a4.png)

è¿™é‡Œï¼ŒÎµ ~ N(0,1)ã€‚

ç°åœ¨æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ç®€å•çš„åå‘ä¼ æ’­æ¥è®­ç»ƒæ¨¡å‹ï¼Œå¹¶å¼•å…¥é‡å‚æ•°åŒ–æŠ€å·§ï¼š

![](img/20d8edd5-d1d0-4190-942c-710c7cd089cb.png)

å¦‚å‰é¢çš„å›¾è¡¨æ‰€ç¤ºï¼Œæˆ‘ä»¬å·²ç»è®­ç»ƒäº†è‡ªåŠ¨ç¼–ç å™¨ä»¥å¹³æ»‘å›¾åƒã€‚

# ç¼–ç ç¤ºä¾‹ - VAE

è¦åœ¨ PyTorch ä¸­ç¼–å†™ VAEï¼Œæˆ‘ä»¬å¯ä»¥åƒåœ¨ä¹‹å‰çš„ç¤ºä¾‹ä¸­é‚£æ ·åŠ è½½åº“å’Œæ•°æ®é›†ã€‚ä»è¿™é‡Œï¼Œæˆ‘ä»¬å¯ä»¥å®šä¹‰ VAE ç±»ï¼š

```py
class VariationalAutoEncoder(nn.Module):
    def __init__(self):
        super(VariationalAutoEncoder, self).__init__()

        self.fc1 = nn.Linear(784, 400)
        self.fc21 = nn.Linear(400, 20)
        self.fc22 = nn.Linear(400, 20)
        self.fc3 = nn.Linear(20, 400)
        self.fc4 = nn.Linear(400, 784)

    def encode_function(self, x):
        h1 = F.relu(self.fc1(x))
        return self.fc21(h1), self.fc22(h1)

    def reparametrize(self, mu, logvar):
        std = logvar.mul(0.5).exp_()
        if torch.cuda.is_available():
            eps = torch.cuda.FloatTensor(std.size()).normal_()
        else:
            eps = torch.FloatTensor(std.size()).normal_()
        eps = Variable(eps)
        return eps.mul(std).add_(mu)

    def decode_function(self, z):
        h3 = F.relu(self.fc3(z))
        return F.sigmoid(self.fc4(h3))

    def forward(self, x):
        mu, logvar = self.encode_function(x)
        z = self.reparametrize(mu, logvar)
        return self.decode_function(z), mu, logvar
```

ç„¶åï¼Œæˆ‘ä»¬ä½¿ç”¨ KL æ•£åº¦æ¥å®šä¹‰æŸå¤±å‡½æ•°ï¼Œå¹¶åˆå§‹åŒ–æ¨¡å‹ï¼š

```py
def loss_function(reconstruction_x, x, mu, latent_log_variance):
    """
    reconstruction_x: generating images
    x: original images
    mu: latent mean
    """
    BCE = reconstruction_function(reconstruction_x, x) 
    # KL loss = 0.5 * sum(1 + log(sigmaÂ²) - muÂ² - sigmaÂ²)
    KLD_aspect = mu.pow(2).add_(latent_log_variance.exp()).mul_(-1).add_(1).add_(logvar)
    KLD = torch.sum(KLD_aspect).mul_(-0.5)
    # KL divergence
    return BCE + KLD

optimizer = optim.Adam(model.parameters(), lr=1e-4)
```

ä»è¿™é‡Œï¼Œæˆ‘ä»¬å¯ä»¥è¿è¡Œæ¨¡å‹çš„æ¯ä¸ªæ—¶æœŸå¹¶ä¿å­˜è¾“å‡ºï¼š

```py
for epoch in range(number_epochs):
    model.train()
    train_loss = 0
    for batch_idx, data in enumerate(data_loader):
        img, _ = data
        img = img.view(img.size(0), -1)
        img = Variable(img)
        if torch.cuda.is_available():
            img = img.cuda()
        optimizer.zero_grad()
        recon_batch, mu, logvar = model(img)
        loss = loss_function(recon_batch, img, mu, logvar)
        loss.backward()
        train_loss += loss.data[0]
        optimizer.step()
        if batch_idx % 100 == 0:
            print('Train Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}'.format(
                epoch,
                batch_idx * len(img),
                len(data_loader.dataset), 100\. * batch_idx / len(data_loader),
                loss.data[0] / len(img)))

    print('Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss / len(data_loader.dataset)))
    if epoch % 10 == 0:
        save = to_image(recon_batch.cpu().data)
        save_image(save, './vae_img/image_{}.png'.format(epoch))

torch.save(model.state_dict(), './vae.pth')
```

ç°åœ¨æˆ‘ä»¬å·²ç»çœ‹è¿‡å„ç§è‡ªåŠ¨ç¼–ç å™¨åŠå…¶å¦‚ä½•ç¼–è¯‘å®ƒä»¬ï¼Œè®©æˆ‘ä»¬å­¦ä¹ å¦‚ä½•åœ¨æ¨èç³»ç»Ÿä¸­å®ç°å®ƒä»¬ã€‚

# å—é™ç»å°”å…¹æ›¼æœº

**RBM**æ˜¯ä¸€ç§å¹¿æ³›ç”¨äºååŒè¿‡æ»¤ã€ç‰¹å¾æå–ã€ä¸»é¢˜å»ºæ¨¡å’Œé™ç»´ç­‰ä»»åŠ¡çš„ç®—æ³•ã€‚å®ƒä»¬å¯ä»¥æ— ç›‘ç£åœ°å­¦ä¹ æ•°æ®é›†ä¸­çš„æ¨¡å¼ã€‚

ä¾‹å¦‚ï¼Œå¦‚æœä½ è§‚çœ‹ç”µå½±å¹¶è¯´å‡ºä½ æ˜¯å¦å–œæ¬¢å®ƒï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¸€ä¸ª**RBM**æ¥å¸®åŠ©æˆ‘ä»¬ç¡®å®šä½ åšå‡ºè¿™ä¸ªå†³å®šçš„åŸå› ã€‚

RBM çš„ç›®æ ‡æ˜¯æœ€å°åŒ–èƒ½é‡ï¼Œç”±ä»¥ä¸‹å…¬å¼å®šä¹‰ï¼Œå…¶ä¾èµ–äºå¯è§/è¾“å…¥çŠ¶æ€ã€éšè—çŠ¶æ€ã€æƒé‡å’Œåç½®çš„é…ç½®ï¼š

![](img/b2d5c938-993c-4018-8312-747bdca6ea70.png)

RBM æ˜¯ DBN çš„åŸºæœ¬æ„å»ºå—çš„ä¸¤å±‚ç½‘ç»œã€‚RBM çš„ç¬¬ä¸€å±‚æ˜¯ç¥ç»å…ƒçš„å¯è§/è¾“å…¥å±‚ï¼Œç¬¬äºŒå±‚æ˜¯éšè—å±‚çš„ç¥ç»å…ƒï¼š

![](img/e6352c09-c581-41b7-858f-b5bf82a3f269.png)

RBM å°†è¾“å…¥ä»å¯è§å±‚ç¿»è¯‘æˆä¸€ç»„æ•°å­—ã€‚é€šè¿‡å‡ æ¬¡å‰å‘å’Œåå‘ä¼ é€’ï¼Œè¯¥æ•°å­—ç„¶åè¢«ç¿»è¯‘å›é‡æ„è¾“å…¥ã€‚åœ¨ RBM ä¸­çš„é™åˆ¶æ˜¯åŒä¸€å±‚ä¸­çš„èŠ‚ç‚¹ä¸è¿æ¥ã€‚

ä»è®­ç»ƒæ•°æ®é›†ä¸­çš„æ¯ä¸ªèŠ‚ç‚¹çš„ä½çº§ç‰¹å¾è¢«é¦ˆé€åˆ°å¯è§å±‚çš„æ¯ä¸ªèŠ‚ç‚¹ã€‚åœ¨å›¾åƒåˆ†ç±»çš„æƒ…å†µä¸‹ï¼Œæ¯ä¸ªèŠ‚ç‚¹å°†ä¸ºå›¾åƒä¸­æ¯ä¸ªåƒç´ æ¥æ”¶ä¸€ä¸ªåƒç´ å€¼ï¼š

![](img/a3310e3c-b99d-4ff3-97bf-aa1ff08491dc.png)

é€šè¿‡ç½‘ç»œè·Ÿè¸ªä¸€ä¸ªåƒç´ ï¼Œè¾“å…¥*x*è¢«éšè—å±‚çš„æƒé‡ä¹˜ä»¥ï¼Œç„¶ååŠ ä¸Šåç½®ã€‚ç„¶åï¼Œè¿™è¢«è¾“å…¥åˆ°æ¿€æ´»å‡½æ•°ä¸­ï¼Œäº§ç”Ÿè¾“å‡ºï¼Œè¿™å®è´¨ä¸Šæ˜¯é€šè¿‡å®ƒä¼ é€’çš„ä¿¡å·å¼ºåº¦ï¼Œç»™å®šè¾“å…¥*x*ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š

![](img/02467675-a93e-4d99-81ca-01aa85c3ac72.png)

åœ¨éšè—å±‚çš„æ¯ä¸ªèŠ‚ç‚¹ï¼Œæ¥è‡ªæ¯ä¸ªåƒç´ å€¼çš„*x*è¢«å•ç‹¬çš„æƒé‡ä¹˜ä»¥ã€‚ç„¶åå°†è¿™äº›ä¹˜ç§¯æ±‚å’Œï¼Œå¹¶æ·»åŠ åç½®ã€‚ç„¶åå°†å…¶è¾“å‡ºé€šè¿‡æ¿€æ´»å‡½æ•°ï¼Œäº§ç”Ÿè¯¥å•ä¸ªèŠ‚ç‚¹çš„è¾“å‡ºï¼š

![](img/00ee7d87-14b2-4e4a-8776-4c879004bb8b.png)

åœ¨æ¯ä¸ªæ—¶åˆ»ï¼ŒRBM å¤„äºæŸç§çŠ¶æ€ï¼Œè¿™æŒ‡çš„æ˜¯å¯è§*v*å’Œéšè—*h*å±‚ä¸­ç¥ç»å…ƒçš„å€¼ã€‚è¿™ç§çŠ¶æ€çš„æ¦‚ç‡å¯ä»¥ç”±ä»¥ä¸‹è”åˆåˆ†å¸ƒå‡½æ•°ç»™å‡ºï¼š

![](img/125757b1-9b57-487d-9133-726cc7addde4.png)

è¿™é‡Œï¼ŒZ æ˜¯åˆ†åŒºå‡½æ•°ï¼Œæ˜¯å¯¹æ‰€æœ‰å¯èƒ½çš„å¯è§å’Œéšè—å‘é‡å¯¹çš„æ±‚å’Œã€‚

# è®­ç»ƒ RBM

åœ¨è®­ç»ƒæœŸé—´ï¼ŒRBM æ‰§è¡Œä¸¤ä¸ªä¸»è¦æ­¥éª¤ï¼š

1.  **å‰å¸ƒæ–¯é‡‡æ ·**ï¼šè®­ç»ƒè¿‡ç¨‹çš„ç¬¬ä¸€æ­¥ä½¿ç”¨å‰å¸ƒæ–¯é‡‡æ ·ï¼Œå®ƒé‡å¤ä»¥ä¸‹è¿‡ç¨‹*k*æ¬¡ï¼š

+   ç»™å®šè¾“å…¥å‘é‡çš„éšè—å‘é‡çš„æ¦‚ç‡ï¼›é¢„æµ‹éšè—å€¼ã€‚

+   ç»™å®šéšè—å‘é‡çš„è¾“å…¥å‘é‡çš„æ¦‚ç‡ï¼›é¢„æµ‹è¾“å…¥å€¼ã€‚ä»è¿™é‡Œï¼Œæˆ‘ä»¬è·å¾—å¦ä¸€ä¸ªè¾“å…¥å‘é‡ï¼Œè¯¥å‘é‡æ˜¯ä»åŸå§‹è¾“å…¥å€¼é‡æ–°åˆ›å»ºçš„ã€‚

1.  **å¯¹æ¯”æ•£åº¦**ï¼šRBM é€šè¿‡å¯¹æ¯”æ•£åº¦è°ƒæ•´å®ƒä»¬çš„æƒé‡ã€‚åœ¨æ­¤è¿‡ç¨‹ä¸­ï¼Œå¯è§èŠ‚ç‚¹çš„æƒé‡æ˜¯éšæœºç”Ÿæˆçš„ï¼Œå¹¶ç”¨äºç”Ÿæˆéšè—èŠ‚ç‚¹ã€‚ç„¶åï¼Œéšè—èŠ‚ç‚¹å†ä½¿ç”¨ç›¸åŒçš„æƒé‡é‡æ„å¯è§èŠ‚ç‚¹ã€‚ç”¨äºé‡æ„å¯è§èŠ‚ç‚¹çš„æƒé‡åœ¨æ•´ä¸ªè¿‡ç¨‹ä¸­æ˜¯ç›¸åŒçš„ã€‚ä½†æ˜¯ç”Ÿæˆçš„èŠ‚ç‚¹ä¸åŒï¼Œå› ä¸ºå®ƒä»¬ä¹‹é—´æ²¡æœ‰è¿æ¥ã€‚

ä¸€æ—¦ RBM è®­ç»ƒå®Œæˆï¼Œå®ƒåŸºæœ¬ä¸Šèƒ½å¤Ÿè¡¨è¾¾ä¸¤ä»¶äº‹æƒ…ï¼š

+   è¾“å…¥æ•°æ®ç‰¹å¾ä¹‹é—´çš„ç›¸äº’å…³ç³»

+   åœ¨è¯†åˆ«æ¨¡å¼æ—¶å“ªäº›ç‰¹å¾æœ€é‡è¦

# ç†è®ºç¤ºä¾‹ - RBM æ¨èç³»ç»Ÿ

åœ¨ç”µå½±çš„èƒŒæ™¯ä¸‹ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ RBM æ­ç¤ºä¸€ç»„ä»£è¡¨å®ƒä»¬ç±»å‹çš„æ½œåœ¨å› ç´ ï¼Œä»è€Œç¡®å®šä¸€ä¸ªäººå–œæ¬¢å“ªç§ç”µå½±ç±»å‹ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬è¦æ±‚æŸäººå‘Šè¯‰æˆ‘ä»¬ä»–ä»¬çœ‹è¿‡å“ªäº›ç”µå½±ä»¥åŠæ˜¯å¦å–œæ¬¢ï¼Œæˆ‘ä»¬å¯ä»¥å°†å®ƒä»¬è¡¨ç¤ºä¸ºäºŒè¿›åˆ¶è¾“å…¥ï¼ˆ1 æˆ– 0ï¼‰åˆ° RBM ä¸­ã€‚å¯¹äºé‚£äº›ä»–ä»¬æ²¡çœ‹è¿‡æˆ–æ²¡å‘Šè¯‰æˆ‘ä»¬çš„ç”µå½±ï¼Œæˆ‘ä»¬éœ€è¦åˆ†é…ä¸€ä¸ªå€¼ä¸º-1ï¼Œè¿™æ ·ç½‘ç»œåœ¨è®­ç»ƒæ—¶å¯ä»¥è¯†åˆ«å¹¶å¿½ç•¥å®ƒä»¬çš„å…³è”æƒé‡ã€‚

è®©æˆ‘ä»¬è€ƒè™‘ä¸€ä¸ªç¤ºä¾‹ï¼Œç”¨æˆ·å–œæ¬¢*è€å¦ˆå¦ˆï¼Œæˆ‘æ¥äº†*ï¼Œ*å®¿é†‰*å’Œ*ä¼´å¨˜*ï¼Œä¸å–œæ¬¢*å°–å«*æˆ–*å¿ƒç†*ï¼Œè¿˜æ²¡æœ‰çœ‹è¿‡*éœæ¯”ç‰¹äºº*ã€‚æ ¹æ®è¿™äº›è¾“å…¥ï¼ŒRBM å¯èƒ½è¯†åˆ«å‡ºä¸‰ä¸ªéšè—å› å­ï¼šå–œå‰§ã€ææ€–å’Œå¥‡å¹»ï¼Œè¿™äº›å› å­å¯¹åº”äºç”µå½±çš„ç±»å‹ï¼š

![](img/6d8e29ec-2944-4f90-a8c8-aaab69ca68c5.png)

å¯¹äºæ¯ä¸ªéšè—ç¥ç»å…ƒï¼ŒRBM åˆ†é…äº†ç»™å®šè¾“å…¥ç¥ç»å…ƒçš„éšè—ç¥ç»å…ƒçš„æ¦‚ç‡ã€‚ç¥ç»å…ƒçš„æœ€ç»ˆäºŒè¿›åˆ¶å€¼æ˜¯é€šè¿‡ä»ä¼¯åŠªåˆ©åˆ†å¸ƒä¸­æŠ½æ ·å¾—åˆ°çš„ã€‚

åœ¨ä¸Šé¢çš„ä¾‹å­ä¸­ï¼Œä»£è¡¨å–œå‰§ç±»å‹çš„å”¯ä¸€éšè—ç¥ç»å…ƒå˜å¾—æ´»è·ƒã€‚å› æ­¤ï¼Œç»™å®šè¾“å…¥åˆ° RBM çš„ç”µå½±è¯„åˆ†ï¼Œå®ƒé¢„æµ‹ç”¨æˆ·æœ€å–œæ¬¢å–œå‰§ç”µå½±ã€‚

å¯¹äºå·²è®­ç»ƒçš„ RBM æ¥è¯´ï¼Œè¦é¢„æµ‹ç”¨æˆ·å°šæœªçœ‹è¿‡çš„ç”µå½±ï¼ŒåŸºäºä»–ä»¬çš„å–œå¥½ï¼ŒRBM ä½¿ç”¨å¯è§ç¥ç»å…ƒç»™å®šéšè—ç¥ç»å…ƒçš„æ¦‚ç‡ã€‚å®ƒä»ä¼¯åŠªåˆ©åˆ†å¸ƒä¸­è¿›è¡ŒæŠ½æ ·ï¼Œä»¥ç¡®å®šå“ªä¸ªå¯è§ç¥ç»å…ƒå¯ä»¥å˜ä¸ºæ´»è·ƒçŠ¶æ€ã€‚

# ç¼–ç ç¤ºä¾‹ - RBM æ¨èç³»ç»Ÿ

ç»§ç»­åœ¨ç”µå½±çš„èƒŒæ™¯ä¸‹ï¼Œæˆ‘ä»¬å°†å±•ç¤ºå¦‚ä½•ä½¿ç”¨ PyTorch åº“æ„å»ºä¸€ä¸ª RBM æ¨èç³»ç»Ÿçš„ç¤ºä¾‹ã€‚è¯¥ç¤ºä¾‹çš„ç›®æ ‡æ˜¯è®­ç»ƒä¸€ä¸ªæ¨¡å‹æ¥ç¡®å®šç”¨æˆ·æ˜¯å¦ä¼šå–œæ¬¢ä¸€éƒ¨ç”µå½±ã€‚

åœ¨è¿™ä¸ªç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº† MovieLens æ•°æ®é›†ï¼ˆ[`grouplens.org/datasets/movielens/`](https://grouplens.org/datasets/movielens/)ï¼‰ï¼ŒåŒ…å« 100 ä¸‡æ¡è¯„åˆ†ï¼Œè¿™ä¸ªæ•°æ®é›†ç”±æ˜å°¼è‹è¾¾å¤§å­¦çš„ GroupLens ç ”ç©¶ç»„åˆ›å»ºï¼š

1.  é¦–å…ˆï¼Œä¸‹è½½æ•°æ®é›†ã€‚å¯ä»¥é€šè¿‡ç»ˆç«¯å‘½ä»¤å®Œæˆå¦‚ä¸‹æ“ä½œï¼š

```py
wget -O moviedataset.zip http://files.grouplens.org/datasets/movielens/ml-1m.zip
unzip -o moviedataset.zip -d ./data
unzip -o moviedataset.zip -d ./data
```

1.  ç°åœ¨å¯¼å…¥æˆ‘ä»¬å°†è¦ä½¿ç”¨çš„åº“ï¼š

```py
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.nn.parallel
import torch.optim as optim
import torch.utils.data
from torch.autograd import Variable
```

1.  ç„¶åå¯¼å…¥æ•°æ®ï¼š

```py
movies = pd.read_csv('ml-1m/movies.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')
users = pd.read_csv('ml-1m/users.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')
ratings = pd.read_csv('ml-1m/ratings.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')
```

ä»¥ä¸‹æˆªå›¾å±•ç¤ºäº†æˆ‘ä»¬æ•°æ®é›†çš„ç»“æ„ï¼š

![](img/272925c4-059f-410c-b3f1-0833472cddf1.png)

1.  å‡†å¤‡æµ‹è¯•å’Œè®­ç»ƒæ•°æ®é›†ï¼š

```py
training_dataset = pd.read_csv('ml-100k/u1.base', delimiter = '\t')
training_dataset = np.array(training_set, dtype = 'int')
test_dataset = pd.read_csv('ml-100k/u1.test', delimiter = '\t')
test_dataset = np.array(test_dataset, dtype = 'int') 
```

1.  ç°åœ¨æˆ‘ä»¬éœ€è¦å‡†å¤‡ä¸€ä¸ªåŒ…å«ç”¨æˆ·è¯„åˆ†çš„çŸ©é˜µã€‚è¯¥çŸ©é˜µå°†ä»¥ç”¨æˆ·ä¸ºè¡Œï¼Œç”µå½±ä¸ºåˆ—ã€‚é›¶ç”¨äºè¡¨ç¤ºç”¨æˆ·æœªå¯¹ç‰¹å®šç”µå½±è¯„åˆ†çš„æƒ…å†µã€‚æˆ‘ä»¬å®šä¹‰`no_users`å’Œ`no_movies`å˜é‡ï¼Œç„¶åè€ƒè™‘è®­ç»ƒå’Œæµ‹è¯•æ•°æ®é›†ä¸­çš„æœ€å¤§å€¼å¦‚ä¸‹ï¼š

```py
no_users = int(max(max(training_dataset[:,0]), max(test_dataset[:,0])))
no_movies = int(max(max(training_dataset[:,1]), max(test_dataset[:,1])))
```

1.  ç°åœ¨æˆ‘ä»¬å®šä¹‰ä¸€ä¸ªåä¸º `convert_dataset` çš„å‡½æ•°ï¼Œå°†æ•°æ®é›†è½¬æ¢ä¸ºçŸ©é˜µã€‚å®ƒé€šè¿‡åˆ›å»ºä¸€ä¸ªå¾ªç¯æ¥è¿è¡Œæ•°æ®é›†ï¼Œå¹¶è·å–ç‰¹å®šç”¨æˆ·è¯„åˆ†çš„æ‰€æœ‰ç”µå½±åŠè¯¥ç”¨æˆ·çš„è¯„åˆ†ã€‚å› ä¸ºç”¨æˆ·æ²¡æœ‰è¯„çº§è¿‡çš„ç”µå½±æœ‰è®¸å¤šï¼Œæ‰€ä»¥æˆ‘ä»¬é¦–å…ˆåˆ›å»ºä¸€ä¸ªå…¨é›¶çŸ©é˜µï¼š

```py
def convert_dataset(data):
    converted_data = []
    for id_users in range(1, no_users + 1):
        id_movies = data[:,1][data[:,0] == id_users]
        id_ratings = data[:,2][data[:,0] == id_users]
        movie_ratings = np.zeros(no_movies)
        ratings[id_movies - 1] = id_ratings
        converted_data.append(list(movie_ratings))
    return converted_data

training_dataset = convert_dataset(training_dataset)
test_dataset = convert_dataset(test_dataset)
```

1.  ç°åœ¨æˆ‘ä»¬ä½¿ç”¨ `FloatTensor` å®ç”¨ç¨‹åºå°†æ•°æ®è½¬æ¢ä¸º Torch å¼ é‡ã€‚è¿™å°†æŠŠæ•°æ®é›†è½¬æ¢ä¸º PyTorch æ•°ç»„ï¼š

```py
training_dataset = torch.FloatTensor(training_dataset)
test_dataset = torch.FloatTensor(test_dataset)
```

1.  åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬æƒ³è¦è¿›è¡ŒäºŒå…ƒåˆ†ç±»ï¼Œå³ç”¨æˆ·æ˜¯å¦å–œæ¬¢è¿™éƒ¨ç”µå½±ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å°†è¯„åˆ†è½¬æ¢ä¸ºé›¶å’Œä¸€ã€‚ä½†æ˜¯é¦–å…ˆï¼Œæˆ‘ä»¬å°†ç°æœ‰çš„é›¶æ›¿æ¢ä¸º -1ï¼Œä»¥è¡¨ç¤ºç”¨æˆ·ä»æœªè¯„çº§è¿‡çš„ç”µå½±ï¼š

```py
training_dataset[training_dataset == 0] = -1
training_dataset[training_dataset == 1] = 0
training_dataset[training_dataset == 2] = 0
training_dataset[training_dataset >= 3] = 1
test_dataset[test_dataset == 0] = -1
test_dataset[test_dataset == 1] = 0
test_dataset[test_dataset == 2] = 0
test_dataset[test_dataset >= 3] = 1
```

1.  ç°åœ¨ï¼Œæˆ‘ä»¬éœ€è¦åˆ›å»ºä¸€ä¸ªç±»æ¥å®šä¹‰ RBM çš„æ¶æ„ã€‚è¯¥ç±»é€šè¿‡ä½¿ç”¨éšæœºæ­£æ€åˆ†å¸ƒåˆå§‹åŒ–æƒé‡å’Œåç½®ã€‚è¿˜å®šä¹‰äº†ä¸¤ç§ç±»å‹çš„åç½®ï¼Œå…¶ä¸­ `a` æ˜¯ç»™å®šå¯è§èŠ‚ç‚¹æ—¶éšè—èŠ‚ç‚¹çš„æ¦‚ç‡ï¼Œ`b` æ˜¯ç»™å®šéšè—èŠ‚ç‚¹æ—¶å¯è§èŠ‚ç‚¹çš„æ¦‚ç‡ã€‚è¯¥ç±»åˆ›å»ºäº†ä¸€ä¸ª `sample_hidden_nodes` å‡½æ•°ï¼Œå®ƒä»¥ `x` ä½œä¸ºå‚æ•°å¹¶è¡¨ç¤ºå¯è§ç¥ç»å…ƒã€‚ä»è¿™é‡Œï¼Œæˆ‘ä»¬è®¡ç®—ç»™å®š `v` çš„ `h` çš„æ¦‚ç‡ï¼Œå…¶ä¸­ `h` å’Œ `v` åˆ†åˆ«è¡¨ç¤ºéšè—å’Œå¯è§èŠ‚ç‚¹ã€‚è¿™ä»£è¡¨äº† S å‹æ¿€æ´»å‡½æ•°ã€‚å®ƒè®¡ç®—ä¸ºæƒé‡å‘é‡å’Œ `x` çš„ä¹˜ç§¯åŠ ä¸Šåç½® `a`ã€‚ç”±äºæˆ‘ä»¬è€ƒè™‘çš„æ˜¯äºŒå…ƒåˆ†ç±»æ¨¡å‹ï¼Œæˆ‘ä»¬è¿”å›éšè—ç¥ç»å…ƒçš„ä¼¯åŠªåˆ©æ ·æœ¬ã€‚ä»è¿™é‡Œï¼Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ª `sample_visible_function` å‡½æ•°ï¼Œå®ƒå°†å¯¹å¯è§èŠ‚ç‚¹è¿›è¡Œé‡‡æ ·ã€‚æœ€åï¼Œæˆ‘ä»¬åˆ›å»ºè®­ç»ƒå‡½æ•°ã€‚å®ƒæ¥å—åŒ…å«ç”µå½±è¯„åˆ†çš„è¾“å…¥å‘é‡ã€*k* æ¬¡é‡‡æ ·åè·å¾—çš„å¯è§èŠ‚ç‚¹ã€æ¦‚ç‡å‘é‡ä»¥åŠ *k* æ¬¡é‡‡æ ·åçš„éšè—èŠ‚ç‚¹çš„æ¦‚ç‡ï¼š

```py
class RBM():
    def __init__(self, num_visible_nodes, num_hidden_nodes):
        self.W = torch.randn(num_hidden_nodes, num_visible_nodes)
        self.a = torch.randn(1, num_hidden_nodes)
        self.b = torch.randn(1, num_visible_nodes)

    def sample_hidden_nodes(self, x):
        wx = torch.mm(x, self.W.t())
        activation = wx + self.a.expand_as(wx)
        p_h_given_v = torch.sigmoid(activation)
        return p_h_given_v, torch.bernoulli(p_h_given_v)

    def sample_visible_nodes(self, y):
        wy = torch.mm(y, self.W)
        activation = wy + self.b.expand_as(wy)
        p_v_given_h = torch.sigmoid(activation)
        return p_v_given_h, torch.bernoulli(p_v_given_h)

    def train(self, v0, vk, ph0, phk):
        self.W += torch.mm(v0.t(), ph0) - torch.mm(vk.t(), phk)
        self.b += torch.sum((v0 - vk), 0)
        self.a += torch.sum((ph0 - phk), 0)
```

1.  ç°åœ¨æˆ‘ä»¬å®šä¹‰æˆ‘ä»¬çš„æ¨¡å‹å‚æ•°ï¼š

```py
num_visible_nodes = len(training_dataset[0])
num_hidden_nodes = 200
batch_size = 100
rbm = RBM(num_visible_nodes, num_hidden_nodes)
```

1.  ä»è¿™é‡Œï¼Œæˆ‘ä»¬å¯ä»¥ä¸ºæ¯ä¸ª epoch è®­ç»ƒæ¨¡å‹ï¼š

```py
nb_epoch = 10
for epoch in range(1, nb_epoch + 1):
    train_loss = 0
    s = 0.
    for id_user in range(0, nb_users - batch_size, batch_size):
        vk = training_dataset[id_user:id_user+batch_size]
        v0 = training_dataset[id_user:id_user+batch_size]
        ph0,_ = rbm.sample_hidden_nodes(v0)
        for k in range(10):
            _,hk = rbm.sample_hidden_nodes(vk)
            _,vk = rbm.sample_visible_nodes(hk)
            vk[v0<0] = v0[v0<0]
        phk,_ = rbm.sample_hidden_nodes(vk)
        rbm.train(v0, vk, ph0, phk)
        train_loss += torch.mean(torch.abs(v0[v0>=0] - vk[v0>=0]))
        s += 1.
    print('epoch: '+str(epoch)+' loss: '+str(train_loss/s))
```

æˆ‘ä»¬å¯ä»¥åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ç»˜åˆ¶è·¨ epoch çš„é”™è¯¯ï¼š

![](img/c613abe5-4900-4baa-bf32-656a44fdf51a.png)

è¿™å¯ä»¥å¸®åŠ©æˆ‘ä»¬ç¡®å®šåº”è¯¥è¿è¡Œå¤šå°‘ä¸ª epoch è¿›è¡Œè®­ç»ƒã€‚æ˜¾ç¤ºåœ¨å…­ä¸ª epoch åï¼Œæ”¹è¿›çš„æ€§èƒ½ç‡ä¸‹é™ï¼Œå› æ­¤æˆ‘ä»¬åº”è¯¥è€ƒè™‘åœ¨è¿™ä¸ªé˜¶æ®µåœæ­¢è®­ç»ƒã€‚

æˆ‘ä»¬å·²ç»çœ‹åˆ°äº†åœ¨ RBM ä¸­å®ç°æ¨èç³»ç»Ÿçš„ç¼–ç ç¤ºä¾‹ï¼Œç°åœ¨è®©æˆ‘ä»¬ç®€è¦åœ°æµè§ˆä¸€ä¸‹ DBN æ¶æ„ã€‚

# DBN æ¶æ„

DBN æ˜¯ä¸€ä¸ªå¤šå±‚ä¿¡å¿µç½‘ç»œï¼Œæ¯ä¸€å±‚éƒ½æ˜¯ä¸€ä¸ªå åŠ çš„ RBMã€‚é™¤äº† DBN çš„ç¬¬ä¸€å±‚å’Œæœ€åä¸€å±‚ä¹‹å¤–ï¼Œæ¯ä¸€å±‚æ—¢ä½œä¸ºå…¶å‰é¢èŠ‚ç‚¹çš„éšè—å±‚ï¼Œåˆä½œä¸ºå…¶åèŠ‚ç‚¹çš„è¾“å…¥å±‚ï¼š

![](img/476edcd1-4181-4f6b-8111-adf963439fc9.png)

DBN ä¸­çš„ä¸¤ä¸ªå±‚é€šè¿‡æƒé‡çŸ©é˜µè¿æ¥ã€‚DBN çš„é¡¶éƒ¨ä¸¤å±‚æ˜¯æ— å‘çš„ï¼Œå®ƒä»¬ä¹‹é—´å½¢æˆå¯¹ç§°è¿æ¥ï¼Œå½¢æˆè”æƒ³å­˜å‚¨å™¨ã€‚è¾ƒä½çš„ä¸¤å±‚ç›´æ¥è¿æ¥åˆ°ä¸Šé¢çš„å±‚ã€‚æ–¹å‘æ„Ÿå°†è”æƒ³å­˜å‚¨å™¨è½¬æ¢ä¸ºè§‚å¯Ÿå˜é‡ï¼š

![](img/884509b6-a309-48a5-a398-c1a3f3cde68f.png)

DBN çš„ä¸¤ä¸ªæœ€æ˜¾è‘—ç‰¹æ€§å¦‚ä¸‹ï¼š

+   DBN é€šè¿‡é«˜æ•ˆçš„é€å±‚è¿‡ç¨‹å­¦ä¹ è‡ªé¡¶å‘ä¸‹çš„ç”Ÿæˆæƒé‡ã€‚è¿™äº›æƒé‡å†³å®šäº†ä¸€ä¸ªå±‚ä¸­çš„å˜é‡å¦‚ä½•ä¾èµ–äºä¸Šé¢çš„å±‚ã€‚

+   è®­ç»ƒå®Œæˆåï¼Œå¯ä»¥é€šè¿‡å•ä¸ªè‡ªä¸‹è€Œä¸Šçš„ä¼ é€’æ¨æ–­æ¯å±‚éšè—å˜é‡çš„å€¼ã€‚ä¼ é€’ä»åº•å±‚çš„å¯è§æ•°æ®å‘é‡å¼€å§‹ï¼Œå¹¶ä½¿ç”¨å…¶ç”Ÿæˆæƒé‡ç›¸åæ–¹å‘ã€‚

è”åˆé…ç½®ç½‘ç»œçš„æ¦‚ç‡åœ¨å¯è§å±‚å’Œéšè—å±‚ä¹‹é—´çš„è”åˆé…ç½®ç½‘ç»œçš„èƒ½é‡ä¾èµ–äºæ‰€æœ‰å…¶ä»–è”åˆé…ç½®ç½‘ç»œçš„èƒ½é‡ï¼š

![](img/9b151fd9-0ff8-4e58-b605-3c292d38b857.png)

ä¸€æ—¦ RBMs å †æ ˆå®Œæˆäº† DBN çš„é¢„è®­ç»ƒé˜¶æ®µï¼Œå°±å¯ä»¥ä½¿ç”¨å‰å‘ç½‘ç»œè¿›è¡Œå¾®è°ƒé˜¶æ®µï¼Œä»è€Œåˆ›å»ºåˆ†ç±»å™¨æˆ–åœ¨æ— ç›‘ç£å­¦ä¹ åœºæ™¯ä¸­ç®€å•åœ°å¸®åŠ©èšç±»æ— æ ‡ç­¾æ•°æ®ã€‚

# å¾®è°ƒ

å¾®è°ƒçš„ç›®æ ‡æ˜¯æ‰¾åˆ°å±‚é—´æƒé‡çš„æœ€ä¼˜å€¼ã€‚å®ƒå¾®è°ƒåŸå§‹ç‰¹å¾ï¼Œä»¥è·å¾—æ›´ç²¾ç¡®çš„ç±»è¾¹ç•Œã€‚ä¸ºäº†å¸®åŠ©æ¨¡å‹å°†æ¨¡å¼å’Œç‰¹å¾å…³è”åˆ°æ•°æ®é›†ï¼Œä½¿ç”¨äº†ä¸€ä¸ªå°çš„æ ‡è®°æ•°æ®é›†ã€‚

å¾®è°ƒå¯ä»¥ä½œä¸ºéšæœºçš„è‡ªä¸‹è€Œä¸Šä¼ é€’åº”ç”¨ï¼Œç„¶åç”¨äºè°ƒæ•´è‡ªä¸Šè€Œä¸‹çš„æƒé‡ã€‚ä¸€æ—¦è¾¾åˆ°é¡¶å±‚ï¼Œé€’å½’è¢«åº”ç”¨äºé¡¶å±‚ã€‚ä¸ºäº†è¿›ä¸€æ­¥å¾®è°ƒï¼Œæˆ‘ä»¬å¯ä»¥è¿›è¡Œéšæœºçš„è‡ªä¸Šè€Œä¸‹ä¼ é€’ï¼Œå¹¶è°ƒæ•´è‡ªä¸‹è€Œä¸Šçš„æƒé‡ã€‚

# æ€»ç»“

åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬è§£é‡Šäº†è‡ªç¼–ç å™¨åŠå…¶ä¸åŒçš„å˜ä½“ã€‚åœ¨æ•´ä¸ªç« èŠ‚ä¸­ï¼Œæˆ‘ä»¬æä¾›äº†ä¸€äº›ç¼–ç ç¤ºä¾‹ï¼Œå±•ç¤ºå®ƒä»¬å¦‚ä½•åº”ç”¨äº MNIST æ•°æ®é›†ã€‚åæ¥æˆ‘ä»¬ä»‹ç»äº†å—é™ç»å°”å…¹æ›¼æœºï¼Œå¹¶è§£é‡Šäº†å¦‚ä½•å°†å…¶å¼€å‘æˆæ·±åº¦ç»å°”å…¹æ›¼æœºï¼ŒåŒæ—¶æä¾›äº†é¢å¤–çš„ç¤ºä¾‹ã€‚

åœ¨ä¸‹ä¸€ç« ä¸­ï¼Œæˆ‘ä»¬å°†ä»‹ç»ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼Œå¹¶å±•ç¤ºå®ƒä»¬å¦‚ä½•ç”¨äºç”Ÿæˆå›¾åƒå’Œæ–‡æœ¬ã€‚

# è¿›ä¸€æ­¥é˜…è¯»

è¿›ä¸€æ­¥çš„ä¿¡æ¯è¯·å‚è€ƒä»¥ä¸‹å†…å®¹ï¼š

+   *å˜åˆ†è‡ªç¼–ç å™¨æ•™ç¨‹*: [`arxiv.org/abs/1606.05908`](https://arxiv.org/abs/1606.05908)

+   *CS598LAZ â€“ å˜åˆ†è‡ªç¼–ç å™¨*: [`slazebni.cs.illinois.edu/spring17/lec12_vae.pdf`](http://slazebni.cs.illinois.edu/spring17/lec12_vae.pdf)

+   *è‡ªç¼–ç å˜åˆ†è´å¶æ–¯*: [`arxiv.org/abs/1312.6114`](https://arxiv.org/abs/1312.6114)

+   *æ·±åº¦å­¦ä¹ ä¹¦ç±*: [`www.deeplearningbook.org/contents/autoencoders.html`](https://www.deeplearningbook.org/contents/autoencoders.html)

+   *æ·±åº¦ä¿¡å¿µç½‘å¿«é€Ÿå­¦ä¹ ç®—æ³•*: [`www.cs.toronto.edu/~fritz/absps/ncfast.pdf`](http://www.cs.toronto.edu/~fritz/absps/ncfast.pdf)

+   *è®­ç»ƒå—é™ç»å°”å…¹æ›¼æœºï¼šç®€ä»‹*: [`www.sciencedirect.com/science/article/abs/pii/S0031320313002495`](https://www.sciencedirect.com/science/article/abs/pii/S0031320313002495)

+   *æ·±åº¦ç»å°”å…¹æ›¼æœº*: [`proceedings.mlr.press/v5/salakhutdinov09a/salakhutdinov09a.pdf`](http://proceedings.mlr.press/v5/salakhutdinov09a/salakhutdinov09a.pdf)

+   *è®­ç»ƒå—é™ç»å°”å…¹æ›¼æœºå®ç”¨æŒ‡å—*: [`www.cs.toronto.edu/~hinton/absps/guideTR.pdf`](https://www.cs.toronto.edu/~hinton/absps/guideTR.pdf)

+   *æ·±åº¦ä¿¡å¿µç½‘ç»œ*: [`link.springer.com/chapter/10.1007/978-3-319-06938-8_8`](https://link.springer.com/chapter/10.1007/978-3-319-06938-8_8)

+   *å®æˆ˜ç¥ç»ç½‘ç»œ:* [`www.amazon.co.uk/Hands-Neural-Networks-neural-network-ebook/dp/B07SKDSGB6/`](https://www.amazon.co.uk/Hands-Neural-Networks-neural-network-ebook/dp/B07SKDSGB6/)
