["```py\n    Output height = 64 -3 + 1 = 62\n    Output width = 64 - 3 + 1 = 62\n    Output depth = 1\n    ```", "```py\n    Output height = 32 - 5 + (2 * 2) + 1 = 32\n    Output width = 32-5 + (2 * 2) + 1 = 32\n    Output depth = 10\n    ```", "```py\n    Output height = (128 - 5)/ 3 + 1 = 42\n    Output width = (128 - 5)/ 3 + 1 = 42\n    Output depth = 5\n    ```", "```py\n    Output height = ((64 - 8 + (2 * 3)) / 3) +1 = 21.6 ≈ 21\n    Output width = ((64 - 8 + (2 * 3)) / 3) +1 = 21.6 ≈ 21\n    Output depth = 1\n    ```", "```py\nimport torch.nn as nn\nimport torch.nn.functional as F\nclass CNN_network(nn.Module):\n    def __init__(self):\n        super(CNN_network, self).__init__()\n# input channels = 3, output channels = 18,\n# filter size = 3, stride = 1 and padding = 1\n        self.conv1 = nn.Conv2d(3, 18, 3, 1, 1)\n        def forward(self, x):\n            x = F.relu(self.conv1(x))\n        return x\n```", "```py\nimport torch.nn as nn\nclass CNN_network(nn.Module):\n    def __init__(self):\n        super(CNN_network, self).__init__()\n        self.conv1 = nn.Sequential(nn.Conv2d(1, 16, 5, 1, 2,),                               nn.ReLU())\n    def forward(self, x):\n        x = self.conv1(x)\n\n        return x\n```", "```py\n    # After the first convolutional layer\n    output_matrix_size = 256 x 256 x 16\n    # After the first pooling layer\n    output_matrix_size = 128 x 128 x 16\n    # After the second convolutional layer\n    output_matrix_size = 128 x 128 x 8\n    # After the second pooling layer\n    output_matrix_size = 64 x 64 x 8\n    ```", "```py\n    import torch.nn as nn\n    import torch.nn.functional as F\n    class CNN_network(nn.Module):\n        def __init__(self):\n            super(CNN_network, self).__init__()\n            self.conv1 = nn.Conv2d(3, 18, 3, 1, 1)\n            self.pool1 = nn.MaxPool2d(2, 2)\n            def forward(self, x):\n                x = F.relu(self.conv1(x))\n                x = self.pool1(x)\n            return x\n    ```", "```py\n    import torch.nn as nn\n    class CNN_network(nn.Module):\n        def __init__(self):\n            super(CNN_network, self).__init__()\n            self.conv1 = nn.Sequential(nn.Conv2d(1, 16, 5, 1, 2,),                               nn.ReLU(),\n                                  nn.MaxPool2d(2, 2))\n        def forward(self, x):\n            x = self.conv1(x)\n\n            return x\n    ```", "```py\nimport torch.nn as nn\nimport torch.nn.functional as F\nclass CNN_network(nn.Module):\n\ndef __init__(self):\n    super(CNN_network, self).__init__()\n\n    self.conv1 = nn.Conv2d(3, 18, 3, 1, 1)    \n    self.pool1 = nn.MaxPool2d(2, 2)\n    self.linear1 = nn.Linear(32*32*16, 64)\n    self.linear2 = nn.Linear(64, 10)\n\ndef forward(self, x):\n    x = F.relu(self.conv1(x))\n    x = self.pool1(x)\n    x = x.view(-1, 32 * 32 *16)\n    x = F.relu(self.linear1(x))\n    x = F.log_softmax(self.linear2(x), dim=1)\n    return x\n```", "```py\nimport torch.nn as nn\nclass CNN_network(nn.Module):\n    def __init__(self):\n        super(CNN_network, self).__init__()\n        self.conv1 = nn.Sequential(nn.Conv2d(1, 16, 5, 1, 2,),                               nn.ReLU(),\n                              nn.MaxPool2d(2, 2))\n        self.linear1 = nn.Linear(32*32*16, 64)\n        self.linear2 = nn.Linear(64, 10)\n    def forward(self, x):\n        x = self.conv1(x)\n\n        x = x.view(-1, 32 * 32 *16)\n        x = F.relu(self.linear1(x))\n        x = F.log_softmax(self.linear2(x), dim=1)\n\n        return x\n```", "```py\nfrom torchvision import datasets\nimport torchvision.transforms as transforms\nbatch_size = 20\ntransform = transforms.Compose([transforms.ToTensor(),\ntransforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\ntrain_data = datasets.MNIST(root='data', train=True,\ndownload=True, transform=transform)\ntest_data = datasets.MNIST(root='data', train=False,\n                           download=True, transform=transform)\ndev_size = 0.2\nidx = list(range(len(train_data)))\nnp.random.shuffle(idx)\nsplit_size = int(np.floor(dev_size * len(train_data)))\ntrain_idx, dev_idx = idx[split_size:], idx[:split_size]\ntrain_sampler = SubsetRandomSampler(train_idx)\ndev_sampler = SubsetRandomSampler(dev_idx)\ntrain_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=train_sampler)\ndev_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=dev_sampler)\ntest_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size)\n```", "```py\n    import numpy as np\n    import torch\n    from torch import nn, optim\n    import torch.nn.functional as F\n    from torchvision import datasets\n    import torchvision.transforms as transforms\n    from torch.utils.data.sampler import SubsetRandomSampler\n    from sklearn.metrics import accuracy_score\n    import matplotlib.pyplot as plt\n    ```", "```py\ntransform = transforms.Compose([\n            transforms.HorizontalFlip(probability_goes_here), \n            transforms.RandomGrayscale(probability_goes_here),\n            transforms.ToTensor(),\n            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\ntrain_data = datasets.CIFAR10('data', train=True, download=True, transform=transform)\ntest_data = datasets.CIFAR10('data', train=False, download=True, transform=transform)\n```", "```py\ntransform = {\n    \"train\": transforms.Compose([\n    transforms.RandomHorizontalFlip(probability_goes_here), \n    transforms.RandomGrayscale(probability_goes_here),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]),\n    \"test\": transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n    transforms.Resize(size_goes_here)])}\ntrain_data = datasets.CIFAR10('data', train=True, download=True, transform=transform[\"train\"])\ntest_data = datasets.CIFAR10('data', train=False, download=True, transform=transform[\"test\"])\n```", "```py\nclass CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n        self.conv1 = nn.Conv2d(3, 16, 3, 1, 1)\n        self.norm1 = nn.BatchNorm2d(16)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.linear1 = nn.Linear(16 * 16 * 16, 100)\n        self.norm2 = nn.BatchNorm1d(100)\n        self.linear2 = nn.Linear(100, 10)\n        def forward(self, x):\n            x = self.pool(self.norm1(F.relu(self.conv1(x))))\n            x = x.view(-1, 16 * 16 * 16)\n            x = self.norm2(F.relu(self.linear1(x)))\n            x = F.log_softmax(self.linear2(x), dim=1)\n        return x\n```"]