["```py\n    !wget https://www.dropbox.com/s/l98lee/Hemanvi.jpeg \n    ```", "```py\n    %matplotlib inline\n    import cv2, matplotlib.pyplot as plt\n    img = cv2.imread('Hemanvi.jpeg') \n    ```", "```py\n    # Crop image\n    img = img[50:250,40:240]\n    # Convert image to grayscale\n    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    # Show image\n    plt.imshow(img_gray, cmap='gray') \n    ```", "```py\n    img_gray_small = cv2.resize(img_gray,(25,25))\n    plt.imshow(img_gray_small, cmap='gray') \n    ```", "```py\n    print(img_gray_small) \n    ```", "```py\n    !wget https://www.dropbox.com/s/l98lee/Hemanvi.jpeg \n    ```", "```py\n    import cv2, matplotlib.pyplot as plt\n    %matplotlib inline\n    img = cv2.imread('Hemanvi.jpeg') \n    ```", "```py\n    img = img[50:250,40:240,:]\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) \n    ```", "```py\n    plt.imshow(img)\n    print(img.shape)\n    # (200,200,3) \n    ```", "```py\n    crop = img[-3:,-3:] \n    ```", "```py\n    print(crop)\n    plt.imshow(crop) \n    ```", "```py\n    from torchvision import datasets\n    import torch\n    data_folder = '~/data/FMNIST' # This can be any directory\n    # you want to download FMNIST to\n    fmnist = datasets.FashionMNIST(data_folder, download=True, train=True) \n    ```", "```py\n    tr_images = fmnist.data\n    tr_targets = fmnist.targets \n    ```", "```py\n    unique_values = tr_targets.unique()\n    print(f'tr_images & tr_targets:\\n\\tX -{tr_images.shape}\\n\\tY \\\n    -{tr_targets.shape}\\n\\tY-Unique Values : {unique_values}')\n    print(f'TASK:\\n\\t{len(unique_values)} class Classification')\n    print(f'UNIQUE CLASSES:\\n\\t{fmnist.classes}') \n    ```", "```py\n    import matplotlib.pyplot as plt\n    %matplotlib inline\n    import numpy as np \n    ```", "```py\n    R, C = len(tr_targets.unique()), 10\n    fig, ax = plt.subplots(R, C, figsize=(10,10))\n    for label_class, plot_row in enumerate(ax):\n        label_x_rows = np.where(tr_targets == label_class)[0] \n    ```", "```py\n     for plot_cell in plot_row:\n            plot_cell.grid(False); plot_cell.axis('off')\n            ix = np.random.choice(label_x_rows)\n            x, y = tr_images[ix], tr_targets[ix]\n            plot_cell.imshow(x, cmap='gray')\n    plt.tight_layout() \n    ```", "```py\n    from torch.utils.data import Dataset, DataLoader\n    import torch\n    import torch.nn as nn\n    import numpy as np\n    import matplotlib.pyplot as plt\n    %matplotlib inline\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    from torchvision import datasets\n    data_folder = '~/data/FMNIST' # This can be any directory you\n    # want to download FMNIST to\n    fmnist = datasets.FashionMNIST(data_folder, download=True, train=True)\n    tr_images = fmnist.data\n    tr_targets = fmnist.targets \n    ```", "```py\n    class FMNISTDataset(Dataset):\n        def __init__(self, x, y):\n            x = x.float()\n            x = x.view(-1,28*28)\n            self.x, self.y = x, y\n        def __getitem__(self, ix):\n            x, y = self.x[ix], self.y[ix]\n            return x.to(device), y.to(device)\n        def __len__(self):\n            return len(self.x) \n    ```", "```py\n    **def****get_data****():**\n        train = FMNISTDataset(tr_images, tr_targets)\n        trn_dl = DataLoader(train, batch_size=32, shuffle=True)\n        return trn_dl \n    ```", "```py\n    from torch.optim import SGD\n    **def****get_model****():**\n        model = nn.Sequential(\n                    nn.Linear(28 * 28, 1000),\n                    nn.ReLU(),\n                    nn.Linear(1000, 10)\n                ).to(device)\n        loss_fn = nn.CrossEntropyLoss()\n        optimizer = SGD(model.parameters(), lr=1e-2)\n        return model, loss_fn, optimizer \n    ```", "```py\n    **def****train_batch****(****x, y, model, opt, loss_fn****):**\n        **model.train()** # <- let's hold on to this until we reach\n        # dropout section\n        # call your model like any python function on your batch\n        # of inputs\n        **prediction = model(x)**\n        # compute loss\n        **batch_loss = loss_fn(prediction, y)**\n        # based on the forward pass in `model(x)` compute all the\n        # gradients of 'model.parameters()'\n        **batch_loss.backward()**\n        # apply new-weights = f(old-weights, old-weight-gradients)\n        # where \"f\" is the optimizer\n        **optimizer.step()**\n        # Flush gradients memory for next batch of calculations\n     **optimizer.zero_grad()**\n    **return** **batch_loss.item()** \n    ```", "```py\n    # since there's no need for updating weights,\n    # we might as well not compute the gradients.\n    # Using this '@' decorator on top of functions\n    # will disable gradient computation in the entire function\n    **@torch.no_grad()**\n    **def****accuracy****(****x, y, model****):**\n        **model.****eval****()** # <- let's wait till we get to dropout\n        # section\n        # get the prediction matrix for a tensor of `x` images\n        **prediction = model(x)**\n        # compute if the location of maximum in each row\n        # coincides with ground truth\n        **max_values, argmaxes = prediction.****max****(-****1****)**\n        **is_correct = argmaxes == y**\n        **return** **is_correct.cpu().numpy().tolist()** \n    ```", "```py\n    trn_dl = get_data()\n    model, loss_fn, optimizer = get_model() \n    ```", "```py\n    losses, accuracies = [], [] \n    ```", "```py\n    for epoch in range(5):\n        print(epoch) \n    ```", "```py\n     epoch_losses, epoch_accuracies = [], [] \n    ```", "```py\n     for ix, batch in enumerate(iter(trn_dl)):\n            x, y = batch \n    ```", "```py\n     batch_loss = train_batch(x, y, model,optimizer, loss_fn)\n            epoch_losses.append(batch_loss) \n    ```", "```py\n     epoch_loss = np.array(epoch_losses).mean() \n    ```", "```py\n     for ix, batch in enumerate(iter(trn_dl)):\n            x, y = batch\n            is_correct = accuracy(x, y, model)\n            epoch_accuracies.extend(is_correct)\n        epoch_accuracy = np.mean(epoch_accuracies) \n    ```", "```py\n     losses.append(epoch_loss)\n        accuracies.append(epoch_accuracy) \n    ```", "```py\n    epochs = np.arange(5)+1\n    plt.figure(figsize=(20,5))\n    plt.subplot(121)\n    plt.title('Loss value over increasing epochs')\n    plt.plot(epochs, losses, label='Training Loss')\n    plt.legend()\n    plt.subplot(122)\n    plt.title('Accuracy value over increasing epochs')\n    plt.plot(epochs, accuracies, label='Training Accuracy')\n    plt.gca().set_yticklabels(['{:.0f}%'.format(x*100) \\\n                              for x in \\ plt.gca().get_yticks()])\n    plt.legend() \n    ```", "```py\n    class FMNISTDataset(Dataset):\n        def __init__(self, x, y):\n            **x = x.****float****()/****255**\n            x = x.view(-1,28*28)\n            self.x, self.y = x, y\n        def __getitem__(self, ix):\n            x, y = self.x[ix], self.y[ix]\n            return x.to(device), y.to(device)\n        def __len__(self):\n            return len(self.x) \n    ```", "```py\n    val_fmnist =datasets.FashionMNIST(data_folder,download=True, train=False)\n    val_images = val_fmnist.data\n    val_targets = val_fmnist.targets \n    ```", "```py\n    def get_data():\n        train = FMNISTDataset(tr_images, tr_targets)\n        trn_dl = DataLoader(train, **batch_size=****32**, shuffle=True)\n        val = FMNISTDataset(val_images, val_targets)\n        val_dl = DataLoader(val, batch_size=len(val_images),\n                                                shuffle=False)\n        return trn_dl, val_dl \n    ```", "```py\n    @torch.no_grad()\n    def val_loss(x, y, model):\n        model.eval()\n        prediction = model(x)\n        val_loss = loss_fn(prediction, y)\n        return val_loss.item() \n    ```", "```py\n    trn_dl, val_dl = get_data()\n    model, loss_fn, optimizer = get_model() \n    ```", "```py\n    train_losses, train_accuracies = [], []\n    val_losses, val_accuracies = [], [] \n    ```", "```py\n    for epoch in range(5):\n        print(epoch)\n        train_epoch_losses, train_epoch_accuracies = [], [] \n    ```", "```py\n     for ix, batch in enumerate(iter(trn_dl)):\n            x, y = batch\n            batch_loss = train_batch(x, y, model,optimizer, loss_fn)\n            train_epoch_losses.append(batch_loss)\n        train_epoch_loss = np.array(train_epoch_losses).mean()\n        for ix, batch in enumerate(iter(trn_dl)):\n            x, y = batch\n            is_correct = accuracy(x, y, model)\n            train_epoch_accuracies.extend(is_correct)\n        train_epoch_accuracy = np.mean(train_epoch_accuracies) \n    ```", "```py\n     for ix, batch in enumerate(iter(val_dl)):\n            x, y = batch\n            val_is_correct = accuracy(x, y, model)\n            validation_loss = val_loss(x, y, model)\n        val_epoch_accuracy = np.mean(val_is_correct) \n    ```", "```py\n     train_losses.append(train_epoch_loss)\n        train_accuracies.append(train_epoch_accuracy)\n        val_losses.append(validation_loss)\n        val_accuracies.append(val_epoch_accuracy) \n    ```", "```py\n    **from** **torch.optim** **import** **SGD, Adam**\n    def get_model():\n        model = nn.Sequential(\n                    nn.Linear(28 * 28, 1000),\n                    nn.ReLU(),\n                    nn.Linear(1000, 10)\n                ).to(device)\n        loss_fn = nn.CrossEntropyLoss()\n        optimizer = **SGD**(model.parameters(), lr=1e-2)\n        return model, loss_fn, optimizer \n    ```", "```py\ndef get_model():\n    model = nn.Sequential(\n                nn.Linear(28 * 28, 1000),\n                nn.ReLU(),\n **nn.Linear(****1000****,** **1000****),**\n **nn.ReLU(),**\n                nn.Linear(1000, 10)\n            ).to(device)\n    loss_fn = nn.CrossEntropyLoss()\n    optimizer = Adam(model.parameters(), lr=1e-3)\n    return model, loss_fn, optimizer \n```", "```py\ndef get_model():\n    model = nn.Sequential(\n                **nn.Linear(****28** ***** **28****,** **10****)**\n            ).to(device)\n    loss_fn = nn.CrossEntropyLoss()\n    optimizer = Adam(model.parameters(), lr=1e-3)\n    return model, loss_fn, optimizer \n```", "```py\nclass FMNISTDataset(Dataset):\n    def __init__(self, x, y):\n        **x = x.****float****()/(****255*********10000****)** **# Done only for us to**\n**# understand the impact of Batch normalization**\n        x = x.view(-1,28*28)\n        self.x, self.y = x, y\n    def __getitem__(self, ix):\n        x, y = self.x[ix], self.y[ix]\n        return x.to(device), y.to(device)\n    def __len__(self):\n        return len(self.x) \n```", "```py\ndef get_model():\n    class neuralnet(nn.Module):\n        def __init__(self):\n            super().__init__()\n            self.input_to_hidden_layer = nn.Linear(784,1000)\n            self.hidden_layer_activation = nn.ReLU()\n            self.hidden_to_output_layer = nn.Linear(1000,10)\n        def forward(self, x):\n            x = self.input_to_hidden_layer(x)\n            x1 = self.hidden_layer_activation(x)\n            x2= self.hidden_to_output_layer(x1)\n            return x2, x1\n    model = neuralnet().to(device)\n    loss_fn = nn.CrossEntropyLoss()\n    optimizer = Adam(model.parameters(), lr=1e-3)\n    return model, loss_fn, optimizer \n```", "```py\ndef train_batch(x, y, model, opt, loss_fn):\n    model.train()\n    **prediction = model(x)[****0****]**\n    batch_loss = loss_fn(prediction, y)\n    batch_loss.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n    return batch_loss.item()\ndef accuracy(x, y, model):\n    model.eval()\n    with torch.no_grad():\n        **prediction = model(x)[****0****]**\n    max_values, argmaxes = prediction.max(-1)\n    is_correct = argmaxes == y\n    return is_correct.cpu().numpy().tolist() \n```", "```py\ndef get_model():\n    class neuralnet(nn.Module):\n        def __init__(self):\n            super().__init__()\n            self.input_to_hidden_layer = nn.Linear(784,1000)\n            **self.batch_norm = nn.BatchNorm1d(****1000****)**\n            self.hidden_layer_activation = nn.ReLU()\n            self.hidden_to_output_layer = nn.Linear(1000,10)\n        def forward(self, x):\n            x = self.input_to_hidden_layer(x)\n            **x0 = self.batch_norm(x)**\n **x1 = self.hidden_layer_activation(x0)**\n            x2= self.hidden_to_output_layer(x1)\n            return x2, x1\n    model = neuralnet().to(device)\n    loss_fn = nn.CrossEntropyLoss()\n    optimizer = Adam(model.parameters(), lr=1e-3)\n    return model, loss_fn, optimizer \n```", "```py\ndef get_model():\n    model = nn.Sequential(\n                **nn.Dropout(****0.25****),**\n                nn.Linear(28 * 28, 1000),\n                nn.ReLU(),\n                **nn.Dropout(****0.25****),**\n                nn.Linear(1000, 10)\n            ).to(device)\n    loss_fn = nn.CrossEntropyLoss()\n    optimizer = Adam(model.parameters(), lr=1e-3)\n    return model, loss_fn, optimizer \n```", "```py\ndef train_batch(x, y, model, opt, loss_fn):\n    model.train()\n    prediction = model(x)\n    **l1_regularization =** **0**\n    for param in model.parameters():\n        **l1_regularization += torch.norm(param,****1****)**\n    **batch_loss = loss_fn(prediction, y)+****0.0001*****l1_regularization**\n    batch_loss.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n    return batch_loss.item() \n```", "```py\ndef train_batch(x, y, model, opt, loss_fn):\n    model.train()\n    prediction = model(x)\n    **l2_regularization =** **0**\n    for param in model.parameters():\n        **l2_regularization += torch.norm(param,****2****)**\n    **batch_loss = loss_fn(prediction, y) +** **0.01*****l2_regularization**\n    batch_loss.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n    return batch_loss.item() \n```"]