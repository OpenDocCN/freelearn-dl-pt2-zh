- en: 'Chapter 4: GPT-3 as Enabler for Next-Gen Startups'
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
- en: Before the release of GPT-3, most people’s interaction with AI was limited to
    certain specific tasks, like asking Alexa to play your favorite song or using
    Google Translate to converse in different languages. Researchers have successfully
    developed AIs capable of performing mundane tasks, but so far, AIs have yet to
    match humans’ creative potential in performing abstract tasks without clear, well-defined
    instructions.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: 'With the era of LLMs around the corner, we are looking at a significant paradigm
    shift. LLMs have shown us that by increasing the size of models, they can perform
    creative and complex tasks similar to humans. Now the biggest question: Is AI
    capable of performing creative activities?'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: The creative potential of AI has always been an exciting area of research, though
    mostly hidden behind the tight R&D walls of companies like Google and Facebook
    of the world. GPT-3 is changing how we interact with AI and empowering people
    to build the next generation of applications that seemed like a far-fetched idea
    before its release.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: Model-as-a-Service
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will show you how GPT-3 is powering the next wave of startups
    by fueling the imaginations of creative entrepreneurs with the right technology.
    We will also look at how AI research is progressing into commercialization in
    several domains. We’ll also speak with one of the venture capitalists backing
    these initiatives to understand the financial aspects of the burgeoning GPT-3
    economy.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: The story of how OpenAI API was created resembles many of the stories of startups
    and companies in this chapter. We interviewed Peter Welinder, VP of Product and
    Partnerships at OpenAI. What he told us was a story of bold experimentation, rapid
    iteration, and leveraging smart design to achieve economies of scale (delivering
    powerful models on a large scale for as little cost as possible).
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: 'Welinder summarizes OpenAI’s mission in three key points: “Develop AGI (artificial
    general intelligence), make sure it''s safe, and then lastly deploy it into the
    world to make it maximize the benefit to all of humanity.” Thus the company is
    focusing on developing AI that can be applied to a more and more general range
    of needs.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: Hoping to achieve AGI as quickly and safely as possible, one of the technologies
    on which OpenAI decided to gamble was large language models, specifically GPT-3\.
    Welinder says of trying GPT-3, “That was the first time where we had something
    that we felt like, ‘Actually, this seems to be fairly useful, it's getting state-of-the-art
    results on a number of tasks in academic benchmarks and so on.’”
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: 'Excited at the possibilities, Welinder and four colleagues debated how best
    to use the algorithm: Building a translation engine? A writing assistant? A customer-service
    application? Then it hit them. Welinder says:  “Why not instead just provide this
    technology as an API and let any developers build their own business on top of
    it?”'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: 'The API approach aligned with OpenAI’s goals and mission by maximizing the
    technology’s adoption and impact, empowering community members to invent applications
    that the OpenAI team could not have predicted. This also leaves product development
    to skilled developers worldwide, freeing up the OpenAI team to focus on what they
    are truly good at: developing robust, groundbreaking models.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: API 的方法与 OpenAI 的目标和使命相契合，通过最大化技术的采用和影响，赋予社区成员发明应用程序的能力，这是 OpenAI 团队无法预测的。这也将产品开发留给全球技术开发人员，让
    OpenAI 团队可以专注于他们真正擅长的事情：开发强大、开创性的模型。
- en: Up to this point, the researchers had focused on designing scalable, efficient
    training systems to squeeze maximum efficiency out of the GPUs. But there had
    been little focus on actually running these models on actual data and getting
    something out of them for real-world applications. So the OpenAI team decided
    to double down on the core API experience, focusing on aspects like fast inference
    and low latency.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 到这一点，研究人员一直致力于设计可扩展、高效的训练系统，以最大程度地提高 GPU 的效率。但实际上在实际数据上运行这些模型并为现实应用获取实际结果的关注却很少。因此，OpenAI
    团队决定加倍核心 API 体验，专注于快速推理和低延迟等方面。
- en: 'Six months before they planned to launch the beta version of the API, they
    had, according to Welinder, reduced latency to around ten times and increased
    throughput by hundreds of times: “We spent a ton of engineering to really take
    these models, make sure that their GPUs are as efficient as possible, make calls
    to them with really low latency, and make it scalable.” Using the model via API
    instead of needing your own GPUs makes it cost-effective and accessible for ordinary
    developers to play with use cases and try new things. Very low latency is important
    as well, to make it easy to iterate. “You don''t want to put something in and
    then wait for minutes to get the response back, which was the case in the very
    earliest days of the API. And now you can see the model output stuff in real-time,”
    Welinder says.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在计划推出 API beta 版本的六个月前，他们根据韦林德的说法，将延迟降低到约十倍，吞吐量提高了数百倍：“我们花了大量的工程技术来确保这些模型，使它们的
    GPU 尽可能高效，以及以极低的延迟调用它们，并且使其具有可扩展性。”通过 API 使用模型而不需要自己的 GPU 使其具有成本效益，并且普通开发人员可以玩转应用案例并尝试新事物。非常低的延迟也很重要，以便轻松迭代。“你不想输入东西，然后等几分钟才能收到响应，这在
    API 最早期确实是这样的情况。现在你可以实时看到模型输出的东西，”韦林德说。
- en: OpenAI believed that the models would grow, making it difficult for developers
    to deploy them; the team wanted to remove this barrier. “It's just going to cost
    you too much because you need so many GPUs and CPUs to play with a use case. It's
    not going to make economic sense for you to deploy this model by yourself,” Welinder
    says. Instead, the company decided to share the model with developers via the
    API. “Thousands of developers are using the same models, and that's the way you
    can reach economies of scale,” Welinder adds. “And that lowers the prices for
    everybody to access these models and further widens the distribution, so more
    people can try out these models.”
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI 认为这些模型将会增长，这会使开发人员难以部署它们；团队希望消除这一障碍。“这只会使您花费太多，因为您需要大量的 GPU 和 CPU 来玩转一个用例。如果您自己部署这个模型，这将毫无经济意义，”韦林德说。相反，公司决定通过
    API 与开发人员分享模型。“成千上万的开发人员正在使用相同的模型，这是您可以实现规模经济的方式，”韦林德补充说。“这降低了每个人访问这些模型的价格并进一步扩大了分发，因此更多的人可以尝试这些模型。”
- en: Releasing the OpenAI API in a private beta brought quite a few surprises. Their
    previous marquee model, GPT-2, had brought very few real-world use cases to life,
    so the team hoped GPT-3 would prove more useful. It did, and very quickly.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在私人 beta 版本发布 OpenAI API 带来了许多惊喜。他们之前的标志性模型 GPT-2 让很少实现真实世界用例，因此团队希望 GPT-3 会更有用。确实，很快就实现了。
- en: 'Another surprise, Welinder says, was that “a lot of people on our platform
    weren''t programmers. They were authors, creatives of various kinds, they were
    designers and product managers, and so on.” GPT-3 in a way, changed what it means
    to be a developer: suddenly, it turns out that to build an AI application, you
    don’t need to know how to program. You just need to be good at describing what
    you want the AI to do using prompts (as discussed in Chapter 2).'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 韦林德表示，另一个惊喜是，“我们平台上许多人并不是程序员。他们是各种作者、创意人士、设计师和产品经理等。” GPT-3 在某种程度上改变了成为开发人员意味着什么：突然间，结果表明要构建一个
    AI 应用程序，并不需要知道如何编程。你只需要擅长使用提示描述你希望 AI 执行的任务（如第 2 章所讨论）。
- en: 'Welinder and his team found that  “oftentimes people that were really good
    at it had no machine learning background”-- and those who did had to unlearn how
    they thought about a lot of problems to use GPT-3\. Many users built GPT-3-based
    applications without code. The OpenAI team had, without really intending to, lowered
    the barriers to creating applications: a first step towards democratizing AI.
    “The core strategy is to make API usable for as many people as possible, Welinder
    says: "It''s core to our mission to make sure that the barrier to use our technology
    is low. That''s why we built this API.” Another unexpected use case of GPT-3 has
    been coding. Early signs of the model’s coding potential led OpenAI to double
    down on designing for coding use cases. Their efforts resulted in Codex, released
    in mid-2021.[[11]](xhtml-0-12.xhtml#aid_72)'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: 'Along with a stunning variety of use cases, the API gave birth to a whole new
    ecosystem of startups: “Within a few months of launching the API, there were several
    companies that were being built entirely on top of the OpenAI API. Many of them
    have now raised VC funding at fairly high valuations,” Welinder says.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: One of OpenAI’s core principles is working closely with customers. Welinder
    says, "Whenever we have new product features, we try to find customers that we
    know would find those features useful, and we create direct communication channels
    where we give them early access.” For example,  they worked with several customers
    on fine-tuning search functionality before publishing that feature more broadly
    in the API.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: Open AI is primarily concerned with ensuring the safe and responsible use of
    AI. In addition to the many positive outcomes, they see growing potential for
    misuse as AI becomes more accessible to the general public. One of the main reasons
    they chose to launch the API in private beta was to understand how people would
    use the models and check their potential for abuse. They examine as many instances
    of undesirable model behavior as possible, using what they learn to inform their
    research and model training.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: Welinder finds inspiration in the breadth and creativity of the projects driven
    by the API.  “The coming decade is going to be so exciting in terms of all the
    things that people will build on top of this technology. And I think by working
    together, we can create some really good guard rails to ensure that these technologies,
    these applications that are going to be built, are going to be really, really
    positive for our society.”
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: 'A Closer Look at the New Startup Environment: Case Studies'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: Soon after OpenAI released the API, the startup landscape filled with companies
    using it to solve problems. These entrepreneurs are pioneers in state-of-the-art
    NLP products, and their journeys are informative, particularly for anyone planning
    future business applications based on OpenAI API. The rest of this chapter portrays
    this dynamic landscape through interviews with leaders of some of the top-performing
    startups using GPT-3 at the core of their product architecture about what they’ve
    learned so far in areas such as the creative arts, data analysis, chatbots, copywriting,
    and developer tools.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: 'Creative Applications of GPT-3: Fable Studio'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: One of GPT-3’s most exciting capabilities is storytelling. You can give the
    model a topic and ask it to write a story in a zero-shot setting.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: The possibilities have writers expanding their imaginations and coming up with
    extraordinary work. For instance, the play [AI](https://www.youngvic.org/whats-on/ai),
    directed by Jennifer Tang and developed with Chinonyerem Odimba and Nina Segal,
    depicts a unique collaboration between human and computer minds with the help
    of GPT-3.  And author K. Allado McDowell treated GPT-3 as a coauthor in writing
    his book [PHARMAKO-AI](https://www.goodreads.com/book/show/56247773-pharmako-ai),
    which McDowell says “reimagines cybernetics for a world facing multiple crises,
    with profound implications for how we see ourselves, nature and technology in
    the 21st century.”
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: 'We sat down with Edward Saatchi, co-founder, and CEO of Fable Studio, and Frank
    Carey, Fable Studio’s CTO, to learn about their journey of creating a new genre
    of interactive stories using GPT-3\. Fable adapted Neil Gaiman and Dave McKean’s
    children’s book The Wolves in the Walls into an Emmy Award-winning VR film experience.
    Lucy, the film’s protagonist, can have natural conversations with people thanks
    to the dialogue generated by GPT-3\. Lucy appeared as a guest at Sundance Film
    Festival 2021 and presented her movie, Dracula: Blood Gazpacho.[[12]](xhtml-0-12.xhtml#aid_84)'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: 'Saatchi and Carey noticed their audience developing emotional connections to
    Lucy. That led them to focus on using AI to create virtual beings and, with them,
    a new category of storytelling and entertainment that weaves together AI and storytelling.
    As Awan puts it, “We will have new kinds of movies and genres altogether: we will
    have interactive, integrated experiences.”'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: 'Carey explains that audiences usually think of AI taking up the role of a character,
    as an actor would: one AI corresponds to one character. Instead, Fable’s AI is
    a storyteller, with all sorts of characters in its repertoire. Carey believes
    it is possible to develop an AI storyteller as skilled and creative as the best
    human writers.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: While Lucy’s conversations mostly take place over text and video chat, Fable
    is also experimenting with GPT-3 in 3D simulated worlds for an immersive VR experience.
    The team uses AI to generate audio and gestures and to sync lip movement. They
    use GPT-3 to generate a significant amount of the content for characters’ audience
    interactions. Some of that content can be pre-authored, but much of it has to
    be created on the fly. Lucy's collaborators used GPT-3 extensively, both impromptu
    during her Sundance appearance both and during the creation of the film. As with
    Lucy’s Twitch appearances, Carey says, “more than 80% of the content was generated
    using GPT-3.”
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然Lucy的对话大多是通过文字和视频聊天进行的，但Fable还在3D模拟世界中进行了对GPT-3的实验，以实现沉浸式VR体验。团队利用AI生成音频和手势，并同步唇部动作。他们使用GPT-3来生成人物与观众互动的大部分内容。其中一些内容可以是预先创作的，但很多内容必须即兴创作。Lucy的合作者们在她在圣丹斯露面期间以及电影创作过程中广泛使用了GPT-3。就像Lucy在Twitch上露面一样，Carey说：“80%以上的内容都是使用GPT-3生成的。”
- en: This is a striking change from the team’s earlier text-only experiments, which
    were authored to a greater degree and followed a more linear narrative. The Fable
    Studio team generally didn't use GPT-3 live to handle audience members’ unpredictable
    responses; their techniques for that predated GPT-3\. They did, however, sometimes
    use GPT-3 as a writing partner or a stand-in for the audience when considering
    their potential responses.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这与团队早期仅限于文本的实验有了明显的变化，那些实验在很大程度上是由人工创作的，并且遵循了更线性的叙事。Fable工作室团队通常不会现场使用GPT-3来处理观众不可预测的回应；他们早在GPT-3之前就已经具备了这方面的技术。然而，他们有时会将GPT-3用作创作伙伴或者为观众在可能的回应中担当替身。
- en: 'Carey explains that GPT-3 is also a useful tool for human authors: “For the
    impromptu content, we’re using GPT-3 to play tests against, so you can treat GPT
    as the human and you''re sort of playing the character. Going back and forth with
    GPT-3 helps you come up with, like, what would someone ask in this situation?
    What would the follow-up be?” This helps the writers cover as many conversation
    outcomes as possible. “Sometimes it''s been a writing partner, sometimes it’s
    been something that can fill in the gaps around what''s happening,” Saatchi says.
    “So we might think: this is what''s going to happen to the character this week.
    What''s going to happen to the character next week? And GPT-3 [is] filling in
    some of those gaps.”'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: Carey解释说，GPT-3也是人类作者的一个有用工具：“对于即兴创作的内容，我们使用GPT-3来进行测试，这样你就可以把GPT看作是人类，而你自己就是在扮演这个角色。与GPT-3来回交流有助于你想出在这种情况下会有什么样的问题？接下来会是什么？”这有助于作者们尽可能多地覆盖对话结果。“有时它是一个创作伙伴，有时它可以填补正在发生的事情周围的空白，”Saatchi说。“所以我们可能会思考：这个角色本周会发生什么？下周会发生什么？GPT-3会填补其中的一些空白。”
- en: The Fable team used GPT-3 to its fullest extent in an experiment at the 2021
    Sundance Film Festival, where Lucy collaborated live with festival participants
    to create her own short film, while Fable Studio and participants were curating
    the ideas she generated, bouncing them off participants, and feeding the audience’s
    ideas back into GPT-3.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: Fable小组在2021年圣丹斯电影节上利用GPT-3进行了一次实验，Lucy与电影节参与者现场合作创作了自己的短片，而Fable工作室和参与者们则在策划她所生成的创意，与参与者们交流，将观众的创意反馈到GPT-3中。
- en: Powering one consistent character with GPT-3 was a special challenge. GPT-3
    is very good for use cases that redirect from the character to the participant,
    like therapy sessions, as well as for characters that have “a very large base
    of knowledge about them, like a celebrity or like a character that’s archetypical
    like Jesus, Santa Claus, or Dracula. But obviously, that caps out around whatever
    information has already been written,” Saatchi explains, noting that anyone who
    interacts extensively with a GPT-3-powered character will reach GPT-3’s limits
    fairly quickly. “It’s trying to get a good answer to the story you’re proposing.
    But if you tell a fantastical story in your prompts, it will come up with fantastical
    answers as well. Right? So it’s not a truth-teller. I would say it’s a storyteller
    by its nature; it’s just trying to find patterns in language.” What many people
    don’t realize about GPT-3 is that its bottom-line task is to tell a story, not
    the “truth,” Carey says.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: “It's one thing just to generate a bunch of random scenarios using GPT-3, but
    it's a whole other thing to make sure it's in the voice of that character,” Carey
    adds. “So we have techniques that we're using to create those prompts so that
    the character is well defined for GPT3.” He admits that the team puts extra effort
    into making sure GPT-3 understands the voice of the character and remains within
    its range of possible responses. They also had to avoid allowing participants
    to influence the character, because GPT-3 can pick up on subtle signals. Carey
    explains that if Lucy interacts with an adult, “it'll just play along with the
    vibe, but [if] Lucy's an eight-year-old, it might be picking up a more of an adult
    vibe from the participant and feeding that back to them. But we actually want
    [Lucy] to be speaking in the eight-year-old child-like voice”.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: Convincing OpenAI to allow them to create virtual beings with GPT-3 took some
    care.  “We were very interested in having our characters talk to people as characters,"
    says Carey. “You can imagine that can be one of their problematic areas, right?
    [It] could definitely have a potential for being nefariously used [by] someone
    pretending to be human.” The Fable Studio and Open AI teams spent some time working
    out the differences between creating lifelike characters and impersonating humans
    before OpenAI approved Fable’s use case.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: 'OpenAI had another requirement: the Fable team at Fable Studio had to keep
    a human in the loop during any narrative experiments where a virtual being pretended
    to be "real" in front of an audience. It was challenging to make GPT-3 work with
    any experience intended for thousands of people, according to Carey. That said,
    he still thinks large language models are going to be a boon, “even if it''s for
    pre-authoring content or, in more forgiving areas, if used ‘live’ and without
    the restrictions.”'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: Carey believes GPT-3 authoring works best as a collaborative tool in the hands
    of a person who knows the art of storytelling and would like to get better results,
    rather than expecting it to do all the work.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: Carey认为，GPT-3创作最好是一个知道讲故事艺术并希望获得更好结果的人手中的协作工具，而不是期望它完成所有工作。
- en: When it comes to price, the challenge he sees for the storytelling use case
    is that with every API request to keep GPT-3 consistent with the unraveling story,
    one has to “give it all the details and generate something that adds to it. So
    just to generate a few lines, you're charged the entire set of tokens. That could
    be a challenge.”
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 说到价格问题，他看到讲故事的用例面临的挑战是，每次与 GPT-3 的 API 请求保持一致以呈现故事情节时，必须“提供所有细节并生成一些内容来补充。所以，为了生成几行内容，你将被收取整套代币。”这可能是一个挑战。
- en: How did Fable Studio tackle the question of pricing? They managed to largely
    avoid it,  thanks to mainly experimenting with pre-generation, in which “you pre-generate
    a bunch of options and then can use search to find the right option to respond
    back with,” Carey says.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: Fable工作室如何解决定价的问题？他们成功地大致避开了这一问题，主要是通过对预生成的尝试，即“你预先生成一堆选项，然后可以使用搜索找到正确的选项作为回应，”Carey解释道。
- en: 'They also found a way to lower the number of API users: rather than having
    a large audience interacting with Lucy through their AI, “we''ve kind of pivoted
    to a model where Lucy is actually having a one-to-one conversation, but in a Twitch
    stream.” The audience watches via Twitch rather than making API calls, which alleviates
    the bandwidth issue, limit the number of people Lucy is interacting with at any
    given time, and broadens the audience.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 他们还找到了降低API用户数量的方法：与其让大量观众通过他们的AI与Lucy互动，“我们有点转变为Lucy实际上正在进行一对一的对话，但是是在Twitch直播中。”观众通过Twitch观看而不是发出API调用，这缓解了带宽问题，限制了Lucy与任何特定时间和人互动的数量，并扩大了观众群体。
- en: Saatchi mentions a rumor that GPT-4 is exploring the spatial understanding of
    virtual spaces, which he sees as having more potential than language-only chatbots.
    He advises people exploring this use case to focus on creating characters in virtual
    worlds. Saatchi notes that [Replika](https://replika.ai/), a company that has
    created a virtual AI friend character, is now exploring extending into a metaverse,4
    where virtual beings will have their own apartments and can meet and interact
    with each other as well as, eventually, with human users. “The point is to make
    a character that feels alive, and GPT-3 is one of many tools. Potentially giving
    virtual beings genuine understanding of the spaces that they’re navigating could
    unlock learning for these characters.”
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: Saatchi提到了一个传言，即 GPT-4正在探索对虚拟空间的空间理解，他认为这比仅使用语言的聊天机器人有更多潜力。他建议探索这一用例的人们专注于在虚拟世界中创造角色。Saatchi指出，已经创建了虚拟AI朋友角色的公司[Replika](https://replika.ai/)现在正在探索扩展到元宇宙，其中虚拟存在将拥有自己的公寓，可以相遇和互动，最终还可以与人类用户互动。“重点是创造一个有生命感的角色，而
    GPT-3 是众多工具中的一个。为这些角色提供对于它们正在航行的空间的真正理解可能为这些角色的学习打开大门。”
- en: What lies ahead? Carey sees a place for future iterations of GPT-3 in building
    the metaverse, a parallel digital reality where humans can interact and perform
    activities as freely as in the real world. He envisions it generating ideas and
    having a human in the loop to curate them.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 未来会发生什么？Carey认为，在构建元宇宙（一个平行的数字现实，人类可以像在现实世界中一样自由互动和进行活动）中，将有未来的GPT-3版本的位置。他设想它生成想法，并将人类置于循环之中来策划这些想法。
- en: Saatchi believes that deemphasizing language as the only mode of interaction
    has the potential to create more interesting and sophisticated interactions with
    AI. “I do think that 3D spaces give us the opportunity to give AI spatial understanding,”
    he continues. The metaverse Saatchi envisions gives AI the ability to walk around
    and explore and gives humans the opportunity to become part of the loop and help
    train virtual beings. He concludes we need radical new thinking, and that the
    metaverse offers significant opportunities to put AIs in 3D spaces and “allow
    them to live simulated lives with humans helping the characters grow.”
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: Saatchi相信，将语言作为唯一交互模式的重要性降低，有潜力创造更有趣和复杂的人工智能交互。“我确实认为，3D空间使我们有机会赋予AI空间理解能力，”他继续说道。Saatchi设想的元宇宙赋予了AI四处行走和探索的能力，并赋予人类成为循环的一部分并帮助训练虚拟存在的机会。他总结说，我们需要激进的新思维，而元宇宙为将AI置于3D空间提供了重大机会，并“允许它们与人类一起过上模拟生活。”
- en: 'Data Analysis Applications of GPT-3: Viable'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-3的数据分析应用：可行
- en: The story of the startup [Viable](https://www.askviable.com/) is an example
    of how much things can change from the moment you start working on a business
    idea to actually finding a product-market fit and a customer base. Viable helps
    companies better understand their customers by using GPT-3 to summarize customer
    feedback.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: 'Viable aggregates feedback like surveys, help desk tickets, live chat logs,
    and customer reviews. It then identifies themes, emotions, and sentiments, pulls
    insights from those results,  and provides a summary in a matter of seconds. For
    example, if asked, “What’s frustrating our customers about the checkout experience?”
    Viable might respond: “Customers are frustrated with the checkout flow because
    it takes too long to load. They also want a way to edit their address in checkout
    and save multiple payment methods.”'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: Viable’s original business model involved helping early-stage startup companies
    find product-market fit using surveys and product roadmaps. Requests started coming
    in from bigger companies, asking for support in analyzing huge volumes of text,
    such as “support tickets, social media, app store reviews and survey responses”
    that changed everything, says Daniel Erickson. Erickson is the founder and CEO
    of Viable–and an early adopter of the OpenAI API.  He explains, “I spent actually
    about a month just experimenting, literally just taking our data, putting it into
    the playground, figuring out different prompts and things like that. And eventually,
    I came to the conclusion that [GPT-3] could power a very powerful question and
    answer system.”
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: Erickson and his colleagues began using the OpenAI API to interact with and
    generate insights from the large datasets they were working with. They initially
    used another NLP model, achieving mediocre results, but when they began working
    with GPT-3, the team saw “at least a 10% increase across the board. When we're
    talking about going from 80% to 90%, that’s a hell of an increase for us”.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: Building on that success, they used GPT-3 in combination with other models and
    systems to create a Q&A feature that allows users to ask a question in plain English
    and get an answer.  Viable converts the question to a complex query that can pull
    all the relevant feedback from the database. It then runs the data through another
    series of summarization and analysis models to generate a refined answer.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: In addition, Viable’s system provides customers with “a 12-paragraph summary
    every week  that outlines things like their top complaints, their top compliments,
    their top requests, and top questions." As you might expect from customer-feedback
    specialists, Viable has thumbs up and thumbs down buttons next to every answer
    the software generates. They use this feedback in retraining.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: 'Humans are part of the process, too: Viable has an annotation team whose members
    are responsible for building training datasets, both for internal models and GPT-3
    fine-tuning. They use the current iteration of that fine-tuned model to generate
    output, which humans then assess for quality. If the output doesn’t make sense
    or isn’t accurate, they rewrite it. And once they have a list of outputs they
    are satisfied with, they feed that list back into the next iteration of the training
    dataset.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 人也参与其中：Viable有一个注释团队，他们负责构建训练数据集，既用于内部模型，也用于GPT-3的微调。他们使用当前版本的经过微调的模型生成输出，然后人类评估质量。如果输出没有意义或不准确，他们会重新编写。一旦他们有了一份满意的输出列表，他们就将该列表反馀到下一个迭代的训练数据集中。
- en: 'Erickson notes that the API is a huge advantage since it leaves the hosting,
    debugging, scaling, and optimization to OpenAI: “I would much rather buy than
    build for almost anything that isn’t super core to our tech. And even if it is
    core to our tech, it still makes sense for us to do it with GPT-3.” Therefore,
    their ideal solution would be to use GPT-3 for all the elements of their process.
    But they had to optimize their usage due to cost: “We have companies that are
    giving us hundreds of thousands of data points that are anywhere from five to
    a thousand words each.” Using GPT-3 for everything could get expensive.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: Erickson指出API是一个巨大的优势，因为它将托管、调试、扩展和优化都交给了OpenAI：“对于几乎任何不是我们技术的核心的东西，我更愿意购买而不是建造。即使它是我们技术的核心，我们也有理由用GPT-3来做。”因此，他们理想的解决方案将是对他们的整个过程使用GPT-3。但由于成本问题，他们不得不优化他们的使用：“我们有一些公司向我们提供了数十万个数据点，每个数据点的字数在五到一千字之间。”把所有东西都用GPT-3可能会变得昂贵。
- en: Instead, Viable mainly uses internal models to structure data, which they developed
    on top of BERT and ALBERT and trained using GPT-3 output. These models are now
    meeting or exceeding the GPT-3’s capabilities for topic extraction, emotion and
    sentiment analysis, and many other tasks. Viable also switched to a usage-based
    pricing model built on top of OpenAI’s API pricing.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，Viable主要使用内部模型来构建数据，他们在BERT和ALBERT之上开发了这些模型，并使用GPT-3的输出进行训练。这些模型目前在主题提取、情感分析和许多其他任务方面达到或超过了GPT-3的能力。Viable还改用了基于OpenAI的API定价模型的使用量定价模型。
- en: 'Erickson maintains that GPT-3 gives Viable an edge over its competition in
    two ways: accuracy and usability.  We have touched upon the impressive 10% accuracy
    boost for Viable. But what about usability? Most of Viable’s competitors build
    tools specifically designed for professional data analysts. Viable felt that was
    too narrow an audience: “We didn''t want to build a piece of software that only
    analysts could use because we feel like that limits the value. What we want to
    do is help teams make better decisions using qualitative data.”'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: Erickson认为GPT-3在两个方面为Viable提供了优势：准确性和可用性。我们已经提及Viable实现了令人印象深刻的10%准确度提升。但可用性呢？Viable的大多数竞争对手都是专门为专业数据分析师设计的工具。Viable认为这个目标受众太狭窄：“我们不想要构建一个只有分析师可以使用的软件，因为我们觉得那样会限制价值。我们想要的是帮助团队使用定性数据做出更好的决策。”
- en: Instead, Viable’s software itself is the “analyst.” And users can iterate faster,
    thanks to a feedback loop that allows them to answer questions about their data
    in natural language and get a fast and accurate response.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，Viable的软件本身就是“分析师”。用户可以通过反馈循环更快地迭代，这使他们能够用自然语言回答关于他们数据的问题，并获得快速准确的回应。
- en: 'Erickson shared some of Viable’s next steps: they will soon introduce quantitative
    data and crunching product analytics. Ultimately, Erickson wants to give users
    the ability to perform a full customer insight analysis and ask questions such
    as  “How many customers are using feature X?” and “Of the customers who use feature
    X, how do they think it should be improved?”'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: Erickson分享了Viable的下一步计划：他们将很快引入定量数据和处理产品分析。最终，Erickson希望给用户能力进行全面的客户洞察分析，并提出问题，比如“有多少客户在使用功能X？”和“使用功能X的客户中，他们认为应该如何改进？”
- en: Ultimately, Erickson concludes, “What we sell is generated insights. And so
    the more in-depth and the more powerful that we make those insights, and the more
    quickly we deliver those insights, the more value we create.”
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，Erickson得出结论：“我们销售的是生成的洞察力。因此，我们使这些洞察力更加深入和强大，以及更快地交付这些洞察力，我们就创造了更多的价值。”
- en: 'Chatbot Applications of GPT-3: Quickchat'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 聊天机器人GPT-3的应用：Quickchat
- en: 'GPT-3, being very proficient at language interactions, is an obvious choice
    to enhance the existing chatbot experience. While many apps entertain users with 
    AI chatbot personas, such as [PhilosopherAI](https://philosopherai.com/) and [TalkToKanye](https://talktokanye.com/), 
    two companies specifically leverage this capability in their business applications:
    Quickchat and Replika. Quickchat is well-known for its AI chatbot persona: Emerson
    AI, accessible via Telegram and the Quickchat mobile application. Emerson AI has
    broad general world knowledge, including access to more recent information, even
    after GPT-3’s training time; supports multiple languages; can handle a coherent
    conversation, and is fun to talk to.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: 'Piotr Grudzień and Dominik Posmyk, co-founders of Quickchat, were excited about
    GPT-3 from the start and full of ideas for leveraging it in a new product. During
    their early experiments with the OpenAI API, they kept coming back to the notion
    of “evolving interfaces between machines and people.”  Grudzień explains that
    since the interactions between humans and computers are constantly evolving, natural
    language would be the logical next step: after all, humans prefer to communicate
    via conversation. GPT-3, they concluded, seemed to have the potential to enable
    human-like chat experiences with computers.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: 'Grudzień says neither of the founders had built any conventional chatbot application
    before. Approaching the task with a “beginner’s mind”  helped them stay fresh
    and open about solving the problem. Unlike other chatbot companies, they didn’t
    start with the ambition of becoming the best customer support or marketing tool.
    What they started with was: “How do I get a human being to talk to a machine in
    such a way that is awe-inspiring and the best thing that they''ve ever tried?”
    They wanted to make a chatbot that doesn’t just complete simple functions such
    as collecting customer data and providing answers but is also ready to answer
    unscripted customer questions or make pleasant small talk. “Instead of saying:
    ‘I don''t know,’” Grudzień adds, it can “fall back on the conversational API and
    keep the conversation going.”'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: Posmyk adds, “Our mission is to empower people with Artificial Intelligence,
    not replace them. We believe that over the next decade, AI will accelerate the
    digitization of crucial industries such as education, legal, and healthcare and
    increase our productivity at work and in everyday life.” To provide a glimpse
    of this far-fetched mission, they created Emerson AI, an intelligent general-purpose
    chatbot application powered by GPT-3.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: Although Emerson AI has a growing community of users, its true purpose is to
    showcase the capabilities of GPT-3 powered chatbots and encourage users to work
    with Quickchat on implementing such a persona for their companies. Quickchat’s
    product offering is a general-purpose conversational AI that can talk about any
    subject. Customers, mostly established companies, can customize the chatbot by
    adding extra information specific to their product (or any topic they want). Quickchat
    has seen diverse applications, such as automating typical FAQ customer-support
    problem-solving and implementing an AI persona to help users search an internal
    company knowledge base.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: 'Unlike typical chatbot service providers, Quickchat does not build any conversation
    trees or rigid scenarios, nor does it need to teach the chatbot to answer questions
    in a given way. Instead, Grudzień explains, customers follow a simple process:
    “You copy-paste text that contains all the information that you want your AI to
    be using [and] click on the retrain button, which takes a few seconds to absorb
    the knowledge, and that''s it.”  Now trained on your data, the chatbot is ready
    to have a test conversation.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: Asked about the tradeoffs between open-source models and OpenAI API, Grudzień
    shares that “OpenAI API is nice and easy to use because you don't need to worry
    about infrastructure, about latency or model training. It's just calling an API
    and getting an answer. It's super reliable.” However, he believes you pay quite
    a high price for the quality. In comparison, open-source models seem to be a great
    free alternative. In practice, “you do need to pay the cost of cloud computing.
    It requires GPUs and setting up GPUs to work with these models to be fast, then
    to do fine-tuning of your own,” which Grudzień admits, is not a trivial process.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: Like Viable’s Ericksen, Grudzień and Posmyk strive to deliver value with every
    API call. But they also hope that as more and more competitive models get released,
    OpenAI’s API pricing will “go down or will plateau to some level, just because
    of the pressure of competition.”
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: So what has Quickchat learned? First, it takes more than hype to build a profitable
    business. A big media sensation, like the one that launched GPT-3, can provide
    an initial influx of excited enthusiasts, “but then people get bored and wait
    for the next big thing. The only products that survive are ones that actually
    solve some problems that people care about,” Grudzień says. “No one's going to
    use your product just because it's GPT-3\. It needs to deliver some value, either
    useful or fun, or solve some problem. GPT-3 is not going to do that for you. So
    you need to just treat it as yet another tool.”
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: Another key lesson was to develop solid performance metrics. “Whenever you're
    building a machine learning product, it's always tricky to evaluate,” says Grudzień.
    In his view, because GPT-3 is robust and operates in the difficult-to-quantify
    domain of natural language, evaluating the quality of its output is complex and
    cumbersome. As exciting as a breakthrough can be, he says, “users are going to
    probably judge you on your worst-case performance, at best on your average performance.”
    Quickchat, therefore, optimizes user satisfaction. It was crucial for them to
    design a metric to capture variables correlated with happy users and high retention,
    both of which directly translate to higher revenue.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: Another challenge, perhaps surprisingly, is GPT’s knack for creativity. “Even
    if you set a temperature very low, whatever prompt you give it, it's still going
    to use that prompt that is tiny and then generates something based on this vast
    knowledge that it has,” Grudzień explains. This makes it easy to generate creative
    text such as poetry, marketing copy, or fantasy stories. But most chatbots are
    for solving customer problems. “It needs to have predictable, repetitive performance,
    while still being conversational and to some extent creative, but not pushing
    it too far.”
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: Large language models sometimes output text that’s  “weird,” “empty,” or just
    “not that great,” so humans do need to intervene. “If you start measuring whether
    it managed to satisfy some condition or fulfill the task, then it's going to turn
    out that it's really creative, but out of 10 tries, it only succeeded six times—which
    is as good as zero when it comes to real business with paying customers.” Therefore,
    for a successful business application, you need a lot of internal systems and
    models that restrain that creativity and bolster reliability. “To create this
    tool for our customers that works 99% of the time, we developed a number of defense
    mechanisms,” Grudzień says.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: 'These days, Quickchat is focused on working deeply with customers to make sure
    their API performance lets them succeed in their use case. What excites Grudzień
    the most is seeing what customers build: “We really, really want to see our chat
    engine being used in thousands of different ways in different products.”'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: 'Marketing Applications of GPT-3: Copysmith'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: 'Can GPT-3 eliminate writer’s block? Kilcher thinks so:  “If you have writer''s
    block, you just ask a model and it gives you a thousand ideas out of a model like
    this, simply as a creative assistance tool.” Let’s look at one such tool: Copysmith.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: One of the most popular applications of GPT-3 is to generate creative content
    on the fly. Copysmith is one of the leading content-creation tools on the market.
    “Copysmith is something that enables users to create and deploy content anywhere
    on the web a hundred times faster through powerful AI,” says co-founder and CTO
    Anna Wang. It uses GPT-3 for copywriting in e-commerce and marketing to generate,
    collaborate and launch quality content at lightning speed. Wang and CEO Shegun
    Otulana shared how two sisters transitioned their small, struggling e-commerce
    store into a successful technology company–and GPT-3’s pivotal role in making
    it possible.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: In June 2019, Anna Wang and her sister Jasmine Wang co-founded a Shopify-based
    boutique. But they lacked marketing experience, and “the business utterly collapsed,”
    Anna Wang says.  When the sisters learned about the OpenAI API in 2020, Wang says,
    “we started exploring it for creative pursuits like writing poetry, trying to
    emulate characters from books and movies. One day we realized that if we had this
    tool while we were trying to build the e-commerce store, we would have been able
    to write better calls-to-action, and product descriptions and leveled up our marketing
    game to get it off the ground.”
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: Inspired, they launched Copysmith in October 2020 to a warm reception. In Anna
    Wang’s words, “That's where everything began. We started talking to users and
    iterating the product based on the feedback.”  GPT-3, she notes, allows you to
    iterate very fast without any prior knowledge, whereas other open source models,
    like BERT and RoBERTa, require a significant level of fine-tuning for every downstream
    task. “It is extremely flexible in terms of the tasks it can perform,” she adds,
    and “it is the most powerful model out there.” What’s more, GPT-3 is “super-friendly
    for developers and users, with its simple text-in text-out interface that allows
    you to perform all kinds of tasks using a simple API.” Its other advantage is
    the simplicity of the API call, compared to the efforts that go into hosting a
    proprietary model.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: As for the challenges of building a product based on GPT-3, Otulana says, “You
    are generally bound by the limitations of OpenAI. So, to overcome that, you have
    to give your own entrepreneurial touch to the API for creating something that
    stands out. Another limitation is a slight loss of control, where your progress
    is in essence limited by OpenAI’s progress.”
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: Anna Wang has two pieces of advice for would-be product designers who want to
    use GPT-3\. First, she says,  “Make sure you are solving a real problem. . .think
    about your user, because one of the easy things with GPT-3 is to fall into the
    mindset of building things within the limit of safety guidelines without allowing
    yourself to be creative.”
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: Second, Wang advises, “Keep a very close eye on what you are feeding to the
    model. Be careful with the punctuation, grammar, and wording of the prompt. I
    guarantee you'll have a much better experience with the model output.”
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: 'Coding Applications of GPT-3: Stenography'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: As GPT-3 and its descendant model Codex continue to show more ability to interact
    with programming and natural languages, new potential use cases are piling up.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: 'Bram Adams, an OpenAI Community Ambassador known for his creative experiments
    with GPT-3 and Codex algorithms, launched one in late 2021: Stenography, which
    leverages both GPT-3 and Codex to automate the annoying task of writing code documentation.
    Stenography found instant success, launching as the number one product of the
    day on the popular product launch portal Product Hunt.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: 'Adams tried several potential use cases with the API before, narrowing his
    ideas down to the one that has become his new business. “I think a lot of those
    experiments were about me unconsciously edge-testing what a language model like
    GPT-3 can handle.” Adams’s search began with the idea: ‘What would I do if I could
    ask a computer to do anything?’” He began exploring, “poking at the corners of
    the OpenAI API and seeing how far it could go.” He came up with a bot that generates
    Instagram poetry; tried a self-podcasting journaling project in which users would
    speak to digital versions of themselves; worked on a music playlist-building project
    on Spotify based on users’ preferences; and created many more projects in service
    of his curiosity. Thanks to that curiosity, “I got really good early on at understanding
    the different engines of GPT-3.”'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: 'So why Stenography? “I got a pretty good signal from the external world that
    this could be very helpful to a lot of people.” While Adams enjoys the elegance
    of well-written code, most GitHub users just download published code and use it:
    “No one''s really gonna admire the beauty that you put into your codebase.” He
    also noticed that great programs on GitHub that aren’t well documented often don’t
    get the visibility they deserve: “The readme [file] is the first thing that everybody
    sees. They immediately scroll down to it.” Stenography was an attempt to think
    about how documentation could evolve to become less annoying for developers: “It''s
    hard because, with documentation in particular, you have to justify what you did.
    So you say, ‘I used this library to do this thing. And then I decided to use this
    thing, and then I added this function to do this thing.’”'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: Adams sees documentation as a way for people to reach out to other people on
    their teams, their future selves, or just interested people who stumble across
    the project. Its goal is to make a project understandable to others.” I was interested
    in the idea if GPT-3 could create understandable comments.”  He tried both GPT-3
    and Codex and was impressed with the level of explanation from both models. The
    next question he asked was, “How do I make this really easy and enjoyable for
    developers?”
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: So how does Stenography work, and how do its components leverage the OpenAI
    API? At a high level, Adams says, there are two main processes, parsing, and explanation,
    and each requires a different strategy. “For the parsing process, I spent a lot
    of time understanding the complexity of code because not all lines in your code
    are even worth documenting.” Some code might have an obvious purpose, have no
    operational value, or no longer be useful.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, “big” code blocks, reaching over 800 lines, are too tricky for
    the model to understand in one go. “You'd have to break down that logic to many
    different kinds of steps to be able to say accurately that this is what this thing
    does. Once I understood that I started thinking, ‘How can I leverage parsing to
    find blocks that are sufficiently complex, but not too complex?’”  Since everyone
    writes code differently, it's a matter of trying to attach to the abstract syntax
    tree and work with the best of what you have. That became the main architectural
    challenge of the parsing layer.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: 'As for the explanation layer, “that''s more of a feature of getting GPT-3 and
    Codex to say what you want them to say,” Adams explains. The way to go about it
    is to find creative ways to understand your code’s audience and get GPT-3 to speak
    to it. This layer “can attempt to solve any question, but it might not solve it
    at a hundred percent accuracy like you would get with something like a calculator.
    If you type two plus two equals four, occasionally you get five, but you don''t
    need to write all the functions for multiplication, division, and subtraction.
    Those come for free.” That’s the trade-off with probabilistic systems: sometimes
    they work and sometimes they don''t, but they always return an answer. Adams advises
    remaining fluid enough to be able to pivot your strategy if necessary.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: 'Adams stresses the importance of really understanding the problem before you
    start using the OpenAI API. “During my office hours, people will come, and they''ll
    have these huge problems. They''ll be like, ‘How do I build a rocket ship from
    scratch using a prompt?’ And I''m like, ‘Well, there''s a lot of components of
    a rocket ship. GPT-3 isn''t a panacea. It''s a very powerful machine, but only
    if you know what you''re using it for.’” He compares GPT-3 to programming languages
    like JavaScript, Python, and C: “They''re compelling, but only if you understand
    recursion and for loops and while loops, and what tools will help you solve your
    particular problem” For Adams, that has meant asking lots of “technical meta-questions,”
    such as “What is the thing that is being helped by having AI documentation?” and
    “What even is documentation in the first place?” Dealing with these questions
    was the biggest challenge for him.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: “I think a lot of people just immediately rushed to Davinci to solve their problems.
    But if you can solve something on a smaller engine, like an Ada, Babbage, or Curie,
    you actually get to know the problem a lot more deeply than you would if you were
    just trying to throw the whole AI at it with Davinci,” he claims.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: When it comes to building and scaling a product with the OpenAI API, he advises
    using “small engines or low temperatures, because you can't predict what your
    final prompt will be like (or if it will continue to evolve over time), what you're
    trying to do, and who your end-user is, but using smaller engines and lower temperatures,
    you’ll find answers to the really hard questions faster.” he tells us.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: Another challenge has been moving from his own standalone experiments to account
    for all the different conditions and ways of working that users might face. Now
    he is working on “finding all the different edge cases” to better understand how
    fast the design layer of the API has to be, how frequently it has to respond with
    a particular request, and how it interacts with different languages.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: What’s next for Stenography? Now that Adams has built a product that he’s very
    happy with, in 2022 he plans to focus on sales and talking to the user base. “Stenography
    isn't going to be as much about building as really perfecting the product and
    getting it in front of people.”
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: An Investor’s Outlook on the GPT-3 Startup Ecosystem
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: To understand the perspective of investors backing GPT-3-based companies, we
    spoke with Jake Flomenberg of Wing VC, a renowned global venture-capital firm
    and lead investor in several GPT-3-powered startups, including Copy.AI and Simplified.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: 'As any market watcher might imagine, venture capitalists are watching nascent
    AI technologies like GPT-3\. Flomenberg summarizes the appeal: GPT-3  is “unlike
    any other NLP model that we have ever seen before. It is a substantial step in
    the direction of building more generalized AI.” The untapped potential is enormous,
    he argues, and the business world still “underestimates and therefore underutilizes
    the capabilities of LLMs.”'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: But how should potential investors evaluate something so new and different?
    “We value startups with a deep understanding of the problem, the domain, and the
    technology” as well as a good fit between product and market, Flomenberg says.
    “The nuance in assessing something built on GPT-3 is asking, what’s the secret
    sauce? What is it that the company has built a technologically deep knowledge
    on? Is the company solving a real problem using GPT-3, or just leveraging the
    hype to get their product out in the market? Why now? Why is this team the best
    fit to execute this idea? Is this idea defensible in the real world?” If a startup
    can’t defend its existence, that’s a huge red flag for investors.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: 'Investors also keep a close eye on OpenAI and its API, since GPT-3-based businesses
    rely completely on its capabilities. Flomenberg cites OpenAI’s due-diligence review
    process as a major factor in this trust-based relationship: “The startups that
    pass the production review and are a subject of interest by OpenAI automatically
    become hot for investment.”'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: 'Investors usually dig into the background and expertise of founders while making
    investment decisions. GPT-3 is unusual, though, in that it allows people from
    any background, not just programmers, to build cutting-edge NLP products. Flomenberg
    stresses the importance of the market here: “Generally with a deep tech startup,
    we look for founders with a great understanding of technical and AI domain. But
    with GPT-3-based startups, we are more focused on whether the market resonates
    with the founders’ vision and whether they’re able to identify and address the
    needs of the end-users”. He cites Copy.AI as  “a classic example of a product-led-growth
    model built on top of GPT-3\. They found an extraordinary resonance with their
    users and developed a deep understanding of the technology, bringing depth and
    value to the table.” Successful startups, he says, “keep the AI inside,” focusing
    more on solving users’ problems and meeting their needs by using the right tool
    for the job.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: It’s mind-blowing to see these use cases, and many more, built on top of GPT-3
    so quickly and with such success. By late 2021, when this chapter was written,
    several startups in the OpenAI community had already raised hefty rounds of funding
    and were looking at rapid expansion plans. This market tide seems to have awakened
    the appetites of bigger businesses as well. More and more enterprises are starting
    to consider implementing experimental GPT-3 projects within their organizations.
    In Chapter 5, we will look at this market segment consisting of large-scale products
    like GitHub Copilot and particularly the new Microsoft Azure OpenAI Service, which
    is designed to meet the needs of large-scale organizations.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
