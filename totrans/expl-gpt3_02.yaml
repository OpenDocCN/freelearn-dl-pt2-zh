- en: '*Chapter 1*: Introducing GPT-3 and the OpenAI API'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第1章*：介绍GPT-3和OpenAI API'
- en: 'The buzz about **Generative Pre-trained Transformer Version 3** (**GPT-3**)
    started with a blog post from a leading **Artificial Intelligence** (**AI**) research
    lab, OpenAI, on June 11, 2020\. The post began as follows:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 关于**生成式预训练变换器第3版**（**GPT-3**）的讨论始于2020年6月11日，由领先的**人工智能**（**AI**）研究实验室OpenAI发布的一篇博客文章。该帖子以以下方式开始：
- en: We're releasing an API for accessing new AI models developed by OpenAI. Unlike
    most AI systems which are designed for one use-case, the API today provides a
    general-purpose "text in, text out" interface, allowing users to try it on virtually
    any English language task.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在发布一个用于访问OpenAI开发的新AI模型的API。与大多数专为一个用例设计的AI系统不同，该API今天提供了一个通用的“文本输入，文本输出”接口，允许用户在几乎任何英语语言任务上尝试它。
- en: Online demos from early beta testers soon followed—some seemed too good to be
    true. GPT-3 was writing articles, penning poetry, answering questions, chatting
    with lifelike responses, translating text from one language to another, summarizing
    complex documents, and even writing code. The demos were incredibly impressive—things
    we hadn't seen a general-purpose AI system do before—but equally impressive was
    that many of the demos were created by people with a limited or no formal background
    in AI and **Machine Learning** (**ML**). GPT-3 had raised the bar, not just in
    terms of the technology, but also in terms of AI accessibility.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 早期测试人员的在线演示很快就出现了——有些看起来太好以至于难以置信。GPT-3正在撰写文章，写诗，回答问题，以栩栩如生的方式进行聊天，将文本从一种语言翻译为另一种语言，总结复杂的文件，甚至编写代码。这些演示令人印象深刻——这是我们以前从未见过的一般用途人工智能系统所做的事情——但同样令人印象深刻的是，许多演示是由在人工智能和**机器学习**（**ML**）方面具有有限或没有正式背景的人创造的。GPT-3提高了标准，不仅在技术方面，还在人工智能可访问性方面。
- en: 'GPT-3 is a general-purpose language processing AI model that practically anybody
    can understand and start using in a matter of minutes. You don''t need a **Doctor
    of Philosophy** (**PhD**) in computer science—you don''t even need to know how
    to write code. In fact, everything you''ll need to get started is right here in
    this book. We''ll begin in this chapter with the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-3是一个通用的语言处理AI模型，几乎任何人都可以在几分钟内理解并开始使用。您不需要计算机科学的**哲学博士**（**PhD**）——甚至不需要知道如何编写代码。实际上，您开始所需的一切都在这本书中。在本章中，我们将从以下主题开始：
- en: Introduction to GPT-3
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPT-3简介
- en: Democratizing NLP
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使NLP大众化
- en: Understanding prompts, completions, and tokens
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解提示、完成和标记
- en: Introducing Davinci, Babbage, Curie, and Ada
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍达芬奇、巴贝奇、居里和艾达
- en: Understanding GPT-3 risks
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解GPT-3的风险
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: This chapter requires you to have access to the **OpenAI** **Application Programming
    Interface** (**API**). You can register for API access by visiting [https://openapi.com](https://openapi.com).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本章需要您访问**OpenAI** **应用程序编程接口**（**API**）。您可以通过访问[https://openapi.com](https://openapi.com)注册API访问权限。
- en: Introduction to GPT-3
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GPT-3简介
- en: 'In short, GPT-3 is a language model: a statistical model that calculates the
    probability distribution over a sequence of words. In other words, GPT-3 is a
    system for guessing which text comes next when text is given as an input.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 简言之，GPT-3是一个语言模型：一个计算一系列单词的概率分布的统计模型。换句话说，GPT-3是一个系统，当输入文本时，猜测接下来的文本是什么。
- en: Now, before we delve further into what GPT-3 is, let's cover a brief introduction
    (or refresher) on **Natural Language Processing** (**NLP**).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在我们更深入地了解GPT-3是什么之前，让我们对**自然语言处理**（**NLP**）进行简要介绍（或复习）。
- en: Simplifying NLP
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 简化自然语言处理（NLP）
- en: NLP is a branch of AI that focuses on the use of natural human language for
    various computing applications. NLP is a broad category that encompasses many
    different types of language processing tasks, including sentiment analysis, speech
    recognition, machine translation, text generation, and text summarization, to
    name but a few.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: NLP是人工智能的一个分支，它专注于利用自然人类语言进行各种计算应用。NLP是一个广泛的类别，涵盖了许多不同类型的语言处理任务，包括情感分析、语音识别、机器翻译、文本生成和文本摘要等。
- en: In NLP, language models are used to calculate the probability distribution over
    a sequence of words. Language models are essential because of the extremely complex
    and nuanced nature of human languages. For example, *pay in full* and *painful*
    or *tee time* and *teatime* sound alike but have very different meanings. A phrase
    such as *she's on fire* could be literal or figurative, and words such as *big*
    and *large* can be used interchangeably in some cases but not in others—for example,
    using the word *big* to refer to an older sibling wouldn't have the same meaning
    as using the word *large*. Thus, language models are used to deal with this complexity,
    but that's easier said than done.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在自然语言处理中，语言模型用于计算一系列单词的概率分布。语言模型的重要性在于人类语言的复杂和微妙的特性。例如，*pay in full* 和 *painful*
    或 *tee time* 和 *teatime* 听起来相似，但意思完全不同。*she's on fire* 这样的表达可能是字面的，也可能是比喻的；而 *big*
    和 *large* 这样的词在某些情况下可以互换使用，但在其他情况下不能——例如，用 *big* 来指代一个年长的兄弟就不会有使用 *large* 的含义。因此，语言模型用于处理这种复杂性，但这说起来容易做起来难。
- en: While understanding things such as word meanings and their appropriate usage
    seems trivial to humans, NLP tasks can be challenging for machines. This is especially
    true for more complex language processing tasks such as recognizing irony or sarcasm—tasks
    that even challenge humans at times.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管人们对词义和适当的使用似乎很容易理解，但自然语言处理任务对机器来说可能是具有挑战性的。这对于更复杂的语言处理任务尤为真实，例如识别讽刺或挖苦——甚至有时连人类本身都会感到困难。
- en: 'Today, the best technical approach to a given NLP task depends on the task.
    So, most of the best-performing, **state-of-the-art** (**SOTA**) NLP systems are
    specialized systems that have been fine-tuned for a single purpose or a narrow
    range of tasks. Ideally, however, a single system could successfully handle any
    NLP task. That''s the goal of GPT-3: to provide a general-purpose AI system for
    NLP. So, even though the best-performing NLP systems today tend to be specialized,
    purpose-built systems, *GPT-3 achieves SOTA performance on a number of common
    NLP tasks*, showing the potential for a future general-purpose NLP system that
    could provide SOTA performance for any NLP task.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 如今，对于特定的自然语言处理任务来说，最好的技术方法取决于任务本身。因此，大多数表现最佳的 **最先进** （**SOTA**）自然语言处理系统都是针对单一目的或狭窄范围任务进行了细化调整的专门系统。然而，理想情况下，一个单一系统应该能够成功地处理任何自然语言处理任务。这就是
    GPT-3 的目标：提供一个通用的自然语言处理系统。因此，尽管今天表现最佳的自然语言处理系统往往是专门的、针对特定任务定制的系统，*GPT-3 在多个常见自然语言处理任务中达到了
    SOTA 表现*，展现了未来通用自然语言处理系统能够为任何自然语言处理任务提供 SOTA 表现的潜力。
- en: What exactly is GPT-3?
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GPT-3 到底是什么？
- en: 'Although GPT-3 is a general-purpose NLP system, it really just does one thing:
    it predicts what comes next based on the text that is provided as input. But it
    turns out that, with the right architecture and enough data, this *one thing*
    can handle a stunning array of language processing tasks.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 GPT-3 是一种通用的自然语言处理系统，但它实际上只做了一件事：基于提供的文本预测接下来会出现什么。但事实证明，通过合适的架构和足够的数据，这“一件事”能够处理惊人的一系列语言处理任务。
- en: GPT-3 is the third version of the GPT language model from OpenAI. So, although
    it started to become popular in the summer of 2020, the first version of GPT was
    announced 2 years earlier, and the following version, GPT-2, was announced in
    February 2019\. But even though GPT-3 is the third version, the general system
    design and architecture hasn't changed much from GPT-2\. There is one big difference,
    however, and that's the size of the dataset that was used for training.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-3 是来自 OpenAI 的 GPT 语言模型的第三个版本。因此，尽管它在 2020 年夏天开始变得流行，但 GPT 的第一个版本是在 2 年前宣布的，接下来的版本
    GPT-2 是在 2019 年 2 月宣布的。但即使 GPT-3 是第三个版本，系统的设计和架构与 GPT-2 没有太大的变化。然而，有一个很大的区别，那就是用于训练的数据集的大小。
- en: GPT-3 was trained with a massive dataset comprised of text from the internet,
    books, and other sources, containing roughly 57 billion words and 175 billion
    parameters. That's 10 times larger than GPT-2 and the next-largest language model.
    To put the model size into perspective, the average human might read, write, speak,
    and hear upward of a billion words in an entire lifetime. So, GPT-3 has been trained
    on an estimated 57 times the number of words most humans will ever process.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-3 是使用从互联网、书籍和其他来源获取的文本组成的海量数据集进行训练的，包含大约 570 亿个单词和 1750 亿个参数。这比 GPT-2 和其他最大规模的语言模型大
    10 倍。为了让模型的大小有所了解，一个普通人一生中可能会读、写、说和听到超过 10 亿个单词。因此，GPT-3 在估计处理的单词数量上约是大多数人的 57
    倍。
- en: The GPT-3 language model is massive, so it isn't something you'll be downloading
    and dabbling with on your laptop. But even if you could (which you can't because
    it's not available to download), it would cost millions of dollars in computing
    resources each time you wanted to build the model. This would put GPT-3 out of
    reach for most small companies and virtually all individuals if you had to rely
    on your own computer resource to use it. Thankfully, you don't. OpenAI makes GPT-3
    available through an API that is both affordable and easy to use. So, anyone can
    use some of the most advanced AI ever created!
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-3 语言模型庞大而庞大，因此它不是你可以在笔记本电脑上下载和摸索的东西。但即使你可以（事实上你不可以因为它无法下载），每次构建模型都需要数百万美元的计算资源。如果你必须依靠自己的计算资源来使用它，这将使
    GPT-3 对大多数小公司和几乎所有个人都不可及。幸运的是，你不必这样做。OpenAI 通过一个既经济又易于使用的 API 提供 GPT-3，所以，任何人都可以使用一些有史以来最先进的人工智能！
- en: Democratizing NLP
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使自然语言处理民主化
- en: Anyone can use GPT-3 with access to the OpenAI API. The API is a general-purpose
    *text in, text out* interface that could be used for virtually any language task.
    To use the API, you simply pass in text and get a text response back. The task
    might be to do sentiment analysis, write an article, answer a question, or summarize
    a document. It doesn't matter, as far as the API is concerned—it's all done the
    same way, which makes using the API easy enough for just about anyone to use,
    even non-programmers.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 任何人都可以通过访问 OpenAI API 使用 GPT-3。API 是一个通用的*文本输入，文本输出*接口，几乎可以用于任何语言任务。要使用 API，你只需输入文本，然后得到一个文本回复。任务可能是情感分析、写一篇文章、回答一个问题或总结一篇文档。对于
    API 来说，这并不重要 —— 它都是以相同的方式完成的，这使得即使对非程序员来说，使用 API 也变得非常容易。
- en: The text you pass in is referred to as a **prompt**, and the returned text is
    called a **completion**. A prompt is used by GPT-3 to determine how best to complete
    the task. In the simplest case, a prompt can provide a few words to get started
    with. For example, if the prompt was *If today is Monday, tomorrow is*, GPT-3
    would likely respond with *Tuesday*, along with some additional text such as *If
    today is Tuesday, tomorrow is Wednesday*, and so on. This means that what you
    get out of GPT-3 depends on what you send to it.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 你传入的文本被称为**提示**，返回的文本称为**完成**。提示被 GPT-3 用于确定如何最好地完成任务。在最简单的情况下，提示可以提供一些词语作为开始。例如，如果提示是
    *如果今天是星期一，明天是*，GPT-3 可能会回复 *星期二*，以及一些额外的文本，例如 *如果今天是星期二，明天是星期三*，依此类推。这意味着你从 GPT-3
    中得到的取决于你发送给它的内容。
- en: As you might guess, the quality of a completion depends heavily on the prompt.
    GPT-3 uses all of the text in a prompt to help generate the most relevant completion.
    Each and every word, along with how the prompt is structured, helps improve the
    language model prediction results. So, *understanding how to write and test prompts
    is the key to unlocking GPT-3's true potential*.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会猜到，完成的质量在很大程度上取决于提示。GPT-3 使用提示中的所有文本来帮助生成最相关的完成。每个词语以及提示的结构方式都有助于改善语言模型的预测结果。因此，*理解如何编写和测试提示是解锁
    GPT-3 真正潜力的关键*。
- en: Understanding prompts, completions, and tokens
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解提示、完成和标记
- en: Literally any text can be used as a prompt—send some text in and get some text
    back. However, as entertaining as it can be to see what GPT-3 does with random
    strings, the real power comes from understanding how to write effective prompts.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，任何文本都可以用作提示 —— 输入一些文本，得到一些文本返回。然而，尽管看到 GPT-3 如何处理随机字符串可能很有趣，但真正的力量来自于理解如何编写有效的提示。
- en: Prompts
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 提示
- en: Prompts are how you get GPT-3 to do what you want. It's like programming, but
    with plain English. So, you have to know what you're trying to accomplish, but
    rather than writing code, you use words and plain text.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 提示是让 GPT-3 做你想要的事情的方式。这就像编程，但用的是简单的英语。所以，你必须知道自己想要实现什么，但不是编写代码，而是使用单词和纯文本。
- en: When you're writing prompts, the main thing to keep in mind is that GPT-3 is
    trying to figure out which text should come next, so including things such as
    instructions and examples provides context that helps the model figure out the
    best possible completion. Also, quality matters— for example, spelling, unclear
    text, and the number of examples provided will have an effect on the quality of
    the completion.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 当你编写提示时，要记住的主要事情是，GPT-3 正试图弄清楚接下来应该出现的文本，因此包括诸如说明和示例等内容提供了上下文，帮助模型找出最佳完成的方式。此外，质量很重要
    —— 例如，拼写、不清晰的文本以及提供的示例数量都会影响完成的质量。
- en: Another key consideration is the prompt size. While a prompt can be any text,
    the prompt and the resulting completion must add up to fewer than 2,048 tokens.
    We'll discuss tokens a bit later in this chapter, but that's roughly 1,500 words.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个关键考虑因素是提示大小。虽然提示可以是任何文本，但提示和生成的完成必须少于2048个令牌。我们将稍后在本章中讨论令牌，但大致相当于1500个单词。
- en: So, a prompt can be any text, and there aren't hard and fast rules that must
    be followed like there are when you're writing code. However, there are some guidelines
    for structuring your prompt text that can be helpful in getting the best results.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，提示文本可以是任何文本，没有像编写代码时必须遵循的硬性规则。但是，有一些指导原则可以帮助您在获得最佳结果方面构建提示文本的结构。
- en: Different kinds of prompts
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 不同类型的提示
- en: 'We''ll dive deep into prompt writing throughout this book, but let''s start
    with the different prompt types. These are outlined as follows:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本书中深入探讨提示写作，但让我们从不同的提示类型开始。以下是概述：
- en: Zero-shot prompts
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 零次提示
- en: One-shot prompts
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 单次提示
- en: Few-shot prompts
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 少数提示
- en: Zero-shot prompts
  id: totrans-41
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 零次提示
- en: 'A `Subject:`:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '一个`Subject:`:'
- en: '[PRE0]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The following screenshot is taken from a web-based testing tool called the
    **Playground**. We''ll discuss the Playground more in [*Chapter 2*](B16854_02_ePub_AM.xhtml#_idTextAnchor038),
    *GPT-3 Applications and Use Cases,* and [*Chapter 3*](B16854_03_ePub_AM.xhtml#_idTextAnchor050),
    *Working with the OpenAI Playground*, but for now we''ll just use it to show the
    completion generated by GPT-3 as a result of the preceding prompt. Note that the
    original prompt text is bold, and the completion shows as regular text:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 以下屏幕截图来自一个名为**Playground**的基于Web的测试工具。我们将在 [*Chapter 2*](B16854_02_ePub_AM.xhtml#_idTextAnchor038),
    *GPT-3 Applications and Use Cases,* 和 [*Chapter 3*](B16854_03_ePub_AM.xhtml#_idTextAnchor050),
    *Working with the OpenAI Playground* 中更多地讨论Playground，但现在我们将其用作显示由于前面的提示而生成的完成的演示。请注意，原始提示文本为粗体，完成显示为普通文本：
- en: '![Figure 1.1 – Zero-shot prompt example'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 1.1 – Zero-shot prompt example'
- en: '](img/B16854_01_001.jpg)'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: ']（img / B16854_01_001.jpg）'
- en: Figure 1.1 – Zero-shot prompt example
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.1-零次提示示例
- en: So, a zero-shot prompt is just a few words or a short description of a task
    without any examples. Sometimes this is all GPT-3 needs to complete the task.
    Other times, you may need to include one or more examples. A prompt that provides
    a single example is referred to as a one-shot prompt.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，零次提示只是一些词或短描述，没有任何示例的任务。有时候，这就是GPT-3完成任务所需要的全部。其他时候，您可能需要包括一个或多个示例。提供单个示例的提示称为单次提示。
- en: One-shot prompts
  id: totrans-49
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 单次提示
- en: 'A **one-shot prompt** provides one example that GPT-3 can use to learn how
    to best complete a task. Here is an example of a one-shot prompt that provides
    a task description (the first line) and a single example (the second line):'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '**单次提示**提供一个示例，GPT-3可以利用它来学习如何最好地完成任务。以下是一个提供任务描述（第一行）和单个示例（第二行）的单次提示的示例：'
- en: '[PRE1]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'From just the description and the one example, GPT-3 learns what the task is
    and that it should be completed. In this example, the task is to create a list
    of actors from the movie *Star Wars*. The following screenshot shows the completion
    generated from this prompt:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 仅凭描述和一个示例，GPT-3就会了解任务是什么以及应该完成任务。在此示例中，任务是创建《星球大战》电影演员的列表。以下屏幕截图显示了此提示生成的完成：
- en: '![Figure 1.2 – One-shot prompt example'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 1.2 – One-shot prompt example'
- en: '](img/B16854_01_002.jpg)'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: ']（img / B16854_01_002.jpg）'
- en: Figure 1.2 – One-shot prompt example
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.2-单次提示示例
- en: The one-shot prompt works great for lists and commonly understood patterns.
    But sometimes you'll need more than one example. When that's the case you'll use
    a few-shot prompt.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 单次提示适用于列表和通常理解的模式。但有时您需要多个例子。在这种情况下，您将使用几次提示。
- en: Few-shot prompts
  id: totrans-57
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 少数提示
- en: A **few-shot prompt** provides multiple examples—typically, 10 to 100\. Multiple
    examples can be useful for showing a pattern that GPT-3 should continue. Few-shot
    prompts and more examples will likely increase the quality of the completion because
    the prompt provides more for GPT-3 to learn from.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '**几次提示**提供多个例子-通常为10到100个。多个示例可用于显示GPT-3应该继续完成的模式。少数提示和更多示例可能会增加完成的质量，因为提示为GPT-3提供了更多的学习机会。'
- en: 'Here is an example of a few-shot prompt to generate a simulated conversation.
    Notice that the examples provide a back-and-forth dialog, with things that might
    be said in a conversation:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是生成模拟对话的几次提示的示例。请注意，这些示例提供了来回对话，提供了可能在对话中说的内容：
- en: '[PRE2]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'In the following screenshot, you can see that GPT-3 continues the simulated
    conversation that was started in the examples provided in the prompt:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.3 – Few-shot prompt example'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16854_01_003.jpg)'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.3 – Few-shot prompt example
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: Now that you understand the different prompt types, let's take a look at some
    prompt examples.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: Prompt examples
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The OpenAI API can handle a variety of tasks. The possibilities range from generating
    original stories to performing complex text analysis, and everything in between.
    To get familiar with the kinds of tasks GPT-3 can perform, OpenAI provides a number
    of prompt examples. You can find example prompts in the Playground and in the
    OpenAI documentation.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: 'In the Playground, the examples are referred to as **presets**. Again, we''ll
    cover the Playground in detail in [*Chapter 3*](B16854_03_ePub_AM.xhtml#_idTextAnchor050),
    *Working with the OpenAI Playground*, but the following screenshot shows some
    of the presets that are available:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.4 – Presets'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16854_01_004.jpg)'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.4 – Presets
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: 'Example prompts are also available in the OpenAI documentation. The OpenAI
    documentation is excellent and includes a number of great prompt examples, with
    links to open and test them in the Playground. The following screenshot shows
    an example prompt from the OpenAI documentation. Notice the **Open this example
    in Playground** link below the prompt example. You can use that link to open the
    prompt in the Playground:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.5 – OpenAI documentation provides prompt examples'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16854_01_005.jpg)'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.5 – OpenAI documentation provides prompt examples
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have an understanding of prompts, let's talk about how GPT-3 uses
    them to generate a completion.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: Completions
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Again, a completion refers to the text that is generated and returned as a result
    of the provided prompt/input. You'll also recall that GPT-3 was not specifically
    trained to perform any one type of NLP task—it's a general-purpose language processing
    system. However, GPT-3 can be shown how to complete a given task using a prompt.
    This is called meta-learning.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: Meta-learning
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: With most NLP systems, the data used to teach the system how to complete a task
    is provided when the underlying ML model is trained. So, to improve results for
    a given task, the underlying training must be updated, and a new version of the
    model must be built. GPT-3 works differently, as it isn't trained for any specific
    task. Rather, it was designed to recognize patterns in the prompt text and to
    continue the pattern(s) by using the underlying general-purpose model. This approach
    is referred to as **meta-learning** because the prompt is used to *teach* GPT-3
    how to generate the best possible completion, without the need for retraining.
    So, in effect, the different prompt types (zero-shot, one-shot, and few-shot)
    can be used to *program* GPT-3 for different types of tasks, and you can provide
    a lot of instructions in the prompt—up to 2,048 tokens. Alright—now is a good
    time to talk about tokens.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数自然语言处理系统，在训练基础的机器学习模型时，使用的数据是提供的。所以，要改进给定任务的结果，必须更新底层训练，并构建新版本的模型。GPT-3 的工作方式不同，因为它没有针对任何特定任务进行训练。相反，它被设计为识别提示文本中的模式，并使用底层的通用模型继续模式。这种方法被称为**元学习**，因为提示被用来*教导*
    GPT-3 如何生成最佳完成，而无需重新训练。因此，不同的提示类型（零次、一次和少次）可以用于为不同类型的任务*编程* GPT-3，你可以在提示中提供大量指令——最多
    2,048 个令牌。好的——现在是谈论令牌的好时机。
- en: Tokens
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 令牌
- en: When a prompt is sent to GPT-3, it's broken down into tokens. **Tokens** are
    numeric representations of words or—more often—parts of words. Numbers are used
    for tokens rather than words or sentences because they can be processed more efficiently.
    This enables GPT-3 to work with relatively large amounts of text. That said, as
    you've learned, there is still a limit of 2,048 tokens (approximately ~1,500 words)
    for the combined prompt and the resulting generated completion.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 当提示被发送到 GPT-3 时，它会被分解为令牌。**令牌**是单词或更常见的单词部分的数值表示。数字被用作令牌而不是单词或句子，因为它们可以更有效地处理。这使得
    GPT-3 能够处理相对较大的文本量。尽管如此，正如你所学到的，仍然存在 2,048 个令牌的限制（约~1,500 个单词），用于组合提示和生成的完成结果。
- en: You can stay under the token limit by estimating the number of tokens that will
    be used in your prompt and resulting completion. On average, for English words,
    every four characters represent one token. So, just add the number of characters
    in your prompt to the *response length* and divide the sum by four. This will
    give you a general idea of the tokens required. This is helpful if you're trying
    to get an idea of how many tokens are required for a number of tasks.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过估算提示和生成的完成结果中将使用的令牌数量来保持在令牌限制以下。平均而言，对于英文单词，每四个字符代表一个令牌。所以，只需将提示中的字符数加上*响应长度*，然后除以四即可。这将给你一个大致的所需令牌数量。如果你想要了解完成一系列任务所需的令牌数量，这非常有帮助。
- en: 'Another way to get the token count is with the token count indicator in the
    Playground. This is located just under the large text input, on the bottom right.
    The magnified area in the following screenshot shows the token count. If you hover
    your mouse over the number, you''ll also see the total count with the completion.
    For our example, the prompt **Do or do not. There is no try.**—the wise words
    from Master Yoda—uses **10** tokens and **74** tokens with the completion:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种获取令牌计数的方法是使用 Playground 中的令牌计数指示器。这位于大型文本输入框的正下方，位于右下角。以下屏幕截图中放大的区域显示了令牌计数。如果你将鼠标悬停在数字上，你还将看到完成后的总计数。对于我们的示例，提示**Do
    or do not. There is no try.**—来自尤达大师的智慧—使用了**10**个令牌，完成后的总计数为**74**个令牌：
- en: '![Figure 1.6 – Token count'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '![图1.6 – 令牌计数'
- en: '](img/B16854_01_006.jpg)'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16854_01_006.jpg)'
- en: Figure 1.6 – Token count
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.6 – 令牌计数
- en: 'While understanding tokens is important for staying under the 2,048 token limit,
    they are also important to understand because tokens are what OpenAI uses as the
    basis for usage fees. Overall token usage reporting is available for your account
    at [https://beta.openai.com/account/usage](https://beta.openai.com/account/usage).
    The following screenshot shows an example usage report. We''ll discuss this more
    in *Chapter 3*, *Working with the OpenAI Playground*:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然理解令牌对于保持在 2,048 个令牌限制以下很重要，但它们也很重要，因为令牌是 OpenAI 用作使用费基础的东西。你的账户中可以获得整体令牌使用情况报告，网址为[https://beta.openai.com/account/usage](https://beta.openai.com/account/usage)。下面的屏幕截图显示了一个示例使用报告。我们将在*第三章*，*使用
    OpenAI Playground*中进一步讨论这个：
- en: '![Figure 1.7 – Usage statistics'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '![图1.7 – 使用统计'
- en: '](img/B16854_01_007.jpg)'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16854_01_007.jpg)'
- en: Figure 1.7 – Usage statistics
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.7 – 使用统计
- en: 'In addition to token usage, the other thing that affects the costs associated
    with using GPT-3 is the engine you choose to process your prompts. The engine
    refers to the language model that will be used. The main difference between the
    engines is the size of the associated model. Larger models can complete more complex
    tasks, but smaller models are more efficient. So, depending on the task complexity,
    you can significantly reduce costs by using a smaller model. The following screenshot
    shows the model pricing at the time of publishing. As you can see, the cost differences
    can be significant:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.8 – Model pricing'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16854_01_008.jpg)'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.8 – Model pricing
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: So, the engines or models each has a different cost but the one you'll need
    depends on the task you're performing. Let's look at the different engine options
    next.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: Introducing Davinci, Babbage, Curie, and Ada
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The massive dataset that is used for training GPT-3 is the primary reason why
    it's so powerful. However, bigger is only better when it's necessary—and more
    power comes at a cost. For those reasons, OpenAI provides multiple models to choose
    from. Today there are four primary models available, along with a model for content
    filtering and **instruct models**.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: The available models or engines (as they're also referred to) are named `Davinci`,
    `Babbage`, `Curie`, and `Ada`. Of the four, `Davinci` is the largest and most
    capable. `Davinci` can perform any tasks that any other engine can perform. `Babbage`
    is the next most capable engine, which can do anything that `Curie` or `Ada` can
    do. `Ada` is the least capable engine, but the best-performing and lowest-cost
    engine.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: When you're getting started and for initially testing new prompts, you'll usually
    want to begin with Davinci , then try, `Ada`, `Babbage`, or `Curie` to see if
    one of them can complete the task faster or more cost-effectively. The following
    is an overview of each engine and the types of tasks that might be best suited
    for each. However, keep in mind that you'll want to test. Even though the smaller
    engines might not be trained with as much data, they are all still general-purpose
    models.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: Davinci
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`Davinci` is the most capable model and can do anything that any other model
    can do, and much more—often with fewer instructions. `Davinci` is able to solve
    logic problems, determine cause and effect, understand the intent of text, produce
    creative content, explain character motives, and handle complex summarization
    tasks.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: Curie
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`Curie` tries to balance power and speed. It can do anything that `Ada` or
    `Babbage` can do but it''s also capable of handling more complex classification
    tasks and more nuanced tasks like summarization, sentiment analysis, chatbot applications,
    and Question and Answers.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: Babbage
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`Babbage` is a bit more capable than `Ada` but not quite as performant. It
    can perform all the same tasks as `Ada`, but it can also handle a bit more involved
    classification tasks, and it''s well suited for semantic search tasks that rank
    how well documents match a search query.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '`Babbage`比`Ada`更有能力，但并不那么高效。它可以执行与`Ada`相同的所有任务，但还可以处理更复杂的分类任务，并且非常适合语义搜索任务，以确定文档与搜索查询匹配程度。'
- en: Ada
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Ada
- en: '`Ada` is usually the fastest model and least costly. It''s best for less nuanced
    tasks—for example, parsing text, reformatting text, and simpler classification
    tasks. The more context you provide `Ada`, the better it will likely perform.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '`Ada`通常是最快的模型，成本最低。它最适合于较少细微差别的任务，例如解析文本、重新格式化文本和更简单的分类任务。您提供给`Ada`的上下文越多，它的表现就越好。'
- en: Content filtering model
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 内容过滤模型
- en: To help prevent inappropriate completions, OpenAI provides a content filtering
    model that is fine-tuned to recognize potentially offensive or hurtful language.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 为了防止不当补全，OpenAI 提供了一个内容过滤模型，该模型经过微调，以识别可能含有冒犯性或伤人的言语。
- en: Instruct models
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 指导模型
- en: These are models that are built on top of the `Davinci` and `Curie` models.
    **Instruct models** are tuned to make it easier to tell the API what you want
    it to do. Clear instructions can often produce better results than the associated
    core model.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 这些模型是在`Davinci`和`Curie`模型的基础上构建的。**指导模型**被调整过，以使得更容易告诉 API 想让它做什么。清晰的指示通常比相关的核心模型产生更好的结果。
- en: A snapshot in time
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 时间的一瞥
- en: A final note to keep in mind about all of the engines is that they are all a
    *snapshot in time*, meaning the data used to train them cuts off on the date the
    model was built. So, GPT-3 is not working with up-to-the-minute or even up-to-the-day
    data—it's likely weeks or months old. OpenAI is planning to add more continuous
    training in the future, but today this is a consideration to keep in mind.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 关于所有引擎的最后一点要牢记的是，它们都是一个*时间的一瞥*，也就是说用于训练它们的数据截止于构建模型的日期。因此，GPT-3 并非使用最新的甚至最新的数据——它可能是几周甚至几个月之前的数据。OpenAI
    打算在未来增加更多的持续训练，但今天这是一个需要考虑的因素。
- en: All of the GPT-3 models are extremely powerful and capable of generating text
    that is indistinguishable from human-written text. This holds tremendous potential
    for all kinds of potential applications. In most cases, that's a good thing. However,
    not all potential use cases are good.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 所有的 GPT-3 模型都非常强大，能够生成与人类编写的文本几乎无法区分的文本。这对各种潜在应用都具有巨大的潜力。在大多数情况下，这是一件好事。但是，并非所有潜在的用例都是好事。
- en: Understanding GPT-3 risks
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 了解 GPT-3 风险
- en: GPT-3 is a fantastic technology, with numerous practical and valuable potential
    applications. But as is often the case with powerful technologies, with its potential
    comes risk. In GPT-3's case, some of those risks include inappropriate results
    and potentially malicious use cases.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-3 是一项了不起的技术，具有许多实际和有价值的潜在应用。但通常情况下，强大技术的潜力就意味着风险。对 GPT-3 而言，其中一些风险包括不当的结果和潜在的恶意用途。
- en: Inappropriate or offensive results
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 不当或冒犯性的结果
- en: GPT-3 generates text so well that it can seem as though it is aware of what
    it is saying. It's not. It's an AI system with an excellent language model—it
    is not conscious in any way, so it will never willfully say something hurtful
    or inappropriate because it has no will. That said, it can certainly generate
    inappropriate, hateful, or malicious results—it's just not intentional.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-3 文本生成得如此出色，以至于看起来像是它意识到自己在说什么。但其实不是这样的。它是一个具有出色语言模型的AI系统－绝对不会有意识，所以从来不会在说出伤人或不当的话语。
- en: Nevertheless, understanding that GPT-3 can and will likely generate offensive
    text at times needs to be understood and considered when using GPT or making GPT-3
    results available to others. This is especially true for results that might be
    seen by children. We'll discuss this more and look at how to deal with it in [*Chapter
    6*](B16854_06_ePub_AM.xhtml#_idTextAnchor126), *Content Filtering*.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，理解 GPT-3 有时会生成冒犯性文本，并考虑在使用 GPT 或向他人公开 GPT-3 结果时需要理解这一点。特别是对于可能被儿童看到的结果。我们将在[*第6章*](B16854_06_ePub_AM.xhtml#_idTextAnchor126)中更详细地讨论这一点，*内容过滤*。
- en: Potential for malicious use
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 恶意使用的潜力
- en: It's not hard to imagine potentially malicious or harmful uses for GPT-3\. OpenAI
    even describes how GPT-3 could be *weaponized* for misinformation campaigns or
    for creating fake product reviews. But OpenAI's declared mission is to *ensure
    that artificial general intelligence benefits all of humanity*. Hence, pursuing
    that mission includes taking responsible steps to prevent their AI from being
    used for the wrong purposes. So, OpenAI has implemented an application approval
    process for all applications that will use GPT-3 or the OpenAI API.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，GPT-3 可能被用于恶意或有害用途并不难。OpenAI 甚至描述了 GPT-3 可能被“武器化”用于误导性宣传或制造虚假产品评论。但 OpenAI
    的宣称使命是“确保人工通用智能造福于人类”，因此，追求该使命包括采取负责任的措施，防止他们的 AI 被用于错误的目的。因此，OpenAI 为所有使用 GPT-3
    或 OpenAI API 的应用程序实施了一个应用批准流程。
- en: But as application developers, this is something we also need to consider. When
    we build an application that uses GPT-3, we need to consider if and how the application
    could be used for the wrong purposes and take the necessary steps to prevent it.
    We'll talk more about this in [*Chapter 10*](B16854_10_ePub_AM.xhtml#_idTextAnchor187),
    *Going Live with OpenAI-Powered Apps*.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 但作为应用程序开发人员，我们也需要考虑这一点。当我们构建使用 GPT-3 的应用程序时，我们需要考虑应用程序可能被用于错误的目的，并采取必要的措施来防止它。我们将在[*第
    10 章*](B16854_10_ePub_AM.xhtml#_idTextAnchor187)中更详细地讨论这个问题，*OpenAI 动力应用的实时运行*。
- en: Summary
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, you learned that GPT-3 is a general-purpose language model
    for processing virtually any language processing task. You learned how GPT-3 works
    at a high level, along with key terms and concepts. We introduced the available
    models and discussed how all GPT-3 applications must go through an approval process
    to prevent potentially inappropriate or harmful results.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您了解到 GPT-3 是一个用于处理几乎任何语言处理任务的通用语言模型。您了解了 GPT-3 的高级工作原理，以及关键术语和概念。我们介绍了可用的模型，并讨论了所有
    GPT-3 应用程序必须经过批准流程才能防止潜在的不适当或有害结果。
- en: In the next chapter, we'll discuss different ways to use GPT-3 and look at specific
    GPT-3 use case examples.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将讨论使用 GPT-3 不同的方式，并查看特定的 GPT-3 用例示例。
