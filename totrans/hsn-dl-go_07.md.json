["```py\npackage main\n\nimport (\n  \"fmt\"\n  \"strings\"\n)\n\nconst START rune = 0x02\nconst END rune = 0x03\nconst BLANK rune = 0x04\n\n// vocab related\nvar sentences []string\nvar vocab []rune\nvar vocabIndex map[rune]int\nvar maxsent int = 30\n\nfunc initVocab(ss []string, thresh int) {\n  s := strings.Join(ss, \" \")\n  fmt.Println(s)\n  dict := make(map[rune]int)\n  for _, r := range s {\n    dict[r]++\n  }\n\n  vocab = append(vocab, START)\n  vocab = append(vocab, END)\n  vocab = append(vocab, BLANK)\n  vocabIndex = make(map[rune]int)\n\n  for ch, c := range dict {\n    if c >= thresh {\n      // then add letter to vocab\n      vocab = append(vocab, ch)\n    }\n  }\n\n  for i, v := range vocab {\n    vocabIndex[v] = i\n  }\n\n  fmt.Println(\"Vocab: \", vocab)\n  inputSize = len(vocab)\n  outputSize = len(vocab)\n  epochSize = len(ss)\n  fmt.Println(\"\\ninputs :\", inputSize)\n  fmt.Println(\"\\noutputs :\", outputSize)\n  fmt.Println(\"\\nepochs: :\", epochSize)\n  fmt.Println(\"\\nmaxsent: :\", maxsent)\n}\n\nfunc init() {\n  sentencesRaw := strings.Split(corpus, \"\\n\")\n\n  for _, s := range sentencesRaw {\n    s2 := strings.TrimSpace(s)\n    if s2 != \"\" {\n      sentences = append(sentences, s2)\n    }\n\n  }\n\n  initVocab(sentences, 1)\n}\n```", "```py\npackage main\n\nimport (\n  \"math/rand\"\n\n  \"gorgonia.org/gorgonia\"\n  \"gorgonia.org/tensor\"\n)\n\nfunc sampleT(val gorgonia.Value) int {\n  var t tensor.Tensor\n  var ok bool\n  if t, ok = val.(tensor.Tensor); !ok {\n    panic(\"Expects a tensor\")\n  }\n\n  return tensor.SampleIndex(t)\n}\n\nfunc sample(val gorgonia.Value) int {\n\n  var t tensor.Tensor\n  var ok bool\n  if t, ok = val.(tensor.Tensor); !ok {\n    panic(\"expects a tensor\")\n  }\n  indT, err := tensor.Argmax(t, -1)\n  if err != nil {\n    panic(err)\n  }\n  if !indT.IsScalar() {\n    panic(\"Expected scalar index\")\n  }\n  return indT.ScalarValue().(int)\n}\n\nfunc shuffle(a []string) {\n  for i := len(a) - 1; i > 0; i-- {\n    j := rand.Intn(i + 1)\n    a[i], a[j] = a[j], a[i]\n  }\n}\n\ntype byteslice []byte\n\nfunc (s byteslice) Len() int { return len(s) }\nfunc (s byteslice) Less(i, j int) bool { return s[i] < s[j] }\nfunc (s byteslice) Swap(i, j int) { s[i], s[j] = s[j], s[i] }\n\ntype uintslice []uint\n\nfunc (s uintslice) Len() int { return len(s) }\nfunc (s uintslice) Less(i, j int) bool { return s[i] < s[j] }\nfunc (s uintslice) Swap(i, j int) { s[i], s[j] = s[j], s[i] }\n```", "```py\npackage main\n\nimport (\n  . \"gorgonia.org/gorgonia\"\n)\n\ntype LSTM struct {\n  wix *Node\n  wih *Node\n  bias_i *Node\n\n  wfx *Node\n  wfh *Node\n  bias_f *Node\n\n  wox *Node\n  woh *Node\n  bias_o *Node\n\n  wcx *Node\n  wch *Node\n  bias_c *Node\n}\n\nfunc MakeLSTM(g *ExprGraph, hiddenSize, prevSize int) LSTM {\n  retVal := LSTM{}\n\n  retVal.wix = NewMatrix(g, Float, WithShape(hiddenSize, prevSize), WithInit(GlorotN(1.0)), WithName(\"wix_\"))\n  retVal.wih = NewMatrix(g, Float, WithShape(hiddenSize, hiddenSize), WithInit(GlorotN(1.0)), WithName(\"wih_\"))\n  retVal.bias_i = NewVector(g, Float, WithShape(hiddenSize), WithName(\"bias_i_\"), WithInit(Zeroes()))\n\n  // output gate weights\n\n  retVal.wox = NewMatrix(g, Float, WithShape(hiddenSize, prevSize), WithInit(GlorotN(1.0)), WithName(\"wfx_\"))\n  retVal.woh = NewMatrix(g, Float, WithShape(hiddenSize, hiddenSize), WithInit(GlorotN(1.0)), WithName(\"wfh_\"))\n  retVal.bias_o = NewVector(g, Float, WithShape(hiddenSize), WithName(\"bias_f_\"), WithInit(Zeroes()))\n\n  // forget gate weights\n\n  retVal.wfx = NewMatrix(g, Float, WithShape(hiddenSize, prevSize), WithInit(GlorotN(1.0)), WithName(\"wox_\"))\n  retVal.wfh = NewMatrix(g, Float, WithShape(hiddenSize, hiddenSize), WithInit(GlorotN(1.0)), WithName(\"woh_\"))\n  retVal.bias_f = NewVector(g, Float, WithShape(hiddenSize), WithName(\"bias_o_\"), WithInit(Zeroes()))\n\n  // cell write\n\n  retVal.wcx = NewMatrix(g, Float, WithShape(hiddenSize, prevSize), WithInit(GlorotN(1.0)), WithName(\"wcx_\"))\n  retVal.wch = NewMatrix(g, Float, WithShape(hiddenSize, hiddenSize), WithInit(GlorotN(1.0)), WithName(\"wch_\"))\n  retVal.bias_c = NewVector(g, Float, WithShape(hiddenSize), WithName(\"bias_c_\"), WithInit(Zeroes()))\n  return retVal\n}\n\nfunc (l *LSTM) learnables() Nodes {\n  return Nodes{\n    l.wix, l.wih, l.bias_i,\n    l.wfx, l.wfh, l.bias_f,\n    l.wcx, l.wch, l.bias_c,\n    l.wox, l.woh, l.bias_o,\n  }\n}\n\nfunc (l *LSTM) Activate(inputVector *Node, prev lstmout) (out lstmout, err error) {\n  // log.Printf(\"prev %v\", prev.hidden.Shape())\n  prevHidden := prev.hidden\n  prevCell := prev.cell\n  var h0, h1, inputGate *Node\n  h0 = Must(Mul(l.wix, inputVector))\n  h1 = Must(Mul(l.wih, prevHidden))\n  inputGate = Must(Sigmoid(Must(Add(Must(Add(h0, h1)), l.bias_i))))\n\n  var h2, h3, forgetGate *Node\n  h2 = Must(Mul(l.wfx, inputVector))\n  h3 = Must(Mul(l.wfh, prevHidden))\n  forgetGate = Must(Sigmoid(Must(Add(Must(Add(h2, h3)), l.bias_f))))\n\n  var h4, h5, outputGate *Node\n  h4 = Must(Mul(l.wox, inputVector))\n  h5 = Must(Mul(l.woh, prevHidden))\n  outputGate = Must(Sigmoid(Must(Add(Must(Add(h4, h5)), l.bias_o))))\n\n  var h6, h7, cellWrite *Node\n  h6 = Must(Mul(l.wcx, inputVector))\n  h7 = Must(Mul(l.wch, prevHidden))\n  cellWrite = Must(Tanh(Must(Add(Must(Add(h6, h7)), l.bias_c))))\n\n  // cell activations\n  var retain, write *Node\n  retain = Must(HadamardProd(forgetGate, prevCell))\n  write = Must(HadamardProd(inputGate, cellWrite))\n  cell := Must(Add(retain, write))\n  hidden := Must(HadamardProd(outputGate, Must(Tanh(cell))))\n  out = lstmout{\n    hidden: hidden,\n    cell: cell,\n  }\n  return\n}\n\ntype lstmout struct {\n  hidden, cell *Node\n}\n```", "```py\npackage main\n\nimport (\n  \"fmt\"\n\n  . \"gorgonia.org/gorgonia\"\n  \"gorgonia.org/tensor\"\n)\n\nvar Float = tensor.Float32\n\ntype contextualError interface {\n  error\n  Node() *Node\n  Value() Value\n  InstructionID() int\n  Err() error\n}\n\ntype GRU struct {\n\n  // weights for mem\n  u *Node\n  w *Node\n  b *Node\n\n  // update gate\n  uz *Node\n  wz *Node\n  bz *Node\n\n  // reset gate\n  ur *Node\n  wr *Node\n  br *Node\n  one *Node\n\n  Name string // optional name\n}\n\nfunc MakeGRU(name string, g *ExprGraph, inputSize, hiddenSize int, dt tensor.Dtype) GRU {\n  // standard weights\n  u := NewMatrix(g, dt, WithShape(hiddenSize, hiddenSize), WithName(fmt.Sprintf(\"%v.u\", name)), WithInit(GlorotN(1.0)))\n  w := NewMatrix(g, dt, WithShape(hiddenSize, inputSize), WithName(fmt.Sprintf(\"%v.w\", name)), WithInit(GlorotN(1.0)))\n  b := NewVector(g, dt, WithShape(hiddenSize), WithName(fmt.Sprintf(\"%v.b\", name)), WithInit(Zeroes()))\n\n  // update gate\n  uz := NewMatrix(g, dt, WithShape(hiddenSize, hiddenSize), WithName(fmt.Sprintf(\"%v.uz\", name)), WithInit(GlorotN(1.0)))\n  wz := NewMatrix(g, dt, WithShape(hiddenSize, inputSize), WithName(fmt.Sprintf(\"%v.wz\", name)), WithInit(GlorotN(1.0)))\n  bz := NewVector(g, dt, WithShape(hiddenSize), WithName(fmt.Sprintf(\"%v.b_uz\", name)), WithInit(Zeroes()))\n\n  // reset gate\n  ur := NewMatrix(g, dt, WithShape(hiddenSize, hiddenSize), WithName(fmt.Sprintf(\"%v.ur\", name)), WithInit(GlorotN(1.0)))\n  wr := NewMatrix(g, dt, WithShape(hiddenSize, inputSize), WithName(fmt.Sprintf(\"%v.wr\", name)), WithInit(GlorotN(1.0)))\n  br := NewVector(g, dt, WithShape(hiddenSize), WithName(fmt.Sprintf(\"%v.bz\", name)), WithInit(Zeroes()))\n\n  ones := tensor.Ones(dt, hiddenSize)\n  one := g.Constant(ones)\n  gru := GRU{\n    u: u,\n    w: w,\n    b: b,\n\n    uz: uz,\n    wz: wz,\n    bz: bz,\n\n    ur: ur,\n    wr: wr,\n    br: br,\n\n    one: one,\n  }\n  return gru\n}\n\nfunc (l *GRU) Activate(x, prev *Node) (retVal *Node, err error) {\n  // update gate\n  uzh := Must(Mul(l.uz, prev))\n  wzx := Must(Mul(l.wz, x))\n  z := Must(Sigmoid(\n    Must(Add(\n      Must(Add(uzh, wzx)),\n      l.bz))))\n\n  // reset gate\n  urh := Must(Mul(l.ur, prev))\n  wrx := Must(Mul(l.wr, x))\n  r := Must(Sigmoid(\n    Must(Add(\n      Must(Add(urh, wrx)),\n      l.br))))\n\n  // memory for hidden\n  hiddenFilter := Must(Mul(l.u, Must(HadamardProd(r, prev))))\n  wx := Must(Mul(l.w, x))\n  mem := Must(Tanh(\n    Must(Add(\n      Must(Add(hiddenFilter, wx)),\n      l.b))))\n\n  omz := Must(Sub(l.one, z))\n  omzh := Must(HadamardProd(omz, prev))\n  upd := Must(HadamardProd(z, mem))\n  retVal = Must(Add(upd, omzh))\n  return\n}\n\nfunc (l *GRU) learnables() Nodes {\n  retVal := make(Nodes, 0, 9)\n  retVal = append(retVal, l.u, l.w, l.b, l.uz, l.wz, l.bz, l.ur, l.wr, l.br)\n  return retVal\n}\n```", "```py\npackage main\n\nimport (\n  \"encoding/json\"\n  \"io\"\n  \"log\"\n  \"os\"\n\n  \"github.com/pkg/errors\"\n  . \"gorgonia.org/gorgonia\"\n  \"gorgonia.org/tensor\"\n)\n\ntype seq2seq struct {\n  in        LSTM\n  dummyPrev *Node // vector\n  dummyCell *Node // vector\n  embedding *Node // NxM matrix, where M is the number of dimensions of the embedding\n\n  decoder *Node\n  vocab []rune\n\n  inVecs []*Node\n  losses []*Node\n  preds []*Node\n  predvals []Value\n  g *ExprGraph\n  vm VM\n}\n\n// NewS2S creates a new Seq2Seq network. Input size is the size of the embedding. Hidden size is the size of the hidden layer\nfunc NewS2S(hiddenSize, embSize int, vocab []rune) *seq2seq {\n  g := NewGraph()\n  // in := MakeGRU(\"In\", g, embSize, hiddenSize, Float)s\n  in := MakeLSTM(g, hiddenSize, embSize)\n  log.Printf(\"%q\", vocab)\n\n  dummyPrev := NewVector(g, Float, WithShape(embSize), WithName(\"Dummy Prev\"), WithInit(Zeroes()))\n  dummyCell := NewVector(g, Float, WithShape(hiddenSize), WithName(\"Dummy Cell\"), WithInit(Zeroes()))\n  embedding := NewMatrix(g, Float, WithShape(len(vocab), embSize), WithInit(GlorotN(1.0)), WithName(\"Embedding\"))\n  decoder := NewMatrix(g, Float, WithShape(len(vocab), hiddenSize), WithInit(GlorotN(1.0)), WithName(\"Output Decoder\"))\n\n  return &seq2seq{\n    in: in,\n    dummyPrev: dummyPrev,\n    dummyCell: dummyCell,\n    embedding: embedding,\n    vocab: vocab,\n    decoder: decoder,\n    g: g,\n  }\n}\n\nfunc (s *seq2seq) learnables() Nodes {\n  retVal := make(Nodes, 0)\n  retVal = append(retVal, s.in.learnables()...)\n  retVal = append(retVal, s.embedding)\n  retVal = append(retVal, s.decoder)\n  return retVal\n}\n```", "```py\nfunc (s *seq2seq) build() (cost *Node, err error) {\n  // var prev *Node = s.dummyPrev\n  prev := lstmout{\n    hidden: s.dummyCell,\n    cell: s.dummyCell,\n  }\n  s.predvals = make([]Value, maxsent)\n\n  var prediction *Node\n  for i := 0; i < maxsent; i++ {\n    var vec *Node\n    if i == 0 {\n      vec = Must(Slice(s.embedding, S(0))) // dummy, to be replaced at runtime\n    } else {\n      vec = Must(Mul(prediction, s.embedding))\n    }\n    s.inVecs = append(s.inVecs, vec)\n    if prev, err = s.in.Activate(vec, prev); err != nil {\n      return\n    }\n    prediction = Must(SoftMax(Must(Mul(s.decoder, prev.hidden))))\n    s.preds = append(s.preds, prediction)\n    Read(prediction, &s.predvals[i])\n\n    logprob := Must(Neg(Must(Log(prediction))))\n    loss := Must(Slice(logprob, S(0))) // dummy, to be replaced at runtime\n    s.losses = append(s.losses, loss)\n\n    if cost == nil {\n      cost = loss\n    } else {\n      cost = Must(Add(cost, loss))\n    }\n  }\n\n  _, err = Grad(cost, s.learnables()...)\n  return\n}\n```", "```py\n\nfunc (s *seq2seq) train(in []rune) (err error) {\n\n  for i := 0; i < maxsent; i++ {\n    var currentRune, correctPrediction rune\n    switch {\n    case i == 0:\n      currentRune = START\n      correctPrediction = in[i]\n    case i-1 == len(in)-1:\n      currentRune = in[i-1]\n      correctPrediction = END\n    case i-1 >= len(in):\n      currentRune = BLANK\n      correctPrediction = BLANK\n    default:\n      currentRune = in[i-1]\n      correctPrediction = in[i]\n    }\n\n    targetID := vocabIndex[correctPrediction]\n    if i == 0 || i-1 >= len(in) {\n      srcID := vocabIndex[currentRune]\n      UnsafeLet(s.inVecs[i], S(srcID))\n    }\n    UnsafeLet(s.losses[i], S(targetID))\n\n  }\n  if s.vm == nil {\n    s.vm = NewTapeMachine(s.g, BindDualValues())\n  }\n  s.vm.Reset()\n  err = s.vm.RunAll()\n\n  return\n}\n```", "```py\n\nfunc (s *seq2seq) predict(in []rune) (output []rune, err error) {\n  g2 := s.g.SubgraphRoots(s.preds...)\n  vm := NewTapeMachine(g2)\n  if err = vm.RunAll(); err != nil {\n    return\n  }\n  defer vm.Close()\n  for _, pred := range s.predvals {\n    log.Printf(\"%v\", pred.Shape())\n    id := sample(pred)\n    if id >= len(vocab) {\n      log.Printf(\"Predicted %d. Len(vocab) %v\", id, len(vocab))\n      continue\n    }\n    r := vocab[id]\n\n    output = append(output, r)\n  }\n  return\n}\n```", "```py\n\nfunc (s *seq2seq) checkpoint() (err error) {\n  learnables := s.learnables()\n  var f io.WriteCloser\n  if f, err = os.OpenFile(\"CHECKPOINT.bin\", os.O_CREATE|os.O_TRUNC|os.O_WRONLY, 0644); err != nil {\n    return\n  }\n  defer f.Close()\n  enc := json.NewEncoder(f)\n  for _, l := range learnables {\n    t := l.Value().(*tensor.Dense).Data() // []float32\n    if err = enc.Encode(t); err != nil {\n      return\n    }\n  }\n\n  return nil\n}\n\nfunc (s *seq2seq) load() (err error) {\n  learnables := s.learnables()\n  var f io.ReadCloser\n  if f, err = os.OpenFile(\"CHECKPOINT.bin\", os.O_RDONLY, 0644); err != nil {\n    return\n  }\n  defer f.Close()\n  dec := json.NewDecoder(f)\n  for _, l := range learnables {\n    t := l.Value().(*tensor.Dense).Data().([]float32)\n    var data []float32\n    if err = dec.Decode(&data); err != nil {\n      return\n    }\n    if len(data) != len(t) {\n      return errors.Errorf(\"Unserialized length %d. Expected length %d\", len(data), len(t))\n    }\n    copy(t, data)\n  }\n  return nil\n}\n```", "```py\n\nfunc train(s *seq2seq, epochs int, solver Solver, data []string) (err error) {\n  cost, err := s.build()\n  if err != nil {\n    return err\n  }\n  var costVal Value\n  Read(cost, &costVal)\n\n  model := NodesToValueGrads(s.learnables())\n  for e := 0; e < epochs; e++ {\n    shuffle(data)\n\n    for _, sentence := range data {\n      asRunes := []rune(sentence)\n      if err = s.train(asRunes); err != nil {\n        return\n      }\n      if err = solver.Step(model); err != nil {\n        return\n      }\n    }\n    // if e%100 == 0 {\n    log.Printf(\"Cost for epoch %d: %1.10f\\n\", e, costVal)\n    // }\n\n  }\n\n  return nil\n\n}\n```", "```py\npackage main\n\nimport (\n    \"image/color\"\n    \"math\"\n\n    \"github.com/pkg/errors\"\n    \"gonum.org/v1/gonum/mat\"\n    \"gonum.org/v1/plot\"\n    \"gonum.org/v1/plot/palette/moreland\"\n    \"gonum.org/v1/plot/plotter\"\n    \"gonum.org/v1/plot/vg\"\n    \"gorgonia.org/tensor\"\n)\n\ntype heatmap struct {\n    x mat.Matrix\n}\n\nfunc (m heatmap) Dims() (c, r int) { r, c = m.x.Dims(); return c, r }\nfunc (m heatmap) Z(c, r int) float64 { return m.x.At(r, c) }\nfunc (m heatmap) X(c int) float64 { return float64(c) }\nfunc (m heatmap) Y(r int) float64 { return float64(r) }\n\ntype ticks []string\n\nfunc (t ticks) Ticks(min, max float64) []plot.Tick {\n    var retVal []plot.Tick\n    for i := math.Trunc(min); i <= max; i++ {\n        retVal = append(retVal, plot.Tick{Value: i, Label: t[int(i)]})\n    }\n    return retVal\n}\n\nfunc Heatmap(a *tensor.Dense) (p *plot.Plot, H, W vg.Length, err error) {\n    switch a.Dims() {\n    case 1:\n        original := a.Shape()\n        a.Reshape(original[0], 1)\n        defer a.Reshape(original...)\n    case 2:\n    default:\n        return nil, 0, 0, errors.Errorf(\"Can't do a tensor with shape %v\", a.Shape())\n    }\n\n    m, err := tensor.ToMat64(a, tensor.UseUnsafe())\n    if err != nil {\n        return nil, 0, 0, err\n    }\n\n    pal := moreland.ExtendedBlackBody().Palette(256)\n    // lum, _ := moreland.NewLuminance([]color.Color{color.Gray{0}, color.Gray{255}})\n    // pal := lum.Palette(256)\n\n    hm := plotter.NewHeatMap(heatmap{m}, pal)\n    if p, err = plot.New(); err != nil {\n        return nil, 0, 0, err\n    }\n    hm.NaN = color.RGBA{0, 0, 0, 0} // black\n    p.Add(hm)\n\n    sh := a.Shape()\n    H = vg.Length(sh[0])*vg.Centimeter + vg.Centimeter\n    W = vg.Length(sh[1])*vg.Centimeter + vg.Centimeter\n    return p, H, W, nil\n}\n\nfunc Avg(a []float64) (retVal float64) {\n    for _, v := range a {\n        retVal += v\n    }\n\n    return retVal / float64(len(a))\n}\n\n```", "```py\npackage main\n\nimport (\n  \"flag\"\n  \"fmt\"\n  \"io/ioutil\"\n  \"log\"\n  \"os\"\n  \"runtime/pprof\"\n\n  . \"gorgonia.org/gorgonia\"\n  \"gorgonia.org/tensor\"\n)\n\nvar cpuprofile = flag.String(\"cpuprofile\", \"\", \"write cpu profile to file\")\nvar memprofile = flag.String(\"memprofile\", \"\", \"write memory profile to this file\")\n\nconst (\n  embeddingSize = 20\n  maxOut = 30\n\n  // gradient update stuff\n  l2reg = 0.000001\n  learnrate = 0.01\n  clipVal = 5.0\n)\n\nvar trainiter = flag.Int(\"iter\", 5, \"How many iterations to train\")\n\n// various global variable inits\nvar epochSize = -1\nvar inputSize = -1\nvar outputSize = -1\n\nvar corpus string\n\nfunc init() {\n  buf, err := ioutil.ReadFile(\"shakespeare.txt\")\n  if err != nil {\n    panic(err)\n  }\n  corpus = string(buf)\n}\n\nvar dt tensor.Dtype = tensor.Float32\n\nfunc main() {\n  flag.Parse()\n  if *cpuprofile != \"\" {\n    f, err := os.Create(*cpuprofile)\n    if err != nil {\n      log.Fatal(err)\n    }\n    pprof.StartCPUProfile(f)\n    defer pprof.StopCPUProfile()\n  }\n\n  hiddenSize := 100\n\n  s2s := NewS2S(hiddenSize, embeddingSize, vocab)\n  solver := NewRMSPropSolver(WithLearnRate(learnrate), WithL2Reg(l2reg), WithClip(clipVal), WithBatchSize(float64(len(sentences))))\n  for k, v := range vocabIndex {\n    log.Printf(\"%q %v\", k, v)\n  }\n\n  // p, h, w, err := Heatmap(s2s.decoder.Value().(*tensor.Dense))\n  // p.Save(w, h, \"embn0.png\")\n\n  if err := train(s2s, 300, solver, sentences); err != nil {\n    panic(err)\n  }\n  out, err := s2s.predict([]rune(corpus))\n  if err != nil {\n    panic(err)\n  }\n  fmt.Printf(\"OUT %q\\n\", out)\n\n  p, h, w, err = Heatmap(s2s.decoder.Value().(*tensor.Dense))\n  p.Save(w, h, \"embn.png\")\n}\n```", "```py\n2019/05/25 23:52:03 Cost for epoch 31: 250.7806701660\n2019/05/25 23:52:19 Cost for epoch 32: 176.0116729736\n2019/05/25 23:52:35 Cost for epoch 33: 195.0501556396\n2019/05/25 23:52:50 Cost for epoch 34: 190.6829681396\n2019/05/25 23:53:06 Cost for epoch 35: 181.1398162842\n```", "```py\nOUT ['S' 'a' 'K' 'a' 'g' 'y' 'h' ',' '\\x04' 'a' 'g' 'a' 't' '\\x04' '\\x04' ' ' 's' 'h' 'h' 'h' 'h' 'h' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ']\n```"]