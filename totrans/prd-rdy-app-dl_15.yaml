- en: '12'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Monitoring Deep Learning Endpoints in Production
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Due to the difference in development and production settings, it is difficult
    to assure the performance of **deep learning** (**DL**) models once they are deployed.
    If any difference exists in model behavior, it must be captured within a reasonable
    time; otherwise, it can affect downstream applications in negative ways.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, our goal is to explain existing solutions for monitoring DL
    model behavior in production. We will start by clearly describing the benefit
    of monitoring and what it takes to keep the overall system running in a stable
    manner. Then, we will discuss popular tools for monitoring DL models and alerting.
    Out of the various tools we introduce, we will get our hands dirty with **CloudWatch**.
    We will start with the basics of CloudWatch and discuss how to integrate CloudWatch
    into endpoints running on **SageMaker** and **Elastic Kubernetes Service** (**EKS**)
    clusters.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’re going to cover the following main topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to DL endpoint monitoring in production
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Monitoring using CloudWatch
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Monitoring a SageMaker endpoint using CloudWatch
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Monitoring an EKS endpoint using CloudWatch
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You can download the supplemental material for this chapter from this book’s
    GitHub repository: [https://github.com/PacktPublishing/Production-Ready-Applied-Deep-Learning/tree/main/Chapter_12](https://github.com/PacktPublishing/Production-Ready-Applied-Deep-Learning/tree/main/Chapter_12)'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to DL endpoint monitoring in production
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will start our chapter by describing the benefits of DL model monitoring
    for a deployed endpoint. Ideally, we should analyze information related to incoming
    data, outgoing data, model metrics, and traffic. A system that monitors the listed
    data can provide us with the following benefits.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: Firstly, *the input and output information for the model can be persisted in
    a data storage solution (for example, a Simple Storage Service (S3) bucket) for
    understanding data distributions*. Detailed analysis of the incoming data and
    predictions can help in identifying potential improvements for the downstream
    process. For example, monitoring the incoming data can help us in identifying
    bias in model predictions. Models can be biased toward specific feature groups
    while handling incoming requests. This information can guide us on what we should
    be considering when we are training a new model for the following deployment.
    Another benefit comes from the model’s explainability. The reasoning behind a
    model predictions needs to be explained for business purposes or legal purposes.
    This involves the techniques we have described in [*Chapter 9*](B18522_09.xhtml#_idTextAnchor187),
    *Scaling a Deep Learning Pipeline*.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: Another key metric we should be tracking is the **throughput** of the endpoint,
    which can help us improve user satisfaction. *A model’s behavior may change depending
    on the volume of incoming requests and the computational power of the underlying
    machines*. We can monitor inference latency with respect to incoming traffic to
    build stable and efficient inference endpoints for users.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该跟踪的另一个关键指标是端点的 **吞吐量**，这有助于我们提高用户满意度。*模型的行为可能会随着传入请求的数量和底层计算机的计算能力而变化*。我们可以监控推断延迟与传入流量之间的关系，以构建稳定高效的推断端点供用户使用。
- en: 'At a high level, monitoring for DL models can be categorized into two areas:
    **endpoint monitoring** and **model monitoring**. In the former area, we aim to
    collect data related to endpoint latency and throughput of the target endpoint.
    The latter area is focused on improving model performance; we need to collect
    incoming data, predictions, and model performances, as well as inference latency.
    While many use cases of model monitoring are achieved in an online fashion on
    a running endpoint, it is also applied during the training and validation process
    in an offline fashion with the goal of understanding the model''s behavior prior
    to deployment.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在高层次上，DL 模型的监控可以分为两个领域：**端点监控** 和 **模型监控**。在前者领域，我们旨在收集与端点延迟和目标端点的吞吐量相关的数据。后者则专注于改善模型性能；我们需要收集传入数据、预测结果和模型性能，以及推断延迟。虽然许多模型监控用例通过在线方式在运行中的端点实现，但在训练和验证过程中也会以离线方式应用，目的是在部署前了解模型的行为。
- en: In the following section, we will introduce popular tools for monitoring DL
    models.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分，我们将介绍用于监控 DL 模型的流行工具。
- en: Exploring tools for monitoring
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探索监控工具
- en: 'Tools for monitoring can be mostly categorized into two groups, depending on
    what they are designed for: **monitoring tools** and **alerting tools**. Covering
    all tools explicitly is out of the scope of this book; however, we will introduce
    a few of them briefly to explain the benefits that monitoring and alerting tools
    aim to provide. Please note that the boundary is often unclear, and some tools
    may be built to support both features.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 监控工具主要可以分为两类，具体取决于它们的设计目标：**监控工具** 和 **警报工具**。详尽介绍所有工具超出了本书的范围；但我们将简要介绍其中的一些，以解释监控和警报工具的优势。请注意，界限通常不清晰，并且一些工具可能同时支持这两个功能。
- en: Let’s dive into monitoring tools first.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先来了解一下监控工具。
- en: Prometheus
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Prometheus
- en: '**Prometheus** is an open-source monitoring and alerting tool ([https://prometheus.io](https://prometheus.io/)).
    Prometheus stores data delivered from the application in local storage. It uses
    a time-series database for storing, aggregating, and retrieving metrics, which
    aligns well with the nature of monitoring tasks. Interacting with Prometheus involves
    using **Prometheus Query Language** (**PromQL**) ([https://prometheus.io/docs/prometheus/latest/querying/basics](https://prometheus.io/docs/prometheus/latest/querying/basics/)).
    Prometheus is designed to process metrics such as **central processing unit**
    (**CPU**) usage, memory usage, and latency. Additionally, custom metrics such
    as model performance or distribution of incoming and outgoing data can be ingested
    for monitoring.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**Prometheus** 是一个开源的监控和警报工具 ([https://prometheus.io](https://prometheus.io/))。Prometheus
    将应用程序传递的数据存储在本地存储中。它使用时间序列数据库来存储、聚合和检索指标数据，这与监控任务的性质非常匹配。与 Prometheus 的交互涉及使用
    **Prometheus 查询语言** (**PromQL**) ([https://prometheus.io/docs/prometheus/latest/querying/basics](https://prometheus.io/docs/prometheus/latest/querying/basics/))。Prometheus
    设计用于处理诸如 **中央处理单元** (**CPU**) 使用情况、内存使用情况和延迟等指标。此外，还可以摄取用于监控的自定义指标，例如模型性能或传入和传出数据的分布。'
- en: CloudWatch
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: CloudWatch
- en: '**CloudWatch** is a monitoring and observability service designed by **Amazon
    Web Services** (**AWS**) ([https://aws.amazon.com/cloudwatch](https://aws.amazon.com/cloudwatch/)).
    CloudWatch is easy to set up compared to setting up a dedicated Prometheus service,
    as it handles data storage management behind the scenes. By default, most AWS
    services such as AWS Lambda and EKS clusters use CloudWatch to persist metrics
    for further analysis. Also, CloudWatch can support alerting users through emails
    or Slack messages for unusual changes from the monitored metric. For example,
    you can set a threshold for a metric and get notified if it goes above or below
    the predefined threshold. Details of the alerting feature can be found at [https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/AlarmThatSendsEmail.html](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/AlarmThatSendsEmail.html).'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**CloudWatch** 是由**亚马逊网络服务**（**AWS**）设计的监控和可观察性服务 ([https://aws.amazon.com/cloudwatch](https://aws.amazon.com/cloudwatch/))。与设置专用的
    Prometheus 服务相比，CloudWatch 设置简单，因为它在幕后处理数据存储管理。默认情况下，大多数 AWS 服务如 AWS Lambda 和
    EKS 集群使用 CloudWatch 持久化指标以供进一步分析。此外，CloudWatch 可以通过电子邮件或 Slack 消息通知用户关于受监视指标的异常变化。例如，您可以为指标设置阈值，并在其超过或低于预定义阈值时收到通知。有关警报功能的详细信息，请参阅
    [https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/AlarmThatSendsEmail.html](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/AlarmThatSendsEmail.html)。'
- en: Grafana
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Grafana
- en: '**Grafana** is a popular tool designed for visualizing metrics collected from
    monitoring tools ([https://grafana.com](https://grafana.com/)). Metrics data from
    CloudWatch or AWS-managed Prometheus can be read by Grafana for visualization.
    For a complete description of these configurations, we recommend you to read [https://grafana.com/docs/grafana/latest/datasources/aws-cloudwatch](https://grafana.com/docs/grafana/latest/datasources/aws-cloudwatch/)
    and [https://docs.aws.amazon.com/prometheus/latest/userguide/AMP-onboard-query-standalone-grafana.html](https://docs.aws.amazon.com/prometheus/latest/userguide/AMP-onboard-query-standalone-grafana.html).'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**Grafana** 是一个流行的工具，用于可视化从监控工具收集的指标 ([https://grafana.com](https://grafana.com/))。Grafana
    可以读取来自 CloudWatch 或 AWS 管理的 Prometheus 的指标数据以进行可视化。关于这些配置的完整描述，建议您阅读 [https://grafana.com/docs/grafana/latest/datasources/aws-cloudwatch](https://grafana.com/docs/grafana/latest/datasources/aws-cloudwatch/)
    和 [https://docs.aws.amazon.com/prometheus/latest/userguide/AMP-onboard-query-standalone-grafana.html](https://docs.aws.amazon.com/prometheus/latest/userguide/AMP-onboard-query-standalone-grafana.html)。'
- en: Datadog
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Datadog
- en: 'One of the popular proprietary solutions is **Datadog** ([https://www.datadoghq.com](https://www.datadoghq.com/)).
    This tool provides a wide variety of monitoring features: log monitoring, application
    performance monitoring, network traffic monitoring, and real-time user monitoring.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 一种流行的专有解决方案是**Datadog** ([https://www.datadoghq.com](https://www.datadoghq.com/))。这个工具提供了多种监控功能：日志监控，应用性能监控，网络流量监控和实时用户监控。
- en: SageMaker Clarify
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: SageMaker Clarify
- en: SageMaker has a built-in support for monitoring endpoints created from SageMaker,
    **SageMaker Clarify** ([https://aws.amazon.com/sagemaker/clarify](https://aws.amazon.com/sagemaker/clarify/)).
    SageMaker Clarify comes with a **software development kit** (**SDK**) which helps
    understand the performance of the model and its bias in predictions. Details of
    SageMaker Clarify can be found at [https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor.html](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor.html).
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker 内置支持监控由 SageMaker 创建的端点，**SageMaker Clarify** ([https://aws.amazon.com/sagemaker/clarify](https://aws.amazon.com/sagemaker/clarify/))。SageMaker
    Clarify 带有一个**软件开发工具包**（**SDK**），有助于理解模型的性能及其在预测中的偏差。有关 SageMaker Clarify 的详细信息，请参阅
    [https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor.html](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor.html)。
- en: In the following section, we will introduce alerting tools.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将介绍警报工具。
- en: Exploring tools for alerting
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探索警报工具
- en: An *incident* is an event that requires a follow-up action, such as a failed
    job or a build. While monitoring tools can capture unusual changes, they often
    lack incident management and automation for the responding process. Alerting tools
    close this gap by providing many of these features out of the box. Therefore,
    many companies often integrate explicit alerting tools to respond to incidents
    in a timely manner.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 一个*事件*是需要后续操作的事件，比如失败的作业或构建。虽然监控工具可以捕获异常变化，但它们通常缺乏事件管理和响应过程的自动化。警报工具通过提供这些功能填补了这一空白。因此，许多公司通常集成明确的警报工具，以及时响应事件。
- en: 'In this section, we will introduce the two most popular alerting tools: PagerDuty
    and Dynatrace.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将介绍两种最流行的警报工具：PagerDuty和Dynatrace。
- en: PagerDuty
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: PagerDuty
- en: As a tool for alerting and managing the **incident response** (**IR**) process,
    many compa[nies integrate **PagerDuty**](https://www.pagerduty.com/) ([https://www.pagerduty.com](https://www.pagerduty.com/)).
    On top of the basic alerting feature, PagerDuty supports assigning priorities
    to incidents based on their type and severity. PagerDuty can read data from several
    popular monitoring software such [as Prometheus and Datadog (https://aws.amazon.com/blogs/mt/using-amazon-managed-service-for-prometheus-alert-manager-to-re](https://aws.amazon.com/blogs/mt/using-amazon-managed-service-for-prometheus-alert-manager-to-receive-alerts-with-pagerduty/)ceive-alerts-with-pagerduty).
    It can also be integrated with CloudWatch with minimal code changes ([https://support.pagerduty.com/docs/aws-cloudwatch-integration-guide](https://support.pagerduty.com/docs/aws-cloudwatch-integration-guide)).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 作为警报和管理**事故响应**（**IR**）过程的工具，许多公司集成了**PagerDuty**（[PagerDuty](https://www.pagerduty.com/)）。在基本的警报功能之上，PagerDuty支持根据事故类型和严重程度分配优先级。PagerDuty可以从多个流行的监控软件中读取数据，比如[Prometheus和Datadog（https://aws.amazon.com/blogs/mt/using-amazon-managed-service-for-prometheus-alert-manager-to-re](https://aws.amazon.com/blogs/mt/using-amazon-managed-service-for-prometheus-alert-manager-to-receive-alerts-with-pagerduty/)ceive-alerts-with-pagerduty)。它还可以通过最小的代码更改与CloudWatch集成（[https://support.pagerduty.com/docs/aws-cloudwatch-integration-guide](https://support.pagerduty.com/docs/aws-cloudwatch-integration-guide)）。
- en: Dynatrace
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Dynatrace
- en: '**Dynatrace** is another proprietary tool for monitoring entire clusters or
    ne[tworks and alerting incide](https://www.dynatrace.com/)nts ([https://www.dynatrace.com](https://www.dynatrace.com/)).
    Information related to resource usage, traffic, and response time of running processes
    can be easily monitored. Dynatrace has a unique alerting system based on alerting
    profiles. These profiles define how the system delivers notifications across the
    organization. Dynatrace has built-in push notifications, but it can be integrated
    with other systems that provide a notification feature, such as Slack and PagerDuty.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dynatrace**是另一种专有工具，用于监控整个集群或网络和警报事件（[Dynatrace](https://www.dynatrace.com/)）。可以轻松监控正在运行的进程的资源使用情况、流量和响应时间。Dynatrace具有基于警报配置文件的独特警报系统。这些配置文件定义了系统如何在整个组织中传递通知。Dynatrace具有内置的推送通知功能，但也可以与其他提供通知功能的系统集成，例如Slack和PagerDuty。'
- en: Things to remember
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 要记住的事情
- en: a. Monitoring information related to incoming data, outgoing data, model metrics,
    and traffic volumes for an endpoint allows us to understand the behavior of our
    endpoint and helps us in identifying potential improvements.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: a. 监控与端点相关的入站数据、出站数据、模型指标和流量量，使我们能够理解端点的行为，并帮助我们识别潜在的改进。
- en: b. Prometheus is an open sourced monitoring and alerting system that can be
    used for monitoring metrics of a DL endpoint. CloudWatch is a monitoring service
    from AWS designed for logging a set of data and tracking unusual changes from
    incoming and outgoing traffic.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: b. Prometheus是一个开源的监控和警报系统，可用于监控DL端点的指标。CloudWatch是AWS的监控服务，专为记录一组数据和跟踪入站和出站流量的异常变化而设计。
- en: c. PagerDuty is a popular alerting tool that handles the complete life cycle
    of an incident.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: c. PagerDuty是一种流行的警报工具，负责处理事故的完整生命周期。
- en: In this section, we looked at why we need monitoring for a DL endpoint and provided
    a list of tools available. In the remaining sections of this chapter, we will
    look in detail at CloudWatch, the most common monitoring tool, as it is integrated
    well into most services within AWS (for example, SageMaker).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们讨论了为什么需要对DL端点进行监控，并提供了可用工具的列表。在本章的其余部分，我们将详细研究CloudWatch，这是最常见的监控工具，因为它与AWS中的大多数服务都很好地集成（例如SageMaker）。
- en: Monitoring using CloudWatch
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用CloudWatch进行监控
- en: 'First, we will introduce a few key concepts in CloudWatch: logs, metrics, alarms,
    and dashboards. **CloudWatch** persists ingested data in the form of logs or metrics
    organized by timestamps. As the name suggests, *logs* refer to text data emitted
    throughout the lifetime of a program. On the other hand, *metrics* represent organized
    numeric data such as CPU or memory utilization. Since metrics are stored in an
    organized matter, CloudWatch supports aggregating metrics and creating histograms
    from collected data. An *alarm* can be set up to alert if unusual changes are
    reported for the target metric. Also, a *dashboard* can be set up to get an intuitive
    view of selected metrics and raised alarms.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将介绍 CloudWatch 中的几个关键概念：日志、指标、报警和仪表板。**CloudWatch** 将摄入的数据以日志或按时间戳组织的指标形式持久化。如其名称所示，*日志*
    指的是程序生命周期中发出的文本数据。另一方面，*指标* 表示组织的数值数据，如 CPU 或内存利用率。由于指标以有组织的方式存储，CloudWatch 支持从收集的数据中聚合指标并创建直方图。*报警*
    可以设置为在目标指标报告异常变化时发出警报。此外，可以设置*仪表板*来直观地查看所选指标和已触发的报警。
- en: 'In the following example, we will describe how to log metric data using a CloudWatch
    service client from the `boto3` library. The metric data is structured as a dictionary
    and consists of metric names, dimensions, and values. The idea of dimensions is
    to capture factual information about the metric. For example, a metric name city
    can have a value of New York City. Then, dimensions can capture specific information
    such as hourly counts of fire accidents or burglaries:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下示例中，我们将描述如何使用 `boto3` 库中的 CloudWatch 服务客户端记录指标数据。指标数据结构化为字典，包含指标名称、维度和值。维度的概念是捕获有关指标的事实信息。例如，指标名称为
    city 可以具有纽约市的值。然后，维度可以捕获特定信息，例如火灾或入室盗窃的每小时计数：
- en: '[PRE0]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'In the preceding code snippet, we first create a `cloudwatch` service client
    for CloudWatch using the `boto3.client` function. This instance will allow us
    to communicate with CloudWatch from a Python environment. The key method for logging
    a set of data is `put_metric_data`. This function `put_metric_data` method from
    the CloudWatch client instance takes in `MetricData` (the target metric data to
    ingest into CloudWatch: `data_metrics`) and `Namespace` (container for the metric
    data: ''`ECOMMERCE/Revenue`''). Data from different namespaces is managed separately
    to support efficient aggregation.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码片段中，我们首先使用 `boto3.client` 函数为 CloudWatch 创建一个 `cloudwatch` 服务客户端实例。这个实例将允许我们从
    Python 环境与 CloudWatch 进行通信。记录数据的关键方法是 `put_metric_data`。这个函数的 `put_metric_data`
    方法从 CloudWatch 客户端实例接收 `MetricData`（要摄入到 CloudWatch 中的目标指标数据：`data_metrics`）和
    `Namespace`（容器，用于容纳指标数据：`ECOMMERCE/Revenue`）。不同命名空间的数据被单独管理，以支持高效的聚合。
- en: In this example, the `data_metrics` metric data contains a field `MetricName`
    of `gross_merchandise_value` with the value of `900000.0`. The unit for `gross_merchandise_value`
    is defined as `None`. Additionally, we are providing the number of goods sold
    (`num_goods_sold`) as additional dimension information.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，`data_metrics` 指标数据包含一个名为 `MetricName` 的字段，其值为 `gross_merchandise_value`，值为
    `900000.0`。`gross_merchandise_value` 的单位被定义为 `None`。此外，我们还提供了销售商品数 (`num_goods_sold`)
    作为额外的维度信息。
- en: For a complete description [of CloudWatch concepts, please refer to https://docs.aws.amazon.com/AmazonCloudWatch/la](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/cloudwatch_concepts.html)test/monitoring/cloudwatch_concepts.html.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 要获取完整的 CloudWatch 概念说明，请参阅 [https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/cloudwatch_concepts.html](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/cloudwatch_concepts.html)。
- en: Things to remember
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 需要记住的事情
- en: a. CloudWatch persists ingested data in the form of logs or metrics organized
    by timestamps. It supports setting up an alarm for unusual changes and provides
    effective visualization through dashboards.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: a. CloudWatch 将摄入的数据以日志或按时间戳组织的指标形式持久化。它支持为异常变化设置报警，并通过仪表板提供有效的可视化。
- en: b. Logging a metric to CloudWatch can be easily achieved using the `boto3` library.
    It provides a service client for CloudWatch that supports logging through the
    `put_metric_data` function.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: b. 使用 `boto3` 库可以轻松地将一个指标记录到 CloudWatch。它提供了一个支持通过 `put_metric_data` 函数进行日志记录的
    CloudWatch 服务客户端。
- en: While logging for CloudWatch can be done explicitly as described in this section,
    SageMaker provides built-in logging features for some of the out-of-the-box metrics.
    Let’s take a closer look at them.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管云观察的日志可以像本节描述的那样明确地记录，但 SageMaker 为一些开箱即用的指标提供了内置的日志记录功能。让我们仔细看看它们。
- en: Monitoring a SageMaker endpoint using CloudWatch
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 CloudWatch 监视 SageMaker 端点
- en: 'Being an end-to-end service for **machine learning**, SageMaker is one of the
    main tools that we use to implement various steps of a DL project. In this section,
    we will describe the last missing piece: monitoring an endpoint created with SageMaker.
    First, we will explain how you can set up CloudWatch-based monitoring for training
    where metrics are reported in batches offline. Next, we will discuss how to monitor
    a live endpoint.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 作为**机器学习**的端到端服务，SageMaker 是我们实施 DL 项目各个步骤的主要工具之一。在本节中，我们将描述最后一个缺失的部分：监控使用 SageMaker
    创建的端点。首先，我们将解释如何设置基于 CloudWatch 的训练监控，其中指标以离线批次报告。接下来，我们将讨论如何监控实时端点。
- en: 'The code snippets in this section are designed to run on SageMaker Studio.
    Therefore, we first need to define an AWS **Identity and Access Management** (**IAM**)
    role and a session object. Let’s have a look at the first code snippet:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 本节中的代码片段设计用于在 SageMaker Studio 上运行。因此，我们首先需要定义 AWS **Identity and Access Management**
    (**IAM**) 角色和一个会话对象。让我们看看第一个代码片段：
- en: '[PRE1]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: In the preceding code snippet, the `get_execution_role` function provides the
    IAM role for the notebook. `role_exec`. `sagemaker.session` provides a SageMaker
    `sag_sess` SageMaker session object required for the job configuration.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码片段中，`get_execution_role` 函数提供笔记本的 IAM 角色。`role_exec`。`sagemaker.session`
    提供了 SageMaker `sag_sess` SageMaker 会话对象，用于作业配置。
- en: Monitoring a model throughout the training process in SageMaker
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 SageMaker 中监控模型的整个训练过程
- en: 'The logging during model training involves SageMaker’s `Estimator` class. It
    can process printed messages using `regex` expressions and store them as metrics.
    You can see an example here:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型训练期间的日志记录涉及 SageMaker 的 `Estimator` 类。它可以使用 `regex` 表达式处理打印的消息，并将它们存储为指标。您可以在此处看到一个例子：
- en: '[PRE2]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: In the preceding code snippet, we create `estimator`, which is an `Estimator`
    instance for training. Explanations for most of the parameters can be found in
    [*Chapter 6*](B18522_06.xhtml#_idTextAnchor133), *Efficient Model Training*. The
    additional parameter we are defining in this example is `metric_definitions`.
    We are passing in `reg_pattern_metrics`, which defines a set of `Train_error=(.*?)`
    and `Valid_error=(.*?)`, training and evaluation logs. Texts that match the given
    patterns will be persisted as metrics in CloudWatch. For the complete details
    of offline metrics recording throughout model training using the `Estimator` class,
    please refer to [https://docs.aws.amazon.com/sagemaker/latest/dg/training-metrics.html](https://docs.aws.amazon.com/sagemaker/latest/dg/training-metrics.html).
    We want to mention that specific training job metrics (such as memory, CPU, **graphics
    processing unit** (**GPU**), and disk utilization) are automatically logged, and
    you can monitor them either through CloudWatch or SageMaker console.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码片段中，我们创建了 `estimator`，这是用于训练的 `Estimator` 实例。大多数参数的解释可以在 [*第 6 章*](B18522_06.xhtml#_idTextAnchor133)，*高效模型训练*
    中找到。在此示例中，我们正在定义的附加参数是 `metric_definitions`。我们传递的是 `reg_pattern_metrics`，它定义了一组
    `Train_error=(.*?)` 和 `Valid_error=(.*?)`，训练和评估日志。匹配给定模式的文本将作为指标持久保存在 CloudWatch
    中。有关使用 `Estimator` 类在整个模型训练过程中进行离线指标记录的完整详情，请参阅 [https://docs.aws.amazon.com/sagemaker/latest/dg/training-metrics.html](https://docs.aws.amazon.com/sagemaker/latest/dg/training-metrics.html)。我们想要提到的是，特定的训练作业指标（如内存、CPU、**图形处理单元**
    (**GPU**) 和磁盘利用率）会自动记录，并且您可以通过 CloudWatch 或 SageMaker 控制台监视它们。
- en: Monitoring a live inference endpoint from SageMaker
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 监控来自 SageMaker 的实时推断端点
- en: 'In this section, we will describe SageMaker’s CloudWatch-based monitoring feature
    for an endpoint. In the following code snippet, we are presenting a sample `inference.py`
    script with an `output_handler` function. This file is assigned for an `entry_point`
    parameter of SageMaker’s `Model` or `Estimator` class to define additional pre-
    and postprocessing logic. Details of `inference.py` can be found in [*Chapter
    9*](B18522_09.xhtml#_idTextAnchor187), *Scaling a Deep Learning Pipeline*. The
    `output_handler` function is designed to process model predictions and log metric
    data using the `print` function. The printed messages get stored as logs in CloudWatch:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将描述 SageMaker 的端点基于 CloudWatch 的监控功能。在下面的代码片段中，我们呈现了一个带有 `output_handler`
    函数的样本 `inference.py` 脚本。该文件被分配为 SageMaker 的 `Model` 或 `Estimator` 类的 `entry_point`
    参数，以定义额外的预处理和后处理逻辑。有关 `inference.py` 的详细信息，请参阅 [*第 9 章*](B18522_09.xhtml#_idTextAnchor187)，*扩展深度学习管道*。`output_handler`
    函数设计用于处理模型预测并使用 `print` 函数记录度量数据。打印的消息作为日志存储在 CloudWatch 中：
- en: '[PRE3]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: In the preceding inference code, we first get a model prediction (`results`)
    and construct a dictionary for metric data (`data_metrics`). The dictionary already
    has a `MetricName` value of `model_name` and a dimension named `classify`. The
    model prediction will be specified for the `classify` dimension. SageMaker will
    collect printed metric data and ingest it to CloudWatch. A sample approach to
    continuous model m[onitoring for quality drift is described online at https://sagemaker-examples.readthedocs.io/en/latest/sagemaker_model](https://sagemaker-examples.readthedocs.io/en/latest/sagemaker_model_monitor/model_quality/model_quality_churn_sdk.html)_monitor/model_quality/model_quality_churn_sdk.html.
    This page nicely explains how you can leverage CloudWatch in such scenarios.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的推断代码中，我们首先获得模型预测（`results`），并为度量数据构建一个字典（`data_metrics`）。该字典已经具有`MetricName`
    值为 `model_name` 和名为 `classify` 的维度。模型预测将被指定为 `classify` 维度。SageMaker 将收集打印的度量数据并将其输入到
    CloudWatch。有关在这种场景下连续模型质量漂移监控的示例方法，请参阅在线说明 [https://sagemaker-examples.readthedocs.io/en/latest/sagemaker_model](https://sagemaker-examples.readthedocs.io/en/latest/sagemaker_model_monitor/model_quality/model_quality_churn_sdk.html)_monitor/model_quality/model_quality_churn_sdk.html。这页详细解释了如何在这些情况下利用
    CloudWatch。
- en: Things to remember
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 需记住的事项
- en: a. The `Estimator` class from SageMaker provides built-in support for CloudWatch-based
    monitoring during training. You need to pass a set of regex patterns to the `metric_definitions`
    parameter when constructing an instance.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: a. SageMaker 的 `Estimator` 类在训练期间提供了对基于 CloudWatch 的监控的内置支持。在构造实例时，您需要将一组正则表达式模式传递给
    `metric_definitions` 参数。
- en: b. Printed messages from a SageMaker endpoint get stored as CloudWatch logs.
    Therefore, we can achieve monitoring by logging metric data through an `entry_point`
    script.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: b. SageMaker 端点的打印消息将存储为 CloudWatch 日志。因此，我们可以通过记录度量数据的 `entry_point` 脚本来实现监控。
- en: In this section, we explained how SageMaker supports CloudWatch-based monitoring.
    Let’s look at how EKS supports monitoring for inference endpoints.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们解释了 SageMaker 如何支持基于 CloudWatch 的监控。让我们看看 EKS 如何支持推断端点的监控。
- en: Monitoring an EKS endpoint using CloudWatch
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 CloudWatch 监控 EKS 端点
- en: Along with SageMaker, we have described EKS-based endpoints in [*Chapter 9*](B18522_09.xhtml#_idTextAnchor187),
    *Scaling a Deep Learning Pipeline*. In this section, we describe CloudWatch-based
    monitoring available for EKS. First, we will learn how EKS metrics from the container
    can be logged for monitoring. Next, we will explain how to log model-related metrics
    from an EKS inference endpoint.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 除了 SageMaker 外，我们还在《*第 9 章*》中描述了基于 EKS 的端点，在*扩展深度学习流水线*中。在本节中，我们描述了 EKS 可用的基于
    CloudWatch 的监控。首先，我们将学习如何从容器中记录 EKS 指标以进行监控。接下来，我们将解释如何从 EKS 推断端点记录与模型相关的度量数据。
- en: Let’s first look at how to set up CloudWatch for monitoring an EKS cluster.
    The simplest approach is to install a CloudWatch agent in the container. Additionally,
    you can install **Fluent Bit**, an open [source tool tha](http://www.fluentbit.io)t
    further enhances the logging process ([www.fluentbit.io](http://www.fluentbit.io)).
    For a complete explanation of CloudWatch agents and Fluent Bit, please read [https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/Container-Insights-setup-EKS-quickstart.html](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/Container-Insights-setup-EKS-quickstart.html).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先看看如何设置 CloudWatch 来监控 EKS 集群。最简单的方法是在容器中安装 CloudWatch 代理。此外，您还可以安装 **Fluent
    Bit**，这是一个开源工具，进一步增强了日志记录过程（[www.fluentbit.io](http://www.fluentbit.io)）。有关 CloudWatch
    代理和 Fluent Bit 的完整说明，请阅读 [https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/Container-Insights-setup-EKS-quickstart.html](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/Container-Insights-setup-EKS-quickstart.html)。
- en: Another option is to persist the default metrics sent by the EKS control plane.
    This can be easily enabled from the EKS web console ([https://docs.aws.amazon.com/eks/latest/userguide/control-plane-logs.html](https://docs.aws.amazon.com/eks/latest/userguide/control-plane-logs.html)).
    The complete list of metrics emitted from the EKS control plane can be found at
    [https://aws.github.io/aws-eks-best-practices/reliability/docs/controlplane](https://aws.github.io/aws-eks-best-practices/reliability/docs/controlplane/).
    For example, if you are interested in logging latency-related metrics, you can
    use `apiserver_request_duration_seconds*`.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个选项是保留由EKS控制平面发送的默认指标。这可以通过EKS Web控制台轻松启用（[https://docs.aws.amazon.com/eks/latest/userguide/control-plane-logs.html](https://docs.aws.amazon.com/eks/latest/userguide/control-plane-logs.html)）。可以在[https://aws.github.io/aws-eks-best-practices/reliability/docs/controlplane](https://aws.github.io/aws-eks-best-practices/reliability/docs/controlplane/)找到EKS控制平面发出的完整指标列表。例如，如果您对记录与延迟相关的指标感兴趣，可以使用`apiserver_request_duration_seconds*`。
- en: To log model-related metrics during model inference, you need to instantiate
    `boto3`’s CloudWatch service client within the code and log them explicitly. The
    code snippet included in the previous section, *Monitoring a SageMaker endpoint
    using CloudWatch*, should be a good starting point.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型推断期间记录模型相关的指标，您需要在代码中实例化`boto3`的CloudWatch服务客户端，并显式记录它们。前一节中包含的代码片段，*使用CloudWatch监视SageMaker端点*，应该是一个很好的起点。
- en: Things to remember
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 记住的事情
- en: a. Logging endpoint-related metrics from an EKS cluster can be achieved by using
    a CloudWatch agent or persisting default metrics sent by the EKS control plane.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: a. 从一个EKS集群记录端点相关的指标可以通过使用CloudWatch代理或保留由EKS控制平面发送的默认指标来实现。
- en: b. Model-related metrics need to be logged explicitly using the `boto3` library.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: b. 使用`boto3`库需要显式记录与模型相关的指标。
- en: As the last topic of this section, we explained how to log various metrics to
    CloudWatch from an EKS cluster.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 作为本节的最后一个主题，我们解释了如何从EKS集群将各种指标记录到CloudWatch。
- en: Summary
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Our goal in this chapter was to explain why you need to monitor an endpoint
    running a DL model and to introduce popular tools in this domain. The tools we
    introduced in this chapter are designed for monitoring a set of information from
    an endpoint and alerting an incident when there are sudden changes to the monitored
    metrics. The tools that we covered are CloudWatch, Prometheus, Grafana, Datadog,
    SageMaker Clarify, PagerDuty, and Dynatrace. For completeness, we looked at how
    CloudWatch can be integrated into SageMaker and EKS for monitoring an endpoint
    as well as model performance.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的目标是解释为什么需要监视运行DL模型的端点，并介绍该领域中的流行工具。我们在本章介绍的工具旨在监控端点的信息集并在监控指标发生突变时提供警报。我们涵盖的工具包括CloudWatch、Prometheus、Grafana、Datadog、SageMaker
    Clarify、PagerDuty和Dynatrace。为了完整起见，我们还介绍了如何将CloudWatch集成到SageMaker和EKS中，以监视端点及模型性能。
- en: In the next chapter, as the last chapter of this book, we will explore the process
    of evaluating a completed project and discussing potential improvements.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，作为本书的最后一章，我们将探讨评估已完成项目的过程并讨论潜在的改进。
