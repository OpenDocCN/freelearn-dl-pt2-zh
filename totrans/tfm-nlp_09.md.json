["```py\n#@title Pre-Requisistes\n!pip install gensim==3.8.3\nimport nltk\nnltk.download('punkt')\nimport math\nimport numpy as np\nfrom nltk.tokenize import sent_tokenize, word_tokenize \nimport gensim \nfrom gensim.models import Word2Vec \nimport numpy as np\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport matplotlib.pyplot as plt\nimport warnings \nwarnings.filterwarnings(action = 'ignore') \n```", "```py\n#@title Word2Vec Tokenization\n#'text.txt' file\nsample = open(\"text.txt\", \"r\")\ns = sample.read()\n# processing escape characters\nf = s.replace(\"\\n\", \" \")\ndata = []\n# sentence parsing\nfor i in sent_tokenize(f):\n  temp = [] \n  # tokenize the sentence into words\n  for j in word_tokenize(i):\n    temp.append(j.lower())\n  data.append(temp)\n# Creating Skip Gram model\nmodel2 = gensim.models.Word2Vec(data, min_count = 1, size = 512,window = 5, sg = 1)\nprint(model2) \n```", "```py\nWord2Vec(vocab=10816, size=512, alpha=0.025) \n```", "```py\n#@title Cosine Similarity\ndef similarity(word1,word2):\n        cosine=False #default value\n        try:\n                a=model2[word1]\n                cosine=True\n        except KeyError:     #The KeyError exception is raised\n                print(word1, \":[unk] key not found in dictionary\")#False implied\n        try:\n                b=model2[word2]#a=True implied\n        except KeyError:       #The KeyError exception is raised\n                cosine=False   #both a and b must be true\n                print(word2, \":[unk] key not found in dictionary\") \n```", "```py\n if(cosine==True):\n                b=model2[word2]\n                # compute cosine similarity\n                dot = np.dot(a, b)\n                norma = np.linalg.norm(a)\n                normb = np.linalg.norm(b)\n                cos = dot / (norma * normb)\n                aa = a.reshape(1,512)\n                ba = b.reshape(1,512)\n                #print(\"Word1\",aa)\n                #print(\"Word2\",ba)\n                cos_lib = cosine_similarity(aa, ba)\n                #print(cos_lib,\"word similarity\")\n\n        if(cosine==False):cos_lib=0;\n        return cos_lib \n```", "```py\n#@title Case 0: Words in text and dictionary\nword1=\"freedom\";word2=\"liberty\"\nprint(\"Similarity\",similarity(word1,word2),word1,word2) \n```", "```py\nSimilarity [[0.79085565]] freedom liberty \n```", "```py\nRun 1: Similarity [[0.62018466]] freedom liberty\nRun 2: Similarity [[0.62018466]] freedom liberty\n...\nRun 10: Similarity [[0.62018466]] freedom liberty \n```", "```py\nRun 1: Similarity [[0.51549244]] freedom liberty\nRun 2: Similarity [[0.51549244]] freedom liberty\n...\nRun 10: Similarity [[0.51549244]] freedom liberty \n```", "```py\nRun 1: Similarity [[0.58365834]] freedom liberty\nRun 2: Similarity [[0.58365834]] freedom liberty\n...\nRun 10: Similarity [[0.58365834]] freedom liberty \n```", "```py\n#@title Word(s) Case 1: Word not in text or dictionary\nword1=\"corporations\";word2=\"rights\"\nprint(\"Similarity\",similarity(word1,word2),word1,word2) \n```", "```py\ncorporations :[unk] key not found in dictionary\nSimilarity 0 corporations rights \n```", "```py\n#@title Case 2: Noisy Relationship\nword1=\"etext\";word2=\"declaration\"\nprint(\"Similarity\",similarity(word1,word2),word1,word2) \n```", "```py\nSimilarity [[0.880751]] etext declaration \n```", "```py\n#@title Case 3: word in text, not in dictionary\nword1=\"pie\";word2=\"logic\"\nprint(\"Similarity\",similarity(word1,word2),word1,word2) \n```", "```py\npie :[unk] key not found in dictionary\nSimilarity 0 pie logic \n```", "```py\n#@title Case 4: Rare words\nword1=\"justiciar\";word2=\"judgement\"\nprint(\"Similarity\",similarity(word1,word2),word1,word2) \n```", "```py\nSimilarity [[0.6606605]] justiciar judgement \n```", "```py\n(39) No free man shall be seized or imprisoned, or stripped of his\nrights or possessions, or outlawed or exiled, or deprived of his\nstanding in any other way, nor will we proceed with force against him,\nor send others to do so, except by the lawful judgement of his equals\nor by the law of the land.\n(40) To no one will we sell, to no one deny or delay right or justice. \n```", "```py\n#@title Case 5: Replacing rare words\nword1=\"judge\";word2=\"judgement\"\nprint(\"Similarity\",similarity(word1,word2),word1,word2) \n```", "```py\nSimilarity [[0.7962761]] judge judgement \n```", "```py\nword1=\"justiciar\";word2=\"judge\"\nprint(\"Similarity\",similarity(word1,word2),word1,word2) \n```", "```py\nSimilarity [[0.9659128]] justiciar judge \n```", "```py\n#@title Case 6: Entailment\nword1=\"pay\";word2=\"debt\"\nprint(\"Similarity\",similarity(word1,word2),word1,word2) \n```", "```py\nSimilarity [[0.89891946]] pay debt \n```", "```py\n#@title Step 11: Generating Unconditional Samples\nimport os # import after runtime is restarted\nos.chdir(\"/content/gpt-2/src\")\n!python generate_unconditional_samples.py --model_name '117M' \n```", "```py\ncommunity-based machinery facilitates biofilm growth. Community members place biochemistry as the main discovery tool to how the cell interacts with the environment and thus with themselves, while identifying and understanding all components for effective Mimicry.\n2\\. Ol Perception\nCytic double-truncation in phase changing (IP) polymerases (sometimes called \"tcrecs\") represents a characteristic pattern of double-crossing enzymes that alter the fundamental configuration that allows initiation and maintenance of process while chopping the plainNA with vibrational operator. Soon after radical modification that occurred during translational parasubstitution (TMT) achieved a more or less uncontrolled activation of SYX. TRSI mutations introduced autophosphorylation of TCMase sps being the most important one that was incorporated into cellular double-triad (DTT) signaling across all\ncells, by which we allow R h and ofcourse an IC 2A- >\n.../... \n```", "```py\n#@title Step 12: Interactive Context and Completion Examples\nimport os # import after runtime is restarted\nos.chdir(\"/content/gpt-2/src\")\n!python interactive_conditional_samples.py --temperature 0.8 --top_k 40 --model_name '117M' --length 50 \n```", "```py\nDuring such processes, cells sense the environment and respond to external factors that induce a certain direction of motion towards specific targets (taxis): this results in a persistent migration in a certain preferential direction. The guidance cues leading to directed migration may be biochemical or biophysical. Biochemical cues can be, for example, soluble factors or growth factors that give rise to chemotaxis, which involves a mono-directional stimulus. Other cues generating mono-directional stimuli include, for instance, bound ligands to the substratum that induce haptotaxis, durotaxis, that involves migration towards regions with an increasing stiffness of the ECM, electrotaxis, also known as galvanotaxis, that prescribes a directed motion guided by an electric field or current, or phototaxis, referring to the movement oriented by a stimulus of light [34]. Important biophysical cues are some of the properties of the extracellular matrix (ECM), first among all the alignment of collagen fibers and its stiffness. In particular, the fiber alignment is shown to stimulate contact guidance [22, 21]. TL;DR: \n```", "```py\nthe ECM of a single tissue is the ECM that is the most effective.\nTo address this concern, we developed a novel imaging and immunostaining scheme that, when activated, induces the conversion of a protein to its exogenous target \n```", "```py\nDo not allow the movement to be directed by a laser (i.e. a laser that only takes one pulse at a time), but rather a laser that is directed at a target and directed at a given direction. In a nutshell, be mindful. \n```", "```py\n#@title Additional Tools : Controlling Tokenized Data\n#Unzip out.npz\nimport zipfile\nwith zipfile.ZipFile('/content/gpt-2/src/out.npz', 'r') as zip_ref:\n    zip_ref.extractall('/content/gpt-2/src/') \n```", "```py\n#Load arr_0.npy which contains encoded dset\nimport numpy as np\nf=np.load('/content/gpt-2/src/arr_0.npy')\nprint(f)\nprint(f.shape)\nfor i in range(0,10):\n    print(f[i]) \n```", "```py\n[1212 5644  326 ...   13  198 2682] \n```", "```py\n#We first import encoder.json\nimport json\ni=0\nwith open(\"/content/gpt-2/models/117M/encoder.json\", \"r\") as read_file:\n    print(\"Converting the JSON encoded data into a Python dictionary\")\n    developer = json.load(read_file) #converts the encoded data into a Python dictionary\n    for key, value in developer.items(): #we parse the decoded json data\n        i+=1\n        if(i>10):\n            break;\n        print(key, \":\", value) \n```", "```py\n#We will now search for the key and value for each encoded token\n    for i in range(0,500):\n        for key, value in developer.items():\n            if f[i]==value:\n                print(key, \":\", value) \n```", "```py\nThis suggests that \n```", "```py\nThis : 1212\nĠsuggests : 5644\nĠthat : 326 \n```", "```py\namoeboid \n```", "```py\nĠam : 716\no : 78\neb : 1765\noid : 1868 \n```", "```py\namoeboid and mesenchymal \n```", "```py\nĠam : 716\no : 78\neb : 1765\noid : 1868\nĠand : 290\nĠmes : 18842\nench : 24421\nym : 4948\nal : 282 \n```", "```py\nA: Amoeboid is a noun which means \"resembling an amoeba\" \n```", "```py\nQ: Is amoeboid a noun or an adjective?\nA: Amoeboid is a noun. \n```", "```py\nQ: What does amoeboid mean in medical terms? \nA: Amoeboid means \"resembling an amoeba\". \n```"]