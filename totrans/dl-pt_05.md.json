["```py\ntransformation = \n  transforms.Compose([transforms.ToTensor(),\n  transforms.Normalize((0.1307,), (0.3081,))])\n\ntrain_dataset = \n  datasets.MNIST('data/',train=True,transform=transformation,\n    download=True)\ntest_dataset =  \n  datasets.MNIST('data/',train=False,transform=transformation,\n    download=True)\n\ntrain_loader =   \n  torch.utils.data.DataLoader(train_dataset,batch_size=32,shuffle=True)\ntest_loader =  \n  torch.utils.data.DataLoader(test_dataset,batch_size=32,shuffle=True)\n```", "```py\ndef plot_img(image):\n    image = image.numpy()[0]\n    mean = 0.1307\n    std = 0.3081\n    image = ((mean * image) + std)\n    plt.imshow(image,cmap='gray')\n```", "```py\nsample_data = next(iter(train_loader))\nplot_img(sample_data[0][1])\nplot_img(sample_data[0][2])\n```", "```py\nclass Net(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n        self.conv2_drop = nn.Dropout2d()\n        self.fc1 = nn.Linear(320, 50)\n        self.fc2 = nn.Linear(50, 10)\n\n    def forward(self, x):\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n        x = x.view(-1, 320)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, training=self.training)\n        x = self.fc2(x)\n        return F.log_softmax(x)\n```", "```py\nconv = nn.Conv1d(1,1,3,bias=False)\nsample = torch.randn(1,1,7)\nconv(Variable(sample))\n\n#Check the weights of our convolution filter by \nconv.weight\n```", "```py\nx.view(-1, 320)\n```", "```py\ndef fit(epoch,model,data_loader,phase='training',volatile=False):\n    if phase == 'training':\n        model.train()\n    if phase == 'validation':\n        model.eval()\n        volatile=True\n    running_loss = 0.0\n    running_correct = 0\n    for batch_idx , (data,target) in enumerate(data_loader):\n        if is_cuda:\n            data,target = data.cuda(),target.cuda()\n        data , target = Variable(data,volatile),Variable(target)\n        if phase == 'training':\n            optimizer.zero_grad()\n        output = model(data)\n        loss = F.nll_loss(output,target)\n\n        running_loss += F.nll_loss(output,target,size_average=False).data[0]\n        preds = output.data.max(dim=1,keepdim=True)[1]\n        running_correct += preds.eq(target.data.view_as(preds)).cpu().sum()\n        if phase == 'training':\n            loss.backward()\n            optimizer.step()\n\n    loss = running_loss/len(data_loader.dataset)\n    accuracy = 100\\. * running_correct/len(data_loader.dataset)\n\n    print(f'{phase} loss is {loss:{5}.{2}} and {phase} accuracy is {running_correct}/{len(data_loader.dataset)}{accuracy:{10}.{4}}')\n    return loss,accuracy\n```", "```py\nmodel = Net()\nif is_cuda:\n    model.cuda()\n\noptimizer = optim.SGD(model.parameters(),lr=0.01,momentum=0.5)\ntrain_losses , train_accuracy = [],[]\nval_losses , val_accuracy = [],[]\nfor epoch in range(1,20):\n    epoch_loss, epoch_accuracy = fit(epoch,model,train_loader,phase='training')\n    val_epoch_loss , val_epoch_accuracy = fit(epoch,model,test_loader,phase='validation')\n    train_losses.append(epoch_loss)\n    train_accuracy.append(epoch_accuracy)\n    val_losses.append(val_epoch_loss)\n    val_accuracy.append(val_epoch_accuracy)\n```", "```py\nplt.plot(range(1,len(train_losses)+1),train_losses,'bo',label = 'training loss')\nplt.plot(range(1,len(val_losses)+1),val_losses,'r',label = 'validation loss')\nplt.legend()\n```", "```py\nplt.plot(range(1,len(train_accuracy)+1),train_accuracy,'bo',label = 'train accuracy')\nplt.plot(range(1,len(val_accuracy)+1),val_accuracy,'r',label = 'val accuracy')\nplt.legend()\n```", "```py\nclass Net(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(3, 10, kernel_size=5)\n        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n        self.conv2_drop = nn.Dropout2d()\n        self.fc1 = nn.Linear(56180, 500)\n        self.fc2 = nn.Linear(500,50)\n        self.fc3 = nn.Linear(50, 2)\n\n    def forward(self, x):\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n        x = x.view(x.size(0),-1)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, training=self.training)\n        x = F.relu(self.fc2(x))\n        x = F.dropout(x,training=self.training)\n        x = self.fc3(x)\n        return F.log_softmax(x,dim=1)\n```", "```py\nfrom torchvision import models\nvgg = models.vgg16(pretrained=True)\n```", "```py\nVGG (\n  (features): Sequential (\n    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU (inplace)\n    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (3): ReLU (inplace)\n    (4): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (6): ReLU (inplace)\n    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (8): ReLU (inplace)\n    (9): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (11): ReLU (inplace)\n    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (13): ReLU (inplace)\n    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (15): ReLU (inplace)\n    (16): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (18): ReLU (inplace)\n    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (20): ReLU (inplace)\n    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (22): ReLU (inplace)\n    (23): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (25): ReLU (inplace)\n    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (27): ReLU (inplace)\n    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (29): ReLU (inplace)\n    (30): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n  )\n  (classifier): Sequential (\n    (0): Linear (25088 -> 4096)\n    (1): ReLU (inplace)\n    (2): Dropout (p = 0.5)\n    (3): Linear (4096 -> 4096)\n    (4): ReLU (inplace)\n    (5): Dropout (p = 0.5)\n    (6): Linear (4096 -> 1000)\n  )\n)\n```", "```py\nfor param in vgg.features.parameters(): param.requires_grad = False\n```", "```py\nvgg.classifier[6].out_features = 2\n```", "```py\noptimizer = \n  optim.SGD(vgg.classifier.parameters(),lr=0.0001,momentum=0.5)\n```", "```py\ntrain_losses , train_accuracy = [],[]\nval_losses , val_accuracy = [],[]\nfor epoch in range(1,20):\n    epoch_loss, epoch_accuracy = fit(epoch,vgg,train_data_loader,phase='training')\n    val_epoch_loss , val_epoch_accuracy = fit(epoch,vgg,valid_data_loader,phase='validation')\n    train_losses.append(epoch_loss)\n    train_accuracy.append(epoch_accuracy)\n    val_losses.append(val_epoch_loss)\n    val_accuracy.append(val_epoch_accuracy)\n```", "```py\nfor layer in vgg.classifier.children():\n    if(type(layer) == nn.Dropout):\n        layer.p = 0.2\n\n#Training\ntrain_losses , train_accuracy = [],[]\nval_losses , val_accuracy = [],[]\nfor epoch in range(1,3):\n    epoch_loss, epoch_accuracy = fit(epoch,vgg,train_data_loader,phase='training')\n    val_epoch_loss , val_epoch_accuracy = fit(epoch,vgg,valid_data_loader,phase='validation')\n    train_losses.append(epoch_loss)\n    train_accuracy.append(epoch_accuracy)\n    val_losses.append(val_epoch_loss)\n    val_accuracy.append(val_epoch_accuracy)\n```", "```py\ntrain_transform =transforms.Compose([transforms.Resize((224,224)),\n                                     transforms.RandomHorizontalFlip(),\n                                     transforms.RandomRotation(0.2),\n                                     transforms.ToTensor(),\n                                     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n                                      ])\n\ntrain = ImageFolder('dogsandcats/train/',train_transform)\nvalid = ImageFolder('dogsandcats/valid/',simple_transform)\n\n#Training \n\ntrain_losses , train_accuracy = [],[]\nval_losses , val_accuracy = [],[]\nfor epoch in range(1,3):\n    epoch_loss, epoch_accuracy = fit(epoch,vgg,train_data_loader,phase='training')\n    val_epoch_loss , val_epoch_accuracy = fit(epoch,vgg,valid_data_loader,phase='validation')\n    train_losses.append(epoch_loss)\n    train_accuracy.append(epoch_accuracy)\n    val_losses.append(val_epoch_loss)\n    val_accuracy.append(val_epoch_accuracy)\n```", "```py\n#Results\n\ntraining loss is 0.041 and training accuracy is 22657/23000 98.51 validation loss is 0.043 and validation accuracy is 1969/2000 98.45 training loss is 0.04 and training accuracy is 22697/23000 98.68 validation loss is 0.043 and validation accuracy is 1970/2000 98.5\n```", "```py\nvgg = models.vgg16(pretrained=True)\nvgg = vgg.cuda()\nfeatures = vgg.features\n\ntrain_data_loader = torch.utils.data.DataLoader(train,batch_size=32,num_workers=3,shuffle=False)\nvalid_data_loader = torch.utils.data.DataLoader(valid,batch_size=32,num_workers=3,shuffle=False)\n\ndef preconvfeat(dataset,model):\n    conv_features = []\n    labels_list = []\n    for data in dataset:\n        inputs,labels = data\n        if is_cuda:\n            inputs , labels = inputs.cuda(),labels.cuda() \n        inputs , labels = Variable(inputs),Variable(labels)\n        output = model(inputs)\n        conv_features.extend(output.data.cpu().numpy())\n        labels_list.extend(labels.data.cpu().numpy())\n    conv_features = np.concatenate([[feat] for feat in conv_features])\n\n    return (conv_features,labels_list)\n\nconv_feat_train,labels_train = preconvfeat(train_data_loader,features)\nconv_feat_val,labels_val = preconvfeat(valid_data_loader,features)\n```", "```py\nclass My_dataset(Dataset):\n    def __init__(self,feat,labels):\n        self.conv_feat = feat\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.conv_feat)\n\n    def __getitem__(self,idx):\n        return self.conv_feat[idx],self.labels[idx]\n\ntrain_feat_dataset = My_dataset(conv_feat_train,labels_train)\nval_feat_dataset = My_dataset(conv_feat_val,labels_val)\n\ntrain_feat_loader = \n  DataLoader(train_feat_dataset,batch_size=64,shuffle=True)\nval_feat_loader = \n  DataLoader(val_feat_dataset,batch_size=64,shuffle=True)\n```", "```py\ntrain_losses , train_accuracy = [],[]\nval_losses , val_accuracy = [],[]\nfor epoch in range(1,20):\n    epoch_loss, epoch_accuracy = fit_numpy(epoch,vgg.classifier,train_feat_loader,phase='training')\n    val_epoch_loss , val_epoch_accuracy = fit_numpy(epoch,vgg.classifier,val_feat_loader,phase='validation')\n    train_losses.append(epoch_loss)\n    train_accuracy.append(epoch_accuracy)\n    val_losses.append(val_epoch_loss)\n    val_accuracy.append(val_epoch_accuracy)\n```", "```py\nvgg = models.vgg16(pretrained=True).cuda()\n\nclass LayerActivations():\n    features=None\n\n    def __init__(self,model,layer_num):\n        self.hook = model[layer_num].register_forward_hook(self.hook_fn)\n\n    def hook_fn(self,module,input,output):\n        self.features = output.cpu()\n\n    def remove(self):\n        self.hook.remove()\n\nconv_out = LayerActivations(vgg.features,0)\n\no = vgg(Variable(img.cuda()))\n\nconv_out.remove()\n\nact = conv_out.features\n```", "```py\nfig = plt.figure(figsize=(20,50))\nfig.subplots_adjust(left=0,right=1,bottom=0,top=0.8,hspace=0,\n  wspace=0.2)\nfor i in range(30):\n    ax = fig.add_subplot(12,5,i+1,xticks=[],yticks=[])\n    ax.imshow(act[0][i])\n```", "```py\nvgg.state_dict().keys()\ncnn_weights = vgg.state_dict()['features.0.weight'].cpu()\n```"]