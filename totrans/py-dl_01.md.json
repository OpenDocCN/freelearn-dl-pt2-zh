["```py\nfrom sklearn.neural_network.multilayer_perceptron import MLPClassifier\n```", "```py\nMLPClassifier().fit(data, labels)\n```", "```py\nprobabilities = MLPClassifier().predict_proba(data)\n```", "```py\nfrom sklearn import datasets\niris = datasets.load_iris() \ndata = iris.data \nlabels = iris.target\n```", "```py\nfrom sklearn.neural_network.multilayer_perceptron import MLPClassifier\n```", "```py\nmlp = MLPClassifier(random_state=1) \nmlp.fit(data, labels)\n```", "```py\npred = mlp.predict(data)\nfrom sklearn.metrics import accuracy_score \nprint('Accuracy: %.2f' % accuracy_score(labels, pred))\n```", "```py\nfrom sklearn.cross_validation import train_test_split \nfrom sklearn.preprocessing import StandardScaler\ndata_train, data_test, labels_train, labels_test = train_test_split(data, labels, test_size=0.5, random_state=1)  \nscaler = StandardScaler() \nscaler.fit(data) \ndata_train_std = scaler.transform(data_train) \ndata_test_std = scaler.transform(data_test)  \ndata_train_std = data_train \ndata_test_std = data_test\n```", "```py\nmlp.fit(data_train, labels_train)\npred = mlp.predict(data_test)\nprint('Misclassified samples: %d' % (labels_test != pred).sum())\nfrom sklearn.metrics import accuracy_score print('Accuracy: %.2f' % accuracy_score(labels_test, pred))\n```", "```py\nMisclassified samples: 3 Accuracy: 0.96\n\n```", "```py\nimport numpy\nfrom matplotlib.colors import ListedColormap \nimport matplotlib.pyplot as plt\nmarkers = ('s', '*', '^') \ncolors = ('blue', 'green', 'red') \ncmap = ListedColormap(colors)   \nx_min, x_max = data[:, 0].min() - 1, data[:, 0].max() + 1 \ny_min, y_max = data[:, 1].min() - 1, data[:, 1].max() + 1 \nresolution = 0.01  \nx, y = numpy.meshgrid(numpy.arange(x_min, x_max, resolution), numpy.arange(y_min, y_max, resolution)) \nZ = mlp.predict(numpy.array([x.ravel(), y.ravel()]).T) \nZ = Z.reshape(x.shape)  \nplt.pcolormesh(x, y, Z, cmap=cmap) \nplt.xlim(x.min(), x.max()) \nplt.ylim(y.min(), y.max())  \n# plot the data \nclasses = [\"setosa\", \"versicolor\", \"verginica\"] \nfor index, cl in enumerate(numpy.unique(labels)):     \nplt.scatter(data[labels == cl, 0], data[labels == cl, 1], c=cmap(index), marker=markers[index], s=50, label=classes[index])     \nplt.xlabel('petal length') \nplt.ylabel('sepal length') \nplt.legend(loc='upper left') \nplt.show() \n```", "```py\nmlp = MLPClassifier(random_state=1, hidden_layer_sizes=(200, 100,))\n```", "```py\nmlp = MLPClassifier(random_state=1, hidden_layer_sizes=(200, 100,), activation = \"logistic\")\n```"]