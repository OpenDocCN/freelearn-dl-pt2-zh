["```py\n!pip install gensim\n```", "```py\n!pip install wget\nimport wget\nwget.download(\n    'https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.en.vec',\n    'wiki.en.vec'\n)\n```", "```py\nfrom sklearn.datasets import fetch_20newsgroups\n\ncategories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']\ntwenty_train = fetch_20newsgroups(\n    subset='train',\n    categories=categories,\n    shuffle=True,\n    random_state=42\n  )\ntwenty_test = fetch_20newsgroups(\n    subset='test',\n    categories=categories,\n    shuffle=True,\n    random_state=42\n)\n```", "```py\nimport numpy as np\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.ensemble import RandomForestClassifier\n\ntext_clf = Pipeline([\n  ('vect', CountVectorizer()),\n  ('tfidf', TfidfTransformer()),\n  ('clf', RandomForestClassifier()),\n])\ntext_clf.fit(twenty_train.data, twenty_train.target)\n```", "```py\npredicted = text_clf.predict(twenty_test.data)\nnp.mean(predicted == twenty_test.target)\n```", "```py\nfrom gensim.models import KeyedVectors\n\nmodel = KeyedVectors.load_word2vec_format(\n    'wiki.en.vec',\n    binary=False, encoding='utf8'\n)\n```", "```py\nimport numpy as np\nfrom tensorflow.keras.preprocessing.text import text_to_word_sequence\n\ndef embed_text(text: str):\n  vector_list = [\n    model.wv[w].reshape(-1, 1) for w in text_to_word_sequence(text)\n    if w in model.wv\n  ]\n  if len(vector_list) > 0:\n    return np.mean(\n        np.concatenate(vector_list, axis=1),\n        axis=1\n    ).reshape(1, 300)\n  else:\n   return np.zeros(shape=(1, 300))\n\nassert embed_text('training run').shape == (1, 300)\n```", "```py\ntrain_transformed = np.concatenate(\n    [embed_text(t) for t in twenty_train.data]\n)\nrf = RandomForestClassifier().fit(train_transformed, twenty_train.target)\n```", "```py\ntest_transformed = np.concatenate(\n    [embed_text(t) for t in twenty_test.data]\n)\npredicted = rf.predict(test_transformed)\nnp.mean(predicted == twenty_test.target)\n```", "```py\nfrom tensorflow.keras import layers\n\nembedding = layers.Embedding(\n    input_dim=5000, \n    output_dim=50, \n    input_length=500\n)\n```", "```py\nfrom tensorflow.keras.preprocessing.text import Tokenizer\n\ntokenizer = Tokenizer(num_words=5000)\ntokenizer.fit_on_texts(twenty_train.data)\n```", "```py\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\nX_train = tokenizer.texts_to_sequences(twenty_train.data)\nX_test = tokenizer.texts_to_sequences(twenty_test.data)\nX_train = pad_sequences(X_train, padding='post', maxlen=500)\nX_test = pad_sequences(X_test, padding='post', maxlen=500)\n```", "```py\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.losses import SparseCategoricalCrossentropy\nfrom tensorflow.keras import regularizers\n\nmodel = Sequential()\nmodel.add(embedding)\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(\n    10,\n    activation='relu',\n    kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4)\n))\nmodel.add(layers.Dense(len(categories), activation='softmax'))\nmodel.compile(optimizer='adam',\n              loss=SparseCategoricalCrossentropy(),\n              metrics=['accuracy'])\nmodel.summary()\n```", "```py\nmodel.fit(X_train, twenty_train.target, epochs=10)\npredicted = model.predict(X_test).argmax(axis=1)\nnp.mean(predicted == twenty_test.target)\n```", "```py\nfrom gensim.utils import tokenize\nfrom gensim.test.utils import datapath\n\nclass FileIter(object):\n  def __init(self, filepath: str):\n    self.path = datapath(filepath)\n\n  def __iter__(self):\n    with utils.open(self.path, 'r', encoding='utf-8') as fin:\n      for line in fin:\n        yield list(tokenize(line))\n```", "```py\nfrom gensim.models import FastText\n\nmodel = FastText(size=4, window=3, min_count=1)\nmodel.build_vocab(\n  sentences=FileIter(\n    'crime-and-punishment.txt'\n))\nmodel.train(sentences=common_texts, total_examples=len(common_texts), epochs=10)\n```", "```py\nmodel.wv['axe']\n```", "```py\nx = Conv1D(128, 5, activation='relu')(embedded_sequences)\nx = MaxPooling1D(5)(x)\n```", "```py\nword_index = {i: w for i, w in enumerate(model.wv.vocab.keys())}\n```", "```py\nfrom tensorflow.keras.layers import Embedding\n\nembedding_layer = Embedding(\n    len(word_index) + 1,\n    300,\n    weights=[list(model.wv.vectors)],\n    input_length=500,\n    trainable=False\n)\n```", "```py\n!pip install git+https://www.github.com/farizrahman4u/eywa.git\n```", "```py\n!pip install pyOWM\n```", "```py\nfrom eywa.nlu import Classifier\n\nCONV_SAMPLES = {\n    'greetings' : ['Hi', 'hello', 'How are you', 'hey there', 'hey'],\n    'taxi' : ['book a cab', 'need a ride', 'find me a cab'],\n    'weather' : ['what is the weather in tokyo', 'weather germany',\n                   'what is the weather like in kochi',\n                   'what is the weather like', 'is it hot outside'],\n    'datetime' : ['what day is today', 'todays date', 'what time is it now',\n                   'time now', 'what is the time'],\n    'music' : ['play the Beatles', 'shuffle songs', 'make a sound']\n}\n\nCLF = Classifier()\nfor key in CONV_SAMPLES:\n    CLF.fit(CONV_SAMPLES[key], key)\n```", "```py\nprint(CLF.predict('will it rain today')) # >>> 'weather'\nprint(CLF.predict('play playlist rock n\\'roll')) # >>> 'music'\nprint(CLF.predict('what\\'s the hour?')) # >>> 'datetime'\n```", "```py\nfrom eywa.nlu import EntityExtractor\n\nX_WEATHER = [\n  'what is the weather in tokyo',\n  'weather germany',\n  'what is the weather like in kochi'\n]\nY_WEATHER = [\n  {'intent': 'weather', 'place': 'tokyo'},\n  {'intent': 'weather', 'place': 'germany'},\n  {'intent': 'weather', 'place': 'kochi'}\n]\n\nEX_WEATHER = EntityExtractor()\nEX_WEATHER.fit(X_WEATHER, Y_WEATHER)\n```", "```py\nEX_WEATHER.predict('what is the weather in London')\n```", "```py\n{'intent': 'weather', 'place': 'London'}\n```", "```py\nfrom pyowm import OWM\n\nmgr = OWM('YOUR-API-KEY').weather_manager()\n\ndef get_weather_forecast(place):\n    observation = mgr.weather_at_place(place)\n    return observation.get_weather().get_detailed_status()\n\nprint(get_weather_forecast('London'))\n```", "```py\novercast clouds\n```", "```py\nX_GREETING = ['Hii', 'helllo', 'Howdy', 'hey there', 'hey', 'Hi']\nY_GREETING = [{'greet': 'Hii'}, {'greet': 'helllo'}, {'greet': 'Howdy'},\n              {'greet': 'hey'}, {'greet': 'hey'}, {'greet': 'Hi'}]\nEX_GREETING = EntityExtractor()\nEX_GREETING.fit(X_GREETING, Y_GREETING)\n\nX_DATETIME = ['what day is today', 'date today', 'what time is it now', 'time now']\nY_DATETIME = [{'intent' : 'day', 'target': 'today'}, {'intent' : 'date', 'target': 'today'},\n              {'intent' : 'time', 'target': 'now'}, {'intent' : 'time', 'target': 'now'}]\n\nEX_DATETIME = EntityExtractor()\nEX_DATETIME.fit(X_DATETIME, Y_DATETIME)\n```", "```py\n_EXTRACTORS = {\n  'taxi': None,\n  'weather': EX_WEATHER,\n  'greetings': EX_GREETING,\n  'datetime': EX_DATETIME,\n  'music': None\n}\n```", "```py\nimport datetime\n\n_EXTRACTORS = {\n  'taxi': None,\n  'weather': EX_WEATHER,\n  'greetings': EX_GREETING,\n  'datetime': EX_DATETIME,\n  'music': None\n}\n\ndef question_and_answer(u_query: str):\n    q_class = CLF.predict(u_query)\n    print(q_class)\n    if _EXTRACTORS[q_class] is None:\n      return 'Sorry, you have to upgrade your software!'\n\n    q_entities = _EXTRACTORS[q_class].predict(u_query)\n    print(q_entities)\n    if q_class == 'greetings':\n      return q_entities.get('greet', 'hello')\n\n    if q_class == 'weather':\n      place = q_entities.get('place', 'London').replace('_', ' ')\n      return 'The forecast for {} is {}'.format(\n          place,\n          get_weather_forecast(place)\n      )\n\n    if q_class == 'datetime':\n      return 'Today\\'s date is {}'.format(\n          datetime.datetime.today().strftime('%B %d, %Y')\n      )\n\n    return 'I couldn\\'t understand what you said. I am sorry.'\n```", "```py\nwhile True:\n    query = input('\\nHow can I help you?')\n    print(question_and_answer(query))\n```", "```py\n[r'Is there (.*)', [\n    \"Do you think there is %1?\",\n    \"It's likely that there is %1.\",\n    \"Would you like there to be %1?\"\n]],\n```", "```py\n gReflections = {\n  #...\n  \"i'd\" : \"you would\",\n}\n```", "```py\nfrom eywa.nlu import Pattern\n\np = Pattern('I want to eat [food: pizza, banana, yogurt, kebab]')\np('i\\'d like to eat sushi')\n```", "```py\n{'food' : 'sushi'}\n```", "```py\n!nvidia-smi\n```", "```py\nTesla T4: 0MiB / 15079MiB\n```", "```py\n!pip install torchtext==0.7.0\n```", "```py\n!pip install hydra-core\n```", "```py\n!python -m spacy download de\n```", "```py\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\nimport torchtext\nfrom torchtext.datasets import Multi30k\nfrom torchtext.data import Field, BucketIterator\n\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\n\nimport spacy\nimport numpy as np\n\nimport math\n```", "```py\nspacy_de = spacy.load('de')\nspacy_en = spacy.load('en')\n\ndef tokenize_de(text):\n    return [tok.text for tok in spacy_de.tokenizer(text)]\n\ndef tokenize_en(text):\n    return [tok.text for tok in spacy_en.tokenizer(text)]\n```", "```py\nSRC = Field(\n    tokenize=tokenize_en, \n    init_token='<sos>', \n    eos_token='<eos>', \n    lower=True, \n    batch_first=True\n)\n\nTRG = Field(\n    tokenize=tokenize_de, \n    init_token='<sos>', \n    eos_token='<eos>', \n    lower=True, \n    batch_first=True\n)\n```", "```py\ntrain_data, valid_data, test_data = Multi30k.splits(\n    exts=('.en', '.de'), \n    fields=(SRC, TRG)\n)\nSRC.build_vocab(train_data, min_freq=2)\nTRG.build_vocab(train_data, min_freq=2)\n```", "```py\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nBATCH_SIZE = 128\n\ntrain_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n    (train_data, valid_data, test_data), \n     batch_size=BATCH_SIZE,\n     device=device\n)\n```", "```py\nclass MultiHeadAttentionLayer(nn.Module):\n    def __init__(self, hid_dim, n_heads, dropout, device):\n        super().__init__()\n        assert hid_dim % n_heads == 0\n        self.hid_dim = hid_dim\n        self.n_heads = n_heads\n        self.head_dim = hid_dim // n_heads\n        self.fc_q = nn.Linear(hid_dim, hid_dim)\n        self.fc_k = nn.Linear(hid_dim, hid_dim)\n        self.fc_v = nn.Linear(hid_dim, hid_dim)\n        self.fc_o = nn.Linear(hid_dim, hid_dim)\n        self.dropout = nn.Dropout(dropout)\n        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n\n    def forward(self, query, key, value, mask = None):\n        batch_size = query.shape[0]\n        Q = self.fc_q(query)\n        K = self.fc_k(key)\n        V = self.fc_v(value)\n        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n        if mask is not None:\n            energy = energy.masked_fill(mask == 0, -1e10)\n        attention = torch.softmax(energy, dim = -1)\n        x = torch.matmul(self.dropout(attention), V)\n        x = x.permute(0, 2, 1, 3).contiguous()\n        x = x.view(batch_size, -1, self.hid_dim)\n        x = self.fc_o(x)\n        return x, attention\n```", "```py\nclass PositionwiseFeedforwardLayer(nn.Module):\n    def __init__(self, hid_dim, pf_dim, dropout):\n        super().__init__()\n        self.fc_1 = nn.Linear(hid_dim, pf_dim)\n        self.fc_2 = nn.Linear(pf_dim, hid_dim)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x):\n        x = self.dropout(torch.relu(self.fc_1(x)))\n        x = self.fc_2(x)\n        return x\n```", "```py\nclass Encoder(nn.Module):\n    def __init__(self, input_dim, hid_dim,\n                 n_layers, n_heads, pf_dim,\n                 dropout, device,\n                 max_length=100):\n        super().__init__()\n        self.device = device\n        self.tok_embedding = nn.Embedding(input_dim, hid_dim)\n        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n        self.layers = nn.ModuleList(\n            [EncoderLayer(\n                hid_dim,\n                n_heads,\n                pf_dim,\n                dropout,\n                device\n            ) for _ in range(n_layers)])\n        self.dropout = nn.Dropout(dropout)\n        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n\n    def forward(self, src, src_mask):\n        batch_size = src.shape[0]\n        src_len = src.shape[1]\n        pos = torch.arange(\n            0, src_len\n        ).unsqueeze(0).repeat(\n            batch_size, 1\n        ).to(self.device)\n        src = self.dropout(\n            (self.tok_embedding(src) * self.scale) +\n            self.pos_embedding(pos)\n        )\n        for layer in self.layers:\n            src = layer(src, src_mask)\n        return src\n```", "```py\nclass EncoderLayer(nn.Module):\n    def __init__(self, hid_dim, n_heads,\n                 pf_dim, dropout, device):\n        super().__init__()\n        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n        self.positionwise_feedforward = PositionwiseFeedforwardLayer(\n            hid_dim, pf_dim, dropout\n        )\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, src, src_mask):\n        _src, _ = self.self_attention(src, src, src, src_mask)\n        src = self.self_attn_layer_norm(src + self.dropout(_src))\n        _src = self.positionwise_feedforward(src)\n        src = self.ff_layer_norm(src + self.dropout(_src))\n        return src\n```", "```py\nclass Decoder(nn.Module):\n    def __init__(self, output_dim, hid_dim,\n                 n_layers, n_heads, pf_dim,\n                 dropout, device, max_length=100):\n        super().__init__()\n        self.device = device\n        self.tok_embedding = nn.Embedding(output_dim, hid_dim)\n        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n        self.layers = nn.ModuleList(\n            [DecoderLayer(\n                hid_dim, n_heads,\n                pf_dim, dropout,\n                device\n            ) for _ in range(n_layers)]\n        )\n        self.fc_out = nn.Linear(hid_dim, output_dim)\n        self.dropout = nn.Dropout(dropout)\n        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n\n    def forward(self, trg, enc_src, trg_mask, src_mask):\n        batch_size = trg.shape[0]\n        trg_len = trg.shape[1]\n        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(\n            batch_size, 1\n        ).to(self.device)\n        trg = self.dropout(\n            (self.tok_embedding(trg) * self.scale) +\n            self.pos_embedding(pos)\n        )\n        for layer in self.layers:\n            trg, attention = layer(trg, enc_src, trg_mask, src_mask)\n        output = self.fc_out(trg)\n        return output, attention\n```", "```py\nclass DecoderLayer(nn.Module):\n    def __init__(self, hid_dim, n_heads,\n                 pf_dim, dropout, device):\n        super().__init__()\n        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n        self.enc_attn_layer_norm = nn.LayerNorm(hid_dim)\n        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n        self.encoder_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n        self.positionwise_feedforward = PositionwiseFeedforwardLayer(\n            hid_dim, pf_dim, dropout\n        )\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, trg, enc_src, trg_mask, src_mask):\n        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\n        trg = self.self_attn_layer_norm(trg + self.dropout(_trg))\n        _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\n        trg = self.enc_attn_layer_norm(trg + self.dropout(_trg))\n        _trg = self.positionwise_feedforward(trg)\n        trg = self.ff_layer_norm(trg + self.dropout(_trg))\n        return trg, attention\n```", "```py\nclass Seq2Seq(nn.Module):\n    def __init__(self, encoder, decoder,\n                 src_pad_idx, trg_pad_idx, device):\n        super().__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n        self.src_pad_idx = src_pad_idx\n        self.trg_pad_idx = trg_pad_idx\n        self.device = device\n\n    def make_src_mask(self, src):\n        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n        return src_mask\n\n    def make_trg_mask(self, trg):\n        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n        trg_len = trg.shape[1]\n        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device=self.device)).bool()\n        trg_mask = trg_pad_mask & trg_sub_mask\n        return trg_mask\n\n    def forward(self, src, trg):\n        src_mask = self.make_src_mask(src)\n        trg_mask = self.make_trg_mask(trg)\n        enc_src = self.encoder(src, src_mask)\n        output, attention = self.decoder(trg, enc_src, trg_mask, src_mask)\n        return output, attention\n```", "```py\nINPUT_DIM = len(SRC.vocab)\nOUTPUT_DIM = len(TRG.vocab)\nHID_DIM = 256\nENC_LAYERS = 3\nDEC_LAYERS = 3\nENC_HEADS = 8\nDEC_HEADS = 8\nENC_PF_DIM = 512\nDEC_PF_DIM = 512\nENC_DROPOUT = 0.1\nDEC_DROPOUT = 0.1\n\nenc = Encoder(INPUT_DIM, \n    HID_DIM, ENC_LAYERS, \n    ENC_HEADS, ENC_PF_DIM, \n    ENC_DROPOUT, device\n)\n\ndec = Decoder(OUTPUT_DIM, \n    HID_DIM, DEC_LAYERS, \n    DEC_HEADS, DEC_PF_DIM, \n    DEC_DROPOUT, device\n)\nSRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\nTRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n\nmodel = Seq2Seq(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)\n```", "```py\ndef initialize_weights(m):\n    if hasattr(m, 'weight') and m.weight.dim() > 1:\n        nn.init.xavier_uniform_(m.weight.data)\n\nmodel.apply(initialize_weights);\n```", "```py\nLEARNING_RATE = 0.0005\n\noptimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n```", "```py\ncriterion = nn.CrossEntropyLoss(ignore_index=TRG_PAD_IDX)\n```", "```py\ndef train(model, iterator, optimizer, criterion, clip):\n    model.train()\n    epoch_loss = 0\n    for i, batch in enumerate(iterator):\n        src = batch.src\n        trg = batch.trg\n        optimizer.zero_grad()\n        output, _ = model(src, trg[:, :-1])\n        output_dim = output.shape[-1]\n        output = output.contiguous().view(-1, output_dim)\n        trg = trg[:,1:].contiguous().view(-1)\n        loss = criterion(output, trg)\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n        optimizer.step()\n        epoch_loss += loss.item()\n    return epoch_loss / len(iterator)\n```", "```py\nN_EPOCHS = 10\nCLIP = 1\nbest_valid_loss = float('inf')\n\nfor epoch in range(N_EPOCHS):    \n    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n\n    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n```", "```py\ndef translate_sentence(sentence, src_field, trg_field, model, device, max_len=50):\n    model.eval()\n    if isinstance(sentence, str):\n        nlp = spacy.load('en')\n        tokens = [token.text.lower() for token in nlp(sentence)]\n    else:\n        tokens = [token.lower() for token in sentence]\n    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n    src_mask = model.make_src_mask(src_tensor)\n    with torch.no_grad():\n        enc_src = model.encoder(src_tensor, src_mask)\n    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n    for i in range(max_len):\n        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n        trg_mask = model.make_trg_mask(trg_tensor)\n        with torch.no_grad():\n            output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\n        pred_token = output.argmax(2)[:, -1].item()\n        trg_indexes.append(pred_token)\n        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n            break\n    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n    return trg_tokens[1:], attention\n```", "```py\nexample_idx = 8\n\nsrc = vars(train_data.examples[example_idx])['src']\ntrg = vars(train_data.examples[example_idx])['trg']\n\nprint(f'src = {src}')\nprint(f'trg = {trg}')\n```", "```py\nsrc = ['a', 'woman', 'with', 'a', 'large', 'purse', 'is', 'walking', 'by', 'a', 'gate', '.']\ntrg = ['eine', 'frau', 'mit', 'einer', 'großen', 'geldbörse', 'geht', 'an', 'einem', 'tor', 'vorbei', '.']\n```", "```py\ntranslation, attention = translate_sentence(src, SRC, TRG, model, device)\nprint(f'predicted trg = {translation}')\n```", "```py\npredicted trg = ['eine', 'frau', 'mit', 'einer', 'großen', 'handtasche', 'geht', 'an', 'einem', 'tor', 'vorbei', '.', '<eos>']\n```", "```py\nfrom torchtext.data.metrics import bleu_score\n\ndef calculate_bleu(data, src_field, trg_field, model, device, max_len=50):\n    trgs = []\n    pred_trgs = []\n\n    for datum in data:\n        src = vars(datum)['src']\n        trg = vars(datum)['trg']\n        pred_trg, _ = translate_sentence(src, src_field, trg_field, model, device, max_len)\n\n        #cut off <eos> token\n        pred_trg = pred_trg[:-1]\n\n        pred_trgs.append(pred_trg)\n        trgs.append([trg])\n\n    return bleu_score(pred_trgs, trgs)\n\nbleu_score = calculate_bleu(test_data, SRC, TRG, model, device)\n\nprint(f'BLEU score = {bleu_score*100:.2f}')\n```", "```py\n!pip install fairseq fastBPE sacremoses\n```", "```py\nimport torch\n\nen2de = torch.hub.load(\n    'pytorch/fairseq',\n    'transformer.wmt19.en-de',\n    checkpoint_file='model1.pt:model2.pt:model3.pt:model4.pt',\n    tokenizer='moses',\n    bpe='fastbpe'\n)\nen2de.translate('Machine learning is great!')\n```", "```py\nMaschinelles Lernen ist großartig!\n```", "```py\n!wget -O pride_and_prejudice.txt http://www.gutenberg.org/files/1342/1342-0.txt\n\n```", "```py\n%tensorflow_version 1.x\n!pip install -q gpt-2-simple\n```", "```py\nimport gpt_2_simple as gpt2\ngpt2.download_gpt2(model_name='124M')\n```", "```py\ngpt2.mount_gdrive()\n```", "```py\ngpt2.copy_file_from_gdrive(file_name)\n```", "```py\nsess = gpt2.start_tf_sess()\n\ngpt2.finetune(\n    sess,\n    dataset=file_name,\n    model_name='124M',\n    steps=1000,\n    restore_from='fresh',\n    run_name='run1',\n    print_every=10,\n    sample_every=200,\n    save_every=500\n)\n```", "```py\nshe will now make her opinions known to the whole of the family, and\n to all their friends.\n\n “At a time when so many middle-aged people are moving into\n town, when many couples are making fortunes off each other, when\n many professions of taste are forming in the society, I am\n really anxious to find some time here in the course of the next three\n months to write to my dear Elizabeth, to seek her informed opinion\n on this happy event, and to recommend it to her husband’s conduct as well\n as her own. I often tell people to be cautious when they see\n connections of importance here. What is to be done after my death?\n To go through the world in such a way as to be forgotten?”\n\n Mr. Bennet replied that he would write again at length to write\n very near to the last lines of his letter. Elizabeth cried\n out in alarm, and while she remained, a sense of shame had\n entered her of her being the less attentive companion she had been\n when she first distinguished her acquaintance. Anxiety increased\n every moment for the other to return to her senses, and\n every opportunity for Mr. Bennet to shine any brighter was given\n by the very first letter.\n```", "```py\ngpt2.copy_checkpoint_to_gdrive(run_name='run1')\n```", "```py\n# 1\\. copy checkpoint from google drive:\ngpt2.copy_checkpoint_from_gdrive(run_name='run1')\n\n# 2\\. continue training:\nsess = gpt2.start_tf_sess()\ngpt2.finetune(\n    sess,\n    dataset=file_name,\n    model_name='124M',\n    steps=500,\n    restore_from='latest',\n    run_name='run1',\n    print_every=10,\n    overwrite=True,\n    sample_every=200,\n    save_every=100\n)\n# 3\\. let's backup the model again:\ngpt2.copy_checkpoint_to_gdrive(run_name='run1')\n```", "```py\ngpt2.copy_checkpoint_from_gdrive(run_name='run1')\nsess = gpt2.start_tf_sess()\ngpt2.load_gpt2(sess, run_name='run1')\n```", "```py\ngen_file = 'gpt2_gentext_{:%Y%m%d_%H%M%S}.txt'.format(datetime.utcnow())\n\ngpt2.generate_to_file(\n  sess,\n  destination_path=gen_file,\n  temperature=0.7,\n  nsamples=100,\n  batch_size=20\n)\nfiles.download(gen_file)\n```"]