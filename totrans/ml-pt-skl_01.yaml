- en: '1'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Giving Computers the Ability to Learn from Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In my opinion, **machine learning**, the application and science of algorithms
    that make sense of data, is the most exciting field of all the computer sciences!
    We are living in an age where data comes in abundance; using self-learning algorithms
    from the field of machine learning, we can turn this data into knowledge. Thanks
    to the many powerful open-source libraries that have been developed in recent
    years, there has probably never been a better time to break into the machine learning
    field and learn how to utilize powerful algorithms to spot patterns in data and
    make predictions about future events.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, you will learn about the main concepts and different types
    of machine learning. Together with a basic introduction to the relevant terminology,
    we will lay the groundwork for successfully using machine learning techniques
    for practical problem solving.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: The general concepts of machine learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The three types of learning and basic terminology
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The building blocks for successfully designing machine learning systems
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Installing and setting up Python for data analysis and machine learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building intelligent machines to transform data into knowledge
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this age of modern technology, there is one resource that we have in abundance:
    a large amount of structured and unstructured data. In the second half of the
    20th century, machine learning evolved as a subfield of **artificial intelligence**
    (**AI**) involving self-learning algorithms that derive knowledge from data to
    make predictions.'
  prefs: []
  type: TYPE_NORMAL
- en: Instead of requiring humans to manually derive rules and build models from analyzing
    large amounts of data, machine learning offers a more efficient alternative for
    capturing the knowledge in data to gradually improve the performance of predictive
    models and make data-driven decisions.
  prefs: []
  type: TYPE_NORMAL
- en: Not only is machine learning becoming increasingly important in computer science
    research, but it is also playing an ever-greater role in our everyday lives. Thanks
    to machine learning, we enjoy robust email spam filters, convenient text and voice
    recognition software, reliable web search engines, recommendations on entertaining
    movies to watch, mobile check deposits, estimated meal delivery times, and much
    more. Hopefully, soon, we will add safe and efficient self-driving cars to this
    list. Also, notable progress has been made in medical applications; for example,
    researchers demonstrated that deep learning models can detect skin cancer with
    near-human accuracy ([https://www.nature.com/articles/nature21056](https://www.nature.com/articles/nature21056)).
    Another milestone was recently achieved by researchers at DeepMind, who used deep
    learning to predict 3D protein structures, outperforming physics-based approaches
    by a substantial margin ([https://deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology](https://deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology)).
    While accurate 3D protein structure prediction plays an essential role in biological
    and pharmaceutical research, there have been many other important applications
    of machine learning in healthcare recently. For instance, researchers designed
    systems for predicting the oxygen needs of COVID-19 patients up to four days in
    advance to help hospitals allocate resources for those in need ([https://ai.facebook.com/blog/new-ai-research-to-help-predict-covid-19-resource-needs-from-a-series-of-x-rays/](https://ai.facebook.com/blog/new-ai-research-to-help-predict-covid-19-resource-needs-from-a-series-of-x-rays/)).
    Another important topic of our day and age is climate change, which presents one
    of the biggest and most critical challenges. Today, many efforts are being directed
    toward developing intelligent systems to combat it ([https://www.forbes.com/sites/robtoews/2021/06/20/these-are-the-startups-applying-ai-to-tackle-climate-change](https://www.forbes.com/sites/robtoews/2021/06/20/these-are-the-startups-applying-ai-to-tackle-climate-change)).
    One of the many approaches to tackling climate change is the emergent field of
    precision agriculture. Here, researchers aim to design computer vision-based machine
    learning systems to optimize resource deployment to minimize the use and waste
    of fertilizers.
  prefs: []
  type: TYPE_NORMAL
- en: The three different types of machine learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we will take a look at the three types of machine learning:
    **supervised learning**, **unsupervised learning**, and **reinforcement learning**.
    We will learn about the fundamental differences between the three different learning
    types and, using conceptual examples, we will develop an understanding of the
    practical problem domains where they can be applied:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface, text, application  Description automatically generated](img/B17582_01_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.1: The three different types of machine learning'
  prefs: []
  type: TYPE_NORMAL
- en: Making predictions about the future with supervised learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The main goal in supervised learning is to learn a model from labeled training
    data that allows us to make predictions about unseen or future data. Here, the
    term “supervised” refers to a set of training examples (data inputs) where the
    desired output signals (labels) are already known. Supervised learning is then
    the process of modeling the relationship between the data inputs and the labels.
    Thus, we can also think of supervised learning as “label learning.”
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 1.2* summarizes a typical supervised learning workflow, where the labeled
    training data is passed to a machine learning algorithm for fitting a predictive
    model that can make predictions on new, unlabeled data inputs:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram  Description automatically generated](img/B17582_01_02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.2: Supervised learning process'
  prefs: []
  type: TYPE_NORMAL
- en: Considering the example of email spam filtering, we can train a model using
    a supervised machine learning algorithm on a corpus of labeled emails, which are
    correctly marked as spam or non-spam, to predict whether a new email belongs to
    either of the two categories. A supervised learning task with discrete class labels,
    such as in the previous email spam filtering example, is also called a **classification
    task**. Another subcategory of supervised learning is **regression**, where the
    outcome signal is a continuous value.
  prefs: []
  type: TYPE_NORMAL
- en: Classification for predicting class labels
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Classification is a subcategory of supervised learning where the goal is to
    predict the categorical class labels of new instances or data points based on
    past observations. Those class labels are discrete, unordered values that can
    be understood as the group memberships of the data points. The previously mentioned
    example of email spam detection represents a typical example of a binary classification
    task, where the machine learning algorithm learns a set of rules to distinguish
    between two possible classes: spam and non-spam emails.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 1.3* illustrates the concept of a binary classification task given
    30 training examples; 15 training examples are labeled as class A and 15 training
    examples are labeled as class B. In this scenario, our dataset is two-dimensional,
    which means that each example has two values associated with it: *x*[1] and *x*[2].
    Now, we can use a supervised machine learning algorithm to learn a rule—the decision
    boundary represented as a dashed line—that can separate those two classes and
    classify new data into each of those two categories given its *x*[1] and *x*[2]
    values:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_01_03.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.3: Classifying a new data point'
  prefs: []
  type: TYPE_NORMAL
- en: However, the set of class labels does not have to be of a binary nature. The
    predictive model learned by a supervised learning algorithm can assign any class
    label that was presented in the training dataset to a new, unlabeled data point
    or instance.
  prefs: []
  type: TYPE_NORMAL
- en: A typical example of a **multiclass classification** task is handwritten character
    recognition. We can collect a training dataset that consists of multiple handwritten
    examples of each letter in the alphabet. The letters (“A,” “B,” “C,” and so on)
    will represent the different unordered categories or class labels that we want
    to predict. Now, if a user provides a new handwritten character via an input device,
    our predictive model will be able to predict the correct letter in the alphabet
    with certain accuracy. However, our machine learning system will be unable to
    correctly recognize any of the digits between 0 and 9, for example, if they were
    not part of the training dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Regression for predicting continuous outcomes
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We learned in the previous section that the task of classification is to assign
    categorical, unordered labels to instances. A second type of supervised learning
    is the prediction of continuous outcomes, which is also called **regression analysis**.
    In regression analysis, we are given a number of predictor (**explanatory**) variables
    and a continuous response variable (**outcome**), and we try to find a relationship
    between those variables that allows us to predict an outcome.
  prefs: []
  type: TYPE_NORMAL
- en: Note that in the field of machine learning, the predictor variables are commonly
    called “features,” and the response variables are usually referred to as “target
    variables.” We will adopt these conventions throughout this book.
  prefs: []
  type: TYPE_NORMAL
- en: For example, let’s assume that we are interested in predicting the math SAT
    scores of students. (The SAT is a standardized test frequently used for college
    admissions in the United States.) If there is a relationship between the time
    spent studying for the test and the final scores, we could use it as training
    data to learn a model that uses the study time to predict the test scores of future
    students who are planning to take this test.
  prefs: []
  type: TYPE_NORMAL
- en: '**Regression toward the mean**'
  prefs: []
  type: TYPE_NORMAL
- en: The term “regression” was devised by Francis Galton in his article *Regression
    towards Mediocrity in Hereditary Stature* in 1886\. Galton described the biological
    phenomenon that the variance of height in a population does not increase over
    time.
  prefs: []
  type: TYPE_NORMAL
- en: He observed that the height of parents is not passed on to their children, but
    instead, their children’s height regresses toward the population mean.
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 1.4* illustrates the concept of linear regression. Given a feature
    variable, *x*, and a target variable, *y*, we fit a straight line to this data
    that minimizes the distance—most commonly the average squared distance—between
    the data points and the fitted line.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now use the intercept and slope learned from this data to predict the
    target variable of new data:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Chart, scatter chart  Description automatically generated](img/B17582_01_04.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.4: A linear regression example'
  prefs: []
  type: TYPE_NORMAL
- en: Solving interactive problems with reinforcement learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Another type of machine learning is **reinforcement learning**. In reinforcement
    learning, the goal is to develop a system (**agent**) that improves its performance
    based on interactions with the environment. Since the information about the current
    state of the environment typically also includes a so-called **reward signal**,
    we can think of reinforcement learning as a field related to supervised learning.
    However, in reinforcement learning, this feedback is not the correct ground truth
    label or value, but a measure of how well the action was measured by a reward
    function. Through its interaction with the environment, an agent can then use
    reinforcement learning to learn a series of actions that maximizes this reward
    via an exploratory trial-and-error approach or deliberative planning.
  prefs: []
  type: TYPE_NORMAL
- en: 'A popular example of reinforcement learning is a chess program. Here, the agent
    decides upon a series of moves depending on the state of the board (the environment),
    and the reward can be defined as **win** or **lose** at the end of the game:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram  Description automatically generated](img/B17582_01_05.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.5: Reinforcement learning process'
  prefs: []
  type: TYPE_NORMAL
- en: There are many different subtypes of reinforcement learning. However, a general
    scheme is that the agent in reinforcement learning tries to maximize the reward
    through a series of interactions with the environment. Each state can be associated
    with a positive or negative reward, and a reward can be defined as accomplishing
    an overall goal, such as winning or losing a game of chess. For instance, in chess,
    the outcome of each move can be thought of as a different state of the environment.
  prefs: []
  type: TYPE_NORMAL
- en: To explore the chess example further, let’s think of visiting certain configurations
    on the chessboard as being associated with states that will more likely lead to
    winning—for instance, removing an opponent’s chess piece from the board or threatening
    the queen. Other positions, however, are associated with states that will more
    likely result in losing the game, such as losing a chess piece to the opponent
    in the following turn. Now, in the game of chess, the reward (either positive
    for winning or negative for losing the game) will not be given until the end of
    the game. In addition, the final reward will also depend on how the opponent plays.
    For example, the opponent may sacrifice the queen but eventually win the game.
  prefs: []
  type: TYPE_NORMAL
- en: In sum, reinforcement learning is concerned with learning to choose a series
    of actions that maximizes the total reward, which could be earned either immediately
    after taking an action or via *delayed* feedback.
  prefs: []
  type: TYPE_NORMAL
- en: Discovering hidden structures with unsupervised learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In supervised learning, we know the right answer (the label or target variable)
    beforehand when we train a model, and in reinforcement learning, we define a measure
    of reward for particular actions carried out by the agent. In unsupervised learning,
    however, we are dealing with unlabeled data or data of an unknown structure. Using
    unsupervised learning techniques, we are able to explore the structure of our
    data to extract meaningful information without the guidance of a known outcome
    variable or reward function.
  prefs: []
  type: TYPE_NORMAL
- en: Finding subgroups with clustering
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Clustering** is an exploratory data analysis or pattern discovery technique
    that allows us to organize a pile of information into meaningful subgroups (**clusters**)
    without having any prior knowledge of their group memberships. Each cluster that
    arises during the analysis defines a group of objects that share a certain degree
    of similarity but are more dissimilar to objects in other clusters, which is why
    clustering is also sometimes called **unsupervised classification**. Clustering
    is a great technique for structuring information and deriving meaningful relationships
    from data. For example, it allows marketers to discover customer groups based
    on their interests, in order to develop distinct marketing programs.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 1.6* illustrates how clustering can be applied to organizing unlabeled
    data into three distinct groups or clusters (A, B, and C, in arbitrary order)
    based on the similarity of their features, *x*[1] and *x*[2]:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram  Description automatically generated](img/B17582_01_06.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.6: How clustering works'
  prefs: []
  type: TYPE_NORMAL
- en: Dimensionality reduction for data compression
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Another subfield of unsupervised learning is **dimensionality reduction**. Often,
    we are working with data of high dimensionality—each observation comes with a
    high number of measurements—that can present a challenge for limited storage space
    and the computational performance of machine learning algorithms. Unsupervised
    dimensionality reduction is a commonly used approach in feature preprocessing
    to remove noise from data, which can degrade the predictive performance of certain
    algorithms. Dimensionality reduction compresses the data onto a smaller dimensional
    subspace while retaining most of the relevant information.
  prefs: []
  type: TYPE_NORMAL
- en: 'Sometimes, dimensionality reduction can also be useful for visualizing data;
    for example, a high-dimensional feature set can be projected onto one-, two-,
    or three-dimensional feature spaces to visualize it via 2D or 3D scatterplots
    or histograms. *Figure 1.7* shows an example where nonlinear dimensionality reduction
    was applied to compress a 3D Swiss roll onto a new 2D feature subspace:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_01_07.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.7: An example of dimensionality reduction from three to two dimensions'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to the basic terminology and notations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have discussed the three broad categories of machine learning—supervised,
    unsupervised, and reinforcement learning—let’s have a look at the basic terminology
    that we will be using throughout this book. The following subsection covers the
    common terms we will be using when referring to different aspects of a dataset,
    as well as the mathematical notation to communicate more precisely and efficiently.
  prefs: []
  type: TYPE_NORMAL
- en: As machine learning is a vast field and very interdisciplinary, you are guaranteed
    to encounter many different terms that refer to the same concepts sooner rather
    than later. The second subsection collects many of the most commonly used terms
    that are found in machine learning literature, which may be useful to you as a
    reference section when reading machine learning publications.
  prefs: []
  type: TYPE_NORMAL
- en: Notation and conventions used in this book
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Figure 1.8* depicts an excerpt of the Iris dataset, which is a classic example
    in the field of machine learning (more information can be found at [https://archive.ics.uci.edu/ml/datasets/iris](https://archive.ics.uci.edu/ml/datasets/iris)).
    The Iris dataset contains the measurements of 150 Iris flowers from three different
    species—Setosa, Versicolor, and Virginica.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, each flower example represents one row in our dataset, and the flower
    measurements in centimeters are stored as columns, which we also call the **features**
    of the dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram  Description automatically generated](img/B17582_01_08.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.8: The Iris dataset'
  prefs: []
  type: TYPE_NORMAL
- en: To keep the notation and implementation simple yet efficient, we will make use
    of some of the basics of linear algebra. In the following chapters, we will use
    a matrix notation to refer to our data. We will follow the common convention to
    represent each example as a separate row in a feature matrix, **X**, where each
    feature is stored as a separate column.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Iris dataset, consisting of 150 examples and four features, can then be
    written as a 150×4 matrix, formally denoted as ![](img/B17582_01_001.png):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_01_002.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Notational conventions**'
  prefs: []
  type: TYPE_NORMAL
- en: For most parts of this book, unless noted otherwise, we will use the superscript
    *i* to refer to the *i*th training example, and the subscript *j* to refer to
    the *j*th dimension of the training dataset.
  prefs: []
  type: TYPE_NORMAL
- en: We will use lowercase, bold-face letters to refer to vectors (![](img/B17582_01_003.png))
    and uppercase, bold-face letters to refer to matrices (![](img/B17582_01_004.png)).
    To refer to single elements in a vector or matrix, we will write the letters in
    italics (*x*^(^n^) or ![](img/B17582_01_005.png), respectively).
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, ![](img/B17582_01_006.png) refers to the first dimension of flower
    example 150, the sepal length. Each row in matrix **X** represents one flower
    instance and can be written as a four-dimensional row vector, ![](img/B17582_01_007.png):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_01_008.png)'
  prefs: []
  type: TYPE_IMG
- en: 'And each feature dimension is a 150-dimensional column vector, ![](img/B17582_01_009.png).
    For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_01_010.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Similarly, we can represent the target variables (here, class labels) as a
    150-dimensional column vector:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_01_011.png)'
  prefs: []
  type: TYPE_IMG
- en: Machine learning terminology
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Machine learning is a vast field and also very interdisciplinary as it brings
    together many scientists from other areas of research. As it happens, many terms
    and concepts have been rediscovered or redefined and may already be familiar to
    you but appear under different names. For your convenience, in the following list,
    you can find a selection of commonly used terms and their synonyms that you may
    find useful when reading this book and machine learning literature in general:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Training example**: A row in a table representing the dataset and synonymous
    with an observation, record, instance, or sample (in most contexts, sample refers
    to a collection of training examples).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Training**: Model fitting, for parametric models similar to parameter estimation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Feature, abbrev.** **x**: A column in a data table or data (design) matrix.
    Synonymous with predictor, variable, input, attribute, or covariate.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Target, abbrev.** **y**: Synonymous with outcome, output, response variable,
    dependent variable, (class) label, and ground truth.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Loss function**: Often used synonymously with a *cost* function. Sometimes
    the loss function is also called an *error* function. In some literature, the
    term “loss” refers to the loss measured for a single data point, and the cost
    is a measurement that computes the loss (average or summed) over the entire dataset.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A roadmap for building machine learning systems
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In previous sections, we discussed the basic concepts of machine learning and
    the three different types of learning. In this section, we will discuss the other
    important parts of a machine learning system accompanying the learning algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 1.9* shows a typical workflow for using machine learning in predictive
    modeling, which we will discuss in the following subsections:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram  Description automatically generated](img/B17582_01_09.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.9: Predictive modeling workflow'
  prefs: []
  type: TYPE_NORMAL
- en: Preprocessing – getting data into shape
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s begin by discussing the roadmap for building machine learning systems.
    Raw data rarely comes in the form and shape that is necessary for the optimal
    performance of a learning algorithm. Thus, the preprocessing of the data is one
    of the most crucial steps in any machine learning application.
  prefs: []
  type: TYPE_NORMAL
- en: If we take the Iris flower dataset from the previous section as an example,
    we can think of the raw data as a series of flower images from which we want to
    extract meaningful features. Useful features could be centered around the color
    of the flowers or the height, length, and width of the flowers.
  prefs: []
  type: TYPE_NORMAL
- en: Many machine learning algorithms also require that the selected features are
    on the same scale for optimal performance, which is often achieved by transforming
    the features in the range [0, 1] or a standard normal distribution with zero mean
    and unit variance, as we will see in later chapters.
  prefs: []
  type: TYPE_NORMAL
- en: Some of the selected features may be highly correlated and therefore redundant
    to a certain degree. In those cases, dimensionality reduction techniques are useful
    for compressing the features onto a lower-dimensional subspace. Reducing the dimensionality
    of our feature space has the advantage that less storage space is required, and
    the learning algorithm can run much faster. In certain cases, dimensionality reduction
    can also improve the predictive performance of a model if the dataset contains
    a large number of irrelevant features (or noise); that is, if the dataset has
    a low signal-to-noise ratio.
  prefs: []
  type: TYPE_NORMAL
- en: To determine whether our machine learning algorithm not only performs well on
    the training dataset but also generalizes well to new data, we also want to randomly
    divide the dataset into separate training and test datasets. We use the training
    dataset to train and optimize our machine learning model, while we keep the test
    dataset until the very end to evaluate the final model.
  prefs: []
  type: TYPE_NORMAL
- en: Training and selecting a predictive model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As you will see in later chapters, many different machine learning algorithms
    have been developed to solve different problem tasks. An important point that
    can be summarized from David Wolpert’s famous *No free lunch theorems* is that
    we can’t get learning “for free” (*The Lack of A Priori Distinctions Between Learning
    Algorithms*, D.H. Wolpert, 1996; *No free lunch theorems for optimization*, D.H.
    Wolpert and W.G. Macready, 1997). We can relate this concept to the popular saying,
    *I suppose it is tempting, if the only tool you have is a hammer, to treat everything
    as if it were a nail* (Abraham Maslow, 1966). For example, each classification
    algorithm has its inherent biases, and no single classification model enjoys superiority
    if we don’t make any assumptions about the task. In practice, it is therefore
    essential to compare at least a handful of different learning algorithms in order
    to train and select the best performing model. But before we can compare different
    models, we first have to decide upon a metric to measure performance. One commonly
    used metric is classification accuracy, which is defined as the proportion of
    correctly classified instances.
  prefs: []
  type: TYPE_NORMAL
- en: 'One legitimate question to ask is this: how do we know which model performs
    well on the final test dataset and real-world data if we don’t use this test dataset
    for the model selection, but keep it for the final model evaluation? To address
    the issue embedded in this question, different techniques summarized as “cross-validation”
    can be used. In cross-validation, we further divide a dataset into training and
    validation subsets in order to estimate the generalization performance of the
    model.'
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we also cannot expect that the default parameters of the different
    learning algorithms provided by software libraries are optimal for our specific
    problem task. Therefore, we will make frequent use of hyperparameter optimization
    techniques that help us to fine-tune the performance of our model in later chapters.
  prefs: []
  type: TYPE_NORMAL
- en: We can think of those hyperparameters as parameters that are not learned from
    the data but represent the knobs of a model that we can turn to improve its performance.
    This will become much clearer in later chapters when we see actual examples.
  prefs: []
  type: TYPE_NORMAL
- en: Evaluating models and predicting unseen data instances
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: After we have selected a model that has been fitted on the training dataset,
    we can use the test dataset to estimate how well it performs on this unseen data
    to estimate the so-called *generalization error*. If we are satisfied with its
    performance, we can now use this model to predict new, future data. It is important
    to note that the parameters for the previously mentioned procedures, such as feature
    scaling and dimensionality reduction, are solely obtained from the training dataset,
    and the same parameters are later reapplied to transform the test dataset, as
    well as any new data instances—the performance measured on the test data may be
    overly optimistic otherwise.
  prefs: []
  type: TYPE_NORMAL
- en: Using Python for machine learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Python is one of the most popular programming languages for data science, and
    thanks to its very active developer and open-source community, a large number
    of useful libraries for scientific computing and machine learning have been developed.
  prefs: []
  type: TYPE_NORMAL
- en: Although the performance of interpreted languages, such as Python, for computation-intensive
    tasks is inferior to lower-level programming languages, extension libraries such
    as NumPy and SciPy have been developed that build upon lower-layer Fortran and
    C implementations for fast vectorized operations on multidimensional arrays.
  prefs: []
  type: TYPE_NORMAL
- en: For machine learning programming tasks, we will mostly refer to the scikit-learn
    library, which is currently one of the most popular and accessible open-source
    machine learning libraries. In the later chapters, when we focus on a subfield
    of machine learning called *deep learning*, we will use the latest version of
    the PyTorch library, which specializes in training so-called *deep neural network*
    models very efficiently by utilizing graphics cards.
  prefs: []
  type: TYPE_NORMAL
- en: Installing Python and packages from the Python Package Index
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Python is available for all three major operating systems—Microsoft Windows,
    macOS, and Linux—and the installer, as well as the documentation, can be downloaded
    from the official Python website: [https://www.python.org](https://www.python.org).'
  prefs: []
  type: TYPE_NORMAL
- en: The code examples provided in this book have been written for and tested in
    Python 3.9, and we generally recommend that you use the most recent version of
    Python 3 that is available. Some of the code may also be compatible with Python
    2.7, but as the official support for Python 2.7 ended in 2019, and the majority
    of open-source libraries have already stopped supporting Python 2.7 ([https://python3statement.org](https://python3statement.org)),
    we strongly advise that you use Python 3.9 or newer.
  prefs: []
  type: TYPE_NORMAL
- en: You can check your Python version by executing
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: or
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: in your terminal (or PowerShell if you are using Windows).
  prefs: []
  type: TYPE_NORMAL
- en: The additional packages that we will be using throughout this book can be installed
    via the `pip` installer program, which has been part of the Python Standard Library
    since Python 3.3\. More information about `pip` can be found at [https://docs.python.org/3/installing/index.html](https://docs.python.org/3/installing/index.html).
  prefs: []
  type: TYPE_NORMAL
- en: 'After we have successfully installed Python, we can execute `pip` from the
    terminal to install additional Python packages:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Already installed packages can be updated via the `--upgrade` flag:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Using the Anaconda Python distribution and package manager
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A highly recommended open-source package management system for installing Python
    for scientific computing contexts is conda by Continuum Analytics. Conda is free
    and licensed under a permissive open-source license. Its goal is to help with
    the installation and version management of Python packages for data science, math,
    and engineering across different operating systems. If you want to use conda,
    it comes in different flavors, namely Anaconda, Miniconda, and Miniforge:'
  prefs: []
  type: TYPE_NORMAL
- en: Anaconda comes with many scientific computing packages pre-installed. The Anaconda
    installer can be downloaded at [https://docs.anaconda.com/anaconda/install/](https://docs.anaconda.com/anaconda/install/),
    and an Anaconda quick start guide is available at [https://docs.anaconda.com/anaconda/user-guide/getting-started/](https://docs.anaconda.com/anaconda/user-guide/getting-started/).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Miniconda is a leaner alternative to Anaconda ([https://docs.conda.io/en/latest/miniconda.html](https://docs.conda.io/en/latest/miniconda.html)).
    Essentially, it is similar to Anaconda but without any packages pre-installed,
    which many people (including the authors) prefer.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Miniforge is similar to Miniconda but community-maintained and uses a different
    package repository (conda-forge) from Miniconda and Anaconda. We found that Miniforge
    is a great alternative to Miniconda. Download and installation instructions can
    be found in the GitHub repository at [https://github.com/conda-forge/miniforge](https://github.com/conda-forge/miniforge).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'After successfully installing conda through either Anaconda, Miniconda, or
    Miniforge, we can install new Python packages using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Existing packages can be updated using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Packages that are not available through the official conda channel might be
    available via the community-supported conda-forge project ([https://conda-forge.org](https://conda-forge.org)),
    which can be specified via the `--channel conda-forge` flag. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Packages that are not available through the default conda channel or conda-forge
    can be installed via `pip` as explained earlier. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Packages for scientific computing, data science, and machine learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Throughout the first half of this book, we will mainly use NumPy’s multidimensional
    arrays to store and manipulate data. Occasionally, we will make use of pandas,
    which is a library built on top of NumPy that provides additional higher-level
    data manipulation tools that make working with tabular data even more convenient.
    To augment your learning experience and visualize quantitative data, which is
    often extremely useful to make sense of it, we will use the very customizable
    Matplotlib library.
  prefs: []
  type: TYPE_NORMAL
- en: The main machine learning library used in this book is scikit-learn (*Chapters
    3* to *11*). *Chapter 12*, *Parallelizing Neural Network Training with PyTorch*,
    will then introduce the PyTorch library for deep learning.
  prefs: []
  type: TYPE_NORMAL
- en: 'The version numbers of the major Python packages that were used to write this
    book are mentioned in the following list. Please make sure that the version numbers
    of your installed packages are, ideally, equal to these version numbers to ensure
    that the code examples run correctly:'
  prefs: []
  type: TYPE_NORMAL
- en: NumPy 1.21.2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: SciPy 1.7.0
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scikit-learn 1.0
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Matplotlib 3.4.3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: pandas 1.3.2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'After installing these packages, you can double-check the installed version
    by importing the package in Python and accessing its `__version__` attribute,
    for example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: For your convenience, we included a `python-environment-check.py` script in
    this book’s complimentary code repository at [https://github.com/rasbt/machine-learning-book](https://github.com/rasbt/machine-learning-book)
    so that you can check both your Python version and the package versions by executing
    this script.
  prefs: []
  type: TYPE_NORMAL
- en: Certain chapters will require additional packages and will provide information
    about the installations. For instance, do not worry about installing PyTorch at
    this point. *Chapter 12* will provide tips and instructions when you need them.
  prefs: []
  type: TYPE_NORMAL
- en: If you encounter errors even though your code matches the code in the chapter
    exactly, we recommend you first check the version numbers of the underlying packages
    before spending more time on debugging or reaching out to the publisher or authors.
    Sometimes, newer versions of libraries introduce backward-incompatible changes
    that could explain these errors.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you do not want to change the package version in your main Python installation,
    we recommend using a virtual environment for installing the packages used in this
    book. If you use Python without the conda manager, you can use the `venv` library
    to create a new virtual environment. For example, you can create and activate
    the virtual environment via the following two commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Note that you need to activate the virtual environment every time you open a
    new terminal or PowerShell. You can find more information about `venv` at [https://docs.python.org/3/library/venv.html](https://docs.python.org/3/library/venv.html).
  prefs: []
  type: TYPE_NORMAL
- en: 'If you are using Anaconda with the conda package manager, you can create and
    activate a virtual environment as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we explored machine learning at a very high level and familiarized
    ourselves with the big picture and major concepts that we are going to explore
    in the following chapters in more detail. We learned that supervised learning
    is composed of two important subfields: classification and regression. While classification
    models allow us to categorize objects into known classes, we can use regression
    analysis to predict the continuous outcomes of target variables. Unsupervised
    learning not only offers useful techniques for discovering structures in unlabeled
    data, but it can also be useful for data compression in feature preprocessing
    steps.'
  prefs: []
  type: TYPE_NORMAL
- en: We briefly went over the typical roadmap for applying machine learning to problem
    tasks, which we will use as a foundation for deeper discussions and hands-on examples
    in the following chapters. Finally, we set up our Python environment and installed
    and updated the required packages to get ready to see machine learning in action.
  prefs: []
  type: TYPE_NORMAL
- en: Later in this book, in addition to machine learning itself, we will introduce
    different techniques to preprocess a dataset, which will help you to get the best
    performance out of different machine learning algorithms. While we will cover
    classification algorithms quite extensively throughout the book, we will also
    explore different techniques for regression analysis and clustering.
  prefs: []
  type: TYPE_NORMAL
- en: We have an exciting journey ahead, covering many powerful techniques in the
    vast field of machine learning. However, we will approach machine learning one
    step at a time, building upon our knowledge gradually throughout the chapters
    of this book. In the following chapter, we will start this journey by implementing
    one of the earliest machine learning algorithms for classification, which will
    prepare us for *Chapter 3*, *A Tour of Machine Learning Classifiers Using Scikit-Learn*,
    where we will cover more advanced machine learning algorithms using the scikit-learn
    open-source machine learning library.
  prefs: []
  type: TYPE_NORMAL
- en: Join our book’s Discord space
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Join the book’s Discord workspace for a monthly *Ask me Anything* session with
    the authors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://packt.link/MLwPyTorch](https://packt.link/MLwPyTorch)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/QR_Code874410888448293359.png)'
  prefs: []
  type: TYPE_IMG
