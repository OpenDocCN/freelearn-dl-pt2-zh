- en: '1'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '1'
- en: Giving Computers the Ability to Learn from Data
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 赋予计算机从数据中学习的能力
- en: In my opinion, **machine learning**, the application and science of algorithms
    that make sense of data, is the most exciting field of all the computer sciences!
    We are living in an age where data comes in abundance; using self-learning algorithms
    from the field of machine learning, we can turn this data into knowledge. Thanks
    to the many powerful open-source libraries that have been developed in recent
    years, there has probably never been a better time to break into the machine learning
    field and learn how to utilize powerful algorithms to spot patterns in data and
    make predictions about future events.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在我看来，**机器学习**，即利用算法理解数据的应用与科学，是所有计算机科学领域中最激动人心的领域！我们生活在一个数据丰富的时代；利用来自机器学习领域的自学习算法，我们可以将这些数据转化为知识。多亏了近年来开发的许多强大开源库，现在可能是进入机器学习领域并学习如何利用强大算法来识别数据模式并对未来事件进行预测的最佳时机。
- en: In this chapter, you will learn about the main concepts and different types
    of machine learning. Together with a basic introduction to the relevant terminology,
    we will lay the groundwork for successfully using machine learning techniques
    for practical problem solving.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将了解主要概念和不同类型的机器学习。与相关术语的基本介绍一起，我们将为成功利用机器学习技术解决实际问题奠定基础。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: The general concepts of machine learning
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习的一般概念
- en: The three types of learning and basic terminology
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 三种学习类型和基本术语
- en: The building blocks for successfully designing machine learning systems
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 成功设计机器学习系统的构建模块
- en: Installing and setting up Python for data analysis and machine learning
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装和设置Python进行数据分析和机器学习
- en: Building intelligent machines to transform data into knowledge
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建智能机器以将数据转化为知识
- en: 'In this age of modern technology, there is one resource that we have in abundance:
    a large amount of structured and unstructured data. In the second half of the
    20th century, machine learning evolved as a subfield of **artificial intelligence**
    (**AI**) involving self-learning algorithms that derive knowledge from data to
    make predictions.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在现代技术时代，我们拥有大量结构化和非结构化数据资源。在20世纪下半叶，**人工智能**（**AI**）的一个子领域——机器学习，作为自学习算法的一部分，通过从数据中获取知识来进行预测逐渐发展起来。
- en: Instead of requiring humans to manually derive rules and build models from analyzing
    large amounts of data, machine learning offers a more efficient alternative for
    capturing the knowledge in data to gradually improve the performance of predictive
    models and make data-driven decisions.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 与要求人类手动推导规则并从分析大量数据中构建模型相比，机器学习提供了更高效的选择，即从数据中提取知识以逐步改进预测模型的性能并做出数据驱动的决策。
- en: Not only is machine learning becoming increasingly important in computer science
    research, but it is also playing an ever-greater role in our everyday lives. Thanks
    to machine learning, we enjoy robust email spam filters, convenient text and voice
    recognition software, reliable web search engines, recommendations on entertaining
    movies to watch, mobile check deposits, estimated meal delivery times, and much
    more. Hopefully, soon, we will add safe and efficient self-driving cars to this
    list. Also, notable progress has been made in medical applications; for example,
    researchers demonstrated that deep learning models can detect skin cancer with
    near-human accuracy ([https://www.nature.com/articles/nature21056](https://www.nature.com/articles/nature21056)).
    Another milestone was recently achieved by researchers at DeepMind, who used deep
    learning to predict 3D protein structures, outperforming physics-based approaches
    by a substantial margin ([https://deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology](https://deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology)).
    While accurate 3D protein structure prediction plays an essential role in biological
    and pharmaceutical research, there have been many other important applications
    of machine learning in healthcare recently. For instance, researchers designed
    systems for predicting the oxygen needs of COVID-19 patients up to four days in
    advance to help hospitals allocate resources for those in need ([https://ai.facebook.com/blog/new-ai-research-to-help-predict-covid-19-resource-needs-from-a-series-of-x-rays/](https://ai.facebook.com/blog/new-ai-research-to-help-predict-covid-19-resource-needs-from-a-series-of-x-rays/)).
    Another important topic of our day and age is climate change, which presents one
    of the biggest and most critical challenges. Today, many efforts are being directed
    toward developing intelligent systems to combat it ([https://www.forbes.com/sites/robtoews/2021/06/20/these-are-the-startups-applying-ai-to-tackle-climate-change](https://www.forbes.com/sites/robtoews/2021/06/20/these-are-the-startups-applying-ai-to-tackle-climate-change)).
    One of the many approaches to tackling climate change is the emergent field of
    precision agriculture. Here, researchers aim to design computer vision-based machine
    learning systems to optimize resource deployment to minimize the use and waste
    of fertilizers.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: The three different types of machine learning
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we will take a look at the three types of machine learning:
    **supervised learning**, **unsupervised learning**, and **reinforcement learning**.
    We will learn about the fundamental differences between the three different learning
    types and, using conceptual examples, we will develop an understanding of the
    practical problem domains where they can be applied:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface, text, application  Description automatically generated](img/B17582_01_01.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.1: The three different types of machine learning'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: Making predictions about the future with supervised learning
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The main goal in supervised learning is to learn a model from labeled training
    data that allows us to make predictions about unseen or future data. Here, the
    term “supervised” refers to a set of training examples (data inputs) where the
    desired output signals (labels) are already known. Supervised learning is then
    the process of modeling the relationship between the data inputs and the labels.
    Thus, we can also think of supervised learning as “label learning.”
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 1.2* summarizes a typical supervised learning workflow, where the labeled
    training data is passed to a machine learning algorithm for fitting a predictive
    model that can make predictions on new, unlabeled data inputs:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram  Description automatically generated](img/B17582_01_02.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.2: Supervised learning process'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: Considering the example of email spam filtering, we can train a model using
    a supervised machine learning algorithm on a corpus of labeled emails, which are
    correctly marked as spam or non-spam, to predict whether a new email belongs to
    either of the two categories. A supervised learning task with discrete class labels,
    such as in the previous email spam filtering example, is also called a **classification
    task**. Another subcategory of supervised learning is **regression**, where the
    outcome signal is a continuous value.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: Classification for predicting class labels
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Classification is a subcategory of supervised learning where the goal is to
    predict the categorical class labels of new instances or data points based on
    past observations. Those class labels are discrete, unordered values that can
    be understood as the group memberships of the data points. The previously mentioned
    example of email spam detection represents a typical example of a binary classification
    task, where the machine learning algorithm learns a set of rules to distinguish
    between two possible classes: spam and non-spam emails.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 1.3* illustrates the concept of a binary classification task given
    30 training examples; 15 training examples are labeled as class A and 15 training
    examples are labeled as class B. In this scenario, our dataset is two-dimensional,
    which means that each example has two values associated with it: *x*[1] and *x*[2].
    Now, we can use a supervised machine learning algorithm to learn a rule—the decision
    boundary represented as a dashed line—that can separate those two classes and
    classify new data into each of those two categories given its *x*[1] and *x*[2]
    values:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_01_03.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.3: Classifying a new data point'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: However, the set of class labels does not have to be of a binary nature. The
    predictive model learned by a supervised learning algorithm can assign any class
    label that was presented in the training dataset to a new, unlabeled data point
    or instance.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: A typical example of a **multiclass classification** task is handwritten character
    recognition. We can collect a training dataset that consists of multiple handwritten
    examples of each letter in the alphabet. The letters (“A,” “B,” “C,” and so on)
    will represent the different unordered categories or class labels that we want
    to predict. Now, if a user provides a new handwritten character via an input device,
    our predictive model will be able to predict the correct letter in the alphabet
    with certain accuracy. However, our machine learning system will be unable to
    correctly recognize any of the digits between 0 and 9, for example, if they were
    not part of the training dataset.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: Regression for predicting continuous outcomes
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We learned in the previous section that the task of classification is to assign
    categorical, unordered labels to instances. A second type of supervised learning
    is the prediction of continuous outcomes, which is also called **regression analysis**.
    In regression analysis, we are given a number of predictor (**explanatory**) variables
    and a continuous response variable (**outcome**), and we try to find a relationship
    between those variables that allows us to predict an outcome.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: Note that in the field of machine learning, the predictor variables are commonly
    called “features,” and the response variables are usually referred to as “target
    variables.” We will adopt these conventions throughout this book.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: For example, let’s assume that we are interested in predicting the math SAT
    scores of students. (The SAT is a standardized test frequently used for college
    admissions in the United States.) If there is a relationship between the time
    spent studying for the test and the final scores, we could use it as training
    data to learn a model that uses the study time to predict the test scores of future
    students who are planning to take this test.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: '**Regression toward the mean**'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: The term “regression” was devised by Francis Galton in his article *Regression
    towards Mediocrity in Hereditary Stature* in 1886\. Galton described the biological
    phenomenon that the variance of height in a population does not increase over
    time.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: He observed that the height of parents is not passed on to their children, but
    instead, their children’s height regresses toward the population mean.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 1.4* illustrates the concept of linear regression. Given a feature
    variable, *x*, and a target variable, *y*, we fit a straight line to this data
    that minimizes the distance—most commonly the average squared distance—between
    the data points and the fitted line.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now use the intercept and slope learned from this data to predict the
    target variable of new data:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: '![Chart, scatter chart  Description automatically generated](img/B17582_01_04.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.4: A linear regression example'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: Solving interactive problems with reinforcement learning
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Another type of machine learning is **reinforcement learning**. In reinforcement
    learning, the goal is to develop a system (**agent**) that improves its performance
    based on interactions with the environment. Since the information about the current
    state of the environment typically also includes a so-called **reward signal**,
    we can think of reinforcement learning as a field related to supervised learning.
    However, in reinforcement learning, this feedback is not the correct ground truth
    label or value, but a measure of how well the action was measured by a reward
    function. Through its interaction with the environment, an agent can then use
    reinforcement learning to learn a series of actions that maximizes this reward
    via an exploratory trial-and-error approach or deliberative planning.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: 'A popular example of reinforcement learning is a chess program. Here, the agent
    decides upon a series of moves depending on the state of the board (the environment),
    and the reward can be defined as **win** or **lose** at the end of the game:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram  Description automatically generated](img/B17582_01_05.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.5: Reinforcement learning process'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: There are many different subtypes of reinforcement learning. However, a general
    scheme is that the agent in reinforcement learning tries to maximize the reward
    through a series of interactions with the environment. Each state can be associated
    with a positive or negative reward, and a reward can be defined as accomplishing
    an overall goal, such as winning or losing a game of chess. For instance, in chess,
    the outcome of each move can be thought of as a different state of the environment.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: To explore the chess example further, let’s think of visiting certain configurations
    on the chessboard as being associated with states that will more likely lead to
    winning—for instance, removing an opponent’s chess piece from the board or threatening
    the queen. Other positions, however, are associated with states that will more
    likely result in losing the game, such as losing a chess piece to the opponent
    in the following turn. Now, in the game of chess, the reward (either positive
    for winning or negative for losing the game) will not be given until the end of
    the game. In addition, the final reward will also depend on how the opponent plays.
    For example, the opponent may sacrifice the queen but eventually win the game.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: In sum, reinforcement learning is concerned with learning to choose a series
    of actions that maximizes the total reward, which could be earned either immediately
    after taking an action or via *delayed* feedback.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: Discovering hidden structures with unsupervised learning
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In supervised learning, we know the right answer (the label or target variable)
    beforehand when we train a model, and in reinforcement learning, we define a measure
    of reward for particular actions carried out by the agent. In unsupervised learning,
    however, we are dealing with unlabeled data or data of an unknown structure. Using
    unsupervised learning techniques, we are able to explore the structure of our
    data to extract meaningful information without the guidance of a known outcome
    variable or reward function.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: Finding subgroups with clustering
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Clustering** is an exploratory data analysis or pattern discovery technique
    that allows us to organize a pile of information into meaningful subgroups (**clusters**)
    without having any prior knowledge of their group memberships. Each cluster that
    arises during the analysis defines a group of objects that share a certain degree
    of similarity but are more dissimilar to objects in other clusters, which is why
    clustering is also sometimes called **unsupervised classification**. Clustering
    is a great technique for structuring information and deriving meaningful relationships
    from data. For example, it allows marketers to discover customer groups based
    on their interests, in order to develop distinct marketing programs.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 1.6* illustrates how clustering can be applied to organizing unlabeled
    data into three distinct groups or clusters (A, B, and C, in arbitrary order)
    based on the similarity of their features, *x*[1] and *x*[2]:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram  Description automatically generated](img/B17582_01_06.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.6: How clustering works'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: Dimensionality reduction for data compression
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Another subfield of unsupervised learning is **dimensionality reduction**. Often,
    we are working with data of high dimensionality—each observation comes with a
    high number of measurements—that can present a challenge for limited storage space
    and the computational performance of machine learning algorithms. Unsupervised
    dimensionality reduction is a commonly used approach in feature preprocessing
    to remove noise from data, which can degrade the predictive performance of certain
    algorithms. Dimensionality reduction compresses the data onto a smaller dimensional
    subspace while retaining most of the relevant information.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: 'Sometimes, dimensionality reduction can also be useful for visualizing data;
    for example, a high-dimensional feature set can be projected onto one-, two-,
    or three-dimensional feature spaces to visualize it via 2D or 3D scatterplots
    or histograms. *Figure 1.7* shows an example where nonlinear dimensionality reduction
    was applied to compress a 3D Swiss roll onto a new 2D feature subspace:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_01_07.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.7: An example of dimensionality reduction from three to two dimensions'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to the basic terminology and notations
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have discussed the three broad categories of machine learning—supervised,
    unsupervised, and reinforcement learning—let’s have a look at the basic terminology
    that we will be using throughout this book. The following subsection covers the
    common terms we will be using when referring to different aspects of a dataset,
    as well as the mathematical notation to communicate more precisely and efficiently.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: As machine learning is a vast field and very interdisciplinary, you are guaranteed
    to encounter many different terms that refer to the same concepts sooner rather
    than later. The second subsection collects many of the most commonly used terms
    that are found in machine learning literature, which may be useful to you as a
    reference section when reading machine learning publications.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: Notation and conventions used in this book
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Figure 1.8* depicts an excerpt of the Iris dataset, which is a classic example
    in the field of machine learning (more information can be found at [https://archive.ics.uci.edu/ml/datasets/iris](https://archive.ics.uci.edu/ml/datasets/iris)).
    The Iris dataset contains the measurements of 150 Iris flowers from three different
    species—Setosa, Versicolor, and Virginica.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, each flower example represents one row in our dataset, and the flower
    measurements in centimeters are stored as columns, which we also call the **features**
    of the dataset:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram  Description automatically generated](img/B17582_01_08.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.8: The Iris dataset'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: To keep the notation and implementation simple yet efficient, we will make use
    of some of the basics of linear algebra. In the following chapters, we will use
    a matrix notation to refer to our data. We will follow the common convention to
    represent each example as a separate row in a feature matrix, **X**, where each
    feature is stored as a separate column.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: 'The Iris dataset, consisting of 150 examples and four features, can then be
    written as a 150×4 matrix, formally denoted as ![](img/B17582_01_001.png):'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_01_002.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
- en: '**Notational conventions**'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: For most parts of this book, unless noted otherwise, we will use the superscript
    *i* to refer to the *i*th training example, and the subscript *j* to refer to
    the *j*th dimension of the training dataset.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: We will use lowercase, bold-face letters to refer to vectors (![](img/B17582_01_003.png))
    and uppercase, bold-face letters to refer to matrices (![](img/B17582_01_004.png)).
    To refer to single elements in a vector or matrix, we will write the letters in
    italics (*x*^(^n^) or ![](img/B17582_01_005.png), respectively).
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, ![](img/B17582_01_006.png) refers to the first dimension of flower
    example 150, the sepal length. Each row in matrix **X** represents one flower
    instance and can be written as a four-dimensional row vector, ![](img/B17582_01_007.png):'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_01_008.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
- en: 'And each feature dimension is a 150-dimensional column vector, ![](img/B17582_01_009.png).
    For example:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_01_010.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
- en: 'Similarly, we can represent the target variables (here, class labels) as a
    150-dimensional column vector:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_01_011.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
- en: Machine learning terminology
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Machine learning is a vast field and also very interdisciplinary as it brings
    together many scientists from other areas of research. As it happens, many terms
    and concepts have been rediscovered or redefined and may already be familiar to
    you but appear under different names. For your convenience, in the following list,
    you can find a selection of commonly used terms and their synonyms that you may
    find useful when reading this book and machine learning literature in general:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: '**Training example**: A row in a table representing the dataset and synonymous
    with an observation, record, instance, or sample (in most contexts, sample refers
    to a collection of training examples).'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Training**: Model fitting, for parametric models similar to parameter estimation.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Feature, abbrev.** **x**: A column in a data table or data (design) matrix.
    Synonymous with predictor, variable, input, attribute, or covariate.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Target, abbrev.** **y**: Synonymous with outcome, output, response variable,
    dependent variable, (class) label, and ground truth.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Loss function**: Often used synonymously with a *cost* function. Sometimes
    the loss function is also called an *error* function. In some literature, the
    term “loss” refers to the loss measured for a single data point, and the cost
    is a measurement that computes the loss (average or summed) over the entire dataset.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A roadmap for building machine learning systems
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In previous sections, we discussed the basic concepts of machine learning and
    the three different types of learning. In this section, we will discuss the other
    important parts of a machine learning system accompanying the learning algorithm.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 1.9* shows a typical workflow for using machine learning in predictive
    modeling, which we will discuss in the following subsections:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram  Description automatically generated](img/B17582_01_09.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.9: Predictive modeling workflow'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: Preprocessing – getting data into shape
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s begin by discussing the roadmap for building machine learning systems.
    Raw data rarely comes in the form and shape that is necessary for the optimal
    performance of a learning algorithm. Thus, the preprocessing of the data is one
    of the most crucial steps in any machine learning application.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: If we take the Iris flower dataset from the previous section as an example,
    we can think of the raw data as a series of flower images from which we want to
    extract meaningful features. Useful features could be centered around the color
    of the flowers or the height, length, and width of the flowers.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: Many machine learning algorithms also require that the selected features are
    on the same scale for optimal performance, which is often achieved by transforming
    the features in the range [0, 1] or a standard normal distribution with zero mean
    and unit variance, as we will see in later chapters.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: Some of the selected features may be highly correlated and therefore redundant
    to a certain degree. In those cases, dimensionality reduction techniques are useful
    for compressing the features onto a lower-dimensional subspace. Reducing the dimensionality
    of our feature space has the advantage that less storage space is required, and
    the learning algorithm can run much faster. In certain cases, dimensionality reduction
    can also improve the predictive performance of a model if the dataset contains
    a large number of irrelevant features (or noise); that is, if the dataset has
    a low signal-to-noise ratio.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: To determine whether our machine learning algorithm not only performs well on
    the training dataset but also generalizes well to new data, we also want to randomly
    divide the dataset into separate training and test datasets. We use the training
    dataset to train and optimize our machine learning model, while we keep the test
    dataset until the very end to evaluate the final model.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: Training and selecting a predictive model
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As you will see in later chapters, many different machine learning algorithms
    have been developed to solve different problem tasks. An important point that
    can be summarized from David Wolpert’s famous *No free lunch theorems* is that
    we can’t get learning “for free” (*The Lack of A Priori Distinctions Between Learning
    Algorithms*, D.H. Wolpert, 1996; *No free lunch theorems for optimization*, D.H.
    Wolpert and W.G. Macready, 1997). We can relate this concept to the popular saying,
    *I suppose it is tempting, if the only tool you have is a hammer, to treat everything
    as if it were a nail* (Abraham Maslow, 1966). For example, each classification
    algorithm has its inherent biases, and no single classification model enjoys superiority
    if we don’t make any assumptions about the task. In practice, it is therefore
    essential to compare at least a handful of different learning algorithms in order
    to train and select the best performing model. But before we can compare different
    models, we first have to decide upon a metric to measure performance. One commonly
    used metric is classification accuracy, which is defined as the proportion of
    correctly classified instances.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: 'One legitimate question to ask is this: how do we know which model performs
    well on the final test dataset and real-world data if we don’t use this test dataset
    for the model selection, but keep it for the final model evaluation? To address
    the issue embedded in this question, different techniques summarized as “cross-validation”
    can be used. In cross-validation, we further divide a dataset into training and
    validation subsets in order to estimate the generalization performance of the
    model.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we also cannot expect that the default parameters of the different
    learning algorithms provided by software libraries are optimal for our specific
    problem task. Therefore, we will make frequent use of hyperparameter optimization
    techniques that help us to fine-tune the performance of our model in later chapters.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: We can think of those hyperparameters as parameters that are not learned from
    the data but represent the knobs of a model that we can turn to improve its performance.
    This will become much clearer in later chapters when we see actual examples.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: Evaluating models and predicting unseen data instances
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: After we have selected a model that has been fitted on the training dataset,
    we can use the test dataset to estimate how well it performs on this unseen data
    to estimate the so-called *generalization error*. If we are satisfied with its
    performance, we can now use this model to predict new, future data. It is important
    to note that the parameters for the previously mentioned procedures, such as feature
    scaling and dimensionality reduction, are solely obtained from the training dataset,
    and the same parameters are later reapplied to transform the test dataset, as
    well as any new data instances—the performance measured on the test data may be
    overly optimistic otherwise.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: Using Python for machine learning
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Python is one of the most popular programming languages for data science, and
    thanks to its very active developer and open-source community, a large number
    of useful libraries for scientific computing and machine learning have been developed.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: Although the performance of interpreted languages, such as Python, for computation-intensive
    tasks is inferior to lower-level programming languages, extension libraries such
    as NumPy and SciPy have been developed that build upon lower-layer Fortran and
    C implementations for fast vectorized operations on multidimensional arrays.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: For machine learning programming tasks, we will mostly refer to the scikit-learn
    library, which is currently one of the most popular and accessible open-source
    machine learning libraries. In the later chapters, when we focus on a subfield
    of machine learning called *deep learning*, we will use the latest version of
    the PyTorch library, which specializes in training so-called *deep neural network*
    models very efficiently by utilizing graphics cards.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: Installing Python and packages from the Python Package Index
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Python is available for all three major operating systems—Microsoft Windows,
    macOS, and Linux—and the installer, as well as the documentation, can be downloaded
    from the official Python website: [https://www.python.org](https://www.python.org).'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: The code examples provided in this book have been written for and tested in
    Python 3.9, and we generally recommend that you use the most recent version of
    Python 3 that is available. Some of the code may also be compatible with Python
    2.7, but as the official support for Python 2.7 ended in 2019, and the majority
    of open-source libraries have already stopped supporting Python 2.7 ([https://python3statement.org](https://python3statement.org)),
    we strongly advise that you use Python 3.9 or newer.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: You can check your Python version by executing
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: or
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: in your terminal (or PowerShell if you are using Windows).
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: The additional packages that we will be using throughout this book can be installed
    via the `pip` installer program, which has been part of the Python Standard Library
    since Python 3.3\. More information about `pip` can be found at [https://docs.python.org/3/installing/index.html](https://docs.python.org/3/installing/index.html).
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: 'After we have successfully installed Python, we can execute `pip` from the
    terminal to install additional Python packages:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Already installed packages can be updated via the `--upgrade` flag:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Using the Anaconda Python distribution and package manager
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A highly recommended open-source package management system for installing Python
    for scientific computing contexts is conda by Continuum Analytics. Conda is free
    and licensed under a permissive open-source license. Its goal is to help with
    the installation and version management of Python packages for data science, math,
    and engineering across different operating systems. If you want to use conda,
    it comes in different flavors, namely Anaconda, Miniconda, and Miniforge:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: Anaconda comes with many scientific computing packages pre-installed. The Anaconda
    installer can be downloaded at [https://docs.anaconda.com/anaconda/install/](https://docs.anaconda.com/anaconda/install/),
    and an Anaconda quick start guide is available at [https://docs.anaconda.com/anaconda/user-guide/getting-started/](https://docs.anaconda.com/anaconda/user-guide/getting-started/).
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Miniconda is a leaner alternative to Anaconda ([https://docs.conda.io/en/latest/miniconda.html](https://docs.conda.io/en/latest/miniconda.html)).
    Essentially, it is similar to Anaconda but without any packages pre-installed,
    which many people (including the authors) prefer.
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Miniforge is similar to Miniconda but community-maintained and uses a different
    package repository (conda-forge) from Miniconda and Anaconda. We found that Miniforge
    is a great alternative to Miniconda. Download and installation instructions can
    be found in the GitHub repository at [https://github.com/conda-forge/miniforge](https://github.com/conda-forge/miniforge).
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'After successfully installing conda through either Anaconda, Miniconda, or
    Miniforge, we can install new Python packages using the following command:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Existing packages can be updated using the following command:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Packages that are not available through the official conda channel might be
    available via the community-supported conda-forge project ([https://conda-forge.org](https://conda-forge.org)),
    which can be specified via the `--channel conda-forge` flag. For example:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 通过社区支持的conda-forge项目（[https://conda-forge.org](https://conda-forge.org)）可能会提供不在官方conda频道中的包，可以通过`--channel
    conda-forge`标志指定。例如：
- en: '[PRE6]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Packages that are not available through the default conda channel or conda-forge
    can be installed via `pip` as explained earlier. For example:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 不能通过默认的conda频道或conda-forge获取的包可以通过`pip`安装，如前所述。例如：
- en: '[PRE7]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Packages for scientific computing, data science, and machine learning
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 用于科学计算、数据科学和机器学习的包
- en: Throughout the first half of this book, we will mainly use NumPy’s multidimensional
    arrays to store and manipulate data. Occasionally, we will make use of pandas,
    which is a library built on top of NumPy that provides additional higher-level
    data manipulation tools that make working with tabular data even more convenient.
    To augment your learning experience and visualize quantitative data, which is
    often extremely useful to make sense of it, we will use the very customizable
    Matplotlib library.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的前半部分，我们主要使用NumPy的多维数组来存储和操作数据。偶尔，我们将使用建立在NumPy之上的pandas库，它提供了额外的高级数据操作工具，使得处理表格数据变得更加方便。为了增强您的学习体验并可视化定量数据，Matplotlib库是非常可定制化的，对于理解数据非常有帮助。
- en: The main machine learning library used in this book is scikit-learn (*Chapters
    3* to *11*). *Chapter 12*, *Parallelizing Neural Network Training with PyTorch*,
    will then introduce the PyTorch library for deep learning.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 本书主要使用的机器学习库是scikit-learn（*第3章*至*第11章*）。*第12章*，“使用PyTorch并行化神经网络训练”，将介绍深度学习库PyTorch。
- en: 'The version numbers of the major Python packages that were used to write this
    book are mentioned in the following list. Please make sure that the version numbers
    of your installed packages are, ideally, equal to these version numbers to ensure
    that the code examples run correctly:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 编写本书所用的主要Python包的版本号列在以下列表中。请确保您安装的包的版本号与这些版本号理想情况下相等，以确保代码示例正确运行：
- en: NumPy 1.21.2
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NumPy 1.21.2
- en: SciPy 1.7.0
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SciPy 1.7.0
- en: Scikit-learn 1.0
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Scikit-learn 1.0
- en: Matplotlib 3.4.3
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Matplotlib 3.4.3
- en: pandas 1.3.2
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: pandas 1.3.2
- en: 'After installing these packages, you can double-check the installed version
    by importing the package in Python and accessing its `__version__` attribute,
    for example:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 安装这些包后，您可以通过在Python中导入包并访问其`__version__`属性来再次检查安装的版本，例如：
- en: '[PRE8]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: For your convenience, we included a `python-environment-check.py` script in
    this book’s complimentary code repository at [https://github.com/rasbt/machine-learning-book](https://github.com/rasbt/machine-learning-book)
    so that you can check both your Python version and the package versions by executing
    this script.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 为了方便起见，我们在本书的免费代码存储库[https://github.com/rasbt/machine-learning-book](https://github.com/rasbt/machine-learning-book)中包含了一个名为`python-environment-check.py`的脚本，这样您可以通过执行此脚本检查您的Python版本和包版本。
- en: Certain chapters will require additional packages and will provide information
    about the installations. For instance, do not worry about installing PyTorch at
    this point. *Chapter 12* will provide tips and instructions when you need them.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 某些章节将需要额外的包，并将提供有关安装的信息。例如，目前不需要安装PyTorch。*第12章*将在需要时提供提示和说明。
- en: If you encounter errors even though your code matches the code in the chapter
    exactly, we recommend you first check the version numbers of the underlying packages
    before spending more time on debugging or reaching out to the publisher or authors.
    Sometimes, newer versions of libraries introduce backward-incompatible changes
    that could explain these errors.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 如果尽管您的代码与章节中的代码完全相同仍然遇到错误，请先检查底层包的版本号，然后再花时间调试或与出版商或作者联系。有时，库的新版本引入了不向后兼容的更改，这可能解释这些错误。
- en: 'If you do not want to change the package version in your main Python installation,
    we recommend using a virtual environment for installing the packages used in this
    book. If you use Python without the conda manager, you can use the `venv` library
    to create a new virtual environment. For example, you can create and activate
    the virtual environment via the following two commands:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Note that you need to activate the virtual environment every time you open a
    new terminal or PowerShell. You can find more information about `venv` at [https://docs.python.org/3/library/venv.html](https://docs.python.org/3/library/venv.html).
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: 'If you are using Anaconda with the conda package manager, you can create and
    activate a virtual environment as follows:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Summary
  id: totrans-155
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we explored machine learning at a very high level and familiarized
    ourselves with the big picture and major concepts that we are going to explore
    in the following chapters in more detail. We learned that supervised learning
    is composed of two important subfields: classification and regression. While classification
    models allow us to categorize objects into known classes, we can use regression
    analysis to predict the continuous outcomes of target variables. Unsupervised
    learning not only offers useful techniques for discovering structures in unlabeled
    data, but it can also be useful for data compression in feature preprocessing
    steps.'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: We briefly went over the typical roadmap for applying machine learning to problem
    tasks, which we will use as a foundation for deeper discussions and hands-on examples
    in the following chapters. Finally, we set up our Python environment and installed
    and updated the required packages to get ready to see machine learning in action.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: Later in this book, in addition to machine learning itself, we will introduce
    different techniques to preprocess a dataset, which will help you to get the best
    performance out of different machine learning algorithms. While we will cover
    classification algorithms quite extensively throughout the book, we will also
    explore different techniques for regression analysis and clustering.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: We have an exciting journey ahead, covering many powerful techniques in the
    vast field of machine learning. However, we will approach machine learning one
    step at a time, building upon our knowledge gradually throughout the chapters
    of this book. In the following chapter, we will start this journey by implementing
    one of the earliest machine learning algorithms for classification, which will
    prepare us for *Chapter 3*, *A Tour of Machine Learning Classifiers Using Scikit-Learn*,
    where we will cover more advanced machine learning algorithms using the scikit-learn
    open-source machine learning library.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: Join our book’s Discord space
  id: totrans-160
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Join the book’s Discord workspace for a monthly *Ask me Anything* session with
    the authors:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: '[https://packt.link/MLwPyTorch](https://packt.link/MLwPyTorch)'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/QR_Code874410888448293359.png)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
