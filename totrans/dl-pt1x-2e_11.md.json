["```py\nclass ResNetBlock(nn.Module):\n    def __init__(self,in_channels,output_channels,stride):\n        super().__init__()\n        self.convolutional_1 = nn.Conv2d(input_channels,output_channels,kernel_size=3,stride=stride,padding=1,bias=False)\n        self.bn1 = nn.BatchNorm2d(output_channels)\n        self.convolutional_2 = nn.Conv2d(output_channels,output_channels,kernel_size=3,stride=stride,padding=1,bias=False)\n        self.bn2 = nn.BatchNorm2d(output_channels)\n        self.stride = stride\n    def forward(self,x):\n        residual = x\n       out = self.convolutional_1(x)\n        out = F.relu(self.bn1(out),inplace=True)\n        out = self.convolutional_2(out)\n        out = self.bn2(out)\n        out += residual\n        return F.relu(out)        \n```", "```py\nfrom torchvision.models import resnet18\nresnet_model = resnet18(pretrained=False)\n```", "```py\ntransform_data = transforms.Compose([\n        transforms.Resize((299,299)),\n        tansforms.ToTensor(),\n        transforms.Normalize([0.30, 0.40, 0.40], [0.20, 0.20, 0.20])\n    ])\n\ntrain_dataset = ImageFolder('../Chapter03/Dog-Cat-Classifier/Data/Train_Data/train/',transform=transform_data)\nvalidation_dataset = ImageFolder('../Chapter03/Dog-Cat-Classifier/Data/Train_Data/valid/',transform=transform_data)\nclasses=2\n```", "```py\ntraining_data_loader = DataLoader(train_dataset,batch_size=32,shuffle=False,num_workers=4)\nvalidation_data_loader = DataLoader(validation_dataset,batch_size=32,shuffle=False,num_workers=4)\n```", "```py\nresnet_model = resnet34(pretrained=True)\n```", "```py\nm = nn.Sequential(*list(resnet_model.children())[:-1])\n```", "```py\nfor p in resnet_model.parameters():\n   p.requires_grad = False\n```", "```py\n# Stores the labels of the train data\ntraining_data_labels = [] \n# Stores the pre convoluted features of the train data\ntraining_features = [] \n```", "```py\nfor d,la in training_data_loader:\n    o = m(Variable(d))\n    o = o.view(o.size(0),-1)\n    training_data_labels.extend(la)\n    training_features.extend(o.data)\n```", "```py\nvalidation_data_labels = []\nvalidation_features = []\nfor d,la in validation_data_loader:\n    o = m(Variable(d))\n    o = o.view(o.size(0),-1)\n    validation_data_labels.extend(la)\n    validation_features.extend(o.data)\n```", "```py\nclass FeaturesDataset(Dataset):\n    def __init__(self,features_list,labels_list):\n        self.features_list = features_list\n        self.labels_list = labels_list\n    def __getitem__(self,index):\n        return (self.features_lst[index],self.labels_list[index])\n    def __len__(self):\n        return len(self.labels_list)\n#Creating dataset for train and validation\ntrain_features_dataset = FeaturesDataset(training_features,training_data_labels)\nvalidation_features_dataset = FeaturesDataset(validation_features,validation_data_labels)\n```", "```py\ntrain_features_loader = DataLoader(train_features_dataset,batch_size=64,shuffle=True)\nvalidation_features_loader = DataLoader(validation_features_dataset,batch_size=64)\n```", "```py\nclass FullyConnectedLinearModel(nn.Module):\n    def __init__(self,input_size,output_size):\n        super().__init__()\n        self.fc = nn.Linear(input_size,output_size)\n\n    def forward(self,inp):\n        out = self.fc(inp)\n        return out\n\nfully_connected_in_size = 8192\n\nfc = FullyConnectedLinearModel(fully_connected_in_size,classes)\nif is_cuda:\n    fc = fc.cuda()\n```", "```py\ntrain_losses , train_accuracy = [],[]\nvalidation_losses , validation_accuracy = [],[]\nfor epoch in range(1,20):\n    epoch_loss, epoch_accuracy = fit(epoch,fc,train_features_loader,phase='training')\n    validation_epoch_loss , validation_epoch_accuracy = fit(epoch,fc,validation_features_loader,phase='validation')\n    train_losses.append(epoch_loss)\n    train_accuracy.append(epoch_accuracy)\n    validation_losses.append(validation_epoch_loss)\n    validation_accuracy.append(validation_epoch_accuracy)\n```", "```py\nclass BasicConvolutional2d(nn.Module):\n\n    def __init__(self, input_channels, output_channels, **kwargs):\n        super(BasicConv2d, self).__init__()\n        self.conv = nn.Conv2d(input_channels, output_channels, bias=False, **kwargs)\n        self.bn = nn.BatchNorm2d(output_channels)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.bn(x)\n        return F.relu(x, inplace=True)\n\nclass InceptionBlock(nn.Module):\n\n    def __init__(self, input_channels, pool_features):\n        super().__init__()\n        self.inception_branch_1x1 = BasicConv2d(input_channels, 64, kernel_size=1)\n\n        self.inception_branch_5x5_1 = BasicConv2d(input_channels, 48, kernel_size=1)\n        self.inception_branch_5x5_2 = BasicConv2d(48, 64, kernel_size=5, padding=2)\n\n        self.inception_branch_3x3dbl_1 = BasicConv2d(input_channels, 64, kernel_size=1)\n        self.inception_branch_3x3dbl_2 = BasicConv2d(64, 96, kernel_size=3, padding=1)\n\n        self.inception_branch_pool = BasicConv2d(input_channels, pool_features, kernel_size=1)\n\n    def forward(self, x):\n        inception_branch_1x1 = self.inception_branch1x1(x)\n\n        inception_branch_5x5 = self.inception_branch_5x5_1(x)\n        inception_branch_5x5 = self.inception_branch_5x5_2(branch5x5)\n\n        inception_branch_3x3dbl = self.inception_branch_3x3dbl_1(x)\n        inception_branch_3x3dbl = self.inception_branch_3x3dbl_2(inception_branch3x3dbl)\n\n        branch_pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1)\n        branch_pool = self.branch_pool(branch_pool)\n\n        outputs = [inception_branch_1x1, inception_branch_5x5, inception_branch_3x3dbl, inception_branch_pool]\n        return torch.cat(outputs, 1)\n```", "```py\ninception_branch_1x1 = self.inception_branch_1x1(x)\n```", "```py\ninception_branch_5x5 = self.inception_branch_5x5_1(x)\ninception_branch_5x5 = self.inception_branch_5x5_2(inception_branch5x5)\n```", "```py\ninception_branch_3x3dbl = self.inception_branch_3x3dbl_1(x)\ninception_branch_3x3dbl = self.inception_branch_3x3dbl_2(inception_branch3x3dbl)\n```", "```py\nbranch_pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1)\nbranch_pool = self.branch_pool(branch_pool)\n```", "```py\ninception_model = inception_v3(pretrained=True)\ninception_model.aux_logits = False\nif is_cuda:\n   inception_model = inception_model.cuda()\n```", "```py\nclass LayerActivations():\n   features=[]\n\n   def __init__(self,model):\n       self.features = []\n       self.hook = model.register_forward_hook(self.hook_function)\n\n   def hook_function(self,module,input,output):\n\n       self.features.extend(output.view(output.size(0),-1).cpu().data)\n\n   def remove(self):\n\n       self.hook.remove()\n```", "```py\n# Create LayerActivations object to store the output of inception model at a particular layer.\ntrain_features = LayerActivations(inception_model.Mixed_7c)\ntrain_labels = []\n\n# Passing all the data through the model , as a side effect the outputs will get stored\n# in the features list of the LayerActivations object.\nfor da,la in train_loader:\n   _ = inception_model(Variable(da.cuda()))\n   train_labels.extend(la)\ntrain_features.remove()\n\n# Repeat the same process for validation dataset .\n\nvalidation_features = LayerActivations(inception_model.Mixed_7c)\nvalidation_labels = []\nfor da,la in validation_loader:\n   _ = inception_model(Variable(da.cuda()))\n   validation_labels.extend(la)\nvalidation_features.remove()\n```", "```py\n#Dataset for pre computed features for train and validation data sets\n\ntrain_feat_dset = FeaturesDataset(train_features.features,train_labels)\nvalidation_feat_dset = FeaturesDataset(validation_features.features,validation_labels)\n\n#Data loaders for pre computed features for train and validation data sets\n\ntrain_feat_loader = DataLoader(train_feat_dset,batch_size=64,shuffle=True)\nvalidation_feat_loader = DataLoader(validation_feat_dset,batch_size=64)\n```", "```py\nclass FullyConnectedModel(nn.Module):\n\n    def __init__(self,input_size,output_size,training=True):\n        super().__init__()\n        self.fully_connected = nn.Linear(input_size,output_size)\n\n    def forward(self,input):\n        output = F.dropout(input, training=self.training)\n        output = self.fully_connected(output)\n        return output\n\n# The size of the output from the selected convolution feature\nfc_in_size = 131072\n\nfc = FullyConnectedModel(fc_in_size,classes)\nif is_cuda:\n   fc = fc.cuda()\n```", "```py\nfor epoch in range(1,10):\n   epoch_loss, epoch_accuracy = fit(epoch,fc,train_feat_loader,phase='training')\n   validation_epoch_loss , validation_epoch_accuracy = fit(epoch,fc,validation_feat_loader,phase='validation')\n   train_losses.append(epoch_loss)\n   train_accuracy.append(epoch_accuracy)\n   validation_losses.append(validation_epoch_loss)\n   validation_accuracy.append(validation_epoch_accuracy)\n```", "```py\ntraining loss is 0.78 and training accuracy is 22825/23000 99.24\nvalidation loss is 5.3 and validation accuracy is 1947/2000 97.35\ntraining loss is 0.84 and training accuracy is 22829/23000 99.26\nvalidation loss is 5.1 and validation accuracy is 1952/2000 97.6\ntraining loss is 0.69 and training accuracy is 22843/23000 99.32\nvalidation loss is 5.1 and validation accuracy is 1951/2000 97.55\ntraining loss is 0.58 and training accuracy is 22852/23000 99.36\nvalidation loss is 4.9 and validation accuracy is 1953/2000 97.65\ntraining loss is 0.67 and training accuracy is 22862/23000 99.4\nvalidation loss is 4.9 and validation accuracy is 1955/2000 97.75\ntraining loss is 0.54 and training accuracy is 22870/23000 99.43\nvalidation loss is 4.8 and validation accuracy is 1953/2000 97.65\ntraining loss is 0.56 and training accuracy is 22856/23000 99.37\nvalidation loss is 4.8 and validation accuracy is 1955/2000 97.75\ntraining loss is 0.7 and training accuracy is 22841/23000 99.31\nvalidation loss is 4.8 and validation accuracy is 1956/2000 97.8\ntraining loss is 0.47 and training accuracy is 22880/23000 99.48\nvalidation loss is 4.7 and validation accuracy is 1956/2000 97.8\n```", "```py\nclass _DenseBlock(nn.Sequential):\n    def __init__(self, number_layers, number_input_features, bn_size, growth_rate, drop_rate):\n        super(_DenseBlock, self).__init__()\n        for i in range(number_layers):\n            layer = _DenseLayer(number_input_features + i * growth_rate, growth_rate, bn_size, drop_rate)\n            self.add_module('denselayer%d' % (i + 1), layer)\n```", "```py\nclass _DenseLayer(nn.Sequential):\n   def __init__(self, number_input_features, growth_rate, bn_size, drop_rate):\n       super(_DenseLayer, self).__init__()\n       self.add_module('norm.1', nn.BatchNorm2d(number_input_features)),\n       self.add_module('relu.1', nn.ReLU(inplace=True)),\n       self.add_module('conv.1', nn.Conv2d(number_input_features, bn_size *\n                       growth_rate, kernel_size=1, stride=1, bias=False)),\n       self.add_module('norm.2', nn.BatchNorm2d(bn_size * growth_rate)),\n       self.add_module('relu.2', nn.ReLU(inplace=True)),\n       self.add_module('conv.2', nn.Conv2d(bn_size * growth_rate, growth_rate,\n                       kernel_size=3, stride=1, padding=1, bias=False)),\n       self.drop_rate = drop_rate\n\n   def forward(self, x):\n       new_features = super(_DenseLayer, self).forward(x)\n       if self.drop_rate > 0:\n           new_features = F.dropout(new_features, p=self.drop_rate, training=self.training)\n       return torch.cat([x, new_features], 1)\n```", "```py\ndef forward(self, input):\n   for module in self._modules.values():\n       input = module(input)\n   return input\n```", "```py\ndensenet_model = densenet121(pretrained=True).features\nif is_cuda:\n   densenet_model = densenet_model.cuda()\n\nfor p in densenet_model.parameters():\n   p.requires_grad = False\n```", "```py\n#For training data\ntrain_labels = []\ntrain_features = []\n\n#code to store densenet features for train dataset.\nfor d,la in train_loader:\n   o = densenet_model(Variable(d.cuda()))\n   o = o.view(o.size(0),-1)\n   train_labels.extend(la)\n   train_features.extend(o.cpu().data)\n\n#For validation data\nvalidation_labels = []\nvalidation_features = []\n\n#Code to store densenet features for validation dataset.\nfor d,la in validation_loader:\n   o = densenet_model(Variable(d.cuda()))\n   o = o.view(o.size(0),-1)\n   validation_labels.extend(la)\n   validation_features.extend(o.cpu().data)\n```", "```py\n# Create dataset for train and validation convolution features\ntrain_feat_dset = FeaturesDataset(train_features,train_labels)\nvalidation_feat_dset = FeaturesDataset(validation_features,validation_labels)\n\n# Create data loaders for batching the train and validation datasets\ntrain_feat_loader = DataLoader(train_feat_dset,batch_size=64,shuffle=True,drop_last=True)\nvalidation_feat_loader = DataLoader(validation_feat_dset,batch_size=64)\n```", "```py\nclass FullyConnectedModel(nn.Module):\n\n    def __init__(self,input_size,output_size):\n        super().__init__()\n        self.fc = nn.Linear(input_size,output_size)\n\n    def forward(self,input):\n        output = self.fc(input)\n        return output\n\nfc = FullyConnectedModel(fc_in_size,classes)\nif is_cuda:\n   fc = fc.cuda()\n```", "```py\ntrain_losses , train_accuracy = [],[]\nvalidation_losses , validation_accuracy = [],[]\nfor epoch in range(1,10):\n   epoch_loss, epoch_accuracy = fit(epoch,fc,train_feat_loader,phase='training')\n   validation_epoch_loss , validation_epoch_accuracy = fit(epoch,fc,validation_feat_loader,phase='validation')\n   train_losses.append(epoch_loss)\n   train_accuracy.append(epoch_accuracy)\n   validation_losses.append(validation_epoch_loss)\n   validation_accuracy.append(validation_epoch_accuracy)\n```", "```py\ntraining loss is 0.057 and training accuracy is 22506/23000 97.85\nvalidation loss is 0.034 and validation accuracy is 1978/2000 98.9\ntraining loss is 0.0059 and training accuracy is 22953/23000 99.8\nvalidation loss is 0.028 and validation accuracy is 1981/2000 99.05\ntraining loss is 0.0016 and training accuracy is 22974/23000 99.89\nvalidation loss is 0.022 and validation accuracy is 1983/2000 99.15\ntraining loss is 0.00064 and training accuracy is 22976/23000 99.9\nvalidation loss is 0.023 and validation accuracy is 1983/2000 99.15\ntraining loss is 0.00043 and training accuracy is 22976/23000 99.9\nvalidation loss is 0.024 and validation accuracy is 1983/2000 99.15\ntraining loss is 0.00033 and training accuracy is 22976/23000 99.9\nvalidation loss is 0.024 and validation accuracy is 1984/2000 99.2\ntraining loss is 0.00025 and training accuracy is 22976/23000 99.9\nvalidation loss is 0.024 and validation accuracy is 1984/2000 99.2\ntraining loss is 0.0002 and training accuracy is 22976/23000 99.9\nvalidation loss is 0.025 and validation accuracy is 1985/2000 99.25\ntraining loss is 0.00016 and training accuracy is 22976/23000 99.9\nvalidation loss is 0.024 and validation accuracy is 1986/2000 99.3\n```", "```py\nresnet_model = resnet34(pretrained=True)\n\nif is_cuda:\n   resnet_model = resnet_model.cuda()\n\nresnet_model = nn.Sequential(*list(resnet_model.children())[:-1])\n\nfor p in resnet_model.parameters():\n   p.requires_grad = False\n```", "```py\ninception_model = inception_v3(pretrained=True)\ninception_model.aux_logits = False\nif is_cuda:\n   inception_model = inception_model.cuda()\nfor p in inception_model.parameters():\n   p.requires_grad = False\n```", "```py\ndensenet_model = densenet121(pretrained=True).features\nif is_cuda:\n   densenet_model = densenet_model.cuda()\n\nfor p in densenet_model.parameters():\n   p.requires_grad = False\n```", "```py\ntrain_labels = []\ntrain_resnet_features = []\nfor d,la in train_loader:\n   o = resnet_model(Variable(d.cuda()))\n   o = o.view(o.size(0),-1)\n   train_labels.extend(la)\n   train_resnet_features.extend(o.cpu().data)\nvalidation_labels = []\nvalidation_resnet_features = []\nfor d,la in validation_loader:\n   o = resnet_model(Variable(d.cuda()))\n   o = o.view(o.size(0),-1)\n   validation_labels.extend(la)\n   validation_resnet_features.extend(o.cpu().data)\n```", "```py\ntrain_inception_features = LayerActivations(inception_model.Mixed_7c)\nfor da,la in train_loader:\n   _ = inception_model(Variable(da.cuda()))\n\ntrain_inception_features.remove()\n\nvalidation_inception_features = LayerActivations(inception_model.Mixed_7c)\nfor da,la in validation_loader:\n   _ = inception_model(Variable(da.cuda()))\n\nvalidation_inception_features.remove()\n```", "```py\ntrain_densenet_features = []\nfor d,la in train_loader:\n   o = densnet_model(Variable(d.cuda()))\n   o = o.view(o.size(0),-1)\n\n   train_densenet_features.extend(o.cpu().data)\n\nvalidation_densenet_features = []\nfor d,la in validation_loader:\n   o = densnet_model(Variable(d.cuda()))\n   o = o.view(o.size(0),-1)\n   validation_densenet_features.extend(o.cpu().data)\n```", "```py\nclass FeaturesDataset(Dataset):\n   def __init__(self,featlst1,featlst2,featlst3,labellst):\n       self.featlst1 = featlst1\n       self.featlst2 = featlst2\n       self.featlst3 = featlst3\n       self.labellst = labellst\n\n   def __getitem__(self,index):\n       return (self.featlst1[index],self.featlst2[index],self.featlst3[index],self.labellst[index])\n\n   def __len__(self):\n       return len(self.labellst)\n\ntrain_feat_dset = FeaturesDataset(train_resnet_features,train_inception_features.features,train_densenet_features,train_labels)\nvalidation_feat_dset = FeaturesDataset(validation_resnet_features,validation_inception_features.features,validation_densenet_features,validation_labels)\n```", "```py\ntrain_feat_loader = DataLoader(train_feat_dset,batch_size=64,shuffle=True)\nvalidation_feat_loader = DataLoader(validation_feat_dset,batch_size=64)\n```", "```py\nclass EnsembleModel(nn.Module):\n\n    def __init__(self,output_size,training=True):\n        super().__init__()\n        self.fully_connected1 = nn.Linear(8192,512)\n        self.fully_connected2 = nn.Linear(131072,512)\n        self.fully_connected3 = nn.Linear(82944,512)\n        self.fully_connected4 = nn.Linear(512,output_size)\n\n    def forward(self,input1,input2,input3):\n        output1 = self.fully_connected1(F.dropout(input1,training=self.training))\n        output2 = self.fully_connected2(F.dropout(input2,training=self.training))\n        output3 = self.fully_connected3(F.dropout(input3,training=self.training))\n        output = output1 + output2 + output3\n        output = self.fully_connected4(F.dropout(out,training=self.training))\n        return output\n\nem = EnsembleModel(2)\nif is_cuda:\n   em = em.cuda()\n```", "```py\ndef fit(epoch,model,data_loader,phase='training',volatile=False):\n   if phase == 'training':\n       model.train()\n   if phase == 'validation':\n       model.eval()\n       volatile=True\n   running_loss = 0.0\n   running_correct = 0\n   for batch_idx , (data1,data2,data3,target) in enumerate(data_loader):\n       if is_cuda:\n           data1,data2,data3,target = data1.cuda(),data2.cuda(),data3.cuda(),target.cuda()\n       data1,data2,data3,target = Variable(data1,volatile),Variable(data2,volatile),Variable(data3,volatile),Variable(target)\n       if phase == 'training':\n           optimizer.zero_grad()\n       output = model(data1,data2,data3)\n       loss = F.cross_entropy(output,target)\n\n       running_loss += F.cross_entropy(output,target,size_average=False).data[0]\n       preds = output.data.max(dim=1,keepdim=True)[1]\n       running_correct += preds.eq(target.data.view_as(preds)).cpu().sum()\n       if phase == 'training':\n           loss.backward()\n           optimizer.step()\n\n   loss = running_loss/len(data_loader.dataset)\n   accuracy = 100\\. * running_correct/len(data_loader.dataset)\n\n   print(f'{phase} loss is {loss:{5}.{2}} and {phase} accuracy is {running_correct}/{len(data_loader.dataset)}{accuracy:{10}.{4}}')\n   return loss,accuracy\n```", "```py\ntrain_losses , train_accuracy = [],[]\nvalidation_losses , validation_accuracy = [],[]\nfor epoch in range(1,10):\n    epoch_loss, epoch_accuracy = fit(epoch,em,trn_feat_loader,phase='training')\n    validation_epoch_loss , validation_epoch_accuracy = fit(epoch,em,validation_feat_loader,phase='validation')\n    train_losses.append(epoch_loss)\n    train_accuracy.append(epoch_accuracy)\n    validation_losses.append(validation_epoch_loss)\n    validation_accuracy.append(validation_epoch_accuracy)\n```", "```py\ntraining loss is 7.2e+01 and training accuracy is 21359/23000 92.87\nvalidation loss is 6.5e+01 and validation accuracy is 1968/2000 98.4\ntraining loss is 9.4e+01 and training accuracy is 22539/23000 98.0\nvalidation loss is 1.1e+02 and validation accuracy is 1980/2000 99.0\ntraining loss is 1e+02 and training accuracy is 22714/23000 98.76\nvalidation loss is 1.4e+02 and validation accuracy is 1976/2000 98.8\ntraining loss is 7.3e+01 and training accuracy is 22825/23000 99.24\nvalidation loss is 1.6e+02 and validation accuracy is 1979/2000 98.95\ntraining loss is 7.2e+01 and training accuracy is 22845/23000 99.33\nvalidation loss is 2e+02 and validation accuracy is 1984/2000 99.2\ntraining loss is 1.1e+02 and training accuracy is 22862/23000 99.4\nvalidation loss is 4.1e+02 and validation accuracy is 1975/2000 98.75\ntraining loss is 1.3e+02 and training accuracy is 22851/23000 99.35\nvalidation loss is 4.2e+02 and validation accuracy is 1981/2000 99.05\ntraining loss is 2e+02 and training accuracy is 22845/23000 99.33\nvalidation loss is 6.1e+02 and validation accuracy is 1982/2000 99.1\ntraining loss is 1e+02 and training accuracy is 22917/23000 99.64\nvalidation loss is 5.3e+02 and validation accuracy is 1986/2000 99.3\n```"]