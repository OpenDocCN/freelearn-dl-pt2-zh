- en: '1'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '1'
- en: Deconstructing the Training Process
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 拆解训练过程
- en: We already know that training neural network models takes a long time to finish.
    Otherwise, we would not be here discussing ways to run this process faster. But
    which characteristics make the building process of these models so computationally
    heavy? Why does the training step take so long? To answer these questions, we
    need to understand the computational burden of the training phase.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经知道训练神经网络模型需要很长时间才能完成。否则，我们不会在这里讨论如何更快地运行这个过程。但是，是什么特征使得这些模型的构建过程如此计算密集呢？为什么训练步骤如此耗时？要回答这些问题，我们需要理解训练阶段的计算负担。
- en: In this chapter, we will first remember how the training phase works under the
    hood. We will understand what makes the training process so computationally heavy.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们首先要记住训练阶段是如何在底层运行的。我们将理解什么使训练过程如此计算密集。
- en: 'Here is what you will learn as part of this first chapter:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是您将在本章的学习中了解到的内容：
- en: Remembering the training process
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 记住训练过程
- en: Understanding the computational burden of the training phase
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解训练阶段的计算负担
- en: Understanding the factors that influence training time
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解影响训练时间的因素
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: You can find the complete code of the examples mentioned in this chapter in
    the book’s GitHub repository at [https://github.com/PacktPublishing/Accelerate-Model-Training-with-PyTorch-2.X/blob/main](https://github.com/PacktPublishing/Accelerate-Model-Training-with-PyTorch-2.X/blob/main).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在本章提到的示例的完整代码在书的GitHub仓库中找到，链接为[https://github.com/PacktPublishing/Accelerate-Model-Training-with-PyTorch-2.X/blob/main](https://github.com/PacktPublishing/Accelerate-Model-Training-with-PyTorch-2.X/blob/main)。
- en: You can access your favorite environment to execute this notebook, such as Google
    Colab or Kaggle.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以访问您喜爱的环境来执行这个笔记本，比如Google Colab或Kaggle。
- en: Remembering the training process
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 记住训练过程
- en: Before describing the computational burden imposed by neural network training,
    we must remember how this process works.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在描述神经网络训练带来的计算负担之前，我们必须记住这个过程是如何工作的。
- en: Important note
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: This section gives a very brief introduction to the training process. If you
    are totally unfamiliar with this topic, you should invest some time to understand
    this theme before moving to the following chapters. An excellent resource for
    learning this topic is the book entitled *Machine Learning with PyTorch and Scikit-Learn*,
    published by Packt and written by Sebastian Raschka, Yuxi (Hayden) Liu, and Vahid
    Mirjalili.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 本节对训练过程进行了非常简要的介绍。如果您对这个主题完全不熟悉，您应该花些时间理解这个主题，然后再转到后面的章节。学习这个主题的一个很好的资源是Packt出版的书籍《使用PyTorch和Scikit-Learn进行机器学习》，作者是Sebastian
    Raschka、Yuxi (Hayden) Liu和Vahid Mirjalili。
- en: Basically speaking, neural networks learn from examples, similar to a child
    observing an adult. The learning process relies on feeding the neural network
    with pairs of input and output values so that the network catches the intrinsic
    relation between the input and output data. Such relationships can be interpreted
    as the knowledge obtained by the model. So, where a human sees a bunch of data,
    the neural network sees veiled knowledge.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上来说，神经网络学习示例，类似于一个孩子观察成年人。学习过程依赖于向神经网络提供输入和输出值对，以便网络捕捉输入和输出数据之间的内在关系。这样的关系可以解释为模型获得的知识。所以，在人看到一堆数据时，神经网络看到的是隐藏的知识。
- en: This learning process depends on the dataset used to train a model.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 这个学习过程取决于用于训练模型的数据集。
- en: Dataset
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据集
- en: A **dataset** comprises a set of **data instances** related to some problem,
    scenario, event, or phenomenon. Each instance has features and target information
    corresponding to the input and output data. The concept of a dataset instance
    is similar to a registry in a table or relational database.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据集**包含一组与某个问题、情景、事件或现象相关的**数据实例**。每个实例都有特征和目标信息，对应输入和输出数据。数据集实例的概念类似于表或关系数据库中的记录。'
- en: 'The dataset is usually split into two parts: training and testing sets. The
    training set is used to train the network, whereas the testing part is used to
    test the model against unseen data. Occasionally, we can also use another part
    to validate the model after each training iteration.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集通常分为两部分：训练集和测试集。训练集用于训练网络，而测试部分则用于针对未见过的数据测试模型。偶尔，我们也可以在每次训练迭代后使用另一部分来验证模型。
- en: Let’s look at Fashion-MNIST, a famous dataset that is commonly used to test
    and teach neural networks. This dataset comprises 70,000 labeled images of clothes
    and accessories such as dresses, shirts, and sandals belonging to 10 distinct
    classes or categories. The dataset is split into 60,000 instances for training
    and 10,000 instances for testing.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看Fashion-MNIST，这是一个常用于测试和教授神经网络的著名数据集。该数据集包含70,000张标记的服装和配饰图像，如裙子、衬衫和凉鞋，属于10个不同的类别。数据集分为60,000个训练实例和10,000个测试实例。
- en: As shown in *Figure 1**.1*, a single instance of this dataset comprises a 28
    x 28 grayscale image and a label identifying its class. In the case of Fashion-MNIST,
    we have 70,000 instances, which is often referred to as the length of the dataset.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 正如*图 1**.1*所示，该数据集的单个实例包括一个 28 x 28 的灰度图像和一个标签，用来识别其类别。在Fashion-MNIST的情况下，我们有70,000个实例，通常称为数据集的长度。
- en: '![Figure 1.1 – Concept of a dataset instance](img/B20959_01_1.jpg)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.1 – 数据集实例的概念](img/B20959_01_1.jpg)'
- en: Figure 1.1 – Concept of a dataset instance
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.1 – 数据集实例的概念
- en: 'Besides the concept of dataset instance, we also have the concept of a **dataset
    sample**. A sample is defined as a group of instances, as shown in *Figure 1**.2*.
    Usually, the training process executes on samples and not just on a single dataset
    instance. The reason why the training process takes samples instead of single
    instances is related to the way the training algorithm works. Don’t worry about
    this topic; we will cover it in the following sections:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 除了数据集实例的概念外，我们还有**数据集样本**的概念。一个样本定义为一组实例，如*图 1**.2*所示。通常，训练过程执行的是样本而不仅仅是单个数据集实例。训练过程之所以采用样本而不是单个实例，与训练算法的工作方式有关。关于这个主题不用担心，我们将在接下来的章节中进行详细讨论：
- en: '![Figure 1.2 – Concept of a dataset sample](img/B20959_01_2.jpg)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.2 – 数据集样本的概念](img/B20959_01_2.jpg)'
- en: Figure 1.2 – Concept of a dataset sample
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.2 – 数据集样本的概念
- en: The number of instances in a sample is called the **batch size**. For example,
    if we divide the Fashion-MNIST training set into samples of a batch size equal
    to 32, we get 1,875 samples since this set has 60,000 instances.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 样本中的实例数量称为**批处理大小**。例如，如果我们将Fashion-MNIST训练集分成批次大小为32的样本，则得到1,875个样本，因为该集合有60,000个实例。
- en: 'The higher the batch size, the lower the number of samples in a training set,
    as pictorially described in *Figure 1**.3*:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 批处理大小越大，训练集中样本的数量越少，如*图 1**.3*中所示：
- en: '![Figure 1.3 – Concept of batch size](img/B20959_01_3.jpg)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.3 – 批处理大小的概念](img/B20959_01_3.jpg)'
- en: Figure 1.3 – Concept of batch size
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.3 – 批处理大小的概念
- en: With a batch size equal to eight, the dataset in the example is divided into
    two samples, each with eight dataset instances. On the other hand, with a lower
    batch size (in this case, four), the training set is divided into a higher number
    of samples (four samples).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在本例中，如果批处理大小为8，则数据集被分为两个样本，每个样本包含八个数据集实例。另一方面，如果批处理大小较小（例如四个），则训练集将被分成更多的样本（四个样本）。
- en: 'The neural network receives input samples and outputs a set of results, each
    corresponding to an instance of the input sample. In the case of a model to treat
    the classification image problem of Fashion-MNIST, the neural network gets a set
    of images and outputs another set of labels, as you can see in *Figure 1**.4*.
    Each one of these labels indicates the corresponding class of the input image:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络接收输入样本并输出一组结果，每个结果对应一个输入样本的实例。对于处理Fashion-MNIST分类图像问题的模型，神经网络接收一组图像并输出另一组标签，正如*图
    1**.4*所示。每个标签表示输入图像对应的类别：
- en: '![Figure 1.4 – Neural networks work on input samples](img/B20959_01_4.jpg)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.4 – 神经网络对输入样本的工作](img/B20959_01_4.jpg)'
- en: Figure 1.4 – Neural networks work on input samples
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.4 – 神经网络对输入样本的工作
- en: To extract the intrinsic knowledge present in the dataset, we need to submit
    the neural network to a training algorithm so it can learn the pattern present
    in the data. Let’s jump to the next section to understand how this algorithm works.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 要提取数据集中的内在知识，我们需要将神经网络提交给训练算法，以便它可以学习数据中存在的模式。让我们跳转到下一节，了解这个算法是如何工作的。
- en: The training algorithm
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练算法
- en: The training algorithm is an **iterative process** that takes each dataset sample
    and adjusts the neural network parameters according to the degree of error related
    to the difference between the correct result and the predicted one.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 训练算法是一个**迭代过程**，它接受每个数据集样本，并根据正确结果与预测结果之间的误差调整神经网络参数。
- en: A single training iteration is called the **training step**. So, the number
    of training steps executed in the learning process equals the number of samples
    used to train the model. As we stated before, the batch size defines the number
    of samples, which also determines the number of training steps.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 单次训练迭代被称为**训练步骤**。因此，在学习过程中执行的训练步骤数量等于用于训练模型的样本数量。正如我们之前所述，批量大小定义了样本数量，也确定了训练步骤的数量。
- en: After executing all the training steps, we say the training algorithm has completed
    a **training epoch**. The developer must define the number of epochs before starting
    the model-building process. Usually, the developer determines the number of epochs
    by varying it and evaluating the accuracy of the resultant model.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 执行所有训练步骤后，我们称训练算法完成了一个**训练周期**。开发者在开始模型构建过程之前必须定义训练周期的数量。通常，开发者通过变化并评估生成模型的准确性来确定训练周期的数量。
- en: 'A single training step executes the four phases sequentially, as illustrated
    in *Figure 1**.5*:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 单个训练步骤按照图*1**.5*顺序执行四个阶段：
- en: '![Figure 1.5 – The four phases of the training process](img/B20959_01_5.jpg)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![图1.5 – 训练过程的四个阶段](img/B20959_01_5.jpg)'
- en: Figure 1.5 – The four phases of the training process
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.5 – 训练过程的四个阶段
- en: Let’s go through each one of these steps to understand their role in the entire
    training process.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐步了解每一个步骤，理解它们在整个训练过程中的作用。
- en: Forward
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 前向
- en: In the forward phase, the neural network receives the input data, performs calculations,
    and outputs a result. This output is also known as the value predicted by the
    neural network. In the case of Fashion-MNIST, the input data is the grayscale
    image and the predicted value is the class to which the item belongs.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在前向阶段，神经网络接收输入数据，执行计算，并输出结果。这个输出也称为神经网络预测的值。在Fashion-MNIST中，输入数据是灰度图像，预测的值是物品所属的类别。
- en: Considering the tasks executed in the training step, the forward phase has a
    higher computational cost. This happens because it executes all the heavy computations
    involved in the neural network. Such computations, commonly known as operations,
    will be explained in the next section.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到训练步骤中执行的任务，前向阶段具有更高的计算成本。这是因为它执行神经网络中涉及的所有重计算。这些计算通常称为操作，将在下一节中解释。
- en: It is interesting to note that the forward phase is exactly the same as the
    inference process. When using the model in practice, we continuously execute the
    forward phase to infer a value or result.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，前向阶段与推断过程完全相同。在实际使用模型时，我们持续执行前向阶段来推断一个值或结果。
- en: Loss calculation
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 损失计算
- en: After the forward phase, the neural network will output a predicted value. Then,
    the training algorithm needs to compare the predicted value with the expected
    one to see how good the prediction made by the model is.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在前向阶段之后，神经网络将会输出一个预测值。然后，训练算法需要比较预测值与期望值，以查看模型所做预测的好坏程度。
- en: If the predicted value is close or equal to the real value, the model is performing
    as expected and the training process is going in the right direction. Otherwise,
    the training step needs to quantify the error achieved by the model to adjust
    the parameters proportionally to the error degree.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 如果预测值接近或等于真实值，则模型表现符合预期，训练过程朝着正确的方向进行。否则，训练步骤需要量化模型达到的错误，以调整参数与错误程度成比例。
- en: Important note
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: In the terminology of neural networks, this error is usually referred to as
    **loss** or **cost**. So, it is common to see names such as loss or cost function
    in the literature when addressing this topic.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在神经网络术语中，这种误差通常称为**损失**或**成本**。因此，在讨论此主题时，文献中常见到损失或成本函数等名称。
- en: There are different kinds of loss functions, each one suitable to treat a specific
    sort of problem. The **cross-entropy** (**CE**) loss function is used in multiclass
    image classification problems, where we need to classify an image within a group
    of classes. For example, this loss function can be used in the Fashion-MNIST problem.
    Suppose we have just two classes or categories. In that case, we face a binary
    class problem, so using the **binary cross-entropy** (**BCE**) function rather
    than the original cross-entropy loss function is recommended.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 不同类型的损失函数，每种适合处理特定类型的问题。**交叉熵**（**CE**）损失函数用于多类图像分类问题，其中我们需要将图像分类到一组类别中。例如，这种损失函数可以在Fashion-MNIST问题中使用。假设我们只有两个类别或分类。在这种情况下，面对二元类问题，建议使用**二元交叉熵**（**BCE**）函数而不是原始的交叉熵损失函数。
- en: For regression problems, the loss function is completely different from the
    ones used in classification problems. We can use functions such as the **mean
    squared error** (**MSE**), which measures the squared difference between the original
    value and the predicted value by the neural network.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 对于回归问题，损失函数与分类问题中使用的不同。我们可以使用诸如**均方误差**（**MSE**）的函数，该函数衡量神经网络预测值与原始值之间的平方差异。
- en: Optimization
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 优化
- en: After obtaining the loss, the training algorithm calculates the partial derivative
    of the loss function concerning the current parameters of the network. This operation
    results in the so-called **gradient**, which the training process uses to adjust
    network parameters.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在获取损失之后，训练算法计算相对于网络当前参数的损失函数的偏导数。这个操作产生所谓的**梯度**，训练过程使用它来调整网络参数。
- en: Leaving the mathematical foundations aside, we can think of the gradient as
    the change we need to apply to network parameters to minimize the error or loss.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 略去数学基础，我们可以将梯度视为需要应用于网络参数以最小化错误或损失的变化。
- en: Important note
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: You can find more information about the math used in deep learning by reading
    the book *Hands-On Mathematics for Deep Learning*, published by Packt and written
    by Jay Dawani.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过阅读Packt出版的《深度学习数学实战》一书（作者Jay Dawani编著）来了解深度学习中使用的数学更多信息。
- en: Similar to the loss function, we also have distinct implementations of optimizers.
    The **stochastic gradient descent** (**SGD**) and Adam are used the most.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 与损失函数类似，优化器也有不同的实现方式。**随机梯度下降**（**SGD**）和Adam最常用。
- en: Backward
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 反向传播
- en: To finish the training process, the algorithm updates the network parameters
    according to the gradient obtained in the optimization phase.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 为完成训练过程，算法根据优化阶段获得的梯度更新网络参数。
- en: Important note
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: This section provides a theoretical explanation of the training algorithm. So,
    be aware that depending on the machine learning framework, the training process
    can have a set of phases that is different from the ones in the preceding list.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 本节提供了训练算法的理论解释。因此，请注意，根据机器学习框架的不同，训练过程可能具有与前述列表不同的一组阶段。
- en: Essentially, these phases constitute the computational burden of the training
    process. Follow me to the next section to understand how this computational burden
    is impacted by different factors.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 本质上，这些阶段构成了训练过程的计算负担。请跟随我到下一节，以了解这种计算负担如何受不同因素影响。
- en: Understanding the computational burden of the model training phase
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解模型训练阶段的计算负担
- en: Now that we’ve brushed up on how the training process works, let’s understand
    the computational cost required to train a model. By using the terms computational
    cost or burden, we mean the computing power needed to execute the training process.
    The higher the computational cost, the higher the time taken to train the model.
    In the same way, the higher the computational burden, the higher the computing
    resources required to train the model.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经复习了训练过程的工作原理，让我们了解训练模型所需的计算成本。通过使用计算成本或负担这些术语，我们指的是执行训练过程所需的计算能力。计算成本越高，训练模型所需的时间就越长。同样，计算负担越高，执行训练模型所需的计算资源就越多。
- en: 'Essentially, we can say the computational burden to train a model is defined
    by a three-fold factor, as illustrated in *Figure 1**.6*:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 本质上，我们可以说训练模型的计算负担由三个因素定义，如*图1.6*所示。
- en: '![Figure 1.6 – Factors that influence the training computational burden](img/B20959_01_6.jpg)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![图1.6 – 影响训练计算负担的因素](img/B20959_01_6.jpg)'
- en: Figure 1.6 – Factors that influence the training computational burden
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.6 – 影响训练计算负担的因素
- en: Each one of these factors contributes (to some degree) to the computational
    complexity imposed by the training process. Let’s talk about each one of them.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 这些因素中的每一个（在某种程度上）都对训练过程施加了计算复杂性。让我们分别讨论每一个。
- en: Hyperparameters
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 超参数
- en: '**Hyperparameters** define two aspects of neural networks: the neural network
    configuration and how the training algorithm works.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '**超参数**定义了神经网络的两个方面：神经网络配置和训练算法的工作方式。'
- en: Concerning neural network configuration, the hyperparameters determine the number
    and type of layers and the number of neurons in each layer. Simple networks have
    a few layers and neurons, whereas complex networks have thousands of neurons spread
    in hundreds of layers. The number of layers and neurons determines the number
    of parameters of the network, which directly impacts the computational burden.
    Due to the significant influence of the number of parameters in the computational
    cost of the training step, we will discuss this topic later in this chapter as
    a separate performance factor.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 关于神经网络配置，超参数确定了每个层的数量和类型以及每个层中的神经元数量。简单的网络有少量的层和神经元，而复杂的网络有成千上万个神经元分布在数百个层中。层和神经元的数量决定了网络的参数数量，直接影响计算负担。由于参数数量在训练步骤的计算成本中有显著影响，我们将在本章稍后讨论这个话题作为一个独立的性能因素。
- en: Regarding how the training algorithm executes the training process, hyperparameters
    control the number of epochs and steps and determine the optimizer and loss function
    used during the training phase, among other things. Some of these hyperparameters
    have a tiny influence on the computational cost of the training process. For example,
    if we change the optimizer from SGD to Adam, we will not face any relevant impact
    on the computational cost of the training process.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 关于训练算法如何执行训练过程，超参数控制着周期数和步数的数量，并确定了训练阶段使用的优化器和损失函数，等等。其中一些超参数对训练过程的计算成本影响微乎其微。例如，如果我们将优化器从SGD改为Adam，对训练过程的计算成本不会产生任何相关影响。
- en: Other hyperparameters can definitely raise the training phase time, though.
    One of the most emblematic examples is the batch size. The higher the batch size,
    the fewer training steps are needed to train a model. So, with a few training
    steps, we can speed up the building process since the training phase will execute
    fewer steps per epoch. On the other hand, we can spend more time executing a single
    training step if we have big batch sizes. This happens because the forward phase
    executed on each training step should deal with a higher dimensional input data.
    In other words, we have a trade-off here.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，其他超参数确实会显著增加训练阶段的时间。其中最典型的例子之一是批大小。批大小越大，训练模型所需的训练步骤就越少。因此，通过少量的训练步骤，我们可以加快建模过程，因为训练阶段每个周期执行的步骤会减少。另一方面，如果批大小很大，我们可能需要更多时间执行单个训练步骤。这是因为在每个训练步骤上执行的前向阶段必须处理更高维度的输入数据。换句话说，这里存在一个权衡。
- en: For example, consider the case of a batch size equal to *32* for the Fashion-MNIST
    dataset. In this case, the input data dimension is *32 x 1 x 28 x 28*, where 32,
    1, and 28 represent the batch size, the number of channels (colors, in this scenario),
    and the image size, respectively. Therefore, for this case, the input data comprises
    25,088 numbers, which is the number of numbers the forward phase should compute.
    However, if we increase the batch size to *128*, the input data changes to 100,352
    numbers, which can result in a longer time to execute a single forward phase iteration.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑批大小等于*32*的Fashion-MNIST数据集的情况。在这种情况下，输入数据的维度为*32 x 1 x 28 x 28*，其中32、1和28分别表示批大小、通道数（颜色，在这种情况下）和图像大小。因此，对于这种情况，输入数据包括25,088个数字，这是前向阶段应该计算的数字数量。然而，如果我们将批大小增加到*128*，输入数据就会变为100,352个数字，这可能导致单个前向阶段迭代执行时间较长。
- en: In addition, a bigger input sample requires a higher amount of memory to execute
    each training step. Depending on the hardware configuration, the amount of memory
    required to execute the training step can drastically reduce the performance of
    the entire training process or even make it impossible to execute in that hardware.
    Conversely, we can accelerate the training process by using hardware endowed with
    huge memory resources. This is why we need to know the details of the hardware
    resources we use and what factors influence the computational complexity of the
    training process.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，更大的输入样本需要更多的内存来执行每个训练步骤。根据硬件配置的不同，执行训练步骤所需的内存量可能会显著降低整个训练过程的性能，甚至使其无法在该硬件上执行。相反，我们可以通过使用具有大内存资源的硬件加速训练过程。这就是为什么我们需要了解我们使用的硬件资源的细节以及影响训练过程计算复杂度的因素。
- en: We will dive into all of these issues throughout the book.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在整本书中深入探讨所有这些问题。
- en: Operations
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 操作
- en: 'We already know each training step executes four training phases: forward,
    loss computation, optimization, and backward. In the forward phase, the neural
    network receives the input data and processes it according to the neural network’s
    architecture. Besides other things, the architecture defines the network layers,
    where each layer has one or more operations that the network executes during the
    forward phase.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经知道每个训练步骤执行四个训练阶段：前向、损失计算、优化和反向。在前向阶段，神经网络接收输入数据并根据神经网络的架构进行处理。除其他事项外，架构定义了网络层，每个层在前向阶段执行一个或多个操作。
- en: For example, a **fully connected neural network** (**FCNN**) usually executes
    general matrix-to-matrix multiplication operations, whereas **convolutional neural
    networks** (**CNNs**) execute special computer vision operations such as convolution,
    padding, and pooling. It turns out that the computational complexity of one operation
    is not the same as another. So, depending on the network architecture and the
    operations, we can get distinct performance behavior.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，一个**全连接神经网络**（**FCNN**）通常执行通用的矩阵乘法运算，而**卷积神经网络**（**CNNs**）执行特殊的计算机视觉操作，如卷积、填充和池化。结果表明，一个操作的计算复杂度与另一个不同。因此，根据网络架构和操作，我们可以得到不同的性能行为。
- en: Nothing is better than an example, right? Let’s define a class to instantiate
    a traditional CNN model that is able to deal with the Fashion-MNIST dataset.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 没有什么比一个例子更好了，对吧？让我们定义一个类来实例化一个传统的CNN模型，该模型能够处理Fashion-MNIST数据集。
- en: Important note
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: The complete code shown in this section is available at [https://github.com/PacktPublishing/Accelerate-Model-Training-with-PyTorch-2.X/blob/main/code/chapter01/cnn-fashion_mnist.ipynb](https://github.com/PacktPublishing/Accelerate-Model-Training-with-PyTorch-2.X/blob/main/code/chapter01/cnn-fashion_mnist.ipynb).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 本节中显示的完整代码可在[https://github.com/PacktPublishing/Accelerate-Model-Training-with-PyTorch-2.X/blob/main/code/chapter01/cnn-fashion_mnist.ipynb](https://github.com/PacktPublishing/Accelerate-Model-Training-with-PyTorch-2.X/blob/main/code/chapter01/cnn-fashion_mnist.ipynb)找到。
- en: This model receives an input sample of size *64 x 1 x 28 x 28*. This means the
    model receives 64 grayscale images (one channel) with a height and width equal
    to 28 pixels. As a result, the model outputs a tensor of dimension *64 x 10*,
    which represents the probability of the image belonging to each of the 10 categories
    of the Fashion-MNIST dataset.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型接收大小为*64 x 1 x 28 x 28*的输入样本。这意味着模型接收到64张灰度图像（一个通道），高度和宽度均为28像素。因此，模型输出一个维度为*64
    x 10*的张量，表示图像属于Fashion-MNIST数据集的10个类别的概率。
- en: The model has two convolutional and two fully connected layers. Each convolutional
    layer comprises one bidimensional convolution, the **rectified linear unit** (**ReLU**)
    activation function, and pooling. The first fully connected layer has 3,136 neurons
    connected to the 512 neurons of the fully connected second layer. The second layer
    is then connected to the 10 neurons of the output layer.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型有两个卷积层和两个全连接层。每个卷积层包括一个二维卷积、**修正线性单元**（**ReLU**）激活函数和池化。第一个全连接层有3,136个神经元连接到第二个全连接层的512个神经元。然后，第二层连接到输出层的10个神经元。
- en: Important note
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: If you are unfamiliar with CNN models, it would be useful to watch the video
    *What is a convolutional neural network (CNN)?* from the Packt YouTube channel
    at [https://youtu.be/K_BHmztRTpA](https://youtu.be/K_BHmztRTpA).
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您对CNN模型不熟悉，观看Packt YouTube频道上的视频*什么是卷积神经网络（CNN）*会很有用，链接在[https://youtu.be/K_BHmztRTpA](https://youtu.be/K_BHmztRTpA)。
- en: 'By exporting this model to the ONNX format, we get the diagram illustrated
    in *Figure 1**.7*:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将这个模型导出为ONNX格式，我们得到了*图1.7*中所示的图表：
- en: '![Figure 1.7 – Operations of a CNN model](img/B20959_01_7.jpg)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![图1.7 – CNN模型的操作](img/B20959_01_7.jpg)'
- en: Figure 1.7 – Operations of a CNN model
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.7 – CNN模型的操作
- en: Important note
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: The **Open Neural Network Exchange** (**ONNX**) is an open standard for machine
    learning interoperability. Besides other things, ONNX provides a standard format
    to export neural network models from many distinct frameworks and tools. We can
    use the ONNX file to inspect model details, import it into another framework,
    or execute the inference process.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '**开放神经网络交换**（**ONNX**）是机器学习互操作性的开放标准。除其他外，ONNX提供了一种标准格式，用于从许多不同的框架和工具中导出神经网络模型。我们可以使用ONNX文件来检查模型细节，将其导入到另一个框架中，或执行推断过程。'
- en: 'By evaluating *Figure 1**.7*, we can see five distinct operations:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 通过评估*图1.7*，我们可以看到五个不同的操作：
- en: '`Conv`: Bidimensional convolution'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Conv`: 二维卷积'
- en: '`MaxPool`: Max pooling'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MaxPool`: 最大池化'
- en: '`Relu`: Activation function (ReLU)'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Relu`: 激活函数（ReLU）'
- en: '`Reshape`: Tensor dimensional transformation'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Reshape`: 张量维度转换'
- en: '`Gemm`: General matrix multiplication'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Gemm`: 通用矩阵乘法'
- en: 'So, under the hood, the neural network executes these operations in the forward
    phase. From a computing perspective, this is the set of real operations that the
    machine runs during each training step. Therefore, we can rethink the training
    process of this model in terms of its operations and write it as a simpler algorithm:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，在底层，神经网络在前向阶段执行这些操作。从计算的角度来看，这是机器在每个训练步骤中运行的真实操作集合。因此，我们可以从操作的角度重新思考这个模型的训练过程，并将其写成一个更简单的算法：
- en: '[PRE0]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: As you can see, the training process is just a set of operations executed one
    after another. Despite the functions or classes used to define the model, the
    machine is actually running this set of operations.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，训练过程只是一系列按顺序执行的操作。尽管用于定义模型的函数或类，机器实际上是在运行这一系列操作。
- en: It turns out that each operation has a particular computational complexity,
    thus requiring distinct levels of computing power and resources to be executed
    satisfactorily. In this way, we can face different performance gains and bottlenecks
    for each one of those operations. Similarly, some operations can be more suitable
    to execute in a given hardware architecture, as we will see throughout the book.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 结果表明，每个操作都具有特定的计算复杂性，因此需要不同级别的计算能力和资源来满足执行的要求。因此，我们可能会面对每个操作的不同性能增益和瓶颈。同样，一些操作可能更适合在特定的硬件架构中执行，这一点我们将在本书中看到。
- en: 'To obtain the practical meaning of this topic, we can check the percentage
    of time these operations spent during the training step. So, let’s use **PyTorch
    Profiler** to get the percentage of CPU usage for each operation. The following
    list resumes the CPU usage when running the forward phase of our CNN model with
    one input sample of the Fashion-MNIST dataset:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解这个主题的实际意义，我们可以检查这些操作在训练阶段花费的时间百分比。因此，让我们使用**PyTorch Profiler**来获取每个操作的CPU使用百分比。以下列表总结了在Fashion-MNIST数据集的一个输入样本上运行CNN模型的前向阶段时的CPU使用情况：
- en: '[PRE1]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Important note
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: ATen is a C++ library used by PyTorch to execute basic operations. You can find
    more information about this library at [https://pytorch.org/cppdocs/#aten](https://pytorch.org/cppdocs/#aten).
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: ATen是PyTorch用于执行基本操作的C++库。您可以在[https://pytorch.org/cppdocs/#aten](https://pytorch.org/cppdocs/#aten)找到有关该库的更多信息。
- en: 'The results show the Conv operation (labeled here as `aten::mkldnn_convolution`)
    presented higher CPU usage (44%), followed by the MaxPool operation (`aten:: max_pool2d_with_indices`),
    with 30% CPU usage. On the other hand, the ReLU (`aten::relu`) and Reshape (`aten::reshape`)
    operations consumed less than 1% of the total CPU usage. Finally, the Gemm operation
    (`aten::addmm`) used around 14% of the CPU time.'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 结果显示，Conv操作（此处标记为`aten::mkldnn_convolution`）占用了更高的CPU使用率（44%），其次是MaxPool操作（`aten::max_pool2d_with_indices`），占用30%的CPU时间。另一方面，ReLU（`aten::relu`）和Reshape（`aten::reshape`）操作消耗的CPU时间不到总CPU使用率的1%。最后，Gemm操作（`aten::addmm`）占用了约14%的CPU时间。
- en: From this simple profiling test, we can assert the operations involved in the
    forward phase; hence, in the training process, there are distinct levels of computational
    complexity. We can see the training process consumed much more CPU cycles when
    executing the Conv operation than the Gemm operation. Notice that our CNN model
    has two layers comprising both operations. Thus, in this example, both operations
    are executed the same number of times.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这个简单的分析测试，我们可以确定前向阶段涉及的操作；因此，在训练过程中，存在不同级别的计算复杂性。我们可以看到，在执行Conv操作时，训练过程消耗了更多的CPU周期，而不是在执行Gemm操作时。请注意，我们的CNN模型具有两层，包含这两种操作。因此，在这个例子中，这两种操作被执行了相同的次数。
- en: Based on this knowledge about the distinct computational burden of neural network
    operations, we can choose the best hardware architecture or software stack to
    reduce the execution time of the predominant operation of a given neural network.
    For example, suppose we need to train a CNN composed of dozens of convolutional
    layers. In that case, we will look for hardware resources endowed with special
    capabilities to execute Conv operations more efficiently. Even though the model
    has some fully connected layers, we already know that the Gemm operation can be
    less computationally intensive than Conv. This justifies prioritizing a hardware
    resource that is able to accelerate convolutional operations to train that model.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 基于对神经网络操作的不同计算负担的了解，我们可以选择最佳的硬件架构或软件堆栈，以减少给定神经网络的主要操作的执行时间。例如，假设我们需要训练一个由数十个卷积层组成的CNN模型。在这种情况下，我们将寻找具有特殊能力的硬件资源，以更有效地执行Conv操作。尽管模型具有一些全连接层，但我们已经知道，与Conv相比，Gemm操作可能计算负担较小。这就证明了，优先考虑能够加速卷积操作的硬件资源是合理的。
- en: Parameters
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参数
- en: Besides hyperparameters and operations, the neural network parameters are another
    factor that has a relevant influence on the computational cost of the training
    process. As we discussed earlier, the number and type of layers in the neural
    network configuration define the total number of parameters on the network.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 除了超参数和操作外，神经网络参数是影响训练过程计算成本的另一个因素。正如我们之前讨论的那样，神经网络配置中层的数量和类型定义了网络上的总参数数量。
- en: Obviously, the higher the number of parameters, the higher the computational
    burden of the training process. These parameters comprise kernel values employed
    on convolutional operations, biases, and the weights of connections between neurons.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，参数数量越多，训练过程的计算负担越重。这些参数包括用于卷积操作的核值、偏置以及神经元之间连接的权重。
- en: 'Our CNN model, with just 4 layers, has 1,630,090 parameters. We can easily
    count the total number of parameters in PyTorch by using this function:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的CNN模型只有4层，却有1,630,090个参数。我们可以使用PyTorch的这个函数轻松地计算出网络中的总参数数量。
- en: '[PRE2]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: If we add an extra fully connected layer with 256 neurons to our CNN model and
    rerun this function, we will get 1,758,858 parameters in total, representing an
    increase of nearly 8%.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们在我们的CNN模型中添加一个额外的具有256个神经元的全连接层，并重新运行这个函数，我们将得到总共1,758,858个参数，增加了近8%。
- en: After training and testing this new CNN model, we got the same accuracy as before.
    Then, paying attention to the trade-off between network complexity and model accuracy
    is essential. On many occasions, increasing the number of layers and neurons will
    not necessarily result in better efficiency but will possibly increase the time
    of the training process.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练和测试这个新的CNN模型之后，我们得到了与之前相同的准确性。因此，注意网络复杂度与模型准确性之间的权衡是至关重要的。在许多情况下，增加层和神经元的数量不一定会导致更好的效率，但可能会增加训练过程的时间。
- en: Another aspect of parameters is the numeric precision used to represent these
    numbers in the model. We will dive into this topic in [*Chapter 7*](B20959_07.xhtml#_idTextAnchor098),
    *Adopting Mixed Precision*, but for now, keep in mind that the number of bytes
    used to represent parameters pays a relevant contribution to the time needed to
    train a model. So, not only does the number of parameters have an impact on training
    time but so does the numeric precision chosen to represent these numbers in the
    model.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 参数的另一个方面是用于表示模型中这些数字的数值精度。我们将在[*第7章*](B20959_07.xhtml#_idTextAnchor098)，*采用混合精度*中深入讨论这个话题，但现在请记住，用于表示参数的字节数对训练模型所需的时间有重要的贡献。因此，参数数量不仅影响训练时间，而且所选择的数值精度也会影响训练时间。
- en: The next section brings a couple of questions to help you retain what you have
    learned in this chapter.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 下一节将提出一些问题，帮助您巩固本章学到的内容。
- en: Quiz time!
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测验时间！
- en: Let’s review what we have learned in this chapter by answering eight questions.
    At first, try to answer these questions without consulting the material.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过回答八个问题来复习本章学到的内容。首先，尝试在不查阅资料的情况下回答这些问题。
- en: Important note
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: The answers to all these questions are available at [https://github.com/PacktPublishing/Accelerate-Model-Training-with-PyTorch-2.X/blob/main/quiz/chapter01-answers.md](https://github.com/PacktPublishing/Accelerate-Model-Training-with-PyTorch-2.X/blob/main/quiz/chapter01-answers.md).
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些问题的答案都可以在 [https://github.com/PacktPublishing/Accelerate-Model-Training-with-PyTorch-2.X/blob/main/quiz/chapter01-answers.md](https://github.com/PacktPublishing/Accelerate-Model-Training-with-PyTorch-2.X/blob/main/quiz/chapter01-answers.md)
    找到。
- en: Before starting the quiz, remember that it is not a test at all! This section
    aims to complement your learning process by revising and consolidating the content
    covered in this chapter.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始测验之前，请记住，这根本不是一次测试！本节旨在通过复习和巩固本章节所涵盖的内容来补充您的学习过程。
- en: 'Choose the correct option for the following questions:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 为以下问题选择正确选项：
- en: Which phases comprise the training process?
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练过程包括哪些阶段？
- en: Forward, processing, optimization, and backward.
  id: totrans-128
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 前向，处理，优化和反向。
- en: Processing, pre-processing, and post-processing.
  id: totrans-129
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 处理，预处理和后处理。
- en: Forward, loss calculation, optimization, and backward.
  id: totrans-130
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 前向，损失计算，优化和反向。
- en: Processing, loss calculation, optimization, and post-processing.
  id: totrans-131
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 处理，损失计算，优化和后处理。
- en: Which factors impact the computational burden of the training process?
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哪些因素影响训练过程的计算负担？
- en: Loss function, optimizer, and parameters.
  id: totrans-133
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 损失函数，优化器和参数。
- en: Hyperparameters, parameters, and operations.
  id: totrans-134
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 超参数，参数和操作。
- en: Hyperparameters, loss function, and operations.
  id: totrans-135
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 超参数，损失函数和操作。
- en: Parameters, operations, and loss function.
  id: totrans-136
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 参数，操作和损失函数。
- en: After executing the training algorithm on all dataset samples, the training
    process has completed a training what?
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在执行训练算法处理所有数据集样本后，训练过程完成了一个训练什么？
- en: Evolution.
  id: totrans-138
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 进化。
- en: Epoch.
  id: totrans-139
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: epoch。
- en: Step.
  id: totrans-140
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 步骤。
- en: Generation.
  id: totrans-141
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成。
- en: A dataset sample comprises a set of what?
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据集样本包含一组什么？
- en: Dataset collections.
  id: totrans-143
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据集集合。
- en: Dataset steps.
  id: totrans-144
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据集步骤。
- en: Dataset epochs.
  id: totrans-145
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据集的 epochs。
- en: Dataset instances.
  id: totrans-146
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据集实例。
- en: Which hyperparameter is more likely to increase the computational burden of
    the training process?
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哪个超参数更有可能增加训练过程的计算负担？
- en: Batch size.
  id: totrans-148
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 批次大小。
- en: Optimizer.
  id: totrans-149
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 优化器。
- en: Number of epochs.
  id: totrans-150
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: epoch 数。
- en: Learning rate.
  id: totrans-151
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 学习率。
- en: A training set has 2,500 instances. By defining a batch size equal to 1 and
    50, the number of steps executed during the training process is, respectively,
    which of the following?
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个训练集有 2,500 个实例。通过定义批次大小分别为 1 和 50，训练过程执行的步骤数分别是以下哪一个？
- en: 500 and 5.
  id: totrans-153
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 500 和 5。
- en: 2,500 and 1.
  id: totrans-154
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 2,500 和 1。
- en: 2,500 and 50.
  id: totrans-155
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 2,500 和 50。
- en: 500 and 50.
  id: totrans-156
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 500 和 50。
- en: The profiling of a training process showed that the most time-consuming operation
    was `aten::mkldnn_convolution`. In this case, what is the heavier computing phase
    of the training process?
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练过程的分析显示，最耗时的操作是 `aten::mkldnn_convolution`。在这种情况下，训练过程中哪个计算阶段更重？
- en: Backward.
  id: totrans-158
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 反向。
- en: Forward.
  id: totrans-159
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 前向。
- en: Loss calculation.
  id: totrans-160
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 损失计算。
- en: Optimization.
  id: totrans-161
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 优化。
- en: A model has two convolutional layers and two fully connected layers. If we add
    two more convolutional layers to the model, it will increase the number of what?
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个模型有两个卷积层和两个全连接层。如果我们向模型添加两个额外的卷积层，将增加什么数量？
- en: Hyperparameters.
  id: totrans-163
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 超参数。
- en: Training steps.
  id: totrans-164
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练步骤。
- en: Parameters.
  id: totrans-165
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 参数。
- en: Training samples.
  id: totrans-166
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练样本。
- en: Let’s summarize what we’ve learned in this chapter.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们总结一下这一章节我们学到的内容。
- en: Summary
  id: totrans-168
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: We have reached the end of the first step of our training acceleration journey.
    You started this chapter by remembering how the training process works. In addition
    to refreshing concepts such as datasets and samples, you remembered the four phases
    of the training algorithm.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经完成了训练加速旅程的第一步。您从回顾训练过程如何工作开始了本章。除了复习数据集和样本等概念外，您还记得训练算法的四个阶段。
- en: Next, you learned that hyperparameters, operations, and parameters are the three-fold
    factors influencing the training process’s computational burden.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，您了解到超参数，操作和参数是影响训练过程计算负担的三个因素。
- en: Now that you have remembered the training process and understood what contributes
    to its computational complexity, it’s time to move on to the next topic.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经记住了训练过程，并理解了导致其计算复杂性的因素，是时候转向下一个主题了。
- en: Let’s take our first steps to learn how to accelerate this heavy computational
    process!
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们迈出第一步，学习如何加速这一繁重的计算过程！
