- en: '3'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A Tour of Machine Learning Classifiers Using Scikit-Learn
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will take a tour of a selection of popular and powerful
    machine learning algorithms that are commonly used in academia as well as in industry.
    While learning about the differences between several supervised learning algorithms
    for classification, we will also develop an appreciation of their individual strengths
    and weaknesses. In addition, we will take our first steps with the scikit-learn
    library, which offers a user-friendly and consistent interface for using those
    algorithms efficiently and productively.
  prefs: []
  type: TYPE_NORMAL
- en: 'The topics that will be covered throughout this chapter are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: An introduction to robust and popular algorithms for classification, such as
    logistic regression, support vector machines, decision trees, and *k*-nearest
    neighbors
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Examples and explanations using the scikit-learn machine learning library, which
    provides a wide variety of machine learning algorithms via a user-friendly Python
    API
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Discussions about the strengths and weaknesses of classifiers with linear and
    nonlinear decision boundaries
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Choosing a classification algorithm
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Choosing an appropriate classification algorithm for a particular problem task
    requires practice and experience; each algorithm has its own quirks and is based
    on certain assumptions. To paraphrase the **no free lunch theorem** by David H.
    Wolpert, no single classifier works best across all possible scenarios (*The Lack
    of A Priori Distinctions Between Learning Algorithms*, *Wolpert, David H*, *Neural
    Computation 8.7* (1996): 1341-1390). In practice, it is always recommended that
    you compare the performance of at least a handful of different learning algorithms
    to select the best model for the particular problem; these may differ in the number
    of features or examples, the amount of noise in a dataset, and whether the classes
    are linearly separable.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Eventually, the performance of a classifier—computational performance as well
    as predictive power—depends heavily on the underlying data that is available for
    learning. The five main steps that are involved in training a supervised machine
    learning algorithm can be summarized as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Selecting features and collecting labeled training examples
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Choosing a performance metric
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Choosing a learning algorithm and training a model
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Evaluating the performance of the model
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Changing the settings of the algorithm and tuning the model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Since the approach of this book is to build machine learning knowledge step
    by step, we will mainly focus on the main concepts of the different algorithms
    in this chapter and revisit topics such as feature selection and preprocessing,
    performance metrics, and hyperparameter tuning for more detailed discussions later
    in the book.
  prefs: []
  type: TYPE_NORMAL
- en: First steps with scikit-learn – training a perceptron
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In *Chapter 2*, *Training Simple Machine Learning Algorithms for Classification*,
    you learned about two related learning algorithms for classification, the **perceptron**
    rule and **Adaline**, which we implemented in Python and NumPy by ourselves. Now
    we will take a look at the scikit-learn API, which, as mentioned, combines a user-friendly
    and consistent interface with a highly optimized implementation of several classification
    algorithms. The scikit-learn library offers not only a large variety of learning
    algorithms, but also many convenient functions to preprocess data and to fine-tune
    and evaluate our models. We will discuss this in more detail, together with the
    underlying concepts, in *Chapter 4*, *Building Good Training Datasets – Data Preprocessing*,
    and *Chapter 5*, *Compressing Data via Dimensionality Reduction*.
  prefs: []
  type: TYPE_NORMAL
- en: To get started with the scikit-learn library, we will train a perceptron model
    similar to the one that we implemented in *Chapter 2*. For simplicity, we will
    use the already familiar **Iris dataset** throughout the following sections. Conveniently,
    the Iris dataset is already available via scikit-learn, since it is a simple yet
    popular dataset that is frequently used for testing and experimenting with algorithms.
    Similar to the previous chapter, we will only use two features from the Iris dataset
    for visualization purposes.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will assign the petal length and petal width of the 150 flower examples
    to the feature matrix, `X`, and the corresponding class labels of the flower species
    to the vector array, `y`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The `np.unique(y)` function returned the three unique class labels stored in
    `iris.target`, and as we can see, the Iris flower class names, `Iris-setosa`,
    `Iris-versicolor`, and `Iris-virginica`, are already stored as integers (here:
    `0`, `1`, `2`). Although many scikit-learn functions and class methods also work
    with class labels in string format, using integer labels is a recommended approach
    to avoid technical glitches and improve computational performance due to a smaller
    memory footprint; furthermore, encoding class labels as integers is a common convention
    among most machine learning libraries.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To evaluate how well a trained model performs on unseen data, we will further
    split the dataset into separate training and test datasets. In *Chapter 6*, *Learning
    Best Practices for Model Evaluation and Hyperparameter Tuning*, we will discuss
    the best practices around model evaluation in more detail. Using the `train_test_split`
    function from scikit-learn’s `model_selection` module, we randomly split the `X`
    and `y` arrays into 30 percent test data (45 examples) and 70 percent training
    data (105 examples):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Note that the `train_test_split` function already shuffles the training datasets
    internally before splitting; otherwise, all examples from class `0` and class
    `1` would have ended up in the training datasets, and the test dataset would consist
    of 45 examples from class `2`. Via the `random_state` parameter, we provided a
    fixed random seed (`random_state=1`) for the internal pseudo-random number generator
    that is used for shuffling the datasets prior to splitting. Using such a fixed
    `random_state` ensures that our results are reproducible.
  prefs: []
  type: TYPE_NORMAL
- en: 'Lastly, we took advantage of the built-in support for stratification via `stratify=y`.
    In this context, stratification means that the `train_test_split` method returns
    training and test subsets that have the same proportions of class labels as the
    input dataset. We can use NumPy’s `bincount` function, which counts the number
    of occurrences of each value in an array, to verify that this is indeed the case:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Many machine learning and optimization algorithms also require feature scaling
    for optimal performance, as we saw in the **gradient descent** example in *Chapter
    2*. Here, we will standardize the features using the `StandardScaler` class from
    scikit-learn’s `preprocessing` module:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Using the preceding code, we loaded the `StandardScaler` class from the `preprocessing`
    module and initialized a new `StandardScaler` object that we assigned to the `sc`
    variable. Using the `fit` method, `StandardScaler` estimated the parameters, ![](img/B17582_03_001.png)
    (sample mean) and ![](img/B17582_03_002.png) (standard deviation), for each feature
    dimension from the training data. By calling the `transform` method, we then standardized
    the training data using those estimated parameters, ![](img/B17582_03_001.png)
    and ![](img/B17582_03_002.png). Note that we used the same scaling parameters
    to standardize the test dataset so that both the values in the training and test
    dataset are comparable with one another.
  prefs: []
  type: TYPE_NORMAL
- en: 'Having standardized the training data, we can now train a perceptron model.
    Most algorithms in scikit-learn already support multiclass classification by default
    via the **one-versus-rest** (**OvR**) method, which allows us to feed the three
    flower classes to the perceptron all at once. The code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The scikit-learn interface will remind you of our perceptron implementation
    in *Chapter 2*. After loading the `Perceptron` class from the `linear_model` module,
    we initialized a new `Perceptron` object and trained the model via the `fit` method.
    Here, the model parameter, `eta0`, is equivalent to the learning rate, `eta`,
    that we used in our own perceptron implementation.
  prefs: []
  type: TYPE_NORMAL
- en: As you will remember from *Chapter 2*, finding an appropriate learning rate
    requires some experimentation. If the learning rate is too large, the algorithm
    will overshoot the global loss minimum. If the learning rate is too small, the
    algorithm will require more epochs until convergence, which can make the learning
    slow—especially for large datasets. Also, we used the `random_state` parameter
    to ensure the reproducibility of the initial shuffling of the training dataset
    after each epoch.
  prefs: []
  type: TYPE_NORMAL
- en: 'Having trained a model in scikit-learn, we can make predictions via the `predict`
    method, just like in our own perceptron implementation in *Chapter 2*. The code
    is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Executing the code, we can see that the perceptron misclassifies 1 out of the
    45 flower examples. Thus, the misclassification error on the test dataset is approximately
    0.022, or 2.2 percent (![](img/B17582_03_005.png)).
  prefs: []
  type: TYPE_NORMAL
- en: '**Classification error versus accuracy**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Instead of the misclassification error, many machine learning practitioners
    report the classification accuracy of a model, which is simply calculated as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 1–*error* = 0.978, or 97.8 percent
  prefs: []
  type: TYPE_NORMAL
- en: Whether we use the classification error or accuracy is merely a matter of preference.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that scikit-learn also implements a large variety of different performance
    metrics that are available via the `metrics` module. For example, we can calculate
    the classification accuracy of the perceptron on the test dataset as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, `y_test` is the true class labels and `y_pred` is the class labels that
    we predicted previously. Alternatively, each classifier in scikit-learn has a
    `score` method, which computes a classifier’s prediction accuracy by combining
    the `predict` call with `accuracy_score`, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '**Overfitting**'
  prefs: []
  type: TYPE_NORMAL
- en: Note that we will evaluate the performance of our models based on the test dataset
    in this chapter. In *Chapter 6*, you will learn about useful techniques, including
    graphical analysis, such as learning curves, to detect and prevent overfitting.
    Overfitting, which we will return to later in this chapter, means that the model
    captures the patterns in the training data well but fails to generalize well to
    unseen data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we can use our `plot_decision_regions` function from *Chapter 2* to
    plot the **decision regions** of our newly trained perceptron model and visualize
    how well it separates the different flower examples. However, let’s add a small
    modification to highlight the data instances from the test dataset via small circles:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'With the slight modification that we made to the `plot_decision_regions` function,
    we can now specify the indices of the examples that we want to mark on the resulting
    plots. The code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'As we can see in the resulting plot, the three flower classes can’t be perfectly
    separated by a linear decision boundary:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Chart  Description automatically generated with low confidence](img/B17582_03_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.1: Decision boundaries of a multi-class perceptron model fitted to
    the Iris dataset'
  prefs: []
  type: TYPE_NORMAL
- en: However, remember from our discussion in *Chapter 2* that the perceptron algorithm
    never converges on datasets that aren’t perfectly linearly separable, which is
    why the use of the perceptron algorithm is typically not recommended in practice.
    In the following sections, we will look at more powerful linear classifiers that
    converge to a loss minimum even if the classes are not perfectly linearly separable.
  prefs: []
  type: TYPE_NORMAL
- en: '**Additional perceptron settings**'
  prefs: []
  type: TYPE_NORMAL
- en: The `Perceptron`, as well as other scikit-learn functions and classes, often
    has additional parameters that we omit for clarity. You can read more about those
    parameters using the `help` function in Python (for instance, `help(Perceptron)`)
    or by going through the excellent scikit-learn online documentation at [http://scikit-learn.org/stable/](http://scikit-learn.org/stable/).
  prefs: []
  type: TYPE_NORMAL
- en: Modeling class probabilities via logistic regression
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Although the perceptron rule offers a nice and easy-going introduction to machine
    learning algorithms for classification, its biggest disadvantage is that it never
    converges if the classes are not perfectly linearly separable. The classification
    task in the previous section would be an example of such a scenario. The reason
    for this is that the weights are continuously being updated since there is always
    at least one misclassified training example present in each epoch. Of course,
    you can change the learning rate and increase the number of epochs, but be warned
    that the perceptron will never converge on this dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'To make better use of our time, we will now take a look at another simple,
    yet more powerful, algorithm for linear and binary classification problems: **logistic
    regression**. Note that, despite its name, logistic regression is a model for
    classification, not regression.'
  prefs: []
  type: TYPE_NORMAL
- en: Logistic regression and conditional probabilities
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Logistic regression is a classification model that is very easy to implement
    and performs very well on linearly separable classes. It is one of the most widely
    used algorithms for classification in industry. Similar to the perceptron and
    Adaline, the logistic regression model in this chapter is also a linear model
    for binary classification.
  prefs: []
  type: TYPE_NORMAL
- en: '**Logistic regression for multiple classes**'
  prefs: []
  type: TYPE_NORMAL
- en: Note that logistic regression can be readily generalized to multiclass settings,
    which is known as **multinomial logistic regression**, or **softmax regression**.
    More detailed coverage of multinomial logistic regression is outside the scope
    of this book, but the interested reader can find more information in my lecture
    notes at [https://sebastianraschka.com/pdf/lecture-notes/stat453ss21/L08_logistic__slides.pdf](https://sebastianraschka.com/pdf/lecture-notes/stat453ss21/L08_logistic__slides.pdf)
    or [https://youtu.be/L0FU8NFpx4E](https://youtu.be/L0FU8NFpx4E).
  prefs: []
  type: TYPE_NORMAL
- en: Another way to use logistic regression in multiclass settings is via the OvR
    technique, which we discussed previously.
  prefs: []
  type: TYPE_NORMAL
- en: 'To explain the main mechanics behind logistic regression as a probabilistic
    model for binary classification, let’s first introduce the **odds**: the odds
    in favor of a particular event. The odds can be written as ![](img/B17582_03_006.png),
    where *p* stands for the probability of the positive event. The term “positive
    event” does not necessarily mean “good,” but refers to the event that we want
    to predict, for example, the probability that a patient has a certain disease
    given certain symptoms; we can think of the positive event as class label *y* = 1
    and the symptoms as features **x**. Hence, for brevity, we can define the probability
    *p* as *p* := *p*(*y* = 1|**x**), the conditional probability that a particular
    example belongs to a certain class 1 given its features, **x**.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can then further define the **logit** function, which is simply the logarithm
    of the odds (log-odds):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_03_007.png)'
  prefs: []
  type: TYPE_IMG
- en: Note that *log* refers to the natural logarithm, as it is the common convention
    in computer science. The *logit* function takes input values in the range 0 to
    1 and transforms them into values over the entire real-number range.
  prefs: []
  type: TYPE_NORMAL
- en: 'Under the logistic model, we assume that there is a linear relationship between
    the weighted inputs (referred to as net inputs in *Chapter 2*) and the log-odds:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_03_008.png)'
  prefs: []
  type: TYPE_IMG
- en: While the preceding describes an assumption we make about the linear relationship
    between the log-odds and the net inputs, what we are actually interested in is
    the probability *p*, the class-membership probability of an example given its
    features. While the logit function maps the probability to a real-number range,
    we can consider the inverse of this function to map the real-number range back
    to a [0, 1] range for the probability *p*.
  prefs: []
  type: TYPE_NORMAL
- en: 'This inverse of the logit function is typically called the **logistic sigmoid
    function**, which is sometimes simply abbreviated to **sigmoid function** due
    to its characteristic S-shape:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_03_009.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, *z* is the net input, the linear combination of weights, and the inputs
    (that is, the features associated with the training examples):'
  prefs: []
  type: TYPE_NORMAL
- en: '*z* = **w**^T**x** + *b*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s simply plot the sigmoid function for some values in the range –7
    to 7 to see how it looks:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'As a result of executing the previous code example, we should now see the S-shaped
    (sigmoidal) curve:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Chart, histogram  Description automatically generated](img/B17582_03_02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.2: A plot of the logistic sigmoid function'
  prefs: []
  type: TYPE_NORMAL
- en: We can see that ![](img/B17582_02_039.png) approaches 1 if *z* goes toward infinity
    (*z*→∞) since *e*^–^z becomes very small for large values of *z*. Similarly, ![](img/B17582_02_039.png)
    goes toward 0 for *z*→–∞ as a result of an increasingly large denominator. Thus,
    we can conclude that this sigmoid function takes real-number values as input and
    transforms them into values in the range [0, 1] with an intercept at ![](img/B17582_03_012.png).
  prefs: []
  type: TYPE_NORMAL
- en: To build some understanding of the logistic regression model, we can relate
    it to *Chapter 2*. In Adaline, we used the identity function, ![](img/B17582_02_040.png),
    as the activation function. In logistic regression, this activation function simply
    becomes the sigmoid function that we defined earlier.
  prefs: []
  type: TYPE_NORMAL
- en: 'The difference between Adaline and logistic regression is illustrated in the
    following figure, where the only difference is the activation function:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram, schematic  Description automatically generated](img/B17582_03_03.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.3: Logistic regression compared to Adaline'
  prefs: []
  type: TYPE_NORMAL
- en: The output of the sigmoid function is then interpreted as the probability of
    a particular example belonging to class 1, ![](img/B17582_03_014.png), given its
    features, *x*, and parameterized by the weights and bias, *w* and *b*. For example,
    if we compute ![](img/B17582_03_015.png) for a particular flower example, it means
    that the chance that this example is an `Iris-versicolor` flower is 80 percent.
    Therefore, the probability that this flower is an `Iris-setosa` flower can be
    calculated as *p*(*y* = 0|**x**; **w**, *b*) = 1 – *p*(*y* = 1|**x**; **w**, *b*) = 0.2,
    or 20 percent.
  prefs: []
  type: TYPE_NORMAL
- en: 'The predicted probability can then simply be converted into a binary outcome
    via a threshold function:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_03_016.png)'
  prefs: []
  type: TYPE_IMG
- en: 'If we look at the preceding plot of the sigmoid function, this is equivalent
    to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_03_017.png)'
  prefs: []
  type: TYPE_IMG
- en: In fact, there are many applications where we are not only interested in the
    predicted class labels, but where the estimation of the class-membership probability
    is particularly useful (the output of the sigmoid function prior to applying the
    threshold function). Logistic regression is used in weather forecasting, for example,
    not only to predict whether it will rain on a particular day, but also to report
    the chance of rain. Similarly, logistic regression can be used to predict the
    chance that a patient has a particular disease given certain symptoms, which is
    why logistic regression enjoys great popularity in the field of medicine.
  prefs: []
  type: TYPE_NORMAL
- en: Learning the model weights via the logistic loss function
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You have learned how we can use the logistic regression model to predict probabilities
    and class labels; now, let’s briefly talk about how we fit the parameters of the
    model, for instance, the weights and bias unit, *w* and *b*. In the previous chapter,
    we defined the mean squared error loss function as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_03_018.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We minimized this function in order to learn the parameters for our Adaline
    classification model. To explain how we can derive the loss function for logistic
    regression, let’s first define the likelihood, ![](img/B17582_03_019.png), that
    we want to maximize when we build a logistic regression model, assuming that the
    individual examples in our dataset are independent of one another. The formula
    is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_03_020.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In practice, it is easier to maximize the (natural) log of this equation, which
    is called the **log-likelihood** function:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_03_021.png)'
  prefs: []
  type: TYPE_IMG
- en: Firstly, applying the log function reduces the potential for numerical underflow,
    which can occur if the likelihoods are very small. Secondly, we can convert the
    product of factors into a summation of factors, which makes it easier to obtain
    the derivative of this function via the addition trick, as you may remember from
    calculus.
  prefs: []
  type: TYPE_NORMAL
- en: '**Deriving the likelihood function**'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can obtain the expression for the likelihood of the model given the data,
    ![](img/B17582_03_022.png), as follows. Given that we have a binary classification
    problem with class labels 0 and 1, we can think of the label 1 as a Bernoulli
    variable—it can take on two values, 0 and 1, with the probability *p* of being
    1: ![](img/B17582_03_023.png). For a single data point, we can write this probability
    as ![](img/B17582_03_024.png) and ![](img/B17582_03_025.png).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Putting these two expressions together, and using the shorthand ![](img/B17582_03_026.png),
    we get the probability mass function of the Bernoulli variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_03_027.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We can write the likelihood of the training labels given the assumption that
    all training examples are independent, using the multiplication rule to compute
    the probability that all events occur, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_03_028.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now, substituting the probability mass function of the Bernoulli variable,
    we arrive at the expression of the likelihood, which we attempt to maximize by
    changing the model parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_03_029.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now, we could use an optimization algorithm such as gradient ascent to maximize
    this log-likelihood function. (Gradient ascent works exactly the same way as gradient
    descent explained in *Chapter 2*, except that gradient ascent maximizes a function
    instead of minimizing it.) Alternatively, let’s rewrite the log-likelihood as
    a loss function, *L*, that can be minimized using gradient descent as in *Chapter
    2*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_03_030.png)'
  prefs: []
  type: TYPE_IMG
- en: 'To get a better grasp of this loss function, let’s take a look at the loss
    that we calculate for one single training example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_03_031.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Looking at the equation, we can see that the first term becomes zero if *y* = 0,
    and the second term becomes zero if *y* = 1:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_03_032.png)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting plot shows the sigmoid activation on the *x* axis in the range
    0 to 1 (the inputs to the sigmoid function were *z* values in the range –10 to
    10) and the associated logistic loss on the *y* axis:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Chart  Description automatically generated](img/B17582_03_04.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.4: A plot of the loss function used in logistic regression'
  prefs: []
  type: TYPE_NORMAL
- en: We can see that the loss approaches 0 (continuous line) if we correctly predict
    that an example belongs to class 1\. Similarly, we can see on the *y* axis that
    the loss also approaches 0 if we correctly predict *y* = 0 (dashed line). However,
    if the prediction is wrong, the loss goes toward infinity. The main point is that
    we penalize wrong predictions with an increasingly larger loss.
  prefs: []
  type: TYPE_NORMAL
- en: Converting an Adaline implementation into an algorithm for logistic regression
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'If we were to implement logistic regression ourselves, we could simply substitute
    the loss function, *L*, in our Adaline implementation from *Chapter 2*, with the
    new loss function:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_03_034.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We use this to compute the loss of classifying all training examples per epoch.
    Also, we need to swap the linear activation function with the sigmoid. If we make
    those changes to the Adaline code, we will end up with a working logistic regression
    implementation. The following is an implementation for full-batch gradient descent
    (but note that the same changes could be made to the stochastic gradient descent
    version as well):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: When we fit a logistic regression model, we have to keep in mind that it only
    works for binary classification tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, let’s consider only setosa and versicolor flowers (classes `0` and `1`)
    and check that our implementation of logistic regression works:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting decision region plot looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Chart, scatter chart  Description automatically generated](img/B17582_03_05.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.5: The decision region plot for the logistic regression model'
  prefs: []
  type: TYPE_NORMAL
- en: '**The gradient descent learning algorithm for logistic regression**'
  prefs: []
  type: TYPE_NORMAL
- en: If you compared the `LogisticRegressionGD` in the previous code with the `AdalineGD`
    code from *Chapter 2*, you may have noticed that the weight and bias update rules
    remained unchanged (except for the scaling factor 2). Using calculus, we can show
    that the parameter updates via gradient descent are indeed similar for logistic
    regression and Adaline. However, please note that the following derivation of
    the gradient descent learning rule is intended for readers who are interested
    in the mathematical concepts behind the gradient descent learning rule for logistic
    regression. It is not essential for following the rest of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 3.6* summarizes how we can calculate the partial derivative of the
    log-likelihood function with respect to the *j*th weight:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram  Description automatically generated](img/B17582_03_06.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.6: Calculating the partial derivative of the log-likelihood function'
  prefs: []
  type: TYPE_NORMAL
- en: Note that we omitted averaging over the training examples for brevity.
  prefs: []
  type: TYPE_NORMAL
- en: 'Remember from *Chapter 2* that we take steps in the opposite direction of the
    gradient. Hence, we flip ![](img/B17582_03_035.png) and update the *j*th weight
    as follows, including the learning rate ![](img/B17582_02_065.png):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_03_037.png)'
  prefs: []
  type: TYPE_IMG
- en: 'While the partial derivative of the loss function with respect to the bias
    unit is not shown, bias derivation follows the same overall concept using the
    chain rule, resulting in the following update rule:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_03_038.png)'
  prefs: []
  type: TYPE_IMG
- en: Both the weight and bias unit updates are equal to the ones for Adaline in *Chapter
    2*.
  prefs: []
  type: TYPE_NORMAL
- en: Training a logistic regression model with scikit-learn
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We just went through useful coding and math exercises in the previous subsection,
    which helped to illustrate the conceptual differences between Adaline and logistic
    regression. Now, let’s learn how to use scikit-learn’s more optimized implementation
    of logistic regression, which also supports multiclass settings off the shelf.
    Note that in recent versions of scikit-learn, the technique used for multiclass
    classification, multinomial, or OvR, is chosen automatically. In the following
    code example, we will use the `sklearn.linear_model.LogisticRegression` class
    as well as the familiar `fit` method to train the model on all three classes in
    the standardized flower training dataset. Also, we set `multi_class='ovr'` for
    illustration purposes. As an exercise for the reader, you may want to compare
    the results with `multi_class='multinomial'`. Note that the `multinomial` setting
    is now the default choice in scikit-learn’s `LogisticRegression` class and recommended
    in practice for mutually exclusive classes, such as those found in the Iris dataset.
    Here, “mutually exclusive” means that each training example can only belong to
    a single class (in contrast to multilabel classification, where a training example
    can be a member of multiple classes).
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s have a look at the code example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'After fitting the model on the training data, we plotted the decision regions,
    training examples, and test examples, as shown in *Figure 3.7*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![A picture containing chart  Description automatically generated](img/B17582_03_07.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.7: Decision regions for scikit-learn’s multi-class logistic regression
    model'
  prefs: []
  type: TYPE_NORMAL
- en: '**Algorithms for convex optimization**'
  prefs: []
  type: TYPE_NORMAL
- en: Note that there exist many different algorithms for solving optimization problems.
    For minimizing convex loss functions, such as the logistic regression loss, it
    is recommended to use more advanced approaches than regular **stochastic gradient
    descent** (**SGD**). In fact, scikit-learn implements a whole range of such optimization
    algorithms, which can be specified via the `solver` parameter, namely, `'newton-cg'`,
    `'lbfgs'`, `'``liblinear'`, `'sag'`, and `'saga'`.
  prefs: []
  type: TYPE_NORMAL
- en: While the logistic regression loss is convex, most optimization algorithms should
    converge to the global loss minimum with ease. However, there are certain advantages
    of using one algorithm over the other. For example, in previous versions (for
    instance, v 0.21), scikit-learn used `'liblinear'` as a default, which cannot
    handle the multinomial loss and is limited to the OvR scheme for multiclass classification.
    However, in scikit-learn v 0.22, the default solver was changed to `'lbfgs'`,
    which stands for the limited-memory **Broyden–Fletcher–Goldfarb–Shanno** (**BFGS**)
    algorithm ([https://en.wikipedia.org/wiki/Limited-memory_BFGS](https://en.wikipedia.org/wiki/Limited-memory_BFGS))
    and is more flexible in this regard.
  prefs: []
  type: TYPE_NORMAL
- en: Looking at the preceding code that we used to train the `LogisticRegression`
    model, you might now be wondering, “What is this mysterious parameter C?” We will
    discuss this parameter in the next subsection, where we will introduce the concepts
    of overfitting and regularization. However, before we move on to those topics,
    let’s finish our discussion of class membership probabilities.
  prefs: []
  type: TYPE_NORMAL
- en: 'The probability that training examples belong to a certain class can be computed
    using the `predict_proba` method. For example, we can predict the probabilities
    of the first three examples in the test dataset as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'This code snippet returns the following array:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: The first row corresponds to the class membership probabilities of the first
    flower, the second row corresponds to the class membership probabilities of the
    second flower, and so forth. Notice that the column-wise sum in each row is 1,
    as expected. (You can confirm this by executing `lr.predict_proba(X_test_std[:3,
    :]).sum(axis=1)`.)
  prefs: []
  type: TYPE_NORMAL
- en: 'The highest value in the first row is approximately 0.85, which means that
    the first example belongs to class 3 (`Iris-virginica`) with a predicted probability
    of 85 percent. So, as you may have already noticed, we can get the predicted class
    labels by identifying the largest column in each row, for example, using NumPy’s
    `argmax` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The returned class indices are shown here (they correspond to `Iris-virginica`,
    `Iris-setosa`, and `Iris-setosa`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding code example, we computed the conditional probabilities and
    converted these into class labels manually by using NumPy’s `argmax` function.
    In practice, the more convenient way of obtaining class labels when using scikit-learn
    is to call the `predict` method directly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Lastly, a word of caution if you want to predict the class label of a single
    flower example: scikit-learn expects a two-dimensional array as data input; thus,
    we have to convert a single row slice into such a format first. One way to convert
    a single row entry into a two-dimensional data array is to use NumPy’s `reshape`
    method to add a new dimension, as demonstrated here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Tackling overfitting via regularization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Overfitting is a common problem in machine learning, where a model performs
    well on training data but does not generalize well to unseen data (test data).
    If a model suffers from overfitting, we also say that the model has a high variance,
    which can be caused by having too many parameters, leading to a model that is
    too complex given the underlying data. Similarly, our model can also suffer from
    **underfitting** (high bias), which means that our model is not complex enough
    to capture the pattern in the training data well and therefore also suffers from
    low performance on unseen data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Although we have only encountered linear models for classification so far,
    the problems of overfitting and underfitting can be best illustrated by comparing
    a linear decision boundary to more complex, nonlinear decision boundaries, as
    shown in *Figure 3.8*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Chart, radar chart  Description automatically generated](img/B17582_03_08.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.8: Examples of underfitted, well-fitted, and overfitted models'
  prefs: []
  type: TYPE_NORMAL
- en: '**The bias-variance tradeoff**'
  prefs: []
  type: TYPE_NORMAL
- en: Often, researchers use the terms “bias” and “variance” or “bias-variance tradeoff”
    to describe the performance of a model—that is, you may stumble upon talks, books,
    or articles where people say that a model has a “high variance” or “high bias.”
    So, what does that mean? In general, we might say that “high variance” is proportional
    to overfitting and “high bias” is proportional to underfitting.
  prefs: []
  type: TYPE_NORMAL
- en: In the context of machine learning models, variance measures the consistency
    (or variability) of the model prediction for classifying a particular example
    if we retrain the model multiple times, for example, on different subsets of the
    training dataset. We can say that the model is sensitive to the randomness in
    the training data. In contrast, bias measures how far off the predictions are
    from the correct values in general if we rebuild the model multiple times on different
    training datasets; bias is the measure of the systematic error that is not due
    to randomness.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you are interested in the technical specification and derivation of the
    “bias” and “variance” terms, I’ve written about it in my lecture notes here: [https://sebastianraschka.com/pdf/lecture-notes/stat451fs20/08-model-eval-1-intro__notes.pdf](https://sebastianraschka.com/pdf/lecture-notes/stat451fs20/08-model-eval-1-intro__notes.pdf).'
  prefs: []
  type: TYPE_NORMAL
- en: One way of finding a good bias-variance tradeoff is to tune the complexity of
    the model via regularization. Regularization is a very useful method for handling
    collinearity (high correlation among features), filtering out noise from data,
    and eventually preventing overfitting.
  prefs: []
  type: TYPE_NORMAL
- en: 'The concept behind regularization is to introduce additional information to
    penalize extreme parameter (weight) values. The most common form of regularization
    is so-called **L2 regularization** (sometimes also called L2 shrinkage or weight
    decay), which can be written as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_03_039.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, ![](img/B17582_03_040.png) is the so-called **regularization parameter**.
    Note that the 2 in the denominator is merely a scaling factor, such that it cancels
    when computing the loss gradient. The sample size *n* is added to scale the regularization
    term similar to the loss.
  prefs: []
  type: TYPE_NORMAL
- en: '**Regularization and feature normalization**'
  prefs: []
  type: TYPE_NORMAL
- en: Regularization is another reason why feature scaling such as standardization
    is important. For regularization to work properly, we need to ensure that all
    our features are on comparable scales.
  prefs: []
  type: TYPE_NORMAL
- en: 'The loss function for logistic regression can be regularized by adding a simple
    regularization term, which will shrink the weights during model training:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_03_041.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The partial derivative of the unregularized loss is defined as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_03_042.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Adding the regularization term to the loss changes the partial derivative to
    the following form:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_03_043.png)'
  prefs: []
  type: TYPE_IMG
- en: Via the regularization parameter, ![](img/B17582_03_040.png), we can then control
    how closely we fit the training data, while keeping the weights small. By increasing
    the value of ![](img/B17582_03_040.png), we increase the regularization strength.
    Please note that the bias unit, which is essentially an intercept term or negative
    threshold, as we learned in *Chapter 2*, is usually not regularized.
  prefs: []
  type: TYPE_NORMAL
- en: 'The parameter, `C`, that is implemented for the `LogisticRegression` class
    in scikit-learn comes from a convention in support vector machines, which will
    be the topic of the next section. The term `C` is inversely proportional to the
    regularization parameter, ![](img/B17582_03_040.png). Consequently, decreasing
    the value of the inverse regularization parameter, `C`, means that we are increasing
    the regularization strength, which we can visualize by plotting the L2 regularization
    path for the two weight coefficients:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'By executing the preceding code, we fitted 10 logistic regression models with
    different values for the inverse-regularization parameter, `C`. For illustration
    purposes, we only collected the weight coefficients of class `1` (here, the second
    class in the dataset: `Iris-versicolor`) versus all classifiers—remember that
    we are using the OvR technique for multiclass classification.'
  prefs: []
  type: TYPE_NORMAL
- en: 'As we can see in the resulting plot, the weight coefficients shrink if we decrease
    parameter `C`, that is, if we increase the regularization strength:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Chart, line chart  Description automatically generated](img/B17582_03_09.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.9: The impact of the inverse regularization strength parameter C on
    L2 regularized model results'
  prefs: []
  type: TYPE_NORMAL
- en: Increasing the regularization strength can reduce overfitting, so we might ask
    why we don’t strongly regularize all models by default. The reason is that we
    have to be careful when adjusting the regularization strength. For instance, if
    the regularization strength is too high and the weights coefficients approach
    zero, the model can perform very poorly due to underfitting, as illustrated in
    *Figure 3.8*.
  prefs: []
  type: TYPE_NORMAL
- en: '**An additional resource on logistic regression**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Since in-depth coverage of the individual classification algorithms exceeds
    the scope of this book, *Logistic Regression: From Introductory to Advanced Concepts
    and Applications*, *Dr. Scott Menard*, *Sage Publications*, *2009*, is recommended
    to readers who want to learn more about logistic regression.'
  prefs: []
  type: TYPE_NORMAL
- en: Maximum margin classification with support vector machines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Another powerful and widely used learning algorithm is the **support vector
    machine** (**SVM**), which can be considered an extension of the perceptron. Using
    the perceptron algorithm, we minimized misclassification errors. However, in SVMs,
    our optimization objective is to maximize the margin. The margin is defined as
    the distance between the separating hyperplane (decision boundary) and the training
    examples that are closest to this hyperplane, which are the so-called **support
    vectors**.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is illustrated in *Figure 3.10*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Chart, diagram, scatter chart  Description automatically generated](img/B17582_03_10.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.10: SVM maximizes the margin between the decision boundary and training
    data points'
  prefs: []
  type: TYPE_NORMAL
- en: Maximum margin intuition
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The rationale behind having decision boundaries with large margins is that they
    tend to have a lower generalization error, whereas models with small margins are
    more prone to overfitting.
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, while the main intuition behind SVMs is relatively simple, the
    mathematics behind them is quite advanced and would require sound knowledge of
    constrained optimization.
  prefs: []
  type: TYPE_NORMAL
- en: 'Hence, the details behind maximum margin optimization in SVMs are beyond the
    scope of this book. However, we recommend the following resources if you are interested
    in learning more:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Chris J.C. Burges’ excellent explanation in *A Tutorial on Support Vector Machines
    for Pattern Recognition* (Data Mining and Knowledge Discovery, 2(2): 121-167,
    1998)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vladimir Vapnik’s book *The Nature of Statistical Learning Theory*, Springer
    Science+Business Media, Vladimir Vapnik, 2000
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Andrew Ng’s very detailed lecture notes available at [https://see.stanford.edu/materials/aimlcs229/cs229-notes3.pdf](https://see.stanford.edu/materials/aimlcs229/cs229-notes3.pdf)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dealing with a nonlinearly separable case using slack variables
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Although we don’t want to dive much deeper into the more involved mathematical
    concepts behind the maximum-margin classification, let’s briefly mention the so-called
    *slack variable*, which was introduced by Vladimir Vapnik in 1995 and led to the
    so-called **soft-margin classification**. The motivation for introducing the slack
    variable was that the linear constraints in the SVM optimization objective need
    to be relaxed for nonlinearly separable data to allow the convergence of the optimization
    in the presence of misclassifications, under appropriate loss penalization.
  prefs: []
  type: TYPE_NORMAL
- en: 'The use of the slack variable, in turn, introduces the variable, which is commonly
    referred to as *C* in SVM contexts. We can consider *C* as a hyperparameter for
    controlling the penalty for misclassification. Large values of *C* correspond
    to large error penalties, whereas we are less strict about misclassification errors
    if we choose smaller values for *C*. We can then use the *C* parameter to control
    the width of the margin and therefore tune the bias-variance tradeoff, as illustrated
    in *Figure 3.11*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Chart, scatter chart  Description automatically generated](img/B17582_03_11.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.11: The impact of large and small values of the inverse regularization
    strength *C* on classification'
  prefs: []
  type: TYPE_NORMAL
- en: This concept is related to regularization, which we discussed in the previous
    section in the context of regularized regression, where decreasing the value of
    `C` increases the bias (underfitting) and lowers the variance (overfitting) of
    the model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have learned the basic concepts behind a linear SVM, let’s train
    an SVM model to classify the different flowers in our Iris dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'The three decision regions of the SVM, visualized after training the classifier
    on the Iris dataset by executing the preceding code example, are shown in *Figure
    3.12*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![A picture containing scatter chart  Description automatically generated](img/B17582_03_12.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.12: SVM’s decision regions'
  prefs: []
  type: TYPE_NORMAL
- en: '**Logistic regression versus SVMs**'
  prefs: []
  type: TYPE_NORMAL
- en: In practical classification tasks, linear logistic regression and linear SVMs
    often yield very similar results. Logistic regression tries to maximize the conditional
    likelihoods of the training data, which makes it more prone to outliers than SVMs,
    which mostly care about the points that are closest to the decision boundary (support
    vectors). On the other hand, logistic regression has the advantage of being a
    simpler model and can be implemented more easily, and is mathematically easier
    to explain. Furthermore, logistic regression models can be easily updated, which
    is attractive when working with streaming data.
  prefs: []
  type: TYPE_NORMAL
- en: Alternative implementations in scikit-learn
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The scikit-learn library’s `LogisticRegression` class, which we used in the
    previous sections, can make use of the LIBLINEAR library by setting `solver='liblinear'`.
    LIBLINEAR is a highly optimized C/C++ library developed at the National Taiwan
    University ([http://www.csie.ntu.edu.tw/~cjlin/liblinear/](http://www.csie.ntu.edu.tw/~cjlin/liblinear/)).
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, the `SVC` class that we used to train an SVM makes use of LIBSVM,
    which is an equivalent C/C++ library specialized for SVMs ([http://www.csie.ntu.edu.tw/~cjlin/libsvm/](http://www.csie.ntu.edu.tw/~cjlin/libsvm/)).
  prefs: []
  type: TYPE_NORMAL
- en: The advantage of using LIBLINEAR and LIBSVM over, for example, native Python
    implementations is that they allow the extremely quick training of large amounts
    of linear classifiers. However, sometimes our datasets are too large to fit into
    computer memory. Thus, scikit-learn also offers alternative implementations via
    the `SGDClassifier` class, which also supports online learning via the `partial_fit`
    method. The concept behind the `SGDClassifier` class is similar to the stochastic
    gradient algorithm that we implemented in *Chapter 2* for Adaline.
  prefs: []
  type: TYPE_NORMAL
- en: 'We could initialize the SGD version of the perceptron (`loss=''perceptron''`),
    logistic regression (`loss=''log''`), and an SVM with default parameters (`loss=''hinge''`),
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Solving nonlinear problems using a kernel SVM
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Another reason why SVMs enjoy high popularity among machine learning practitioners
    is that they can be easily **kernelized** to solve nonlinear classification problems.
    Before we discuss the main concept behind the so-called **kernel SVM**, the most
    common variant of SVMs, let’s first create a synthetic dataset to see what such
    a nonlinear classification problem may look like.
  prefs: []
  type: TYPE_NORMAL
- en: Kernel methods for linearly inseparable data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Using the following code, we will create a simple dataset that has the form
    of an XOR gate using the `logical_or` function from NumPy, where 100 examples
    will be assigned the class label `1`, and 100 examples will be assigned the class
    label `-1`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'After executing the code, we will have an XOR dataset with random noise, as
    shown in *Figure 3.13*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Chart, scatter chart  Description automatically generated](img/B17582_03_13.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.13: A plot of the XOR dataset'
  prefs: []
  type: TYPE_NORMAL
- en: Obviously, we would not be able to separate the examples from the positive and
    negative class very well using a linear hyperplane as a decision boundary via
    the linear logistic regression or linear SVM model that we discussed in earlier
    sections.
  prefs: []
  type: TYPE_NORMAL
- en: 'The basic idea behind **kernel methods** for dealing with such linearly inseparable
    data is to create nonlinear combinations of the original features to project them
    onto a higher-dimensional space via a mapping function, ![](img/B17582_03_047.png),
    where the data becomes linearly separable. As shown in *Figure 3.14*, we can transform
    a two-dimensional dataset into a new three-dimensional feature space, where the
    classes become separable via the following projection:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_03_048.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This allows us to separate the two classes shown in the plot via a linear hyperplane
    that becomes a nonlinear decision boundary if we project it back onto the original
    feature space, as illustrated with the following concentric circle dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram  Description automatically generated](img/B17582_03_14.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.14: The process of classifying nonlinear data using kernel methods'
  prefs: []
  type: TYPE_NORMAL
- en: Using the kernel trick to find separating hyperplanes in a high-dimensional
    space
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To solve a nonlinear problem using an SVM, we would transform the training data
    into a higher-dimensional feature space via a mapping function, ![](img/B17582_03_047.png),
    and train a linear SVM model to classify the data in this new feature space. Then,
    we could use the same mapping function, ![](img/B17582_03_050.png), to transform
    new, unseen data to classify it using the linear SVM model.
  prefs: []
  type: TYPE_NORMAL
- en: However, one problem with this mapping approach is that the construction of
    the new features is computationally very expensive, especially if we are dealing
    with high-dimensional data. This is where the so-called **kernel trick** comes
    into play.
  prefs: []
  type: TYPE_NORMAL
- en: 'Although we did not go into much detail about how to solve the quadratic programming
    task to train an SVM, in practice, we just need to replace the dot product **x**^(^i^)^T**x**^(^j^)
    by ![](img/B17582_03_051.png). To save the expensive step of calculating this
    dot product between two points explicitly, we define a so-called **kernel function**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_03_052.png)'
  prefs: []
  type: TYPE_IMG
- en: 'One of the most widely used kernels is the **radial basis function** (**RBF**)
    kernel, which can simply be called the **Gaussian kernel**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_03_053.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This is often simplified to:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_03_054.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, ![](img/B17582_03_055.png) is a free parameter to be optimized.
  prefs: []
  type: TYPE_NORMAL
- en: Roughly speaking, the term “kernel” can be interpreted as a **similarity function**
    between a pair of examples. The minus sign inverts the distance measure into a
    similarity score, and, due to the exponential term, the resulting similarity score
    will fall into a range between 1 (for exactly similar examples) and 0 (for very
    dissimilar examples).
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have covered the big picture behind the kernel trick, let’s see
    if we can train a kernel SVM that is able to draw a nonlinear decision boundary
    that separates the XOR data well. Here, we simply use the `SVC` class from scikit-learn
    that we imported earlier and replace the `kernel=''linear''` parameter with `kernel=''rbf''`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'As we can see in the resulting plot, the kernel SVM separates the XOR data
    relatively well:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Chart, scatter chart  Description automatically generated](img/B17582_03_15.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.15: The decision boundary on the XOR data using a kernel method'
  prefs: []
  type: TYPE_NORMAL
- en: 'The ![](img/B17582_03_056.png) parameter, which we set to `gamma=0.1`, can
    be understood as a cut-off parameter for the Gaussian sphere. If we increase the
    value for ![](img/B17582_03_056.png), we increase the influence or reach of the
    training examples, which leads to a tighter and bumpier decision boundary. To
    get a better understanding of ![](img/B17582_03_056.png), let’s apply an RBF kernel
    SVM to our Iris flower dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Since we chose a relatively small value for ![](img/B17582_03_056.png), the
    resulting decision boundary of the RBF kernel SVM model will be relatively soft,
    as shown in *Figure 3.16*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![A picture containing chart  Description automatically generated](img/B17582_03_16.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.16: The decision boundaries on the Iris dataset using an RBF kernel
    SVM model with a small ![](img/B17582_03_056.png) value'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s increase the value of ![](img/B17582_03_056.png) and observe the
    effect on the decision boundary:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'In *Figure 3.17*, we can now see that the decision boundary around the classes
    `0` and `1` is much tighter using a relatively large value of ![](img/B17582_03_056.png):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Scatter chart  Description automatically generated](img/B17582_03_17.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.17: The decision boundaries on the Iris dataset using an RBF kernel
    SVM model with a large ![](img/B17582_03_056.png) value'
  prefs: []
  type: TYPE_NORMAL
- en: Although the model fits the training dataset very well, such a classifier will
    likely have a high generalization error on unseen data. This illustrates that
    the ![](img/B17582_03_064.png) parameter also plays an important role in controlling
    overfitting or variance when the algorithm is too sensitive to fluctuations in
    the training dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Decision tree learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Decision tree** classifiers are attractive models if we care about interpretability.
    As the name “decision tree” suggests, we can think of this model as breaking down
    our data by making a decision based on asking a series of questions.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s consider the following example in which we use a decision tree to decide
    upon an activity on a particular day:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_03_18.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.18: An example of a decision tree'
  prefs: []
  type: TYPE_NORMAL
- en: 'Based on the features in our training dataset, the decision tree model learns
    a series of questions to infer the class labels of the examples. Although *Figure
    3.18* illustrates the concept of a decision tree based on categorical variables,
    the same concept applies if our features are real numbers, like in the Iris dataset.
    For example, we could simply define a cut-off value along the **sepal width**
    feature axis and ask a binary question: “Is the sepal width ≥ 2.8 cm?”'
  prefs: []
  type: TYPE_NORMAL
- en: Using the decision algorithm, we start at the tree root and split the data on
    the feature that results in the largest **information gain** (**IG**), which will
    be explained in more detail in the following section. In an iterative process,
    we can then repeat this splitting procedure at each child node until the leaves
    are pure. This means that the training examples at each node all belong to the
    same class. In practice, this can result in a very deep tree with many nodes,
    which can easily lead to overfitting. Thus, we typically want to **prune** the
    tree by setting a limit for the maximum depth of the tree.
  prefs: []
  type: TYPE_NORMAL
- en: Maximizing IG – getting the most bang for your buck
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To split the nodes at the most informative features, we need to define an objective
    function to optimize via the tree learning algorithm. Here, our objective function
    is to maximize the IG at each split, which we define as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_03_065.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, *f* is the feature to perform the split; *D*[p] and *D*[j] are the dataset
    of the parent and *j*th child node; *I* is our **impurity** measure; *N*[p] is
    the total number of training examples at the parent node; and *N*[j] is the number
    of examples in the *j*th child node. As we can see, the information gain is simply
    the difference between the impurity of the parent node and the sum of the child
    node impurities—the lower the impurities of the child nodes, the larger the information
    gain. However, for simplicity and to reduce the combinatorial search space, most
    libraries (including scikit-learn) implement binary decision trees. This means
    that each parent node is split into two child nodes, *D*[left] and *D*[right]:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_03_066.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The three impurity measures or splitting criteria that are commonly used in
    binary decision trees are **Gini impurity** (*I*[G]), **entropy** (*I*[H]), and
    the **classification error** (*I*[E]). Let’s start with the definition of entropy
    for all **non-empty** classes (![](img/B17582_03_067.png)):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_03_068.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, *p*(*i*|*t*) is the proportion of the examples that belong to class *i*
    for a particular node, *t*. The entropy is therefore 0 if all examples at a node
    belong to the same class, and the entropy is maximal if we have a uniform class
    distribution. For example, in a binary class setting, the entropy is 0 if *p*(*i*=1|*t*) = 1
    or *p*(*i*=0|*t*) = 0\. If the classes are distributed uniformly with *p*(*i*=1|*t*) = 0.5
    and *p*(*i*=0|*t*) = 0.5, the entropy is 1\. Therefore, we can say that the entropy
    criterion attempts to maximize the mutual information in the tree.
  prefs: []
  type: TYPE_NORMAL
- en: 'To provide a visual intuition, let us visualize the entropy values for different
    class distributions via the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: '*Figure 3.19* below shows the plot produced by the preceding code:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Venn diagram  Description automatically generated](img/B17582_03_19.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.19: Entropy values for different class-membership probabilities'
  prefs: []
  type: TYPE_NORMAL
- en: 'The Gini impurity can be understood as a criterion to minimize the probability
    of misclassification:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_03_069.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Similar to entropy, the Gini impurity is maximal if the classes are perfectly
    mixed, for example, in a binary class setting (*c* = 2):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_03_070.png)'
  prefs: []
  type: TYPE_IMG
- en: However, in practice, both the Gini impurity and entropy typically yield very
    similar results, and it is often not worth spending much time on evaluating trees
    using different impurity criteria rather than experimenting with different pruning
    cut-offs. In fact, as you will see later in *Figure 3.21*, both the Gini impurity
    and entropy have a similar shape.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another impurity measure is the classification error:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_03_071.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This is a useful criterion for pruning, but not recommended for growing a decision
    tree, since it is less sensitive to changes in the class probabilities of the
    nodes. We can illustrate this by looking at the two possible splitting scenarios
    shown in *Figure 3.20*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_03_20.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.20: Decision tree data splits'
  prefs: []
  type: TYPE_NORMAL
- en: 'We start with a dataset, *D*[p], at the parent node, which consists of 40 examples
    from class 1 and 40 examples from class 2 that we split into two datasets, *D*[left]
    and *D*[right]. The information gain using the classification error as a splitting
    criterion would be the same (*IG*[E] = 0.25) in both scenarios, *A* and *B*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_03_072.png)'
  prefs: []
  type: TYPE_IMG
- en: 'However, the Gini impurity would favor the split in scenario *B* (![](img/B17582_03_073.png))
    over scenario *A* (*IG*[G] = 0.125), which is indeed purer:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_03_074.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Similarly, the entropy criterion would also favor scenario B (*IG*[H] = 0.31)
    over scenario A (*IG*[H] = 0.19):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_03_075.png)'
  prefs: []
  type: TYPE_IMG
- en: 'For a more visual comparison of the three different impurity criteria that
    we discussed previously, let’s plot the impurity indices for the probability range
    [0, 1] for class 1\. Note that we will also add a scaled version of the entropy
    (entropy / 2) to observe that the Gini impurity is an intermediate measure between
    entropy and the classification error. The code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'The plot produced by the preceding code example is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Chart  Description automatically generated](img/B17582_03_21.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.21: The different impurity indices for different class-membership
    probabilities between 0 and 1'
  prefs: []
  type: TYPE_NORMAL
- en: Building a decision tree
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Decision trees can build complex decision boundaries by dividing the feature
    space into rectangles. However, we have to be careful since the deeper the decision
    tree, the more complex the decision boundary becomes, which can easily result
    in overfitting. Using scikit-learn, we will now train a decision tree with a maximum
    depth of 4, using the Gini impurity as a criterion for impurity.
  prefs: []
  type: TYPE_NORMAL
- en: 'Although feature scaling may be desired for visualization purposes, note that
    feature scaling is not a requirement for decision tree algorithms. The code is
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'After executing the code example, we get the typical axis-parallel decision
    boundaries of the decision tree:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Scatter chart  Description automatically generated](img/B17582_03_22.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.22: The decision boundaries of the Iris data using a decision tree'
  prefs: []
  type: TYPE_NORMAL
- en: 'A nice feature in scikit-learn is that it allows us to readily visualize the
    decision tree model after training via the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: '![A picture containing text, sign  Description automatically generated](img/B17582_03_23.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.23: A decision tree model fit to the Iris dataset'
  prefs: []
  type: TYPE_NORMAL
- en: Setting `filled=True` in the `plot_tree` function we called colors the nodes
    by the majority class label at that node. There are many additional options available,
    which you can find in the documentation at [https://scikit-learn.org/stable/modules/generated/sklearn.tree.plot_tree.html](https://scikit-learn.org/stable/modules/generated/sklearn.tree.plot_tree.html).
  prefs: []
  type: TYPE_NORMAL
- en: Looking at the decision tree figure, we can now nicely trace back the splits
    that the decision tree determined from our training dataset. Regarding the feature
    splitting criterion at each node, note that the branches to the left correspond
    to “True” and branches to the right correspond to “False.”
  prefs: []
  type: TYPE_NORMAL
- en: Looking at the root node, it starts with 105 examples at the top. The first
    split uses a sepal width cut-off ≤ 0.75 cm for splitting the root node into two
    child nodes with 35 examples (left child node) and 70 examples (right child node).
    After the first split, we can see that the left child node is already pure and
    only contains examples from the `Iris-setosa` class (Gini impurity = 0). The further
    splits on the right are then used to separate the examples from the `Iris-versicolor`
    and `Iris-virginica` class.
  prefs: []
  type: TYPE_NORMAL
- en: Looking at this tree, and the decision region plot of the tree, we can see that
    the decision tree does a very good job of separating the flower classes. Unfortunately,
    scikit-learn currently does not implement functionality to manually post-prune
    a decision tree. However, we could go back to our previous code example, change
    the `max_depth` of our decision tree to `3`, and compare it to our current model,
    but we leave this as an exercise for the interested reader.
  prefs: []
  type: TYPE_NORMAL
- en: 'Alternatively, scikit-learn provides an automatic cost complexity post-pruning
    procedure for decision trees. Interested readers can find more information about
    this more advanced topic in the following tutorial: [https://scikit-learn.org/stable/auto_examples/tree/plot_cost_complexity_pruning.html](https://scikit-learn.org/stable/auto_examples/tree/plot_cost_complexity_pruning.html).'
  prefs: []
  type: TYPE_NORMAL
- en: Combining multiple decision trees via random forests
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Ensemble methods have gained huge popularity in applications of machine learning
    during the last decade due to their good classification performance and robustness
    toward overfitting. While we are going to cover different ensemble methods, including
    **bagging** and **boosting**, later in *Chapter 7*, *Combining Different Models
    for Ensemble Learning*, let’s discuss the decision tree-based **random forest**
    algorithm, which is known for its good scalability and ease of use. A random forest
    can be considered as an **ensemble** of decision trees. The idea behind a random
    forest is to average multiple (deep) decision trees that individually suffer from
    high variance to build a more robust model that has a better generalization performance
    and is less susceptible to overfitting. The random forest algorithm can be summarized
    in four simple steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Draw a random **bootstrap** sample of size *n* (randomly choose *n* examples
    from the training dataset with replacement).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Grow a decision tree from the bootstrap sample. At each node:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Randomly select *d* features without replacement.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Split the node using the feature that provides the best split according to the
    objective function, for instance, maximizing the information gain.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Repeat *steps 1*-*2* *k* times.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Aggregate the prediction by each tree to assign the class label by **majority
    vote**. Majority voting will be discussed in more detail in *Chapter 7*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We should note one slight modification in *step 2* when we are training the
    individual decision trees: instead of evaluating all features to determine the
    best split at each node, we only consider a random subset of those.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Sampling with and without replacement**'
  prefs: []
  type: TYPE_NORMAL
- en: In case you are not familiar with the terms sampling “with” and “without” replacement,
    let’s walk through a simple thought experiment. Let’s assume that we are playing
    a lottery game where we randomly draw numbers from an urn. We start with an urn
    that holds five unique numbers, 0, 1, 2, 3, and 4, and we draw exactly one number
    on each turn. In the first round, the chance of drawing a particular number from
    the urn would be 1/5\. Now, in sampling without replacement, we do not put the
    number back into the urn after each turn. Consequently, the probability of drawing
    a particular number from the set of remaining numbers in the next round depends
    on the previous round. For example, if we have a remaining set of numbers 0, 1,
    2, and 4, the chance of drawing number 0 would become 1/4 in the next turn.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, in random sampling with replacement, we always return the drawn number
    to the urn so that the probability of drawing a particular number at each turn
    does not change; we can draw the same number more than once. In other words, in
    sampling *with* replacement, the samples (numbers) are independent and have a
    covariance of zero. For example, the results from five rounds of drawing random
    numbers could look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Random sampling without replacement: 2, 1, 3, 4, 0'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Random sampling with replacement: 1, 3, 3, 4, 1'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Although random forests don’t offer the same level of interpretability as decision
    trees, a big advantage of random forests is that we don’t have to worry so much
    about choosing good hyperparameter values. We typically don’t need to prune the
    random forest since the ensemble model is quite robust to noise from averaging
    the predictions among the individual decision trees. The only parameter that we
    need to care about in practice is the number of trees, *k*, (*step 3*) that we
    choose for the random forest. Typically, the larger the number of trees, the better
    the performance of the random forest classifier at the expense of an increased
    computational cost.
  prefs: []
  type: TYPE_NORMAL
- en: Although it is less common in practice, other hyperparameters of the random
    forest classifier that can be optimized—using techniques that we will discuss
    in *Chapter 6*, *Learning Best Practices for Model Evaluation and Hyperparameter**Tuning*—are
    the size, *n*, of the bootstrap sample (*step 1*) and the number of features,
    *d*, that are randomly chosen for each split (*step 2a*), respectively. Via the
    sample size, *n*, of the bootstrap sample, we control the bias-variance tradeoff
    of the random forest.
  prefs: []
  type: TYPE_NORMAL
- en: Decreasing the size of the bootstrap sample increases the diversity among the
    individual trees since the probability that a particular training example is included
    in the bootstrap sample is lower. Thus, shrinking the size of the bootstrap samples
    may increase the *randomness* of the random forest, and it can help to reduce
    the effect of overfitting. However, smaller bootstrap samples typically result
    in a lower overall performance of the random forest and a small gap between training
    and test performance, but a low test performance overall. Conversely, increasing
    the size of the bootstrap sample may increase the degree of overfitting. Because
    the bootstrap samples, and consequently the individual decision trees, become
    more similar to one another, they learn to fit the original training dataset more
    closely.
  prefs: []
  type: TYPE_NORMAL
- en: In most implementations, including the `RandomForestClassifier` implementation
    in scikit-learn, the size of the bootstrap sample is chosen to be equal to the
    number of training examples in the original training dataset, which usually provides
    a good bias-variance tradeoff. For the number of features, *d*, at each split,
    we want to choose a value that is smaller than the total number of features in
    the training dataset. A reasonable default that is used in scikit-learn and other
    implementations is ![](img/B17582_03_076.png), where *m* is the number of features
    in the training dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'Conveniently, we don’t have to construct the random forest classifier from
    individual decision trees by ourselves because there is already an implementation
    in scikit-learn that we can use:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'After executing the preceding code, we should see the decision regions formed
    by the ensemble of trees in the random forest, as shown in *Figure 3.24*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Scatter chart  Description automatically generated](img/B17582_03_24.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.24: Decision boundaries on the Iris dataset using a random forest'
  prefs: []
  type: TYPE_NORMAL
- en: Using the preceding code, we trained a random forest from 25 decision trees
    via the `n_estimators` parameter. By default, it uses the Gini impurity measure
    as a criterion to split the nodes. Although we are growing a very small random
    forest from a very small training dataset, we used the `n_jobs` parameter for
    demonstration purposes, which allows us to parallelize the model training using
    multiple cores of our computer (here, two cores). If you encounter errors with
    this code, your computer may not support multiprocessing. You can omit the `n_jobs`
    parameter or set it to `n_jobs=None`.
  prefs: []
  type: TYPE_NORMAL
- en: K-nearest neighbors – a lazy learning algorithm
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The last supervised learning algorithm that we want to discuss in this chapter
    is the **k-nearest neighbor** (**KNN**) classifier, which is particularly interesting
    because it is fundamentally different from the learning algorithms that we have
    discussed so far.
  prefs: []
  type: TYPE_NORMAL
- en: KNN is a typical example of a **lazy learner**. It is called “lazy” not because
    of its apparent simplicity, but because it doesn’t learn a discriminative function
    from the training data but memorizes the training dataset instead.
  prefs: []
  type: TYPE_NORMAL
- en: '**Parametric versus non-parametric models**'
  prefs: []
  type: TYPE_NORMAL
- en: Machine learning algorithms can be grouped into parametric and non-parametric
    models. Using parametric models, we estimate parameters from the training dataset
    to learn a function that can classify new data points without requiring the original
    training dataset anymore. Typical examples of parametric models are the perceptron,
    logistic regression, and the linear SVM. In contrast, non-parametric models can’t
    be characterized by a fixed set of parameters, and the number of parameters changes
    with the amount of training data. Two examples of non-parametric models that we
    have seen so far are the decision tree classifier/random forest and the kernel
    (but not linear) SVM.
  prefs: []
  type: TYPE_NORMAL
- en: KNN belongs to a subcategory of non-parametric models described as instance-based
    learning. Models based on instance-based learning are characterized by memorizing
    the training dataset, and lazy learning is a special case of instance-based learning
    that is associated with no (zero) cost during the learning process.
  prefs: []
  type: TYPE_NORMAL
- en: 'The KNN algorithm itself is fairly straightforward and can be summarized by
    the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Choose the number of *k* and a distance metric
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Find the *k*-nearest neighbors of the data record that we want to classify
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Assign the class label by majority vote
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Figure 3.25* illustrates how a new data point (**?**) is assigned the triangle
    class label based on majority voting among its five nearest neighbors:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_03_25.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.25: How k-nearest neighbors works'
  prefs: []
  type: TYPE_NORMAL
- en: Based on the chosen distance metric, the KNN algorithm finds the *k* examples
    in the training dataset that are closest (most similar) to the point that we want
    to classify. The class label of the data point is then determined by a majority
    vote among its *k* nearest neighbors.
  prefs: []
  type: TYPE_NORMAL
- en: '**Advantages and disadvantages of memory-based approaches**'
  prefs: []
  type: TYPE_NORMAL
- en: The main advantage of such a memory-based approach is that the classifier immediately
    adapts as we collect new training data. However, the downside is that the computational
    complexity for classifying new examples grows linearly with the number of examples
    in the training dataset in the worst-case scenario—unless the dataset has very
    few dimensions (features) and the algorithm has been implemented using efficient
    data structures for querying the training data more effectively. Such data structures
    include k-d tree ([https://en.wikipedia.org/wiki/K-d_tree](https://en.wikipedia.org/wiki/K-d_tree))
    and ball tree ([https://en.wikipedia.org/wiki/Ball_tree](https://en.wikipedia.org/wiki/Ball_tree)),
    which are both supported in scikit-learn. Furthermore, next to computational costs
    for querying data, large datasets can also be problematic in terms of limited
    storage capacities.
  prefs: []
  type: TYPE_NORMAL
- en: However, in many cases when we are working with relatively small to medium-sized
    datasets, memory-based methods can provide good predictive and computational performance
    and are thus a good choice for approaching many real-world problems. Recent examples
    of using nearest neighbor methods include predicting properties of pharmaceutical
    drug targets (*Machine Learning to Identify Flexibility Signatures of Class A
    GPCR Inhibition*, Biomolecules, 2020, Joe Bemister-Buffington, Alex J. Wolf, Sebastian
    Raschka, and Leslie A. Kuhn, [https://www.mdpi.com/2218-273X/10/3/454](https://www.mdpi.com/2218-273X/10/3/454))
    and state-of-the-art language models (*Efficient Nearest Neighbor Language Models*,
    2021, Junxian He, Graham Neubig, and Taylor Berg-Kirkpatrick, [https://arxiv.org/abs/2109.04212](https://arxiv.org/abs/2109.04212)).
  prefs: []
  type: TYPE_NORMAL
- en: 'By executing the following code, we will now implement a KNN model in scikit-learn
    using a Euclidean distance metric:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'By specifying five neighbors in the KNN model for this dataset, we obtain a
    relatively smooth decision boundary, as shown in *Figure 3.26*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![A picture containing map  Description automatically generated](img/B17582_03_26.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.26: k-nearest neighbors’ decision boundaries on the Iris dataset'
  prefs: []
  type: TYPE_NORMAL
- en: '**Resolving ties**'
  prefs: []
  type: TYPE_NORMAL
- en: In the case of a tie, the scikit-learn implementation of the KNN algorithm will
    prefer the neighbors with a closer distance to the data record to be classified.
    If the neighbors have similar distances, the algorithm will choose the class label
    that comes first in the training dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'The *right* choice of *k* is crucial to finding a good balance between overfitting
    and underfitting. We also have to make sure that we choose a distance metric that
    is appropriate for the features in the dataset. Often, a simple Euclidean distance
    measure is used for real-value examples, for example, the flowers in our Iris
    dataset, which have features measured in centimeters. However, if we are using
    a Euclidean distance measure, it is also important to standardize the data so
    that each feature contributes equally to the distance. The `minkowski` distance
    that we used in the previous code is just a generalization of the Euclidean and
    Manhattan distance, which can be written as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_03_077.png)'
  prefs: []
  type: TYPE_IMG
- en: It becomes the Euclidean distance if we set the parameter `p=2` or the Manhattan
    distance at `p=1`. Many other distance metrics are available in scikit-learn and
    can be provided to the `metric` parameter. They are listed at [https://scikit-learn.org/stable/modules/generated/sklearn.metrics.DistanceMetric.html](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.DistanceMetric.html).
  prefs: []
  type: TYPE_NORMAL
- en: Lastly, it is important to mention that KNN is very susceptible to overfitting
    due to the **curse of dimensionality**. The curse of dimensionality describes
    the phenomenon where the feature space becomes increasingly sparse for an increasing
    number of dimensions of a fixed-size training dataset. We can think of even the
    closest neighbors as being too far away in a high-dimensional space to give a
    good estimate.
  prefs: []
  type: TYPE_NORMAL
- en: We discussed the concept of regularization in the section about logistic regression
    as one way to avoid overfitting. However, in models where regularization is not
    applicable, such as decision trees and KNN, we can use feature selection and dimensionality
    reduction techniques to help us to avoid the curse of dimensionality. This will
    be discussed in more detail in the next two chapters.
  prefs: []
  type: TYPE_NORMAL
- en: '**Alternative machine learning implementations with GPU support**'
  prefs: []
  type: TYPE_NORMAL
- en: 'When working with large datasets, running k-nearest neighbors or fitting random
    forests with many estimators can require substantial computing resources and processing
    time. If you have a computer equipped with an NVIDIA GPU that is compatible with
    recent versions of NVIDIA’s CUDA library, we recommend considering the RAPIDS
    ecosystem ([https://docs.rapids.ai/api](https://docs.rapids.ai/api)). For instance,
    RAPIDS’ cuML ([https://docs.rapids.ai/api/cuml/stable/](https://docs.rapids.ai/api/cuml/stable/))
    library implements many of scikit-learn’s machine learning algorithms with GPU
    support to accelerate the processing speeds. You can find an introduction to cuML
    at [https://docs.rapids.ai/api/cuml/stable/estimator_intro.html](https://docs.rapids.ai/api/cuml/stable/estimator_intro.html).
    If you are interested in learning more about the RAPIDS ecosystem, please also
    see the freely accessible journal article that we wrote in collaboration with
    the RAPIDS team: *Machine Learning in Python: Main Developments and Technology
    Trends in Data Science, Machine Learning, and Artificial Intelligence* ([https://www.mdpi.com/2078-2489/11/4/193](https://www.mdpi.com/2078-2489/11/4/193)).'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you learned about many different machine learning algorithms
    that are used to tackle linear and nonlinear problems. You have seen that decision
    trees are particularly attractive if we care about interpretability. Logistic
    regression is not only a useful model for online learning via SGD, but also allows
    us to predict the probability of a particular event.
  prefs: []
  type: TYPE_NORMAL
- en: Although SVMs are powerful linear models that can be extended to nonlinear problems
    via the kernel trick, they have many parameters that have to be tuned in order
    to make good predictions. In contrast, ensemble methods, such as random forests,
    don’t require much parameter tuning and don’t overfit as easily as decision trees,
    which makes them attractive models for many practical problem domains. The KNN
    classifier offers an alternative approach to classification via lazy learning
    that allows us to make predictions without any model training, but with a more
    computationally expensive prediction step.
  prefs: []
  type: TYPE_NORMAL
- en: However, even more important than the choice of an appropriate learning algorithm
    is the available data in our training dataset. No algorithm will be able to make
    good predictions without informative and discriminatory features.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will discuss important topics regarding the preprocessing
    of data, feature selection, and dimensionality reduction, which means that we
    will need to build powerful machine learning models. Later, in *Chapter 6*, *Learning
    Best Practices for Model Evaluation and Hyperparameter Tuning*, we will see how
    we can evaluate and compare the performance of our models and learn useful tricks
    to fine-tune the different algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Join our book’s Discord space
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Join the book’s Discord workspace for a monthly *Ask me Anything* session with
    the authors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://packt.link/MLwPyTorch](https://packt.link/MLwPyTorch)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/QR_Code874410888448293359.png)'
  prefs: []
  type: TYPE_IMG
