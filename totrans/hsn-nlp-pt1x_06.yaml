- en: '*Chapter 4*: Text Preprocessing, Stemming, and Lemmatization'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第4章*：文本预处理，词干化和词形归并'
- en: Textual data can be gathered from a number of different sources and takes many
    different forms. Text can be tidy and readable or raw and messy and can also come
    in many different styles and formats. Being able to preprocess this data so that
    it can be converted into a standard format before it reaches our NLP models is
    what we'll be looking at in this chapter.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 文本数据可以从许多不同的来源收集，并采用许多不同的形式。文本可以整洁可读，也可以原始混乱，还可以以许多不同的样式和格式出现。能够对此数据进行预处理，使其能够在到达我们的NLP模型之前转换为标准格式，这是我们将在本章中探讨的内容。
- en: 'Stemming and lemmatization, similar to tokenization, are other forms of NLP
    preprocessing. However, unlike tokenization, which reduces a document into individual
    words, stemming and lemmatization are attempts to reduce these words further to
    their lexical roots. For example, almost any verb in English has many different
    variations, depending on tense:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 词干化和词形归并，类似于分词，是NLP预处理的其他形式。然而，与将文档减少为单个词语的分词不同，词干化和词形归并试图进一步将这些词语减少到它们的词汇根。例如，英语中几乎任何动词都有许多不同的变体，取决于时态：
- en: '*He jumped*'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '*他跳跃了*'
- en: '*He is jumping*'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '*他正在跳跃*'
- en: '*He jumps*'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '*他跳跃*'
- en: While all these words are different, they all relate to the same root word –
    **jump**. Stemming and lemmatization are both techniques we can use to reduce
    word variations to their common roots.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管所有这些单词不同，它们都与相同的词根词 – **jump** 相关。词干化和词形归并都是我们可以使用的技术，用于将单词变体减少到它们的共同词根。
- en: In this chapter, we will explain how to perform preprocessing on textual data,
    as well as explore both stemming and lemmatization and show how these can be implemented
    in Python.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将解释如何对文本数据进行预处理，以及探索词干化和词形归并，并展示如何在Python中实现这些技术。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Text preprocessing
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文本预处理
- en: Stemming
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 词干化
- en: Lemmatization
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 词形归并
- en: Uses of stemming and lemmatization
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 词干化和词形归并的用途
- en: Technical requirements
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: For the text preprocessing in this chapter, we will mostly use inbuilt Python
    functions, but we will also use the external `BeautifulSoup` package. For stemming
    and lemmatization, we will use the NLTK Python package. All the code in this chapter
    can be found at [https://github.com/PacktPublishing/Hands-On-Natural-Language-Processing-with-PyTorch-1.x/tree/master/Chapter4](https://github.com/PacktPublishing/Hands-On-Natural-Language-Processing-with-PyTorch-1.x/tree/master/Chapter4).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本章中的文本预处理，我们将主要使用Python内置函数，但也会使用外部的`BeautifulSoup`包。对于词干化和词形归并，我们将使用NLTK
    Python包。本章的所有代码可以在[https://github.com/PacktPublishing/Hands-On-Natural-Language-Processing-with-PyTorch-1.x/tree/master/Chapter4](https://github.com/PacktPublishing/Hands-On-Natural-Language-Processing-with-PyTorch-1.x/tree/master/Chapter4)找到。
- en: Text preprocessing
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 文本预处理
- en: Textual data can come in a variety of formats and styles. Text may be in a structured,
    readable format or in a more raw, unstructured format. Our text may contain punctuation
    and symbols that we don't wish to include in our models or may contain HTML and
    other non-textual formatting. This is of particular concern when scraping text
    from online sources. In order to prepare our text so that it can be input into
    any NLP models, we must perform preprocessing. This will clean our data so that
    it is in a standard format. In this section, we will illustrate some of these
    preprocessing steps in more detail.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 文本数据可以以多种格式和样式出现。文本可能以结构化、可读的格式或更原始、非结构化的格式存在。我们的文本可能包含我们不希望在模型中包含的标点符号和符号，或者可能包含HTML和其他非文本格式。这在从在线源获取文本时尤为重要。为了准备我们的文本以便能够输入到任何NLP模型中，我们必须进行预处理。这将清洁我们的数据，使其处于标准格式。在本节中，我们将详细说明一些这些预处理步骤。
- en: Removing HTML
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 移除HTML
- en: 'When scraping text from online sources, you may find that your text contains
    HTML markup and other non-textual artifacts. We do not generally want to include
    these in our NLP inputs for our models, so these should be removed by default.
    For example, in HTML, the `<b>` tag indicates that the text following it should
    be in bold font. However, this does not contain any textual information about
    the content of the sentence, so we should remove this. Fortunately, in Python,
    there is a package called `BeautifulSoup` that allows us to remove all HTML in
    a few lines:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 当从在线源中抓取文本时，您可能会发现您的文本包含HTML标记和其他非文本性的工件。通常我们不希望将这些内容包含在我们的NLP输入中供我们的模型使用，因此默认应删除这些内容。例如，在HTML中，`<b>`标签指示其后的文本应为粗体字体。然而，这并未包含有关句子内容的任何文本信息，因此我们应该将其删除。幸运的是，在Python中有一个名为`BeautifulSoup`的包，可以让我们用几行代码轻松删除所有HTML：
- en: '[PRE0]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This returns the following output:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这将返回以下输出：
- en: '![Figure 4.1 – Removing HTML'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '![图4.1 – 删除HTML'
- en: '](img/B12365_04_01.jpg)'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B12365_04_01.jpg)'
- en: Figure 4.1 – Removing HTML
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.1 – 删除HTML
- en: The preceding screenshot shows that the HTML has been successfully removed.
    This could be useful in any situations where HTML code may be present within raw
    text data, such as when scraping a web page for data.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的截图显示已成功删除了HTML。这在原始文本数据中存在HTML代码的任何情况下可能很有用，例如在从网页上抓取数据时。
- en: Converting text into lowercase
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将文本转换为小写
- en: 'It is standard practice when preprocessing text to convert everything into
    lowercase. This is because any two words that are the same should be considered
    semantically identical, regardless of whether they are capitalized or not. ''`Cat`'',
    ''`cat`'', and ''`CAT`'' are all the same words but just have different elements
    capitalized. Our models will generally consider these three words as separate
    entities as they are not identical. Therefore, it is standard practice to convert
    all words into lowercase so that these words are all semantically and structurally
    identical. This can be done very easily within Python using the following lines of
    code:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在预处理文本时，将所有内容转换为小写是标准做法。这是因为任何两个相同的单词应该被认为在语义上是相同的，无论它们是否大写。 '`Cat`'，'`cat`'和'`CAT`'都是相同的单词，只是元素大小写不同。我们的模型通常会将这三个单词视为不同实体，因为它们并不相同。因此，将所有单词转换为小写是标准做法，这样这些单词在语义上和结构上都是相同的。在Python中，可以通过以下几行代码很容易地完成这个过程：
- en: '[PRE1]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'This returns the following output:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这将返回以下输出：
- en: '![Figure 4.2 – Converting input into lowercase'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '![图4.2 – 将输入转换为小写'
- en: '](img/B12365_04_02.jpg)'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B12365_04_02.jpg)'
- en: Figure 4.2 – Converting input into lowercase
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.2 – 将输入转换为小写
- en: This shows that the inputs have all been transformed into identical lowercase
    representations. There are a few examples where capitalization may actually provide
    additional semantic information. For example, *May* (the month) and *may* (meaning
    *might*) are semantically different and *May* (the month) will always be capitalized.
    However, instances like this are very rare and it is much more efficient to convert
    everything into lowercase than trying to account for these rare examples.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这显示输入已全部转换为相同的小写表示。有几个例子，大写实际上可能提供额外的语义信息。例如，*May*（月份）和*may*（表示“可能”）在语义上是不同的，*May*（月份）始终大写。然而，这种情况非常罕见，将所有内容转换为小写比试图考虑这些罕见例子要有效得多。
- en: It is worth noting that capitalization may be useful in some tasks such as part
    of speech tagging, where a capital letter may indicate the word's role in the
    sentence, and named entity recognition, where a capital letter may indicate that
    a word is a proper noun rather than the non-proper noun alternative; for example,
    *Turkey* (the country) and *turkey* (the bird).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 大写在某些任务中可能很有用，例如词性标注，其中大写字母可能表明单词在句子中的角色，以及命名实体识别，其中大写字母可能表明单词是专有名词而不是非专有名词替代词；例如，*Turkey*（国家）和*turkey*（鸟）。
- en: Removing punctuation
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 删除标点符号
- en: 'Sometimes, depending on the type of model being constructed, we may wish to
    remove punctuation from our input text. This is particularly useful in models
    where we are aggregating word counts, such as in a bag-of-words representation.
    The presence of a full stop or a comma within the sentence doesn''t add any useful
    information about the semantic content of the sentence. However, more complicated
    models that take into account the position of punctuation within the sentence
    may actually use the position of the punctuation to infer a different meaning.
    A classic example is as follows:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，根据正在构建的模型类型，我们可能希望从输入文本中删除标点符号。这在像词袋表示法这样的模型中特别有用，我们在这些模型中聚合词频。句子中的句号或逗号并不会增加关于句子语义内容的有用信息。然而，在考虑标点符号位置的复杂模型中，实际上可以使用标点符号的位置来推断不同的含义。一个经典的例子如下：
- en: '*The panda eats shoots and leaves*'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '*熊猫吃饭开枪和离开*'
- en: '*The panda eats, shoots, and leaves*'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '*熊猫吃饭，开枪和离开*'
- en: 'Here, the addition of a comma transforms the sentence describing a panda''s
    eating habits into a sentence describing an armed robbery of a restaurant by a
    panda! Nevertheless, it is still important to be able to remove punctuation from
    sentences for the sake of consistency. We can do this in Python by using the `re`
    library, to match any punctuation using a regular expression, and the `sub()`
    method, to replace any matched punctuation with an empty character:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，通过添加逗号，将描述熊猫饮食习惯的句子转变为描述熊猫抢劫餐馆的句子！然而，为了保持一致性，能够从句子中删除标点符号仍然很重要。我们可以通过使用
    `re` 库来实现这一点，在正则表达式中匹配任何标点符号，并使用 `sub()` 方法将任何匹配的标点符号替换为空字符来完成这一操作：
- en: '[PRE2]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'This returns the following output:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这返回以下输出：
- en: '![Figure 4.3 – Removing punctuation from input'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '![图4.3 – 从输入中删除标点符号'
- en: '](img/B12365_04_03.jpg)'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B12365_04_03.jpg)'
- en: Figure 4.3 – Removing punctuation from input
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.3 – 从输入中删除标点符号
- en: This shows that the punctuation has been removed from the input sentence.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这表明输入句子中的标点已被移除。
- en: 'There may be instances where we may not wish to directly remove punctuation.
    A good example would be the use of the ampersand (`&`), which in almost every
    instance is used interchangeably with the word "`and`". Therefore, rather than
    completely removing the ampersand, we may instead opt to replace it directly with
    the word "`and`". We can easily implement this in Python using the `.replace()`
    function:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 可能存在我们不希望直接删除标点符号的情况。一个很好的例子是使用和符号 (`&`)，几乎在每个实例中都可以与单词 "`and`" 交换使用。因此，与其完全删除和符号，我们可能会选择直接用单词
    "`and`" 替换它。我们可以在Python中使用 `.replace()` 函数轻松实现这一点：
- en: '[PRE3]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'This returns the following output:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这返回以下输出：
- en: '![Figure 4.4 – Removing and replacing punctuation'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '![图4.4 – 删除和替换标点符号'
- en: '](img/B12365_04_04.jpg)'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B12365_04_04.jpg)'
- en: Figure 4.4 – Removing and replacing punctuation
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.4 – 删除和替换标点符号
- en: 'It is also worth considering specific circumstances where punctuation may be
    essential for the representation of a sentence. One crucial example is email addresses.
    Removing the `@` from email addresses doesn''t make the address any more readable:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 同样值得考虑的是特定情况下标点符号可能对句子的表达至关重要。一个关键的例子是电子邮件地址。从电子邮件地址中删除 `@` 不会使地址更易读：
- en: '`name@gmail.com`'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '`name@gmail.com`'
- en: 'Removing the punctuation returns this:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 删除标点符号返回如下结果：
- en: namegmailcom
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: namegmailcom
- en: So, in instances like this, it may be preferable to remove the whole item altogether,
    according to the requirements and purpose of your NLP model.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在这种情况下，根据您的NLP模型的要求和目的，可能更倾向于完全删除整个项目。
- en: Replacing numbers
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 替换数字
- en: 'Similarly, with numbers, we also want to standardize our outputs. Numbers can
    be written as digits (9, 8, 7) or as actual words (nine, eight, seven). It may
    be worth transforming these all into a single, standardized representation so
    that 1 and one are not treated as separate entities. We can do this in Python
    using the following methodology:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 同样地，对于数字，我们也希望标准化我们的输出。数字可以用数字（9、8、7）或实际单词（九、八、七）来表示。值得将这些统一转换为单一的标准表示形式，以便1和one不被视为不同实体。我们可以使用以下方法在Python中实现这一点：
- en: '[PRE4]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'This returns the following output:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这返回以下输出：
- en: '![Figure 4.5 – Replacing numbers with text'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '![图4.5 – 用文本替换数字'
- en: '](img/B12365_04_05.jpg)'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B12365_04_05.jpg)'
- en: Figure 4.5 – Replacing numbers with text
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.5 – 用文本替换数字
- en: This shows that we have successfully converted our digits into text.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 这表明我们已成功将数字转换为文本。
- en: 'However, in a similar fashion to processing email addresses, processing phone
    numbers may not require the same representation as regular numbers. This is illustrated
    in the following example:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，类似于处理电子邮件地址，处理电话号码可能不需要与常规数字相同的表示形式。以下示例说明了这一点：
- en: '[PRE5]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'This returns the following output:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 这返回以下输出：
- en: '![Figure 4.6 – Converting a phone number into text'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.6 – 将电话号码转换为文本'
- en: '](img/B12365_04_06.jpg)'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B12365_04_06.jpg)'
- en: Figure 4.6 – Converting a phone number into text
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.6 – 将电话号码转换为文本
- en: Clearly, the input in the preceding example is a phone number, so the full text
    representation is not necessarily fit for purpose. In instances like this, it
    may be preferable to drop any long numbers from our input text.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，在上述示例中输入的是电话号码，因此完整的文本表示未必适合特定用途。在这种情况下，可能更倾向于从我们的输入文本中删除任何较长的数字。
- en: Stemming and lemmatization
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 词干提取和词形还原
- en: 'In language, **inflection** is how different grammatical categories such as
    tense, mood, or gender can be expressed by modifying a common root word. This
    often involves changing the prefix or suffix of a word but can also involve modifying
    the entire word. For example, we can make modifications to a verb to change its
    tense:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在语言中，**屈折变化**是通过修改一个共同的根词来表达不同的语法类别，如时态、语气或性别。这通常涉及改变单词的前缀或后缀，但也可能涉及修改整个单词。例如，我们可以修改动词以改变其时态：
- en: '*Run -> Runs (Add "s" suffix to make it present tense)*'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '*Run -> Runs（添加 "s" 后缀以使其现在时）*'
- en: '*Run -> Ran (Modify middle letter to "a" to make it past tense)*'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '*Run -> Ran（修改中间字母为 "a" 以使其过去时）*'
- en: 'But in some cases, the whole word changes:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 但在某些情况下，整个单词会发生变化：
- en: '*To be -> Is (Present tense)*'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '*To be -> Is（现在时）*'
- en: '*To be -> Was (Past tense)*'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '*To be -> Was（过去时）*'
- en: '*To be -> Will be (Future tense – addition of modal)*'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '*To be -> Will be（将来时 – 添加情态动词）*'
- en: 'There can be lexical variations on nouns too:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 名词也可以存在词汇变化：
- en: '*Cat -> Cats (Plural)*'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '*Cat -> Cats（复数）*'
- en: '*Cat -> Cat''s (Possessive)*'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '*Cat -> Cat''s（所有格）*'
- en: '*Cat -> Cats'' (Plural possessive)*'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '*Cat -> Cats''（复数所有格）*'
- en: 'All these words relate back to the root word cat. We can calculate the root
    of all the words in the sentence to reduce the whole sentence to its lexical roots:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些单词都与根词 cat 相关。我们可以计算句子中所有单词的根，以将整个句子简化为其词汇根：
- en: '*"His cats'' fur are different colors" -> "He cat fur be different color"*'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '*"他的猫的毛色不同" -> "他 猫 毛色 不同"*'
- en: Stemming and lemmatization is the process by which we arrive at these root words.
    **Stemming** is an algorithmic process in which the ends of words are cut off
    to arrive at a common root, whereas lemmatization uses a true vocabulary and structural
    analysis of the word itself to arrive at the true roots, or **lemmas**, of the
    word. We will cover both of these methodologies in detail in the following sections.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '**词干提取**和**词形还原**是通过这些根词来达到这些根词的过程。**词干提取**是一种算法过程，在这种过程中，单词的结尾被切掉以得到一个共同的词根，而词形还原则使用真实的词汇和对单词本身的结构分析，以得到单词的真正词根或**词元**。我们将在接下来的部分详细介绍这两种方法。'
- en: Stemming
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 词干提取
- en: '**Stemming** is the algorithmic process by which we trim the ends off words
    in order to arrive at their lexical roots, or **stems**. To do this, we can use
    different **stemmers** that each follow a particular algorithm in order to return
    the stem of a word. In English, one of the most common stemmers is the Porter
    Stemmer.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '**词干提取**是通过裁剪单词的末尾来到达它们的词汇根或**词干**的算法过程。为此，我们可以使用不同的**词干提取器**，每个都遵循特定的算法以返回单词的词干。在英语中，最常见的词干提取器之一是
    Porter Stemmer。'
- en: 'The **Porter Stemmer** is an algorithm with a large number of logical rules
    that can be used to return the stem of a word. We will first show how to implement
    a Porter Stemmer in Python using NLTK before moving on and discussing the algorithm
    in more detail:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '**Porter Stemmer** 是一个具有大量逻辑规则的算法，用于返回单词的词干。我们将首先展示如何使用 NLTK 在 Python 中实现 Porter
    Stemmer，然后进一步讨论该算法的详细内容：'
- en: 'First, we create an instance of the Porter Stemmer:'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们创建一个 Porter Stemmer 的实例：
- en: '[PRE6]'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'We then simply call this instance of the stemmer on individual words and print
    the results. Here, we can see an example of the stems returned by the Porter Stemmer:'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们简单地在单词上调用这个词干提取器的实例并打印结果。在这里，我们可以看到 Porter Stemmer 返回的词干示例：
- en: '[PRE7]'
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'This results in the following output:'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这导致以下输出：
- en: '![Figure 4.7 – Returning the stems of words'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.7 – 返回单词的词干'
- en: '](img/B12365_04_07.jpg)'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B12365_04_07.jpg)'
- en: Figure 4.7 – Returning the stems of words
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.7 – 返回单词的词干
- en: 'We can also apply stemming to an entire sentence, first by tokenizing the sentence
    and then by stemming each term individually:'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还可以将词干提取应用于整个句子，首先将句子进行标记化，然后逐个提取每个词项：
- en: '[PRE8]'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'This returns the following output:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 这将返回以下输出：
- en: '![Figure 4.8 – Applying stemming to a sentence'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.8 – 将词干提取应用于句子'
- en: '](img/B12365_04_08.jpg)'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B12365_04_08.jpg)'
- en: Figure 4.8 – Applying stemming to a sentence
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.8 – 将词干提取应用于句子
- en: Here, we can see how different words are stemmed using the Porter Stemmer. Some
    words, such as `stemming` and `timing`, reduce to their expected stems of `stem`
    and `time`. However, some words, such as `saw`, don't reduce to their logical
    stem (`see`). This illustrates the limitations of the Porter Stemmer. Since stemming
    applies a series of logical rules to the word, it is very difficult to define
    a set of rules that will correctly stem all words. This is especially true in
    the cases of words in English where the word changes completely, depending on
    the tense (is/was/be). This is because there are no generic rules that can be
    applied to these words to transform them all into the same root stem.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到如何使用 Porter Stemmer 提取不同的单词。一些单词，如 `stemming` 和 `timing`，会缩减为它们期望的词干
    `stem` 和 `time`。然而，一些单词，如 `saw`，并不会缩减为它们的逻辑词干（`see`）。这展示了 Porter Stemmer 的局限性。由于词干提取对单词应用一系列逻辑规则，定义一组可以正确提取所有单词的规则是非常困难的。特别是在英语中，一些词根据时态变化完全不同（is/was/be），因此没有通用的规则可以应用于这些单词，将它们全部转换为相同的根词。
- en: 'We can examine some of the rules the Porter Stemmer applies in more detail
    to understand exactly how the transformation into the stem occurs. While the actual
    Porter algorithm has many detailed steps, here, we will simplify some of the rules
    for ease of understanding:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以详细研究一些 Porter Stemmer 应用的规则，以了解转换为词干的确切过程。虽然实际的 Porter 算法有许多详细步骤，但在这里，我们将简化一些规则以便于理解：
- en: '![Figure 4.9 – Rules of the Porter Stemmer algorithm'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.9 – Porter Stemmer 算法的规则'
- en: '](img/B12365_04_09.jpg)'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B12365_04_09.jpg)'
- en: Figure 4.9 – Rules of the Porter Stemmer algorithm
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.9 – Porter Stemmer 算法的规则
- en: While it is not essential to understand every rule within the Porter Stemmer,
    it is key that we understand its limitations. While the Porter Stemmer has been
    shown to work well across a corpus, there will always be words that it cannot
    reduce to their true stems correctly. Since the rule set of the Porter Stemmer
    relies on the conventions of English word structure, there will always be words
    that do not fall within the conventional word structure and are not correctly
    transformed by these rules. Fortunately, some of these limitations can be overcome
    through the use of lemmatization.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然理解 Porter Stemmer 内的每条规则并非必需，但我们理解其局限性至关重要。尽管 Porter Stemmer 在语料库中表现良好，但总会有些词汇无法正确还原为其真实的词干。由于
    Porter Stemmer 的规则集依赖于英语单词结构的惯例，总会有些词汇不符合传统的单词结构，无法通过这些规则正确变换。幸运的是，通过词形还原，我们可以克服其中一些限制。
- en: Lemmatization
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 词形还原
- en: '`ran` will just be *ran*, its lemma is the true lexical root of the word, which
    would be `run`.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '`ran` 将仅仅是 *ran*，它的词形还原是这个单词的真实词根，即 `run`。'
- en: The lemmatization process uses both inbuilt pre-computed lemmas and associated
    words, as well as the context of the word within the sentence to determine the
    correct lemma for a given word. In this example, we will look at using the **WordNet**
    **Lemmatizer** within NLTK. WordNet is a large database of English words and their
    lexical relationships to one another. It contains one of the most robust and comprehensive
    mappings of the English language, specifically with regard to words' relationships
    to their lemmas.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 词形还原过程利用预先计算的词形和相关单词，以及单词在句子中的上下文来确定给定单词的正确词形。在这个例子中，我们将介绍如何在 NLTK 中使用 **WordNet**
    **Lemmatizer**。WordNet 是一个包含英语单词及其词汇关系的大型数据库。它包含了对英语语言关系的最强大和最全面的映射，特别是单词与它们词形关系的映射。
- en: 'We will first create an instance of our lemmatizer and call it on a selection
    of words:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先创建一个词形还原器的实例，并对一些单词进行调用：
- en: '[PRE9]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'This results in the following output:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 这导致以下输出：
- en: '![Figure 4.10 – Lemmatization output'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.10 – 词形还原输出'
- en: '](img/B12365_04_10.jpg)'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B12365_04_10.jpg)'
- en: Figure 4.10 – Lemmatization output
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.10 – 词形还原输出
- en: 'Here, we can already begin to see the advantages of using lemmatization over
    stemming. Since the WordNet Lemmatizer is built on a database of all the words
    in the English language, it knows that `mice` is the plural version of `mouse`.
    We would not have been able to reach this same root using stemming. Although lemmatization
    works better in the majority of cases, because it relies on a built-in index of
    words, it is not able to generalize to new or made-up words:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们已经可以开始看到使用词形还原法比使用词干提取法的优势。由于 WordNet 词形还原器建立在包含所有英语单词的数据库上，它知道 `mice`
    是 `mouse` 的复数形式。使用词干提取法我们无法达到相同的词根。尽管在大多数情况下词形还原法效果更好，因为它依赖于内置的单词索引，但它无法泛化到新的或虚构的单词：
- en: '[PRE10]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'This results in the following output:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 这导致以下输出：
- en: '![Figure 4.11 – Lemmatization output for made-up words'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.11 – 虚构单词的词形还原输出'
- en: '](img/B12365_04_11.jpg)'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B12365_04_11.jpg)'
- en: Figure 4.11 – Lemmatization output for made-up words
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.11 – 虚构单词的词形还原输出
- en: Here, we can see that, in this instance, our stemmer is able to generalize better
    to previously unseen words. Therefore, using a lemmatizer may be a problem if
    we're lemmatizing sources where language doesn't necessarily match up with *real*
    English language, such as social media sites where people may frequently abbreviate
    language.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到，在这种情况下，我们的词干提取器能够更好地泛化到以前未见过的单词。因此，在词形还原化不一定与*真实*英语语言相匹配的源语言，例如人们可能经常缩写语言的社交媒体网站上使用词形还原器可能会有问题。
- en: 'If we call our lemmatizer on two verbs, we will see that this doesn''t reduce
    them to their expected common lemma:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们对两个动词调用我们的词形还原器，我们会发现这并没有将它们减少到预期的共同词形还原形式：
- en: '[PRE11]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'This results in the following output:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 这导致以下输出：
- en: '![Figure 4.12 – Running lemmatization on verbs'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.12 – 对动词进行词形还原'
- en: '](img/B12365_04_12.jpg)'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B12365_04_12.jpg)'
- en: Figure 4.12 – Running lemmatization on verbs
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.12 – 对动词进行词形还原
- en: 'This is because our lemmatizer relies on the context of words to be able to
    return the lemmas. Recall from our POS analysis that we can easily return the
    context of a word in a sentence and determine whether a given word is a noun,
    verb, or adjective. For now, let''s manually specify that our words are verbs.
    We can see that this now correctly returns the lemma:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 这是因为我们的词形还原器依赖于单词的上下文来返回词形还原形式。回顾我们的词性分析，我们可以轻松地返回句子中单词的上下文，并确定给定单词是名词、动词还是形容词。现在，让我们手动指定我们的单词是动词。我们可以看到，现在它能够正确返回词形还原形式：
- en: '[PRE12]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'This results in the following output:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 这导致以下输出：
- en: '![Figure 4.13 – Implementing POS in the function'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.13 – 在函数中实现词性标注'
- en: '](img/B12365_04_13.jpg)'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B12365_04_13.jpg)'
- en: Figure 4.13 – Implementing POS in the function
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.13 – 在函数中实现词性标注
- en: 'This means that in order to return the correct lemmatization of any given sentence,
    we must first perform POS tagging to obtain the context of the words in the sentence,
    then pass this through the lemmatizer to obtain the lemmas of each of the words
    in the sentence. We first create a function that will return our POS tagging for
    each word in the sentence:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着为了返回任意给定句子的正确词形还原，我们必须首先执行词性标注以获取句子中单词的上下文，然后通过词形还原器获取句子中每个单词的词形还原形式。我们首先创建一个函数，用于返回句子中每个单词的词性标注：
- en: '[PRE13]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'This results in the following output:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 这导致以下输出：
- en: '![Figure 4.14 – Output of POS tagging on a sentence'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.14 – 句子的词性标注输出'
- en: '](img/B12365_04_14.jpg)'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B12365_04_14.jpg)'
- en: Figure 4.14 – Output of POS tagging on a sentence
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.14 – 句子的词性标注输出
- en: 'Note how this returns the NLTK POS tags for each of the words in the sentence.
    Our WordNet lemmatizer requires a slightly different input for POS. This means
    that we first create a function that maps the NLTK POS tags to the required WordNet
    POS tags:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 注意这如何返回句子中每个单词的 NLTK 词性标签。我们的 WordNet 词形还原器需要稍微不同的输入以获取词性标签。这意味着我们首先创建一个函数，将
    NLTK 词性标签映射到所需的 WordNet 词性标签：
- en: '[PRE14]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'This results in the following output:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 这导致以下输出：
- en: '![Figure 4.15 – Mapping NTLK POS tags to WordNet POS tags'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.15 – 将 NLTK 词性标签映射到 WordNet 词性标签'
- en: '](img/B12365_04_15.jpg)'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B12365_04_15.jpg)'
- en: Figure 4.15 – Mapping NTLK POS tags to WordNet POS tags
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.15 – 将 NLTK 词性标签映射到 WordNet 词性标签
- en: 'Finally, we combine these functions into one final function that will perform
    lemmatization on the whole sentence:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将这些函数组合成一个最终函数，将对整个句子进行词形还原：
- en: '[PRE15]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'This results in the following output:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 这导致以下输出：
- en: '![Figure 4.16 – Output of the finalized lemmatization function'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.16 – 最终词形还原函数的输出'
- en: '](img/B12365_04_16.jpg)'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B12365_04_16.jpg)'
- en: Figure 4.16 – Output of the finalized lemmatization function
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.16 - 最终词形还原函数的输出
- en: Here, we can see that, in general, lemmas generally provide a better representation
    of a word's true root compared to stems, with some notable exceptions. When we
    might decide to use stemming and lemmatization depends on the requirements of
    the task at hand, some of which we will explore now.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到，总体而言，词形还原一般提供了比词干更好的词根表示，但也有一些显著的例外。我们何时决定使用词干化和词形还原取决于手头任务的需求，其中一些我们现在将进行探索。
- en: Uses of stemming and lemmatization
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用词干化和词形还原
- en: Stemming and lemmatization are both a form of NLP that can be used to extract
    information from text. This is known as **text mining**. Text mining tasks come
    in a variety of categories, including text clustering, categorization, summarizing
    documents, and sentiment analysis. Stemming and lemmatization can be used in conjunction
    with deep learning to solve some of these tasks, as we will see later in this
    book.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 词干化和词形还原都是一种可以用于从文本中提取信息的自然语言处理形式。这被称为**文本挖掘**。文本挖掘任务有各种类别，包括文本聚类、分类、文档摘要和情感分析。词干化和词形还原可以与深度学习结合使用来解决其中一些任务，我们将在本书后面看到。
- en: By performing preprocessing using stemming and lemmatization, coupled with the
    removal of stop words, we can better reduce our sentences to understand their
    core meaning. By removing words that do not significantly contribute to the meaning
    of the sentence and by reducing words to their roots or lemmas, we can efficiently
    analyze sentences within our deep learning frameworks. If we are able to reduce
    a 10-word sentence to five words consisting of multiple core lemmas rather than
    multiple variations of similar words, this means much less data that we need to
    feed through our neural networks. If we use bag-of-words representations, our
    corpus will be significantly smaller as multiple words all reduce down to the
    same lemmas, whereas if we calculate embedding representations, the dimensionality
    required to capture the true representations of our words will be smaller for
    a reduced corpus of words.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用词干化和词形还原的预处理，再加上去除停用词，我们可以更好地减少句子以理解其核心含义。通过去除对句子含义贡献不大的词汇，并将词汇还原为其词根或词形还原形式，我们可以在深度学习框架内高效分析句子。如果我们能将一个由10个词组成的句子缩减为包含多个核心词形还原形式而非多个类似词汇变化的五个词，那么我们需要馈送到神经网络的数据量就大大减少了。如果我们使用词袋表示法，我们的语料库会显著减小，因为多个词都可以还原为相同的词形还原形式，而如果我们计算嵌入表示法，所需的维度则更小，用于表示我们的词汇的真实表示形式。
- en: Differences in lemmatization and stemming
  id: totrans-159
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 单词的词形还有提取
- en: Now that we have seen both lemmatization and stemming in action, the question
    still remains as to under which circumstances we should use both of these techniques.
    We saw that both techniques attempt to reduce each word to its root. In stemming,
    this may just be a reduced form of the target room, whereas in lemmatization,
    it reduces to a true English language word root.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经看到词形还原和词干化的应用，问题仍然是在什么情况下我们应该使用这两种技术。我们看到这两种技术都试图将每个词减少到它的根本。在词干化中，这可能只是目标词的简化形式，而在词形还原中，它则减少到一个真正的英语单词根。
- en: Because lemmatization requires cross-referencing the target word within the
    WordNet corpus, as well as performing part-of-speech analysis to determine the
    form of the lemma, this may take a significant amount of processing time if a
    large number of words have to be lemmatized. This is in contrast to stemming,
    which uses a detailed but relatively fast algorithm to stem words. Ultimately,
    as with many problems in computing, it is a question of trading off speed versus
    detail. When choosing which of these methods to incorporate in our deep learning
    pipeline, the trade-off may be between speed and accuracy. If time is of the essence,
    then stemming may be the way to go. On the other hand, if you need your model
    to be as detailed and as accurate as possible, then lemmatization will likely
    result in the superior model.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 因为词形还原需要在WordNet语料库内交叉参考目标词，以及执行词性分析来确定词形还原的形式，如果需要词形还原大量单词，这可能需要大量的处理时间。这与词干化相反，词干化使用了详细但相对快速的算法来词干化单词。最终，就像计算中的许多问题一样，这是一个在速度与详细度之间权衡的问题。在选择这些方法之一来结合我们的深度学习管道时，权衡可能在速度和准确性之间。如果时间紧迫，那么词干化可能是更好的选择。另一方面，如果您需要模型尽可能详细和准确，那么词形还原可能会产生更优越的模型。
- en: Summary
  id: totrans-162
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概述
- en: In this chapter, we have covered both stemming and lemmatization in detail by
    exploring the functionality of both methods, their use cases, and how they can
    be implemented. Now that we have covered all of the fundamentals of deep learning
    and NLP preprocessing, we are ready to start training our own deep learning models
    from scratch.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们详细讨论了词干提取和词形还原，通过探索这两种方法的功能、使用案例以及它们的实施方式。现在，我们已经掌握了深度学习和自然语言处理预处理的所有基础知识，可以开始从头开始训练我们自己的深度学习模型了。
- en: 'In the next chapter, we will explore the fundamentals of NLP and demonstrate
    how to build the most widely used models within the field of deep NLP: recurrent
    neural networks.'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将探讨自然语言处理的基础知识，并展示如何在深度自然语言处理领域内构建最常用的模型：循环神经网络。
