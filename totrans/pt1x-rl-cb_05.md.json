["```py\n>>> import torch\n>>> class BanditEnv():\n...     \"\"\"\n...     Multi-armed bandit environment\n...     payout_list:\n...         A list of probabilities of the likelihood that a \n particular bandit will pay out\n...     reward_list:\n...         A list of rewards of the payout that bandit has\n...     \"\"\"\n...     def __init__(self, payout_list, reward_list):\n...         self.payout_list = payout_list\n...         self.reward_list = reward_list\n...\n...     def step(self, action):\n...         if torch.rand(1).item() < self.payout_list[action]:\n...             return self.reward_list[action]\n...         return 0\n```", "```py\n>>> bandit_payout = [0.1, 0.15, 0.3]\n>>> bandit_reward = [4, 3, 1]>>> bandit_env = BanditEnv(bandit_payout, bandit_reward)\n```", "```py\n>>> n_episode = 100000\n>>> n_action = len(bandit_payout)\n>>> action_count = [0 for _ in range(n_action)]\n>>> action_total_reward = [0 for _ in range(n_action)]\n>>> action_avg_reward = [[] for action in range(n_action)]\n```", "```py\n>>> def random_policy():\n...     action = torch.multinomial(torch.ones(n_action), 1).item()\n...     return action\n```", "```py\n>>> for episode in range(n_episode):\n...     action = random_policy()\n...     reward = bandit_env.step(action)\n...     action_count[action] += 1\n...     action_total_reward[action] += reward\n...     for a in range(n_action):\n...         if action_count[a]:\n...             action_avg_reward[a].append(\n                     action_total_reward[a] / action_count[a])\n...         else:\n...             action_avg_reward[a].append(0)\n```", "```py\n>>> import matplotlib.pyplot as plt\n >>> for action in range(n_action):\n ...     plt.plot(action_avg_reward[action])\n >>> plt.legend([‘Arm {}’.format(action) for action in range(n_action)])\n >>> plt.title(‘Average reward over time’)\n >>> plt.xscale(‘log’)\n >>> plt.xlabel(‘Episode’)\n >>> plt.ylabel(‘Average reward’)\n >>> plt.show()\n```", "```py\n>>> import torch\n >>> from multi_armed_bandit import BanditEnv\n```", "```py\n>>> bandit_payout = [0.1, 0.15, 0.3]\n >>> bandit_reward = [4, 3, 1] >>> bandit_env = BanditEnv(bandit_payout, bandit_reward)\n```", "```py\n>>> n_episode = 100000\n >>> n_action = len(bandit_payout)\n >>> action_count = [0 for _ in range(n_action)]\n >>> action_total_reward = [0 for _ in range(n_action)]\n >>> action_avg_reward = [[] for action in range(n_action)]\n```", "```py\n>>> def gen_epsilon_greedy_policy(n_action, epsilon):\n ...     def policy_function(Q):\n ...         probs = torch.ones(n_action) * epsilon / n_action\n ...         best_action = torch.argmax(Q).item()\n ...         probs[best_action] += 1.0 - epsilon\n ...         action = torch.multinomial(probs, 1).item()\n ...         return action\n ...     return policy_function >>> epsilon = 0.2\n >>> epsilon_greedy_policy = gen_epsilon_greedy_policy(n_action, epsilon)\n```", "```py\n>>> Q = torch.zeros(n_action)\n```", "```py\n>>> for episode in range(n_episode):\n ...     action = epsilon_greedy_policy(Q)\n ...     reward = bandit_env.step(action)\n ...     action_count[action] += 1\n ...     action_total_reward[action] += reward\n ...     Q[action] = action_total_reward[action] / action_count[action]\n ...     for a in range(n_action):\n ...         if action_count[a]:\n ...             action_avg_reward[a].append(\n                         action_total_reward[a] / action_count[a])\n ...         else:\n ...             action_avg_reward[a].append(0)\n```", "```py\n>>> import matplotlib.pyplot as plt\n >>> for action in range(n_action):\n ...     plt.plot(action_avg_reward[action])\n >>> plt.legend([‘Arm {}’.format(action) for action in range(n_action)])\n >>> plt.title(‘Average reward over time’)\n >>> plt.xscale(‘log’)\n >>> plt.xlabel(‘Episode’)\n >>> plt.ylabel(‘Average reward’)\n >>> plt.show()\n```", "```py\n>>> print(sum(action_total_reward) / n_episode)\n 0.43718\n```", "```py\n>>> import torch\n >>> from multi_armed_bandit import BanditEnv\n```", "```py\n>>> bandit_payout = [0.1, 0.15, 0.3]\n >>> bandit_reward = [4, 3, 1] >>> bandit_env = BanditEnv(bandit_payout, bandit_reward)\n```", "```py\n>>> n_episode = 100000\n >>> n_action = len(bandit_payout)\n >>> action_count = [0 for _ in range(n_action)]\n >>> action_total_reward = [0 for _ in range(n_action)]\n >>> action_avg_reward = [[] for action in range(n_action)]\n```", "```py\n>>> def gen_softmax_exploration_policy(tau):\n ...     def policy_function(Q):\n ...         probs = torch.exp(Q / tau)\n ...         probs = probs / torch.sum(probs)\n ...         action = torch.multinomial(probs, 1).item()\n ...         return action\n ...     return policy_function >>> tau = 0.1\n >>> softmax_exploration_policy = gen_softmax_exploration_policy(tau)\n```", "```py\n>>> Q = torch.zeros(n_action)\n```", "```py\n>>> for episode in range(n_episode):\n ...     action = softmax_exploration_policy(Q)\n ...     reward = bandit_env.step(action)\n ...     action_count[action] += 1\n ...     action_total_reward[action] += reward\n ...     Q[action] = action_total_reward[action] / action_count[action]\n ...     for a in range(n_action):\n ...         if action_count[a]:\n ...             action_avg_reward[a].append(                         action_total_reward[a] / action_count[a])\n ...         else:\n ...             action_avg_reward[a].append(0)\n```", "```py\n>>> import matplotlib.pyplot as plt\n >>> for action in range(n_action):\n ...     plt.plot(action_avg_reward[action])\n >>> plt.legend([‘Arm {}’.format(action) for action in range(n_action)])\n >>> plt.title(‘Average reward over time’)\n >>> plt.xscale(‘log’)\n >>> plt.xlabel(‘Episode’)\n >>> plt.ylabel(‘Average reward’)\n >>> plt.show()\n```", "```py\n>>> import torch\n >>> from multi_armed_bandit import BanditEnv\n```", "```py\n>>> bandit_payout = [0.1, 0.15, 0.3]\n >>> bandit_reward = [4, 3, 1] >>> bandit_env = BanditEnv(bandit_payout, bandit_reward)\n```", "```py\n>>> n_episode = 100000\n >>> n_action = len(bandit_payout)\n >>> action_count = torch.tensor([0\\. for _ in range(n_action)])\n >>> action_total_reward = [0 for _ in range(n_action)]\n >>> action_avg_reward = [[] for action in range(n_action)]\n```", "```py\n>>> def upper_confidence_bound(Q, action_count, t):\n ...     ucb = torch.sqrt((2 * torch.log(torch.tensor(float(t))))                                              / action_count) + Q\n ...     return torch.argmax(ucb)\n```", "```py\n>>> Q = torch.empty(n_action)\n```", "```py\n>>> for episode in range(n_episode):\n ...     action = upper_confidence_bound(Q, action_count, episode)\n ...     reward = bandit_env.step(action)\n ...     action_count[action] += 1\n ...     action_total_reward[action] += reward\n ...     Q[action] = action_total_reward[action] / action_count[action]\n ...     for a in range(n_action):\n ...         if action_count[a]:\n ...             action_avg_reward[a].append(                         action_total_reward[a] / action_count[a])\n ...         else:\n ...             action_avg_reward[a].append(0)\n```", "```py\n>>> import matplotlib.pyplot as plt\n >>> for action in range(n_action):\n ...     plt.plot(action_avg_reward[action])\n >>> plt.legend([‘Arm {}’.format(action) for action in range(n_action)])\n >>> plt.title(‘Average reward over time’)\n >>> plt.xscale(‘log’)\n >>> plt.xlabel(‘Episode’)\n >>> plt.ylabel(‘Average reward’)\n >>> plt.show()\n```", "```py\n>>> print(sum(action_total_reward) / n_episode)\n 0.44605\n```", "```py\n>>> import torch\n>>> from multi_armed_bandit import BanditEnv\n```", "```py\n>>> bandit_payout = [0.01, 0.015, 0.03]\n>>> bandit_reward = [1, 1, 1]>>> bandit_env = BanditEnv(bandit_payout, bandit_reward)\n```", "```py\n>>> n_episode = 100000\n>>> n_action = len(bandit_payout)\n>>> action_count = torch.tensor([0\\. for _ in range(n_action)])\n>>> action_total_reward = [0 for _ in range(n_action)]\n>>> action_avg_reward = [[] for action in range(n_action)]\n```", "```py\n>>> def upper_confidence_bound(Q, action_count, t):\n...     ucb = torch.sqrt((2 * torch.log(\n torch.tensor(float(t)))) / action_count) + Q\n...     return torch.argmax(ucb)\n```", "```py\n>>> Q = torch.empty(n_action)\n```", "```py\n>>> for episode in range(n_episode):\n...     action = upper_confidence_bound(Q, action_count, episode)\n...     reward = bandit_env.step(action)\n...     action_count[action] += 1\n...     action_total_reward[action] += reward\n...     Q[action] = action_total_reward[action] / action_count[action]\n...     for a in range(n_action):\n...         if action_count[a]:\n...             action_avg_reward[a].append(\n action_total_reward[a] / action_count[a])\n...         else:\n...             action_avg_reward[a].append(0)\n```", "```py\n>>> import matplotlib.pyplot as plt\n>>> for action in range(n_action):\n...     plt.plot(action_avg_reward[action])\n>>> plt.legend([‘Arm {}’.format(action) for action in range(n_action)])\n>>> plt.title(‘Average reward over time’)\n>>> plt.xscale(‘log’)\n>>> plt.xlabel(‘Episode’)\n>>> plt.ylabel(‘Average reward’)\n>>> plt.show()\n```", "```py\n>>> import torch\n>>> import matplotlib.pyplot as plt\n```", "```py\n>>> beta1 = torch.distributions.beta.Beta(1, 1)\n>>> samples1 = [beta1.sample() for _ in range(100000)]\n>>> plt.hist(samples1, range=[0, 1], bins=10)\n>>> plt.title(‘beta(1, 1)’)\n>>> plt.show()\n```", "```py\n>>> beta2 = torch.distributions.beta.Beta(5, 1)\n>>> samples2 = [beta2.sample() for _ in range(100000)]\n>>> plt.hist(samples2, range=[0, 1], bins=10)\n>>> plt.title(‘beta(5, 1)’)\n>>> plt.show()\n```", "```py\n>>> beta3 = torch.distributions.beta.Beta(1, 5)\n>>> samples3= [beta3.sample() for _ in range(100000)]\n>>> plt.hist(samples3, range=[0, 1], bins=10)\n>>> plt.title(‘beta(1, 5)’)\n>>> plt.show()\n```", "```py\n>>> beta4 = torch.distributions.beta.Beta(5, 5)\n>>> samples4= [beta4.sample() for _ in range(100000)]\n>>> plt.hist(samples4, range=[0, 1], bins=10)\n>>> plt.title(‘beta(5, 5)’)\n>>> plt.show()\n```", "```py\n>>> from multi_armed_bandit import BanditEnv\n```", "```py\n>>> bandit_payout = [0.01, 0.015, 0.03]\n>>> bandit_reward = [1, 1, 1]>>> bandit_env = BanditEnv(bandit_payout, bandit_reward)\n```", "```py\n>>> n_episode = 100000\n>>> n_action = len(bandit_payout)\n>>> action_count = torch.tensor([0\\. for _ in range(n_action)])\n>>> action_total_reward = [0 for _ in range(n_action)]\n>>> action_avg_reward = [[] for action in range(n_action)]\n```", "```py\n>>> def thompson_sampling(alpha, beta):\n...     prior_values = torch.distributions.beta.Beta(alpha, beta).sample()\n...     return torch.argmax(prior_values)\n```", "```py\n>>> alpha = torch.ones(n_action)\n>>> beta = torch.ones(n_action)\n```", "```py\n>>> for episode in range(n_episode):\n ...     action = thompson_sampling(alpha, beta)\n ...     reward = bandit_env.step(action)\n ...     action_count[action] += 1\n ...     action_total_reward[action] += reward\n ...     if reward > 0:\n ...         alpha[action] += 1\n ...     else:\n ...         beta[action] += 1\n ...     for a in range(n_action):\n ...         if action_count[a]:\n ...             action_avg_reward[a].append(                         action_total_reward[a] / action_count[a])\n ...         else:\n ...             action_avg_reward[a].append(0)\n```", "```py\n>>> import matplotlib.pyplot as plt\n>>> for action in range(n_action):\n...     plt.plot(action_avg_reward[action])\n>>> plt.legend([‘Arm {}’.format(action) for action in range(n_action)])\n>>> plt.title(‘Average reward over time’)\n>>> plt.xscale(‘log’)\n>>> plt.xlabel(‘Episode’)\n>>> plt.ylabel(‘Average reward’)\n>>> plt.show()\n```", "```py\n>>> import torch\n>>> from multi_armed_bandit import BanditEnv\n```", "```py\n>>> bandit_payout_machines = [\n...     [0.01, 0.015, 0.03],\n...     [0.025, 0.01, 0.015]\n... ]\n>>> bandit_reward_machines = [\n...     [1, 1, 1],\n...     [1, 1, 1]\n... ]\n```", "```py\n>>> n_machine = len(bandit_payout_machines)\n```", "```py\n>>> bandit_env_machines = [BanditEnv(bandit_payout, bandit_reward)\n...           for bandit_payout, bandit_reward in\n...           zip(bandit_payout_machines, bandit_reward_machines)]\n```", "```py\n>>> n_episode = 100000\n>>> n_action = len(bandit_payout_machines[0])\n>>> action_count = torch.zeros(n_machine, n_action)\n>>> action_total_reward = torch.zeros(n_machine, n_action)\n>>> action_avg_reward = [[[] for action in range(n_action)] for _ in range(n_machine)]\n```", "```py\n>>> def upper_confidence_bound(Q, action_count, t):\n...     ucb = torch.sqrt((2 * torch.log( \n                 torch.tensor(float(t)))) / action_count) + Q\n...     return torch.argmax(ucb)\n```", "```py\n>>> Q_machines = torch.empty(n_machine, n_action)\n```", "```py\n>>> for episode in range(n_episode):\n...     state = torch.randint(0, n_machine, (1,)).item()\n...     action = upper_confidence_bound(                 Q_machines[state], action_count[state], episode)\n...     reward = bandit_env_machines[state].step(action)\n...     action_count[state][action] += 1\n...     action_total_reward[state][action] += reward\n...     Q_machines[state][action] =                              action_total_reward[state][action]                              / action_count[state][action]\n...     for a in range(n_action):\n...         if action_count[state][a]:\n...             action_avg_reward[state][a].append(                             action_total_reward[state][a]                              / action_count[state][a])\n...         else:\n...             action_avg_reward[state][a].append(0)\n```", "```py\n>>> import matplotlib.pyplot as plt\n>>> for state in range(n_machine):\n...     for action in range(n_action):\n...         plt.plot(action_avg_reward[state][action])\n...     plt.legend([‘Arm {}’.format(action)                      for action in range(n_action)])\n...     plt.xscale(‘log’)\n...     plt.title(       ‘Average reward over time for state {}’.format(state))\n...     plt.xlabel(‘Episode’)\n...     plt.ylabel(‘Average reward’)\n...     plt.show()\n```"]