- en: Preface
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 序言
- en: The surge in interest in reinforcement learning is due to the fact that it revolutionizes
    automation by learning the optimal actions to take in an environment in order
    to maximize the notion of cumulative reward.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 强化学习兴起的原因在于它通过学习在环境中采取最优行动来最大化累积奖励的概念，从而革新了自动化。
- en: '*PyTorch 1.x Reinforcement Learning Cookbook* introduces you to important reinforcement
    learning concepts and implementations of algorithms in PyTorch. Each chapter of
    the book walks you through a different type of reinforcement learning method and
    its industry-adopted applications. With the help of recipes that contain real-world
    examples, you will find it intriguing to enhance your knowledge and proficiency
    of reinforcement learning techniques in areas such as dynamic programming, Monte
    Carlo methods, temporal difference and Q-learning, multi-armed bandit, function
    approximation, deep Q-Networks, and policy gradients—they are no more obscure
    than you thought. Interesting and easy-to-follow examples, such as Atari games,
    Blackjack, Gridworld environments, internet advertising, Mountain Car, and Flappy
    Bird, will keep you interested until you reach your goal.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '*PyTorch 1.x强化学习菜谱*向您介绍了重要的强化学习概念，以及在PyTorch中实现算法的方法。本书的每一章都将引导您了解不同类型的强化学习方法及其在行业中的应用。通过包含真实世界示例的配方，您将发现在动态规划、蒙特卡洛方法、时间差分与Q-learning、多臂老虎机、函数逼近、深度Q网络和策略梯度等强化学习技术领域提升知识和熟练度是多么有趣而易于跟随的事情。有趣且易于跟随的示例，如Atari游戏、21点、Gridworld环境、互联网广告、Mountain
    Car和Flappy Bird，将让您在实现目标之前保持兴趣盎然。'
- en: By the end of this book, you will have mastered the implementation of popular
    reinforcement learning algorithms and learned the best practices of applying reinforcement
    learning techniques to solve other real-world problems.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 通过本书，您将掌握流行的强化学习算法的实现，并学习将强化学习技术应用于解决其他实际问题的最佳实践。
- en: Who this book is for
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本书适合对象
- en: Machine learning engineers, data scientists, and AI researchers looking for
    quick solutions to different problems in reinforcement learning will find this
    book useful. Prior exposure to machine learning concepts is required, while previous
    experience with PyTorch will be a bonus.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 寻求在强化学习中快速解决不同问题的机器学习工程师、数据科学家和人工智能研究人员会发现本书非常有用。需要有机器学习概念的先验知识，而对PyTorch的先前经验将是一个优势。
- en: What this book covers
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本书内容概述
- en: Chapter 1, *Getting Started with Reinforcement Learning and PyTorch*, is the
    starting point for readers who are looking forward to beginning this book's step-by-step
    guide to reinforcement learning with PyTorch. We will set up the working environment
    and OpenAI Gym and get familiar with reinforcement learning environments using
    the Atari and CartPole playgrounds. The chapter will also cover the implementation
    of several basic reinforcement learning algorithms, including random search, hill-climbing,
    and policy gradient. At the end, readers will also have a chance to review the
    essentials of PyTorch and get ready for the upcoming learning examples and projects.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 第一章，*使用PyTorch入门强化学习*，是本书逐步指南开始的地方，为那些希望开始学习使用PyTorch进行强化学习的读者提供了指导。我们将建立工作环境并熟悉使用Atari和CartPole游戏场景的强化学习环境。本章还将涵盖几种基本的强化学习算法的实现，包括随机搜索、爬山法和策略梯度。最后，读者还将有机会复习PyTorch的基础知识，并为即将到来的学习示例和项目做好准备。
- en: Chapter 2, *Markov Decision Process and Dynamic Programming*, starts with the
    creation of a Markov chain and a Markov Decision Process, which is the core of
    most reinforcement learning algorithms. It will then move on to two approaches
    to solve a Markov Decision Process (MDP), value iteration and policy iteration.
    We will get more familiar with MDP and the Bellman equation by practicing policy
    evaluation. We will also demonstrate how to solve the interesting coin flipping
    gamble problem step by step. At the end, we will learn how to perform dynamic
    programming to scale up the learning.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 第二章，*马尔可夫决策过程与动态规划*，从创建马尔可夫链和马尔可夫决策过程开始，后者是大多数强化学习算法的核心。然后，我们将介绍两种解决马尔可夫决策过程（MDP）的方法，即值迭代和策略迭代。通过实践策略评估，我们将更加熟悉MDP和贝尔曼方程。我们还将逐步演示如何解决有趣的硬币翻转赌博问题。最后，我们将学习如何执行动态规划以扩展学习能力。
- en: Chapter 3, *Monte Carlo Methods for Making Numerical Estimations*, is focused
    on Monte Carlo methods. We will start by estimating the value of pi with Monte
    Carlo. Moving on, we will learn how to use the Monte Carlo method to predict state
    values and state-action values. We will demonstrate training an agent to win at
    Blackjack using Monte Carlo. Also, we will explore on-policy, first-visit Monte
    Carlo control and off-policy Monte Carlo control by developing various algorithms.
    Monte Carlo Control with an epsilon-greedy policy and weighted importance sampling
    will also be covered.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 第 3 章，*蒙特卡洛方法进行数值估计*，专注于蒙特卡洛方法。我们将从使用蒙特卡洛估算 pi 值开始。接着，我们将学习如何使用蒙特卡洛方法预测状态值和状态-动作值。我们将展示如何训练一个代理程序在
    21 点中获胜。此外，我们将通过开发各种算法探索在线策略的第一次访问蒙特卡洛控制和离线蒙特卡洛控制。还将涵盖带有 epsilon-greedy 策略和加权重要性采样的蒙特卡洛控制。
- en: Chapter 4, *Temporal Difference and Q-Learning*, starts by setting up the CliffWalking
    and Windy Gridworld environment playground, which will be used in temporal difference
    and Q-Learning. Through our step-by-step guide, readers will explore Temporal
    Difference for prediction, and will gain practical experience with Q-Learning
    for off-policy control, and SARSA for on-policy control. We will also work on
    an interesting project, the taxi problem, and demonstrate how to solve it using
    the Q-Learning and SARSA algorithms. Finally, we will cover the Double Q-learning
    algorithm as a bonus section.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 第 4 章，*时间差分与 Q 学习*，首先建立了 CliffWalking 和 Windy Gridworld 环境场地，这些将在时间差分和 Q 学习中使用。通过我们的逐步指南，读者将探索用于预测的时间差分，并且会通过
    Q 学习获得实际控制经验，以及通过 SARSA 实现在线策略控制。我们还将处理一个有趣的项目，出租车问题，并展示如何使用 Q 学习和 SARSA 算法解决它。最后，我们将涵盖
    Double Q-learning 算法作为额外的部分。
- en: Chapter 5, *Solving Multi-Armed Bandit Problems*, covers the multi-armed bandit
    algorithm, which is probably one of the most popular algorithms in reinforcement
    learning. This will start with the creation of a multi-armed bandit problem. We
    will see how to solve the multi-armed bandit problem using four strategies, these
    being the epsilon-greedy policy, softmax exploration, the upper confidence bound
    algorithm, and the Thompson sampling algorithm. We will also work on a billion-dollar
    problem, online advertising, and demonstrate how to solve it using the multi-armed
    bandit algorithm. Finally, we will develop a more complex algorithm, the contextual
    bandit algorithm, and use it to optimize display advertising.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 第 5 章，*解决多臂赌博问题*，涵盖了多臂赌博算法，这可能是强化学习中最流行的算法之一。我们将从创建多臂赌博问题开始。我们将看到如何使用四种策略解决多臂赌博问题，包括
    epsilon-greedy 策略、softmax 探索、上置信度界算法和 Thompson 采样算法。我们还将处理一个十亿美元的问题，在线广告，展示如何使用多臂赌博算法解决它。最后，我们将开发一个更复杂的算法，上下文赌博算法，并用它来优化显示广告。
- en: '[Chapter 6](6371b431-5738-4267-966d-eb3be840d471.xhtml), *Scaling Up Learning
    with Function Approximation*, is focused on function approximation and will start
    with setting up the Mountain Car environment playground. Through our step-by-step
    guide, we will cover the motivation for function approximation over Table Lookup,
    and gain experience in incorporating function approximation into existing algorithms
    such as Q-Learning and SARSA. We will also cover an advanced technique, batching
    using experience replay. Finally, we will cover how to solve the CartPole problem
    using what we have learned in the chapter as a whole.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[第 6 章](6371b431-5738-4267-966d-eb3be840d471.xhtml)，*使用函数逼近扩展学习*，专注于函数逼近，并将从设置
    Mountain Car 环境场地开始。通过我们的逐步指南，我们将讨论为什么使用函数逼近而不是表查找，并且通过 Q 学习和 SARSA 等现有算法融入函数逼近的实际经验。我们还将涵盖一个高级技术，即使用经验重放进行批处理。最后，我们将介绍如何使用本章学到的内容来解决
    CartPole 问题。'
- en: Chapter 7, *Deep Q-Networks in Action*, covers Deep Q-Learning, or **Deep Q
    Network** (**DQN**), which is considered the most modern reinforcement learning
    technique. We will develop a DQN model step by step and understand the importance
    of Experience Replay and a target network in making Deep Q-Learning work in practice.
    To help readers solve Atari games, we will demonstrate how to incorporate convolutional
    neural networks into DQNs. We will also cover two DQN variants, Double DQNs and
    Dueling DQNs. We will cover how to fine-tune a Q-Learning algorithm using Double
    DQNs as an example.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 第7章，《行动中的深度 Q 网络》，涵盖了深度 Q 学习或**深度 Q 网络**（**DQN**），被认为是最现代的强化学习技术。我们将逐步开发一个 DQN
    模型，并了解经验回放和目标网络在实践中使深度 Q 学习发挥作用的重要性。为了帮助读者解决雅达利游戏问题，我们将演示如何将卷积神经网络融入到 DQN 中。我们还将涵盖两种
    DQN 变体，分别为双重 DQN 和对战 DQN。我们将介绍如何使用双重 DQN 调优 Q 学习算法。
- en: Chapter 8, *Implementing Policy Gradients and Policy Optimization*, focuses
    on policy gradients and optimization and starts by implementing the REINFORCE
    algorithm. We will then develop the REINFORCE algorithm with the baseline for
    CliffWalking. We will also implement the actor-critic algorithm and apply it to
    solve the CliffWalking problem. To scale up the deterministic policy gradient
    algorithm, we apply tricks from DQN and develop the Deep Deterministic Policy
    Gradients. As a bit of fun, we train an agent based on the cross-entropy method
    to play the CartPole game. Finally, we will talk about how to scale up policy
    gradient methods using the asynchronous actor-critic method and neural networks.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 第8章，《实施策略梯度和策略优化》，专注于策略梯度和优化，并首先实施 REINFORCE 算法。然后，我们将基于 ClifWalking 开发带基准线的
    REINFORCE 算法。我们还将实施 actor-critic 算法，并应用它来解决 ClifWalking 问题。为了扩展确定性策略梯度算法，我们从 DQN
    中应用技巧，并开发深度确定性策略梯度。作为一个有趣的体验，我们训练一个基于交叉熵方法的代理来玩 CartPole 游戏。最后，我们将谈论如何使用异步 actor-critic
    方法和神经网络来扩展策略梯度方法。
- en: Chapter 9, *Capstone Project – Playing Flappy Bird with DQN*, takes us through
    a capstone project – playing Flappy Bird using reinforcement learning. We will
    apply what we have learned throughout this book to build an intelligent bot. We
    will focus on building a DQN, fine-tuning model parameters, and deploying the
    model. Let's see how long the bird can fly in the air.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 第9章，《毕业项目 - 使用 DQN 玩 Flappy Bird》带领我们进行一个毕业项目 - 使用强化学习玩 Flappy Bird。我们将应用本书中学到的知识来构建一个智能机器人。我们将专注于构建一个
    DQN，调优模型参数，并部署模型。让我们看看鸟在空中能飞多久。
- en: To get the most out of this book
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为了从本书中获得最大收益
- en: Data scientists, machine learning engineers, and AI researchers looking for
    quick solutions to different problems in reinforcement learning will find this
    book useful. Prior exposure to machine learning concepts is required, while previous
    experience with PyTorch is not required but will be a bonus.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 寻求强化学习中不同问题的快速解决方案的数据科学家、机器学习工程师和人工智能研究人员会发现这本书很有用。需要有机器学习概念的先前接触，而 PyTorch
    的先前经验并非必需，但会是一个优势。
- en: Download the example code files
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 下载示例代码文件
- en: You can download the example code files for this book from your account at [www.packt.com](http://www.packt.com).
    If you purchased this book elsewhere, you can visit [www.packtpub.com/support](https://www.packtpub.com/support)
    and register to have the files emailed directly to you.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从您在 [www.packt.com](http://www.packt.com) 的账户中下载本书的示例代码文件。如果您在其他地方购买了本书，您可以访问
    [www.packtpub.com/support](https://www.packtpub.com/support) 并注册，以直接通过电子邮件接收文件。
- en: 'You can download the code files by following these steps:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以按照以下步骤下载代码文件：
- en: Log in or register at [www.packt.com](http://www.packt.com).
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 [www.packt.com](http://www.packt.com) 登录或注册。
- en: Select the Support tab.
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择“支持”选项卡。
- en: Click on Code Downloads.
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击“代码下载”。
- en: Enter the name of the book in the Search box and follow the onscreen instructions.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在搜索框中输入书名，然后按照屏幕上的说明操作。
- en: 'Once the file is downloaded, please make sure that you unzip or extract the
    folder using the latest version of:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 下载文件后，请确保您使用最新版本的解压工具解压或提取文件夹：
- en: WinRAR/7-Zip for Windows
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Windows 系统使用 WinRAR/7-Zip
- en: Zipeg/iZip/UnRarX for Mac
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mac 系统使用 Zipeg/iZip/UnRarX
- en: 7-Zip/PeaZip for Linux
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Linux 系统使用 7-Zip/PeaZip
- en: The code bundle for the book is also hosted on GitHub at [https://github.com/PacktPublishing/PyTorch-1.x-Reinforcement-Learning-Cookbook](https://github.com/PacktPublishing/PyTorch-1.x-Reinforcement-Learning-Cookbook).
    In case there's an update to the code, it will be updated on the existing GitHub
    repository.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: The code bundle for the book is also hosted on GitHub at [https://github.com/PacktPublishing/PyTorch-1.x-Reinforcement-Learning-Cookbook](https://github.com/PacktPublishing/PyTorch-1.x-Reinforcement-Learning-Cookbook).
    In case there's an update to the code, it will be updated on the existing GitHub
    repository.
- en: We also have other code bundles from our rich catalog of books and videos available
    at **[https://github.com/PacktPublishing/](https://github.com/PacktPublishing/)**.
    Check them out!
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: We also have other code bundles from our rich catalog of books and videos available
    at **[https://github.com/PacktPublishing/](https://github.com/PacktPublishing/)**.
    Check them out!
- en: Download the color images
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Download the color images
- en: 'We also provide a PDF file that has color images of the screenshots/diagrams
    used in this book. You can download it here: [https://static.packt-cdn.com/downloads/9781838551964_ColorImages.pdf](https://static.packt-cdn.com/downloads/9781838551964_ColorImages.pdf)[.](http://www.packtpub.com/sites/default/files/downloads/Bookname_ColorImages.pdf)'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 'We also provide a PDF file that has color images of the screenshots/diagrams
    used in this book. You can download it here: [https://static.packt-cdn.com/downloads/9781838551964_ColorImages.pdf](https://static.packt-cdn.com/downloads/9781838551964_ColorImages.pdf)[.](http://www.packtpub.com/sites/default/files/downloads/Bookname_ColorImages.pdf)'
- en: Conventions used
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Conventions used
- en: There are a number of text conventions used throughout this book.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: There are a number of text conventions used throughout this book.
- en: '`CodeInText`: Indicates code words in text, database table names, folder names,
    filenames, file extensions, pathnames, dummy URLs, user input, and Twitter handles.
    Here is an example: "By saying `empty`, it doesn''t mean all elements have a value
    of `Null`."'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '`CodeInText`：指示文本中的代码词、数据库表名、文件夹名、文件名、文件扩展名、路径名、虚拟网址、用户输入和Twitter用户名。例如："所谓的`empty`并不意味着所有元素都有`Null`值。"'
- en: 'A block of code is set as follows:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 'A block of code is set as follows:'
- en: '[PRE0]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Any command-line input or output is written as follows:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 'Any command-line input or output is written as follows:'
- en: '[PRE1]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '**Bold**: Indicates a new term, an important word, or words that you see onscreen.
    For example, words in menus or dialog boxes appear in the text like this. Here
    is an example: "This approach is called **random search**, since the weight is
    randomly picked in each trial with the hope that the best weight will be found
    with a large number of trials."'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**Bold**: 表示新术语、重要词汇或屏幕上看到的词语。例如，菜单或对话框中的单词以这种方式出现在文本中。例如："这种方法称为**随机搜索**，因为每次试验中权重都是随机选择的，希望通过大量试验找到最佳权重。"'
- en: Warnings or important notes appear like this.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: Warnings or important notes appear like this.
- en: Tips and tricks appear like this.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: Tips and tricks appear like this.
- en: Sections
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Sections
- en: In this book, you will find several headings that appear frequently (*Getting
    ready*, *How to do it...*, *How it works...*, *There's more...*, and *See also*).
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: In this book, you will find several headings that appear frequently (*Getting
    ready*, *How to do it...*, *How it works...*, *There's more...*, and *See also*).
- en: 'To give clear instructions on how to complete a recipe, use these sections
    as follows:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 'To give clear instructions on how to complete a recipe, use these sections
    as follows:'
- en: Getting ready
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Getting ready
- en: This section tells you what to expect in the recipe and describes how to set
    up any software or any preliminary settings required for the recipe.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: This section tells you what to expect in the recipe and describes how to set
    up any software or any preliminary settings required for the recipe.
- en: How to do it...
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: How to do it...
- en: This section contains the steps required to follow the recipe.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: This section contains the steps required to follow the recipe.
- en: How it works...
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: How it works...
- en: This section usually consists of a detailed explanation of what happened in
    the previous section.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: This section usually consists of a detailed explanation of what happened in
    the previous section.
- en: There's more...
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: There's more...
- en: This section consists of additional information about the recipe in order to
    make you more knowledgeable about the recipe.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: This section consists of additional information about the recipe in order to
    make you more knowledgeable about the recipe.
- en: See also
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: See also
- en: This section provides helpful links to other useful information for the recipe.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: This section provides helpful links to other useful information for the recipe.
- en: Get in touch
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Get in touch
- en: Feedback from our readers is always welcome.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: Feedback from our readers is always welcome.
- en: '**General feedback**: If you have questions about any aspect of this book,
    mention the book title in the subject of your message and email us at `customercare@packtpub.com`.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '**General feedback**: 如果您对本书的任何方面有疑问，请在邮件主题中提及书名，并发送邮件至`customercare@packtpub.com`联系我们。'
- en: '**Errata**: Although we have taken every care to ensure the accuracy of our
    content, mistakes do happen. If you have found a mistake in this book, we would
    be grateful if you would report this to us. Please visit [www.packtpub.com/support/errata](https://www.packtpub.com/support/errata),
    selecting your book, clicking on the Errata Submission Form link, and entering
    the details.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '**勘误**：尽管我们已竭尽全力确保内容准确性，但错误难免会发生。如果您在本书中发现错误，请向我们报告，我们将不胜感激。请访问[www.packtpub.com/support/errata](https://www.packtpub.com/support/errata)，选择您的书籍，点击“勘误提交表格”链接，并填写详细信息。'
- en: '**Piracy**: If you come across any illegal copies of our works in any form
    on the Internet, we would be grateful if you would provide us with the location
    address or website name. Please contact us at `copyright@packt.com` with a link
    to the material.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '**盗版**：如果您在互联网上发现我们作品的任何形式的非法复制，请向我们提供位置地址或网站名称，我们将不胜感激。请通过`copyright@packt.com`与我们联系，并附上材料链接。'
- en: '**If you are interested in becoming an author**: If there is a topic that you
    have expertise in and you are interested in either writing or contributing to
    a book, please visit [authors.packtpub.com](http://authors.packtpub.com/).'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '**如果您有兴趣成为作者**：如果您在某个专题上有专业知识，并且有意写作或为书籍做贡献，请访问[authors.packtpub.com](http://authors.packtpub.com/)。'
- en: Reviews
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评论
- en: Please leave a review. Once you have read and used this book, why not leave
    a review on the site that you purchased it from? Potential readers can then see
    and use your unbiased opinion to make purchase decisions, we at Packt can understand
    what you think about our products, and our authors can see your feedback on their
    book. Thank you!
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 请留下您的评论。在阅读并使用本书后，为何不在您购买它的网站上留下评论呢？潜在的读者可以看到并使用您的客观意见来作出购买决策，我们在Packt可以了解您对我们产品的看法，而我们的作者可以看到您对他们书籍的反馈。谢谢！
- en: For more information about Packt, please visit [packt.com](http://www.packt.com/).
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于Packt的信息，请访问[packt.com](http://www.packt.com/)。
