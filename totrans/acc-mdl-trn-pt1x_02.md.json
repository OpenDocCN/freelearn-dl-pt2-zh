["```py\nfor each epoch    for each training step\n        result = conv(input)\n        result = maxpool(result)\n        result = relu(result)\n        result = conv(result)\n        result = maxpool(result)\n        result = relu(result)\n        result = reshape(result)\n        result = gemm(result)\n        result = gemm(result)\n    loss = calculate_loss(result)\n    gradient = optimization(loss)\n    backwards(gradient)\n```", "```py\naten::mkldnn_convolution: 44.01%aten::max_pool2d_with_indices: 30.01%\naten::addmm: 13.68%\naten::clamp_min: 6.96%\naten::convolution: 1.18%\naten::copy_: 0.70%\naten::relu: 0.59%\naten::_convolution: 0.49%\naten::empty: 0.35%\naten::_reshape_alias: 0.31%\naten::t: 0.31%\naten::conv2d: 0.24%\naten::as_strided_: 0.24%\naten::reshape: 0.21%\naten::linear: 0.21%\naten::max_pool2d: 0.17%\naten::expand: 0.14%\naten::transpose: 0.10%\naten::as_strided: 0.07%\naten::resolve_conj: 0.00%\n```", "```py\ndef count_parameters(model):    parameters = list(model.parameters())\n    total_parms = sum(\n        [np.prod(p.size()) for p in parameters if p.requires_grad])\n    return total_parms\n```"]