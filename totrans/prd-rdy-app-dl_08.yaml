- en: '6'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '6'
- en: Efficient Model Training
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 高效模型训练
- en: 'Similar to how we scaled up data processing pipelines in the previous chapter,
    we can reduce the time it takes to train **deep learning** (**DL**) models by
    allocating more computational resources. In this chapter, we will learn how to
    configure the **TensorFlow** (**TF**) and **PyTorch** training logic to utilize
    multiple CPU and GPU devices on different machines. First, we will learn how TF
    and PyTorch support distributed training without any external tools. Next, we
    will describe how to utilize SageMaker, since it is built to handle the DL pipeline
    on the cloud from end to end. Lastly, we will look at tools that have been developed
    specifically for distributed training: Horovod, Ray, and Kubeflow.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 与我们在前一章中扩展数据处理流水线的方式类似，我们可以通过分配更多计算资源来缩短训练**深度学习**（**DL**）模型所需的时间。在本章中，我们将学习如何配置**TensorFlow**（**TF**）和**PyTorch**的训练逻辑，以利用不同机器上多个CPU和GPU设备。首先，我们将学习TF和PyTorch如何支持分布式训练，无需任何外部工具。接下来，我们将描述如何利用SageMaker，因为它专为从云端到端处理DL管道而构建。最后，我们将看看专为分布式训练开发的工具：Horovod、Ray和Kubeflow。
- en: 'In this chapter, we’re going to cover the following main topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论以下主要主题：
- en: Training a model on a single machine
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在单台机器上训练模型
- en: Training a model on a cluster
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在集群上训练模型
- en: Training a model using SageMaker
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用SageMaker训练模型
- en: Training a model using Horovod
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Horovod训练模型
- en: Training a model using Ray
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Ray训练模型
- en: Training a model using Kubeflow
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Kubeflow训练模型
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'You can download the supplemental material for this chapter from this book’s
    GitHub repository: https://github.com/PacktPublishing/Production-Ready-Applied-Deep-Learning/tree/main/Chapter_6.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从本书的GitHub存储库下载本章的补充材料：https://github.com/PacktPublishing/Production-Ready-Applied-Deep-Learning/tree/main/Chapter_6。
- en: Training a model on a single machine
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在单台机器上训练模型
- en: As described in [*Chapter 3*](B18522_03.xhtml#_idTextAnchor062), *Developing
    a Powerful Deep Learning Model*, training a DL model involves extracting meaningful
    patterns from a dataset. When the size of the dataset is small and the model has
    few parameters to tune, a **central processing unit** (**CPU**) might be sufficient
    to train the model. However, DL models have shown greater performance when they
    are trained with a larger training set and consist of a greater number of neurons.
    Therefore, training using a **graphics processing unit** (**GPU**) has become
    the standard since you can exploit its massive parallelism in matrix multiplication.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 如[*第三章*](B18522_03.xhtml#_idTextAnchor062)中所述，*开发强大的深度学习模型*，训练DL模型涉及从数据集中提取有意义的模式。当数据集大小较小且模型参数较少时，使用**中央处理单元**（**CPU**）可能足以训练模型。然而，当使用更大的训练集并且模型包含更多神经元时，DL模型表现出更好的性能。因此，使用**图形处理单元**（**GPU**）进行训练已成为标准，因为您可以利用其在矩阵乘法中的大规模并行性。
- en: Utilizing multiple devices for training in TensorFlow
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在TensorFlow中利用多个设备进行训练
- en: 'TF provides the `tf.distribute.Strategy` module, which allows you to use multiple
    GPU or CPU devices for training with very simple code modifi[cations (https://www.tensorflow.org/guide/distributed](https://www.tensorflow.org/guide/distributed_training)_training).
    `tf.distribute.Strategy` is fully compatible with `tf.keras.Model.fit`, as well
    as custom training loops, as described in the *Implementing and training a model
    in TensorFlow* section of [*Chapter 3*](B18522_03.xhtml#_idTextAnchor062), *Developing
    a Powerful Deep Learning Model*. Various components of Keras, including variables,
    layers, models, optimizers, metrics, summaries, and checkpoints, are designed
    to support various `tf.distribute.Strategy` classes, keeping the transition to
    distributed training as simple as possible. Let’s have a look at how the `tf.distribute.Strategy`
    module allows you to quickly modify a set of code designed for a single device
    to multiple devices on a single machine:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: TF 提供了`tf.distribute.Strategy`模块，允许您使用多个GPU或CPU设备进行训练，只需非常简单的代码修改，详见[分布式训练](https://www.tensorflow.org/guide/distributed_training)。`tf.distribute.Strategy`与`tf.keras.Model.fit`完全兼容，以及自定义训练循环，如[*第三章*](B18522_03.xhtml#_idTextAnchor062)中的*在TensorFlow中实现和训练模型*部分描述的那样，*开发强大的深度学习模型*。Keras的各个组件，包括变量、层、模型、优化器、度量、摘要和检查点，均设计为支持各种`tf.distribute.Strategy`类，以尽可能简化转向分布式训练。让我们看看`tf.distribute.Strategy`模块如何使您能够快速修改为多设备上的单机代码集合：
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Once the model has been saved, it can be loaded with or without the `tf.distribute.Strategy`
    scope. To achieve distributed training with a custom training loop, you can follow
    the example p[resented at https://www.tensorflow.org/tutorials/distribute/cus](https://www.tensorflow.org/tutorials/distribute/custom_training)tom_training.
    Having said that, let’s review the most used strategies. We will cover the most
    common approaches, some of which go beyond training a single instance. They will
    be used in the next few sections, which cover training on multiple machines:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 模型保存后，可以在有或无`tf.distribute.Strategy`作用域的情况下加载。为了在自定义训练循环中实现分布式训练，您可以参考示例：[https://www.tensorflow.org/tutorials/distribute/custom_training](https://www.tensorflow.org/tutorials/distribute/custom_training)。话虽如此，让我们来回顾一下最常用的策略。我们将涵盖最常见的方法，其中一些超出了单个实例的训练。它们将用于接下来的几节，涵盖在多台机器上进行训练：
- en: 'Strategies that provide full support for `tf.keras.Model.fit` and custom training
    loops:'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供对`tf.keras.Model.fit`和自定义训练循环全面支持的策略：
- en: '`MirroredStrategy`: Synchronous distributed training using multiple GPUs on
    a single machine'
  id: totrans-19
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MirroredStrategy`: 在单台机器上使用多个GPU进行同步分布式训练'
- en: '`MultiWorkerMirroredStrategy`: Synchronous distributed training on multiple
    machines (potentially using multiple GPUs per machine). This strategy class requires
    a TF cluster that’s been configured using the `TF_CONFIG` environment variable
    ([https://www.tensorflow.org/guide/distributed_training#TF_CONFIG](https://www.tensorflow.org/guide/distributed_training#TF_CONFIG))'
  id: totrans-20
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MultiWorkerMirroredStrategy`: 在多台机器上进行同步分布式训练（可能使用每台机器上的多个GPU）。此策略类需要使用已配置`TF_CONFIG`环境变量的TF集群（[https://www.tensorflow.org/guide/distributed_training#TF_CONFIG](https://www.tensorflow.org/guide/distributed_training#TF_CONFIG)）。'
- en: '`TPUStrategy`: Training on multiple **tensor processing units** (**TPUs**)'
  id: totrans-21
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TPUStrategy`: 在多个**张量处理单元**（**TPU**）上进行训练。'
- en: 'Strategies with experimental features (meaning that classes and methods are
    still in the development stage) for `tf.keras.Model.fit` and custom training loops:'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 具有实验特性的策略（意味着类和方法仍处于开发阶段），适用于`tf.keras.Model.fit`和自定义训练循环：
- en: '`ParameterServerStrategy`: Model parameters are shared across multiple workers
    (the cluster consists of workers and parameter servers). Workers read and update
    the variables that are created on parameter servers after each iteration.'
  id: totrans-23
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ParameterServerStrategy`: 模型参数在多个工作节点间共享（集群包括工作节点和参数服务器）。每次迭代后，工作节点读取和更新在参数服务器上创建的变量。'
- en: '`CentralStorageStrategy`: Variables are stored in central storage and replicated
    across each GPU.'
  id: totrans-24
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CentralStorageStrategy`: 变量存储在中央存储中，并在每个GPU上复制。'
- en: 'The last strategy that we want to mention is `tf.distribute.OneDev`[`iceStrategy` 
    (https://www.tensorflow.org/api_docs/python/tf/distribute/One](https://www.tensorflow.org/api_docs/python/tf/distribute/OneDeviceStrategy)DeviceStrategy).
    It runs the training code on a single GPU device as follows:'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们想要提及的最后一个策略是`tf.distribute.OneDev`[`iceStrategy`（https://www.tensorflow.org/api_docs/python/tf/distribute/One](https://www.tensorflow.org/api_docs/python/tf/distribute/OneDeviceStrategy)DeviceStrategy）。它在单个GPU设备上运行训练代码：
- en: '[PRE1]'
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: In the preceding example, we have selected the first GPU (`"/gpu:0"`).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述示例中，我们选择了第一个GPU（`"/gpu:0"`）。
- en: 'It is also worth mentioning that the `tf.distribute.get_strategy` function
    can be used to get the current `tf.distribute.Strategy` object. You can use this
    function to change the `tf.distribute.Strategy` object dynamically for your training
    code, as shown in the following code snippet:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 值得一提的是，可以使用`tf.distribute.get_strategy`函数获取当前的`tf.distribute.Strategy`对象。您可以使用此函数动态地为您的训练代码更改`tf.distribute.Strategy`对象，如下面的代码片段所示：
- en: '[PRE2]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: In the preceding code, we are using `tf.distribute.MirroredStrategy` when GPU
    devices are available and fall back to the default strategy when GPU devices are
    not available. Next, let’s look at the features provided by PyTorch.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述代码中，当GPU设备可用时，我们使用`tf.distribute.MirroredStrategy`，当GPU设备不可用时则回退到默认策略。接下来，让我们看一下PyTorch提供的功能。
- en: Utilizing multiple devices for training in PyTorch
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在PyTorch中利用多个设备进行训练
- en: 'To train a PyTorch model successfully, the model and input tensor need to be
    configured for the same device. If you want to use a GPU device, they need to
    be loaded on the target GPU device explicitly before training, using either the
    `to(device=torch.device(''cuda''))` or `cuda()` function:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 要成功训练一个PyTorch模型，模型和输入张量需要配置到相同的设备上。如果要使用GPU设备，它们需要在训练之前显式地加载到目标GPU设备上，可以使用`to(device=torch.device('cuda'))`或`cuda()`函数：
- en: '[PRE3]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The preceding example shows some of the key operations you should be aware
    of when using a GPU device. This is a subset of what is presented in the official
    PyTorch documentation: https://pytorch.org/docs/stable/notes/cuda.html.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 前述示例展示了在使用GPU设备时需要注意的一些关键操作。这是官方PyTorch文档中介绍的一部分内容：https://pytorch.org/docs/stable/notes/cuda.html。
- en: 'However, setting up individual components for training can be tiresome. Therefore,
    `gpus` parameter of `Trainer`:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，为了进行训练设置各个组件可能会很繁琐。因此，`Trainer`的`gpus`参数：
- en: '[PRE4]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'In the preceding example, we are describing various training setups for a single
    machine: training only using CPU devices, training using a set of GPU devices,
    and training using all GPU devices.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在前述示例中，我们描述了单台机器上的各种训练设置：仅使用CPU设备进行训练，使用一组GPU设备进行训练以及使用所有GPU设备进行训练。
- en: Things to remember
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 需要记住的事情
- en: a. TF and PyTorch provide built-in support for training a model using both CPU
    and GPU devices.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: a. TF和PyTorch都内置了使用CPU和GPU设备训练模型的支持。
- en: b. Training can be controlled using the `tf.distribute.Strategy` class in TF.
    When training a model with a single machine, you can use `MirroredStrategy` or
    `OneDeviceStrategy`.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: b. 使用TF的`tf.distribute.Strategy`类可以控制训练过程。在单台机器上训练模型时，可以使用`MirroredStrategy`或`OneDeviceStrategy`。
- en: c. To train a PyTorch model using GPU devices, the model and relevant tensors
    need to be loaded on the same GPU device manually. PL hides most of the boilerplate
    code by handling the placements as part of the `Trainer` class.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: c. 使用GPU设备训练PyTorch模型时，需要手动将模型和相关张量加载到同一GPU设备上。PL通过`Trainer`类处理放置操作，隐藏了大部分样板代码。
- en: In this section, we learned how to utilize multiple devices on a single machine.
    However, there have been many efforts to utilize a cluster of machines for training
    as there is a limit on the computational power that a single machine can have.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们学习了如何在单台机器上利用多个设备。然而，随着单台机器计算能力的限制，已经有很多努力将集群用于训练。
- en: Training a model on a cluster
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在集群上训练模型
- en: 'Even though using multiple GPUs on a single machine has reduced the training
    time a lot, some models are extremely huge and still require multiple days for
    training. Adding more GPUs is still an option but physical limitations often exist,
    preventing you from utilizing the full potential of the multi-GPU setting: motherboards
    can support a limited number of GPU devices.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管在单台机器上使用多个GPU已经大大减少了训练时间，但有些模型仍然非常庞大，需要多天的时间进行训练。增加更多的GPU仍然是一种选择，但通常存在物理限制，阻止您充分利用多GPU设置的潜力：主板可能仅支持有限数量的GPU设备。
- en: 'Fortunately, many DL frameworks already support training a model on a distributed
    system. While there are minor differences in the actual implementation, most frameworks
    adopt the idea of **model parallelism** and **data parallelism**. As shown in
    the following diagram, model parallelism distributes components of the model to
    multiple machines, while data parallelism distributes the samples of the training
    set:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，许多深度学习框架已经支持在分布式系统上训练模型。尽管在实际实施中存在一些细微差异，但大多数框架都采纳了**模型并行**和**数据并行**的理念。如下图所示，模型并行将模型的组件分布到多台机器上，而数据并行则将训练集的样本分布到多个设备上：
- en: '![Figure 6.1 – The difference between model parallelism and data parallelism'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 6.1 – 模型并行和数据并行之间的区别'
- en: '](img/B18522_06_01.jpg)'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18522_06_01.jpg)'
- en: Figure 6.1 – The difference between model parallelism and data parallelism
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.1 – 模型并行和数据并行之间的区别
- en: There are a couple of details that you must be aware of when setting up a distributed
    system for model training. First, the machines in the cluster need to have a stable
    connection to the internet since they communicate over the network. If stability
    is not guaranteed, the cluster must have a way to recover from the connection
    issue. Ideally, the distributed system should be agnostic to the available machines
    and be able to add or remove a machine without affecting the overall progress.
    Such functionality will allow users to increase or decrease the number of machines
    dynamically, achieving the model training in the most cost-efficient way. AWS
    provides the aforementioned functionalities out of the box through **Elastic MapReduce**
    (**EMR**) and **Elastic Container Service** (**ECS**).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在设置分布式系统进行模型训练时，有几个必须注意的细节。首先，集群中的机器需要稳定连接到互联网，因为它们通过网络进行通信。如果不能保证稳定性，集群必须有一种方法来恢复连接问题。理想情况下，分布式系统应该对可用的机器无感知，并且能够在不影响总体进度的情况下添加或删除机器。这样的功能将允许用户动态增加或减少机器数量，以最经济高效的方式进行模型训练。AWS通过**弹性
    MapReduce** (**EMR**) 和 **弹性容器服务** (**ECS**) 提供上述功能。
- en: In the next two sections, we will take a deeper look into model parallelism
    and data parallelism.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的两个部分，我们将更深入地研究模型并行ism和数据并行ism。
- en: Model parallelism
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型并行ism
- en: 'In the case of model parallelism, each machine in a distributed system takes
    a part of the model and manages computations for the assigned components. This
    approach is often considered when a network is too big to fit on a single GPU.
    However, it is not that common in reality because GPU devices often have enough
    memory to fit the model, and it is quite complex to set it up. In this section,
    we are going to describe the two most basic approaches of model parallelism: **model
    sharding** and **model pipelining**.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型并行ism的情况下，分布式系统中的每台机器都负责模型的一部分，并管理分配组件的计算。当一个网络太大以至于无法放入单个GPU时，通常会考虑这种方法。然而，在实际情况下并不常见，因为GPU设备通常有足够的内存来容纳模型，并且设置起来非常复杂。在本节中，我们将描述模型并行ism的两种最基本的方法：**模型分片ism**
    和 **模型管道化**。
- en: Model sharding
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型分片ism
- en: 'Model sharding is nothing more than partitioning the model into multiple computational
    subgraphs across multiple devices. Let’s assume a simple scenario of a basic single-tier
    **deep neural network** (**DNN**) model (no parallel paths). The model can be
    split into a few consecutive subgraphs, and the sharding profile can be graphically
    represented as follows. The data will flow sequentially starting from the device
    with the first subgraph. Each device will pass the computed values to the device
    of the next subgraph. Until the necessary data arrives, the devices will stay
    idle. In this example, we have four subgraphs:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 模型分片ism不过是将模型分割成多个计算子图，分布在多个设备上。让我们假设一个简单的基本单层**深度神经网络** (**DNN**) 模型的简单场景（没有并行路径）。模型可以分成几个连续的子图，并且分片配置可以以图形方式表示如下。数据将从带有第一个子图的设备开始顺序流动。每个设备将将计算值传递给下一个子图的设备，直到到达所需的数据为止，设备将保持空闲状态。在此示例中，我们有四个子图：
- en: '![Figure 6.2 – A sample distribution of a model in model sharding; each arrow
    indicates a mini-batch'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 6.2 – 模型分片示例分布图；每个箭头表示一个小批量'
- en: '](img/B18522_06_02.jpg)'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18522_06_02.jpg)'
- en: Figure 6.2 – A sample distribution of a model in model sharding; each arrow
    indicates a mini-batch
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.2 – 模型分片示例分布图；每个箭头表示一个小批量
- en: As you can see, model sharding does not utilize the full computational resources;
    a device is waiting for the other device to process its subgraph. To solve this
    problem, the pipelining approach is proposed.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，模型分片ism未充分利用计算资源；设备在等待另一个设备处理其子图。为了解决这个问题，提出了管道化方法。
- en: Model pipelining
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型管道化
- en: 'In the case of model pipelining, a mini-batch is split into micro-batches and
    provided to the system in chains, as shown in the following diagram:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型管道化的情况下，一个小批量被分割成微批次，并按照链式提供给系统，如下图所示：
- en: '![Figure 6.3 – A diagram of model pipeline logic; each arrow indicates a mini-batch'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 6.3 – 模型管道逻辑图示；每个箭头表示一个小批量'
- en: '](img/B18522_06_03.jpg)'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18522_06_03.jpg)'
- en: Figure 6.3 – A diagram of model pipeline logic; each arrow indicates a mini-batch
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.3 – 模型管道逻辑图示；每个箭头表示一个小批量
- en: 'However, model pipelining requires a modified version of backward propagation.
    Let’s look at how a single forward and backward propagation can be achieved in
    a model pipelining setting. At some point, each device needs to perform not only
    forward computations for its subgraph but also gradient computations. A single
    forward and backward propagation can be achieved like so:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，模型管道需要反向传播的修改版本。让我们看看如何在模型管道设置中实现单个前向和反向传播。在某些时候，每个设备不仅需要为其子图进行前向计算，还需要进行梯度计算。单个前向和反向传播可以如下实现：
- en: '![Figure 6.4 – A single forward and backward propagation in model pipelining'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '![图6.4 – 模型管道中的单个前向和反向传播'
- en: '](img/B18522_06_04.jpg)'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18522_06_04.jpg)'
- en: Figure 6.4 – A single forward and backward propagation in model pipelining
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.4 – 模型管道中的单个前向和反向传播
- en: 'In the preceding diagram, we can see that each device runs forward propagation
    one by one and backward propagation in reverse order, passing the computed values
    to the next device. Putting everything together, we get the following diagram,
    which summarizes the logic of model pipelining:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在上图中，我们可以看到每个设备依次运行前向传播和反向传播，以相反的顺序传递计算值给下一个设备。将所有内容汇总在一起，我们得到下面的图表，总结了模型管道的逻辑：
- en: '![Figure 6.5 – Model parallelism based on model pipelining'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '![图6.5 – 基于模型管道的模型并行ism'
- en: '](img/B18522_06_05.jpg)'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18522_06_05.jpg)'
- en: Figure 6.5 – Model parallelism based on model pipelining
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.5 – 基于模型管道的模型并行ism
- en: To further improve the training time, each device stores the values it computed
    previously and utilizes them in the following computations.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步提高训练时间，每个设备都存储其先前计算的值，并在接下来的计算中利用这些值。
- en: Model parallelism in TensorFlow
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在TensorFlow中的模型并行ism
- en: 'The following code snippet shows how to assign a set of layers to a specific
    device in TF as you define the model architecture:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的代码片段展示了如何在定义模型架构时将一组层分配给特定设备：
- en: '[PRE5]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: If you want to explore model parallelism in TF even more, we r[ecommend checking
    out the Mesh TF](https://github.com/tensorflow/mesh) repository (https://github.com/tensorflow/mesh).
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想进一步探索TensorFlow中的模型并行ism，我们推荐查看Mesh TF存储库（https://github.com/tensorflow/mesh）。
- en: Model parallelism in PyTorch
  id: totrans-77
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在PyTorch中的模型并行ism
- en: 'Model parallelism is only available on PyTorch and has not yet been implemented
    in PL. While there are many ways to achieve model parallelism with PyTorch, the
    most standard approach is to use the `torch.distributed.rpc` module which achieves
    the communication among the machines using a **remote procedure call** (**RPC**).
    The three main features of the RPC-based approaches are triggering functions or
    networks remotely (remote execution), accessing and referencing remote data objects
    (remote reference), and extending the gradients update functionality of PyTorch
    across the machine boundaries (distributed gradients update). We delegate [the
    details to the official docum](https://pytorch.org/docs/stable/rpc.html)entation:
    https://pytorch.org/docs/stable/rpc.html.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 模型并行ism仅适用于PyTorch，并尚未在PL中实现。尽管有许多方法可以使用PyTorch实现模型并行ism，但最标准的方法是使用`torch.distributed.rpc`模块，该模块通过**远程过程调用**（**RPC**）在机器之间进行通信。基于RPC的方法的三个主要特征是远程执行函数或网络（远程执行）、访问和引用远程数据对象（远程引用）以及扩展PyTorch跨机器边界的梯度更新功能（分布式梯度更新）。我们将详细信息委托给[官方文档](https://pytorch.org/docs/stable/rpc.html)：https://pytorch.org/docs/stable/rpc.html.
- en: Data parallelism
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据并行ism
- en: Data parallelism, unlike model parallelism, aims to speed up the training by
    sharding the dataset to the machines in the cluster. Each machine gets a copy
    of the model and computes the gradients with the dataset it has been assigned
    to. Then, the gradients are aggregated and the models are updated globally at
    once.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 数据并行ism与模型并行ism不同，其目的是通过将数据集分片到集群中的机器来加速训练。每台机器都获得模型的副本，并与其分配的数据集计算梯度。然后，梯度被聚合，并且模型一次全局更新。
- en: Data parallelism in TensorFlow
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在TensorFlow中的数据并行ism
- en: Data parallelism can be realized in TF by leveraging `tf.distribute.MultiWorkerMirroredStrategy`,
    `tf.distribute.ParameterServerStrategy`, and `tf.distribute.CentralStorageStrategy`.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过利用`tf.distribute.MultiWorkerMirroredStrategy`、`tf.distribute.ParameterServerStrategy`和`tf.distribute.CentralStorageStrategy`在TF中实现数据并行ism。
- en: We introduced these strategies in the *Utilizing multiple devices for training
    in TensorFlow* section since specific `tf.distributed` strategies are also used
    to set up training on multiple devices within a single machine.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在 *TensorFlow 中利用多个设备进行训练* 部分介绍了这些策略，因为特定的 `tf.distributed` 策略也用于在单个机器内多设备上设置训练。
- en: To use these strategies, you need to set up a TF cluster where each machine
    can communicate with the other.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用这些策略，您需要设置一个 TF 集群，其中每台机器可以与其他机器通信。
- en: 'Typically, a TF cluster is defined using a `TF_CONFIG` environment variable.
    `TF_CONFIG` is just a `JSON` string that specifies cluster configuration by defining
    two components: `cluster` and `task`. The following Python code shows how to generate
    a `.json` file for `TF_CONFIG` from a Python dictionary:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，TF 集群使用 `TF_CONFIG` 环境变量定义。 `TF_CONFIG` 只是一个 `JSON` 字符串，通过定义两个组件来指定集群配置：`cluster`
    和 `task`。以下 Python 代码展示了如何从 Python 字典生成 `TF_CONFIG` 的 `.json` 文件：
- en: '[PRE6]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[The `TF_CONFIG` fields and formats are described at https://cloud.google.com](https://cloud.google.com/ai-platform/training/docs/distributed-training-details)/ai-platform/training/docs/distributed-training-details.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '[关于 `TF_CONFIG` 的字段和格式，请参阅 https://cloud.google.com/ai-platform/training/docs/distributed-training-details](https://cloud.google.com/ai-platform/training/docs/distributed-training-details)。'
- en: As demonstrated in the *Utilizing multiple devices for training in TensorFlow*
    section, you need to put the training code under the `tf.distribute.Strategy`
    scope. In the following example, we will show a sample usage for `tf.distribute.MultiWorkerMirroredStrategy`
    class.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 正如在 *TensorFlow 中利用多个设备进行训练* 部分演示的，您需要将训练代码放在 `tf.distribute.Strategy` 范围内。在下面的示例中，我们将展示
    `tf.distribute.MultiWorkerMirroredStrategy` 类的样例用法。
- en: 'First of all, you must put your model instance under the scope of `tf.distribute.MultiWorkerMirroredStrategy`,
    as shown in the following code snippet:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，您必须将您的模型实例放在 `tf.distribute.MultiWorkerMirroredStrategy` 的范围内，如下所示：
- en: '[PRE7]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Next, you need to make sure the `TF_CONFIG` environment variables have been
    set up correctly for each machine in the cluster and run the training script,
    as follows:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，您需要确保每台机器的 `TF_CONFIG` 环境变量已正确设置，并运行训练脚本，如下所示：
- en: '[PRE8]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'To correctly save your [model, please take a look at the official documentation:
    https://www.t](https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras)ensorflow.org/tutorials/distribute/multi_worker_with_keras.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 要正确保存您的[模型，请查看官方文档：https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras](https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras)。
- en: In the case of a [custom training loop, you can follow the instructions at https://ww](https://www.tensorflow.org/tutorials/distribute/multi_worker_with_ctl)w.tensorflow.org/tutorials/distribute/multi_worker_with_ctl.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 如果使用[自定义训练循环，可以按照 https://www.tensorflow.org/tutorials/distribute/multi_worker_with_ctl](https://www.tensorflow.org/tutorials/distribute/multi_worker_with_ctl)
    中的说明操作。
- en: Data parallelism in PyTorch
  id: totrans-95
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: PyTorch 中的数据并行
- en: Unlike model parallelism, data parallelism is available for both PyTorch and
    PL. Among the various implementations, the most standard feature is `torch.nn.parallel.DistributedDataParallel`
    (DDP). In this section, we will mainly discuss PL as its main advantage comes
    from the simplicity of the training models that use data parallelism.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 与模型并行不同，数据并行在 PyTorch 和 PL 中都可用。在各种实现中，最标准的功能是 `torch.nn.parallel.DistributedDataParallel`（DDP）。本节中，我们将主要讨论
    PL，因为其主要优势来自于使用数据并行的训练模型的简易性。
- en: To train a model using data parallelism, you need to modify the training code
    to utilize the underlying distributed system and spawn a process with the `torch.distributed.run`
    module on each machine ([https://pytorch.org/docs/stable/distributed.html](https://pytorch.org/docs/stable/distributed.html)).
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用数据并行训练模型，您需要修改训练代码以利用底层分布式系统，并使用 `torch.distributed.run` 模块在每台机器上生成一个进程（[https://pytorch.org/docs/stable/distributed.html](https://pytorch.org/docs/stable/distributed.html)）。
- en: 'The following code snippet describes what you need to change for ddp. You simply
    need to provide `ddp` for the `accelerator` parameter of `Trainer`. `num_nodes`
    is the parameter to adjust when there is more than one machine in the cluster:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的代码片段描述了您需要为 ddp 更改的内容。您只需为 `Trainer` 的 `accelerator` 参数提供 `ddp`。当集群中有多台机器时，需要调整
    `num_nodes` 参数：
- en: '[PRE9]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Once the script has been set up, you need to run the following command on each
    machine. Please keep in mind that `MASTER_ADDR` and `MASTER_PORT` must be consistent
    as they are used by each processor to communicate. On the other hand, `NODE_RANK`
    indicates the index of the machine. In other words, it must be different for each
    machine, and it must start from zero:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦脚本设置完毕，您需要在每台机器上运行以下命令。请记住，`MASTER_ADDR`和`MASTER_PORT`必须保持一致，因为每个处理器都会使用它们进行通信。另外，`NODE_RANK`表示机器的索引。换句话说，它必须对每台机器都不同，并且必须从零开始：
- en: '[PRE10]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Based on the official documentation, DDP works as follows:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 根据官方文档，DDP的工作原理如下：
- en: Each GPU across each node spins up a process.
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每个节点上的每个GPU都会启动一个进程。
- en: Each process gets a subset of the training set.
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每个进程获取训练集的一个子集。
- en: Each process initializes the model.
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每个进程初始化模型。
- en: Each process performs both forward and backward propagation in parallel.
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每个进程都并行执行前向和后向传播。
- en: The gradients are synchronized and averaged across all processes.
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 梯度在所有进程之间同步和平均。
- en: Each process updates the weights of the model it has.
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每个进程更新其拥有的模型的权重。
- en: Things to remember
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 要记住的事情
- en: a. TF and PyTorch provide options for training DL models across multiple machines
    using model parallelism and data parallelism.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: a. TF和PyTorch提供了使用模型并行ism和数据并行ism在多台机器上训练DL模型的选项。
- en: b. Model parallelism splits the model into multiple components and distributes
    them across machines. To set up model parallelism in TF and PyTorch, you can use
    the `Mesh TensorFlow` library and the `torch.distributed.rpc` package, respectively.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: b. 模型并行将模型分成多个组件，并将它们分布在多台机器上。在TF和PyTorch中设置模型并行ism，可以使用`Mesh TensorFlow`库和`torch.distributed.rpc`包，分别。
- en: c. Data parallelism copies the model to each machine and distributes mini-batches
    across machines for training. In TF, data parallelism can be achieved using either
    `MultiWorkerMirroredStrategy`, `ParameterServerStrategy`, or `CentralStorageStrategy`.
    The main package that’s been designed for data parallelism in PyTorch is called
    `torch.nn.parallel.DistributedDataParallel`.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: c. 数据并行ism将模型复制到每台机器上，并分布小批量数据以进行训练。在TF中，可以使用`MultiWorkerMirroredStrategy`、`ParameterServerStrategy`或`CentralStorageStrategy`实现数据并行ism。PyTorch中专门用于数据并行ism的主要包是`torch.nn.parallel.DistributedDataParallel`。
- en: In this section, we learned how to achieve model training where the lifetime
    of the cluster is explicitly managed. However, some tools manage the clusters
    for model training as well. Since each of them has different advantages, you should
    understand the difference to select the right tool for your development.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们学习了如何实现模型训练，其中集群的生命周期得到明确管理。然而，一些工具还管理模型训练的集群。由于它们各自具有不同的优势，您应该理解其差异，以选择适合您开发的正确工具。
- en: First, we will look at the built-in features of SageMaker that train a DL model
    in a distributed fashion.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将查看SageMaker的内置功能，以分布式方式训练DL模型。
- en: Training a model using SageMaker
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用SageMaker训练模型
- en: As mentioned in the *Utilizing SageMaker for ETL* section of [*Chapter 5*](B18522_05.xhtml#_idTextAnchor106),
    *Data Preparation in the Cloud*, the motivation of SageMaker is to help engineers
    and researchers focus on developing high-quality DL pipelines without worrying
    about infrastructure management. SageMaker manages data storage and computational
    resources for you, allowing you to utilize a distributed system for model training
    with minimal effort. In addition, SageMaker supports streaming data to your models
    for inferencing, hyperparameter tuning, and tracking experiments and artifacts.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 正如在[*第5章*](B18522_05.xhtml#_idTextAnchor106)的*在云中利用SageMaker进行ETL*部分中提到的，SageMaker的动机是帮助工程师和研究人员专注于开发高质量的DL流水线，而无需担心基础设施管理。SageMaker为您管理数据存储和计算资源，使您可以利用分布式系统轻松进行模型训练。此外，SageMaker支持向模型流式传输数据以进行推断、超参数调整和跟踪实验和工件。
- en: SageMaker Studio is the place where you define the logic for your model. The
    SageMaker Studio notebooks allow you to quickly explore the available data and
    set up model training logic. When model training takes too long, scaling up to
    use multiple computational resources and finding the best set of hyperparameters
    can be efficiently achieved by making a few modifications to the infrastructure’s
    configuration. Furthermore, SageMaker supports hyperparameter tuning on a distributed
    system to exploit parallelism.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker Studio是您定义模型逻辑的地方。SageMaker Studio笔记本允许您快速探索可用数据并设置模型训练逻辑。当模型训练时间过长时，通过对基础架构配置进行少量修改，可以有效地实现扩展使用多个计算资源和找到最佳超参数集。此外，SageMaker支持在分布式系统上进行超参数调整以利用并行性。
- en: Even though SageMaker sounds like a magic key for a DL pipeline, there are disadvantages
    as well. The first is its cost. Instances that have been allocated to SageMaker
    are around 40% more expensive than equivalent EC2 instances. Next, you may find
    that not all the libraries are available in the notebook. In other words, you
    may need to spend some additional time building and installing the library you
    need.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管SageMaker听起来像深度学习流水线的魔法钥匙，但也有其不足之处。首先是其成本。分配给SageMaker的实例比等效的EC2实例贵约40%。其次，您可能会发现并非所有库都在笔记本中可用。换句话说，您可能需要额外的时间来构建和安装所需的库。
- en: Setting up model training for SageMaker
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置SageMaker的模型训练
- en: 'By now, you should be able to start a notebook and select a predefined development
    environment for your project since we covered these in the *Utilizing SageMaker
    for ETL* section of [*Chapter 5*](B18522_05.xhtml#_idTextAnchor106), *Data Preparation
    in the Cloud*. Assuming that you have already processed raw data and stored the
    processed data in a data storage, we will focus on model training in this section.
    Model training with SageMaker can be summarized into the following three steps:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你应该能够启动一个笔记本并选择一个预定义的开发环境，因为我们在[*第5章*](B18522_05.xhtml#_idTextAnchor106)的*利用SageMaker进行ETL*部分已经涵盖了这些内容。假设您已经处理了原始数据并将处理后的数据存储在数据存储中，我们将在本节中专注于模型训练。使用SageMaker进行模型训练可以总结为以下三个步骤：
- en: If the processed data in the storage hasn’t been split into training, validation,
    and test sets yet, you must split them first.
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果存储中的处理数据尚未分割为训练、验证和测试集，则必须首先对其进行分割。
- en: You need to define the model training logic and specify the cluster configuration.
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您需要定义模型训练逻辑并指定集群配置。
- en: Lastly, you need to train your model and save the artifacts back in data storage.
    When training is completed, the allocated instances will be terminated automatically.
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，您需要训练您的模型并将生成的结果保存回数据存储中。当训练完成时，分配的实例将自动终止。
- en: 'The key for model training with SageMaker is `sagemaker.estimator.Estimator`.
    It allows you to configure the training settings, including i[nfrastructure setup,
    type of Docker images to use, and hyperparameters](https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html)
    ([https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html](https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html)).
    The following are the main parameters that you would typically configure:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 使用SageMaker进行模型训练的关键是`sagemaker.estimator.Estimator`。它允许您配置训练设置，包括基础架构设置、要使用的Docker镜像类型和超参数。以下是您通常会配置的主要参数：
- en: '`role` (`str`): An AWS IAM role'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`role` (`str`): AWS IAM角色'
- en: '`instance_count` (`int`): The number of SageMaker EC2 instances to use for
    training'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`instance_count` (`int`): 用于训练的SageMaker EC2实例数量'
- en: '`instance_type` (`str`): The type of SageMaker EC2 instance to use for training'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`instance_type` (`str`): 用于训练的SageMaker EC2实例类型'
- en: '`volume_size` (`int`): The size of the Amazon **Elastic Block Store** (**EBS**)
    volume (in gigabytes) that will be used to download input data temporarily for
    training'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`volume_size` (`int`): 用于临时下载训练输入数据的Amazon **弹性块存储**（**EBS**）卷的大小（以GB为单位）'
- en: '`output_path` (`str`): An S3 object where the training result will be stored'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_path` (`str`): 训练结果将存储在的S3对象'
- en: '`use_spot_instances` (`bool`): A flag specifying whether to use SageMaker-managed
    AWS Spot instances for training'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_spot_instances` (`bool`): 指定是否使用SageMaker管理的AWS Spot实例进行训练的标志'
- en: '`checkpoint_s3_uri` (`str`): An S3 URI where the checkpoints will be stored
    during training'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`checkpoint_s3_uri` (`str`): 训练期间将检查点存储在的S3 URI'
- en: '`hyperparameters` (`dict`): A dictionary containing the initial set of hyperparameters'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hyperparameters` (`dict`): 包含初始超参数集的字典'
- en: '`entry_point` (`str`): The path to the Python file to run'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`entry_point` (`str`): 运行的Python文件路径'
- en: '`dependencies` (`list[str]`): A list of directories that will be loaded into
    the job'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dependencies` (`list[str]`): 将加载到作业中的目录列表'
- en: So long as you select the right container from Amazon **Elastic Container Registry**
    (**ECR**), you can set up any training configuration for SageMaker. Containers
    with variou[s configurations for CPU and GPU devices also exist. You can find
    these at http](https://github.com/aws/deep-learning-containers/blob/master/available_images.md)s://github.com/aws/deep-learning-containers/blob/master/available_images.md.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 只要您从Amazon **弹性容器注册表** (**ECR**)中选择正确的容器，您就可以为SageMaker设置任何训练配置。还存在具有不同CPU和GPU设备配置的容器。您可以在http://github.com/aws/deep-learning-containers/blob/master/available_images.md中找到这些信息。
- en: 'In addition, there exist repositories of open sourced toolkits designed to
    help TF and PyTorch model training on Amazon SageMaker. These repositories also
    contain Docker files that already have the necessary libraries installed, such
    as TF, PyTo[rch, and other dependencies necessary to build SageMaker ima](https://github.com/aws/sagemaker-tensorflow-training-toolkit)ges:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，还存在开源工具包的存储库，旨在帮助在Amazon SageMaker上进行TF和PyTorch模型训练。这些存储库还包含已经安装了必要库（如TF、PyTo[rch和其他构建SageMaker
    ima](https://github.com/aws/sagemaker-tensorflow-training-toolkit)ges所需的依赖项的Docker文件：
- en: 'TF[: https://github.com/aws/sagemaker-tensorflow-traini](https://github.com/aws/sagemaker-pytorch-training-toolkit)ng-toolkit'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'TF[: https://github.com/aws/sagemaker-tensorflow-traini](https://github.com/aws/sagemaker-pytorch-training-toolkit)ng-toolkit'
- en: 'PyTorch: https://github.com/aws/sagemaker-pytorch-training-toolkit'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'PyTorch: https://github.com/aws/sagemaker-pytorch-training-toolkit'
- en: Lastly, we would like to mention that you can build and run the containers on
    your local machine. You can also update the installed libraries if you need to.
    If any modification is made, you need to upload the modified container to Amazon
    ECR before you can use it with `sagemaker.estimator.Estimator`.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们想提一下，您可以在本地机器上构建和运行容器。如果需要，您还可以更新安装的库。如果进行任何修改，需要将修改后的容器上传到Amazon ECR，然后才能在`sagemaker.estimator.Estimator`中使用它。
- en: In the following two sections, we will describe a set of changes that are required
    to train TF and PyTorch models.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的两个部分中，我们将描述训练TF和PyTorch模型所需的一系列更改。
- en: Training a TensorFlow model using SageMaker
  id: totrans-141
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用SageMaker训练TensorFlow模型
- en: 'SageMaker provides a `sagemaker.estimator.Estimator` class built for TF: `sagemaker.tensorflow.estimator.TensorFlow`
    ([https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/sagemaker.tensorflow.html](https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/sagemaker.tensorflow.html)).'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker为TF提供了一个`sagemaker.estimator.Estimator`类：`sagemaker.tensorflow.estimator.TensorFlow`
    ([https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/sagemaker.tensorflow.html](https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/sagemaker.tensorflow.html)).
- en: 'The following example shows the wrapper script that you need to write using the
    `sagemaker.tensorflow.estimator.TensorFlow` class to train a TF model on SageMaker:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例展示了您需要使用`sagemaker.tensorflow.estimator.TensorFlow`类编写的包装脚本，以在SageMaker上训练TF模型：
- en: '[PRE11]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Please keep in mind that every key in the `hyperparameters` parameter must
    have a corresponding entry defined in `ArgumentParser` of the training script
    (`train_script.py`). In the preceding example, we only have epochs defined (`''epochs'':
    30`).'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '请记住，在训练脚本（`train_script.py`）的`ArgumentParser`中，`hyperparameters`参数的每个键必须有相应的条目定义。在上述示例中，我们仅定义了epochs
    (`''epochs'': 30`)。'
- en: 'To trigger the training, you need to call the `fit` function. You will need
    to provide datasets for training and validation. If you have them on an S3 bucket,
    the `fit` function will look as follows:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 要启动训练，您需要调用`fit`函数。如果您的数据集在S3桶上，`fit`函数将如下所示：
- en: '[PRE12]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The preceding example will run `training_script.py`, specified in the `entry_point`
    parameter, by locating it in the directory provided by `source_dir`. The details
    of the instance can be found in the `instance_count` and `instance_type` parameters.
    The training script will run with the parameters defined for `hyperparameters`
    of `tf_estimator` on the training and validation datasets defined in the `fit`
    function.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的示例将在由 `source_dir` 提供的目录中运行 `entry_point` 参数指定的 `training_script.py`。实例的详细信息可以在
    `instance_count` 和 `instance_type` 参数中找到。训练脚本将在 `fit` 函数中定义的训练和验证数据集上使用 `tf_estimator`
    的 `hyperparameters` 进行运行。
- en: Training a PyTorch model using SageMaker
  id: totrans-149
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用SageMaker训练PyTorch模型
- en: 'Similar [to `sagemaker.tensorflow.estimator.TensorFlow`, there’s `sagemaker.pytorch.PyTorch`
    (](https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/sagemaker.pytorch.html)).
    You can set up the training for your PyTorch (or PL) model, as described in the
    *Implementing and training a model in PyTorch* section of , *Data Preparation
    in the Cloud*, and integrate `sagemaker.pytorch.PyTorch`, as shown in the following
    code snippet:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于 `sagemaker.tensorflow.estimator.TensorFlow`，存在 `sagemaker.pytorch.PyTorch`（[链接](https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/sagemaker.pytorch.html)）。您可以按照《在PyTorch中实现和训练模型》一节中的描述设置PyTorch（或PL）模型的训练，并集成
    `sagemaker.pytorch.PyTorch`，如下面的代码片段所示：
- en: '[PRE13]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The usage of a PyTorch estimator is identical to a TF estimator described in
    the previous section.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 使用PyTorch估算器的方法与前一节描述的TF估算器相同。
- en: This concludes the basic usage of SageMaker for model training. Next, we will
    learn how to scale up training jobs in SageMaker. We will discuss distributed
    training using a distribution strategy. We will also cover how you can speed up
    the training by utilizing other data storage services that have lower latency.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 这就完成了使用SageMaker进行模型训练的基本用法。接下来，我们将学习如何在SageMaker中扩展训练作业。我们将讨论使用分布策略进行分布式训练。我们还将介绍如何通过使用具有更低延迟的其他数据存储服务来加快训练速度。
- en: Training a model in a distributed fashion using SageMaker
  id: totrans-154
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用SageMaker以分布方式训练模型
- en: Da[ta parallelism in SageMaker can be achieved using a distributed data paralle](https://sagemaker.readthedocs.io/en/stable/api/training/smd_data_parallel.html)l
    library (https://sagemaker.readthedocs.io/en/stable/api/training/smd_data_parallel.html).
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在SageMaker中可以通过使用分布式数据并行库（[链接](https://sagemaker.readthedocs.io/en/stable/api/training/smd_data_parallel.html)）实现数据并行。
- en: 'All you need to do is to enable `dataparallel` as you create the `sagemaker.estimator.Estimator`
    instance, as follows:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 您所需做的就是在创建 `sagemaker.estimator.Estimator` 实例时启用 `dataparallel`，如下所示：
- en: '[PRE14]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The following code snippet sho[ws a TF estimator that’s been created with `dataparallel`.
    The full details can b](https://docs.aws.amazon.com/en_jp/sagemaker/latest/dg/data-parallel-use-api.html)e
    found at https://docs.aws.amazon.com/en_jp/sagemaker/latest/dg/data-parallel-use-api.html:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的代码片段展示了使用 `dataparallel` 创建的TF估算器。详细信息可以在 https://docs.aws.amazon.com/en_jp/sagemaker/latest/dg/data-parallel-use-api.html
    找到：
- en: '[PRE15]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The same modifications are necessary for a PyTorch estimator.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 对于PyTorch估算器，需要进行相同的修改。
- en: 'SageMaker supports two different mechanisms for transferring input data to
    the underlying algorithm: file mode and pipe mode. By default, SageMaker uses
    file mode, which downloads the input data to an EBS volume for training. However,
    if the amount of data is huge, this can slow down the training. In this case,
    you can use pipe mode, which streams data from S3 (using Linux FIFO) without making
    extra copies.'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker支持两种不同的机制来将输入数据传输给底层算法：文件模式和管道模式。默认情况下，SageMaker使用文件模式，将输入数据下载到用于训练的EBS卷中。但是，如果数据量很大，这可能会减慢训练速度。在这种情况下，您可以使用管道模式，它会从S3（使用Linux
    FIFO）流式传输数据，而无需进行额外的复制。
- en: 'In [the case of TF, you can simply use `PipeModeDataset` fr](https://github.com/aws/sagemaker-tensorflow-extensions)om
    the `sagemaker-tensorflow` extension (https://github.com/aws/sagemaker-tensorflow-extensions)
    as follows:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在TF的情况下，您可以简单地从 `sagemaker-tensorflow` 扩展中使用 `PipeModeDataset`，如 https://github.com/aws/sagemaker-tensorflow-extensions
    所示：
- en: '[PRE16]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'However, training a PyTorch model using pipe mode requires a bit more engineering
    e[ffort. Therefore, we will point you to a notebook example that describes each
    step in depth: https://github.com/aws/amazon-sage](https://github.com/aws/amazon-sagemaker-examples/blob/main/advanced_functionality/pipe_bring_your_own/pipe_bring_your_own.ipynb)maker-examples/blob/main/advanced_functionality/pipe_bring_your_own/pipe_bring_your_own.ipynb.'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，使用管道模式训练PyTorch模型需要更多的工程化**努力**。因此，我们将为您指引一个笔记本示例，深入描述每个步骤：[https://github.com/aws/amazon-sagemaker-examples/blob/main/advanced_functionality/pipe_bring_your_own/pipe_bring_your_own.ipynb](https://github.com/aws/amazon-sagemaker-examples/blob/main/advanced_functionality/pipe_bring_your_own/pipe_bring_your_own.ipynb)。
- en: 'The distributed strategy and pipe mode should speed up the training by scaling
    up the underlying computational resources and increasing the data transfer throughputs.
    However, if they are not sufficient, you can try leveraging two other more efficient
    data storage services that are compatible with SageMaker: Amazon **Elastic File
    System** (**EFS**) and Amazon **fully managed shared storage** (**FSx**) which
    [was built for the Lustre f](https://aws.amazon.com/efs/)ilesy[stem. For more
    details, you can re](https://aws.amazon.com/fsx/lustre/)fer to their official
    pages at https://aws.amazon.com/efs/ and https://aws.amazon.com/fsx/lustre/, respectively.'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 分布策略和管道模式应该通过扩展底层计算资源和提高数据传输吞吐量来加速训练。然而，如果它们不足以满足需求，您可以尝试利用另外两种与SageMaker兼容的更高效的数据存储服务：亚马逊**弹性文件系统**（**EFS**）和亚马逊**完全托管的共享存储**（**FSx**），它是为Lustre文件系统而构建的。有关更多详细信息，请分别参阅它们的官方页面：[https://aws.amazon.com/efs/](https://aws.amazon.com/efs/)
    和 [https://aws.amazon.com/fsx/lustre/](https://aws.amazon.com/fsx/lustre/)。
- en: SageMaker with Horovod
  id: totrans-166
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SageMaker与Horovod
- en: 'The other option for SageMaker distributed training is to use *Horovod,* a
    free and open source framework for distributed DL training based on **Message
    Passing Interface** (**MPI**) principles. MPI is a standard message-passing library
    that is widely used in parallel computing architectures. Horovod assumes that
    MPI is available for worker discovery and reduction coordination. Horovod can
    also utilize Gloo instead of MPI, an open source collective communications library.
    Here is an example of the distribution parameter configured for Horovod:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker分布式训练的另一选择是使用*Horovod*，这是一个基于**消息传递接口**（**MPI**）原理的免费开源框架，用于分布式DL训练。MPI是一种标准消息传递库，在并行计算架构中被广泛使用。Horovod假设MPI用于工作节点的发现和减少协调。Horovod还可以利用Gloo替代MPI，这是一个开源的集体通信库。这里是为Horovod配置的分布参数示例：
- en: '[PRE17]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: In the preceding code snippet, we are achieving coordination among the machines
    using MPI. `processes_per_host` defines the number of processes to run on each
    instance. This is equivalent to defining the number of processes using the `-H`
    parameter in the `mpirun` or `horovodrun` command, which controls the program’s
    execution in MPI and Horovod, respectively.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码片段中，我们使用MPI实现了机器之间的协调。`processes_per_host`定义了在每个实例上运行的进程数量。这相当于在MPI和Horovod中使用`-H`参数定义进程数量，以控制程序在MPI和Horovod中的执行。
- en: 'In the following code snippet, we are selecting the number of parallel processes
    that control the number of training script executions (the `-np` parameter). Then,
    this number is split into specific machines using the specified values for the
    `-H` parameter. With the following commands, each machine will run `train.py`
    twice. This would be a typical setting when you have four machines with two GPUs
    each. The sum of assigned `-H` processes cannot exceed the `-np` value:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的代码片段中，我们选择了控制训练脚本执行数量的并行进程数（`-np`参数）。然后，使用指定的`-H`参数值将此数目分配到具体的机器上。使用以下命令，每台机器将运行两次`train.py`。这在每台有两个GPU的四台机器的典型设置中是典型的。分配给`-H`进程的总和不能超过`-np`值：
- en: '[PRE18]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: We will discuss Horovod in depth in the following section as we cover how to
    train a DL model on a standalone Horovod cluster composed of EC2 instances.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一节中深入讨论Horovod，讲述如何在由EC2实例组成的独立Horovod集群上训练DL模型。
- en: Things to remember
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 记住的事情
- en: a. SageMaker provides an excellent tool, SageMaker Studio, which allows you
    to quickly perform initial data exploration and train baseline models.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: a. SageMaker提供了一个优秀的工具，SageMaker Studio，允许您快速进行初始数据探索和训练基线模型。
- en: b. The `sagemaker.estimator.Estimator` object is an important component for
    training a model using SageMaker. It also supports distributed training on a set
    of machines with various CPU and GPU configurations.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: c. Utilizing SageMaker for TF and PyTorch model training can be achieved estimators
    that are specifically designed for each framework.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s look at how to use Horovod without SageMaker for distributed model
    training.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: Training a model using Horovod
  id: totrans-178
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Even though we introduced Horovod as we introduced SageMaker, Horovod is designed
    to support distributed training alone (https://horovod.ai/). It aims to provide
    a simple way to train models in a distributed fashion by providing nice integrations
    for popular DL frameworks, including TensorFlow and PyTorch.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned previously in the *SageMaker with Horovod* section, the core principles
    of Horovod a[re based on MPI concepts such as size, rank, local ra](https://horovod.readthedocs.io/en/stable/concepts.html)nk,
    allreduce, allgather, broadcast, and alltoall (https://horovod.readthedocs.io/en/stable/concepts.html).
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will learn about how to set up a Horovod cluster using EC2
    instances. Then, we will describe the modifications you need to make in TF and
    PyTorch scripts to train your model on the Horovod cluster.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: Setting up a Horovod cluster
  id: totrans-182
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To set up a Horovod cluster using EC2 instances, you must follow these steps:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: 'Go to the EC2 instance console: https://console.aws.amazon.com/ec2/.'
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click the **Launch Instances** button in the top-right corner.
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select **Deep Learning AMI** (the abbreviation for Amazon Machine Image) with
    TF, PyTorch, and Horovod installed. Click the **Next …** button at the bottom
    right.
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Select the right **Instance Type** for your training. You can select CPU or
    GPU instance types that fit your needs. Click the **Next …** button at the bottom
    right:'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 6.6 – Instance type selection in the EC2 Instance console'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18522_06_06.jpg)'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.6 – Instance type selection in the EC2 Instance console
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: Select the desired number of instances that will make up your Horovod cluster.
    Here, you can also request AWS Spot instances (cheaper instances based on the
    sparse EC2 capacity that can be interrupted, making them only feasible for fault-tolerant
    tasks). However, let’s use on-demand resources for simplicity.
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the right network and subnet settings. In real life, this type of information
    will be provided by the DevOps department.
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: On the same page, select **Add instance to placement group** and **Add to a
    new placement group**, type the name that you want to use for the group, and select
    **cluster** for **placement group strategy**.
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: On the same page, provide your **Identity and Access Management** (**IAM**)
    role so that you can access S3 buckets. Click the **Next …** button at the bottom
    right.
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the ri[ght storage size for your instances. Click the **Next …** button
    a](https://docs.aws.amazon.com/general/latest/gr/aws_tagging.html)t the bottom
    right.
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为您的实例选择正确的存储大小。在右下角的**下一步……**按钮。
- en: Select unique labels/tags (https://docs.aws.amazon.com/general/latest/gr/aws_tagging.html)
    for your instances. In real life, these might be used as additional security measures,
    such as terminating instances with specific tags. Click the **Next …** button
    at the bottom right.
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为您的实例选择唯一的标签（https://docs.aws.amazon.com/general/latest/gr/aws_tagging.html）。在实际情况中，这些标签可能被用作额外的安全措施，例如使用特定标签终止实例。点击右下角的**下一步……**按钮。
- en: Create a security group or choose an existing one. Again, you must talk to the
    DevOps department to get the proper information. Click the **Next …** button at
    the bottom right.
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建安全组或选择现有的安全组。同样，您必须与DevOps部门沟通以获取适当的信息。在右下角的**下一步……**按钮。
- en: Review all the information and launch. You will be asked to provide a **Privacy
    Enhanced Mail** (**PEM**) key for authentication.
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 审查所有信息并启动。您将被要求提供用于认证的**隐私增强邮件**（**PEM**）密钥。
- en: After these steps, the desired number of instances will start up. If you didn’t
    add the **Name** tag in *Step 10*, your instances will not have any names. In
    this case, you can navigate to the EC2 Instances console and update the names
    manually. At t[he time of writing, you can request static IPv4 addresses called
    Elastic IPs and](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/elastic-ip-addresses-eip.html)
    assign them to your instances (https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/elastic-ip-addresses-eip.html).
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 完成这些步骤后，所需数量的实例将启动。如果您在*步骤10*中没有添加**名称**标签，则您的实例将没有任何名称。在这种情况下，您可以导航到EC2实例控制台并手动更新名称。在写作时，您可以请求称为弹性IP的静态IPv4地址并将其分配给您的实例（https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/elastic-ip-addresses-eip.html）。
- en: Finally, you need to ensure that the instances can communicate with each other
    without an issue. You should check the **Security Groups** settings and add inbound
    rules for SSH and other traffic if necessary.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，确保实例能够无问题地相互通信。您应检查**安全组**设置，并根据需要为SSH和其他流量添加入站规则。
- en: 'At this point, you just need to copy your PEM key from your local machine to
    the master EC2 instance. For an Ubuntu AMI, you can run the following command:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，您只需将本地计算机上的PEM密钥复制到主EC2实例即可。对于Ubuntu AMI，您可以运行以下命令：
- en: '[PRE19]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Now, you can use SSH to connect to the master EC2 instance. What you need to
    do next is to set the passwordless connections between EC2 instances by providing
    your PEM key in the SSH command using the following commands:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您可以使用SSH连接到主EC2实例。接下来要做的是通过以下命令在EC2实例之间设置无密码连接，并在SSH命令中提供您的PEM密钥：
- en: '[PRE20]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: In the preceding code snippet, the `eval` command sets the environment variables
    provided by the `ssh-agent` command, while `ssh-add` command adds a PEM identity
    to the authentication agent.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述代码片段中，`eval`命令设置由`ssh-agent`命令提供的环境变量，而`ssh-add`命令将PEM身份添加到认证代理中。
- en: Now, the cluster is ready to support Horovod! When you are finished, you must
    stop or terminate your cluster on the web console. Otherwise, it will continuously
    charge you for the resources.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，集群已准备好支持Horovod！完成后，必须在Web控制台上停止或终止集群。否则，将持续收取资源费用。
- en: In the next two sections, we will learn how to change the TF and PyTorch training
    scripts for Horovod.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的两个部分中，我们将学习如何更改Horovod的TF和PyTorch训练脚本。
- en: Configuring a TensorFlow training script for Horovod
  id: totrans-208
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为Horovod配置TensorFlow训练脚本
- en: 'To train a TF model using Horovod, you need the `horovod.tensorflow.keras`
    module. First of all, you need to import the `tensorflow` and `horovod.tensorflow.keras`
    modules. We will refer to `horovod.tensorflow.keras` as `hvd`. Then, you need
    to initialize the Horovod cluster as follows:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用Horovod训练TF模型，您需要`horovod.tensorflow.keras`模块。首先，您需要导入`tensorflow`和`horovod.tensorflow.keras`模块。我们将`horovod.tensorflow.keras`称为`hvd`。然后，您需要按以下方式初始化Horovod集群：
- en: '[PRE21]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: At this point, you can check the size of the cluster using the `hvd.size` function.
    Each process in Horovod will be assigned a rank (a number from 0 to the size of
    the cluster in terms of the processes you want to run or devices you want to use),
    which you can access through the `hvd.rank` function. On each instance, each process
    has a distinct number assigned from 0 to the number of processes on that instance,
    known as the local rank (the unique numbers per instance but duplicated across
    instances). The local rank for the current process can be accessed using the `hvd.local_rank`
    function.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，您可以使用`hvd.size`函数检查集群的大小。Horovod中的每个进程将被分配一个等级（从0到集群大小，即您要运行的进程或要使用的设备的数量），您可以通过`hvd.rank`函数访问此等级。在每个实例上，每个进程都被分配一个不同的编号，从0到该实例上的进程数，称为本地等级（每个实例唯一的数字，但在不同实例之间重复）。可以使用`hvd.local_rank`函数访问当前进程的本地等级。
- en: 'You can pin a specific GPU device for each process using local rank as follows.
    This example also shows how to set memory growth for your GPUs using `tf.config.experimental.set_memory_growth`:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用本地排名来为每个进程固定特定的GPU设备。此示例还展示了如何使用`tf.config.experimental.set_memory_growth`设置GPU的内存增长：
- en: '[PRE22]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'In the following code, we are splitting the data based on rank so that each
    process trains on a different set of examples:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的代码中，我们根据等级来拆分数据，以便每个进程在不同的示例集上训练：
- en: '[PRE23]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'For the model architecture, you can follow the instructions in the *Implementing
    and training a model in TensorFlow* section of [*Chapter 3*](B18522_03.xhtml#_idTextAnchor062),
    *Developing a Powerful Deep Learning Model*:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 对于模型架构，您可以按照[*第3章*](B18522_03.xhtml#_idTextAnchor062)中的*在TensorFlow中实现和训练模型*部分的说明进行操作：
- en: '[PRE24]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Next, you need to configure the optimizer. In the following example, the learning
    rate is scaled by the Horovod size. Also, the optimizer needs to be wrapped with
    a Horovod optimizer:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，您需要配置优化器。在以下示例中，学习率将按照Horovod大小进行缩放。此外，优化器需要用Horovod优化器包装：
- en: '[PRE25]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The next step is to compile your model and put the network architecture definition
    and optimizer together. When you are calling the `compile` function with a version
    of TF that’s older than v2.2, you need to disable `experimental_run_tf_function`
    so that TF uses `hvd.DistributedOptimizer` to compute gradients:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是编译您的模型，并将网络架构定义和优化器放在一起。当您使用早于v2.2的TF版本调用`compile`函数时，您需要禁用`experimental_run_tf_function`，以便TF使用`hvd.DistributedOptimizer`来计算梯度：
- en: '[PRE26]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Another component you need to configure is the callback function. You need
    to add `hvd.callbacks.BroadcastGlobalVariablesCallback(0)`. This will broadcast
    the initial values of the weights and biases from rank 0 to all other machines
    and processes. This is necessary to ensure consistent initialization or to correctly
    restore training from a checkpoint:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要配置的另一个组件是回调函数。您需要添加`hvd.callbacks.BroadcastGlobalVariablesCallback(0)`。这将从等级0向所有其他机器和进程广播权重和偏差的初始值。这是确保一致的初始化或正确从检查点恢复训练所必需的：
- en: '[PRE27]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'You can use `rank` to perform a particular operation on a specific instance.
    For example, logging and saving artifacts on a master node can be achieved by
    checking whether `rank` is 0 (`hvd.rank()==0`), as shown in the following code
    snippet:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`rank`可以在特定实例上执行特定操作。例如，通过检查`rank`是否为0 (`hvd.rank()==0`)，可以在主节点上记录和保存工件，如下面的代码片段所示：
- en: '[PRE28]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Now, you are ready to trigger the `fit` function. The following example shows
    how to scale the number of steps per epoch using the size of the Horovod cluster.
    Messages from the `fit` function will be only visible on the master node:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您可以触发`fit`函数。以下示例显示了如何使用Horovod集群的大小来缩放每个epoch的步数。`fit`函数的消息只会在主节点上可见：
- en: '[PRE29]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'This is [all you need to change to train a TF model in a distr](https://horovod.readthedocs.io/en/stable/tensorflow.html)ibuted
    fashion using Horovod. You c[an find the complete example at https://horovod.rea](https://horovod.readthedocs.io/en/stable/keras.html)dthedocs.io/en/stable/tensorflow.html.
    The Keras version can be found at https://horovod.rea[dthedocs.io/en/stable/keras.html.
    Additionally, you can modif](https://horovod.readthedocs.io/en/stable/elastic_include.html)y
    your training script so that it runs in a fault-tolerant way: https://horovod.readthedocs.io/en/stable/elastic_include.html.
    With this change, you should be able to use AWS Spot instances and significantly
    decrease the cost of training.'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 这是[您需要更改以在分布式](https://horovod.readthedocs.io/en/stable/tensorflow.html)Horovod中训练TF模型的所有内容。您可以在https://horovod.rea[找到完整示例](https://horovod.readthedocs.io/en/stable/keras.html).
    Keras版本可在https://horovod.rea[dthedocs.io/en/stable/keras.html找到。此外，您可以修改](https://horovod.readthedocs.io/en/stable/elastic_include.html)您的训练脚本，使其以容错方式运行：https://horovod.readthedocs.io/en/stable/elastic_include.html。通过此更改，您应该能够使用AWS
    Spot实例并显著降低培训成本。
- en: Configuring a PyTorch training script for Horovod
  id: totrans-229
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 配置用于Horovod的PyTorch训练脚本
- en: 'Unfortunately, PL does not have proper documentation for Horovod support yet.
    Therefore, we will focus on PyTorch in this section. Similar to what we described
    in the preceding section, we will demonstrate the code change you need to make
    for the PyTorch training script. For PyTorch, you need the `horovod.torch` module,
    which we will refer to as `hvd` again. In the following code snippet, we are importing
    the necessary modules and initializing the cluster:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，PL目前尚无适当的Horovod支持文档。因此，在本节中，我们将专注于PyTorch。与前一节中描述的类似，我们将演示您为PyTorch训练脚本进行的代码更改。对于PyTorch，您需要`horovod.torch`模块，我们将再次称之为`hvd`。在以下代码片段中，我们正在导入必要的模块并初始化集群：
- en: '[PRE30]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'As described in the TF example, you need to bind a GPU device for the current
    process using the local rank:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 如TF示例所述，您需要使用本地排名为当前进程绑定GPU设备：
- en: '[PRE31]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The other parts of the training script require similar modifications. The dataset
    needs to be distributed across the instances using `torch.utils.data.distributed.DistributedSampler`
    and the optimizers must be wrapped around `hvd.DistributedOptimizer`. The major
    difference comes from `hvd.broadcast_parameters(model.state_dict(), root_rank=0)`,
    which broadcasts the model weights. You can find the details in the following
    code snippet:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 训练脚本的其余部分需要进行类似的修改。数据集需要使用`torch.utils.data.distributed.DistributedSampler`在实例之间分发，并且优化器必须使用`hvd.DistributedOptimizer`进行包装。主要区别在于`hvd.broadcast_parameters(model.state_dict(),
    root_rank=0)`，用于广播模型权重。您可以在以下代码片段中找到详细信息：
- en: '[PRE32]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Now, you are ready to train the model. The training loop does not require any
    modifications. You can just pass the input tensor to the model and trigger backward
    propagation by triggering the `backward` function on the `loss` and `step` function
    of `optimizer`. The following code snippet describes the main part of the training
    logic:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您已经准备好训练模型了。训练循环不需要任何修改。您只需将输入张量传递给模型，并通过触发`loss`的`backward`函数和`optimizer`的`step`函数来触发反向传播。以下代码片段描述了训练逻辑的主要部分：
- en: '[PRE33]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '[The c](https://horovod.readthedocs.io/en/stable/pytorch.html)omplete description
    can be found on the official Horovod documentation page: https://horovod.readthedocs.io/en/stable/pytorch.html.'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 完整描述可以在官方Horovod文档页面找到：https://horovod.readthedocs.io/en/stable/pytorch.html。
- en: As the last piece of content for the *Training model using Horovod* section,
    the next section explains how to use the `horovodrun` and `mpirun` commands to
    initiate the model training process.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 作为*使用Horovod训练模型*部分的最后一个内容，接下来的部分将解释如何使用`horovodrun`和`mpirun`命令启动模型训练过程。
- en: Training a DL model on a Horovod cluster
  id: totrans-240
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在Horovod集群上训练DL模型
- en: 'Horovod uses MPI principles to coordinate work between processes. To run four
    processes on a single machine, you can use one of the following commands:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: Horovod使用MPI原则协调进程之间的工作。要在单台机器上运行四个进程，可以使用以下其中一个命令：
- en: '[PRE34]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: In both cases, the `-np` parameter defines the number of times the `train.py`
    script runs in parallel. The `-H` parameter can be used to define the number of
    processes per machine (see the `horovodrun` command in the preceding example).
    As we learn how to run on a single machine, `-H` can be dropped, as presented
    in the `mpirun` command. Other `mpirun` parameters are described at https://www.open-mpi.org/doc/v4.0/man1/mpirun.1.php#sect6.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 在两种情况下，`-np`参数定义了`train.py`脚本并行运行的次数。`-H`参数可用于定义每台机器上的进程数（请参见上述示例中的`horovodrun`命令）。随着我们学习如何在单台机器上运行，可以省略`-H`，如在`mpirun`命令中所示。其他`mpirun`参数在https://www.open-mpi.org/doc/v4.0/man1/mpirun.1.php#sect6中描述。
- en: 'If you do not have MPI installed, you can run the `horovodrun` command using
    Gloo. To run the same script to `localhost` four times (four processes) using
    Gloo, you just need to add the `--gloo` flag:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 如果未安装MPI，可以使用Gloo运行`horovodrun`命令。要在`localhost`上使用Gloo运行相同脚本四次（四个进程），只需添加`--gloo`标志：
- en: '[PRE35]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Scaling up to multiple instances is quite simple. The following command shows
    how to run the training script on four machines using `horovodrun`:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 扩展到多个实例非常简单。以下命令展示了如何使用`horovodrun`在四台机器上运行训练脚本：
- en: '[PRE36]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The following command shows how to run the training script on four machines
    using `mpirun`:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令展示了如何使用`mpirun`在四台机器上运行训练脚本：
- en: '[PRE37]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Once one of the preceding commands is triggered from the master node, you will
    see that each instance runs one process for training.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 当主节点触发上述任一命令后，您将看到每个实例运行一个训练进程。
- en: Things to remember
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 需要记住的事情
- en: a. To use Horovod, you need a cluster with open cross-communication among the
    nodes.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: a. 要使用Horovod，您需要一个具有节点间开放交叉通信的集群。
- en: b. Horovod provides a simple and effective way to achieve data parallelism for
    TF and PyTorch.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: b. Horovod提供了一种简单有效的方法，用于实现TF和PyTorch的数据并行。
- en: c. The training scripts can be executed on a Horovod cluster using the `horovodrun`
    or `mpirun` commands.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: c. 可以使用`horovodrun`或`mpirun`命令在Horovod集群上执行训练脚本。
- en: In the next section, we will describe Ray, another popular framework for [distributed
    train](https://www.ray.io/)ing.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将描述Ray，另一个流行的用于[分布式训练](https://www.ray.io/)的框架。
- en: Training a model using Ray
  id: totrans-256
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Ray训练模型
- en: 'Ray is an open source execution framework for scaling Python workloads across
    machines (https://www.ray.io). The following Python workloads are supported by
    Ray:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: Ray是一个开源的执行框架，用于跨多台机器扩展Python工作负载（https://www.ray.io）。Ray支持以下Python工作负载：
- en: DL model training implemented with PyTorch or TF
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用PyTorch或TF实现的DL模型训练
- en: Hyperparameter tuning via Ray Tune (https://docs.ray.io/en/latest/tune/index.html)
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过Ray Tune进行超参数调整（https://docs.ray.io/en/latest/tune/index.html）
- en: '**Reinforcement learning** (**RL**) via RLlib (https://docs.ray.io/en/latest/rllib/index.html),
    an open source library for RL'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**强化学习**（**RL**）通过RLlib实现（https://docs.ray.io/en/latest/rllib/index.html），这是一个开源的RL库'
- en: Data processing leveraging Ray Datasets ([https://docs.ray.io/en/latest/data/dataset.html](https://docs.ray.io/en/latest/data/dataset.html))
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用Ray数据集进行数据处理（[https://docs.ray.io/en/latest/data/dataset.html](https://docs.ray.io/en/latest/data/dataset.html)）
- en: Model serving via Ray Serve ([https://docs.ray.io/en/latest/serve/index.html](https://docs.ray.io/en/latest/serve/index.html))
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过Ray Serve进行模型服务（[https://docs.ray.io/en/latest/serve/index.html](https://docs.ray.io/en/latest/serve/index.html)）
- en: A general Python application leveraging Ray Core ([https://docs.ray.io/en/latest/ray-core/walkthrough.html](https://docs.ray.io/en/latest/ray-core/walkthrough.html))
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用Ray Core进行通用Python应用程序（[https://docs.ray.io/en/latest/ray-core/walkthrough.html](https://docs.ray.io/en/latest/ray-core/walkthrough.html)）
- en: The key advantage of Ray comes from the simplicity of its cluster definition;
    you can define a cluster with machines of different types and from various sources.
    For example, Ray allows you to build instance fleets (clusters based on a wide
    variety of EC2 instances with flexible and elastic resourcing strategies for each
    node) by mixing AWS EC2 on-demand instances and EC2 Spot instances with different
    CPU and GPU configurations. Ray simplifies both cluster creation and integration
    with DL frameworks, making it an effective tool for distributed DL model training
    processes.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: Ray的关键优势在于其集群定义的简单性；您可以定义具有不同类型和来源的机器的集群。例如，Ray允许您通过混合AWS EC2按需实例和具有不同CPU和GPU配置的EC2
    Spot实例来构建实例群集（基于每个节点的灵活和弹性资源策略），从而简化了集群的创建和与DL框架的集成，使其成为分布式DL模型训练过程的有效工具。
- en: First, we will learn how to set up a Ray cluster.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将学习如何设置Ray集群。
- en: Setting up a Ray cluster
  id: totrans-266
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置Ray集群
- en: 'You can set up a Ray cluster in two ways:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过两种方式设置 Ray 集群：
- en: '**Ray Cluster Launcher**: A tool provided by Ray to help build clusters using
    instances on cloud services, including AWS, GCP, and Azure'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Ray 集群启动器**：Ray 提供的工具，用于利用云服务（包括 AWS、GCP 和 Azure）的实例构建集群。'
- en: '**Manual cluster construction**: All the nodes need to be connected to the
    Ray cluster manually'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**手动集群构建**：所有节点都需要手动连接到 Ray 集群。'
- en: A Ray cluster consists of a head node (master node) and worker nodes. The instances
    that form the cluster should be configured to communicate with each other over
    the network. Communication among Ray instances is based on a **Transmission Control
    Protocol** (**TCP**) connection, and you must have the corresponding ports open.
    In the next two sections, we will take a closer look at Ray Cluster Launcher and
    manual cluster construction.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: Ray 集群包括一个头节点（主节点）和工作节点。形成集群的实例应配置为通过网络互相通信。Ray 实例之间的通信基于**传输控制协议**（**TCP**）连接，必须打开相应的端口。在接下来的两个部分中，我们将更详细地介绍
    Ray 集群启动器和手动集群构建。
- en: Setting up a Ray cluster using Ray Cluster Launcher
  id: totrans-271
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 Ray Cluster Launcher 设置 Ray 集群
- en: 'A YAML file is used [to configure the cluster when using Ray Cluster Launcher.
    You can](https://github.com/ray-project/ray/tree/master/python/ray/autoscaler)
    find many sample `YAML` files for different configurations on Ray’s GitHub repository:
    [https://github.com/ray-project/ray/tree/master/python/ray/autoscaler](https://github.com/ray-project/ray/tree/master/python/ray/autoscaler).'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Ray 集群启动器时，需要使用 YAML 文件来配置集群。您可以在 Ray 的 GitHub 仓库中找到多个用于不同配置的示例 `YAML` 文件：[https://github.com/ray-project/ray/tree/master/python/ray/autoscaler](https://github.com/ray-project/ray/tree/master/python/ray/autoscaler)。
- en: 'We will introduce the most basic one in this section. The `YAML` file starts
    with some basic information about the cluster, such as the name of the cluster,
    number of maximum workers, and upscaling speed, as follows:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将介绍最基本的配置。`YAML` 文件从集群的基本信息开始，例如集群名称、最大工作节点数和扩展速度，如下所示：
- en: '[PRE38]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Next, it configures the cloud service providers:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，它配置云服务提供商：
- en: '[PRE39]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'In the preceding example, we specify the provider type (`type: aws`) and select
    the Region and Availability Zone where instances will be provided (`region: us-east-1`
    and `availability_zone: us-east-1c, us-east-1b, us-east-1a`). Then, we define
    whether nodes can be reused in the future (`cache_stopped_nodes: True`). The last
    configurations are for user authentication (`ssh_user:ubuntu` and `ssh_private_key:/Users/BookDL/.ssh/BookDL.pem`).'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: '在上述示例中，我们指定了提供者类型（`type: aws`），并选择将提供实例的区域和可用区（`region: us-east-1` 和 `availability_zone:
    us-east-1c, us-east-1b, us-east-1a`）。然后，我们定义节点在未来是否可以重复使用（`cache_stopped_nodes:
    True`）。最后的配置是用户认证（`ssh_user:ubuntu` 和 `ssh_private_key:/Users/BookDL/.ssh/BookDL.pem`）。'
- en: 'Next, the node configuration needs to be specified. First of all, we will start
    with the head node:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来需要指定节点配置。首先，我们将从头节点开始：
- en: '[PRE40]'
  id: totrans-279
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Next, we must set up the security settings. The detailed settings must be consulted
    with DevOps, which monitors and secures the instances:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们必须设置安全设置。详细设置必须与 DevOps 协商，以监控和保护实例：
- en: '[PRE41]'
  id: totrans-281
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'The following configurations are for the instance type and AMI that should
    be used:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的配置适用于应使用的实例类型和 AMI：
- en: '[PRE42]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'In the following code snippet, we are providing configurations for storage:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下代码片段中，我们提供了存储配置：
- en: '[PRE43]'
  id: totrans-285
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'You can easily define `Tags` as follows:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以按如下方式轻松定义 `Tags`：
- en: '[PRE44]'
  id: totrans-287
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'If needed, you can provide an IAM instance profile for accessing particular
    S3 buckets:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 如果需要，可以为访问特定 S3 存储桶提供 IAM 实例配置文件：
- en: '[PRE45]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'In the next section of the `YAML` file, we need to provide a configuration
    for worker nodes:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `YAML` 文件的下一个部分，我们需要为工作节点提供配置：
- en: '[PRE46]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'First of all, we must specify the number of workers (`min_workers` and `max_workers`).
    Then, we can define the node configuration similar to how we defined the master
    node configuration:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们必须指定工作节点的数量（`min_workers` 和 `max_workers`）。然后，我们可以定义类似于我们定义主节点配置的节点配置：
- en: '[PRE47]'
  id: totrans-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'In addition, you can specify a list of shell commands to run on each node in
    the `YAML` file:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，您可以在 `YAML` 文件中指定要在每个节点上运行的一系列 shell 命令：
- en: '[PRE48]'
  id: totrans-295
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: In this example, we will add `tensorflow2_p38` for the `conda` environment to
    the path, activate the environment, and install a few other modules using `pip`.
    If you want to run some other commands just on the head or worker nodes, you can
    specify them in `head_setup_commands` and `worker_setup_commands`, respectively.
    They will be executed after the commands defined in `setup_commands` are executed.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们将在路径中添加`tensorflow2_p38`以供`conda`环境使用，激活环境，并使用`pip`安装一些其他模块。如果您想在头节点或工作节点上运行其他命令，可以分别在`head_setup_commands`和`worker_setup_commands`中指定它们。它们将在`setup_commands`中定义的命令执行后执行。
- en: 'Finally, the `YAML` file ends with commands for starting the Ray cluster:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，YAML文件以启动Ray集群的命令结束：
- en: '[PRE49]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: At first, setting up a Ray cluster with a `YAML` file may look complex. However,
    once you are used to it, you will notice that adjusting cluster settings for future
    projects becomes rather simple. In addition, it reduces the time needed to spin
    up correctly defined clusters significantly as you may reuse information about
    security groups, subnets, tags, and IAM profiles from previous projects.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 起初，使用YAML文件设置Ray集群可能看起来很复杂。但是，一旦您习惯了，您会发现为未来项目调整集群设置变得相当简单。此外，它显著减少了启动正确定义的集群所需的时间，因为您可以重用来自先前项目的安全组、子网、标签和IAM配置信息。
- en: 'If you need other details, we recommend you spend some time looking at the
    official documentation: https://docs.ray.io/en/latest/cluster/config.html#cluster-config.'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您需要其他详细信息，我们建议您花些时间查阅官方文档：https://docs.ray.io/en/latest/cluster/config.html#cluster-config。
- en: It is worth mentioning that Ray Cluster Launcher supports both autoscaling and
    using instance fleets with or without EC2 Spot instances. We used AMI in the preceding
    example, but you can also provide a specific Docker image for your instances.
    By exploiting the flexibility of the YAML configuration file, you can construct
    any cluster configurations using a single file.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 值得一提的是，Ray集群启动器支持自动缩放和使用实例群，无论是否使用EC2 Spot实例。我们在前面的示例中使用了AMI，但您也可以为您的实例提供特定的Docker镜像。通过灵活使用YAML配置文件，您可以使用单个文件构建任何集群配置。
- en: As we mentioned at the beginning of this section, you can also set up a Ray
    cluster by manually adding individual instances. We’ll look at this option next.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在本节开头提到的，您还可以通过手动添加单独实例来设置Ray集群。接下来我们将看看这个选项。
- en: Manually setting up a Ray cluster
  id: totrans-303
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 手动设置Ray集群
- en: 'Given that you have a set of machines with a network connection, the first
    step is to install Ray on each machine. Next, you need to change the security
    settings of each machine so that the machines can communicate with each other.
    After that, you need to select one node as a head node and run the following command:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于您拥有一组具有网络连接的机器，第一步是在每台机器上安装Ray。接下来，您需要更改每台机器的安全设置，以便它们可以相互通信。之后，您需要选择一个节点作为头节点，并在其上运行以下命令：
- en: '[PRE50]'
  id: totrans-305
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: The preceding command establishes the Ray cluster; the Redis server (used for
    the centralized control plane) is started, and its IP address gets printed on
    the terminal (for example, `123.45.67.89:6379`).
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 上述命令建立了Ray集群；Redis服务器（用于集中控制平面）已启动，并且其IP地址在终端上打印出来（例如`123.45.67.89:6379`）。
- en: 'Next, you need to run the following command on all the other nodes:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，您需要在所有其他节点上运行以下命令：
- en: '[PRE51]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: The address you need to provide is the one that is printed from the command
    on the head node.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要提供的地址是从头节点命令打印出的地址。
- en: 'Now, your machines are ready to support Ray applications. In the manual setting
    case, the following steps need to be done manually: starting machines, connecting
    to a head node terminal, copying training files to all nodes, and stopping machines.
    Let’s have a look at how Ray Cluster Launcher can be utilized to help with those
    tasks.'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您的机器已准备好支持Ray应用程序。在手动设置的情况下，需要手动执行以下步骤：启动机器，连接到头节点终端，将训练文件复制到所有节点，并停止机器。让我们看看如何利用Ray集群启动器来帮助完成这些任务。
- en: 'At this stage, you should be able to specify the desired Ray cluster settings
    using a YAML file. Whenever you are ready, you can launch your first Ray cluster
    using the following command:'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，您应该能够使用YAML文件指定所需的Ray集群设置。一旦准备好，您可以使用以下命令启动您的第一个Ray集群：
- en: '[PRE52]'
  id: totrans-312
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'To get a remote terminal on the head node, you can run the following command:'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 要在头节点上获取远程终端，您可以运行以下命令：
- en: '[PRE53]'
  id: totrans-314
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'To terminate the cluster, the following command can be used:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 要终止集群，可以使用以下命令：
- en: '[PRE54]'
  id: totrans-316
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: Now, it’s time to learn how to perform DL model training on a Ray cluster.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，是时候学习如何在 Ray 集群上执行 DL 模型训练了。
- en: Training a model in a distributed fashion using Ray
  id: totrans-318
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Ray 进行分布式模型训练
- en: Ray provides the Ray Train library, which allows you to focus on defining training
    logic by handling the distributed training behind the scenes. Ray Train supports
    TF and PyTorch. It also provides simple integration with Horovod. In addition,
    Ray Datasets exists, which provides distributed data loading through distributed
    data transformations. Finally, Ray provides hyperparameter tuning through the
    Ray Tune library.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: Ray 提供 Ray Train 库，通过处理幕后的分布式训练来帮助您专注于定义训练逻辑。Ray Train 支持 TF 和 PyTorch。此外，Ray
    Datasets 存在，通过分布式数据转换提供分布式数据加载。最后，Ray 通过 Ray Tune 库提供超参数调整功能。
- en: Adjusting TF training logic for Ray is similar to what we described in the *Data
    parallelism in TensorFlow* section. The main difference comes from the Ray Train
    library, which helps us set `TF_CONFIG`.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 调整 TF 训练逻辑以适应 Ray 类似于我们在 *TensorFlow 中的数据并行ism* 部分中描述的方式。主要区别来自 Ray Train 库，它帮助我们设置
    `TF_CONFIG`。
- en: 'The adjusted training logic looks as follows:'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 调整后的训练逻辑如下所示：
- en: '[PRE55]'
  id: totrans-322
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Then, you can run the training with Ray Trainer, as follows:'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，您可以使用 Ray Trainer 运行训练，如下所示：
- en: '[PRE56]'
  id: totrans-324
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'In the preceding example, the model definition is similar to a single device
    case, except that it should be compiled with a specific strategy: `MultiWorkerMirroredStrategy`.
    The dataset gets split inside the `dataset` function, providing a different set
    of samples for each worker node. Finally, the `Trainer` [instance handles the
    distributed training.](https://docs.ray.io/en/latest/train/examples.html)'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的例子中，模型定义与单设备案例类似，唯一的区别在于应使用特定策略进行编译：`MultiWorkerMirroredStrategy`。数据集在 `dataset`
    函数内部分割，为每个工作节点提供不同的样本集。最后，`Trainer` [实例处理分布式训练。](https://docs.ray.io/en/latest/train/examples.html)
- en: '[Trai](https://docs.ray.io/en/latest/train/examples.html)ning PyTorch models
    using Ray can be achieved with a minimal set of changes as well. A few examples
    are presented at [https://docs.ray.io/en/latest/train/examples.html#pytorch](https://docs.ray.io/en/latest/train/examples.html#pytorch).'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: '[使用 Ray 训练 PyTorch 模型](https://docs.ray.io/en/latest/train/examples.html) 可以通过少量变更来实现。一些示例在
    [https://docs.ray.io/en/latest/train/examples.html#pytorch](https://docs.ray.io/en/latest/train/examples.html#pytorch)
    上呈现。'
- en: In addition, you can use Ray with Horovod, where you can leverage Elastic Horovod
    to train in a fault-tolerant way. Ray [will autoscale the training process by
    simplifying the discovery and orc](https://docs.ray.io/en/latest/train/examples/horovod/horovod_example.html)hestration
    of hosts. We will not cover the details, but a good starting point can be found
    at [https://docs.ray.io/en/latest/train/examples/horovod/horovod_example.html](https://docs.ray.io/en/latest/train/examples/horovod/horovod_example.html).
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，您还可以将 Ray 与 Horovod 结合使用，利用 Elastic Horovod 以容错的方式进行训练。Ray [将通过简化主机的发现和 orc](https://docs.ray.io/en/latest/train/examples/horovod/horovod_example.html)
    串来自动缩放训练过程。我们不会详细介绍，但您可以在 [https://docs.ray.io/en/latest/train/examples/horovod/horovod_example.html](https://docs.ray.io/en/latest/train/examples/horovod/horovod_example.html)
    找到一个很好的起点。
- en: Things to remember
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 需要记住的事情
- en: a. The key advantage of Ray comes from its simplicity of cluster definition.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: a. Ray 的主要优势在于其集群定义的简易性。
- en: b. A Ray cluster can be created manually by connecting each machine or using
    a built-in tool called Ray Cluster Launcher.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: b. Ray 集群可以通过手动连接每台机器或使用名为 Ray Cluster Launcher 的内置工具来创建。
- en: c. Ray provides a nice support for autoscaling the training process. It simplifies
    the discovery and orchestration of hosts.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: c. Ray 提供了良好的支持来自动缩放训练过程。它简化了主机的发现和编排。
- en: Finally, let’s learn how to use Kubeflow for distributed training.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们学习如何使用 Kubeflow 进行分布式训练。
- en: Training a model using Kubeflow
  id: totrans-333
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Kubeflow 训练模型
- en: Kubeflow ([https://www.kubeflow.org](https://www.kubeflow.org)) covers every
    step of model development, including data exploration, preprocessing, feature
    extraction, model training, model serving, inferencing, and versioning. Kubeflow
    allows you to easily scale from a local development environment to production
    clusters by leveraging containers and Kubernetes, a management system for containerized
    applications.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: Kubeflow ([https://www.kubeflow.org](https://www.kubeflow.org)) 涵盖了模型开发的每个步骤，包括数据探索、预处理、特征提取、模型训练、模型服务、推断和版本控制。通过利用容器和
    Kubernetes，Kubeflow 允许您轻松从本地开发环境扩展到生产集群。
- en: Kubeflow might be your first choice for distributed training if your organization
    is already [using the Kubernetes](https://kubernetes.io) ecosystem.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的组织已经在[使用Kubernetes](https://kubernetes.io)生态系统，那么Kubeflow可能是您进行分布式训练的首选。
- en: Introducing Kubernetes
  id: totrans-336
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍Kubernetes
- en: 'Kubernetes is an open source orchestration platform that’s used to manage containerized
    workloads and services ([https://kubernetes.io](https://kubernetes.io)):'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes是一个开源的编排平台，用于管理容器化工作负载和服务（[https://kubernetes.io](https://kubernetes.io)）：
- en: Kubernetes helps with continuous delivery, integration, and deployment.
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes有助于持续交付、集成和部署。
- en: It separates development environments from deployment environments. You can
    construct a container image and develop the application in parallel.
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它将开发环境与部署环境分离。您可以构建一个容器镜像并同时开发应用程序。
- en: The container-based approach ensures the consistency of the environment for
    development, testing, as well as production. The environment will be consistent
    on a desktop computer or in the cloud, which minimizes the modifications necessary
    from one step to the other.
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于容器的方法确保了开发、测试和生产环境的一致性。环境将在桌面计算机或云中保持一致，从而最大限度地减少从一步到另一步所需的修改。
- en: 'We assume that you have Kubeflow and all of its dependencies installed already,
    along with a running Kubernetes cluster. The steps we will describe in this section
    are generic enough that they can be used for any cluster settings – **Minikube**
    (a local version of Kubernetes), AWS **Elastic Kubernetes Service** (**EKS**),
    or a cluster of many nodes. This is the beauty of containerized workloads and
    services. The local Minikube installation steps can be found online at [https://minikube.sigs.k8s.io/docs/start/](https://minikube.sigs.k8s.io/docs/start/). For
    EKS, we direct you to the AWS user guide: [https://docs.aws.amazon.com/eks/latest/userguide/getting-started.html](https://docs.aws.amazon.com/eks/latest/userguide/getting-started.html).'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 我们假设您已经安装了Kubeflow及其所有依赖项，并且运行着一个Kubernetes集群。本节中我们将描述的步骤是通用的，适用于任何集群设置 - **Minikube**（一个本地版本的Kubernetes）、AWS
    **弹性Kubernetes服务**（**EKS**），或者一个多节点的集群。这正是容器化工作负载和服务的美妙之处。您可以在以下网址找到本地Minikube安装步骤：[https://minikube.sigs.k8s.io/docs/start/](https://minikube.sigs.k8s.io/docs/start/)。对于EKS，我们建议您查阅AWS用户指南：[https://docs.aws.amazon.com/eks/latest/userguide/getting-started.html](https://docs.aws.amazon.com/eks/latest/userguide/getting-started.html)。
- en: Setting up model training for Kubeflow
  id: totrans-342
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为Kubeflow设置模型训练
- en: The first step is to package your [training code into a container. This can
    be achieved with a Docker file. Depending](https://docs.nvidia.com/deeplearning/frameworks/tensorflow-release-notes/running.html)
    on your startin[g point, you can use containers from the NVIDIA container image
    space (TF at htt](https://docs.nvidia.com/deeplearning/frameworks/pytorch-release-notes/index.html)ps://docs.nvidia.com/deeplearning/frameworks/tensor[flow-release-notes/running.html
    or PyTorch at](https://hub.docker.com/r/tensorflow/tensorflow/) https://docs.nv[idia.com/deeplearning/frameworks/pytorch](https://hub.docker.com/r/pytorch/pytorch)-release-notes/index.html)
    or containers directly from DL frameworks (TF at https://hub.docker.com/r/tensorflow/tensorflow
    or PyTorch at https://hub.docker.com/r/pytorch/pytorch).
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是将您的[训练代码打包成一个容器。这可以通过一个Docker文件实现。取决于您的起始点，您可以使用来自NVIDIA容器镜像空间的容器（TF位于htt](https://docs.nvidia.com/deeplearning/frameworks/pytorch-release-notes/index.html)ps://docs.nvidia.com/deeplearning/frameworks/tensor[flow-release-notes/running.html或PyTorch在](https://hub.docker.com/r/pytorch/pytorch/)
    https://docs.nv[idia.com/deeplearning/frameworks/pytorch](https://hub.docker.com/r/tensorflow/tensorflow)-release-notes/index.html)或直接从DL框架获取容器（TF位于https://hub.docker.com/r/tensorflow/tensorflow或PyTorch位于https://hub.docker.com/r/pytorch/pytorch）。
- en: 'Let’s have a look at an example TF docker file (`kubeflow/tf_example_job`):'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一个TF Docker文件的示例（`kubeflow/tf_example_job`）：
- en: '[PRE57]'
  id: totrans-345
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: In the preceding Docker definition, the `train.py` script is a typical TF training
    script.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 在前述的Docker定义中，`train.py`脚本是一个典型的TF训练脚本。
- en: 'For now, we assume that a single machine will be used for training. In other
    words, it will be a single container job. Given that you have a Docker file and
    a training script prepared, you can build your container and push it to the repository
    using the following commands:'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们假设单机将用于训练。换句话说，它将是一个单容器作业。假设您已经准备好一个Docker文件和一个训练脚本，您可以使用以下命令构建您的容器并将其推送到仓库：
- en: '[PRE58]'
  id: totrans-348
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'We will use `TFJob`, a custom component of Kubeflow that contains a `TFJob`
    is represented as a YAML file that describes the container image, the script for
    training, and execution parameters. Let’s have a look at a YAML file, `tf_example_job.yaml`,
    which contains a Kubeflow model training job running on a single machine:'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用`TFJob`，这是Kubeflow的一个自定义组件，其中包含一个将`TFJob`表示为描述容器镜像、训练脚本和执行参数的YAML文件。让我们看看一个YAML文件，`tf_example_job.yaml`，其中包含在单台机器上运行的Kubeflow模型训练作业：
- en: '[PRE59]'
  id: totrans-350
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'The API version is defined in the first line. Then, the type of your custom
    resource is listed, `kind: "TFJob"`. The `metadata` field is used to identify
    your job by giving it a custom name. The cluster is defined in the `tfReplicaSpecs`
    field. As shown in the preceding example, the script (`tf_example_job:1.0)` will
    be executed just once (`replicas: 1`).'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 'API版本在第一行中定义。然后列出了您自定义资源的类型，`kind: "TFJob"`。`metadata`字段用于通过提供自定义名称来识别您的作业。集群在`tfReplicaSpecs`字段中定义。如前面的示例所示，脚本（`tf_example_job:1.0`）将执行一次（`replicas:
    1`）。'
- en: 'To deploy the defined `TFJob` to your cluster, you can use the `kubectl` command,
    as follows:'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 要将定义的`TFJob`部署到您的集群中，您可以使用`kubectl`命令，如下所示：
- en: '[PRE60]'
  id: totrans-353
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'You can monitor your job with the following command (using the name defined
    in the metadata):'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用以下命令监视您的作业（使用元数据中定义的名称）：
- en: '[PRE61]'
  id: totrans-355
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: To perform distributed training, you can use TF code with a specific `tf.distribute.Strategy`,
    create a new container, and modify `TFJob`. We will have a look at the necessary
    changes for `TFJob` in the next session.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 要执行分布式训练，您可以使用带有特定`tf.distribute.Strategy`的TF代码，创建一个新的容器，并修改`TFJob`。我们将在下一节中查看`TFJob`所需的更改。
- en: Training a TensorFlow model in a distributed fashion using Kubeflow
  id: totrans-357
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Kubeflow在分布式环境中训练TensorFlow模型
- en: 'Let’s assume that we already have the TF training code from `MultiWorkerMirroredStrategy`.
    For `TFJob` to support this strategy, you need to adjust `tfReplicaSpecs` in the
    `spec` field. We can define replicas of the following types through the YAML file:'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们已经有了来自`MultiWorkerMirroredStrategy`的TF训练代码。为了支持此策略，需要在`spec`字段中调整`tfReplicaSpecs`。我们可以通过YAML文件定义以下类型的副本：
- en: '**Chief (master)**: Orchestrates computational tasks'
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**主节点（主机）**：编排计算任务'
- en: '**Worker**: Runs computations'
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**工作节点**：运行计算任务'
- en: '**Parameter server**: Manages storage for model parameters'
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**参数服务器**：管理模型参数的存储'
- en: '**Evaluator**: Runs evaluations during model training'
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**评估节点**：在模型训练期间运行评估'
- en: As the simplest example, we will define a worker as one of those that can act
    as a chief node. Parameter `server` and `evaluator` are not obligatory.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 作为最简单的例子，我们将定义一个作为主节点之一的工作节点。参数`server`和`evaluator`不是必须的。
- en: 'Let''s look at the adjusted YAML file, `tf_example_job_dist.yaml`, for the
    distributed TF training:'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看调整后的YAML文件，`tf_example_job_dist.yaml`，用于分布式TF训练：
- en: '[PRE62]'
  id: totrans-365
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'The preceding `YAML` file will run the training job based on `MultiWorkerMirroredStrategy`
    on a new container, `kubeflow/tf_example_job:1.1`. We can deploy `TFJob` to the
    cluster with the same command:'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 前述的YAML文件将基于`MultiWorkerMirroredStrategy`在新的容器`kubeflow/tf_example_job:1.1`上运行训练作业。我们可以使用相同的命令将`TFJob`部署到集群：
- en: '[PRE63]'
  id: totrans-367
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: In the next section, we will learn how to use PyTorch with Ray.
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将学习如何使用PyTorch和Ray。
- en: Training a PyTorch model in a distributed fashion using Kubeflow
  id: totrans-369
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Kubeflow在分布式环境中训练PyTorch模型
- en: 'For PyTorch, we just need to change `TFJob` to `PyTorchJob` and provide a PyTorch
    training script. For the training script itself, please refer to the *Data parallelism
    in PyTorch* section. The YAML file requires the same set of modifications, as
    shown in the following code snippet:'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 对于PyTorch，我们只需将`TFJob`更改为`PyTorchJob`，并提供一个PyTorch训练脚本。至于训练脚本本身，请参阅*PyTorch中的数据并行ism*部分。如下面的代码片段所示，YAML文件需要相同的修改：
- en: '[PRE64]'
  id: totrans-371
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: In this example, we have one master node and five replicas of worker nodes.
    The complete details can be found at [https://www.kubeflow.org/docs/components/training/pytorch](https://www.kubeflow.org/docs/components/training/pytorch).
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 在此示例中，我们有一个主节点和五个工作节点的副本。完整详情请查看[https://www.kubeflow.org/docs/components/training/pytorch](https://www.kubeflow.org/docs/components/training/pytorch)。
- en: Things to remember
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 需要记住的事项
- en: a. Kubeflow allows you to easily scale from a local development environment
    to large clusters leveraging containers and Kubernetes.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: a. Kubeflow允许您轻松地从本地开发环境扩展到利用容器和Kubernetes的大型集群。
- en: b. `TFJob` and `PyTorchJob` allow you to run TF and PyTorch training jobs in
    a distributed fashion using Kubeflow, respectively.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: b. `TFJob`和`PyTorchJob`分别允许您以分布式方式在Kubeflow中运行TF和PyTorch训练作业。
- en: In this section, we described how to utilize Kubeflow for training TF and PyTorch
    models in a distributed fashion.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们描述了如何利用Kubeflow以分布式方式训练TF和PyTorch模型。
- en: Summary
  id: totrans-377
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'By realizing the benefit of parallelism that comes from multiple devices and
    machines, we have learned about various ways to train a DL model. First, we learned
    how to use multiple CPU and GPU devices on a single machine. Then, we covered
    how to utilize the built-in features of TF and PyTorch to achieve the training
    in a distributed fashion, where the underlying cluster is managed explicitly.
    After that, we learned how to use SageMaker for distributed training and scaling
    up. Finally, the last three sections described frameworks that are designed for
    distributed training: Horovod, Ray, and Kubeflow.'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 通过意识到多设备和多机器并行带来的好处，我们学习了多种训练深度学习模型的方法。首先，我们学习了如何在单台机器上利用多个CPU和GPU设备。然后，我们介绍了如何利用TF和PyTorch的内置功能以分布式方式进行训练，其中底层集群由显式管理。之后，我们学习了如何使用SageMaker进行分布式训练和扩展。最后，最后三节描述了专为分布式训练设计的框架：Horovod、Ray和Kubeflow。
- en: In the next chapter, we will cover model understanding. We will learn about
    popular techniques for model understanding that provide some insights into what
    is happening within the model throughout the training process.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将介绍模型理解。我们将学习关于模型理解的流行技术，这些技术在训练过程中提供一些关于模型内部运行情况的见解。
