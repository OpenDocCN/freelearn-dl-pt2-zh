- en: Deep Learning Fundamentals
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Deep learning is generally considered a subset of machine learning, involving
    the training of **artificial neural networks** (**ANNs**). ANNs are at the forefront
    of machine learning. They have the ability to solve complex problems involving
    massive amounts of data. Many of the principles of machine learning generally
    are also important in deep learning specifically, so we will spend some time reviewing
    these here.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will discuss the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Approaches to machine learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learning tasks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Features
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Artificial neural networks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Approaches to machine learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Prior to general machine learning, if we wanted to, for example, build a spam
    filter, we could start by compiling a list of words that commonly appear in spam.
    The spam detector then scans each email and when the number of blacklisted words
    reaches a threshold, the email would be classified as spam. This is called a rules-based
    approach, and is illustrated in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/fb64e897-aa70-4633-bed0-090d24381b10.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The problem with this approach is that once the writers of spam know the rules,
    they are able to craft emails that avoid this filter. The people with the unenviable
    task of maintaining this spam filter would have to continually update the list
    of rules. With machine learning, we can effectively automate this rule-updating
    process. Instead of writing a list of rules, we build and train a model. As a
    spam detector, it will be more accurate since it can analyze large volumes of
    data. It is able to detect patterns in data that would be impossible for a human
    to do in a meaningful timeframe. The following diagram illustrates this approach:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/742c2b29-9dc9-4346-bd61-2dec414eabb2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'There are a large number of ways that we can approach machine learning and
    these approaches are broadly characterized by the following factors:'
  prefs: []
  type: TYPE_NORMAL
- en: Whether or not models are trained with labelled training data. There are several
    possibilities here, including entirely supervised, semi-supervised, based on reinforcement,
    or entirely unsupervised.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Whether they are **online** (that is, learning on the fly as new data is presented),
    or learn using pre-existing data. This is referred to as batch learning.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Whether they are instance-based, simply comparing new data to known data, or
    model-based, involving the detection of patterns and building a predictive model.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These approaches are not mutually exclusive and most algorithms are a combination
    of the approaches. For example, a typical way to build a spam detector is using
    an online, model-based supervised learning algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: Learning tasks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are several distinct types of learning tasks that are partially defined
    by the type of data that they work on. Based on this, we can divide learning tasks
    into two broad categories:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Unsupervised learning**: Data is unlabeled so the algorithm must infer a
    relationship between variables or by finding clusters of similar variables'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Supervised learning**: Uses a labeled dataset to build an inferred function
    that can be used to predict the label of an unlabeled sample'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Whether the data is labeled or not has a predetermining effect on the way a
    learning algorithm is built.
  prefs: []
  type: TYPE_NORMAL
- en: Unsupervised learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the main drawbacks to supervised learning is that it requires data that
    is accurately labeled. Most real-world data consists of unlabeled and unstructured
    data and this is the major challenge to machine learning and the broader endeavor of
    artificial intelligence. Unsupervised learning plays an important role in finding
    structure in unstructured data. The division between supervised and unsupervised learning
    is not absolute. Many unsupervised algorithms are used to together with supervised
    learning; for example, where data is only partially labeled or when we are trying
    to find the most important features of a deep learning model.
  prefs: []
  type: TYPE_NORMAL
- en: Clustering
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This is the most straightforward unsupervised method. In many cases, it does
    not matter that the data is unlabeled; what we are interested in is the fact that
    the data clusters around certain points. Recommender systems that, say, recommend
    movies or books from an online store often use clustering techniques. An approach
    here is for an algorithm to analyze a customer's purchase history, comparing it
    to other customers, and making recommendations based on similarities. The algorithm *clusters* customers'
    usage patterns into groups. At no time does the algorithm know what the groups
    are; it is able to work this out for itself. One of the most used clustering algorithms
    is **k-means**. This algorithm works by establishing cluster centers based on
    the mean of the observed samples.
  prefs: []
  type: TYPE_NORMAL
- en: Principle component analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Another unsupervised method, often used in conjunction with supervised learning,
    is **principle component analysis** (**PCA**). This is used when we have a large
    amount of features that may be correlated and we are unsure of the impact each
    feature has in determining a result. For example, in weather prediction, we could
    use each meteorological observation as a feature and feed them directly to a model.
    This means the model would have to analyze a large amount of data, much of it
    irrelevant. Further, the data may be correlated so that we need to consider not
    just individual features but how these features interact with each other. What
    we need is a tool that will reduce this large amount of possibly correlated and
    redundant features into a small number of principle components. PCA belongs to
    a type of algorithm called **dimensionality reduction** because this reduces the
    number of dimensions in the input dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Reinforcement learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Reinforcement learning is somewhat different to other methods and is often classified
    as an unsupervised method because the data it uses is not labeled in the supervised
    sense. Reinforcement learning probably comes closer to the way humans interact
    and learn from the world than other methods. In reinforcement learning, the learning
    system is called an **agent** and this agent interacts with an **environment** by
    observation and by performing **actions. **Each action results in either a **reward** or
    a **penalty**. The agent must develop a strategy or **policy** to maximize reward
    and minimize penalties over time. Reinforcement learning has applications in many
    domains, such as game theory and robotics where the algorithm must learn its environment
    without direct human prompting.
  prefs: []
  type: TYPE_NORMAL
- en: Supervised learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In supervised learning, a machine learning model is trained on a labeled dataset.
    Most successful deep learning models so far have been focused on supervised learning
    tasks. With supervised learning, each data instance (say, an image or an email),
    comes with two elements: a set of features, usually denoted as an uppercase *X*,
    and a label, denoted with a lower case, *y*. Sometimes, the label is called the
    target or answer.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Supervised learning is usually conducted in two stages: a training phase when
    the model learns the characteristics of the data, and a testing phase, where predictions
    are made on unlabeled data. It is important that the model is trained and tested
    on separate datasets, since the goal is to generalize to new data and not precisely
    learn the characteristics of a single dataset. This can lead to the common problems
    of over **overfitting** the training set, and consequently underfitting a test
    set of data.'
  prefs: []
  type: TYPE_NORMAL
- en: Classification
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Classification is probably the most common supervised machine learning task.
    There are several types of classification problems based the number of input and
    output labels. The task of a classification model is to find a pattern in the
    input features and associate this pattern with a label. A model should learn the
    distinguishing features of the data and then be able to predict the label of an
    unlabeled sample. The model essentially builds an inferred function from the training
    data. We will look at how this function is built shortly. We can distinguish three
    types of classification models:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Binary classification**: As in our toy—no toy example, this involves distinguishing between
    two labels.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Multi-label classification**: Involves distinguishing between more than two
    classes. For example, if the toy example was extended to distinguish between the
    types of toy in the image (car, truck, plane, and so on). A common way to solve
    multi-label classification problems is to divide the problem into multiple binary
    problems.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Multiple output classification**: Each sample may have more than one output
    label. For example, perhaps the task is to analyze images of scenes and determine
    what type of toys are in them. Each image can have multiple types of toys and
    therefore has multiple labels.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaluating classifiers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You may think that the best way to measure the performance of a classifier
    is to count the proportion of successful predictions compared with the total predictions
    made. However, consider a classification task on a dataset of handwritten digits,
    where the target is all the digits that are *not* 7\. Just guessing that every
    sample is not 7 will give a success rate, assuming the data is evenly distributed,
    of 90%. When evaluating classifiers, we must consider four variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '**TP true positive**: The predictions that correctly identify a target'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**TN true negative**: The predictions that correctly identify a non-target'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**FP false positive**: Predictions that incorrectly identify a target'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**FN false negative**: Predictions that incorrectly identify a non-target'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Two metrics, *precision* and *recall*, are commonly used together to measure
    the performance of a classifier. *Precision* is defined by the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1e226135-1258-4d90-9aea-31b85dba8926.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Recall* is defined by the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/24bcaee3-cd40-422c-b114-089bff352a26.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We can combine these ideas in what is known as a confusion matrix. It is called
    confusion matrix, not because it is confusing to understand, but because it tabulates
    instances where the classifier confuses targets. The following diagram should
    make this clearer:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e501a920-e58f-461c-b7df-f41a983284ac.png)'
  prefs: []
  type: TYPE_IMG
- en: Which measure we use, or give more weight in determining the success or not
    of a classifier, really depends on the application. There is a trade-off between
    precision and recall. Improving precision will often result in a reduction in
    recall. For example, increasing the number of true positives will often mean that
    the false positive rate is increased. The right balance of precision and recall
    depends on the requirements of the application. For example, in a medical test
    for cancer, we probably need higher precision, since a false negative means an
    instance of cancer remains undiagnosed, with potentially fatal consequences.
  prefs: []
  type: TYPE_NORMAL
- en: Features
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'It is important to remember that an image detection model does not see an image
    but a set of pixel color values, or, in the case of a spam filter, a collection
    of characters in an email. These are raw features of the model. An important part
    of machine learning is feature transformation. A feature transformation we have
    already discussed is dimensionality reduction in regard to principle component
    analysis. The following is a list common feature transformations:'
  prefs: []
  type: TYPE_NORMAL
- en: Dimensionality reduction to reduce the number of features using techniques such
    as PCA
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scaling or normalizing features to be within a particular numerical range
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Transforming the feature data type (for example, assigning categories to numbers)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adding random or generated data to augment features
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each feature is encoded on to a dimension of our input tensor, *X*, so in order
    to make a learning model as efficient as possible, the number of features needs
    to be minimised. This is where principle component analysis and other dimensionality reduction techniques
    come in to play.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another important feature transformation is scaling. Most machine learning
    models do not perform well when features are of different scales. There are two
    common techniques used for feature scaling:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Normalization or min-max scaling**: Values are shifted and re-scaled to be
    between zero and one. This is the most used scaling method for neural networks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Standardization**: Subtracts the mean and divides by the variance. This does
    not bound variables to a particular range, but the resultant distribution has
    unit variance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Handling text and categories
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'What do we do when a feature is a set of categories rather than a number? Suppose
    we are building a model to predict house prices. A feature of this model could
    be the cladding material of the house, with possible values such as timber, iron,
    and cement. How can we encode this feature to be of use to a deep learning model?
    The obvious solution is to simply assign a real number to each category: say,
    1 for timber, 2 for iron, and 3 for cement. The problem with this representation
    is that it infers that the category values are ordered. That is, timber and iron
    are somehow closer than timber and cement.'
  prefs: []
  type: TYPE_NORMAL
- en: 'A solution that avoids this is **one-hot encoding**. The feature values are
    encoded as binary vectors, as shown in the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Timber** | 1 | 0 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| **Iron** | 0 | 1 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| **Cement** | 0 | 0 | 1 |'
  prefs: []
  type: TYPE_TB
- en: This solution works well when the number of category values is small. If, for
    example, the data is a corpus of text, and our task is natural language processing,
    using one-hot encoding is not practical. The number of category values, and therefore
    the length of the feature vector, is the number of words in the vocabulary. In
    this case, the feature vector becomes large and unmanageable.
  prefs: []
  type: TYPE_NORMAL
- en: 'One-hot encoding uses what is called a sparse representation. Most of the values
    are 0\. As well as not scaling very well, one-hot encoding has another serious
    drawback for natural language processing. It does not encode a word''s meaning,
    or its relationship to other words. An approach we can use is called dense word
    embedding. Each word in a vocabulary is represented by a real numbered vector,
    representing a score for a particular attribute. The general idea is that this
    vector encodes semantic information relevant to the task at hand. For example,
    if the task is to analyze movie reviews and determine the genre of the movie based
    on a review, we could create word embedding, as shown in the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Word** | **Drama** | **Comedy** | **Documentary** |'
  prefs: []
  type: TYPE_TB
- en: '| Funny | -4 | 4.5 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| Action | 3.5 | 2.5 | 2 |'
  prefs: []
  type: TYPE_TB
- en: '| Suspense | 4.5 | 1.5 | 3 |'
  prefs: []
  type: TYPE_TB
- en: Here, the leftmost column lists words that may be present in a movie review.
    Each word is given a score relative to how often it appears in a review of the
    respective genre. We could build such a table from a supervised learning task
    that analyzes movie reviews in conjunction with their labeled genre. This trained
    model could then be applied to non-labeled reviews to determine the most likely
    genre.
  prefs: []
  type: TYPE_NORMAL
- en: Models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Choosing a model representation is an important task in machine learning. So
    far, we have been referring to models as black boxes. Some data is put in, and,
    based on training, the model makes a prediction. Before we look inside this black
    box, let's review some of the linear algebra that we will need to understand deep
    learning models.
  prefs: []
  type: TYPE_NORMAL
- en: Linear algebra review
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Linear algebra is concerned with the representation of linear equations through
    the use of matrices. In the algebra taught in high school, we were concerned with
    scalar, that is, single number, values. We have equations, and rules for manipulating
    these equations, so that they can be evaluated. The same is true when, instead
    of scalar values, we use matrices. Let's review some of the concepts involved.
  prefs: []
  type: TYPE_NORMAL
- en: 'A matrix is simply a rectangular array of numbers. We saw that we added two
    matrices simply by adding each corresponding element. A matrix can be multiplied
    by a scalar by simply multiplying every element in the array by the scalar, as
    shown in the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c6fc4406-537b-47ea-b2a9-d794189a35a8.png)'
  prefs: []
  type: TYPE_IMG
- en: This is an example of matrix addition and, as you would expect, you can perform
    matrix subtraction in the same way, except of course, rather than add corresponding
    elements, you subtract them. Note that we can only add or subtract matrices of
    the same size.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another common matrix operation is multiplication by a scalar:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/07f16399-180b-42b3-9407-bab4e2276361.png)'
  prefs: []
  type: TYPE_IMG
- en: Notice the indexing style we use: *X*[*ij*], where *i* refers to the row and
    *j* refers to the column. There are two conventions when it comes to indexing.
    Here, I am using zero indexing; that is, indexing starts at zero. This is to keep
    it consistent with the way we index tensors in PyTorch. Be aware that in some
    mathematical texts, and depending on what programming language you use, indexing
    may start at 1\. Also, we refer to the size, or the dimension of a matrix, as
    *m* by *n, *where *m* is the number of rows and *n* is the number of columns.
    For example, *A* and *B* are both 3 x 2 matrices.
  prefs: []
  type: TYPE_NORMAL
- en: 'There is a special case of a matrix called a vector. This is simply a *n* by
    1 matrix, so it has one column and any number of rows, as shown in the following
    example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b994a6ca-e95c-48f8-940c-60f2fd32b490.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s now look at how to multiply a vector with a matrix. In the following
    example, we multiply a 3 x 2 matrix with a vector of size 2:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d221cdb5-43b0-4208-a954-0fa03513a687.png)'
  prefs: []
  type: TYPE_IMG
- en: 'A concrete example may make this clearer:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/838642ca-7a21-4e66-a288-caf75ed27121.png)'
  prefs: []
  type: TYPE_IMG
- en: Note that here, the 3 x 2 matrix results in a 3 vector and, in general, an *m*
    row matrix multiplied by a vector will result in an *m-*sized vector.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also multiply matrices with other matrices by combining matrix vector
    multiplication, as shown in the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7320f5e4-cd95-4a40-bb1e-113494f9740f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/feea3afa-8e16-4b66-ae43-43fd16c99832.png)![](img/e0143737-6993-49d0-b83d-9cc5c3da7902.png)![](img/18b7f873-51af-4b74-9cfe-ced353327e1a.png)![](img/dffb20dd-011b-46ff-a040-2a87a2f06522.png)'
  prefs: []
  type: TYPE_IMG
- en: Another way of understanding this is that we obtain the first column of matrix
    *C* by multiplying matrix *A* with a vector comprising of the first column of
    matrix *B*. We obtain the second column of matrix *C* by multiplying matrix *A*
    with a vector obtained from the second column of matrix *B*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s look at a concrete example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ff79a42b-72f4-48a9-9042-5accf01153db.png)'
  prefs: []
  type: TYPE_IMG
- en: 'It is important to understand that we can only multiply two matrices if the
    number of rows in *A* is equal to the number of columns in *B*. The resultant
    matrix will always have the same number of rows as *A* and the same number of
    columns as *B*. Note that matrix multiplication is not commutative; as in the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9da42d43-ccbd-467c-8504-65fef2b733f5.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Matrix multiplication is, however, associative, as shown in the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f10ca8a5-8315-4c00-a0dc-8c44e48eea54.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Matrices are useful because we can represent a large number of operations with
    relatively simple equations. There are two matrix operations that are particularly
    important for machine learning:'
  prefs: []
  type: TYPE_NORMAL
- en: Transpose
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Inverse
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To transpose a matrix, we simply swap the columns and rows, as shown in the
    following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/aced5013-84eb-400b-bbbc-fb68b385eb48.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Finding the inverse of a matrix is a little more complicated. In the set of
    real numbers, the numbers 1 plays the role of **identity**. That is to say, the
    number 1 multiplied by any other number that equals that number. Also, almost
    every number has an inverse; that is, a number that when it is multiplied by itself
    equals 1\. For example, the inverse of 2 is 0.5 because two times 0.5 equals 1\.
    It turns out an equivalent idea holds for matrices and tensors. The identity matrix
    consists of 1s along its primary diagonal and zeros everywhere else, as shown
    in the following 3 x 3 example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ad6dd3f0-ace6-4ad6-9a4f-42b799f0d4bd.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The identity matrix is the result when we multiply a matrix that is inverse.
    We write this in the following way:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8724e18d-d0b9-4b0d-8f9d-d33d188d5a39.png)'
  prefs: []
  type: TYPE_IMG
- en: Importantly, we can only find the inverse of a square matrix. It is not expected
    to calculate inverse matrices, or indeed any matrix operation, by hand. That is
    what computers are good at. Inverting matrices is a non-trivial operation and
    they are, even for a computer, computationally expensive.
  prefs: []
  type: TYPE_NORMAL
- en: Linear models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The simplest models we will encounter in machine learning are linear models.
    Solving linear models is important in many different settings, and they form the
    building blocks of many nonlinear techniques. With a linear model, we attempt
    to fit training data to a linear function, sometimes called the **hypothesis function**.
    This is done through a process called linear regression.
  prefs: []
  type: TYPE_NORMAL
- en: 'The hypothesis function for single variable linear regression has the following
    form:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9c54f0a3-0a2f-41ad-a199-0ee91fab1854.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, *θ[0]* and *θ[1]* are the model **parameters** and *x* is the single independent
    variable. For our house price example, *x* could represent the size of floor space
    and *h(x)* could represent the predicted house price.
  prefs: []
  type: TYPE_NORMAL
- en: For simplicity, we will begin by looking at just the single variable, or single
    feature case.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following diagram, we show a number of points, representing training
    data, and an attempt to fit a straight line to these points:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e1a8bfdf-e61c-4ae5-a5cc-59c85d44da5e.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, *x* is the single feature and **θ*[0]*** and **θ*[1]*** represent the
    intercept and the slope of the hypothesis function, respectively. Our aim is to
    find values for **θ*[0]*** and **θ*[1]***, the model parameters, which will give
    us our line of best fit in the preceding diagram. In this diagram, **θ***[**0** ]*is
    set to **1** and **θ***[**1** ]*is set to **0.5**. Therefore, its intercept is
    **1** and the line has a slope of **0.5**. We can see that most of the training
    points lie above the line and a few lower-valued points lie below the line. We
    could guess that **θ***[**1** ]*is probably slightly too low, since the training
    points appear to have a slightly steeper slope. Also, **θ*[0]*** is too high,
    since there are two data points below the line on the left and the intercept appears
    to be slightly lower than 1.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is clear that we need a formal approach to finding the error in the hypothesis
    function. This is done through what is known as a **cost function**. The cost
    function measures the total error between the values given by the hypotheses function
    and the actual values in the data. Essentially, the loss function sums each point''s
    distance from the hypothesis. The cost function is sometimes called the **mean
    squared error** (**MSE**). This is expressed by the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c3956662-ef67-4e3d-9aa5-9e42c2c31af5.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, *h[θ](x^i**)* is the value calculated by the hypothesis for the *i*th
    training sample, and *y^i* is its actual value. The difference is squared as statistical
    convenience, since it ensures the result is always positive. Squaring also adds
    more weight to larger differences; that is, it places greater importance on outliers.
    This sum is then divided by *m*, the number of training samples, to calculate
    the mean. Here, the sum is also divided by two to make subsequent math a little
    more straightforward.
  prefs: []
  type: TYPE_NORMAL
- en: The final part is to adjust the parameter values so that the hypothesis function
    fits the training data as closely as possible. We need to find parameter values
    that minimize the error.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two ways we can do this:'
  prefs: []
  type: TYPE_NORMAL
- en: Using gradient descent to iterate over the training set and adjust parameters
    to minimize a cost function
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Directly computing model parameters, using a *closed-form* equation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gradient descent
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Gradient descent is a general-purpose optimization algorithm that has a wide
    variety of applications. Gradient descent minimizes the cost function by iteratively
    adjusting the model parameters. Gradient descent works by taking the partial derivative
    of the cost function. If we plot the cost function against a parameter value,
    it forms a convex function, as shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b4f54c07-d3e6-4ae9-b04d-fcc3629b874e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'You can see that as we vary *θ*, from right to left in the preceding diagram,
    the cost, *J[θ]*, decreases to a minimum and then rises. The aim is that on each
    iteration of gradient descent, the cost moves closer to the minimum, and then
    stops once it reaches this minimum. This is achieved using the following update
    rule:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5a4faae8-3e9e-4791-bf23-3419d8c76146.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, *α* is the **learning rate,** a settable **hyperparameter**. It is called
    a hyperparameter to distinguish it from the model parameters, theta. The partial
    derivative term is the slope of the cost function and this needs to be calculated
    for both theta *0* and theta *1*. You can see that when the derivative, and therefore
    the slope, is positive, a positive value is subtracted from the previous value
    of theta, moving from right to left in the preceding diagram. Alternatively, if
    the slope is negative, theta increases, moving from right to left. Also, at the
    minimum, the slope is zero, so gradient descent will stop. This is exactly what
    we want, since no matter where we start gradient descent, the update rule is guaranteed
    to move theta toward the minimum.
  prefs: []
  type: TYPE_NORMAL
- en: 'Substituting the cost function into the preceding equation and then taking
    the derivative for both values of theta results in the following two update rules,
    results in the following equations:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2b3128b9-8194-467d-92f2-62d2fa158d26.png)![](img/0b152aad-3357-429e-8de3-0a4358fa65a0.png)'
  prefs: []
  type: TYPE_IMG
- en: On iteration and subsequent updates, theta will converge to values that minimize
    the cost function, resulting in the best fit straight line to the training data. There
    are two things that need to be considered. Firstly, the initialization values
    of theta; that is, where we start gradient descent. In most cases, random initialization works
    best. The other thing we need to consider is setting the learning rate, alpha
    (*α*). This is a number between zero and one. If the learning rate is set too
    high, then it will likely overshoot the minima. If it is set too low, then it
    will take too long to converge. It may take some experimentation with the particular
    model being used; in deep learning, an adaptive learning rate is often used for
    best results. This is where the learning rate changes, usually getting smaller,
    on each iteration of gradient descent.
  prefs: []
  type: TYPE_NORMAL
- en: The type of gradient descent we have discussed so far is called **batch gradient
    descent **(**BGD**). This refers to the fact that on each update, the entire training
    set is used. This means that as the training set gets large, batch gradient descent
    becomes increasingly slow. On the other hand, batch gradient descent scales much
    better when there are a large number of features, so it is most often used when
    there is a smaller training set with a large number of features.
  prefs: []
  type: TYPE_NORMAL
- en: 'An alternative to batch gradient descent is **stochastic gradient descent**
    (**SGD**). Instead of calculating the gradient using the entire training set,
    SGD calculates the gradient using a single sample chosen randomly on each iteration.
    The advantage of SGD is that the entire training set does not have to reside in
    memory, since on each iteration it works with one instance only. Because stochastic
    gradient descent chooses samples at random, its behavior is a little less regular
    than BGD. With batch gradient descent, every iteration smoothly moves the error
    (*J[θ]*) toward the minima. With SGD, every iteration does not necessarily move
    the cost closer to the minima. It tends to jump around a bit, moving toward the
    minima only on average over a number of iterations. This means that it may jump
    around close to the minima but never actually reach it by the time it completes
    its iterations. The random nature of SGD can be used to advantage when there is
    more than one minima, since it may be able to jump out of this local minima and
    find the global minima. For example, consider the following cost function:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f6c75291-ee32-430b-9413-662bb4d21b56.png)'
  prefs: []
  type: TYPE_IMG
- en: If batch gradient descent were to begin to the right of the **Local Minimum**,
    it would not be able to find the **Global Minimum**. Fortunately, the cost function
    for linear regression is always going to be a convex function with a single minima.
    However, this is not always the case, particularly with neural networks, where
    the cost function can have a number of local minima.
  prefs: []
  type: TYPE_NORMAL
- en: Multiple features
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In a realistic example, we would have more than one feature and each feature
    has an associated parameter value that requires fitting. We write the hypothesis function
    for multiple features as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e037ff82-52fb-4849-89dc-81d5480d803f.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, *x[0]* is called the bias variable and is set to one, *x**[1]* to *x**[n]* are
    the feature values, and *n* is the total number of features. Notice that we can
    write a vectorized version of the hypothesis function. Here, *θ* is the **parameter
    vector** and *x* is the **feature vector.**
  prefs: []
  type: TYPE_NORMAL
- en: The cost function is still basically the same as the single feature case; we
    are just summing the error. We do, however, need to adjust the gradient descent
    rules and be clear about the required notation. In the update rules for gradient
    descent for a single feature, we used the notation for parameter values *θ[0]*
    and *θ[1]*. For the multiple feature version, we simply wrap these parameters'
    values and their associated features into vectors. The parameter vector is notated
    as *θ[j]*, where the subscript *j* refers to the feature and is an integer between
    *1* and *n*, where *n* is the number of features.
  prefs: []
  type: TYPE_NORMAL
- en: 'There needs to be a separate update rule for each parameter. We can generalize
    these rules as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b17f154a-f6b4-4a97-94f6-00b15af88d0e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'There is an update rule for each parameter; so, for example, the update rule
    for the parameter for feature *j = 1* would be the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2f946159-a81c-443f-ad8c-d070160ca57e.png)'
  prefs: []
  type: TYPE_IMG
- en: The variables *x^((i))* and *y^((i))* refer, as in the single feature example,
    to the predicted value and actual value of the *i^(th)* training sample, respectively.
    In the multiple feature case, however, instead of being single values, they are
    now vectors. The value *x[j]^((i))* refers to feature *j* of training sample *i*, and *m*
    is the total number of samples in the training set.
  prefs: []
  type: TYPE_NORMAL
- en: The normal equation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For some linear regression problems, the closed form solution, also known as
    the **normal equation**, is a better way to find optimum values of theta. If you
    know calculus, then to minimize the cost function, you can find the partial derivatives
    of the cost function, with respect to each value of theta, and set each derivative
    to zero and then solve for each value of theta. Don''t worry if you are not familiar
    with calculus; it turns out that we can derive the normal equation from these
    partial derivatives and this results in the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1156e0cd-2127-4b45-8251-5ab7b134d2bb.png)'
  prefs: []
  type: TYPE_IMG
- en: You may wonder why we need to bother with gradient descent and the added complications
    this entails, since the normal equation allows us to compute the parameters in
    one step. The reason is that the computational effort required to invert a matrix
    is not insignificant. When a feature matrix *X* becomes large (and remember *X*
    is a matrix holding all the values of features for every training sample), then
    finding the inverse of this matrix simply takes too long. Even though gradient
    descent involves many iterations, it is still faster than the normal equation
    for large datasets.
  prefs: []
  type: TYPE_NORMAL
- en: An advantage of the normal equation is that, unlike gradient descent, it does
    not expect features to be of the same scale. Another advantage of the normal equation
    is that is not necessary to choose a learning rate.
  prefs: []
  type: TYPE_NORMAL
- en: Logistic regression
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We can use the linear regression model to perform binary classification by
    finding a decision boundary that divides two predicted classes. A common way to
    do this is by using a `sigmoid` function, defined as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/227a06ad-2f85-4bfa-8bca-91a5d6d65bde.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The plot of the `sigmoid` function looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ed10f260-7263-418e-86ef-4652695481e2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The `sigmoid` function can be used in the hypothesis function, to output a
    probability, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9f7db059-84ee-4fa9-b128-bec7fe1ed2da.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, the output of the hypothesis function is the probability *y = 1* given
    *x* parameterized by theta. To decide when to predict *y = 0* or *y = 1*, we can
    use the following two rules:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4988133c-dfdf-4dd9-a92f-484c2182184e.png)![](img/04f301da-b0fe-45eb-8727-c3a962af3c80.png)'
  prefs: []
  type: TYPE_IMG
- en: The characteristics of the `sigmoid` function (that is, having asymptotes at
    *0* and *1*, and having a value of *0.5* at *z = 0*), has some attractive properties
    for use with logistic regression problems. Notice that the decision boundary is
    a property of the parameters of the model, not the training set. We still need
    to fit the parameters so that the cost, or the error, is minimized. To do this,
    we need to formalize what we know already.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have a training set with *m* samples, written as the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2f0169de-7a8b-4ccd-b3fe-e61eacbf5a25.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Each training sample consists of vector *x*, of size *n**,* where *n* is the
    number of features:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bf321cf3-03b2-4b49-b17a-7b4ad6fb43ae.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Each training sample also consists of a value *y* and, for logistic regression,
    this value is either zero or one. We also have a hypothesis function for logistic
    regression, which we can rewrite as the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/15d8625e-183d-4b07-b91f-77b48261c812.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Using the same cost function for linear regression, with the hypotheses for
    logistic regression, we introduce a nonlinearity via the `sigmoid` function. This
    means that the cost function is no longer convex, and as a result, it may have
    a number of local minima, which can be a problem for gradient descent. It turns
    out that a function that works well for logistic regression, and results in a
    convex cost function, is the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6e2dbf0d-1cbe-498f-995e-c95322f826da.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We can plot these functions for the two cases:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0c45eefd-80e3-4396-936c-85e876b4bcf1.png)'
  prefs: []
  type: TYPE_IMG
- en: It can be seen from the previous diagrams that, when the label **y** equals
    **1** and the hypothesis predicts **0**, the cost approaches infinity. Also, when
    the actual value of **y** is **0**, and the hypothesis predicts **1**, similarly,
    the cost rises toward infinity. Alternatively, when the hypothesis predicts the
    correct value, either **0** or **1**, the cost falls to **0**. This is exactly
    what we want for logistic regression.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we need to apply gradient descent to minimize the cost. We can rewrite
    the logistic regression cost function for binary classification to a more compact
    form, summing it over multiple training samples, using the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5e391513-ae15-4481-90dd-accf9a3b203c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Finally, we can update the parameter values with this update rule:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/24af04b6-7839-47d8-ade7-04154f25c041.png)'
  prefs: []
  type: TYPE_IMG
- en: Superficially, this looks identical to the update rule for linear regression;
    however, the hypothesis is a function of the `sigmoid` function, so it actually
    behaves quite differently.
  prefs: []
  type: TYPE_NORMAL
- en: Nonlinear models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We have seen that linear models, by themselves, fail to represent nonlinear
    real-world data. A possible solution is to add polynomial features to the hypotheses
    function. For example, a cubic model can be represented by the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/97fe1a3f-2036-4b85-a916-3585fe58a41a.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, we need to choose two derived features to add to our model. These added
    terms could simply be the square and cube of the size feature in the housing example.
  prefs: []
  type: TYPE_NORMAL
- en: An important consideration when adding polynomial terms is feature scaling.
    The squared and cubic terms in this model will be of quite different scales. In
    order for gradient descent to work correctly, it is necessary to scale these added
    polynomial terms.
  prefs: []
  type: TYPE_NORMAL
- en: Choosing polynomial terms is a way to inject knowledge into a model. For example,
    simply knowing that house prices tend to flatten out relative to floor space,
    as the floor space gets large, suggests adding squared and cubic terms, giving
    us the shape that we expect the data to take. However, feature selection where,
    say in logistic regression, when we are trying to predict a complicated multidimensional
    decision boundary, it may mean thousands of polynomial terms. Under such circumstances,
    the machinery of linear regression grinds to a halt. We will see that neural networks
    offer a more automated and powerful solution to complicated nonlinear problems.
  prefs: []
  type: TYPE_NORMAL
- en: Artificial neural networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As the name suggests, ANNs are inspired by their biological counterpart, although
    the reason is, perhaps, misunderstood. An artificial neuron, or what we will call
    a **unit**, is grossly simplified compared to a biological neuron, both in terms
    of functionality and structure. The biological inspiration comes more from the
    insight that each neuron in a brain performs an identical function regardless
    of whether it is processing sound, vision, or pondering complex mathematics problems.
    This single algorithm approach is, fundamentally, the inspiration for ANNs.
  prefs: []
  type: TYPE_NORMAL
- en: An artificial neuron, a unit, performs a single simple function. It adds up
    its inputs and, dependent on an activation function, gives an output. One of the
    major benefits of ANNs is that they are highly scalable. Since they are composed
    of fundamental units, simply adding more units in the right configuration allows
    ANNs to easily scale to massive, complex data.
  prefs: []
  type: TYPE_NORMAL
- en: 'The theory of ANNs has been around for quite some time, first proposed in the
    early 1940''s. However, it is not until recently that they have been able to outperform
    more traditional machine learning techniques. There are three broad reasons for
    this:'
  prefs: []
  type: TYPE_NORMAL
- en: The improvement in algorithms, notably the implementation of **backpropagation**, allowing
    an ANN to distribute the error at the output to input layers and adjust activation
    weights accordingly
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The availability of massive datasets to train ANNs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The increase in processing power, allowing large-scale ANNs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The perceptron
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'One of the most simple ANN models is the perceptron, consisting of a single
    logistic unit. We can represent the perceptron in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/878bbf1d-61e1-4f4d-a2e6-9e0b1944f659.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Each of the inputs are associated with a weight and these are fed into the
    logistic unit. Note that we add a bias feature, **x[0] = 1**. This logistic unit
    consists of two elements: a function to sum inputs and an activation function.
    If we use the `sigmoid` as the activation function, then we can write the following
    equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5f42d9f1-a522-45ca-9d21-25b72e211ec9.png)'
  prefs: []
  type: TYPE_IMG
- en: Note that this is exactly the hypothesis we used for logistic regression; we
    have simply swapped *θ* for *w,* to denote to the weights in the logistic unit.
    These weights are exactly equivalent to the parameters of the logistic regression
    model.
  prefs: []
  type: TYPE_NORMAL
- en: 'To create a neural network, we connect these logistic units into layers. The
    following diagram represents a three-layered neural network. Note that for the
    sake of clarity, we omit the bias unit:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/30bec0aa-c10b-4014-a129-03c7fe47c813.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This simple ANN consists of an input layer with three units; one hidden layer,
    also with three units; and finally, a single unit in the output. We use the notation
    *ai(j)* to refer to the activation of unit *i* in layer *j* and with *W* ^((j)) denoting
    the matrix of weights that map layer *j* to layer *j+1*. Using this notation,
    we can express the activation of the three hidden units with the following equations:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3fd2c34b-8976-4342-922a-8695c073863d.png)![](img/16851b0a-9c75-41c0-bc77-2295c603947f.png)![](img/cb5695a9-bacc-46e7-a734-9708672c6571.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The activation of the output unit can then be expressed by the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d72f5919-43ac-4479-b12c-a1f728349985.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, *W*^(*(1)* )is a 3 x 4 matrix controlling the function mapping between
    the input, layer one, and the single hidden layer, layer two. The weight matrix
    *W^(^(2))*, of size 1 X 4, controls the mapping between the hidden layer and the
    output layer, H. More generally, a network with *s[j] *units in layer *j* and
    *s[k]* units in layer *j+1* will have a size of *s[k] *by *(s[j])+1.* For example,
    for a network that has five input units and three units in the next forward layer,
    layer two, the associated weight matrix, *W^((1))* will be of size 3 x 6.
  prefs: []
  type: TYPE_NORMAL
- en: 'Having established a hypotheses function, the next step is to formulate a cost
    function to measure, and ultimately minimize, the error of the model. For classification,
    the cost function is almost identical to that used for logistic regression. The
    important difference is that with neural networks, we can add output units to
    allow multi-class classification. We can write the cost function for multiple
    outputs as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/459fdd75-08ab-4dd3-9454-25288f27e48c.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, *K* is the number of output units representing the number of output classes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we need to minimize the cost function, which is done using the backpropagation
    algorithm. Essentially, what this does is backpropagate the error, the gradient
    of the cost function, from the output units to the input units. To do this, we
    need to evaluate partial derivatives. That is, we need to compute the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a05b11e0-d145-47fa-b88f-85d0d646e2bf.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, *l* is the layer, *j* is the unit, and *i* is the sample. In other word,
    for each unit in each layer, and for every sample, we need to calculate the partial
    derivative, the gradient, of the cost function with respect to each parameter.
    For example, consider we have a network with four layers. Consider also that we
    are working with a single sample. We need to find the error at each layer, beginning
    at the output. The error at the output is just the error of the hypothesis:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/88176028-0f46-4339-a542-bca008929666.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This is a vector of the error for each unit, *j*. The superscript *(4)* indicates
    this is the fourth layer; that is, the output layer. It turns out that, through
    some complicated math we do not need to worry about here, the error for the two
    hidden layers can be calculated with the following equations:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7b0e678d-77b4-47b0-badc-71603e40d9f0.png)![](img/a00835ff-2cee-4bc2-b334-745674ddc273.png)'
  prefs: []
  type: TYPE_IMG
- en: The `.*`operator here is element-wise vector multiplication. Notice that the
    error vector of the next forward layer is required in each of these equations.
    That is, to calculate the error in layer three, the error vector of the output
    layer is required. Similarly, to calculate the error in layer two requires the
    error vector of layer three.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is how backpropagation works with a single sample. To loop across an entire
    dataset, we need to accumulate the gradients for each unit and each sample. So,
    for each sample in the training set, the neural net performs forward propagation
    to compute the activation for the hidden layers and the output layer. Then, for
    the same sample, that is within the same loop, the output error can be calculated. Consequently,
    we are able calculate the error for each previous layer in turn, and the neural
    net does exactly this, accumulating each gradient in a matrix. The loop begins
    again performing the identical set of operations on the next sample, and these
    gradients are also accumulated in the error matrix. We can write an update rule
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6f9c3ede-fcc7-49ec-a32d-0d0eb6500927.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The capital delta is the matrix that stores the accumulated gradients by adding
    the activation for layer *l,* unit *j*, and sample *i*, then multiplying it with
    the associated error of the next forward layer for this same sample, *i*. Finally,
    once we have made a pass over the entire training set—an epoch—we can calculate
    the derivative of the cost function with respect to each parameter:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c1980f30-b352-4d7e-8f33-a0f196067f1f.png)'
  prefs: []
  type: TYPE_IMG
- en: Once again, it is not necessary to know the formal proof for this; it's just
    to give you some intuitive understanding of the mechanics of backpropagation.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We have covered a lot of material in this chapter. Don''t worry if you do not
    understand some of the mathematics presented here. The aim is to give you some
    intuition into how some common machine learning algorithms work, not to have a
    complete understanding of the theory behind these algorithms. After reading this
    chapter, you should have some understanding of the following:'
  prefs: []
  type: TYPE_NORMAL
- en: General approaches to machine learning, including knowing the difference between
    supervised and unsupervised methods, online and batch learning, and rule-based,
    as opposed to model-based, learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Some unsupervised methods and their applications, such as clustering and principle
    component analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Types of classification problems, such as binary, multi-class, and multi-out
    classification
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Features and feature transformations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The mechanics of linear regression and gradient descent
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An overview of neural networks and the backpropagation algorithm
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In [Chapter 3](77e1b6da-e5d6-46a4-8a2c-ee1cfa686cc6.xhtml), *Computational Graphs
    and Linear Models*, we will apply some of these concepts using PyTorch. Specifically,
    we will show how to find the gradients of functions by building a simple linear
    model. You will also gain a practical understanding of backpropagation by implementing
    a simple neural network.
  prefs: []
  type: TYPE_NORMAL
