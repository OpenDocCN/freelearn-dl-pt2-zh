- en: Artificial Intelligence in Production
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: 生产中的人工智能
- en: In the creation of a system that involves **artificial intelligence** (**AI**),
    the actual AI usually only takes a small fraction of the total amount of work,
    while a major part of the implementation entails the surrounding infrastructure,
    starting from data collection and verification, feature extraction, analysis,
    resource management, and serving and monitoring (David Sculley and others. *Hidden
    technical debt in machine learning systems*, 2015).
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在涉及**人工智能**（**AI**）的系统创建中，实际上AI通常只占总工作量的一小部分，而实施的主要部分涉及周围基础设施，从数据收集和验证开始，特征提取，分析，资源管理，到服务和监控（David Sculley等人，《机器学习系统中隐藏的技术债务》，2015年）。
- en: In this chapter, we'll deal with monitoring and model versioning, visualizations
    as dashboards, and securing a model against malicious hacking attacks that could
    leak user data.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将处理监控和模型版本控制、作为仪表板的可视化以及保护模型免受可能泄露用户数据的恶意黑客攻击。
- en: 'In this chapter, we''ll be covering the following recipes:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍以下配方：
- en: Visualizing model results
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可视化模型结果
- en: Serving a model for live decisioning
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为实时决策服务模型
- en: Securing a model against attack
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 保护模型免受攻击
- en: Technical requirements
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: For Python libraries, we will work with models developed in TensorFlow and PyTorch,
    and we'll apply different, more specialized libraries in each recipe.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 对于Python库，我们将使用在TensorFlow和PyTorch中开发的模型，并在每个配方中应用不同的、更专业的库。
- en: As always, you can find the recipe notebooks on GitHub at [https://github.com/PacktPublishing/Artificial-Intelligence-with-Python-Cookbook/tree/master/chapter11](https://github.com/PacktPublishing/Artificial-Intelligence-with-Python-Cookbook/tree/master/chapter11).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在GitHub上找到配方笔记本，网址是[https://github.com/PacktPublishing/Artificial-Intelligence-with-Python-Cookbook/tree/master/chapter11](https://github.com/PacktPublishing/Artificial-Intelligence-with-Python-Cookbook/tree/master/chapter11)。
- en: Visualizing model results
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可视化模型结果
- en: Frequent communication with business shareholders is key to getting the buy-in
    for deploying an AI solution, and should start from the idea and premises to decisions
    and findings. How results are communicated can make the difference between success
    and failure in a commercial setting. In this recipe, we'll be building a visualization
    solution for a **machine learning** (**ML**) model.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 与业务股东的频繁沟通是获取部署AI解决方案的关键，并应从思路和前提到决策和发现开始。结果如何传达可以决定在商业环境中成功或失败的关键因素。在这个配方中，我们将为一个**机器学习**（**ML**）模型构建一个可视化解决方案。
- en: Getting ready
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'We''ll be building our solution in `streamlit` ([https://www.streamlit.io/](https://www.streamlit.io/))
    and we''ll be using visualizations from `altair`, one of the many Python plotting
    libraries that `streamlit` integrates with (a list that also includes `matplotlib`
    and `plotly`). Let''s install `streamlit` and `altair`:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在`streamlit` ([https://www.streamlit.io/](https://www.streamlit.io/))中构建我们的解决方案，并使用来自`altair`的可视化工具，这是`streamlit`集成的众多Python绘图库之一（还包括`matplotlib`和`plotly`）。让我们安装`streamlit`和`altair`：
- en: '[PRE0]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: We won't use the notebook in this recipe. Therefore, we've omitted the exclamation
    marks in this code block. We'll be running everything from the terminal.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个配方中，我们不会使用笔记本。因此，在这个代码块中，我们已经省略了感叹号。我们将从终端运行所有内容。
- en: Altair has a very pleasant declarative way to plot graphs, which we'll see in
    the recipe. Streamlit is a framework to create data apps – interactive applications
    in the browser with visualizations.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: Altair有一种非常愉快的声明性方法来绘制图形，我们将在配方中看到。Streamlit是一个创建数据应用程序的框架 - 在浏览器中具有可视化功能的交互式应用程序。
- en: Let's proceed with building an interactive data app.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续构建一个交互式数据应用程序。
- en: How to do it...
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做…
- en: We'll be building a simple app for model building. This is meant to show how
    easy it is to create a visual interactive application for the browser in order
    to demonstrate findings to non-technical or technical audiences.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将构建一个简单的应用程序用于模型构建。这旨在展示如何轻松创建一个面向浏览器的视觉交互式应用程序，以向非技术或技术观众展示发现。
- en: For a very quick, practical introduction to `streamlit`, let's look at how a
    few lines of code in a Python script can be served.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 作为对`streamlit`的快速实用介绍，让我们看看如何在Python脚本中的几行代码可以提供服务。
- en: Streamlit hello-world
  id: totrans-21
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Streamlit hello-world
- en: We'll write our streamlit applications as Python scripts, not as notebooks,
    and we'll execute the scripts with streamlit to be deployed.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将以Python脚本形式编写我们的streamlit应用程序，而不是笔记本，并且我们将使用streamlit执行这些脚本以进行部署。
- en: 'We''ll create a new Python file, let''s say `streamlit_test.py`, in our favorite
    editor, for example, vim, and we''ll write these lines:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在我们喜爱的编辑器（例如vim）中创建一个新的Python文件，假设名为`streamlit_test.py`，并编写以下代码行：
- en: '[PRE1]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This would show a select box or drop-down menu with the title *Hello* and a
    choice between options *A*, *B*, and *C*. This choice will be stored in the `chosen_option` variable,
    which we can output in the browser.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这将显示一个选择框或下拉菜单，标题为*Hello*，并在选项*A*、*B*和*C*之间进行选择。这个选择将存储在变量`chosen_option`中，在浏览器中可以输出。
- en: 'We can run our intro app from the terminal as follows:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以从终端运行我们的简介应用程序如下：
- en: '[PRE2]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The server port option is optional.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 服务器端口选项是可选的。
- en: This should open our browser in a new tab or window showing our drop-down menu
    with the three choices. We can change the option, and the new value will be displayed.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该在新标签页或窗口中打开我们的浏览器，显示带有三个选项的下拉菜单。我们可以更改选项，新值将显示出来。
- en: This should be enough for an introduction. We'll come to the actual recipe now.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该足够作为介绍。现在我们将进入实际的步骤。
- en: Creating our data app
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 创建我们的数据应用
- en: The main idea of our data app is that we incorporate decisions such as modeling
    choices into our application, and we can observe the consequences, both summarized
    in numbers and visually in plots.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们数据应用的主要思想是将建模选择等决策纳入我们的应用程序，并观察其后果，无论是用数字总结还是在图表中直观显示。
- en: 'We''ll start by implementing the core functionality, such as modeling and dataset
    loading, and then we''ll create the interface to it, first in the side panel,
    and then the main page. We''ll write all of the code in this recipe to a single
    Python script that we can call `visualizing_model_results.py`:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从实现核心功能开始，如建模和数据集加载，然后创建其界面，首先是侧边栏，然后是主页面。我们将所有代码写入一个单独的Python脚本中，可以称之为`visualizing_model_results.py`：
- en: 'Loading the dataset – we''ll implement dataset loaders:'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载数据集 – 我们将实现数据集加载器：
- en: 'Let''s begin with a few preliminaries such as imports:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从一些预备工作开始，如导入：
- en: '[PRE3]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: If you've followed the hello-world introduction attentively, you might have
    wondered how the interface communicates with Python. This is handled by streamlit
    by re-running your script every time the user makes a change by clicking somewhere
    or entering a field.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您注意到了hello-world介绍，您可能会想知道界面如何与Python通信。这由streamlit处理，每次用户点击某处或输入字段时重新运行您的脚本。
- en: 'We need to load datasets into memory. This can include a download step, and
    for bigger datasets, downloading could potentially take a long time. Therefore,
    we are going to cache this step to disk, so instead of downloading every time
    there''s a button-click, we''ll retrieve it from the cache on disk:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要将数据集加载到内存中。这可能包括下载步骤，对于更大的数据集，下载可能需要很长时间。因此，我们将缓存此步骤到磁盘上，所以不是每次点击按钮时都要下载，我们将从磁盘缓存中检索它：
- en: '[PRE4]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: This implements the functions for modeling and dataset loaders.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这实现了建模和数据集加载器的功能。
- en: Please note the use of the streamlit cache decorator, `@st.cache`. It handles
    the caching of the decorated function, in this case, `load_data()`, in such a
    way that any number of parameters passed to the function will be stored together
    with the associated outputs.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意使用streamlit缓存装饰器，`@st.cache`。它处理装饰函数（在这种情况下是`load_data()`）的缓存，使得传递给函数的任意数量的参数都将与相关输出一起存储。
- en: Here, the dataset loading might take some time. However, caching means that
    we only have to load each dataset exactly once, because subsequently the dataset
    will be retrieved from cache, and therefore loading will be much faster. This
    caching functionality, which can be applied to long-running functions, is central
    to making streamlit respond more quickly.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，数据集加载可能需要一些时间。但是，缓存意味着我们只需加载每个数据集一次，因为随后的数据集将从缓存中检索，因此加载速度会更快。这种缓存功能，可以应用于长时间运行的函数，是使streamlit响应更快的核心。
- en: We are using the scikit-learn datasets API to download a dataset. Since scikit-learn's
    `load_x()` type functions, such as `load_iris()`, which are mostly for toy datasets,
    include attributes such as `target_names` and `feature_names`, but scikit-learn's
    `fetch_x()` functions, such as `fetch_covtype()`, are intended for bigger, more
    serious datasets, we'll generate feature and target names for these separately.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在使用scikit-learn数据集API下载数据集。由于scikit-learn的`load_x()`类型函数（如`load_iris()`，主要用于玩具数据集）包括`target_names`和`feature_names`等属性，但是scikit-learn的`fetch_x()`函数（如`fetch_covtype()`）用于更大、更严肃的数据集，我们将为这些分别生成特征和目标名称。
- en: 'The training procedure is similarly decorated to be cached. However, please
    note that we have to include our hyperparameters in order to make sure that the
    cache is unique to the model type, dataset, and all hyperparameters as well:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 训练过程同样被装饰成可以缓存。但请注意，为了确保缓存与模型类型、数据集以及所有超参数都是唯一的，我们必须包含我们的超参数：
- en: '[PRE5]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The modeling function takes a list of models, which we'll update based on the
    choices of hyperparameters. We'll implement this choice now.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 建模函数接受模型列表，我们将根据超参数的选择进行更新。我们现在将实施这个选择。
- en: 'Exposing key decisions in the side panel:'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在侧边栏中呈现关键决策：
- en: 'In the side panel, we''ll be presenting the choices of datasets, model type,
    and hyperparameters. Let''s start by choosing the dataset:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在侧边栏中，我们将呈现数据集、模型类型和超参数的选择。让我们首先选择数据集：
- en: '[PRE6]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This will load the datasets after we've made the choice between iris, wine,
    and cover type.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这将在我们在iris、wine和cover type之间做出选择后加载数据集。
- en: 'For the model hyperparameters, we''ll provide slider bars:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 对于模型的超参数，我们将提供滑动条：
- en: '[PRE7]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Finally, we will expose the model type again as a drop-down menu:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将再次将模型类型暴露为一个下拉菜单：
- en: '[PRE8]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: In the end, after the choice, we will call the `train_model()` function with
    the dataset, model type, and hyperparameters as arguments.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在选择后，我们将调用`train_model()`函数，参数为数据集、模型类型和超参数。
- en: 'This screenshot shows what the side panel looks like:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 此截图显示了侧边栏的外观：
- en: '![](img/3941d25d-401c-44d0-9eef-960efb578eaa.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3941d25d-401c-44d0-9eef-960efb578eaa.png)'
- en: This shows you the menu options in the browser. We'll show the results of these
    choices in the main part of the browser page.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这显示了浏览器中的菜单选项。我们将在浏览器页面的主要部分展示这些选择的结果。
- en: 'Reporting classification results in the main panel:'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在主面板上报告分类结果：
- en: In the main panel, we'll be showing important statistics, including a classification
    report, a few plots that should give insights into the model strengths and weaknesses,
    and a view of the data itself, where incorrect decisions by the model will be
    highlighted.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在主面板上，我们将展示重要的统计数据，包括分类报告、几个图表，应该能够揭示模型的优势和劣势，以及数据本身的视图，在这里模型错误的决策将被突出显示。
- en: 'We first need a title:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先需要一个标题：
- en: '[PRE9]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Then we present basic statistics in relation to our modeling result, such as
    the area under the curve, precision, and many more:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们将展示与我们的建模结果相关的基本统计数据，例如曲线下面积、精度等等：
- en: '[PRE10]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We''ll then show a confusion matrix that tabulates the actual and predicted
    labels for each of the classes:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将展示一个混淆矩阵，表格化每个类别的实际和预测标签：
- en: '[PRE11]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We also want to be able to scroll through our test data to be able to inspect
    samples that were incorrectly classified:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还希望能够滚动查看被错误分类的测试数据样本：
- en: '[PRE12]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Incorrectly classified samples will be highlighted against a red background.
    We've made this raw data exploration optional. It needs to be activated by clicking
    a checkbox.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 错误分类的样本将以红色背景突出显示。我们将这种原始数据探索设为可选项，需要通过点击复选框激活。
- en: 'Finally, we''ll show a facet plot of variables plotted against each other in
    scatter plots. This is the part where we use the `altair` library:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将展示变量在散点图中相互绘制的面板图。这部分将使用`altair`库：
- en: '[PRE13]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Incorrectly classified examples are highlighted in these plots. Again, we've
    made this part optional, activated by marking a checkbox.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 这些图中突出显示了错误分类的例子。同样，我们将这部分设为可选项，通过标记复选框激活。
- en: 'The upper part of the main page for the `Covetype` dataset looks like this:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 主页上部分用于`Covetype`数据集的样式如下：
- en: '![](img/1e4d7a5d-be93-434d-b320-f007ddfba7c4.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1e4d7a5d-be93-434d-b320-f007ddfba7c4.png)'
- en: You can see the classification report and the confusion matrix. Below these
    (not part of the screenshot) would be the data exploration and the data plots.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以看到分类报告和混淆矩阵。在这些内容之下（不在截图范围内），将是数据探索和数据图表。
- en: This concludes our demo app. Our app is relatively simple, but hopefully this
    recipe can serve as a guide for building these apps for clear communication.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 这结束了我们的演示应用程序。我们的应用程序相对简单，但希望这个方法能作为构建这些应用程序以进行清晰沟通的指南。
- en: How it works...
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理如下...
- en: This book is about hands-on learning, and we'd recommend this for streamlit
    as well. Working with streamlit, you have a quick feedback loop where you implement
    changes and see the results, and you continue until you are happy with what you
    see.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 本书关注于实践学习，我们也推荐这种方式用于streamlit。在使用streamlit时，您可以快速实施更改并查看结果，直到您对所见到的内容满意为止。
- en: Streamlit provides a local server that you can access remotely over the browser
    if you want. So you can run your streamlit application server on Azure, Google
    Cloud, AWS, or your company cloud, and see your results in your local browser.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你愿意，Streamlit提供了一个本地服务器，可以通过浏览器远程访问。因此，你可以在Azure、Google Cloud、AWS或你公司的云上运行你的Streamlit应用服务器，并在本地浏览器中查看你的结果。
- en: What is important to understand is the streamlit workflow. Values for widgets
    are stored by streamlit. Other values are recomputed on the fly every time a user
    interacts with a widget as the Python script is executed again from top to bottom.
    In order to avoid expensive computations, these can be cached using the `@st.cache`
    decorator, as we've seen in the recipe.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是理解Streamlit的工作流程。小部件的值由Streamlit存储。其他值在用户与小部件交互时每次都会根据Python脚本从头到尾重新计算。为了避免昂贵的计算，可以使用`@st.cache`装饰器进行缓存，就像我们在这个示例中看到的那样。
- en: Streamlit's API has an integration for many plotting and graphing libraries.
    These include Matplotlib, Seaborn, Plotly, Bokeh, interactive plotting libraries,
    such as Altair, Vega Lite, deck.gl for maps and 3D charts, and graphviz graphs.
    Other integrations include Keras models, SymPy expressions, pandas DataFrames,
    images, audio, and others.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: Streamlit的API集成了许多绘图和图表库。这些包括Matplotlib、Seaborn、Plotly、Bokeh，以及Altair、Vega Lite、用于地图和3D图表的deck.gl等交互式绘图库，以及graphviz图形。其他集成包括Keras模型、SymPy表达式、pandas
    DataFrames、图像、音频等。
- en: Streamlit also comes with several types of widgets, such as sliders, buttons,
    and drop-down menus. Streamlit also includes an extensible component system, where
    each component consists of a browser frontend in HTML and JavaScript and a Python
    backend, able to send and receive information bi-directionally. Existing components interface
    with further libraries, including HiPlot, Echarts, Spacy, and D3, to name but
    a few: [https://www.streamlit.io/components](https://www.streamlit.io/components).
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: Streamlit还配备了多种类型的小部件，如滑块、按钮和下拉菜单。Streamlit还包括一个可扩展的组件系统，每个组件由HTML和JavaScript构成的浏览器前端以及Python后端组成，能够双向发送和接收信息。现有组件接口进一步与HiPlot、Echarts、Spacy和D3等库进行集成：[https://www.streamlit.io/components](https://www.streamlit.io/components).
- en: You can play around with different inputs and outputs, you can start from scratch,
    or you can improve on the code in this recipe. We could extend it to show different
    results, build dashboards, connect to a database for live updates, or build user
    feedback forms for subject matter experts to relay their judgment such as, for
    example, annotation or approval.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以玩转不同的输入和输出，可以从头开始，也可以改进这个*食谱*中的代码。我们可以扩展它以显示不同的结果，构建仪表板，连接到数据库进行实时更新，或者为专业主题专家建立用户反馈表单，例如注释或批准。
- en: See also
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: Visualization in AI and statistics is a broad field. Fernanda Viégas and Martin
    Wattenberg gave an overview talk, *Visualization for Machine Learning*, at NIPS
    2018, and you can find their slide deck and a recording of their talk.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: AI和统计可视化是一个广泛的领域。Fernanda Viégas和Martin Wattenberg在NIPS 2018上进行了一场名为*机器学习可视化*的概述演讲，并且你可以找到他们的幻灯片和演讲录像。
- en: 'Here''s a list of a few interesting streamlit demos to look at:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一些有趣的Streamlit演示列表：
- en: Using a live TensorFlow session to create an interactive face-GAN explorer: [https://github.com/streamlit/demo-face-gan/](https://github.com/streamlit/demo-face-gan/).
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用一个实时的TensorFlow会话来创建一个交互式的人脸-GAN探索器：[https://github.com/streamlit/demo-face-gan/](https://github.com/streamlit/demo-face-gan/).
- en: An image browser for the Udacity self-driving car dataset and real-time object
    detection: [https://github.com/streamlit/demo-self-driving](https://github.com/streamlit/demo-self-driving).
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个用于Udacity自动驾驶车辆数据集和实时目标检测的图像浏览器：[https://github.com/streamlit/demo-self-driving](https://github.com/streamlit/demo-self-driving).
- en: A components demo for maps, audio, images, and many others: [https://fullstackstation.com/streamlit-components-demo](https://fullstackstation.com/streamlit-components-demo).
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个地图、音频、图像以及其他多个组件的演示：[https://fullstackstation.com/streamlit-components-demo](https://fullstackstation.com/streamlit-components-demo).
- en: Aside from streamlit, there are other libraries and frameworks that can help
    to create interactive dashboards, presentations, and reports, such as Bokeh, Jupyter
    Voilà, Panel, and Plotly Dash.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 除了Streamlit，还有其他可以帮助创建交互式仪表板、演示和报告的库和框架，比如Bokeh、Jupyter Voilà、Panel和Plotly Dash。
- en: If you are looking for dashboarding and live charting with database integration,
    tools such as Apache Superset come in handy: [https://](https://superset.apache.org/)[superset.apache.org/](https://superset.apache.org/).
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您正在寻找具有数据库集成的仪表板和实时图表，诸如Apache Superset这样的工具非常方便：[https://superset.apache.org/](https://superset.apache.org/)。
- en: Serving a model for live decisioning
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为实时决策提供模型服务
- en: Often, specialists in AI are asked to model, present, or come up with models.
    However, even though the solution could be commercially impactful, in practice, productionizing
    a **proof of concept** (**POC**) for live decisioning in order to actually act
    on the insight can be a bigger struggle than coming up with the models in the
    first place. Once we've created a model based on training data, analyzed it to
    verify that it's working to an expected standard, and communicated with stakeholders,
    we want to make that model available so it can provide predictions on data for
    new decisions. This can mean certain requirements, such as latency (for real-time
    applications), and bandwidth (for servicing a large volume of customers). Often,
    a model is deployed as part of a microservice such as an inference server.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: AI专家经常被要求建模、呈现或提出模型。但是，即使解决方案可能在商业上具有影响力，实际上，将概念验证（**POC**）生产化以进行实时决策实施，往往比最初提出模型更具挑战性。一旦我们基于训练数据创建了模型，并对其进行分析以验证其按预期标准运行，并与利益相关者进行沟通，我们希望使该模型可用，以便为新决策的数据提供预测。这可能意味着满足特定要求，例如延迟（用于实时应用程序）和带宽（用于为大量客户提供服务）。通常，模型部署为诸如推断服务器之类的微服务的一部分。
- en: In this recipe, we'll build a small inference server from scratch, and we'll
    focus on the technical challenges around bringing AI into production. We'll showcase
    how to develop a POC into a software solutions that is fit for production by being
    robust, scaling to demand, responding timely, and that you can update as fast
    as needed.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将从头开始构建一个小型推断服务器，并专注于将人工智能引入生产环境的技术挑战。我们将展示如何通过稳健性、按需扩展、及时响应的软件解决方案将POC开发成适合生产的解决方案，并且可以根据需要快速更新。
- en: Getting ready
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: We'll have to switch between the terminal and the Jupyter environment in this
    recipe. We'll create and log the model from the Jupyter environment. We'll control
    the `mlflow` server from the terminal. We will note which one is appropriate for
    each code block.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将在终端和Jupyter环境之间切换。我们将在Jupyter环境中创建和记录模型。我们将从终端控制`mlflow`服务器。我们会注意哪个代码块适合哪个环境。
- en: 'We''ll use `mlflow` in this recipe. Let''s install it from the terminal:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在这个示例中使用`mlflow`。让我们从终端安装它：
- en: '[PRE14]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: We'll assume you have conda installed. If not, please refer to the *Setting
    up a Jupyter environment* recipe in [Chapter 1](87098651-b37f-4b05-b0ee-878193f28b95.xhtml), *Getting
    Started with Artificial Intelligence in Python*, for detailed instructions.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我们假设您已经安装了conda。如果没有，请参考《Python人工智能入门》中的*设置Jupyter环境*一章，以获取详细说明。
- en: 'We can start our local `mlflow` server with a `sqlite` database backend for
    backend storage from the terminal like this:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以像这样从终端启动我们的本地`mlflow`服务器，使用`sqlite`数据库作为后端存储：
- en: '[PRE15]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: We should see a message that our server is listening at [http://0.0.0.0:5000](http://0.0.0.0:5000).
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该看到一条消息，指出我们的服务器正在监听[http://0.0.0.0:5000](http://0.0.0.0:5000)。
- en: This is where we can access this server from our browser. In the browser, we'll
    be able to compare and check different experiments, and see the metrics of our
    models.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们可以从浏览器访问此服务器的地方。在浏览器中，我们可以比较和检查不同的实验，并查看我们模型的指标。
- en: 'In the *There''s more...* section, we''ll do a quick demo of setting up a custom
    API using the `FastAPI` library. We''ll quickly install this library as well:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在*更多内容...*部分，我们将快速演示如何使用`FastAPI`库设置自定义API。我们也将快速安装此库：
- en: '[PRE16]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: With this, we are ready to go!
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这个，我们就准备好了！
- en: How to do it...
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实现...
- en: 'We''ll build a simple model from a **column-separated value** (**CSV**) file.
    We''ll try different modeling options, and compare them. Then we''ll deploy this
    model:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从一个**逗号分隔值**（**CSV**）文件中构建一个简单的模型。我们将尝试不同的建模选项，并进行比较。然后我们将部署这个模型：
- en: 'Downloading and preparing the dataset:'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载和准备数据集：
- en: 'We''ll download a dataset as a CSV file and prepare for training. The dataset
    chosen in this recipe is the Wine dataset, describing the quality of wine samples.
    We''ll download and read the wine-quality CSV file from the UCI ML archive:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将下载一个数据集作为CSV文件并准备进行训练。在这个示例中选择的数据集是葡萄酒数据集，描述了葡萄酒样本的质量。我们将从UCI ML存档中下载并读取葡萄酒质量的CSV文件：
- en: '[PRE17]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'We split the data into training and test sets. The predicted column is **column
    quality**:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将数据分割为训练集和测试集。预测列是**quality列**：
- en: '[PRE18]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Training with different hyperparameters:'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用不同的超参数进行训练：
- en: 'We can track as much as we like in the `mlflow` server. We can create a reporting
    function for performance metrics like this:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在`mlflow`服务器中跟踪我们喜欢的任何东西。我们可以创建一个用于性能指标报告的函数，如下所示：
- en: '[PRE19]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Before running our training, we need to register the `mlflow` library with
    the server:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行训练之前，我们需要将`mlflow`库注册到服务器上：
- en: '[PRE20]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: We set our server URI. We can also give our experiment a name.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 我们设置了我们的服务器URI。我们还可以给我们的实验起个名字。
- en: Each time we run the training set with different options, MLflow can log the
    results, including metrics, hyperparameters, the pickled model, and a definition
    as MLModel that captures library versions and creation time.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 每次我们使用不同选项运行训练集时，MLflow都可以记录结果，包括指标、超参数、被pickled的模型，以及作为MLModel捕获库版本和创建时间的定义。
- en: 'In our training function, we train on our training data, extracting metrics
    of our model over the test data. We need to choose the appropriate hyperparameters
    and metrics for comparison:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的训练函数中，我们在训练数据上训练，在测试数据上提取我们的模型指标。我们需要选择适合比较的适当超参数和指标：
- en: '[PRE21]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: We fit the model, extract our metrics, print them to the screen, log them to
    the `mlflow` server, and store the model artifact on the server as well.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们拟合模型，提取我们的指标，将它们打印到屏幕上，在`mlflow`服务器上记录它们，并将模型工件存储在服务器上。
- en: 'For convenience, we are exposing our model hyperparameter in the `train()`
    function. We chose to log all the hyperparameters with `mlflow`. Alternatively,
    we could have logged only store-relevant parameters like this: `mlflow.log_param(''alpha'',
    alpha)`.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 为了方便起见，我们在`train()`函数中暴露了我们的模型超参数。我们选择使用`mlflow`记录所有超参数。或者，我们也可以仅记录像这样与存储相关的参数：`mlflow.log_param('alpha',
    alpha)`。
- en: We could also calculate more artifacts to accompany our model, for example,
    variable importance.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以计算更多伴随模型的工件，例如变量重要性。
- en: 'We can also try with different hyperparameters, for example, as follows:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以尝试使用不同的超参数，例如以下方式：
- en: '[PRE22]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'We should get the performance metrics as an output:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该得到性能指标作为输出：
- en: '[PRE23]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: After we've run this for a number of times with different parameters, we can
    go to our server, compare model runs, and choose a model for deployment.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们使用不同参数多次运行之后，我们可以转到我们的服务器，比较模型运行，并选择一个模型进行部署。
- en: Deploying a model as a local server. We can compare our models in the browser.
    We should be able to find our wine experiments under the experiments tab on our
    server.
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将模型部署为本地服务器。我们可以在浏览器中比较我们的模型。我们应该能够在服务器的实验选项卡下找到我们的葡萄酒实验。
- en: 'We can then compare different model runs in the overview table, or get an overview
    plot for different hyperparameters, such as this:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以在概述表中比较不同模型运行，或者获取不同超参数的概述图，例如这样：
- en: '![](img/72165e28-19c7-4ee2-b5b9-91375c757cec.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![](img/72165e28-19c7-4ee2-b5b9-91375c757cec.png)'
- en: This contour plot shows us the two hyperparameters we've changed against the
    **Mean Average Error** (**MAE**).
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 这个等高线图向我们展示了我们针对**平均绝对误差**（**MAE**）改变的两个超参数。
- en: 'We can then choose a model for deployment. We can see the run ID for our best
    model. Deployment of a model to a server can be done from the command line, for
    example, like this:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以选择一个模型进行部署。我们可以看到我们最佳模型的运行ID。可以通过命令行将模型部署到服务器，例如像这样：
- en: '[PRE24]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'We can pass data as JSON, for example, using curl, again from the terminal.
    This could look as follows:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将数据作为JSON传递，例如使用curl，同样是从终端。这可能看起来像这样：
- en: '[PRE25]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: With this, we've finished our demo of model deployment with `mlflow`.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这个，我们完成了使用`mlflow`进行模型部署的演示。
- en: How it works...
  id: totrans-140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理是这样的...
- en: 'The basic workflow for productionizing a model is as follows:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 将模型产品化的基本工作流程如下：
- en: Train a model on data.
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在数据上训练模型。
- en: Package the model itself in a reusable and reproducible model format together
    with glue code that extracts a prediction from the model.
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将模型本身打包为可重复使用和可再现的模型格式，以及提取模型预测的胶水代码。
- en: Deploy the model in an HTTP server that will enable you to score predictions.
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将模型部署在启用您进行预测评分的HTTP服务器中。
- en: This typically results in a microservice that communicates via JSON (usually
    this is then called a RESTful service) or GRPC (remote procedure calls via Google's
    protocol buffers). This has the advantage of being able to disentangle shipping
    of the decisioning intelligence from the backend, and have ML experts take full
    ownership of their solution.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 这通常导致一个通过JSON通信的微服务（通常这被称为RESTful服务）或GRPC（通过Google的协议缓冲区进行远程过程调用）。这具有将决策智能从后端分离出来，并让ML专家完全负责他们的解决方案的优势。
- en: A **microservice** is a single service that is independently deployable, maintainable,
    and testable. Structuring an application as a collection of loosely coupled microservices
    is called a **microservice**** architecture.**
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '**微服务** 是一个可以独立部署、维护和测试的单个服务。将应用程序结构化为一组松散耦合的微服务称为**微服务架构**。'
- en: 'Another route would be to package your model and glue code for deployment within
    the existing enterprise backend of your company. This integration has several
    alternatives:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种方法是将您的模型和粘合代码打包部署到公司现有企业后端中。此集成有几种替代方案：
- en: In model interchange formats such as the **Predictive Model Markup Language**
    (**PMML**), a format developed by a group of organizations under the umbrella
    of the Data Mining Group.
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在诸如**预测模型标记语言**（**PMML**）等模型交换格式中，这是由数据挖掘组织联合开发的一种格式。
- en: Some software implementations, such as LightGBM, XGBoost, or TensorFlow have
    APIs in multiple programming languages, so that models can be developed in Python,
    and loaded up from languages such as C, C++, or Java.
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一些软件实现，如LightGBM、XGBoost或TensorFlow，具有多种编程语言的API，因此可以在Python中开发模型，并从诸如C、C++或Java等语言中加载。
- en: 'Re-engineering your model:'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重新工程化您的模型：
- en: Some tools can help to convert models such as decision trees into C or other
    languages.
  id: totrans-151
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一些工具可以帮助将决策树等模型转换为C或其他语言。
- en: This can be done manually as well.
  id: totrans-152
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这也可以手动完成。
- en: MLflow has command-line, Python, R, Java, and REST API interfaces for uploading
    models to a model repository, for logging model results (**experiments**), for uploading
    models to a model repository, for downloading them again to use them locally,
    for controlling the server, and much more. It offers a server, however, that also
    allows deployment to Azure ML, Amazon Sagemaker, Apache Spark UDF, and RedisAI.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: MLflow具有命令行、Python、R、Java和REST API接口，用于将模型上传到模型库，记录模型结果（**实验**），再次下载以便在本地使用，控制服务器等等。它提供了一个服务器，还允许部署到Azure
    ML、Amazon Sagemaker、Apache Spark UDF和RedisAI。
- en: If you want to be able to access your `mlflow` server remotely, such as the
    case usually when using the model server as an independent service (microservice),
    we want to set the root to `0.0.0.0`, as we've done in the recipe. By default,
    the local server will start up at `http://127.0.0.1:5000`.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您希望能够远程访问您的`mlflow`服务器，例如通常在将模型服务器作为独立服务（微服务）时的情况，我们希望将根设置为`0.0.0.0`，就像我们在示例中所做的那样。默认情况下，本地服务器将在`http://127.0.0.1:5000`上启动。
- en: If we want to access models, we need to switch from the default backend storage (this
    is where metrics will be stored) to a database backend, and we have to define
    our artifact storage using a protocol in the URI, such as `file://$PWD/mlruns` for
    the local `mlruns/` directory. We've enabled a SQLite database for the backend,
    which is the easiest way (but probably not the best for production). We could
    have chosen MySQL Postgres, or another database backend as well.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想要访问模型，我们需要从默认的后端存储（这是存储指标的地方）切换到数据库后端，并且我们必须使用URI中的协议定义我们的工件存储，例如对于本地`mlruns/`目录，使用`file://$PWD/mlruns`。我们已经启用了后端的SQLite数据库，这是最简单的方式（但可能不适合生产环境）。我们也可以选择MySQL、Postgres或其他数据库后端。
- en: This is only part of the challenge, however, because models become stale or
    might be unsuitable, facts we can only establish if we are equipped to monitor
    model and server performance in deployment. Therefore, a note on monitoring is
    in order.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这只是挑战的一部分，因为模型可能变得陈旧或不适用，这些事实只有在我们具备监视部署中模型和服务器性能的能力时才能确认。因此，需要关注监控问题。
- en: Monitoring
  id: totrans-157
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 监控
- en: 'When monitoring AI solutions, what we are especially interested in are metrics
    that are either operational or relate to appropriate decision making. Metrics
    of the former kind are as follows:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在监控AI解决方案时，我们特别关注的是操作性或与适当决策相关的指标。前一种类型的指标如下：
- en: '**Latency** – How long does it take to perform a prediction on data?'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**延迟** – 在数据上执行预测需要多长时间？'
- en: '**Throughput** – How many data points can we process in any timeframe?'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**吞吐量** – 我们能在任何时间段内处理多少数据点？'
- en: '**Resource usage** – How much CPU, memory, and disk space do we allocate when
    completing inference?'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**资源使用率** – 在完成推理时，我们分配了多少 CPU、内存和磁盘空间？'
- en: 'The following metrics could form part of monitoring the decision-making process:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 以下指标可以作为监控决策过程的一部分：
- en: Statistical indicators, such as averages, variances of predictions over a certain
    period of time
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 统计指标，例如在一定时间内预测的平均值和方差
- en: Outlier and drift detection
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 异常值和漂移检测
- en: The business impact of decisions
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 决策的业务影响
- en: For methods to detect outliers, please refer to the *Discovering anomalies* recipe in
    [Chapter 3](424f3988-2d11-4098-9c52-beb685a6ed27.xhtml), *Patterns, Outliers,
    and Recommendations*.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解检测异常值的方法，请参阅[第 3 章](424f3988-2d11-4098-9c52-beb685a6ed27.xhtml)中的*发现异常*配方，*模式、异常值和推荐*。
- en: Standalone monitoring could be built from scratch following a template similar
    to the *Visualizing model results* recipe in this chapter, or be integrated with
    more specialist monitoring solutions, such as Prometheus, Grafana, or Kibana (for
    log monitoring).
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 可以从头开始构建独立的监控，类似于本章中*可视化模型结果*的模板，或者与更专业的监控解决方案集成，如 Prometheus、Grafana 或 Kibana（用于日志监控）。
- en: See also
  id: totrans-168
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参阅
- en: 'This is a very broad topic, and we''ve mentioned many aspects of productionization
    in the *How it works...* section of this recipe. There are many competing industrial-strength
    solutions for ML and **deep learning** (**DL**) models, and we can only try to
    give an overview given the space constraint. As always in this book, we''ll be
    mostly concentrating on open source solutions that will avoid a vendor lock-in:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个非常广泛的话题，在本文档的*工作原理……*部分中提到了许多生产化方面。在 ML 和**深度学习**（**DL**）模型中有许多竞争激烈的工业级解决方案，考虑到空间限制，我们只能尝试给出一个概述。像往常一样，在本书中，我们主要集中于避免供应商锁定的开源解决方案：
- en: MLflow aspires to manage the whole ML life cycle, including experimentation,
    reproducibility, deployment, and a central model registry: [https://mlflow.org/](https://mlflow.org/).
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MLflow 致力于管理整个 ML 生命周期，包括实验、可复现性、部署和中心化模型注册：[https://mlflow.org/](https://mlflow.org/)。
- en: BentoML creates a high-performance API endpoint serving trained models: [https://github.com/bentoml/bentoml](https://github.com/bentoml/bentoml).
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: BentoML 创建一个高性能 API 端点，用于提供训练好的模型：[https://github.com/bentoml/bentoml](https://github.com/bentoml/bentoml)。
- en: While some tools support only one or a few modeling frameworks, others, particularly
    BentoML and MLflow, support deploying models trained under all major ML training
    frameworks such as FastAI, scikit-learn, PyTorch, Keras, XGBoost, LightGBM, H2o,
    FastText, Spacy, and ONNX. Both of these further provide maximum flexibility for
    anything created in Python, and they both have a tracking functionality for monitoring.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然某些工具只支持一个或少数几个建模框架，但其他工具，特别是 BentoML 和 MLflow，支持部署在所有主要 ML 训练框架下训练的模型。这两者提供了在
    Python 中创建的任何东西的最大灵活性，并且它们都具有用于监控的跟踪功能。
- en: Our recipe was adapted from the `mlflow` tutorial example. MLflow has many more
    examples for different modeling framework integrations on GitHub: [https://github.com/mlflow/mlflow/](https://github.com/mlflow/mlflow/).
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的配方是从 `mlflow` 教程示例中调整的。MLflow 在 GitHub 上有更多不同建模框架集成的示例：[https://github.com/mlflow/mlflow/](https://github.com/mlflow/mlflow/)。
- en: 'Other tools include the following:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 其他工具包括以下内容：
- en: Elyra is a cloud-based deployment solution for Jupyter notebooks that comes
    with a visual data flow editor: [https://elyra.readthedocs.io/en/latest/index.html](https://elyra.readthedocs.io/en/latest/index.html).
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Elyra 是一个基于云的 Jupyter 笔记本部署解决方案，配备了可视化数据流编辑器：[https://elyra.readthedocs.io/en/latest/index.html](https://elyra.readthedocs.io/en/latest/index.html)。
- en: RedisAI is a Redis module for executing DL/ML models and managing their data: [https://oss.redislabs.com/redisai/](https://oss.redislabs.com/redisai/).
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RedisAI 是一个用于执行 DL/ML 模型和管理它们数据的 Redis 模块：[https://oss.redislabs.com/redisai/](https://oss.redislabs.com/redisai/)。
- en: TFX is a Google production-scale ML platform: [https://www.tensorflow.org/tfx/guide](https://www.tensorflow.org/tfx/guide).
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TFX 是一个由 Google 推出的生产级 ML 平台：[https://www.tensorflow.org/tfx/guide](https://www.tensorflow.org/tfx/guide)。
- en: TorchServe is a tool for serving PyTorch models: [https://pytorch.org/serve/](https://pytorch.org/serve/).
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TorchServe 是一个用于服务 PyTorch 模型的工具：[https://pytorch.org/serve/](https://pytorch.org/serve/)。
- en: 'Furthermore, there are many libraries available for creating custom microservices.
    Two of the most popular such libraries are these:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，还有许多库可用于创建自定义微服务。其中最受欢迎的两个库是：
- en: Flask: [https://palletsprojects.com/p/flask/](https://palletsprojects.com/p/flask/)
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Flask：[https://palletsprojects.com/p/flask/](https://palletsprojects.com/p/flask/)
- en: FastAPI: [https://fastapi.tiangolo.com/](https://fastapi.tiangolo.com/)
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: FastAPI：[https://fastapi.tiangolo.com/](https://fastapi.tiangolo.com/)
- en: Using these, you can create endpoints that would take data such as images or
    text and return a prediction.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这些，您可以创建端点，该端点可以接收像图像或文本这样的数据，并返回预测结果。
- en: Securing a model against attack
  id: totrans-183
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 保护模型免受攻击
- en: '**Adversarial attacks** in ML refer to fooling a model by feeding input with
    the purpose of deceiving it. Examples of such attacks include adding perturbations
    to an image by changing a few pixels, thereby causing the classifier to misclassify
    the sample, or carrying t-shirts with certain patterns to evade person detectors
    (**adversarial t-shirts**). One particular kind of adversarial attack is a **privacy
    attack**, where a hacker can gain knowledge of the training dataset of the model,
    potentially exposing personal or sensitive information by membership inference
    attacks and model inversion attacks.'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '**对抗攻击**在机器学习中指的是通过输入欺骗模型的行为。这种攻击的示例包括通过改变几个像素向图像添加扰动，从而导致分类器误分类样本，或者携带特定图案的T恤以逃避人物检测器（**对抗T恤**）。一种特定的对抗攻击是**隐私攻击**，其中黑客可以通过成员推理攻击和模型反演攻击获取模型的训练数据集知识，从而可能暴露个人或敏感信息。'
- en: Privacy attacks are dangerous, particularly in domains such as medical or financial,
    where the training data can involve sensitive information (for example, a health
    status) and that is possibly traceable to an individual's identity. In this recipe,
    we'll build a model that is safe against privacy attacks, and therefore cannot
    be hacked.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 在医疗或金融等领域，隐私攻击尤为危险，因为训练数据可能涉及敏感信息（例如健康状态），并且可能可以追溯到个人身份。在本配方中，我们将构建一个免受隐私攻击的模型，因此无法被黑客攻击。
- en: Getting ready
  id: totrans-186
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'We''ll implement a PyTorch model, but we''ll rely on a script in the TensorFlow/privacy
    repository created and maintained by Nicolas Papernot and others. We''ll clone
    the repository as follows:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将实现一个PyTorch模型，但我们将依赖由Nicolas Papernot和其他人创建和维护的TensorFlow/privacy存储库中的脚本。我们将按以下步骤克隆存储库：
- en: '[PRE26]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Later during the recipe, we'll use the analysis script to calculate the privacy
    bounds of our model.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 配方后期，我们将使用分析脚本计算我们模型的隐私边界。
- en: How to do it...
  id: totrans-190
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: We'll have to define data loaders for teacher models and the student model.
    The teacher and student architectures are the same in our case. We'll train the
    teachers, and then we train the student from the aggregates of the teacher responses.
    We'll close with a privacy analysis executing the script from the privacy repository.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须为教师模型和学生模型定义数据加载器。在我们的情况下，教师和学生架构相同。我们将训练教师，然后从教师响应的聚合训练学生。我们将最终进行隐私分析，执行来自隐私存储库的脚本。
- en: 'This is adapted from a notebook by Diego Muñoz that is available on GitHub: [https://github.com/dimun/pate_torch](https://github.com/dimun/pate_torch):'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 这是从Diego Muñoz的GitHub笔记本调整而来的：[https://github.com/dimun/pate_torch](https://github.com/dimun/pate_torch)：
- en: 'Let''s start by loading the data. We''ll download the data using `torch` utility
    functions:'
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们从加载数据开始。我们将使用`torch`实用程序函数下载数据：
- en: '[PRE27]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: This will load the MNIST dataset, and may take a moment. The transform converts
    data to `torch.FloatTensor`. `train_data` and `test_data` define the loaders for
    training and test data, respectively.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 这将加载MNIST数据集，可能需要一段时间。转换将数据转换为`torch.FloatTensor`。`train_data`和`test_data`分别定义了训练和测试数据的加载器。
- en: Please refer to the *Recognizing clothing items* recipe in [Chapter 7](f386de9e-b56d-4b39-bf36-803860def385.xhtml), *Advanced
    Image Applications*, for a brief discussion of the MNIST dataset, and the *Generating
    images* recipe in the same chapter for another model using the dataset.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 请参阅[第7章](f386de9e-b56d-4b39-bf36-803860def385.xhtml)中的*识别服装项目*配方，简要讨论MNIST数据集，以及同一章节中的*生成图像*配方，用于使用该数据集的另一个模型。
- en: Please note that we'll define a few parameters in an ad hoc fashion throughout
    the recipe. Among these are `num_teachers` and `standard_deviation`. You'll see
    an explanation of the algorithm in the *How it works...* section and, hopefully,
    the parameters will make sense then.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们将在整个配方中以临时方式定义一些参数。其中包括`num_teachers`和`standard_deviation`。您将在*工作原理...*部分看到算法的解释，希望那时这些参数会变得合理。
- en: Another parameter, `num_workers`, defines the number of subprocesses to use
    for data loading. `batch_size` defines how many samples per batch to load.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个参数，`num_workers`，定义了用于数据加载的子进程数。`batch_size`定义了每批加载的样本数。
- en: 'We''ll define data loaders for the teachers:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将为教师定义数据加载器：
- en: '[PRE28]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: The `get_data_loaders()` function implements a simple partitioning algorithm
    that returns the right portion of the data needed by a given teacher out of a
    certain number of teachers. Each teacher model will get a disjoint subset of the
    training data.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '`get_data_loaders()`函数实现了一个简单的分区算法，返回给定教师所需的数据部分。每个教师模型将获取训练数据的不相交子集。'
- en: 'We define a training set for the student of 9,000 training samples and 1,000
    test samples. Both sets are taken from the teachers'' test dataset as unlabeled
    training points – they will be labeled using the teacher predictions:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为学生定义一个训练集，包括9000个训练样本和1000个测试样本。这两个集合都来自教师的测试数据集，作为未标记的训练点 - 将使用教师的预测进行标记：
- en: '[PRE29]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Defining the models: We are going to define a single model for all the teachers:'
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义模型：我们将为所有教师定义一个单一模型：
- en: '[PRE30]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: This is a convolutional neural network for image processing. Please refer to
    [Chapter 7](f386de9e-b56d-4b39-bf36-803860def385.xhtml), *Advanced Image Applications*,
    for more image processing models.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 这是用于图像处理的卷积神经网络。请参阅[第7章](f386de9e-b56d-4b39-bf36-803860def385.xhtml)，*高级图像应用*，了解更多图像处理模型。
- en: 'Let''s create another utility function for prediction from these models given
    a `dataloader`:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们为预测创建另一个工具函数，给定一个`dataloader`：
- en: '[PRE31]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: We can now start training the teachers.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以开始训练教师。
- en: 'Training the teacher models:'
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练教师模型：
- en: 'First, we''ll implement a function to train the models:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将实现一个训练模型的函数：
- en: '[PRE32]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'We are now ready to train our teachers:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们准备训练我们的教师：
- en: '[PRE33]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: This instantiates and trains the models for each teacher.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 这将实例化并训练每个教师的模型。
- en: 'Training the student:'
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练学生：
- en: 'For the student, we require an aggregation function. You can see an explanation
    of the aggregation function in the *How it works...* section:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 对于学生，我们需要一个聚合函数。您可以在*工作原理...*部分看到聚合函数的解释：
- en: '[PRE34]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: The `aggregated_teacher()` function makes the predictions for all the teachers,
    counts the votes, and adds noise. Finally, it returns the votes and the results aggregated
    by `argmax`.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '`aggregated_teacher()`函数为所有教师做出预测，计数投票，并添加噪声。最后，它通过`argmax`返回投票和结果的聚合。'
- en: '`standard_deviation` defines the standard deviation for noise. This is important
    for the privacy guarantees.'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: '`standard_deviation`定义了噪声的标准差。这对隐私保证至关重要。'
- en: 'The student requires a data loader first:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 学生首先需要一个数据加载器：
- en: '[PRE35]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'This student data loader will be fed the aggregated teacher label:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 这个学生数据加载器将被提供聚合的教师标签：
- en: '[PRE36]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: This runs the student training.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 这将运行学生训练。
- en: 'Some parts of this code have been omitted from the training loop for the sake
    of brevity. The validation looks like this:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 由于简洁起见，本代码中的某些部分已从训练循环中省略。验证如下所示：
- en: '[PRE37]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'The final training update reads as follows:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 最终的训练更新如下：
- en: '[PRE38]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'We see that it''s a good model: 95.2 percent accuracy on the test dataset.'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到这是一个好模型：在测试数据集上准确率为95.2%。
- en: 'Analyzing the privacy:'
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 分析隐私：
- en: In Papernot and others (2018), they detail how data-dependent differential privacy
    bounds can be computed to estimate the cost of training the student.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 在Papernot等人（2018）中，他们详细介绍了如何计算数据相关的差分隐私界限，以估算训练学生的成本。
- en: 'They provide a script to do this analysis based on the vote counts and the
    used standard deviation of the noise. We''ve clone this repository earlier, so
    we can change into a directory within it, and execute the analysis script:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 他们提供了一个基于投票计数和噪声标准差的分析脚本。我们之前克隆了这个仓库，因此可以切换到其中一个目录，并执行分析脚本：
- en: '[PRE39]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'We need to save the aggregated teacher counts as a NumPy file. This can then
    be loaded by the analysis script:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要将聚合后的教师计数保存为一个NumPy文件。然后可以通过分析脚本加载它：
- en: '[PRE40]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: This puts together the `counts` matrix, and saves it as a file.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 这将`counts`矩阵放在一起，并将其保存为文件。
- en: 'Finally, we call the privacy analysis script:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们调用隐私分析脚本：
- en: '[PRE41]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: The epsilon privacy guarantee is estimated at 34.226 (data-independent) and 6.998
    (data-dependent). The epsilon value is not intuitive by itself, but needs an interpretation
    in the context of the dataset and its dimensions.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 隐私保证的ε估计为34.226（数据独立）和6.998（数据相关）。ε值本身并不直观，但需要在数据集及其维度的背景下进行解释。
- en: How it works...
  id: totrans-241
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理...
- en: We've created a set of teacher models from a dataset, and then we bootstrapped
    from these teachers a student model that gives privacy guarantees. In this section,
    we'll discuss some background about the problem of privacy in ML, differential
    privacy, and how PATE works.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从数据集中创建了一组教师模型，然后从这些教师模型中引导出了一个能提供隐私保证的学生模型。在本节中，我们将讨论机器学习中隐私问题的一些背景，差分隐私，以及PATE的工作原理。
- en: Leaking data about customers can bring great reputational damage to a company,
    not to speak of fees from the regulator for being in violation of data protection
    and privacy laws such as GDPR. Therefore, considering privacy in the creation
    of datasets and in ML is as important as ever. As a point in case, data of 500,000
    users from the well-known Netflix prize dataset for recommender development was
    de-anonymized by co-referencing them to publicly available Amazon reviews.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 泄露客户数据可能会给公司带来严重的声誉损失，更不用说因违反数据保护和隐私法（如GDPR）而遭到监管机构处罚的费用。因此，在数据集的创建和机器学习中考虑隐私问题至关重要。作为一个例子，来自著名的Netflix奖数据集的50万用户的数据通过与公开可用的亚马逊评论的关联而被重新匿名化。
- en: While a combination of a few columns could give too much away about specific
    individuals, for example, an address or postcode together with the age would be
    a give-away for anyone trying to trace data, ML models created on top of such
    datasets can be insecure as well. ML models can potentially leak sensitive information
    when hit by attacks such as membership inference attacks and model inversion attacks.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管几列的组合可能泄露特定个体的太多信息，例如，地址或邮政编码再加上年龄，对于试图追踪数据的人来说是一个线索，但是建立在这些数据集之上的机器学习模型也可能不安全。当遭受成员推断攻击和模型反演攻击等攻击时，机器学习模型可能会泄漏敏感信息。
- en: '**Membership attacks** consist, roughly speaking, of recognizing differences
    in the target model''s predictions on inputs that it was trained on compared to
    inputs that it wasn''t trained on. You can find out more about membership attacks
    from the paper *Membership Inference Attacks against Machine Learning Models* (Reza
    Shokri and others, 2016). They showed that off-the-shelf models provided as a
    service by Google and others can be vulnerable to these attacks.'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: '**成员攻击** 大致上是识别目标模型在训练输入上的预测与在未经训练的输入上的预测之间的差异。您可以从论文*针对机器学习模型的成员推断攻击*（Reza
    Shokri等人，2016）了解更多信息。他们表明，Google等公司提供的现成模型可能容易受到这些攻击的威胁。'
- en: 'In **inversion attacks**, given API or black box access to a model and some
    demographic information, the samples used in the model training can be reconstructed.
    In a particularly impressive example, faces used for training facial recognition
    models were reconstructed. Of even greater concern, Matthew Fredrikson and others
    showed that models in personalized medicine can expose sensitive genomic information
    about individuals (*Privacy in pharmacogenetics*: *An end-to-end case study of
    personalized warfarin dosing*; 2014)'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 在**反演攻击**中，通过API或黑盒访问模型以及一些人口统计信息，可以重建用于训练模型的样本。在一个特别引人注目的例子中，用于训练人脸识别模型的面部被重建了。更令人关注的是，Matthew
    Fredrikson等人表明，个性化药物基因组学模型可以暴露个体的敏感基因信息（*个性化华法林剂量定制的隐私*：*个案研究；2014*）。
- en: '**Differential privacy** (**DP**) mechanisms can prevent model inversion and
    membership attacks. In the next sections, we''ll be talking about DP and then
    about PATE.'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: '**差分隐私** (**DP**) 机制可以防止模型反演和成员攻击。接下来的部分，我们将讨论差分隐私，然后是关于PATE的内容。'
- en: Differential privacy
  id: totrans-248
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 差分隐私
- en: The concept of DP, first formulated by Cynthia Dwork and others in 2006 (*Calibrating
    Noise to Sensitivity in Private Data Analysis*), is the gold standard for privacy
    in ML. It centers around the influence of individual data points on the decisions
    of an algorithm. Roughly speaking, this implies, in turn, that any output from
    the model wouldn't give away whether an individual’s information was included. In
    DP, data is perturbed with the noise of a certain distribution. This not only
    can lead to safety against privacy attacks, but also to less overfitting.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 差分隐私的概念，最初由Cynthia Dwork等人在2006年提出（*在私有数据分析中校准噪声和灵敏度*），是机器学习中隐私的金标准。它集中在个体数据点对算法决策的影响上。大致而言，这意味着，模型的任何输出都不会泄露是否包含了个人信息。在差分隐私中，数据会被某种分布的噪声干扰。这不仅可以提供防止隐私攻击的安全性，还可以减少过拟合的可能性。
- en: In order to properly explain DP, we need to introduce the notion of a neighboring
    database (think *dataset*), which is a database that only differs in a single
    row or, in other words, a single individual. Two datasets, ![](img/55700e1a-0f83-4775-8c1c-fbc3caa7aeb0.png),
    differ only in the fact that ![](img/2a14b3c8-c40c-42b5-89be-c929571c7d56.png) and ![](img/9785a1e6-2768-4195-959c-67271285d237.png).
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 为了正确解释差分隐私，我们需要介绍邻近数据库（类似*数据集*）的概念，这是一个只在单个行或者说单个个体上有所不同的数据库。两个数据集，![](img/55700e1a-0f83-4775-8c1c-fbc3caa7aeb0.png)，仅在![](img/2a14b3c8-c40c-42b5-89be-c929571c7d56.png)和![](img/9785a1e6-2768-4195-959c-67271285d237.png)事实上的不同之处。
- en: 'The key is then to set an upper bound to require nearly identical behavior
    of the mapping (or mechanism) ![](img/ac721097-c2e1-4ff1-8681-e7dca18cf7e7.png) on
    neighboring databases:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 关键是设定一个上限要求映射（或机制）在相邻数据库上的行为几乎完全相同！[](img/ac721097-c2e1-4ff1-8681-e7dca18cf7e7.png)。
- en: '![](img/159ecea7-78ce-4908-b2c3-1d1dd77a4fdc.png)'
  id: totrans-252
  prefs: []
  type: TYPE_IMG
  zh: '![](img/159ecea7-78ce-4908-b2c3-1d1dd77a4fdc.png)'
- en: This is called the epsilon-delta parametrized DP for an algorithm, ![](img/9c8f6557-cc19-4c1f-ba59-9d7eaf478a25.png), on
    any neighboring databases ![](img/f0c7a900-7bd1-4625-bf25-8c5aafc0764d.png), and
    any subsets ![](img/e22dc4a5-e34e-4811-b770-361205818947.png) of outcomes ![](img/a0d85543-c836-44f7-b342-dbf5d81c5656.png).
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 这被称为算法的epsilon-delta参数化差分隐私，![](img/9c8f6557-cc19-4c1f-ba59-9d7eaf478a25.png)，在任何邻近数据库![](img/f0c7a900-7bd1-4625-bf25-8c5aafc0764d.png)和任何结果![](img/e22dc4a5-e34e-4811-b770-361205818947.png)子集![](img/a0d85543-c836-44f7-b342-dbf5d81c5656.png)上。
- en: In this formulation, the epsilon parameter is the multiplicative guarantee,
    and the delta parameter the additive guarantee of probabilistically almost exact
    outcomes. This means the DP cost that an individual incurs as a result of their
    data being used is minimal. Delta privacy can be seen as a subset or the special
    case, where epsilon is *0*, and epsilon privacy as the case, where delta is *0*.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个表述中，epsilon参数是乘法保证，delta参数是概率几乎完全准确结果的加法保证。这意味着个人由于其数据被使用而产生的差异隐私成本是最小的。Delta隐私可以被视为epsilon为*0*的子集或特殊情况，而epsilon隐私则是delta为*0*的情况。
- en: 'These guarantees are achieved by masking small changes in the input data. For
    example, a simple routine for this masking was described by Stanley L. Warner
    in 1965 (*Randomized response: A survey technique for eliminating evasive answer
    bias*). Respondents in surveys answer sensitive questions such as *Have you had
    an abortion?* either truthfully or deterministically according to coin flips:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 这些保证是通过掩盖输入数据中的微小变化来实现的。例如，斯坦利·L·沃纳在1965年描述了这种掩盖的简单程序（*随机化响应：消除逃避性答案偏差的调查技术*）。调查中的受访者对敏感问题如*你有过堕胎吗？*以真实方式或根据硬币翻转决定：
- en: Flip a coin.
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 抛一枚硬币。
- en: 'If tails, respond truthfully: no.'
  id: totrans-257
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果反面，真实回答：没有。
- en: If heads, flip a second coin and respond *yes* if heads, or respond *no* if
    tails.
  id: totrans-258
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果正面，再翻一枚硬币，如果正面回答*是*，如果反面回答*否*。
- en: This gives plausible deniability.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 这提供了合理的否认能力。
- en: Private aggregation of teacher ensembles
  id: totrans-260
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 教师集合的私有聚合
- en: Based on the paper *Semi-supervised Knowledge Transfer for Deep Learning from
    Private Training Data*, by Nicolas Papernot and others (2017), the **Private Aggregation
    of Teacher Ensembles** (**PATE**) technique relies on the noisy aggregation of
    teachers. In 2018, Nicolas Papernot and others (*Scalable private learning with
    PATE*) refined the 2017 framework, improving both the accuracy and privacy of
    the combined model. They further demonstrated the applicability of the PATE framework to large-scale,
    real-world datasets.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 基于Nicolas Papernot等人（2017）的论文*来自私有训练数据的半监督知识转移*，**教师集合的私有聚合**（**PATE**）技术依赖于教师的嘈杂聚合。2018年，Nicolas
    Papernot等人（*具有PATE的可扩展私有学习*）改进了2017年的框架，提高了组合模型的准确性和隐私性。他们进一步展示了PATE框架在大规模、真实世界数据集中的适用性。
- en: 'The PATE training follows this procedure:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: PATE训练遵循这个过程：
- en: An ensemble of models (**teacher models**) is created based on different datasets
    with no training examples in common.
  id: totrans-263
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 基于不共享训练示例的不同数据集创建了模型集合（**教师模型**）。
- en: A student model is trained based on querying noisy aggregate decisions of the
    teacher models.
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 学生模型是基于查询教师模型的嘈杂聚合决策进行训练。
- en: Only the student model can be published, not the teacher models.
  id: totrans-265
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 只能发布学生模型，而不能发布教师模型。
- en: As mentioned, each teacher is trained on disjointed subsets of the dataset.
    The intuition is that if teachers agree on how to classify a new input example,
    then the aggregate decision does not reveal information about any single training
    example.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 正如提到的，每个教师都在数据集的不相交子集上训练。直觉上，如果教师们就如何对新的输入样本进行分类达成一致意见，那么集体决策不会透露任何单个训练样本的信息。
- en: 'The aggregate mechanism in queries includes **Gaussian NoisyMax** (**GNMax**),
    an argmax with Gaussian noise, ![](img/975cbb64-614f-4915-a4de-44635c8bee5b.png), defined
    as follows:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 查询中的聚合机制包括**Gaussian NoisyMax**（**GNMax**），具有高斯噪声的argmax，如下所定义：![](img/975cbb64-614f-4915-a4de-44635c8bee5b.png)。
- en: '![](img/0ac6440c-ab4d-4e7f-b6a7-cc7c72c2d0d6.png)'
  id: totrans-268
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0ac6440c-ab4d-4e7f-b6a7-cc7c72c2d0d6.png)'
- en: This has a data point ![](img/de7e5935-dcdc-4fdb-912a-0937f3558686.png), classes ![](img/f5a8f67f-93ce-4c48-bf39-f77d46115d19.png),
    and the vote ![](img/0811e4a1-0de7-4374-b6a3-37f988052e7a.png) of teacher ![](img/092eca96-251d-4e05-85c4-05cf49aa91aa.png) on x.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 这有一个数据点 ![](img/de7e5935-dcdc-4fdb-912a-0937f3558686.png)，类别 ![](img/f5a8f67f-93ce-4c48-bf39-f77d46115d19.png)，以及教师
    ![](img/092eca96-251d-4e05-85c4-05cf49aa91aa.png) 在 x 上的投票 ![](img/0811e4a1-0de7-4374-b6a3-37f988052e7a.png)。
- en: '![](img/2242b80b-3881-4650-8540-3f99f826c212.png) denotes the vote count for
    class ![](img/b9e69f5f-f720-4683-9e9a-f6a900dc7cf0.png):'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/2242b80b-3881-4650-8540-3f99f826c212.png) 表示类别 ![](img/b9e69f5f-f720-4683-9e9a-f6a900dc7cf0.png)
    的投票计数：'
- en: '![](img/9d0a05f3-2e88-4efe-9857-6b89ecc169d2.png)'
  id: totrans-271
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9d0a05f3-2e88-4efe-9857-6b89ecc169d2.png)'
- en: Intuitively, accuracy decreases with the variance of the noise, so the variance
    has to be chosen tight enough to provide good performance, but wide enough for
    privacy.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 直观上，准确性随噪声的方差增加而降低，因此方差必须选择足够紧密以提供良好的性能，但又足够宽以保护隐私。
- en: The epsilon value depends on the aggregation, particularly the noise level,
    but also on the context of the dataset and its dimensions. Please see *How Much
    is Enough? Choosing ![](img/ddf81d96-459b-48e2-88c3-a4bd813cc607.png) for Differential
    Privacy* (2011), by Jaewoo Lee and Chris Clifton, for a discussion.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: ε值取决于聚合，特别是噪声水平，还取决于数据集及其维度的上下文。请参阅*Jaewoo Lee和Chris Clifton的《多少是足够的？选择差分隐私的敏感性参数》*（2011年），以进行讨论。
- en: See also
  id: totrans-274
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: A detailed overview of the concepts in DP can be found in *The Algorithmic Foundations
    of Differential Privacy*, by Cynthia Dwork and Aaron Roth. Please see the second
    PATE paper (Nicolas Papernot and others 2018; [https://arxiv.org/pdf/1802.08908.pdf](https://arxiv.org/pdf/1802.08908.pdf)),
    the method of which we adopted for this recipe.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 关于DP概念的详细概述可以在*Cynthia Dwork和Aaron Roth的《差分隐私的算法基础》*中找到。请参阅我们为此配方采用的第二篇PATE论文（Nicolas
    Papernot等人2018年；[https://arxiv.org/pdf/1802.08908.pdf](https://arxiv.org/pdf/1802.08908.pdf)）。
- en: 'As for Python libraries concerning DP, a number are available:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 至于与DP相关的Python库，有许多选择：
- en: Opacus enables training PyTorch models with DP: [https://github.com/pytorch/opacus](https://github.com/pytorch/opacus).
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Opacus允许使用DP训练PyTorch模型：[https://github.com/pytorch/opacus](https://github.com/pytorch/opacus).
- en: PySyft works with PyTorch, TensorFlow, and Keras, and includes many mechanisms,
    including PATE: [https://github.com/OpenMined/PySyft](https://github.com/OpenMined/PySyft).
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PySyft适用于PyTorch，TensorFlow和Keras，包括许多机制，包括PATE：[https://github.com/OpenMined/PySyft](https://github.com/OpenMined/PySyft).
- en: TensorFlow's cleverhans library provides tools for benchmarking model vulnerability
    to adversarial attacks: [https://github.com/tensorflow/cleverhans](https://github.com/tensorflow/cleverhans).
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow的cleverhans库提供了用于评估模型对对抗攻击的工具：[https://github.com/tensorflow/cleverhans](https://github.com/tensorflow/cleverhans).
- en: TensorFlow's privacy repository contains optimizers and models related to DP.
    It also contains tutorials using different mechanisms, such as a DP Stochastic
    Gradient Descent, DP Adam Optimizer, or PATE, on the adult, IMDB, or other datasets: [https://github.com/tensorflow/privacy](https://github.com/tensorflow/privacy).
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow的隐私库包含与DP相关的优化器和模型。它还包含使用不同机制的教程，例如DP随机梯度下降，DP Adam优化器或PATE，适用于成人，IMDB或其他数据集：[https://github.com/tensorflow/privacy](https://github.com/tensorflow/privacy).
- en: 'There are frameworks for both TensorFlow and PyTorch for encrypted ML:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 有关TensorFlow和PyTorch的加密ML框架：
- en: tf-encrypted relates to privacy-preserving ML and encryption in TensorFlow: [tf-encrypted.io/](https://tf-encrypted.io/).
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: tf-encrypted涉及TensorFlow中的隐私保护ML和加密：[tf-encrypted.io/](https://tf-encrypted.io/).
- en: Facebook's CrypTen also relates to PyTorch, and includes the encryption of models
    and data: [https://github.com/facebookresearch/CrypTen](https://github.com/facebookresearch/CrypTen).
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Facebook的CrypTen也涉及PyTorch，包括对模型和数据的加密：[https://github.com/facebookresearch/CrypTen](https://github.com/facebookresearch/CrypTen).
