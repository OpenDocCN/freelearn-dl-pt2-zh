["```py\nimport tensorflow as tf\n# path to the trained TF model\ntrained_model_dir = \"s3://mybucket/tf_model\"\n# TFLiteConverter class is necessary for the conversion\nconverter = tf.lite.TFLiteConverter.from_saved_model(trained_model_dir)\ntfl_model = converter.convert()\n# save the converted model to TF Lite format \nwith open('model_name.tflite', 'wb') as f:\n  f.write(tfl_model)\n```", "```py\nimport torch\nfrom torch.utils.mobile_optimizer import optimize_for_mobile\n# load a trained PyTorch model\nsaved_model_file = \"model.pt\"\nmodel = torch.load(saved_model_file)\n# the model should be in evaluate mode for dropout and batch normalization layers\nmodel.eval()\n# convert the model into a TorchScript model and apply optimization for mobile environment\ntorchscript_model = torch.jit.script(model)\ntorchscript_model_optimized = optimize_for_mobile(torchscript_model)\n# save the optimized TorchScript model into a .pt file \ntorch.jit.save(torchscript_model_optimized, \"mobile_optimized.pt\")\n```", "```py\npod 'TensorFlowLiteSwift'\n```", "```py\n    import TensorFlowLite\n    ```", "```py\n    let interpreter = try Interpreter(modelPath: modelPath) \n    ```", "```py\n    let inputData: Data\n    inputData = ...\n    try self.interpreter.copy(inputData, toInputAt: 0)\n    ```", "```py\n    try self.interpreter.invoke()\n    ```", "```py\n    let outputTensor = try self.interpreter.output(at: 0)\n    let outputSize = outputTensor.shape.dimensions.reduce(1, {x, y in x * y})\n    let outputData = UnsafeMutableBufferPointer<Float32>.allocate(capacity: outputSize)\n    outputTensor.data.copyBytes(to: outputData)\n    ```", "```py\npod 'LibTorch_Lite', '~>1.10.0'\n```", "```py\n    #include \"TorchModule.h\"\n    ```", "```py\n    let modelPath = \"model_dir/torchscript_model.pt\"\n    let module = TorchModule(modelPath: modelPath)\n    ```", "```py\n    let inputData: Data\n    inputData = ...\n    let outputs = module.predict(input: UnsafeMutableRawPointer(&inputData))\n    ```", "```py\ndependencies {\n     implementation 'org.tensorflow:tensorflow-lite-support:0.3.1'\n}\n```", "```py\n    import org.tensorflow.lite.Interpreter;\n    ```", "```py\n    let tensorflowlite_model_path = \"tflitemodel.tflite\";\n    Interpreter = new Interpreter(tensorflowlite_model_path);\n    ```", "```py\n    Map<> input = new HashMap<>();\n    Input = ...\n    Map<> output = new HashMap<>();\n    interpreter.run(input, output);\n    ```", "```py\ndependencies {\n    implementation 'org.pytorch:pytorch_android_lite:1.11'\n}\n```", "```py\n    import org.pytorch.Module;\n    ```", "```py\n    let torchscript_model_path = \"model_dir/torchscript_model.pt\";\n    Module = Module.load(torchscript_model_path);\n    ```", "```py\n    Tensor outputTensor = module.forward(IValue.from(inputTensor)).toTensor();\n    ```"]