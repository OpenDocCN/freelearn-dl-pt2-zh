- en: Getting the Most out of PyTorch
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 充分利用PyTorch
- en: 'By now, you should be able to build and train three different types of model:
    linear, convolutional, and recurrent. You should have an appreciation of the theory
    and mathematics behind these model architectures and explain how they make predictions. Convolutional
    networks are probably the most studied deep learning network, especially in relation
    to image data. Of course, both convolutional and recurrent networks make extensive
    use of linear layers, so the theory behind linear networks, most notably linear
    regression and gradient descent, is fundamental to all artificial neural networks.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你应该能够构建和训练三种不同类型的模型：线性模型、卷积模型和循环模型。你应该对这些模型架构背后的理论和数学有所了解，并能解释它们如何进行预测。卷积网络可能是最研究的深度学习网络，特别是与图像数据相关的情况。当然，卷积网络和循环网络都广泛使用线性层，因此线性网络背后的理论，尤其是线性回归和梯度下降，对所有人工神经网络都是基础的。
- en: 'Our discussion so far has been fairly contained. We have looked at a well-studied
    problem, such as classification using MNIST, to give you a solid understanding
    of the basic PyTorch building blocks. This final chapter is the launching pad
    for your use of PyTorch in the real world, and after reading it you should be
    well placed to begin your own deep learning exploration. In this chapter, we will
    discuss the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 迄今为止，我们的讨论相当有限。我们已经研究了一个被广泛研究的问题，比如使用MNIST进行分类，以便让你对PyTorch的基本构建块有扎实的理解。这最后一章是你在现实世界中使用PyTorch的跳板，阅读完后，你应该可以开始自己的深度学习探索。在本章中，我们将讨论以下主题：
- en: Using **graphics processing units** (**GPUs**) to improve performance
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用**图形处理单元**（**GPUs**）以提高性能
- en: Optimization strategies and techniques
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 优化策略和技术
- en: Using pretrained models
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用预训练模型
- en: Multiprocessor and distributed environments
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多处理器和分布式环境
- en: There are a variety of multiprocessor and distributed environment possibilities.
    The most common reason for using more than one processor is, of course, to make
    models run faster. The time it takes to load MNIST—a relatively tiny dataset of
    60,000 images—to memory is not significant. However, consider the situation where
    we have giga or terabytes of data, or if the data is distributed across multiple
    servers. The situation is even more complex when we consider online models, where
    data is being harvested from multiple servers in real time. Clearly, some sort
    of parallel processing capability is required.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 有各种多处理器和分布式环境的可能性。使用多处理器的最常见原因当然是为了使模型运行更快。将MNIST加载到内存中的时间并不重要，因为它只是一个相对较小的数据集，包含6万张图像。然而，考虑到我们有吉格或者TB级别的数据，或者数据分布在多台服务器上的情况，情况会更加复杂。当考虑在线模型时，数据实时从多台服务器收集的情况更是如此。显然，这些情况都需要某种形式的并行处理能力。
- en: Using a GPU
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用GPU
- en: The simplest way to make a model run faster is to add GPUs. A significant reduction
    in training time can be achieved by transferring processor-intensive tasks from
    the **central processing unit** (**CPU**) to one or more GPUs. PyTorch uses the
    `torch.cuda()` module to interface with the GPUs. CUDA is a parallel computing
    model created by NVIDIA that features lazy assignment so that resources are only
    allocated when needed. The resulting efficiency gains are substantial.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 使模型运行更快的最简单方法是添加GPU。通过将处理器密集型任务从**中央处理单元**（**CPU**）转移到一个或多个GPU上，可以显著减少训练时间。PyTorch使用`torch.cuda()`模块与GPU进行接口交互。CUDA是由NVIDIA创建的并行计算模型，具有延迟分配功能，因此资源只在需要时分配。由此带来的效率提升是显著的。
- en: 'PyTorch uses a context manager, `torch.device()`, to assign tensors to a particular
    device. The following screenshot shows an example of this:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch使用上下文管理器`torch.device()`将张量分配给特定设备。以下截图展示了一个示例：
- en: '![](img/28f918be-0a58-4290-ac06-197935fad27d.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](img/28f918be-0a58-4290-ac06-197935fad27d.png)'
- en: 'It is a more usual practice to test for a GPU and assign a device to a variable
    using the following semantics:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 通常的做法是测试GPU的存在并使用以下语义将设备分配给变量：
- en: '[PRE0]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The `"cuda:0"` string refers to the default GPU device. Note that we test for
    the presence of a GPU device and assign it to the `device `variable. If a GPU
    device is unavailable, then the device is assigned to the CPU. This allows code
    to run on machines that may or may not have a GPU.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 字符串`"cuda:0"`指的是默认的GPU设备。请注意，我们会检查GPU设备的存在并将其分配给`device`变量。如果GPU设备不可用，则会将设备分配给CPU。这样可以使代码在可能有或没有GPU的机器上运行。
- en: Consider the linear model we explored in [Chapter 3](77e1b6da-e5d6-46a4-8a2c-ee1cfa686cc6.xhtml),
    *Computational Graphs and Linear Models*. We can use exactly the same model definition;
    however, we need to change a few things in our training code to ensure processor-intensive
    operations occur on the GPU. Once we have create our `device` variable, we can
    assign operations to that device.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑我们在[第3章](77e1b6da-e5d6-46a4-8a2c-ee1cfa686cc6.xhtml)中探讨的线性模型，*计算图和线性模型*。我们可以使用完全相同的模型定义；但是，我们需要在训练代码中做一些改变，以确保处理器密集型操作在GPU上执行。一旦创建了我们的`device`变量，我们可以将操作分配给该设备。
- en: 'In the benchmark function we created earlier, we need to add the following
    line of code after we initialize the model:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们之前创建的基准函数中，我们需要在初始化模型后添加以下代码行：
- en: '[PRE1]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We also need to ensure the operations on the images, labels, and outputs all
    occur on the selected device. In the `for` loop of the benchmark function, we
    make the following changes:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要确保对图像、标签和输出的操作都在选定的设备上进行。在基准函数的`for`循环中，我们进行如下更改：
- en: '![](img/027ab9e2-ba48-4ed2-a9bf-d43a566d05e4.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](img/027ab9e2-ba48-4ed2-a9bf-d43a566d05e4.png)'
- en: We need do to exactly the same thing for the images, labels, and outputs defined
    in our accuracy function, simply appending `.to(device)` to these tensor definitions.
    Once these changes have been made, if it is run on a system with a GPU, it should
    run noticeably faster. For a model with four linear layers, this code ran in just
    over 55 seconds, compared to over 120 seconds when run just on the CPU on my system.
    Of course, CPU speed, memory, and other factors contribute to running time, so
    these benchmarks will be different on different systems. The exact same training
    code will work for a logistic regression model. The same modifications also work
    for the training code for the other networks we have studied. Almost anything
    can be transferred to a GPU, but be aware that there is a computational expense
    incurred every time data is copied to the GPU, so do not unnecessarily transfer
    operations to the GPU unless a complex computation—for example, calculating a
    gradient—is involved.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要对在我们的准确度函数中定义的图像、标签和输出做完全相同的事情，只需将`.to(device)`附加到这些张量定义中。一旦做出这些更改，如果在具有GPU的系统上运行，速度应明显更快。对于具有四个线性层的模型，此代码运行时间仅稍逾55秒，而在我的系统上仅在CPU上运行时超过120秒。当然，CPU速度、内存和其他因素会影响运行时间，因此这些基准在不同系统上会有所不同。完全相同的训练代码将适用于逻辑回归模型。同样的修改也适用于我们研究过的其他网络的训练代码。几乎任何东西都可以传输到GPU，但请注意，每次数据复制到GPU时都会产生计算开销，因此除非涉及复杂的计算（例如计算梯度），否则不要不必要地将操作传输到GPU。
- en: 'If you have multiple GPUs available on your system, then `nn.DataParallel`
    can be used to transparently distribute operations across these GPUs. This can
    be as simple as using a wrapper around your model—for example, `model=torch.nn.DataParallel(model)`.
    We can of course use a more granular approach and assign specific operations to
    specific devices, as shown in the following example:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的系统上有多个GPU可用，则可以使用`nn.DataParallel`来透明地在这些GPU上分发操作。这可以简单地使用一个模型包装器来实现，例如，`model=torch.nn.DataParallel(model)`。当然，我们也可以采用更细粒度的方法，将特定操作分配给特定设备，如下例所示：
- en: '[PRE2]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: PyTorch has a specific memory space available to speed up the transfer of tensors
    to the GPU. This is used when a tensor is repeatedly allocated to a GPU. This
    is achieved using the `pin_memory()` function—for example, `w3.pin_memory()`.
    One of the major uses for this is to speed up the loading of input data, which
    occurs repeatedly over a model's training cycle. To do this, simply pass the `pin_memory=True` argument to
    the `DataLoader` object when it is instantiated.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch有一个特定的内存空间，可用于加速张量传输到GPU。当张量重复分配到GPU时使用此功能。使用`pin_memory()`函数实现，例如，`w3.pin_memory()`。其中一个主要用途是加速输入数据的加载，这在模型训练周期内反复发生。为此，只需在实例化`DataLoader`对象时传递`pin_memory=True`参数。
- en: Distributed environments
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分布式环境
- en: Sometimes, data and computing resources are not available on a single physical
    machine. This requires protocols for exchanging tensor data over a network. With
    distributed environments, where computations can occur on different kinds of physical
    hardware over a network, there are a large number of considerations—for example,
    network latencies or errors, processor availability, scheduling and timing issues,
    and competing processing resources. In an ANN, it is essential that calculations
    are produced in a certain order. The complex machinery for the assigning and timing
    of each computation across networks of machines and processors in each machine
    is, thankfully, largely hidden in PyTorch using higher-level interfaces.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，数据和计算资源不可用于单个物理机。这需要在网络上交换张量数据的协议。在分布式环境中，计算可以在不同类型的物理硬件上通过网络进行，有许多考虑因素，例如网络延迟或错误，处理器的可用性，调度和时间问题以及竞争的处理资源。在ANN中，计算必须按照一定的顺序进行。幸运的是，PyTorch使用更高级的接口大部分隐藏了跨机器和处理器网络的每个计算的分配和时间安排的复杂机制。
- en: 'PyTorch has two main packages, each of which deals the various aspects of distributed
    and parallel environments. This is in addition to CUDA, which we discussed previously.
    These packages are as follows:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch有两个主要的包，分别处理分布式和并行环境的各个方面。这是除了我们之前讨论的CUDA之外。这些包如下：
- en: '`torch.distributed`'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`torch.distributed`'
- en: '`torch.multiprocessing`'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`torch.multiprocessing`'
- en: torch.distributed
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '`torch.distributed`'
- en: 'Using `torch.distributed` is probably the most common approach. This package
    provides communication primitives, such as classes, to check the number of nodes
    in a network, ensure the availability of backend communication protocols, and
    initialize process groups. It works on the module level. The `torch.nn.parallel.DistributedDataParallel()` class is
    a container that wraps a PyTorch model, allowing it to inherit the functionality
    of `torch.distributed`. The most common use case involves multiple processes that
    each operate on their own GPU, either locally or over a network. A process group
    is initialized to a device using the following code:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`torch.distributed`可能是最常见的方法。此包提供通信原语，如类，以检查网络中的节点数，确保后端通信协议的可用性，并初始化进程组。它在模块级别上运行。`torch.nn.parallel.DistributedDataParallel()`类是一个容器，包装了一个PyTorch模型，使其继承`torch.distributed`的功能。最常见的用例涉及多个进程，每个进程在其自己的GPU上操作，可以是本地的也可以是网络上的。通过以下代码初始化进程组到设备：
- en: '[PRE3]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This is run on each host. The backend specifies what communication protocols
    to use. The NCCL (pronounced nickel) backend is generally the fastest and most
    reliable. Be aware that this may need to be installed on your system. The `world_size`
    is the number of processes in the job and the `init_method` is a URL pointing
    to location and port for the process to be initialized. This can either be a network
    address—for example, (`tcp://......`)—or a shared filesystem (`file://... /...`).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这在每个主机上运行。后端指定了要使用的通信协议。NCCL（发音为nickel）后端通常是最快且最可靠的。请注意，这可能需要安装在您的系统上。`world_size`是作业中的进程数，`init_method`是指向进程初始化位置和端口的URL。这可以是网络地址，例如（`tcp://...`），也可以是共享文件系统（`file://...
    /...`）。
- en: A device can be set using `torch.cuda.set_devices(i)`. Finally, we can assign
    the model by using the code phrase
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 通过`torch.cuda.set_devices(i)`可以设置设备。最后，我们可以使用以下代码短语来分配模型
- en: '`model = distributedDataParallel(model, device_ids=[i], output_device=i`. This
    is typically used in an initialization function that spawns each process and assigns
    it to a processor. This ensures that every process is coordinated through a master
    using the same IP address and port.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '`model = distributedDataParallel(model, device_ids=[i], output_device=i`。这通常用于生成每个进程并将其分配给处理器的初始化函数。这确保每个进程通过使用相同的IP地址和端口通过主进程协调。'
- en: torch.multiprocessing
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '`torch.multiprocessing`'
- en: The `torch.multiprocessor` package is a replacement for the Python multiprocessor
    package, and is used in exactly the same way, that is, as a process-based threading
    interface. One of the ways it extends the Python distributed package is by placing
    PyTorch tensors into shared memory and only sending their handles to other processes.
    This is achieved using a `multiprocessing.Queue` object. In general, multiprocessing
    occurs asynchronously; that is, processes for a particular device are enqueued
    and executed when the process reaches the top of the queue. Each device executes
    a process in the order that it is queued and PyTorch periodically synchronizes
    the multiple processes when copying between devices. This means that, as far as
    the caller of a multi-process function is concerned, the processes occur synchronously.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '`torch.multiprocessor` 包是 Python 多处理包的替代品，使用方式完全相同，即作为基于进程的线程接口。它通过将 PyTorch
    张量放入共享内存并仅发送其句柄到其他进程来扩展 Python 分布式包的方式之一。这是通过 `multiprocessing.Queue` 对象实现的。一般情况下，多进程是异步执行的；也就是说，特定设备的进程会被入队并在达到队列顶部时执行。每个设备按入队顺序执行进程，并且
    PyTorch 在设备间复制时定期同步多个进程。这意味着对于多进程函数的调用者来说，进程是同步进行的。'
- en: One of the major difficulties when writing multithreaded applications is avoiding
    deadlocking, where two processes compete for a single resource. A common reason
    for this is when background threads lock or import a module and a subprocess is
    forked. The subprocess will likely be spawned in a corrupted state, causing a
    deadlock or another error. The `multiprocessingQueue` class itself spawns multiple
    background threads to send, receive, and serialize objects, and these threads
    can also cause deadlocks. For these circumstances, the thread free `multiprocessingQueue.queues.SimpleQueue`
    can be used.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 编写多线程应用程序时的主要困难之一是避免死锁，即两个进程竞争一个资源的情况。这种常见情况是后台线程锁定或导入模块并分叉子进程时发生的。子进程很可能会以损坏的状态启动，导致死锁或其他错误。`multiprocessingQueue`
    类本身会生成多个后台线程来发送、接收和序列化对象，这些线程也可能导致死锁。对于这些情况，可以使用无线程的 `multiprocessingQueue.queues.SimpleQueue`。
- en: Optimization techniques
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 优化技术
- en: The `torch.optim` package contains a number of optimization algorithms, and
    each of these algorithms has several parameters that we can use to fine-tune deep
    learning models. Optimization is a critical component in deep learning, so it
    is no surprise that different optimization techniques can be key to a model's
    performance. Remember, its role is to store and update the parameter state based
    on the calculated gradients of the loss function.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '`torch.optim` 包含多种优化算法，每种算法都有几个参数可以用来微调深度学习模型。优化在深度学习中是一个关键组成部分，因此不同的优化技术对模型的性能可能至关重要。记住，它的作用是基于损失函数的计算梯度来存储和更新参数状态。'
- en: Optimizer algorithms
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 优化器算法
- en: 'There are a number of optimization algorithms besides SGD available in PyTorch.
    The following code shows one such algorithm:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 除了 SGD 外，PyTorch 中还提供了许多优化算法。以下代码展示了其中一种算法：
- en: '[PRE4]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The `Adedelta` algorithm is based on stochastic gradient descent; however,
    instead of having the same learning rate over each iteration, the learning rate
    adapts over time. The `Adadelta` algorithm maintains separate dynamic learning
    rates for each dimension. This can make training quicker and more efficient, as
    the overhead of calculating new learning rates on each iteration is quite small
    compared to actually calculating the gradients. The `Adadelta` algorithm performs
    well with noisy data for a range of model architectures, large gradients, and
    in distributed environments. The `Adadelta` algorithm is particularly effective
    with large models, and works well with large initial learning rates. There are
    two hyperparameters associated with `Adadelta` that we have not discussed yet.
    The `rho` is used to calculate the running averages of the squared gradients;
    this determines the decay rate. The `eps` hyperparameter is added to improve the
    numerical stability of `Adadelta`, as shown in the following code:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '`Adadelta` 算法基于随机梯度下降；然而，不同于每次迭代保持相同的学习率，学习率会随时间调整。`Adadelta` 算法为每个维度维护单独的动态学习率。这可以使训练更快速和更有效率，因为与计算梯度相比，计算新学习率的开销相当小。`Adadelta`
    算法在各种模型架构、大梯度和分布式环境中表现良好。`Adadelta` 算法特别适用于大型模型，并且在使用大初始学习率时效果显著。有两个与 `Adadelta`
    相关的超参数我们还没有讨论。`rho` 用于计算平方梯度的运行平均值，这决定了衰减率。`eps` 超参数用于提高 `Adadelta` 的数值稳定性，如下代码所示：'
- en: '[PRE5]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The `Adagrad` algorithm, or adaptive subgradient methods for stochastic optimization,
    is a technique that incorporates geometric knowledge of the training data observed
    in earlier iterations. This allows the algorithm to find infrequent, but highly
    predictive, features. The `Adagrad` algorithm uses an adaptive learning rate that
    give frequently occurring features low learning rates and rare features higher
    learning rates. This has the effect of finding rare but important features of
    the data and calculating each gradient step accordingly. The learning rate decreases
    faster over each iteration for more frequent features, and slower for rarer features,
    meaning that rare features tend to maintain higher learning rates over more iterations.
    The `Adagrad` algorithm tends to work best for sparse datasets. An example of
    its application is shown in the following code:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '`Adagrad` 算法，或者适应性次梯度方法用于随机优化，是一种技术，它融入了在先前迭代中观察到的训练数据的几何知识。这使得算法能够发现罕见但高度预测的特征。`Adagrad`
    算法使用自适应学习率，为频繁出现的特征赋予较低的学习率，为罕见特征赋予较高的学习率。这样做的效果是找到数据中罕见但重要的特征，并相应地计算每个梯度步长。学习率在每次迭代中对于更频繁出现的特征会更快地减小，对于罕见特征则减小得更慢，这意味着罕见特征在更多迭代中保持较高的学习率。`Adagrad`
    算法通常对于稀疏数据集效果最佳。其应用示例如下代码所示：'
- en: '[PRE6]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The `Adam` algorithm (adaptive moment estimation) uses an adaptive learning
    rate based on the mean and the uncentered variance (the first and second moments)
    of the gradient. Like `Adagrad`, it stores the average of past squared gradients.
    It also stores the decaying average of these gradients. It calculates the learning
    rate on each iteration on a per-dimension basis. The `Adam` algorithm combines
    the benefits of `Adagrad`, working well on sparse gradients, with the ability
    to work well in online and nonstationary settings. Note that `Adam` takes an optional
    tuple of beta parameters. These are coefficients that are used in the calculation
    of the running average and the square of these averages. The `amsgrad` flag, when
    set to `True`, enables a variant of `Adam` that incorporates the long-term memory
    of gradients. This can assist with the convergence, where, in certain situations,
    the standard `Adam` algorithm fails to converge. In addition to the `Adam` algorithm,
    PyTorch contains two variants of `Adam`. The `optim.SparseAdam` performs lazy
    updating of parameters, where only the moments that appear in the gradient get
    updated and applied to the parameters. This provides a more efficient way of working
    with sparse tensors, such as those used for word embedding. The second variant,
    `optim.Adamax`, uses the infinite norm to calculate the gradients, and this, theoretically,
    reduces its susceptibility to noise. In practice, the choice of the best optimizer
    is often a matter of trial and error.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '`Adam` 算法（自适应矩估计）根据梯度的均值和未居中方差（梯度的第一和第二时刻）使用自适应学习率。类似于 `Adagrad`，它存储过去平方梯度的平均值。它还存储这些梯度的衰减平均值。它在每次迭代时基于每个维度计算学习率。`Adam`
    算法结合了 `Adagrad` 的优点，对稀疏梯度效果显著，并且能够在在线和非静态设置中良好工作。请注意，`Adam` 可以接受一个可选的 beta 参数元组。这些系数用于计算运行平均值及其平方的平均值。当设置
    `amsgrad` 标志为 `True` 时，会启用 `Adam` 的一种变体，它结合了梯度的长期记忆。在某些情况下，这有助于收敛，而标准 `Adam` 算法则可能无法收敛。除了
    `Adam` 算法之外，PyTorch 还包含 `Adam` 的两个变体。`optim.SparseAdam` 采用惰性参数更新，仅更新梯度中出现的时刻，并将其应用于参数。这提供了一种更有效的处理稀疏张量（如用于词嵌入的张量）的方法。第二个变体
    `optim.Adamax` 使用无穷范数来计算梯度，理论上降低了对噪声的敏感性。在实践中，选择最佳优化器通常需要经过试验和错误。'
- en: 'The following code demonstrates the `optim.RMSprop` optimizer:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的代码演示了 `optim.RMSprop` 优化器：
- en: '[PRE7]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The `RMSprop` algorithm divides the learning rate for each parameter by a running
    average of the squares of the magnitude of recent gradients for that particular
    parameter. This ensures that the step size on each iteration is of the same scale
    as the gradient. This has the effect of stabilizing gradient descent and reduces
    the problem of disappearing or exploding gradients. The alpha hyperparameter is
    a smoothing parameter that helps make the network resilient to noise. Its use
    can be seen in the following code:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '`RMSprop` 算法将每个参数的学习率除以该特定参数最近梯度的平方的运行平均值。这确保每次迭代的步长与梯度的尺度相同。这样做可以稳定梯度下降，并减少消失或爆炸梯度的问题。alpha
    超参数是一个平滑参数，有助于使网络对噪声具有鲁棒性。其用法可以在下面的代码中看到：'
- en: '[PRE8]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The `Rprop` algorithm (resilient back propagation) is an adaptive algorithm
    that calculates weight updates by using the sign, but not the magnitude, of the
    partial derivative of the cost function for each weight. These are calculated
    for each weight independently. The `Rprop` algorithm takes a tuple pair of arguments,
    `etas`. These are multiplicative factors that either increase or decrease the
    weight depending on the sign of the derivative calculated on the entire loss function
    of the previous iteration. If the last iteration produced the opposite sign as
    the current derivative, then the update is multiplied by the first value in the
    tuple, called `etaminus`, a value less than one and defaulting to `0.5`. If the
    sign is the same on the current iteration, then that weight update is multiplied
    by the second value in the `etas` tuple, called `etaplis`, a value greater than
    `1` and defaulting to `1.2`. In this way, the total error function is minimized.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '`Rprop` 算法（弹性反向传播）是一种自适应算法，通过使用每个权重的成本函数的偏导数的符号（而不是大小）来计算权重更新。这些独立地为每个权重计算。`Rprop`
    算法接受一个元组对参数 `etas`。这些是乘法因子，根据前一个迭代整体损失函数的导数的符号来增加或减少权重。如果最后一个迭代产生与当前导数相反的符号，则更新乘以元组中的第一个值，称为
    `etaminus`，一个小于 1 的值，默认为 `0.5`。如果当前迭代的符号与上一个相同，则该权重更新乘以元组中的第二个值，称为 `etaplis`，一个大于
    `1` 的值，默认为 `1.2`。通过这种方式，最小化总误差函数。'
- en: Learning rate scheduler
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 学习率调度器
- en: 'The `torch.optim.lr_schedular `class serves as a wrapper around an to schedule
    the learning rate according to a specific function multiplied by the initial learning
    rate. The learning rate scheduler can be applied separately to each parameter
    group. This can speed up training time since, typically, we are able to use larger
    learning rates at the beginning of the training cycle and shrink this rate as
    the optimizer approaches minimal loss. Once a scheduler object is defined, it
    is typically stepped every epoch using `scheduler.step()`. There are a number
    of learning rate scheduler classes available in PyTorch, and the most common one
    is shown in the following code:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '`torch.optim.lr_schedular` 类作为一个包装器，根据一个特定函数乘以初始学习率来调度学习率。学习率调度器可以分别应用于每个参数组。这可以加快训练时间，因为通常我们能够在训练周期的开始使用更大的学习率，并在优化器接近最小损失时缩小此速率。一旦定义了调度器对象，通常会使用
    `scheduler.step()` 来逐个 epoch 进行步进。PyTorch 提供了许多学习率调度器类，其中最常见的一个如下所示：'
- en: '[PRE9]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'This learning rate scheduler class takes a function that multiplies the initial
    learning rate of each parameter group, and is either passed as a single function
    or a list of functions if there is more than one parameter group. The `last_epoch`
    is the index of the last epoch, so the default, `-1`, is the initial learning
    rate. The following screenshot of an example of this class assumes that we have
    two parameter groups:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 此学习率调度器类采用一个函数，该函数乘以每个参数组的初始学习率，并且如果有多个参数组，则作为单个函数或函数列表传递。`last_epoch` 是最后一个时期的索引，因此默认值
    `-1` 是初始学习率。以下是此类的示例截图，假设我们有两个参数组：
- en: '![](img/76f9618c-2c83-4e84-826d-cfef3306afc5.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](img/76f9618c-2c83-4e84-826d-cfef3306afc5.png)'
- en: '`optim.lr_schedular.StepLR(optimizer, step_size, gamma=0.1, last_epoch=-1` decays
    the learning rate by a multiplicative factor, `gamma`, every `step_size` of epochs.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '`optim.lr_schedular.StepLR(optimizer, step_size, gamma=0.1, last_epoch=-1)`
    每 `step_size` 个 epoch 将学习率按乘法因子 `gamma` 减少。'
- en: '`optim.lr_schedular.MultiStepLR(optimizer, milestones, gamma=0.1,last_epoch=-1)` takes
    a list of milestones, measured in the number of epochs, when the learning rate
    is decayed by `gamma`. The `milestones` phrase is an increasing list of `epoch`
    indices.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '`optim.lr_schedular.MultiStepLR(optimizer, milestones, gamma=0.1, last_epoch=-1)`
    接受一个里程碑列表，以 epoch 数量度量，当学习率减少 `gamma` 时。`milestones` 是一个递增的 `epoch` 索引列表。'
- en: Parameter groups
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参数组
- en: When an optimizer is instantiated, it is the as well as a variety of hyperparameters
    such as the learning rate. Optimizers are also passed other hyperparameters specific
    to each optimization algorithm. It can be extremely useful to set up groups of
    these hyperparameters, which can be applied to different parts of the model. This
    can be achieved by creating a parameter group, essentially a list of dictionaries
    that can be passed to the optimizer.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 当实例化优化器时，它是以及一些超参数，如学习率。优化器还传递了其他每种优化算法特定的超参数。设置这些超参数的组合可以极大地有助于设置模型的不同部分。通过创建参数组，实质上是一个可以传递给优化器的字典列表，可以实现这一点。
- en: The `param` variable must either be an iterator over a `torch.tens``or` or a
    Python dictionary specifying a default value of optimization options. Note that
    the parameters themselves need to be specified as an ordered collection, such
    as a list, so that parameters are a consistent sequence between model runs.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '`param` 变量必须是 `torch.tens` 的迭代器或指定优化选项默认值的Python字典。请注意，参数本身需要指定为有序集合，例如列表，以便在模型运行之间保持参数一致的顺序。'
- en: 'It is possible to specify the parameters as a parameter group. Consider the
    code shown in the following screenshot:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 可以将参数指定为参数组。考虑下面截图中显示的代码：
- en: '![](img/0f14fc80-5800-4ab0-99eb-d19abcccf827.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0f14fc80-5800-4ab0-99eb-d19abcccf827.png)'
- en: The `param_groups` function returns a list of dictionaries containing the weights
    and the optimizer hyperparameters. We have already discussed the learning rate.
    The SGD optimizer also has several other hyperparameters that can be used to fine-tune
    your models. The `momentum` hyperparameter modifies the SGD algorithm to help
    accelerate gradient tensors towards the optimum, usually leading to faster convergence.
    The momentum defaults to `0`; however, using higher values, usually around `0.9`,
    often results in faster optimization. This is especially effective on noisy data.
    It works by calculating a moving average across the dataset, effectively smoothing
    the data and consequently improving optimization. The `dampening` parameter can
    be used in conjunction with `momentum` as a dampening factor. The `weight_decay` parameter
    applies L2 regularization. This adds a term to the loss function, with the effect
    of shrinking the parameter estimates, making the model simpler and less likely
    to overfit. Finally, the `nestrove` parameter calculates the momentum based on
    future weight predictions. This enables the algorithm to look ahead by calculating
    a gradient, not with respect to current parameters, but with respect to approximate
    future parameters.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '`param_groups` 函数返回包含权重和优化器超参数的字典列表。我们已经讨论了学习率。SGD优化器还具有几个其他超参数，可用于微调您的模型。`momentum` 超参数修改SGD算法，帮助加速梯度张量朝向最优点，通常导致更快的收敛。`momentum` 默认为 `0`；然而，使用较高的值，通常在 `0.9` 左右，往往会导致更快的优化。这在处理嘈杂数据时特别有效。它通过计算数据集的移动平均来工作，有效地平滑数据，从而改善优化效果。`dampening` 参数可以与 `momentum` 一起使用作为抑制因子。`weight_decay` 参数应用L2正则化。这向损失函数添加了一个项，效果是缩小参数估计，使模型更简单，更不易过拟合。最后，`nestrove` 参数基于未来的权重预测计算动量。这使得算法可以向前看，通过计算一个梯度，不是针对当前参数，而是针对近似未来参数。'
- en: 'We can use the `param_groups` function to assign different sets of parameters
    to each parameter group. Consider the code shown in the following screenshot:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 `param_groups` 函数将不同的参数集分配给每个参数组。考虑下面截图中显示的代码：
- en: '![](img/04b193a5-3112-4d6d-81de-6b54c5306952.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](img/04b193a5-3112-4d6d-81de-6b54c5306952.png)'
- en: 'Here, we have created another weight, `w2`, and assigned it to a parameter
    group. Note that in the output we have two sets of hyperparameters, one for each
    parameter group. This enables us to set weight-specific hyperparameters, allowing,
    for example, different options to be applied to each layer in a network. We can
    access each parameter group and change a parameter value, using its list index,
    as shown in the code in the following screenshot:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们创建了另一个权重 `w2` ，并将其分配给一个参数组。请注意，在输出中我们有两组超参数，每个参数组一个。这使我们能够设置特定于权重的超参数，例如允许在网络的每一层中应用不同的选项。我们可以访问每个参数组并更改参数值，使用其列表索引，如下面截图中的代码所示：
- en: '![](img/552d4d51-37a2-45b0-accf-dabdd9ad3f43.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](img/552d4d51-37a2-45b0-accf-dabdd9ad3f43.png)'
- en: Pretrained models
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预训练模型
- en: One of the major difficulties with image classification models is the lack of
    labeled data. It is difficult to assemble a labeled dataset of sufficient size
    to train a model well; it is an extremely time consuming and laborious task. This
    is not such a problem for MNIST, since the images are relatively simple. They
    are greyscale and largely consist only of target features, there are no distracting
    background features, and the images are all aligned the same way and are of the
    same scale. A small dataset of 60,000 images is quite sufficient to train a model
    well. It is rare to find such a well-organized and consistent dataset in the problems
    we encounter in real life. Images are often of variable quality, and the target
    features can be obscured or distorted. They can also be of widely variable scales
    and rotations. The solution is to use a model architecture that is pretrained
    on a very large dataset.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 图像分类模型的主要困难之一是缺乏标记数据。组装足够大小的标记数据集以很好地训练模型是困难的；这是一项非常耗时且费力的任务。对于MNIST来说，这并不是问题，因为这些图像相对简单。它们是灰度的，主要由目标特征组成，没有令人分心的背景特征，所有图像都对齐在同一方式，并且是相同比例的。一个包含60,000张图像的小数据集已经足够很好地训练模型。在我们在现实生活中遇到的问题中，很难找到这样一个组织良好且一致的数据集。图像的质量通常是可变的，目标特征可能被遮蔽或扭曲。它们还可以具有广泛可变的尺度和旋转。解决方案是使用一个在非常大的数据集上预训练的模型架构。
- en: 'PyTorch includes six model architectures based on convolutional networks, designed
    for working with images on classification or regression tasks. The following list
    describes these models in detail:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch 包含六种基于卷积网络的模型架构，专为处理分类或回归任务中的图像设计。以下列表详细描述了这些模型：
- en: '**AlexNet**: This model is based on convolutional networks and achieves significant
    performance improvements through a strategy of parallelizing operations across
    processors. The reason for this is that operations on the convolutional layers
    are somewhat different to those that occur on the linear layers of a convolutional
    network. The convolutional layers account for around 90% of the overall computation,
    but operate on only 55% of the parameters. For the fully connected linear layers,
    the reverse is true, accounting for around 5% of the computations, yet they contain
    around 95% of the parameters. AlexNet uses a different parellelizing strategy
    to take into account the differences between linear and convolutional layers.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AlexNet**：这个模型基于卷积网络，通过并行化操作在处理器之间实现显著的性能改进。其原因在于，卷积层的操作与卷积网络的线性层中发生的操作有所不同。卷积层大约占总计算量的90%，但只操作55%的参数。对于完全连接的线性层，情况相反，它们占大约5%的计算量，但包含大约95%的参数。AlexNet
    使用不同的并行化策略来考虑线性层和卷积层之间的差异。'
- en: '**VGG**: The basic strategy behind **very deep convolutional networks** (**VGG**)
    for large-scale image recognition is to increase the depth the number of layers—while
    using a very small filter with a receptive field of 3 x 3 for all convolutional
    layers. All hidden layers include ReLU nonlinearity, and the output layers consist
    of three fully connected linear layers and a softmax layer. The VGG architecture
    is available in the `vgg11`, `vgg13`, `vgg16`, `vgg19`, `vgg 11_bn`, `vgg13_bn`,
    `vgg16_bn`, and `vgg19_bn `variants.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**VGG**：用于大规模图像识别的**非常深度卷积网络**（VGG）的基本策略是增加层数的深度，同时对所有卷积层使用一个3 x 3的接受领域的非常小过滤器。所有隐藏层都包括ReLU非线性，输出层由三个完全连接的线性层和一个softmax层组成。VGG
    架构提供 `vgg11`、`vgg13`、`vgg16`、`vgg19`、`vgg11_bn`、`vgg13_bn`、`vgg16_bn` 和 `vgg19_bn`
    几种变体。'
- en: '**ResNet**: While very deep networks offer potentially greater computation
    power, they can be very difficult to optimize and train. Very deep networks often
    result in gradients that either vanish or explode. ResNet uses a residual network
    that includes shortcut skip connections to jump over some layers. These skip layers
    have variable weights so that in the initial training phase the network effectively
    collapses into a few layers, and as training proceeds, the number of layers is
    expanded as new features are learned. Resnet is available in the `resnet18`, `resnet34`,
    `resnet50`, `resnet101`, and `resnet152 `variants.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ResNet**：虽然非常深的网络可能提供更强的计算能力，但它们很难进行优化和训练。非常深的网络通常会导致梯度消失或爆炸。ResNet 使用残差网络，其中包括快捷跳过连接以跳过某些层。这些跳过层具有可变权重，因此在初始训练阶段，网络有效地折叠成几层，随着训练的进行，随着新特征的学习，层数会扩展。ResNet
    提供 `resnet18`、`resnet34`、`resnet50`、`resnet101` 和 `resnet152` 几种变体。'
- en: '**SqueezeNet**:SqueezeNet was designed to create smaller models with fewer
    parameters that are easier to export and run in distributed environments. This
    is achieved using three strategies. Firstly, it reduces the receptive field of
    the majority of convolutions from 3 x 3 to 1 X 1\. Secondly, it reduces the input
    channels into the remaining 3 x 3 filters. Thirdly, it down samples in the final
    layers in the network. SqueezeNet is available in the `squeezenet1_0 `and `squeezenet1_1 `variants.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**SqueezeNet**：SqueezeNet 旨在创建更小、参数更少且更易于在分布式环境中导出和运行的模型。这是通过三种策略实现的。首先，将大多数卷积的感受野从
    3 x 3 减少到 1 x 1。其次，将输入通道减少到剩余的 3 x 3 过滤器中。第三，对网络的最终层进行下采样。SqueezeNet 可在 `squeezenet1_0`
    和 `squeezenet1_1` 变体中找到。'
- en: '**DenseNet**:Densely convolutional networks—in contrast to standard CNNs, where
    weights propagate through each layer from input to output— each layer, the feature
    maps for all preceding layers are used as inputs. This results in shorter connections
    between layers and a network that encourages the reuse of parameters. This results
    in fewer parameters and strengthens the propagation of features. DenseNet is available
    in the `Densenet121`, `Densenet169`, and `Densenet201 `variants.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**DenseNet**：密集卷积网络与标准CNN相比，其中权重从输入传播到输出的每一层，每一层使用所有前一层的特征图作为输入。这导致层之间的连接更短，网络鼓励参数的重复使用。这样可以减少参数数量并增强特征的传播。DenseNet
    可在 `Densenet121`、`Densenet169` 和 `Densenet201` 变体中找到。'
- en: '**Inception**: This architecture uses several strategies to improve performance,
    including reducing informational bottlenecks by gently reducing dimensionality
    between the input and output, factorizing convolutions from larger to smaller
    receptive fields, and balancing the width and depth of the network. The latest
    version is `inception_v3`. Importantly, Inception requires images to be of size
    299 x 299, in contrast to the other models, which require images to be of size
    224 x 224.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Inception**：这种架构使用多种策略来提高性能，包括通过逐渐减少输入和输出之间的维度来减少信息瓶颈，将卷积从较大的感受野因子化为较小的感受野，以及平衡网络的宽度和深度。最新版本是
    `inception_v3`。重要的是，Inception 要求图像大小为 299 x 299，与其他模型要求的 224 x 224 不同。'
- en: These models can be initialized with random weights by simply calling their
    constructor, for example `model = resnet18()`. To initialize a pre-trained model,
    set the Boolean `pretrained= True`, for example, `model = resnet18(pretrained=True)`.
    This will load the dataset with their weight values pre-loaded. These weights are
    calculated by training the network on the `Imagenet` dataset. This dataset contains
    over 14 million images with over 100 indexes.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 这些模型可以通过简单调用其构造函数以随机权重初始化，例如 `model = resnet18()`。要初始化预训练模型，请设置布尔值 `pretrained=
    True`，例如 `model = resnet18(pretrained=True)`。这将加载预加载的权重数值数据集。这些权重通过在 `Imagenet`
    数据集上训练网络来计算。该数据集包含超过 1400 万张图像和超过 100 个索引。
- en: Many of these model architectures come in several configurations—for example, `resnet18`,
    `resnet34`, `vgg11`, and `vgg13`. These variants exploit differences in layer
    depth, normalization strategies, and other hyperparameters. Finding which one
    works best for a particular task requires some experimentation.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 许多这些模型架构具有多种配置，例如 `resnet18`、`resnet34`、`vgg11` 和 `vgg13`。这些变体利用层深度、标准化策略和其他超参数的差异。找出哪种最适合特定任务需要进行一些实验。
- en: 'Also, be aware that these models are designed for working with image data,
    and require RGB images in the form of `(3, W, H)`. Input images need to be resized
    to 224 x 224, except for Inception, which requires images of size 299 x 299\.
    Importantly, they need to be normalized in a very specific way. This can be done
    by creating a `normalize` variable and passing it to `torch.utils.data.DataLoader`,
    usually as part of a `transforms.compose()` object. It is important that the `normalize`
    variable is given exactly the following values:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 还要注意，这些模型设计用于处理图像数据，需要RGB图像格式为 `(3, W, H)`。输入图像需要调整大小为 224 x 224，除了Inception，它需要大小为
    299 x 299 的图像。重要的是，它们需要以非常特定的方式进行归一化。可以通过创建一个 `normalize` 变量并将其传递给 `torch.utils.data.DataLoader`
    来完成这一点，通常作为 `transforms.compose()` 对象的一部分。非常重要的是，`normalize` 变量必须精确地具有以下值：
- en: '[PRE10]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: This ensures that the input images have the same distribution as the `Imagenet`
    set that they were trained on.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 这确保了输入图像与它们在 `Imagenet` 数据集上训练的相同分布。
- en: Implementing a pretrained model
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现预训练模型
- en: 'Remember the Guiseppe toys dataset we played with in [Chapter 1](2d1384b3-ec8a-40f0-96d0-5ac061f08a65.xhtml), *Introduction
    to PyTorch*? We now finally have the tools and knowledge to be able to create
    a classification model for this data. We are going to do this by using a model
    pretrained on the `Imagenet` dataset. This is called transfer learning, because
    we are transferring the learning achieved on one dataset to make predictions on
    a different, usually much smaller, dataset. Using a network with pretrained weights
    dramatically increases its performance on much smaller datasets, and this is surprisingly
    easy to achieve. In the simplest case, we can pass the pretrained model a data
    of labeled images and simply change the number of output features. Remember that
    `Imagenet` has `100` indexes or potential labels. For our task here, we want to
    categorize images into three classes: `toy`, `notoy`, and `scenes`. For this reason,
    we need to assign the number of output features to three.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 还记得我们在《PyTorch入门》的[第一章](2d1384b3-ec8a-40f0-96d0-5ac061f08a65.xhtml)中玩过的Guiseppé玩具数据集吗？现在我们终于有了工具和知识来创建这些数据的分类模型。我们将使用在`Imagenet`数据集上预训练的模型来实现这一目标。这被称为迁移学习，因为我们正在将在一个数据集上学到的知识迁移到另一个（通常要小得多的）数据集上进行预测。使用具有预训练权重的网络显著提高了在较小数据集上的性能，而且这是非常容易实现的。在最简单的情况下，我们可以将预训练模型传递给带标签图像的数据，并简单地更改输出特征的数量。请记住，`Imagenet`有`100`个索引或潜在标签。对于我们的任务，我们希望将图像分类为三类：`toy`、`notoy`和`scenes`。因此，我们需要将输出特征的数量分配为三。
- en: The code in the following screenshot is an adaption of code from the transfer learning
    tutorial by Sasank Chilamkurthy, found at [https://chsasank.github.io](https://chsasank.github.io).
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 下图中的代码是基于Sasank Chilamkurthy的迁移学习教程中的代码进行调整的，可在[https://chsasank.github.io](https://chsasank.github.io)找到。
- en: 'To begin, we need to import the data. This is available from this book''s website
    (`.../toydata`). Unzip this file into your working directory. You can actually
    use any image data you like, provided it has the same directory structure: that
    is two subdirectories for training and validation sets, and within these two directories,
    subdirectories for each of the classes. Other datasets you might like to try are
    the hymenoptera dataset, containing two classes of either ants or bees, available
    from [https://download.pytorch.org/tutorial/hymenoptera_data.zip](https://download.pytorch.org/tutorial/hymenoptera_data.zip),
    and the CIFAR-10 dataset from `torchvision/datasets`, or the much larger and more
    challenging plant seedling dataset, containing 12 classes, available from [https://www.kaggle.com/c/plant-seedlings-classification](https://www.kaggle.com/c/plant-seedlings-classification).'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要导入数据。这些数据可以从本书的网站(`.../toydata`)获取。将该文件解压缩到您的工作目录中。实际上，您可以使用任何您喜欢的图像数据，只要它具有相同的目录结构：即用于训练和验证集的两个子目录，并在这两个目录中，为每个类别建立子目录。您可能还想尝试的其他数据集包括蜜蜂和蚂蚁的hymenoptera数据集，可在[https://download.pytorch.org/tutorial/hymenoptera_data.zip](https://download.pytorch.org/tutorial/hymenoptera_data.zip)获取，以及来自`torchvision/datasets`的CIFAR-10数据集，或者更大更具挑战性的植物种子数据集，包含12个类别，可在[https://www.kaggle.com/c/plant-seedlings-classification](https://www.kaggle.com/c/plant-seedlings-classification)获取。
- en: 'We need to apply separate data transformations for training and validation
    datasets, import and make the datasets iterable, and then assign the device to
    a GPU, if available, as shown in the code in the following screenshot:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要对训练和验证数据集应用单独的数据转换，导入并使数据集可迭代，然后根据下图中的代码将设备分配给GPU（如果可用）：
- en: '![](img/d918ebae-9d7b-4807-bd5e-61f637ab2640.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d918ebae-9d7b-4807-bd5e-61f637ab2640.png)'
- en: Note that a dictionary is used to store two lists of `compose` objects in order
    to transform the training and validation sets. The `RandomResizedCrop` and `RandomHorizontalFlip` transforms
    are used to augment the training set. For both the training and validation sets,
    the images are resized and center cropped, and the specific normalization values,
    as discussed in the last section, are applied.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，字典用于存储两个`compose`对象列表，以便转换训练和验证集。使用`RandomResizedCrop`和`RandomHorizontalFlip`转换来增强训练集。对于训练和验证集，图像都被调整大小并居中裁剪，并且应用了上一节讨论的特定标准化值。
- en: The data is unpacked using a dictionary comprehension. This uses the `datasets.Imagefolder`
    class, which is a generic data loader for use where the data is organized into
    their class folders. In this case, we have three folders, `NoToy`, `Scenes`, and
    `SingleToy`, for their respective classes. This directory structure is replicated
    in both the `val` and `train` directories. There are 117 training images and 24
    validation images, divided into the three classes.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 数据使用字典推导进行解包。这使用`datasets.Imagefolder`类，这是一个通用的数据加载器，用于在数据组织为其类文件夹的情况下使用。在本例中，我们有三个文件夹，`NoToy`、`Scenes`和`SingleToy`，分别对应它们的类。这种目录结构在`val`和`train`目录中都有。共有117张训练图像和24张验证图像，分为三个类。
- en: 'We can retrieve the class names simply by calling the `classes` attribute of
    the `ImageFolder`, as shown in the code in the following screenshot:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 通过调用`ImageFolder`的`classes`属性，我们可以简单地检索类名，如下面截图中所示的代码所示：
- en: '![](img/513366ab-885c-48fb-b03a-904975aaca52.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](img/513366ab-885c-48fb-b03a-904975aaca52.png)'
- en: 'A batch of images and their class indexes can be retrieved using the code in
    the following screenshot:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用以下截图中的代码检索一批图像及其类索引：
- en: '![](img/a44ce0e3-7031-4f95-84b5-61c5a7206a34.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a44ce0e3-7031-4f95-84b5-61c5a7206a34.png)'
- en: 'The `inputs` tensor has a size in the form of `(batch, RGB, W,H)`. The first
    tensor, of size `4`, contains either a `0` (`NoToy`), `1` (`Scenes`), or `2` (`SingleToy`),
    representing the class for each of the `4` images in the batch. The class names
    of each image in the batch can be retrieved using the following list comprehension:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '`inputs`张量的大小为`(batch, RGB, W,H)`。第一个大小为`4`的张量包含`0`（`NoToy`）、`1`（`Scenes`）或`2`（`SingleToy`），表示批次中每个图像的类。可以使用以下列表推导来检索批次中每个图像的类名：'
- en: '![](img/f78f1227-8603-4cf2-8f32-3827530bee1f.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f78f1227-8603-4cf2-8f32-3827530bee1f.png)'
- en: 'Now, let''s look at the function that is used to train the model. This has
    a similar structure to our earlier training code, with a few additions. Training
    is divided into two phases, `train` and `val`. Also, the learning rate scheduler
    needs to be stepped for every `epoch` in the `train` phase, as shown in the code
    in the following screenshot:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看一下用于训练模型的函数。这与我们先前的训练代码结构类似，但有一些增加。训练分为两个阶段，`train`和`val`。此外，需要在`train`阶段的每个`epoch`中调整学习率调度器，如下面截图中的代码所示：
- en: '![](img/8ffc7b19-15d8-406d-9f98-27f3344ae0eb.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8ffc7b19-15d8-406d-9f98-27f3344ae0eb.png)'
- en: The `train_model` function takes as arguments the model, the loss criteria,
    a learning rate scheduler, and the number of epochs. The model weights are stored
    by deep copying `model.state_dict()`. Deep copying this ensures that all elements
    of the state dictionary are copied, and not just referenced, into the `best_model_wts`
    variable. For every epoch there are two phases, a training phase and a validation
    phase. In the validation phase, the model is set to evaluation mode using `model.eval()`.
    This changes the behaviour of some model layers, typically the dropout layer,
    setting the dropout probability to zero to validate on the complete model. The
    accuracy and loss for both the training and validation phases are printed on each
    epoch. Once this is done, the best validation accuracy is printed.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '`train_model`函数的参数包括模型、损失标准、学习率调度器和epoch数。模型权重通过深复制`model.state_dict()`来存储。深复制确保所有状态字典的元素都被复制，而不仅仅是引用到`best_model_wts`变量中。每个epoch分为两个阶段，训练阶段和验证阶段。在验证阶段，使用`model.eval()`将模型设置为评估模式。这会改变一些模型层的行为，通常是dropout层，将dropout概率设置为零以验证完整模型。每个epoch打印训练和验证阶段的准确性和损失。完成后打印最佳验证准确性。'
- en: 'Before we can run the training code, we need to instantiate the model and set
    up the optimizer, loss criteria, and learning rate scheduler. Here, we use the `resnet18` model,
    as shown in the code in the following screenshot. This code works for all `resnet`
    variants, although not necessarily with the same accuracy:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行训练代码之前，我们需要实例化模型并设置优化器、损失标准和学习率调度器。在这里，我们使用`resnet18`模型，如下面截图中的代码所示。这段代码适用于所有`resnet`变体，尽管准确性可能有所不同：
- en: '![](img/68111a99-dc1f-4183-b102-bef34c6d1fb1.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![](img/68111a99-dc1f-4183-b102-bef34c6d1fb1.png)'
- en: The model is used with all weights, excluding the output layer, trained on the
    `Imagenet` dataset. We need only change the output layer since the weights in
    all hidden layers are frozen in their pretrained state. This is done by setting
    the output layer to a linear layer with its output set to the number of classes
    we are predicting. The output layer is essentially a feature extractor for the
    dataset we are working with. At the output, the features we are trying to extract
    are the classes themselves.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型使用了所有权重（不包括输出层），这些权重在`Imagenet`数据集上进行了训练。我们只需要改变输出层，因为所有隐藏层的权重都处于预训练状态并被冻结。这通过设置输出层为具有输出设置为我们预测的类数的线性层来完成。输出层本质上是我们正在处理的数据集的特征提取器。在输出时，我们尝试提取的特征就是类本身。
- en: We can look at the structure of the model by simply running `print(model)`.
    The final layer is named `fc`, so we can access this layer with `model.fc`. This
    is assigned a linear layer and is passed the number of input features, accessed
    with `fc.in_features`, and the number of output classes, here set to `3`. When
    we run this model, we are able to achieve an accuracy of around 90%, which is
    actually quite impressive, considering the tiny dataset we are using. This is
    possible because most of the training, apart from the final layer, is done on
    a much larger training set.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过简单运行`print(model)`来查看模型的结构。最后一层被命名为`fc`，因此我们可以通过`model.fc`访问该层。这被分配了一个线性层，并传递了输入特征的数量，通过`fc.in_features`访问，并且输出类的数量，在这里设置为`3`。当我们运行这个模型时，我们能够达到大约90%的准确率，这实际上是相当令人印象深刻的，考虑到我们使用的小数据集。这是可能的，因为除了最后一层之外，大部分训练都是在一个更大的训练集上完成的。
- en: 'It is possible, and a worthwhile exercise, to use the other pretrained models
    with a few changes to the training code. For example, the DenseNet model can be
    directly substituted for ResNet by simply changing the name of the output layer
    from `fc` to `classifier`, so instead of writing `model.fc`, we write `model.classifier`.
    SqueezeNet, VGG, and AlexNet have their final layers wrapped inside a sequential
    container, so to change the output `fc` layer, we need to go through the following
    four steps:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过对训练代码进行少量更改来使用其他预训练模型，这是一种值得的练习。例如，DenseNet模型可以直接替换ResNet，只需将输出层的名称从`fc`更改为`classifier`，所以我们不再写`model.fc`而是写`model.classifier`。SqueezeNet、VGG和AlexNet将它们的最后层包装在一个顺序容器中，所以要更改输出`fc`层，我们需要经历以下四个步骤：
- en: Find the number of filters in the output layer
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 找出输出层中过滤器的数量
- en: Convert the layers in the sequential object to a list and remove the last element
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将顺序对象中的层转换为列表，并移除最后一个元素
- en: Add the last linear layer, specifying the number of output classes, to the end
    of the list
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在列表末尾添加最后一个线性层，指定输出类的数量
- en: Convert the list back to a sequential container and add it to the model class
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将列表转换回顺序容器并将其添加到模型类中
- en: 'For the `vgg11` model, the following code can be used to implement these four
    steps:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 对于`vgg11`模型，可以使用以下代码来实现这四个步骤：
- en: '![](img/a71d4a48-4c04-442f-bd96-f23aa9322633.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a71d4a48-4c04-442f-bd96-f23aa9322633.png)'
- en: Summary
  id: totrans-112
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Now that you have an understanding of the foundations of deep learning, you
    should be well placed to apply this knowledge to specific learning problems that
    you are interested in. In this chapter, we have developed an out-of-the-box solution
    for image classification using pretrained models. As you have seen, this is quite
    simple to implement, and can be applied to almost any image classification problem
    you can think of. Of course, the actual performance in each situation will depend
    on the number and quality of images presented, as well as the precise tuning of
    the hyperparameters associated with each model and task.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经对深度学习的基础有了理解，应该能够将这些知识应用于您感兴趣的特定学习问题上。在本章中，我们已经开发了一个使用预训练模型进行图像分类的开箱即用解决方案。正如您所见，这个实现相当简单，并且可以应用于您能想到的几乎任何图像分类问题。当然，每种情况下的实际表现将取决于所呈现的图像数量和质量，以及与每个模型和任务相关的超参数的精确调整。
- en: You can generally get very good results on most image classification tasks by
    simply running the pretrained models with default parameters. This requires no
    theoretical knowledge, apart from installing the programs' running environment.
    You will find that when you adjust some parameters, you may improve the network's
    training time and/or accuracy. For example, you may have noticed that increasing
    the learning rate may dramatically improve a model's performance over a small
    number of epochs, but over subsequent epochs the accuracy actually declines. This
    is an example of gradient descent overshooting, and failing to find the true optimum.
    Finding the best learning rate requires some knowledge of gradient descent.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 通过简单地使用预训练模型和默认参数，通常可以在大多数图像分类任务上获得非常好的结果。这不需要理论知识，除了安装程序的运行环境。当你调整一些参数时，你会发现可以改善网络的训练时间和/或准确率。例如，你可能已经注意到，增加学习率可能会在少数epochs内显著提高模型的性能，但在后续epochs中，准确率实际上会下降。这是梯度下降过冲的一个例子，未能找到真正的最优解。要找到最佳的学习率，需要一些梯度下降的知识。
- en: In order to get the most out of PyTorch and apply it in different problem domains—such
    as language processing, physical modeling, weather and climate prediction, and
    so on (the applications are almost endless)—you need to have some understanding
    of the theory behind these algorithms. This not only allows improvement on known
    tasks, such as image classification, but also gives you some insight into how
    deep learning might be applied in a situation where, for example, the input data
    is a time series and the task is to predict the next sequence. After reading this
    book, you should know the solution, which is of course to use a recurrent network.
    You would have noticed that the model we built to generate text—that is, to make
    predictions on a sequence—was quite different to the model used to make predictions
    on static image data. But what about the model you would have to build to help
    you gain insights into a particular process? This could be the electronic traffic
    on a website, the physical traffic on a road network, the carbon and oxygen cycle
    of the planet, or a human biological system. These are the frontiers of deep learning,
    with immense power to do good. I hope reading this short introduction has left
    you feeling empowered and inspired to begin exploring some of these applications.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 要充分利用PyTorch，并将其应用于不同的问题领域——如语言处理、物理建模、天气和气候预测等（应用几乎无穷无尽）——你需要对这些算法背后的理论有一定的了解。这不仅可以改进已知任务，如图像分类，还可以让你洞察深度学习在某些情况下的应用，例如输入数据为时间序列，任务是预测下一个序列。阅读本书后，你应该知道解决方案，也就是使用递归网络。你会注意到，我们用来生成文本的模型——即在序列上做出预测的模型——与用来对静态图像数据进行预测的模型有很大不同。但是，为了帮助你洞察特定过程而建立的模型又是什么样的呢？这可能是网站上的电子流量、道路网络上的物理流量、地球的碳氧循环或人类生物系统。这些是深度学习的前沿，具有巨大的潜力去创造好的影响。希望阅读这篇简短介绍让你感到自信，并激发你开始探索其中一些应用。
