- en: '7'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Revealing the Secret of Deep Learning Models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, we have described how to construct and efficiently train a **deep learning**
    (**DL**) model. However, model training often involves multiple iterations because
    only rough guidance on how to configure the training correctly for a given task
    exists.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will introduce hyperparameter tuning, the most standard
    process of finding the right training configuration. As we guide you through the
    steps of hyperparameter tuning, we will introduce popular search algorithms adopted
    for the tuning process (grid search, random search, and Bayesian optimization).
    We will also look into the field of Explainable AI, which is the process of understanding
    what models do during prediction. We will describe the three most common techniques
    in this domain: **Permutation Feature Importance** (**PFI**), **SHapley Additive
    exPlanations** (**SHAP**), **Local Interpretable Model-agnostic Explanations**
    (**LIME**).'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’re going to cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Obtaining the best performing model using hyperparameter tuning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding the behavior of the model with Explainable AI
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can download the supplemental material for this chapter from this book’s
    GitHub repository at [https://github.com/PacktPublishing/Production-Ready-Applied-Deep-Learning/tree/main/Chapter_7](https://github.com/PacktPublishing/Production-Ready-Applied-Deep-Learning/tree/main/Chapter_7).
  prefs: []
  type: TYPE_NORMAL
- en: Obtaining the best performing model using hyperparameter tuning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As described in [*Chapter 3*](B18522_03.xhtml#_idTextAnchor062), *Developing
    a Powerful Deep Learning Model*, obtaining a DL model that extracts the right
    pattern for the underlying task requires multiple components to be configured
    appropriately. While building the right model architecture often introduces many
    difficulties, setting up the proper model training is another challenge that most
    people struggle with.
  prefs: []
  type: TYPE_NORMAL
- en: In **machine learning** (**ML**), *a* **hyperparameter** *refers to any parameter
    that controls the learning process*. In many cases, data scientists often focus
    on model-relevant hyperparameters such as the number of a particular type of layer,
    learning rate, or type of optimizer. However, hyperparameters also include data-relevant
    configurations such as types of augmentation to apply and a sampling strategy
    for model training. The iterative process of changing a set of hyperparameters,
    and understanding performance changes, to find the right set of hyperparameters
    for the target task is called *hyperparameter tuning*. To be precise, you will
    have a set of hyperparameters that you want to explore. For each iteration, one
    or more hyperparameters will be configured differently and a new model will be
    trained with the adjusted setting. After the iterative process, the hyperparameter
    configuration used for the best model will be the final output.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will learn various techniques and tools available for hyperparameter
    tuning.
  prefs: []
  type: TYPE_NORMAL
- en: Hyperparameter tuning techniques
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Techniques for hyperparameter tuning can differ by how the values for the
    target hyperparameters are selected*. Out of the various techniques, we will be
    focusing on the most common ones: **grid search**, **random search**, and **Bayesian
    optimization**.'
  prefs: []
  type: TYPE_NORMAL
- en: Grid search
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The most basic approach is called grid search, where *every possible value is
    evaluated one by one*. For example, if you want to explore a learning rate from
    0 to 1 with an increase of 0.25, then grid search will train the model for every
    possible learning rate (0.25, 0.5, 0.75, and 1) and select the learning rate that
    generates the best model.
  prefs: []
  type: TYPE_NORMAL
- en: Random search
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: On the other hand, *random search generates a random value for the hyperparameter
    and repeats the training until the maximum number of experiments is reached*.
    If we convert the example in the previous section for random search, we must define
    the maximum number of experiments and a boundary for the learning rate. In this
    example, we will set the maximum number as 5 and the boundary as 0 to 1\. Then,
    random search will select a random value between 0 and 1 and train a model with
    the selected learning rate. This process will be repeated 5 times and the learning
    rate that generates the best model will be selected as the output of hyperparameter
    tuning.
  prefs: []
  type: TYPE_NORMAL
- en: 'To help your understanding, the following diagram summarizes the difference
    between grid search and random search:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.1 – The difference between grid search and random search'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18522_07_01.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.1 – The difference between grid search and random search
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding diagram, *x* and *y* indicate two different hyperparameters.
    The purple and green graphs on each axis represent the model performance changes
    concerning each hyperparameter.
  prefs: []
  type: TYPE_NORMAL
- en: 'While grid search and random search are easy to implement, they both have a
    common limitation: they do not guarantee the best value for the target hyperparameter.
    This issue mainly comes from the fact that the previous results are not considered
    when selecting the next value to explore. To overcome this issue, a new search
    algorithm was introduced: Bayesian optimization.'
  prefs: []
  type: TYPE_NORMAL
- en: Bayesian optimization
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The idea of Bayesian optimization is straightforward: *a surrogate model that
    maps the relationship between the hyperparameters and the underlying model is
    constructed and adjusted throughout the hyperparameter tuning so that we can select
    a hyperparameter value that will most likely lead us to have a better understanding
    about the relationship from the following experiment*. Using the generated surrogate
    model, we can select the hyperparameter value that will likely give us a better
    model.'
  prefs: []
  type: TYPE_NORMAL
- en: There are many ways to build a surrogate model. If we assume that the relationship
    can be represented as a linear function, the surrogate model generation process
    will simply be linear regression. In reality, the relationship is much more complex,
    and the most successful technique is to use Gaussian process regression. Here,
    we assume that the relationship can be represented by a set of normal distributions.
    In other words, each value we select is randomly selected from a multivariate
    normal distribution. We would need to introduce multiple probability and mathematical
    terms if we wanted to go over every detail of Bayesian optimization. We believe
    that the high-level description in this section and the complete example in the
    following section will be sufficient for you to apply hyperparameter tuning using
    Bayesian optimization. If you would like to understand the theory behind Bayesian
    optimization, please go to [https://ieeexplore.ieee.org/abstract/document/7352306](https://ieeexplore.ieee.org/abstract/document/7352306).
  prefs: []
  type: TYPE_NORMAL
- en: Hyperparameter tuning tools
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As hyperparameter tuning plays an important role in ML projects, many libraries
    exist that are designed to simplify the process. The popular ones are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Scikit-Optimize**: [https://scikit-optimize.github.io](https://scikit-optimize.github.io)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Optuna**: [https://optuna.org](https://optuna.org)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**HyperOpt**: [http://hyperopt.github.io](http://hyperopt.github.io)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Ray Tune**: [https://docs.ray.io/en/latest/tune/index.html](https://docs.ray.io/en/latest/tune/index.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Bayesian Optimization**: [https://github.com/fmfn/BayesianOptimization](https://github.com/fmfn/BayesianOptimization)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Metric Optimization Engine** (**MOE**): [https://github.com/Yelp/MOE](https://github.com/Yelp/MOE)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Spearmint**: [https://github.com/HIPS/Spearmint](https://github.com/HIPS/Spearmint)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**GPyOpt**: [https://github.com/SheffieldML/GPyOpt](https://github.com/SheffieldML/GPyOpt)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**SigOpt**: [https://sigopt.com](https://sigopt.com/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**FLAML**: [https://github.com/microsoft/FLAML](https://github.com/microsoft/FLAML)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Dragonfly**: [https://github.com/dragonfly/dragonfly](https://github.com/dragonfly/dragonfly)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**HpBandSter**: [https://github.com/automl/HpBandSter](https://github.com/automl/HpBandSter)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Nevergrad**: [https://github.com/facebookresearch/nevergrad](https://github.com/facebookresearch/nevergrad)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ZOOpt**: [https://github.com/polixir/ZOOpt](https://github.com/polixir/ZOOpt)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**HEBO**: [https://github.com/huawei-noah/HEBO/tree/master/HEBO](https://github.com/huawei-noah/HEBO/tree/master/HEBO)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**SageMaker**: [https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-how-it-works.html](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-how-it-works.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Among the various tools, we will look at Ray Tune as we covered how to use Ray
    for distributed training in [*Chapter 6*](B18522_06.xhtml#_idTextAnchor133), *Efficient
    Model Training*, in the *Training a model using Ray* section.
  prefs: []
  type: TYPE_NORMAL
- en: Hyperparameter tuning using Ray Tune
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As part of Ray, a framework developed for scaling Python workloads across machines,
    Ray Tune is designed for experiment execution and hyperparameter tuning at scale.
    In this section, we will walk you through how to configure and schedule hyperparameter
    tuning using **Ray Tune**. Even though the examples are designed for an abstract
    representation of model training functionality, setups and documentation of Ray
    Tune are clear enough that **PyTorch** and **TensorFlow** (**TF**) integration
    will come naturally at the end of the section.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we will look at the basics of Ray Tune. The core functionality of Ray
    Tune comes from the `tune.run` function, which manages all the experiments, logs,
    and checkpoints. The basic usage of the `tune.run` function is demonstrated in
    the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The `tune.run` function takes in `run_or_experiment`, which defines the training
    logic, and `conf`, which configures the hyperparameter tuning. The number of experiments
    depends on the type of search function provided for each hyperparameter in `conf`.
    In the preceding example, we have `tune.grid_search([10, 20, 30, 40])`, which
    will spin up four experiments, each running the function provided for `run_or_experiment`
    (`tr_function`) with a distinct value of `num_iterations`. Within `tr_function`,
    we can access the assigned hyperparameter through the `conf` argument. It is worth
    mentioning that Ray Tune provides a vast number of sampling methods ([https://docs.ray.io/en/latest/tune/api_docs/search_space.html#tune-sample-docs](https://docs.ray.io/en/latest/tune/api_docs/search_space.html#tune-sample-docs)).
  prefs: []
  type: TYPE_NORMAL
- en: 'Ray Tune has integrated many open source optimization libraries as part of
    `tune.suggest` providing various state-of-the-art search algorithms for hyperparameter
    tuning. Popular ones include HyperOpt, Bayesian Optimization, Scitkit-Optimize,
    and Optuna. The complete list can be found at [https://docs.ray.io/en/latest/tune/api_docs/suggestion.html](https://docs.ray.io/en/latest/tune/api_docs/suggestion.html).
    In the following example, we will describe how to use `BayesOptSearch`, which,
    as its name suggests, implements Bayesian optimization:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code snippet, we provided an instance of `BayesOptSearch` to
    the `search_alg` parameter. This example will try to find `num_iterations`, which
    will provide us a model with the highest `mean_accuracy`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another key parameter of `tune.run` is `stop`. This parameter can take in a
    dictionary, a function, or a `Stopper` object that defines a stopping criterion.
    If it is a dictionary, keys must be one of the fields in the returned results
    of the `run_or_experiment` function. If it’s a function, it should return a Boolean
    that becomes `True` once the stopping criteria are met. These two cases are described
    in the following examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: In the dictionary-based example, each trial will stop if it completes 10 iterations
    or `mean_accuracy` reaches the specified value, `0.96`. The function-based example
    implements the same logic but uses the `stp_function` function. For a `stopper`
    class use case, you can refer to [https://docs.ray.io/en/latest/tune/tutorials/tune-stopping.html#stopping-with-a-class](https://docs.ray.io/en/latest/tune/tutorials/tune-stopping.html#stopping-with-a-class).
  prefs: []
  type: TYPE_NORMAL
- en: '*A trial is an internal data structure of Ray Tune that contains metadata about
    each experiment* ([https://docs.ray.io/en/latest/tune/api_docs/internals.html#trial-objects](https://docs.ray.io/en/latest/tune/api_docs/internals.html#trial-objects)).
    Each trial gets a unique ID (`trial.trial_id`) and its hyperparameter settings
    can be checked through `trial.config`. Interestingly, different scales of machine
    resources can be allocated for each trial through the `resources_per_trial` parameter
    of `tune.run` and `trial.placement_group_factory`. Additionally, the `num_samples`
    parameter can be used to control the number of trials.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The summary of your experiments can be obtained using the `Analysis` instance
    returned from `ray.tune`. The following code snippet describes a set of information
    you can retrieve from an `Analysis` instance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: You can also retrieve other useful information from an `Analysis` instance.
    The complete details can be found at [https://docs.ray.io/en/latest/tune/api_docs/analysis.html](https://docs.ray.io/en/latest/tune/api_docs/analysis.html).
  prefs: []
  type: TYPE_NORMAL
- en: This completes the core components of Ray Tune. If you want to integrate Ray
    Tune for your PyTorch or TF model training, all you must do is adjust `tr_function`
    in the examples so that it trains your model as it logs relevant performance metrics.
  prefs: []
  type: TYPE_NORMAL
- en: Overall, we have explored different options for hyperparameter tuning. The tools
    we have covered in this section should help us efficiently find the best configuration
    for our DL model.
  prefs: []
  type: TYPE_NORMAL
- en: Things to remember
  prefs: []
  type: TYPE_NORMAL
- en: a. Obtaining a working DL model for a particular task requires finding the right
    model architecture and using appropriate training configurations. The process
    of finding the best combination is called hyperparameter tuning.
  prefs: []
  type: TYPE_NORMAL
- en: b. The three most popular hyperparameter tuning techniques are grid search,
    random search, and Bayesian optimization.
  prefs: []
  type: TYPE_NORMAL
- en: c. Popular hyperparameter tuning tools include Scikit-Optimize, Optuna, Hyperopt,
    Ray Tune, Bayesian Optimization, MOE, Spearmint, GpyOpt, and SigOpt.
  prefs: []
  type: TYPE_NORMAL
- en: So far, we have treated DL models as black boxes. Hyperparameter tuning involves
    searching an unknown space that does not explain how the model finds the underlying
    pattern. In the next section, we will look at what researchers have recently worked
    on to understand the flexibility of DL.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the behavior of the model with Explainable AI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Explainable AI** is a very active area of research. In business settings,
    understanding AI models can easily lead to a distinctive competitive advantage.
    The so-called *black-box models (complex algorithmic models)*, even though they
    bring exceptional results, are commonly criticized due to their hidden logic.
    It is hard for higher-level management to fully design the core business based
    on AI, as interpreting the model and predictions is not an easy task. How can
    you convince your business partners that an AI model will always deliver the expected
    results? How can you ensure that the model will still work on new data? How does
    the model generate the results? Explainable AI helps us address these questions.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we go any further, let’s look at two important concepts: **interpretability**
    and **explainability**. At first, they might sound similar. Interpretability tells
    us why a specific input produces the specific model’s output: the effects of specific
    variables on the result. Explainability goes beyond interpretability; it focuses
    not only on causality between inputs and outputs but helps us understand how a
    model works as a whole, including all its sub-elements. Explainability is also
    driven by three fundamental ideas: transparency, reproducibility, and transferability.
    This means that we should be able to fully understand what our models do, how
    data affects the model as it passes through, and be able to reproduce the results.'
  prefs: []
  type: TYPE_NORMAL
- en: Explainable AI plays a role in every step of an ML project – development (an
    explanation of model architecture and meaning of each hyperparameter), training
    (changes within the model throughout training), as well as inference (results
    interpretation). In the case of DL models, it is hard to achieve explainability
    due to the complexity of the network architecture, high algorithmic complexity,
    and use of random numbers while initializing weights, biases, regularization,
    and hyperparameters optimization.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, we will discuss a few methods that are commonly used to build
    additional trustworthiness behind DL models: **Permutation Feature Importance**
    (**PFI**), **Feature Importance** (**FI**), **SHapley Additive exPlanations**
    (**SHAP**), and **Local Interpretable Model-agnostic Explanations** (**LIME**).
    All these methods are model agnostic; they can be applied to DL models as well
    as other supporting ML models commonly used to set baseline evaluation metrics.'
  prefs: []
  type: TYPE_NORMAL
- en: Permutation Feature Importance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Neural networks lack intrinsic attributes needed to understand the impact of
    input features on the predictions (the model’s output). However, there is a model
    agnostic approach called **Permutation Feature Importance** (**PFI**) designed
    for this difficulty. *The idea of PFI comes from the relationship between input
    features and outputs: for an input feature that has a high correlation with an
    output variable, changing its value will increase the model’s prediction error*.
    If the relationship is weak, the model performance won’t be affected as much.
    If the relationship is strong, the performance will be degraded. PFI is often
    applied to test sets to obtain a broader understanding of the model’s interpretability
    on unseen data.'
  prefs: []
  type: TYPE_NORMAL
- en: The key disadvantage of PFI relates to the fact that it will not work correctly
    when data has a group of correlated input features. In this case, even though
    you change one feature from the group, the model performance does not change much
    because other features will remain unchanged.
  prefs: []
  type: TYPE_NORMAL
- en: Going further with the idea, we can completely remove that feature and measure
    the model performance. This approach is called **Feature Importance** (**FI**),
    also known as **Permutation Importance** (**PI**) or **Mean Decrease Accuracy**
    (**MDA**). Let’s have a look at how we can implement FI for any black-box model.
  prefs: []
  type: TYPE_NORMAL
- en: Feature Importance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, we will use the *ELI5* Python package ([https://eli5.readthedocs.io](https://eli5.readthedocs.io))
    to perform FI analysis. It stands out in the field of FI because it’s very simple
    to use. Let’s look at a minimal code example for TF with a Keras-defined model
    (see [*Chapter 3*](B18522_03.xhtml#_idTextAnchor062), *Developing a Powerful Deep
    Learning Model*, for details on model definition):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see, the code is almost self-explanatory. First, we need to create
    a wrapper for the score function that calculates the target evaluation metric.
    Then, the `tf.keras` model gets passed to the constructor of the `PermutationImportance`
    class. The `fit` function, which takes in features and labels, handles the FI
    calculation. After this calculation, we can access the mean FI for each feature
    (`fi_perm`) and the standard deviation of the permuted results (`fi_std`). The
    following code snippet shows how to visualize the results of permutation importance
    as a bar graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'If the model is neither based on scikit-learn nor Keras, you need to use the
    `permutation_importance.get_score_importance` function. The following code snippet
    describes how to use this function with a PyTorch model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Unlike the `PermutationImportance` class, the `get_score_importances` function
    takes in a scoring function, features, and labels all at the same time.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will have a look at **SHapley Additive exPlanations** (**SHAP**), which
    is also a model-agnostic approach.
  prefs: []
  type: TYPE_NORMAL
- en: SHapley Additive exPlanations (SHAP)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'SHAP is an interpretation method that leverages Shapley values to understand
    the given black-box model. We won’t cover the cooperative game theory that SHAP
    is based on but we will cover the process at a high level. First, let’s look at
    the definition of Shapley values: *the average of marginal contributions among
    all possible coalitions over different simulations*. What exactly does this mean?
    Let’s say that a group of four friends (*f1*, *f2*, *f3*, and *f4*) is working
    to get the highest score together for an online game. To calculate the Shapley
    value for a person, we need to calculate the marginal contribution, which is the
    difference in score when the person is playing versus not playing. This calculation
    must be done for all possible subgroups (**coalitions**).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s take a closer look. To calculate the marginal contribution of *f1* for
    the coalition of friends *f2*, *f3*, and *f4*, we need to do the following :'
  prefs: []
  type: TYPE_NORMAL
- en: Calculate the score (*s1*) generated by all friends (*f1*, *f2*, *f3*, and *f4*).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Calculate the score (*s2*) generated by friends *f2*, *f3*, and *f4*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, the marginal contribution of friend *f1* for the coalition of friends
    *f2*, *f3*, and *f4* *(v)* equals *s1-s2*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now, we need to calculate marginal contributions for *all subgroups* (not only
    for a coalition of friends; that is, *f2*, *f3*, and *f4*). Here is every possible
    combination:'
  prefs: []
  type: TYPE_NORMAL
- en: '*f1* versus *no one* is contributing (*v1*)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*f1* and *f2* versus *f2* (*v2*)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*f1* and *f3* versus *f3* (*v3*)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*f1* and *f4* versus *f4* (*v4*)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*f1* and *f2* and *f3* versus *f2* and *f3* (*v5*)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*f1* and *f2* and *f4* versus *f2* and *f4* (*v6*)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*f1* and *f3* and *f4* versus *f3* and *f4* (*v7*)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*f1* and *f2* and *f3* and *f4* versus *f2* and *f3* and *f4* (*v8*)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Overall, the Shapley value (*SV*) for *f1* is *(v1+v2+...+v8) / 8*.
  prefs: []
  type: TYPE_NORMAL
- en: For have our results to be statistically sound, we need to run these calculations
    over multiple simulations. You can see that if we extend the number of friends,
    the calculations get extremely complex, resulting in high consumption of computational
    resources. Therefore, specific approximations are used, resulting in different
    types of so-called explainers (approximators of Shapley values) in the `shap`
    library ([https://shap.readthedocs.io/en/latest/index.html](https://shap.readthedocs.io/en/latest/index.html)).
    Comparing Shapley's values for all friends, we can find the individual’s contribution
    to the final score.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we go back to the explanation of DL models, we can see that the friends
    become a set of features and that the score is the model performance. With this
    in mind, let’s have a look at SHAP explainers, which can be used for DL models:'
  prefs: []
  type: TYPE_NORMAL
- en: '`KernelExplainer`: This is the most popular method and is model agnostic. It’s
    based on **Local Interpretable Model-agnostic Explanations** (**LIME**), which
    we will discuss in the next section.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`DeepExplainer`: This method is based on the DeepList approach, which decomposes
    the output on a specific input ([https://arxiv.org/abs/1704.02685](https://arxiv.org/abs/1704.02685)).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`GradientExplainer`: This method is based on the extension of integrated gradients
    ([https://arxiv.org/abs/1703.01365](https://arxiv.org/abs/1703.01365)).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For example, we will present a minimalistic code example where SHAP is applied
    to a TF model. The complete details can be found in the official documentation
    at [https://shap-lrjball.readthedocs.io/en/latest/index.html](https://shap-lrjball.readthedocs.io/en/latest/index.html):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'For PyTorch models, you will need to wrap your model in a wrapper to convert
    the input and output into the correct types (`f=lambda x: model(torch.autograd.Variable(torch.from_numpy(x))).detach().numpy()`).
    In the proceeding example, we have defined `KernelExplainer`, which takes in a
    DL model and `sampled_data` as inputs. Next, we calculate the SHAP values (approximations
    of Shapley values) using the `explainer.shap_values` function. In this example,
    we are using `300` perturbation samples to estimate the SHAP values for the given
    prediction. If our `sampled_data` contains `100` examples, we will be performing
    100*300 model evaluations. Similarly, you can use `GradientExplainer` (`shap.GradientExplainer(model,
    sampled_data)`) or `DeepExplainer` (`shap.DeepExplainer(model, sampled_data)`).
    The size of `sampled_data` needs to be big enough to represent the distribution
    correctly. In the last few lines, we visualize the SHAP values in an additive
    force layout using the `shap.force_plot` function and create a global model interpretation
    plot using the `shap.summary_plot` function.'
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s look at the LIME approach.
  prefs: []
  type: TYPE_NORMAL
- en: Local Interpretable Model-agnostic Explanations (LIME)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: LIME is a method that trains a local surrogate model to explain the model predictions.
    First, you need to prepare a model you want to interpret and a sample. LIME uses
    your model to collect predictions from a set of perturbed data and compare them
    against the original sample to assign similarity weights (higher if predictions
    are closer to the prediction on the initial sample). LIME fits an intrinsically
    interpretable surrogate model on the sampled data using a specific number of features
    weighted by the similarity weights. Finally, LIME treats the surrogate model interpretation
    as an interpretation of the black-box model for your selected example. To perform
    LIME analysis, we can use the `lime` package ([https://lime-ml.readthedocs.io](https://lime-ml.readthedocs.io)).
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s have a look at an example designed for a DL model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, we are using the `LimeTabularExplainer` class. The
    constructor takes in a train set, feature, class names, and a mode type (`'classification'`).
    Similarly, you can set LIME for regression problems by providing the `'regression'`
    mode type. Then, by showing the five most important features and their influences,
    we explain the first prediction from the test set (`x[0]`). Lastly, we generate
    a plot from the computed LIME explanation.
  prefs: []
  type: TYPE_NORMAL
- en: Things to remember
  prefs: []
  type: TYPE_NORMAL
- en: a. Model interpretability and explainability are the two key concepts in Explainable
    AI.
  prefs: []
  type: TYPE_NORMAL
- en: b. Popular model-agnostic techniques in Explainable AI are PFI, FI, SHAP, and
    LIME.
  prefs: []
  type: TYPE_NORMAL
- en: c. PFI, FI, and SHAP are methods that allow you to interpret your model at both
    local (a single sample) and global (a set of samples) levels. On the other hand,
    LIME focuses on a single sample and the corresponding model prediction.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, we have explained the idea of Explainable AI and the four
    most common techniques: PFI, FI, SHAP, and LIME.'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We started the chapter with hyperparameter tuning. We described the three basic
    search algorithms that are used for hyperparameter tuning (grid search, random
    search, and Bayesian optimization) and introduced many tools you can integrate
    into your project. Out of the tools we listed, we covered Ray Tune as it supports
    distributed hyperparameter tuning and implements many of the state-of-the-art
    search algorithms out of the box.
  prefs: []
  type: TYPE_NORMAL
- en: Then, we discussed Explainable AI. We explained the most standard techniques
    (PFI, FI, SHAP, and LIME) and how they can be used to find out how a model's behavior
    changes with respect to each feature in a dataset.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will shift our focus toward deployment. We will learn
    about ONNX, an open format for ML models, and look at how to convert a TF or PyTorch
    model into an ONNX model.
  prefs: []
  type: TYPE_NORMAL
