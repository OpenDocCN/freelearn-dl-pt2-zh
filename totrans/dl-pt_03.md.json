["```py\nfrom torch.nn import Linear\nmyLayer = Linear(in_features=10,out_features=5,bias=True)\n```", "```py\ninp = Variable(torch.randn(1,10))\nmyLayer = Linear(in_features=10,out_features=5,bias=True)\nmyLayer(inp)\n```", "```py\nmyLayer.weight\n\nOutput :\nParameter containing:\n-0.2386 0.0828 0.2904 0.3133 0.2037 0.1858 -0.2642 0.2862 0.2874 0.1141\n 0.0512 -0.2286 -0.1717 0.0554 0.1766 -0.0517 0.3112 0.0980 -0.2364 -0.0442\n 0.0776 -0.2169 0.0183 -0.0384 0.0606 0.2890 -0.0068 0.2344 0.2711 -0.3039\n 0.1055 0.0224 0.2044 0.0782 0.0790 0.2744 -0.1785 -0.1681 -0.0681 0.3141\n 0.2715 0.2606 -0.0362 0.0113 0.1299 -0.1112 -0.1652 0.2276 0.3082 -0.2745\n[torch.FloatTensor of size 5x10]\n\nmyLayer.bias\n Output : Parameter containing:-0.2646-0.2232 0.2444 0.2177 0.0897[torch.FloatTensor of size 5\n```", "```py\nmyLayer1 = Linear(10,5)\nmyLayer2 = Linear(5,2)\nmyLayer2(myLayer1(inp))\n```", "```py\nsample_data = Variable(torch.Tensor([[1,2,-1,-1]]))\nmyRelu = ReLU()\nmyRelu(sample_data)\n\nOutput:\n\nVariable containing:\n 1 2 0 0\n[torch.FloatTensor of size 1x4]\n```", "```py\nclass MyFirstNetwork(nn.Module):\n\n    def __init__(self,input_size,hidden_size,output_size):\n        super(MyFirstNetwork,self).__init__()\n        self.layer1 = nn.Linear(input_size,hidden_size)\n        self.layer2 = nn.Linear(hidden_size,output_size)\n\n    def __forward__(self,input): \n        out = self.layer1(input)\n        out = nn.ReLU(out)\n        out = self.layer2(out)\n        return out\n\n```", "```py\nloss = nn.MSELoss()\ninput = Variable(torch.randn(3, 5), requires_grad=True)\ntarget = Variable(torch.randn(3, 5))\noutput = loss(input, target)\noutput.backward()\n```", "```py\ndef cross_entropy(true_label, prediction):\n    if true_label == 1:\n        return -log(prediction)\n    else:\n        return -log(1 - prediction)\n```", "```py\nloss = nn.CrossEntropyLoss()\ninput = Variable(torch.randn(3, 5), requires_grad=True)\ntarget = Variable(torch.LongTensor(3).random_(5))\noutput = loss(input, target)\noutput.backward()\n```", "```py\noptimizer = optim.SGD(model.parameters(), lr = 0.01)\n```", "```py\nfor input, target in dataset:\n    optimizer.zero_grad()\n    output = model(input)\n    loss = loss_fn(output, target)\n    loss.backward()\n    optimizer.step()\n```", "```py\npath = '../chapter3/dogsandcats/'\n\n#Read all the files inside our folder.\nfiles = glob(os.path.join(path,'*/*.jpg'))\n\nprint(f'Total no of images {len(files)}')\n\nno_of_images = len(files)\n\n#Create a shuffled index which can be used to create a validation data set\nshuffle = np.random.permutation(no_of_images)\n\n#Create a validation directory for holding validation images.\nos.mkdir(os.path.join(path,'valid'))\n\n#Create directories with label names \nfor t in ['train','valid']:\n     for folder in ['dog/','cat/']:\n          os.mkdir(os.path.join(path,t,folder)) \n\n#Copy a small subset of images into the validation folder.\nfor i in shuffle[:2000]:\n     folder = files[i].split('/')[-1].split('.')[0]\n     image = files[i].split('/')[-1]\n     os.rename(files[i],os.path.join(path,'valid',folder,image))\n\n#Copy a small subset of images into the training folder.\nfor i in shuffle[2000:]:\n     folder = files[i].split('/')[-1].split('.')[0]\n     image = files[i].split('/')[-1]\n     os.rename(files[i],os.path.join(path,'train',folder,image))\n```", "```py\nfiles = glob(os.path.join(path,'*/*.jpg'))\n```", "```py\nshuffle = np.random.permutation(no_of_images)\n```", "```py\nos.mkdir(os.path.join(path,'valid'))\nfor t in ['train','valid']:\n     for folder in ['dog/','cat/']:\n          os.mkdir(os.path.join(path,t,folder)) \n```", "```py\nfor i in shuffle[:2000]:\n     folder = files[i].split('/')[-1].split('.')[0]\n     image = files[i].split('/')[-1]\n     os.rename(files[i],os.path.join(path,'valid',folder,image))\n```", "```py\nsimple_transform=transforms.Compose([transforms.Scale((224,224)),\n                             transforms.ToTensor(),\n                             transforms.Normalize([0.485, 0.456,                     0.406], [0.229, 0.224, 0.225])])\ntrain = ImageFolder('dogsandcats/train/',simple_transform)\nvalid = ImageFolder('dogsandcats/valid/',simple_transform)\n```", "```py\ndef imshow(inp):\n    \"\"\"Imshow for Tensor.\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n    plt.imshow(inp)\n\n```", "```py\nimshow(train[50][0])\n```", "```py\ntrain_data_gen =  \n  torch.utils.data.DataLoader(train,batch_size=64,num_workers=3)\nvalid_data_gen = \n  torch.utils.data.DataLoader(valid,batch_size=64,num_workers=3)\n```", "```py\nmodel_ft = models.resnet18(pretrained=True)\nnum_ftrs = model_ft.fc.in_features\nmodel_ft.fc = nn.Linear(num_ftrs, 2)\n\nif is_cuda:\n    model_ft = model_ft.cuda()\n```", "```py\nmodel_ft.fc = nn.Linear(num_ftrs, 2)\n```", "```py\nif is_cuda:\n    model_ft = model_ft.cuda()\n```", "```py\n# Loss and Optimizer\nlearning_rate = 0.001\ncriterion = nn.CrossEntropyLoss()\noptimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7,  \n  gamma=0.1)\n```", "```py\ndef train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n    since = time.time()\n\n    best_model_wts = model.state_dict()\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'valid']:\n            if phase == 'train':\n                scheduler.step()\n                model.train(True) # Set model to training mode\n            else:\n                model.train(False) # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for data in dataloaders[phase]:\n                # get the inputs\n                inputs, labels = data\n\n                # wrap them in Variable\n                if is_cuda:\n                    inputs = Variable(inputs.cuda())\n                    labels = Variable(labels.cuda())\n                else:\n                    inputs, labels = Variable(inputs),                 Variable(labels)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                outputs = model(inputs)\n                _, preds = torch.max(outputs.data, 1)\n                loss = criterion(outputs, labels)\n\n                # backward + optimize only if in training phase\n                if phase == 'train':\n                    loss.backward()\n                    optimizer.step()\n\n                # statistics\n                running_loss += loss.data[0]\n                running_corrects += torch.sum(preds == labels.data)\n\n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc = running_corrects / dataset_sizes[phase]\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n\n            # deep copy the model\n            if phase == 'valid' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = model.state_dict()\n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed // 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model\n```", "```py\nEpoch 18/24\n----------\ntrain Loss: 0.0044 Acc: 0.9877\nvalid Loss: 0.0059 Acc: 0.8740\n\nEpoch 19/24\n----------\ntrain Loss: 0.0043 Acc: 0.9914\nvalid Loss: 0.0059 Acc: 0.8725\n\nEpoch 20/24\n----------\ntrain Loss: 0.0041 Acc: 0.9932\nvalid Loss: 0.0060 Acc: 0.8725\n\nEpoch 21/24\n----------\ntrain Loss: 0.0041 Acc: 0.9937\nvalid Loss: 0.0060 Acc: 0.8725\n\nEpoch 22/24\n----------\ntrain Loss: 0.0041 Acc: 0.9938\nvalid Loss: 0.0060 Acc: 0.8725\n\nEpoch 23/24\n----------\ntrain Loss: 0.0041 Acc: 0.9938\nvalid Loss: 0.0060 Acc: 0.8725\n\nEpoch 24/24\n----------\ntrain Loss: 0.0040 Acc: 0.9939\nvalid Loss: 0.0060 Acc: 0.8725\n\nTraining complete in 27m 8s\nBest val Acc: 0.874000\n```"]