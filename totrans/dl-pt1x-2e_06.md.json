["```py\ntransformation = transforms.Compose([transforms.ToTensor(),\ntransforms.Normalize((0.14,), (0.32,))])\ntraining_dataset = datasets.MNIST('dataset/',train=True,transform=transformation,\ndownload=True) test_dataset =\ndatasets.MNIST('dataset/',train=False,transform=transformation, download=True)\ntraining_loader = torch.utils.data.DataLoader(training_dataset,batch_size=32,shuffle=True)\ntest_loader = torch.utils.data.DataLoader(test_dataset,batch_size=32,shuffle=True)\n```", "```py\ndef plot_img(image):\nimage = image.numpy()[0] mean = 0.1307\nstd = 0.3081\nimage = ((mean * image) + std) plt.imshow(image,cmap='gray')\n```", "```py\nsample_data = next(iter(training_loader)) plot_img(sample_data[0][1]) plot_img(sample_data[0][2])\n```", "```py\nclass Network(nn.Module): def   init  (self):\nsuper(). init  ()\nself.conv1 = nn.Conv2d(1, 10, kernel_size=3)\nself.conv2 = nn.Conv2d(10, 20, kernel_size=3) self.conv2_drop = nn.Dropout2d()\nself.fullyconnected1 = nn.Linear(320, 50) self.fullyconnected2 = nn.Linear(50, 10)\n\ndef forward(self, x):\nx = F.relu(F.max_pool2d(self.conv1(x), 2))\nx = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2)) x = x.view(-1, 320)\nx = F.relu(self.fullyconnected1(x))\nx = F.dropout(x, training=self.training) x = self.fullyconnected2(x)\nreturn F.log_softmax(x)\n```", "```py\nconv = nn.Conv1d(1,1,3,bias=False) \nsample = torch.randn(1,1,7) \nconv(Variable(sample))\n\n#Check the weights of our convolution filter by \nconv.weight\n```", "```py\nx.view(-1, 320)\n```", "```py\ndef fit_model(epoch,model,data_loader,phase='training',volatile=False): if phase == 'training':\nmodel.train()\nif phase == 'validation': model.eval() volatile=True\nrunning_loss = 0.0\nrunning_correct = 0\nfor batch_idx , (data,target) in enumerate(data_loader): if is_cuda:\ndata,target = data.cuda(),target.cuda()\ndata , target = Variable(data,volatile),Variable(target) if phase == 'training':\noptimizer.zero_grad() output = model(data)\nloss = F.null_loss(output,target) running_loss +=\nF.null_loss(output,target,size_average=False).data[0] predictions = output.data.max(dim=1,keepdim=True)[1]\nrunning_correct += preds.eq(target.data.view_as(predictions)).cpu().sum() if phase == 'training':\nloss.backward() optimizer.step()\nloss = running_loss/len(data_loader.dataset)\naccuracy = 100\\. * running_correct/len(data_loader.dataset) print(f'{phase} loss is {loss:{5}.{2}} and {phase} accuracy is\n{running_correct}/{len(data_loader.dataset)}{accuracy:{10}.{4}}') return loss,accuracy\n```", "```py\nmodel = Network() if is_cuda:\nmodel.cuda()\n\noptimizer = optim.SGD(model.parameters(),lr=0.01,momentum=0.5) training_losses , training_accuracy = [],[]\nvalidation_losses , validation_accuracy = [],[] for epoch in range(1,20):\nepoch_loss, epoch_accuracy = fit(epoch,model,training_loader,phase='training')\nvalidation_epoch_loss , validation_epoch_accuracy = fit(epoch,model,test_loader,phase='validation')\ntraining_losses.append(epoch_loss) training_accuracy.append(epoch_accuracy) validation_losses.append(validation_epoch_loss) validation_accuracy.append(validation_epoch_accuracy)\n```", "```py\nplt.plot(range(1,len(training_losses)+1),training_losses,'bo',label = 'training loss')\nplt.plot(range(1,len(validation_losses)+1),validation_losses,'r',label = 'validation loss')\nplt.legend()\n```", "```py\nplt.plot(range(1,len(training_accuracy)+1),training_accuracy,'bo',label = 'train accuracy')\nplt.plot(range(1,len(validation_accuracy)+1),validation_accuracy,'r',label = 'val accuracy')\nplt.legend()\n```", "```py\nclass Network(nn.Module): def   init  (self):\nsuper(). init  ()\nself.conv1 = nn.Conv2d(3, 10, kernel_size=3) self.conv2 = nn.Conv2d(10, 20, kernel_size=3) self.conv2_drop = nn.Dropout2d()\nself.fc1 = nn.Linear(56180, 500) self.fc2 = nn.Linear(500,50) self.fc3 = nn.Linear(50, 2)\n\ndef forward(self, x):\nx = F.relu(F.max_pool2d(self.conv1(x), 2))\nx = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2)) x = x.view(x.size(0),-1)\nx = F.relu(self.fc1(x))\nx = F.dropout(x, training=self.training) x = F.relu(self.fc2(x))\nx = F.dropout(x,training=self.training) x = self.fc3(x)\nreturn F.log_softmax(x,dim=1)\n```", "```py\nfrom torchvision import models\nvgg = models.vgg16(pretrained=True)\n```", "```py\nVGG (\n  (features): Sequential (\n    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU (inplace)\n    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (3): ReLU (inplace)\n    (4): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (6): ReLU (inplace)\n   (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (8): ReLU (inplace)\n    (9): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n    (10):Conv2d(128, 256, kernel_size=(3, 3), stride=(1,1), padding=(1, 1))\n    (11): ReLU (inplace)\n    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (13): ReLU (inplace)\n    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (15): ReLU (inplace)\n    (16): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (18): ReLU (inplace)\n    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (20): ReLU (inplace)\n    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (22): ReLU (inplace)\n    (23): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1,1))\n    (25): ReLU (inplace)   \n    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (27): ReLU (inplace)\n    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (29): ReLU (inplace)\n    (30): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n  )\n  (classifier): Sequential ( \n    (0): Linear (25088 -> 4096)\n    (1): ReLU (inplace)\n    (2): Dropout (p = 0.5)\n    (3): Linear (4096 -> 4096)\n    (4): ReLU (inplace)\n    (5): Dropout (p = 0.5)\n    (6): Linear (4096 -> 1000)\n  )\n)\n```", "```py\nfor param in vgg.features.parameters(): param.requires_grad = False\n```", "```py\nvgg.classifier[6].out_features = 2\n```", "```py\noptimizer = optim.SGD(vgg.classifier.parameters(),lr=0.0001,momentum=0.5)\n```", "```py\ntraining_losses , training_accuracy = [],[] \nvalidation_losses , validation_accuracy = [],[]\nfor epoch in range(1,20): \n    epoch_loss, epoch_accuracy =\nfit(epoch,vgg,training_data_loader,phase='training')\n    validation_epoch_loss , validation_epoch_accuracy =\nfit(epoch,vgg,valid_data_loader,phase='validation')\n    training_losses.append(epoch_loss)\n    training_accuracy.append(epoch_accuracy)\n    validation_losses.append(validation_epoch_loss)\n    validation_accuracy.append(validation_epoch_accuracy)\n```", "```py\nfor layer in vgg.classifier.children(): if(type(layer) == nn.Dropout):\nlayer.p = 0.2\n\n#Training\ntraining_losses , training_accuracy = [],[] validation_losses , validation_accuracy = [],[]\nfor epoch in range(1,3): \n    epoch_loss, epoch_accuracy =\nfit(epoch,vgg,training_data_loader,phase='training')\n    validation_epoch_loss , validation_epoch_accuracy =\nfit(epoch,vgg,valid_data_loader,phase='validation')\n    training_losses.append(epoch_loss)\n    training_accuracy.append(epoch_accuracy)\n    validation_losses.append(validation_epoch_loss)\n    validation_accuracy.append(validation_epoch_accuracy)\n```", "```py\ntraining_transform =transforms.Compose([transforms.Resize((224,224)),\n                                     transforms.RandomHorizontalFlip(), \n                                        transforms.RandomRotation(0.2), \n                                        transforms.ToTensor(), \n                                        transforms.Normalize([0.485, 0.32, 0.406], [0.229, 0.224, 0.225])\n])\n\ntrain = ImageFolder('dogsandcats/train/',training_transform) valid = ImageFolder('dogsandcats/valid/',simple_transform)\n\n#Training\n\ntraining_losses , training_accuracy = [],[]\nvalidation_losses , validation_accuracy = [],[]\nfor epoch in range(1,3):\n    epoch_loss, epoch_accuracy = fit(epoch,vgg,training_data_loader,phase='training')\n    validation_epoch_loss , validation_epoch_accuracy = fit(epoch,vgg,valid_data_loader,phase='validation')\n    training_losses.append(epoch_loss)\n    training_accuracy.append(epoch_accuracy)\n    validation_losses.append(validation_epoch_loss)\n    validation_accuracy.append(validation_epoch_accuracy)\n```", "```py\n#Results\ntraining loss is 0.041 and training accuracy is 22657/23000 98.51 validation loss is 0.043 and validation accuracy is 1969/2000 98.45 training loss is 0.04 and training accuracy is 22697/23000 98.68 validation loss is 0.043 and validation accuracy is 1970/2000 98.5\n```", "```py\nvgg = models.vgg16(pretrained=True) vgg = vgg.cuda()\nfeatures = vgg.features\n\ntraining_data_loader = torch.utils.data.DataLoader(train,batch_size=32,num_workers=3,shuffle=False)\nvalid_data_loader = torch.utils.data.DataLoader(valid,batch_size=32,num_workers=3,shuffle=False)\n\ndef preconvfeat(dataset,model):\n    conv_features = [] \n    labels_list = []\n    for data in dataset: \n        inputs,labels = data\n        if is_cuda:\n            inputs , labels = inputs.cuda(),labels.cuda() \n        inputs , labels = Variable(inputs),Variable(labels) \n        output = model(inputs)\n        conv_features.extend(output.data.cpu().numpy())\n        labels_list.extend(labels.data.cpu().numpy())\n    conv_features = np.concatenate([[feat] for feat in conv_features])\n\n    return (conv_features,labels_list)\nconv_feat_train,labels_train = preconvfeat(training_data_loader,features) conv_feat_val,labels_val = preconvfeat(valid_data_loader,features)\n```", "```py\nclass CustomDataset(Dataset):\ndef init (self,feat,labels): self.conv_feat = feat self.labels = labels\ndef len (self):\nreturn len(self.conv_feat) def getitem (self,idx):\nreturn self.conv_feat[idx],self.labels[idx]\n\ntraining_feat_dataset = CustomDataset(conv_feat_train,labels_train) validation_feat_dataset = CustomDataset(conv_feat_val,labels_val)\n\ntraining_feat_loader = DataLoader(training_feat_dataset,batch_size=64,shuffle=True)\nvalidation_feat_loader = DataLoader(validation_feat_dataset,batch_size=64,shuffle=True)\n```", "```py\ntraining_losses , training_accuracy = [],[] validation_losses , validation_accuracy = [],[]\nfor epoch in range(1,20): epoch_loss, epoch_accuracy =\nfit_numpy(epoch,vgg.classifier,training_feat_loader,phase='training') validation_epoch_loss , validation_epoch_accuracy =\nfit_numpy(epoch,vgg.classifier,validation_feat_loader,phase='validation') training_losses.append(epoch_loss) training_accuracy.append(epoch_accuracy) validation_losses.append(validation_epoch_loss) validation_accuracy.append(validation_epoch_accuracy)\n```", "```py\nvgg = models.vgg16(pretrained=True).cuda()\n\nclass LayerActivations(): features=None\ndef   init  (self,model,layer_num):\nself.hook = model[layer_num].register_forward_hook(self.hook_fn) def hook_fn(self,module,input,output):\nself.features = output.cpu() def remove(self):\nself.hook.remove()\n\nconv_out = LayerActivations(vgg.features,0) o = vgg(Variable(img.cuda())) conv_out.remove()\nact = conv_out.features\n```", "```py\nfig = plt.figure(figsize=(20,50)) fig.subplots_adjust(left=0,right=1,bottom=0,top=0.8,hspace=0,\nwspace=0.2)\nfor i in range(30):\nax = fig.add_subplot(12,5,i+1,xticks=[],yticks=[]) ax.imshow(act[0][i])\n```", "```py\nvgg.state_dict().keys()\ncnn_weights = vgg.state_dict()['features.0.weight'].cpu()\n```"]