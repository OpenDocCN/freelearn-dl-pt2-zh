["```py\nimport os\nfrom torch import nn\nfrom torch.autograd import Variable\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nfrom torchvision.datasets import MNIST\nfrom torchvision.utils import save_image\n```", "```py\nnumber_epochs = 10\nbatch_size = 128\nlearning_rate = 1e-4\n```", "```py\ntransform_image = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])\n\ndataset = MNIST('./data', transform=transform_image)\ndata_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n```", "```py\nclass autoencoder_model(nn.Module):\n    def __init__(self):\n        super(autoencoder_model, self).__init__()\n        self.encoder = nn.Sequential(\n            nn.Linear(28 * 28, 128),\n            nn.ReLU(True),\n            nn.Linear(128, 64),\n            nn.ReLU(True), nn.Linear(64, 12), nn.ReLU(True), nn.Linear(12, 3))\n        self.decoder = nn.Sequential(\n            nn.Linear(3, 12),\n           nn.ReLU(True),\n            nn.Linear(12, 64),\n            nn.ReLU(True),\n            nn.Linear(64, 128),\n            nn.ReLU(True), nn.Linear(128, 28 * 28), nn.Tanh())\n\n    def forward(self, x):\n        x = self.encoder(x)\n        x = self.decoder(x)\n        return x\n\nmodel = autoencoder_model()\ncriterion = nn.MSELoss()\noptimizer = torch.optim.Adam(\nmodel.parameters(), lr=learning_rate, weight_decay=1e-5)\n```", "```py\ndef to_image(x):\n    x = 0.5 * (x + 1)\n    x = x.clamp(0, 1)\n    x = x.view(x.size(0), 1, 28, 28)\n    return x\n```", "```py\nfor epoch in range(number_epochs):\n    for data in data_loader:\n        image, i = data\n        image = image.view(image.size(0), -1)\n        image = Variable(image)\n\n        # Forward pass\n        output = model(image)\n        loss = criterion(output, image)\n\n        # Backward pass\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n    print('Epoch [{}/{}], Loss:{:.4f}'.format(epoch + 1, number_epochs, loss.data[0]))\n    if epoch % 10 == 0:\n        pic = to_image(output.cpu().data)\n        save_image(pic, './mlp_img/image_{}.png'.format(epoch))\n\ntorch.save(model.state_dict(), './sim_autoencoder.pth')\n```", "```py\nnumber_epochs = 10\nbatch_size = 128\nlearning_rate = 1e-4\n\ntransform_image = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])\n\ndataset = MNIST('./data', transform=transform_image)\ndata_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n```", "```py\nclass conv_autoencoder(nn.Module):\n    def __init__(self):\n        super(conv_autoencoder, self).__init__()\n        self.encoder = nn.Sequential(\n            nn.Conv2d(1, 16, 3, stride=3, padding=1), \n            nn.ReLU(True),\n            nn.MaxPool2d(2, stride=2), \n            nn.Conv2d(16, 8, 3, stride=2, padding=1), \n            nn.ReLU(True),\n            nn.MaxPool2d(2, stride=1) \n        )\n        self.decoder = nn.Sequential(\n            nn.ConvTranspose2d(8, 16, 3, stride=2), \n            nn.ReLU(True),\n            nn.ConvTranspose2d(16, 8, 5, stride=3, padding=1), \n            nn.ReLU(True),\n            nn.ConvTranspose2d(8, 1, 2, stride=2, padding=1), \n            nn.Tanh()\n        )\n\n    def forward(self, x):\n        x = self.encoder(x)\n        x = self.decoder(x)\n        return x\n\nmodel = conv_autoencoder()\ncriterion = nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n```", "```py\nfor epoch in range(number_epochs):\n    for data in data_loader:\n        img, i = data\n        img = Variable(img)\n\n        # Forward pass\n        output = model(img)\n        loss = criterion(output, img)\n\n        # Backward pass\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    # Print results\n    print('epoch [{}/{}], loss:{:.4f}'\n          .format(epoch+1, number_epochs, loss.data[0]))\n    if epoch % 10 == 0:\n        pic = to_image(output.cpu().data)\n        save_image(pic, './dc_img/image_{}.png'.format(epoch))\n\ntorch.save(model.state_dict(), './convolutional_autoencoder.pth')\n```", "```py\nclass VariationalAutoEncoder(nn.Module):\n    def __init__(self):\n        super(VariationalAutoEncoder, self).__init__()\n\n        self.fc1 = nn.Linear(784, 400)\n        self.fc21 = nn.Linear(400, 20)\n        self.fc22 = nn.Linear(400, 20)\n        self.fc3 = nn.Linear(20, 400)\n        self.fc4 = nn.Linear(400, 784)\n\n    def encode_function(self, x):\n        h1 = F.relu(self.fc1(x))\n        return self.fc21(h1), self.fc22(h1)\n\n    def reparametrize(self, mu, logvar):\n        std = logvar.mul(0.5).exp_()\n        if torch.cuda.is_available():\n            eps = torch.cuda.FloatTensor(std.size()).normal_()\n        else:\n            eps = torch.FloatTensor(std.size()).normal_()\n        eps = Variable(eps)\n        return eps.mul(std).add_(mu)\n\n    def decode_function(self, z):\n        h3 = F.relu(self.fc3(z))\n        return F.sigmoid(self.fc4(h3))\n\n    def forward(self, x):\n        mu, logvar = self.encode_function(x)\n        z = self.reparametrize(mu, logvar)\n        return self.decode_function(z), mu, logvar\n```", "```py\ndef loss_function(reconstruction_x, x, mu, latent_log_variance):\n    \"\"\"\n    reconstruction_x: generating images\n    x: original images\n    mu: latent mean\n    \"\"\"\n    BCE = reconstruction_function(reconstruction_x, x) \n    # KL loss = 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n    KLD_aspect = mu.pow(2).add_(latent_log_variance.exp()).mul_(-1).add_(1).add_(logvar)\n    KLD = torch.sum(KLD_aspect).mul_(-0.5)\n    # KL divergence\n    return BCE + KLD\n\noptimizer = optim.Adam(model.parameters(), lr=1e-4)\n```", "```py\nfor epoch in range(number_epochs):\n    model.train()\n    train_loss = 0\n    for batch_idx, data in enumerate(data_loader):\n        img, _ = data\n        img = img.view(img.size(0), -1)\n        img = Variable(img)\n        if torch.cuda.is_available():\n            img = img.cuda()\n        optimizer.zero_grad()\n        recon_batch, mu, logvar = model(img)\n        loss = loss_function(recon_batch, img, mu, logvar)\n        loss.backward()\n        train_loss += loss.data[0]\n        optimizer.step()\n        if batch_idx % 100 == 0:\n            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                epoch,\n                batch_idx * len(img),\n                len(data_loader.dataset), 100\\. * batch_idx / len(data_loader),\n                loss.data[0] / len(img)))\n\n    print('Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss / len(data_loader.dataset)))\n    if epoch % 10 == 0:\n        save = to_image(recon_batch.cpu().data)\n        save_image(save, './vae_img/image_{}.png'.format(epoch))\n\ntorch.save(model.state_dict(), './vae.pth')\n```", "```py\nwget -O moviedataset.zip http://files.grouplens.org/datasets/movielens/ml-1m.zip\nunzip -o moviedataset.zip -d ./data\nunzip -o moviedataset.zip -d ./data\n```", "```py\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.optim as optim\nimport torch.utils.data\nfrom torch.autograd import Variable\n```", "```py\nmovies = pd.read_csv('ml-1m/movies.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\nusers = pd.read_csv('ml-1m/users.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\nratings = pd.read_csv('ml-1m/ratings.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n```", "```py\ntraining_dataset = pd.read_csv('ml-100k/u1.base', delimiter = '\\t')\ntraining_dataset = np.array(training_set, dtype = 'int')\ntest_dataset = pd.read_csv('ml-100k/u1.test', delimiter = '\\t')\ntest_dataset = np.array(test_dataset, dtype = 'int') \n```", "```py\nno_users = int(max(max(training_dataset[:,0]), max(test_dataset[:,0])))\nno_movies = int(max(max(training_dataset[:,1]), max(test_dataset[:,1])))\n```", "```py\ndef convert_dataset(data):\n    converted_data = []\n    for id_users in range(1, no_users + 1):\n        id_movies = data[:,1][data[:,0] == id_users]\n        id_ratings = data[:,2][data[:,0] == id_users]\n        movie_ratings = np.zeros(no_movies)\n        ratings[id_movies - 1] = id_ratings\n        converted_data.append(list(movie_ratings))\n    return converted_data\n\ntraining_dataset = convert_dataset(training_dataset)\ntest_dataset = convert_dataset(test_dataset)\n```", "```py\ntraining_dataset = torch.FloatTensor(training_dataset)\ntest_dataset = torch.FloatTensor(test_dataset)\n```", "```py\ntraining_dataset[training_dataset == 0] = -1\ntraining_dataset[training_dataset == 1] = 0\ntraining_dataset[training_dataset == 2] = 0\ntraining_dataset[training_dataset >= 3] = 1\ntest_dataset[test_dataset == 0] = -1\ntest_dataset[test_dataset == 1] = 0\ntest_dataset[test_dataset == 2] = 0\ntest_dataset[test_dataset >= 3] = 1\n```", "```py\nclass RBM():\n    def __init__(self, num_visible_nodes, num_hidden_nodes):\n        self.W = torch.randn(num_hidden_nodes, num_visible_nodes)\n        self.a = torch.randn(1, num_hidden_nodes)\n        self.b = torch.randn(1, num_visible_nodes)\n\n    def sample_hidden_nodes(self, x):\n        wx = torch.mm(x, self.W.t())\n        activation = wx + self.a.expand_as(wx)\n        p_h_given_v = torch.sigmoid(activation)\n        return p_h_given_v, torch.bernoulli(p_h_given_v)\n\n    def sample_visible_nodes(self, y):\n        wy = torch.mm(y, self.W)\n        activation = wy + self.b.expand_as(wy)\n        p_v_given_h = torch.sigmoid(activation)\n        return p_v_given_h, torch.bernoulli(p_v_given_h)\n\n    def train(self, v0, vk, ph0, phk):\n        self.W += torch.mm(v0.t(), ph0) - torch.mm(vk.t(), phk)\n        self.b += torch.sum((v0 - vk), 0)\n        self.a += torch.sum((ph0 - phk), 0)\n```", "```py\nnum_visible_nodes = len(training_dataset[0])\nnum_hidden_nodes = 200\nbatch_size = 100\nrbm = RBM(num_visible_nodes, num_hidden_nodes)\n```", "```py\nnb_epoch = 10\nfor epoch in range(1, nb_epoch + 1):\n    train_loss = 0\n    s = 0.\n    for id_user in range(0, nb_users - batch_size, batch_size):\n        vk = training_dataset[id_user:id_user+batch_size]\n        v0 = training_dataset[id_user:id_user+batch_size]\n        ph0,_ = rbm.sample_hidden_nodes(v0)\n        for k in range(10):\n            _,hk = rbm.sample_hidden_nodes(vk)\n            _,vk = rbm.sample_visible_nodes(hk)\n            vk[v0<0] = v0[v0<0]\n        phk,_ = rbm.sample_hidden_nodes(vk)\n        rbm.train(v0, vk, ph0, phk)\n        train_loss += torch.mean(torch.abs(v0[v0>=0] - vk[v0>=0]))\n        s += 1.\n    print('epoch: '+str(epoch)+' loss: '+str(train_loss/s))\n```"]