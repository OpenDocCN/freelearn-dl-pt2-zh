- en: Deep Learning for Predictive Maintenance
  prefs: []
  type: TYPE_NORMAL
- en: Predictive maintenance is one of the most sought after machine learning solutions
    for IoT. It is also one of the most elusive machine learning solutions for IoT.
    Other areas of machine learning can easily be solved, implementing Computer Vision,
    for example, can be done in hours using tools such as OpenCV or Keras. To be successful
    with predictive maintenance you first need the right sensors. The *Data collection
    design* recipe in [Chapter 2](f3f42fb7-fd75-4607-8b92-3970c18ae234.xhtml), *Handling
    Data*, can be used to help determine proper sensor placement. The *Exploratory
    factor analysts* recipe in [Chapter 2](f3f42fb7-fd75-4607-8b92-3970c18ae234.xhtml),
    *Handling Data* can help determine the cadence with which the data needs to be
    stored. One of the biggest hurdles to implementing predictive maintenance is that
    there needs to be a sufficient amount of device failures. For rugged industrial
    devices, this can take a long time. Linking repair records with device telemetry
    is also a critical step.
  prefs: []
  type: TYPE_NORMAL
- en: Even though the challenge is daunting the rewards are great. A properly implemented
    predictive maintenance solution can save lives by helping to ensure critical devices
    are ready when needed. They can also increase customer loyalty because they help
    companies have less downtime than similar products on the market. Finally, they
    can reduce costs and improve efficiency by giving service technicians the information
    they need before servicing the device. This can help them diagnose the device
    and ensure that they have the right parts with them when they are servicing the
    device.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will continue to use the NASA Turbofan dataset for predictive
    maintenance and cover the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: Enhancing data using feature engineering
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using Keras for fall detection
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing LSTM to predict device failure
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying models to web services
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Enhancing data using feature engineering
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the best use of time in improving models is feature engineering. The
    ecosystem of IoT has many tools that can make it easier. Devices can be geographically
    connected or hierarchically connected with digital twins, graph frames, and GraphX.
    This can add features such as showing the degree of contentedness to other failing
    devices. Windowing can show how the current reading differs over a period of time.
    Streaming tools such as Kafka can combine different data streams allowing you
    to combine data from other sources. Machines that are outdoor may be negatively
    affected by high temperatures or moisture as opposed to machines that are in a
    climate-controlled building.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we are going to look at enhancing our data by looking at time-series
    data such as deltas, seasonality, and windowing. One of the most valuable uses
    of time for a data scientist is feature engineering. Being able to slice the data
    into meaningful features can greatly increase the accuracy of our models.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the *Predictive maintenance with XGBoost* recipe in the previous chapter,
    we used XGBoost to predict whether or not a machine needed maintenance. We have
    imported the NASA *Turbofan engine degradation simulation* dataset which can be
    found at [https://data.nasa.gov/dataset/Turbofan-engine-degradation-simulation-data-set/vrks-gjie](https://data.nasa.gov/dataset/Turbofan-engine-degradation-simulation-data-set/vrks-gjie).
    In the rest of this chapter, we will continue to use that dataset. To get ready
    you will need the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Then if you have not already imported `numpy`, `pandas`, `matplotlib`, and `seaborn`
    into Databricks do so now.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following steps need to be observed to follow this recipe:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Firstly, import the required libraries. We will be using `pyspark.sql`, `numpy`, and
    `pandas` for data manipulation and `matplotlib` and `seaborn` for visualization:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we''re going to import the data and apply a schema to it so that the
    data types can be correctly used. To do this we import the data file through the
    wizard and then apply our schema to it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we put it into a Spark DataFrame:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'We then create a temporary view so that we can run a Spark SQL job on it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we calculate **remaining useful life** (**RUL**). Using the SQL magics,
    we create a table named `engine` from the `raw_engine` temp view we just created.
    We then use SQL to calculate the RUL:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'We then import the data into a Spark DataFrame:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we calculate the r**ate of change** (**ROC**).In the ROC calculation, we
    are looking at the ROC based on the current record compared to the previous record. 
    The ROC calculation gets the percent of change between the current cycle and the
    previous one:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we review static columns. In order to do that, we''re going to convert
    the Spark DataFrame to Pandas so that we can view summary statistics on the data
    such as mean quartiles and​ standard deviation:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'This will get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f5e81791-47d8-409d-889d-d7dce9d1933a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now we drop the columns that are not valuable to us in this exercise. For example,
    we are going to drop `settings3` and `s1` columns because the values never change:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we are going to review the correlation between values. We are looking
    for columns that are exactly the same. First, we perform a correlation function
    on the DataFrame. Then we use `np.zeros_like` to mask the upper triangle. We are
    then going to set the figure size. Next, we are going to use `diverging_palette`
    to define a custom color map, then we are going to use the `heatmap` function
    do draw the heat map:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The following heat map shows values with a high degree of correlation. The
    values that are `1` show that they are perfectly correlated and therefore can
    be dropped from the analysis:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d4faf71c-ccdf-4a10-9ffd-43fc492f6403.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Remove similar columns. We found that `S14` is exactly the same as `S9` so
    we are removing that column:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we take the DataFrame and express it visually. A histogram or distribution
    table is used to show potential issues with our data such as outliers, skew data,
    random data and data that would not affect the model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The following histogram screenshots are the results:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4c9b992c-c00f-4fc0-823d-cf325eb3d7a7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We then review the noise of our model to make sure that it is not unduly affected
    by fluctuation:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c9c1d93d-82d5-4054-b97f-e88d4ebb5f6e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Based on the previous step, it is clear that the data is noisy. This can lead
    to false readings. A rolling average can help smooth the data. Using a 7 cycle
    rolling average we denoise the data as shown:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'The following screenshot is a chart of `rolling_average_s4` versus `s4`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a06cb431-58c3-48ee-8b3f-899137feb76c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Since we want this data to be accessible to other notebooks, we''re going to
    save it as an ML ready table:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this recipe, we have performed feature engineering so that we could make
    our data more usable by our ML algorithms. We removed the columns with no variation,
    high correlation, and we denoised the dataset. In *step 8* we removed the columns
    with no variation. The method describes the data in several ways. Reviewing the
    chart showed that many variables do not change at all. Next, we used a heat map
    to find sensors that had the same data. Finally, we used a rolling average to
    smooth the data from our original dataset into a new one.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'So far we have just looked at training data. But we will also need to look
    at testing the data. There is a test dataset and a RUL dataset. These datasets
    will help us test our models. To import them you would run 2 additional import
    steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Importing test data**: Relying on the schema from the training set the test
    set is imported and put in a table called `engine_test`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '**Importing the RUL Dataset**: The next step is to import the remaining useful
    life dataset and save that to a table as well:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Using keras for fall detection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One strategy for predictive maintenance is to look at patterns of device failures
    for a given record. In this recipe, we will classify the data that exhibits a
    pattern that happens before the device fails.
  prefs: []
  type: TYPE_NORMAL
- en: We will be using `keras`, which is a fairly powerful machine learning library.
    Keras strips away some of the complexity of TensorFlow and PyTorch. Keras is a
    great framework for beginners in machine learning as it is easy to get started
    on and the concepts learned in Keras transfer to more expressive machine learning
    libraries such as TensorFlow and PyTorch.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This recipe expands on the predictive maintenance dataset we feature engineered
    in the previous recipe. If you have not already done so you will need to import
    the `keras`, `tensorflow`, `sklearn`, `pandas`, and `numpy` libraries into your
    Databricks cluster.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Please observe the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Firstly, import the required libraries. We import `pandas`, `pyspark.sql`,
    and `numpy` for data manipulation, `keras` for machine learning, and `sklearn`
    for evaluating the model. After evaluating the model we use `io`, `pickle`, and
    `mlflow` to save the model and results so that it can be evaluated against other
    models:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we import training and testing data. Out training data will be used to
    train our models and our testing data will be used to evaluate the models:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we scale the data. Each sensor of the dataset has a different scale. For
    example, the maximum value of `S1` is `518` while the maximum value of `S16` is
    `0.03`. For that reason, we convert all of the values to a range between `0` and
    `1`. Allowing each metric affect the model in a similar way. We will make use
    of the `MinMaxScaler` function from the `sklearn` library to adjust the scale:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'The first layer, the input layer, has 32 nodes. The activation function, `LeakyReLU`,
    defines the output node when given the input. To prevent overfitting, 25% of the
    layers both hidden and visible are dropped when training:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Similar to the input layer, the hidden layer, uses 32 nodes as the input layer
    and `LeakyReLU` as its output layer. It also uses a 25% drop out to prevent overfitting:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we add an output layer. We give it one layer so that we can have an
    output between `0` and `1`. `sigmoid`, our activation function, helps predict
    the probability of the output. Our optimizer, `rmsprop`, along with the loss function
    helps optimize the data pattern and reduce the error rate:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we train the Model. We use the `model.fit` function to specify our training
    and test data.  The batch size is used to set the number of training records used
    in 1 iteration of the algorithm.  The epoch of `5` means that it will pass through
    the data set 5 times:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'The next step is to evaluate the results. We use the trained model and our `X_test` dataset
    to get the predictions (`y_pred`). We then compare the predictions with the real
    results and review how accurate it is:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we save the results to `mlflow`. The results will be compared against
    the other ML algorithms for predictive maintenance we are using in this book:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are typically three tasks that neural networks does:'
  prefs: []
  type: TYPE_NORMAL
- en: Import data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Recognize the patterns of the data by training
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Predicting the outcomes of new data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Neural networks take in data, trains themselves to recognize the patterns of
    the data, and then are used to predict the outcomes of new data. This recipe uses
    the cleaned and feature engineered dataset saved in the previous recipe. The `X_train` dataset
    is pulled in from the `spark` data table into a Panda DataFrame. The training
    DataFrames, `X_train`, and `y_train` are used for training. `X_test` gives us
    a list of devices that have failed and `y_test` gives us the real-time failure
    of those machines. Those datasets are used to train models and test the results.
  prefs: []
  type: TYPE_NORMAL
- en: First, we have the input layer. The data is fed to each of our 32 input neurons.
    The neurons are connected through channels. The channel is assigned a numerical
    value known as **weight**. The inputs are multiplied by the corresponding weight
    and their sum is sent as input to the neurons in the hidden layer. Each of these
    neurons is associated with a numerical value called the **bias**, which is added
    to the input sum. This value is then passed to a threshold function called the
    **activation function**. The activation function determines if a neuron will get
    activated or not. We used Leaky ReLU as our activation function for our first
    2 layers. **ReLU** or **Rectified Linear Unit** is a popular activation function
    because it solves the vanishing gradient problem. In this recipe, we used the
    Leaky ReLU. Leaky ReLU solves a problem that ReLU has where big gradients can
    cause the neuron to never fire. The activated neuron passes its data to the next
    layer over the channels. This method allows the data to be propagated through
    the network. This is called **forward propagation**. In the output layer, the
    neuron with the highest layer fires and determines the output.
  prefs: []
  type: TYPE_NORMAL
- en: 'When we first start running data through our network, the data usually has
    a high degree of error. Our error and optimizer functions use backpropagation
    to update the weights. The cycle of forward propagation and backpropagation is
    repeated to achieve a lower error rate. The following diagram shows how the input,
    hidden, and output layers are linked together:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5d5bf0ad-fd08-43b0-969e-c5222122e358.png)'
  prefs: []
  type: TYPE_IMG
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this recipe, we used `LeakyReLU` as our activation function, `rmsprop` as
    our optimizer, and `binary_crossentropy` as our loss function. We then saved the
    results to `mlflow`. We can tune parameters in this experiment by trying different
    combinations such as the number of neurons or the number of layers. We could also
    change the activation function to use ReLU or TanH. We could also use `Adam` as
    our optimizer. Saving those results to `mlflow` allows us to improve our model.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing LSTM to predict device failure
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Recurrent neural networks predict sequences of data. In the previous recipe,
    we looked at 1 point in time and determined to determine if maintenance was needed.
    As we saw in the first recipe when we did the data analysis the turbofan run to
    failure dataset is highly variable. The data reading at any point in time might
    indicate a need for maintenance while the next indicates that there is no need
    for maintenance. When determining whether or not to send a technician out having
    an oscillating signal can be problematic. **Long Short Term Memory** (**LSTM**)
    is often used with time-series data such as the turbofan run to failure dataset.
  prefs: []
  type: TYPE_NORMAL
- en: With the LSTM, we look at a series of data, similar to windowing. LSTM uses
    an ordered sequence to help determine, in our case, if a turbofan engine is about
    to fail based on the previous sequence of data.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For this recipe we will use the NASA *Turbofan run to failure* dataset. For
    this recipe we will be using a Databricks notebook. This recipe requires a few
    libraries to be installed. For data processing we need to install `numpy` and
    `pandas`, `keras` for creating a LSTM model, and `sklearn` and `mlflow` for evaluating
    and saving the results of our model.
  prefs: []
  type: TYPE_NORMAL
- en: Even though in previous recipes we added windowing and preprocessed the data,
    in this recipe we will use the raw data. LSTMs window the data and also have a
    good deal of extraction and transformation that is unique to this type of ML Algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will execute the following steps for this recipe:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we will import all of the libraries which we will need later. We will
    import `pandas` and `numpy` for data processing, `keras` for the ML models, `sklearn`
    for evaluations, and `pickel` and `mlflow` for storing the results:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Next we will set the variables. We will set 2 cycles periods. In addition we
    use a sequence length variable. The sequence length allows the LSTM to look back
    over 5 cycles. This is similar to windowing that was discussed in [Chapter 1](a6e87d27-4456-40a7-a006-5fdb54960858.xhtml),
    *Setting Up the IoT and AI Environment*. We are also going to get a list of data
    columns:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Next we import data from the `spark` data tables we created in the *Simple
    predictive maintenance with XGBoost* recipe in [Chapter 3](4dd8d581-73ef-4698-9a85-85b415c0b2f2.xhtml),
    *Machine Learning for IoT*.  We also drop the `label` column because we are going
    to recalculate the labels. We are going to import three DataFrames. The `train`
    DataFrame is used to train the model. The `test` DataFrame is used to test the
    accuracy of the model and the `truth` DataFrame is the actual failures for the
    `test` DataFrame:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we generate labels that show if a device needs maintenance. `label1` shows
    when a device will fail in 14 cycles and `label2` shows when a device will fail
    in 7 cycles. First we create a DataFrame that shows the RUL based on the maximum
    cycle number for each engine. Next we use that the RUL DataFrame create a RUL
    column in our train DataFrame. We do this by subtracting the maximum life from
    the current cycle. We then drop our `max` column. Next we create a new column
    `label1`. `label1` has a `1` value if the RUL is less than the 14 cycles. Then
    copy that over to `label2` and add a `2` value if the RUL is less than 1 week:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'In addition to generating labels for training data we also need to do so for
    test data. The training and test data are slightly different. The training data
    had an end date that signified when the machine broke. The training set does not.
    Instead we have a `truth` DataFrame that shows when the machine actually failed.
    To add the label columns we need to combine the `test` and `truth` dataset before
    we can calculate the labels:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, because the columns have different mins and maxes, we will normalize
    the data so that one variable does not overshadow the rest. To do this we are
    going to use the `sklearn` library''s `MinMaxScaler` function. This function transforms
    the values between `0` and `1`. It is a great scalier to use when, as in our case,
    there is not a lot of outlier values. We are going to do the same normalization
    step for both the training and test set:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'The LSTM algorithm in Keras requires the data to be in a sequence. In our variables
    section, we chose to have `sequence_length` equal to `100`. This is one of the
    hyperparameters that can be tuned during experimentation. As this is a look at
    data over a sequential period of time the sequence length is the length of the
    sequence of data we are training the model on. There is no real rule of thumb
    on what is the optimal length for a sequence. But from experimentation, it became
    clear that small sequences were less accurate. To aid in generating our sequence
    we use the function to return the sequential data in a way that the LSTM algorithm
    expects:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'The next step is to build a neural network. We build the first layer of our
    LSTM. We start off with a sequential model. Then give it the input shape and length
    of the sequence. The units tell us the dimensionality of the output shape which
    it will pass to the next layer. Next, it returns either `true` or `false`. We
    then add `Dropout` to add the randomness to our training that prevents overfitting:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'We then build the network''s hidden layer. Similar to the first layer the hidden
    layer is an LSTM layer. If, however, instead of passing the entire sequence state
    to the output just passes the last nodes'' values:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we build the network''s output layer. The output layer specifies the
    output dimensions and the `activation` function. With this we have built the shape
    of our neural network:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we run the `compile` method which configures the model for training.
    In it we put the metric we are evaluating against. In this case, we are measuring against
    `accuracy`. We then define our measure of error or loss. In this example, we are
    using `binary_crossentropy` as our measure. Finally, we specify the optimizer that
    will reduce error every iteration:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'We then use our `fit` function to train the model. Our `epochs` parameters
    means that the data will be run through 10 times. Because of the random dropout,
    the extra runs will increase accuracy. We are using `batch_size` of `200`. This
    means that model will train through 200 samples before it updates the gradients.
    Next, we use `validation_split` to put 95% of the data to training the model and
    5% to validating the model. Finally, we use an `EarlyStopping` callback to stop
    the model from training when it stops improving accuracy:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we evaluate our model based on the 95%/5% split we performed on the training
    data. The results show our model is evaluating the 5% data that we held back at
    an 87% accuracy:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we look at the confusion matrix which shows us a matrix of correct or
    wrong assessments of whether the engine needed maintenance or not:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Our confusion matrix looks like the following grid:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | **Actually Did not need maintenance** | **Predicted Needed Maintenance**
    |'
  prefs: []
  type: TYPE_TB
- en: '| **Actually Did not need maintenance** | 13911 | 220 |'
  prefs: []
  type: TYPE_TB
- en: '| **Actually  Needed Maintenance** | 201 | 1299 |'
  prefs: []
  type: TYPE_TB
- en: 'We then compute the precision and recall. Because the dataset is unbalanced,
    meaning there are far more values that do not need maintenance than they do, precision
    and recall are the most appropriate measures for evaluating this algorithm:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we need to transform the data so that the testing data is the same type
    of sequential data that the training data is. To do this we perform a data transformation
    step similar to the one we did for the training data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we evaluate the model generated with the training dataset against the
    test dataset to see how accurately the model predicts when an engine needs maintenance:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have our results we store those along with the model in our MLflow
    database:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A LSTM is a special type of **recurrent neural network** (**RNN**). A RNN is
    a neural network architecture that deal with sequenced data by keeping the sequence
    in memory. Conversely, a typical feed-forward neural does not keep the information
    about the sequences and do not allow for flexible inputs and outputs. A recursive
    neural network uses recursion to call from one output back to its input thereby
    generating a sequence. It passes a copy of the state of the network at any given
    time. In our case we are using two layers for our RNN. This additional layer helps
    with accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: LSTMs solve a problem of vanilla RNNs by dropping out data to solve the vanishing
    gradient problem. The vanishing gradient problem is when the neural network stops
    training early but is inaccurate. By using dropout data we can help solve that
    problem. The LSTM does this by using gating functions.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying models to web services
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Deployment of the model can be different depending on the capabilities of the
    device. Some devices with extra compute can handle having the machine learning
    models run directly on the device. While others require assistance. In this chapter,
    we are going to deploy the model to a simple web service. With modern cloud web
    apps or Kubernetes these web services can scale to meet the needs of the fleet
    of devices. In the next chapter, we will show how to run the model on the device.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: So far in this book, we have looked at three different machine learning algorithms
    to solve the predictive maintenance problem with the NASA Turbofan run to failure
    dataset. We recorded the results to MLflow. We can see that our XGBoost notebook
    outperformed the more complex neural networks. The following screenshot shows
    the MLflow result set showing the parameters and their associated scores.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/46fbd902-91fa-438d-9978-be9a8f860bef.png)'
  prefs: []
  type: TYPE_IMG
- en: From here we can download our model and put it in our web service. To do this
    we are going to use a Python Flask web service and Docker to make the service
    portable. Before we start, `pip install` the python `Flask` package. Also install
    Docker onto your local computer. Docker is a tool that allows you to build out
    complex deployments.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this project, you will need to create three files for testing the predictor
    web service and one file to scale it to production. First create `app.py` for
    our web server, `requirements.txt` for the dependencies, and the XGBoost model
    you downloaded from `mlflow`. These files will allow you to test the web service.
    Next, to put it into production you will need to dockerize the application. Dockerizing
    the file allow you to deploy it to services such as cloud-based web application
    or Kubernetes services. These services scale easily making onboarding new IoT
    devices seamless. Then execute the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `app.py` file is the Flask application. Import `Flask` for the web service,
    `os` and `pickle` for reading the model into memory, `pandas` for data manipulation,
    and `xgboost` to run our model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Next is to initialize our variables. By loading the Flask application and XGBoost
    model into memory outside a function we ensure that it only loads once rather
    than on every web service call.  By doing this we greatly increase the speed and
    efficiency of the web service. We use `pickle` to re-hydrate our model. `pickle`
    can take almost any Python object and write it to disk. It can also, as in our
    case, read if from disk and put it back into memory:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'We then create `@application.route` to give us an `http` endpoint. The `POST`
    methods section specifies that it will only accept post web request. We also specify
    that the URL will route to `/predict`. For example, when we run this locally we
    could use the `http://localhost:8000/precict` URL to post our JSON string. We
    then convert it into a `pandas` DataFrame and then an XGBoost data matrix becomes
    calling `predict`. We then determine if it is above `.5` or below and return the
    results:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, the last thing to do in any Flask app is to call the `application.run`
    method.  This method allows us to specify a host. In this case, we are specifying
    a special host of `0.0.0.0` which tells flask to accept requests from other computers.
    Next, we specify a port. The port can be any number. It does however need to match
    the port in the Dockerfile:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'We then create a requirements file. The `requirements.txt` file will install
    all of the python dependencies for the project. The docker will use this to install
    the dependencies:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we create the Dockerfile. The `docker` file allows the deployment of
    the predictor to a web endpoint. The first line of the docker file will pull in
    the official python 3.7.5 image from Docker Hub. Next, we copy the local folder
    to a new folder in the docker container in a folder named `app`. Next, we set
    the working directory to the `app` folder. Then we use `pip install` to install
    the requirements from the file we created in *step 5*. Then we expose port `8000`.
    Finally, we run the `gunicorn` command that starts the Gunicorn server:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Flask is a lightweight web server. We pull in the model that we saved to disk
    using `pickle` to rehydrate the model. We then create an `http` endpoint to call
    into.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Modern cloud-based web applications such as **Azure Web Apps** can automatically
    pull new Docker images into production. There is also a great deal of DevOps tools
    that can pull images and run them through various tests before deploying them
    with Docker container instances or docker orchestration tools such as Kubernetes.
    But for them to do this one must first put them into a container registry such
    as **Azure Container Registry** or **Docker Hub**. To do this we will need to
    do a few steps. First, we will build our container. Next, we can run our container
    to ensure that it works. Then we log into our container registry service and push
    the container to it. The detailed steps are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we build the container. To do it we navigate to the folder with the
    docker file and run docker build. We are going to tag it with the `-t` command
    to `ch4`.  We then specify that the docker file is in the local folder with the
    period `.`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have a docker image built, we are going to run the container based
    on the image with the `docker run` command. We are going to use the `-it` interactive
    command so we can see any output from the server. We are also going to use the
    `-p` or `port` command to specify that we are mapping the docker containers internal
    port `8000` to the external port `8000`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: We then need to put the container into something that can be accessible by our
    compute resource. To do this, first register for a Docker Registry service such
    as Docker Hub or Azure Container Registry. Then create a new repository. The repository
    provider will give you a path for that repository.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Next is to log in to your container registry service, tag the container, and
    push the container.  Remember to replace `[Your container path]` with the registry
    name or path provided by the registry service:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: You can then use docker enabled cloud technology to push that predictor service
    into production. Your device can then send its sensor reading to the web service
    and receive through a cloud to device message whether the device needs maintenance
    or not.
  prefs: []
  type: TYPE_NORMAL
