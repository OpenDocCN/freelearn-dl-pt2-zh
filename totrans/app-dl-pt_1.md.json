["```py\n    import torch\n    ```", "```py\n    tensor_1 = torch.tensor([0.1,1,0.9,0.7,0.3])\n    tensor_2 = torch.tensor([[0,0.2,0.4,0.6],[1,0.8,0.6,0.4]])\n    tensor_3 = torch.tensor([[[0.3,0.6],[1,0]], [[0.3,0.6],[0,1]]])\n    ```", "```py\n    tensor_1 = torch.cuda.tensor([0.1,1,0.9,0.7,0.3])\n    tensor_2 = torch.cuda.tensor([[0,0.2,0.4,0.6],[1,0.8,0.6,0.4]])\n    tensor_3 = torch.cuda.tensor([[[0.3,0.6],[1,0]], [[0.3,0.6],[0,1]]])\n    ```", "```py\n    print(tensor_1.shape)\n    print(tensor_2.shape)\n    print(tensor_3.shape)\n    ```", "```py\n    torch.Size([5])\n    torch.Size([2, 4])\n    torch.Size([2, 2, 2])\n    ```", "```py\na = torch.tensor([5.0, 3.0], requires_grad=True)\nb = torch.tensor([1.0, 4.0])\nab = ((a + b) ** 2).sum()\nab.backward()\n```", "```py\nimport torch.nn as nn\nmodel = nn.Sequential(nn.Linear(input_units, hidden_units),         nn.ReLU(),         nn.Linear(hidden_units, output_units),         nn.Sigmoid())\nloss_funct = torch.nn.MSELoss()\n```", "```py\noptimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n```", "```py\nfor i in range(100):\n    # Call to to the model to perform a prediction\n    y_pred = model(x)\n    # Calculation of loss function based on y_pred and y\n    loss = loss_func(y_pred, y)\n    # Zero the gradients so that previous ones don't accumulate\n    optimizer.zero_grad()\n    # Calculate the gradients of the loss function\n    loss.backward()\n    # Call to the optimizer to perform an update of the parameters\n    optimizer.step()\n```", "```py\n    model.state_dict()\n    ```"]