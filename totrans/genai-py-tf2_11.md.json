["```py\nmusic21. We then use its utility function to visualize the information in the file:\n```", "```py\nfrom music21 import converter\nmidi_filepath = 'Piano Sonata No.27.mid'\nmidi_score = converter.parse(midi_filepath).chordify()\n# text-form\nprint(midi_score.show('text'))\n# piano-roll form\nprint(midi_score.show()) \n```", "```py\nfrom music21 import converter\ndata_dir = 'midi_dataset'\n# list of files\nmidi_list = os.listdir(data_dir)\n# Load and make list of stream objects\noriginal_scores = []\nfor midi in tqdm(midi_list):\n    score = converter.parse(os.path.join(data_dir,midi))\n    original_scores.append(score)\n# Merge notes into chords\noriginal_scores = [midi.chordify() for midi in tqdm(original_scores)] \n```", "```py\n# Define empty lists of lists\noriginal_chords = [[] for _ in original_scores]\noriginal_durations = [[] for _ in original_scores]\noriginal_keys = []\n# Extract notes, chords, durations, and keys\nfor i, midi in tqdm(enumerate(original_scores)):\n    original_keys.append(str(midi.analyze('key')))\n    for element in midi:\n        if isinstance(element, note.Note):\n            original_chords[i].append(element.pitch)\n            original_durations[i].append(element.duration.quarterLength)\n        elif isinstance(element, chord.Chord):\n            original_chords[i].append('.'.join(str(n) for n in element.pitches))\n            original_durations[i].append(element.duration.quarterLength) \nC major key:\n```", "```py\n# Create list of chords and durations from songs in C major\nmajor_chords = [c for (c, k) in tqdm(zip(original_chords, original_keys)) if (k == 'C major')]\nmajor_durations = [c for (c, k) in tqdm(zip(original_durations, original_keys)) if (k == 'C major')] \nmapping and presents a sample output as well:\n```", "```py\ndef get_distinct(elements):\n    # Get all pitch names\n    element_names = sorted(set(elements))\n    n_elements = len(element_names)\n    return (element_names, n_elements)\ndef create_lookups(element_names):\n    # create dictionary to map notes and durations to integers\n    element_to_int = dict((element, number) for number, element in enumerate(element_names))\n    int_to_element = dict((number, element) for number, element in enumerate(element_names))\n    return (element_to_int, int_to_element)\n# get the distinct sets of notes and durations\nnote_names, n_notes = get_distinct([n for chord in major_chords for n in chord])\nduration_names, n_durations = get_distinct([d for dur in major_durations for d in dur])\ndistincts = [note_names, n_notes, duration_names, n_durations]\nwith open(os.path.join(store_folder, 'distincts'), 'wb') as f:\n    pickle.dump(distincts, f)\n# make the lookup dictionaries for notes and durations and save\nnote_to_int, int_to_note = create_lookups(note_names)\nduration_to_int, int_to_duration = create_lookups(duration_names)\nlookups = [note_to_int, int_to_note, duration_to_int, int_to_duration]\nwith open(os.path.join(store_folder, 'lookups'), 'wb') as f:\n    pickle.dump(lookups, f)\nprint(\"Unique Notes={} and Duration values={}\".format(n_notes,n_durations)) \n```", "```py\nUnique Notes=2963 and Duration values=18 \n```", "```py\n# Set sequence length\nsequence_length = 32\n# Define empty array for training data\ntrain_chords = []\ntrain_durations = []\ntarget_chords = []\ntarget_durations = []\n# Construct train and target sequences for chords and durations\n# hint: refer back to Chapter 9 where we prepared similar \n# training data\n# sequences for an LSTM-based text generation network\nfor s in range(len(major_chords)):\n    chord_list = [note_to_int[c] for c in major_chords[s]]\n    duration_list = [duration_to_int[d] for d in major_durations[s]]\n    for i in range(len(chord_list) - sequence_length):\n        train_chords.append(chord_list[i:i+sequence_length])\n        train_durations.append(duration_list[i:i+sequence_length])\n        target_chords.append(chord_list[i+1])\n        target_durations.append(duration_list[i+1]) \n```", "```py\nprint(train_chords[0]) \n```", "```py\narray([ 935, 1773, 2070, 2788,  244,  594, 2882, 1126,  152, 2071, \n        2862, 2343, 2342,  220,  221, 2124, 2123, 2832, 2584, 939, \n        1818, 2608, 2462,  702,  935, 1773, 2070, 2788,  244, 594,\n        2882, 1126]) \n```", "```py\nprint(target_chords[0]) \n```", "```py\n1773 \n```", "```py\nprint(train_durations[0]) \n```", "```py\narray([ 9,  9,  9, 12,  5,  8,  2,  9,  9,  9,  9,  5,  5,  8,  2,\n        5,  5,  9,  9,  7,  3,  2,  4,  3,  9,  9,  9, 12,  5,  8,\n        2,  9]) \n```", "```py\nprint(target_durations[0]) \n```", "```py\n9 \n```", "```py\ndef create_network(n_notes, n_durations, embed_size = 100,                                          rnn_units = 256):\n    \"\"\" create the structure of the neural network \"\"\"\n    notes_in = Input(shape = (None,))\n    durations_in = Input(shape = (None,))\n    x1 = Embedding(n_notes, embed_size)(notes_in)\n    x2 = Embedding(n_durations, embed_size)(durations_in) \n    x = Concatenate()([x1,x2])\n    x = LSTM(rnn_units, return_sequences=True)(x)\n    x = LSTM(rnn_units, return_sequences=True)(x)\n    # attention\n    e = Dense(1, activation='tanh')(x)\n    e = Reshape([-1])(e)\n    alpha = Activation('softmax')(e)\n    alpha_repeated = Permute([2, 1])(RepeatVector(rnn_units)(alpha))\n    c = Multiply()([x, alpha_repeated])\n    c = Lambda(lambda xin: K.sum(xin, axis=1), output_shape=(rnn_units,))(c)\n\n    notes_out = Dense(n_notes, activation = 'softmax', name = 'pitch')(c)\n    durations_out = Dense(n_durations, activation = 'softmax', name = 'duration')(c)\n\n    model = Model([notes_in, durations_in], [notes_out, durations_out])\n    model.compile(loss=['sparse_categorical_crossentropy', \n                        'sparse_categorical_crossentropy'], optimizer=RMSprop(lr = 0.001))\n    return model \nnetwork (one input each for notes and durations respectively). Each of the inputs is transformed into vectors using respective embedding layers. We then concatenate both inputs and pass them through a couple of LSTM layers followed by a simple attention mechanism. After this point, the model again diverges into two outputs (one for the next note and the other for the duration of that note). Readers are encouraged to use keras utilities to visualize the network on their own.\n```", "```py\ntensorflow.keras to prepare our generator model:\n```", "```py\ndef build_generator(latent_dim,seq_shape):\n  model = Sequential()\n  model.add(Dense(256, input_dim=latent_dim))\n  model.add(LeakyReLU(alpha=0.2))\n  model.add(BatchNormalization(momentum=0.8))\n  model.add(Dense(512))\n  model.add(LeakyReLU(alpha=0.2))\n  model.add(BatchNormalization(momentum=0.8))\n  model.add(Dense(1024))\n  model.add(LeakyReLU(alpha=0.2))\n  model.add(BatchNormalization(momentum=0.8))\n  model.add(Dense(np.prod(seq_shape), activation='tanh'))\n  model.add(Reshape(seq_shape))\n  model.summary()\n  noise = Input(shape=(latent_dim,))\n  seq = model(noise)\n  return Model(noise, seq) \n```", "```py\ndef build_discriminator(seq_shape):\n  model = Sequential()\n  model.add(LSTM(512, input_shape=seq_shape, return_sequences=True))\n  model.add(Bidirectional(LSTM(512)))\n  model.add(Dense(512))\n  model.add(LeakyReLU(alpha=0.2))\n  model.add(Dense(256))\n  model.add(LeakyReLU(alpha=0.2))\n  model.add(Dense(1, activation='sigmoid'))\n  model.summary()\n  seq = Input(shape=seq_shape)\n  validity = model(seq)\n  return Model(seq, validity) \n```", "```py\nrows = 100\nseq_length = rows\nseq_shape = (seq_length, 1)\nlatent_dim = 1000\noptimizer = Adam(0.0002, 0.5)\n# Build and compile the discriminator\ndiscriminator = build_discriminator(seq_shape)\ndiscriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n# Build the generator\ngenerator = build_generator(latent_dim,seq_shape)\n# The generator takes noise as input and generates note sequences\nz = Input(shape=(latent_dim,))\ngenerated_seq = generator(z)\n# For the combined model we will only train the generator\ndiscriminator.trainable = False\n# The discriminator takes generated images as input and determines validity\nvalidity = discriminator(generated_seq)\n# The combined model  (stacked generator and discriminator)\n# Trains the generator to fool the discriminator\ngan = Model(z, validity)\ngan.compile(loss='binary_crossentropy', optimizer=optimizer) \n```", "```py\ndef train(latent_dim, \n          notes, \n          generator, \n          discriminator, \n          gan,\n          epochs, \n          batch_size=128, \n          sample_interval=50):\n  disc_loss =[]\n  gen_loss = []\n  n_vocab = len(set(notes))\n  X_train, y_train = prepare_sequences(notes, n_vocab)\n  # ground truths\n  real = np.ones((batch_size, 1))\n  fake = np.zeros((batch_size, 1))\n  for epoch in range(epochs):\n      idx = np.random.randint(0, X_train.shape[0], batch_size)\n      real_seqs = X_train[idx]\n      noise = np.random.normal(0, 1, (batch_size, latent_dim))\n      # generate a batch of new note sequences\n      gen_seqs = generator.predict(noise)\n      # train the discriminator\n      d_loss_real = discriminator.train_on_batch(real_seqs, real)\n      d_loss_fake = discriminator.train_on_batch(gen_seqs, fake)\n      d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n      #  train the Generator\n      noise = np.random.normal(0, 1, (batch_size, latent_dim))\n      g_loss = gan.train_on_batch(noise, real)\n      # visualize progress\n      if epoch % sample_interval == 0:\n        print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0],100*d_loss[1],g_loss))\n        disc_loss.append(d_loss[0])\n        gen_loss.append(g_loss)\n  generate(latent_dim, generator, notes)\n  plot_loss(disc_loss,gen_loss) \n```", "```py\ndef build_temporal_network(z_dim, n_bars, weight_init):\n    input_layer = Input(shape=(z_dim,), name='temporal_input')\n    x = Reshape([1, 1, z_dim])(input_layer)\n    x = Conv2DTranspose(\n        filters=512,\n        kernel_size=(2, 1),\n        padding='valid',\n        strides=(1, 1),\n        kernel_initializer=weight_init\n    )(x)\n    x = BatchNormalization(momentum=0.9)(x)\n    x = Activation('relu')(x)\n    x = Conv2DTranspose(\n        filters=z_dim,\n        kernel_size=(n_bars - 1, 1),\n        padding='valid',\n        strides=(1, 1),\n        kernel_initializer=weight_init\n    )(x)\n    x = BatchNormalization(momentum=0.9)(x)\n    x = Activation('relu')(x)\n    output_layer = Reshape([n_bars, z_dim])(x)\n    return Model(input_layer, output_layer) \n```", "```py\ndef build_bar_generator(z_dim, n_steps_per_bar, n_pitches, weight_init):\n    input_layer = Input(shape=(z_dim * 4,), name='bar_generator_input')\n    x = Dense(1024)(input_layer)\n    x = BatchNormalization(momentum=0.9)(x)\n    x = Activation('relu')(x)\n    x = Reshape([2, 1, 512])(x)\n    x = Conv2DTranspose(\n        filters=512,\n        kernel_size=(2, 1),\n        padding='same',\n        strides=(2, 1),\n        kernel_initializer=weight_init\n    )(x)\n    x = BatchNormalization(momentum=0.9)(x)\n    x = Activation('relu')(x)\n    x = Conv2DTranspose(\n        filters=256,\n        kernel_size=(2, 1),\n        padding='same',\n        strides=(2, 1),\n        kernel_initializer=weight_init\n    )(x)\n    x = BatchNormalization(momentum=0.9)(x)\n    x = Activation('relu')(x)\n    x = Conv2DTranspose(\n        filters=256,\n        kernel_size=(2, 1),\n        padding='same',\n        strides=(2, 1),\n        kernel_initializer=weight_init\n    )(x)\n    x = BatchNormalization(momentum=0.9)(x)\n    x = Activation('relu')(x)\n    x = Conv2DTranspose(\n        filters=256,\n        kernel_size=(1, 7),\n        padding='same',\n        strides=(1, 7),\n        kernel_initializer=weight_init\n    )(x)\n    x = BatchNormalization(momentum=0.9)(x)\n    x = Activation('relu')(x)\n    x = Conv2DTranspose(\n        filters=1,\n        kernel_size=(1, 12),\n        padding='same',\n        strides=(1, 12),\n        kernel_initializer=weight_init\n    )(x)\n    x = Activation('tanh')(x)\n    output_layer = Reshape([1, n_steps_per_bar, n_pitches, 1])(x)\n    return Model(input_layer, output_layer) \nshows that the bar generator consists of a dense layer followed by batch-normalization, before a stack of transposed convolutional layers, which help to expand the vector along time and pitch dimensions.\n```", "```py\ndef build_critic(input_dim, weight_init, n_bars):\n    critic_input = Input(shape=input_dim, name='critic_input')\n    x = critic_input\n    x = conv_3d(x,\n                num_filters=128,\n                kernel_size=(2, 1, 1),\n                stride=(1, 1, 1),\n                padding='valid',\n                weight_init=weight_init)\n    x = conv_3d(x,\n                num_filters=64,\n                kernel_size=(n_bars - 1, 1, 1),\n                stride=(1, 1, 1),\n                padding='valid',\n                weight_init=weight_init)\n    x = conv_3d(x,\n                num_filters=64,\n                kernel_size=(1, 1, 12),\n                stride=(1, 1, 12),\n                padding='same',\n                weight_init=weight_init)\n    x = conv_3d(x,\n                num_filters=64,\n                kernel_size=(1, 1, 7),\n                stride=(1, 1, 7),\n                padding='same',\n                weight_init=weight_init)\n    x = conv_3d(x,\n                num_filters=64,\n                kernel_size=(1, 2, 1),\n                stride=(1, 2, 1),\n                padding='same',\n                weight_init=weight_init)\n    x = conv_3d(x,\n                num_filters=64,\n                kernel_size=(1, 2, 1),\n                stride=(1, 2, 1),\n                padding='same',\n                weight_init=weight_init)\n    x = conv_3d(x,\n                num_filters=128,\n                kernel_size=(1, 4, 1),\n                stride=(1, 2, 1),\n                padding='same',\n                weight_init=weight_init)\n    x = conv_3d(x,\n                num_filters=256,\n                kernel_size=(1, 3, 1),\n                stride=(1, 2, 1),\n                padding='same',\n                weight_init=weight_init)\n    x = Flatten()(x)\n    x = Dense(512, kernel_initializer=weight_init)(x)\n    x = LeakyReLU()(x)\n    critic_output = Dense(1,\n                          activation=None,\n                          kernel_initializer=weight_init)(x)\n    critic = Model(critic_input, critic_output)\n    return critic \n```"]