- en: Introduction to PyTorch
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: PyTorch介绍
- en: This is a step-by-step introduction to deep learning using the PyTorch framework.
    PyTorch is a great entry point into deep learning and if you have some knowledge
    of Python then you will find PyTorch an intuitive, productive, and enlightening
    experience. The ability to rapidly prototype experiments and test ideas is a core
    strength of PyTorch. Together with the possibility of being able to turn experiments
    into productive, deployable resources, the learning curve challenge is abundantly
    rewarded.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 这是使用PyTorch框架进行深度学习的逐步介绍。PyTorch是进入深度学习的一个绝佳起点，如果你对Python有一些了解，那么你会发现PyTorch是一个直观、高效和启发性的体验。快速原型设计实验和测试想法的能力是PyTorch的核心优势。再加上能够将实验转化为生产可部署资源的可能性，学习曲线挑战将得到丰富的回报。
- en: PyTorch is a relatively easy and fun way to understand deep learning concepts.
    You may be surprised at how few lines of code it takes to solve common problems
    of classification, such as hand-writing recognition and image classification.
    Having said that PyTorch is *easy* cannot override the fact that deep learning
    is, in many ways, *hard*. It involves some complicated math and some intractable
    logical conundrums. This should not, however, distract from the fun and useful
    part of this enterprise. There is no doubt machine learning can provide deep insights
    and solve important problems in the world around us but to get there can take
    some work.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch是理解深度学习概念的相对简单和有趣的方式。你可能会惊讶于解决分类问题（如手写识别和图像分类）所需的代码行数是多么少。尽管说PyTorch是*易于使用*，但不能否认深度学习在很多方面都是*困难*的。它涉及一些复杂的数学和一些棘手的逻辑难题。然而，这不应该让人们忘记这一企业的有趣和有用部分。毫无疑问，机器学习可以为我们周围的世界提供深刻的见解，并解决重要的问题，但要到达那里可能需要一些工作。
- en: This book is an attempt, not to gloss over important ideas, but to explain them
    in a way that is jargon free and succinct. If the idea of solving complicated
    differential equations makes you break out in a cold sweat, you are not alone.
    This might be related to some high school trauma of a bad-tempered math teacher
    furiously demanding you cite Euler's formula or the trigonometric identities.
    This is a problem because math itself should be fun, and insight arises not from
    the laborious memorizing of formulas but through understanding relationships and
    foundational concepts.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本书试图不是简单地掠过重要的思想，而是以不带行话且简洁的方式解释它们。如果解决复杂的微分方程的想法让你感到心慌，你并不孤单。这可能与高中时期一位脾气暴躁的数学老师愤怒地要求你引用欧拉公式或三角恒等式有关。这是一个问题，因为数学本身应该是有趣的，洞察力并不是通过费力记忆公式而是通过理解关系和基础概念产生的。
- en: Another thing that can make deep learning appear difficult is that it has a
    diverse and dynamic frontier of research. This may be confusing for the novice
    because it does not present an obvious entry point. If you understand some principles
    and want to test your ideas, it can be a bewildering task to find a suitable set
    of tools. The combinations of development language, framework, deployment architecture,
    and so on, present a non-trivial decision process.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习看起来困难的另一个原因是其具有多样化和动态的研究前沿。对于新手来说，这可能会感到困惑，因为它并没有明显的入门点。如果你理解了一些原则并想测试你的想法，那么找到一个合适的工具集可能会是一个令人困惑的任务。开发语言、框架、部署架构等的组合呈现出一个非平凡的决策过程。
- en: The science of machine learning has matured to the point that a set of general
    purpose algorithms for solving problems such has classification and regression
    have emerged. Subsequently, several frameworks have been created to harness the
    power of these algorithms and use them for general problem solving. This means
    that the entry point is at such a level that these technologies are now in the
    hands of the non-computer science professional. Experts in a diverse array of
    domains can now use these ideas to advance their endeavors. By the end of this
    book, and with a little dedication, you will be able to build and deploy useful
    deep learning models to help solve the problems you are interested in.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习科学已经发展到一个阶段，即已经出现了一组通用算法来解决分类和回归等问题。随后，几个框架被创建出来，以利用这些算法的力量并将它们用于一般问题解决。这意味着入门点已经达到这样一个水平，以至于这些技术现在已经掌握在非计算机科学专业人士手中。各种领域的专家现在可以使用这些思想来推动他们的努力。通过本书，再加上一点奉献精神，你将能够构建和部署有用的深度学习模型，以帮助解决你感兴趣的问题。
- en: 'In this chapter, we will discuss the following topics:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论以下主题：
- en: What is PyTorch?
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是PyTorch？
- en: Installing PyTorch
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装PyTorch
- en: Basic operations
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基本操作
- en: Loading data
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加载数据
- en: What is PyTorch?
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是PyTorch？
- en: PyTorch is a dynamic tensor-based, deep learning framework for experimentation,
    research, and production. It can be used as a GPU-enabled replacement for NumPy
    or a flexible, efficient platform for building neural networks. The dynamic graph
    creation and tight Python integration makes PyTorch a standout in deep learning
    frameworks.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch是一种用于实验、研究和生产的动态张量深度学习框架。它可以作为NumPy的支持GPU的替代品，或者作为构建神经网络的灵活高效平台。动态图创建和紧密的Python集成使得PyTorch在深度学习框架中脱颖而出。
- en: If you are at all familiar with the deep learning ecosystem, then frameworks
    such as Theano and TensorFlow, or higher-level derivatives such as Keras, are
    amongst the most popular. PyTorch is a relative newcomer to the deep learning
    framework set. Despite this, it is now being used extensively by Google, Twitter,
    and Facebook. It stands out from other frameworks in that both Theano and TensorFlow
    encode computational graphs in static structures that need to be run in self-contained
    sessions. In contrast, PyTorch can dynamically implement computational graphs.
    The consequence for a neural net is that the network can change behavior as it
    is being run, with little or no overhead. In TensorFlow and Theano, to change
    behavior, you effectively have to rebuild the network from scratch.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对深度学习生态系统稍有了解，那么像Theano和TensorFlow这样的框架，或者更高级的衍生框架如Keras，都是最受欢迎的。PyTorch是深度学习框架中的相对新进者。尽管如此，它现在已经被Google、Twitter和Facebook广泛使用。它与其他框架的区别在于，Theano和TensorFlow将计算图编码为静态结构，需要在封闭会话中运行。相反，PyTorch可以动态实现计算图。对于神经网络来说，这意味着网络在运行时可以更改行为，几乎没有额外开销。而在TensorFlow和Theano中，要更改行为，实际上需要从头开始重建网络。
- en: This dynamic implementation comes about through a process called tape-based
    auto-diif, allowing PyTorch expressions to be automatically differentiated. This
    has numerous advantages. Gradients can be calculated on the fly and since the
    computational graph is dynamic, it can be changed at each function call, allowing
    it to be used in interesting ways in loops and under conditional calls that can
    respond, for example, to input parameters or intermediate results. This dynamic
    behavior and great flexibility has made PyTorch a favored experimental platform
    for deep learning.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 这种动态实现是通过一种称为基于“tape”的自动微分过程实现的，允许PyTorch表达式自动进行微分。这带来了许多优势。梯度可以即时计算，由于计算图是动态的，因此可以在每次函数调用时更改，允许在循环中和条件调用下以有趣的方式使用。PyTorch的这种动态行为和极大的灵活性使其成为深度学习实验平台的首选。
- en: Another advantage of PyTorch is that it is closely integrated with the Python
    language. For Python coders, it is very intuitive and it interoperates seamlessly
    with other Python packages, such as NumPy and SciPy. PyTorch is very easy to experiment
    with. It makes an ideal tool for not only building and running useful models,
    but also as a way to understand deep learning principles by direct experimentation.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch的另一个优势是与Python语言的紧密集成。对于Python编程者来说，它非常直观，并且与NumPy和SciPy等其他Python包无缝交互。PyTorch非常易于进行实验。它不仅是构建和运行有用模型的理想工具，还是通过直接实验理解深度学习原理的好方式。
- en: As you would expect, PyTorch can be run on multiple **graphical processing units**
    (**GPUs**). Deep learning algorithms can be computationally expensive. This is
    especially true for big datasets. PyTorch has strong GPU support, with intelligent
    memory sharing of tensors between processes. This basically means there is an
    efficient and user-friendly way to distribute the processing load across the CPU
    and GPUs. This can make a big difference to the time it takes to test and run
    large complex models.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所料，PyTorch可以在多个**图形处理单元**（**GPUs**）上运行。深度学习算法可能需要大量计算资源，尤其是在处理大型数据集时更是如此。PyTorch具有强大的GPU支持，在进程间智能地共享张量内存。这基本上意味着在CPU和GPU之间有一种高效且用户友好的方式来分配处理负载。这可以极大地减少测试和运行大型复杂模型所需的时间。
- en: Dynamic graph generation, tight Python language integration, and a relatively
    simple API makes PyTorch an excellent platform for research and experimentation.
    However, versions prior to PyTorch 1 had deficits that prevented it from excelling
    in production environments. This deficiency is being addressed in PyTorch 1.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 动态图生成，紧密集成Python语言，并且相对简单的API使得PyTorch成为研究和实验的优秀平台。然而，PyTorch 1之前的版本存在缺陷，阻碍了其在生产环境中的卓越表现。这一不足正在PyTorch
    1中得到解决。
- en: Research is an important application for deep learning, but increasingly, deep
    learning is being embedded in applications that run live on the web, on a device,
    or in a robot. Such an application may service thousands of simultaneous queries
    and interact with massive, dynamic data. Although Python is one of the best languages
    for humans to work with, specific efficiencies and optimizations are available
    in other languages, most commonly C++ and Java. Even though the best way to build
    a particular deep learning model may be with PyTorch, this may not be the best
    way to deploy it. This is no longer a problem because now with PyTorch 1, we can
    export Python free representations of PyTorch models.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 研究是深度学习的一个重要应用，但越来越多地，深度学习被嵌入到在Web上、设备上或机器人中实时运行的应用程序中。这样的应用程序可能会处理成千上万个同时查询并与大规模动态数据交互。尽管Python是人类工作中最好的语言之一，但其他语言，如C++和Java，通常具有特定的效率和优化。即使构建特定深度学习模型的最佳方式可能是使用PyTorch，但这可能不是部署它的最佳方式。这不再是一个问题，因为现在使用PyTorch
    1，我们可以导出Python free模型的PyTorch表示。
- en: This has come about through a partnership between Facebook, the major stakeholder
    of PyTorch, and Microsoft, to create the **Open Neural Network Exchange** (**ONNX**)
    to assist developers in converting neural net models between frameworks. This
    has led to the merging of PyTorch with the more production-ready framework, CAFFE2\.
    In CAFFE2, models are represented by a plain text schema, making them language
    agnostic. This means they are more easily deployed to Android, iOS, or Rasberry
    Pi devices.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这是Facebook和PyTorch的主要利益相关者与微软合作的结果，创建了**开放神经网络交换**（**ONNX**），以帮助开发人员在不同框架之间转换神经网络模型。这导致了PyTorch与更适合生产的框架CAFFE2的合并。在CAFFE2中，模型由纯文本模式表示，使其与语言无关。这意味着它们更容易部署到Android、iOS或Raspberry
    Pi设备上。
- en: With this in mind, PyTorch version 1 has expanded its API included production-ready
    capabilities, such as optimizing code for Android and iPhone, a **just in time**
    (**JIT**) C++ compiler, and several ways to make *Python free* representations
    of your models.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这个想法，PyTorch版本1扩展了其API，包括生产就绪功能，如优化Android和iPhone的代码，一个**即时**（**JIT**）C++编译器，以及几种方式来创建*Python
    free*模型的表示。
- en: 'In summary, PyTorch has the following characteristics:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，PyTorch具有以下特点：
- en: Dynamic graph representation
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 动态图表示
- en: Tightly integrated with the Python programming language
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与Python编程语言紧密集成
- en: A mix of high-and low-level APIs
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高低级API混合使用
- en: Straightforward implementation on multiple GPUs
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在多个GPU上实现简单
- en: Able to build *Python-free* model representation for export and production
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 能够构建*Python-free*模型表示以进行导出和生产
- en: Scales to massive data using the Caffe framework
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Caffe框架扩展到大规模数据
- en: Installing PyTorch
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装PyTorch
- en: PyTorch will run on macOS X, 64 bit Linux, and 64 bit Windows. Be aware that
    Windows does not currently offer (easy) support for the use of GPUs in PyTorch.
    You will need to have either Python 2.7 or Python 3.5 / 3.6 installed on your
    computer before you install PyTorch, remembering to install the correct version
    for each Python version. Unless you have a reason not to, it is recommended that
    you install the Anaconda distribution of Python. This this is available from: [https://anaconda.org/anaconda/python](https://anaconda.org/anaconda/python).
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch将在macOS X、64位Linux和64位Windows上运行。请注意，Windows目前不提供（易于）支持PyTorch中GPU的使用。在安装PyTorch之前，您需要在计算机上安装Python
    2.7或Python 3.5 / 3.6，并记住为每个Python版本安装正确的版本。除非有理由不这样做，建议您安装Anaconda Python发行版。这可以从以下地址获取：[https://anaconda.org/anaconda/python](https://anaconda.org/anaconda/python)。
- en: Anaconda includes all the dependencies of PyTorch, as well as technical, math,
    and scientific libraries essential to your work in deep learning. These will be
    used throughout the book, so unless you want to install them all separately, install
    Anaconda.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: Anaconda包括PyTorch的所有依赖项，以及在深度学习中必不可少的技术、数学和科学库。这些将在整本书中使用，因此，除非您想单独安装它们，否则请安装Anaconda。
- en: 'The following is a list of the packages and tools that we will be using in
    this book. They are all installed with Anaconda:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我们在本书中将要使用的软件包和工具列表。它们都已经在Anaconda中安装好：
- en: '`NumPy`: A math library primarily used for working with multidimensional arrays'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`NumPy`: 主要用于处理多维数组的数学库'
- en: '`Matplotlib`: A plotting and visualization library'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Matplotlib`: 用于绘图和可视化的库'
- en: '`SciPy`: A package for scientific and technical computing'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`SciPy`: 用于科学和技术计算的软件包'
- en: '`Skit-Learn`: A library for machine learning'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Skit-Learn`: 用于机器学习的库'
- en: '`Pandas`: A library for working with data'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Pandas`: 用于处理数据的库。'
- en: '`IPython`: A notebook-style code editor used for writing and running code in
    a browser'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`IPython`: 一种笔记本风格的代码编辑器，用于在浏览器中编写和运行代码。'
- en: Once you have Anaconda installed, you can now install PyTorch. Go to the PyTorch
    website at [https://pytorch.org/](https://pytorch.org/).
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 安装了Anaconda之后，现在可以安装PyTorch了。请访问PyTorch网站：[https://pytorch.org/](https://pytorch.org/)。
- en: The installation matrix on this website is pretty self-explanatory. Simply select
    your operating system, Python version, and, if you have GPUs, your CUDA version,
    and then run the appropriate command.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 此网站上的安装矩阵相当自解释。只需选择您的操作系统、Python版本，以及如果您有GPU，则选择您的CUDA版本，然后运行适当的命令。
- en: As always, it is good practice to ensure your operating system and dependent
    packages are up to date before installing PyTorch. Anaconda and PyTorch run on
    Windows, Linux, and macOS, although Linux is probably the most used and consistent
    operating system. Throughout this book, I will be using Python 3.7 and Anaconda
    3.6.5 running on Linux
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 与往常一样，在安装PyTorch之前确保您的操作系统和依赖包是最新的是个好习惯。Anaconda和PyTorch支持Windows、Linux和macOS，尽管Linux可能是最常用和最一致的操作系统。在本书中，我将使用Python
    3.7和Anaconda 3.6.5运行在Linux上。
- en: Code in this book was written on the Jupyter Notebook and these notebooks are
    available from the book's website.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中的代码是在Jupyter Notebook上编写的，这些笔记本可以从该书的网站上获取。
- en: You can either choose to set up your PyTorch environment locally on your own
    machine or remotely on a cloud server. They each have their pros and cons. Working
    locally has the advantage that it is generally easier and quicker to get started.
    This is especially true if you are not familiar with SSH and the Linux terminal.
    It is simply a matter of installing Anaconda and PyTorch, and you are on your
    way. Also, you get to choose and control your own hardware, and while this is
    an upfront cost, it is often cheaper in the long run. Once you start expanding
    hardware requirements, cloud solutions can become expensive. Another advantage
    of working locally is that you can choose and customize your **integrated development
    envionment** (**IDE**). In fact, Anaconda has its own excellent desktop IDE called
    Spyder.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以选择在本地自己的计算机上设置PyTorch环境，也可以选择在云服务器上远程设置。它们各有利弊。在本地工作的优势在于通常更容易和更快地开始。特别是如果您不熟悉SSH和Linux终端的话。只需安装Anaconda和PyTorch，您就可以开始了。此外，您可以选择和控制自己的硬件，虽然这是一笔前期成本，但通常在长期来看更便宜。一旦您开始扩展硬件需求，云解决方案可能变得昂贵。在本地工作的另一个优势是可以选择和定制您的**集成开发环境**（**IDE**）。事实上，Anaconda有自己出色的桌面IDE称为Spyder。
- en: 'There are a few things you need to keep in mind when building your own deep
    learning hardware and you require GPU acceleration:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建自己的深度学习硬件时，需要注意几件事情，您需要GPU加速：
- en: Use NVIDIA CUDA-compliant GPUs (for example, GTX 1060 or GTX 1080)
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用NVIDIA兼容CUDA的GPU（例如GTX 1060或GTX 1080）。
- en: A chipset that has at least 16 PCIe lanes
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 至少具有16个PCIe通道的芯片组。
- en: At least 16 GB of RAM
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 至少16GB的RAM。
- en: Working on the cloud does offer the flexibility to work from any machine as
    well as more easily experiment with different operating systems, platforms, and
    hardware. You also have the benefit of being able to share and collaborate more
    easily. It is generally cheap to get started, costing a few dollars a month, or
    even free, but as your projects become more complex and data intensive, you will
    need to pay for more capacity.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在云上工作确实提供了从任何计算机工作的灵活性，以及更容易地尝试不同的操作系统、平台和硬件。您还可以更轻松地分享和协作。通常可以廉价开始，每月几美元，甚至免费，但随着项目变得更复杂和数据密集，您需要支付更多的容量。
- en: 'Let''s look briefly at the installation procedures for two cloud server hosts:
    Digital Ocean and Amazon Web Services.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们简要看一下两个云服务器主机的安装过程：Digital Ocean和Amazon Web Services。
- en: Digital Ocean
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Digital Ocean。
- en: 'Digital Ocean offers one of the simplest entry points into cloud computing.
    It offers predictable simple payment structures and straightforward server administration.
    Unfortunately, Digital Ocean does not currently support GPUs. The functionality
    revolves around d*roplets*, pre-built instances of virtual private servers. The
    following are the steps required to set up a droplet:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: Digital Ocean 提供了进入云计算的最简单入口之一。它提供可预测的简单付款结构和直观的服务器管理。不幸的是，Digital Ocean目前不支持GPU。其功能围绕着*droplets*（预构建的虚拟专用服务器实例）展开。以下是设置droplet所需的步骤：
- en: Sign up for an account with Digital Ocean. Go to [https://www.digitalocean.com/.](https://www.digitalocean.com/)
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在[Digital Ocean](https://www.digitalocean.com/)注册一个账号。前往[https://www.digitalocean.com/.](https://www.digitalocean.com/)
- en: Click on the Create button and choose New Droplet**.**
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击“创建”按钮并选择“新建Droplet**”。**
- en: Select the Ubuntu distribution of Linux and choose the two gigabyte plan or
    above.
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择Linux的Ubuntu发行版，并选择两千兆字节或以上的计划。
- en: Select the CPU optimization if required. The default values should be fine to
    get started.
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果需要，选择CPU优化。默认值应该足以开始使用。
- en: Optionally, set up public/private key encryption.
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可选择设置公共/私有密钥加密。
- en: Set up an SSH client (for example, PuTTY) using the information contained in
    the email sent to you.
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用您收到的电子邮件中的信息设置SSH客户端（例如PuTTY）。
- en: Connect to your droplet via your SSH client and `curl`the latest Anaconda installer.
    You can find the address location of the installer for your particular environment
    at [https://repo.continuum.io/](https://repo.continuum.io/).
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过SSH客户端连接到您的Droplet，并`curl`获取最新的Anaconda安装程序。您可以在[https://repo.continuum.io/](https://repo.continuum.io/)找到适合您特定环境的安装程序地址。
- en: 'Install PyTorch using this command:'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令安装PyTorch：
- en: '[PRE0]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Once you have spun up your droplet, you can access the Linux command through
    an SSH client. From Command Prompt, you can `curl` the latest Anaconda installer
    available from: [https://www.anaconda.com/download/#linux](https://www.anaconda.com/download/#linux).'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您启动了您的Droplet，您可以通过SSH客户端访问Linux命令。从命令提示符，您可以`curl`获取最新的Anaconda安装程序，地址是：[https://www.anaconda.com/download/#linux](https://www.anaconda.com/download/#linux)。
- en: An installation script is also available from the continuum archive at [https://repo.continuum.io/archive/.](https://repo.continuum.io/archive/) Full
    step-by-step instructions are available from the Digital Ocean tutorials section.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在[Digital Ocean教程](https://repo.continuum.io/archive/)部分可以找到完整的逐步指南。
- en: Tunneling in to IPython
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 远程连接到IPython
- en: 'IPython is an easy and convenient way to edit code through a web browser. If
    you are working on a desktop computer, you can just launch IPython and point your
    browser to `localhost:8888`. This is the port that the IPython server, Jupyter,
    runs on. However, if you are working on a cloud server, then a common way to work
    with code is to tunnel in to IPython using SSH. Tunneling in to IPython involves
    the following steps:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: IPython是通过Web浏览器编辑代码的简便方式。如果您使用桌面电脑，只需启动IPython并将浏览器指向`localhost:8888`。这是IPython服务器Jupyter运行的端口。然而，如果您在云服务器上工作，那么通过SSH隧道连接到IPython是处理代码的常见方式。连接到IPython的隧道包括以下步骤：
- en: In your SSH client, set your destination port to `localhost:8888`. In PuTTY,
    go to Connection | SSH | Tunnels.
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在SSH客户端中，将目标端口设置为`localhost:8888`。在PuTTY中，转到Connection | SSH | Tunnels。
- en: Set the source port to anything above `8000` to avoid conflicting with other
    services. Click Add. Save these settings and open the connection. Log in to your
    droplet as usual.
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将源端口设置为大于`8000`以避免与其他服务冲突。点击添加。保存这些设置并打开连接。像往常一样登录到您的Droplet。
- en: Start the IPython server by typing `jupyter notebook` into Command Prompt of
    your server instance.
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过在服务器实例的命令提示符中键入`jupyter notebook`启动IPython服务器。
- en: 'Access IPython by pointing your browser to `localhost: source port`*; *for
    example, `localhost:8001`.'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '通过将浏览器指向`localhost: source port`，例如`localhost:8001`，访问IPython。'
- en: Start the IPython server.
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动IPython服务器。
- en: 'Note that you may need a token to access the server for the first time. This
    is available from the command output once you start Jupyter. You can either copy
    the URL given in this output directly into your browser''s address bar, changing
    the port address to your local source port address, for example: `8001`, or you
    can elect to paste the token, the part after `token=`, into the Jupyter start-up
    page and replace it with a password for future convenience. You now should be
    able to open, run, and save IPython notebooks.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，您可能需要一个令牌第一次访问服务器。这可以从您启动Jupyter后的命令输出中获取。您可以直接复制此输出中给出的URL到浏览器的地址栏，并将端口地址更改为您的本地源端口地址，例如：`8001`，或者您可以选择将令牌（`token=`后面的部分）粘贴到Jupyter启动页面，并将其替换为将来方便使用的密码。现在，您应该能够打开、运行和保存IPython笔记本。
- en: Amazon Web Services (AWS)
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 亚马逊网络服务（AWS）
- en: AWS is the original cloud computing platform, most noted for its highly-scalable
    architecture. It offers a vast array of products. What we need to begin is an
    EC2 instance. This can be accessed form the Services tab of the AWS control panel.
    From there, select EC2 and then Launch Instance. From here, you can choose the
    machine image you require. AWS provide several types of machine images specifically
    for deep learning. Feel free to experiment with any of these but the one we are
    going to use here is the deep learning AMI for Ubuntu version 10\. It comes with
    pre-installed environments for PyTorch and TensorFlow. After selecting this, you
    get to choose other options. The default T2 micro with 2 GB of memory should be
    fine to experiment with; however, if you want GPU acceleration, you will need
    to use the T2 medium instance type. Finally, when you launch your instance, you
    will be prompted to create and download your public-private key pair. You can
    then use your SSH client to connect to the server instance and tunnel in to the
    Jupyter Notebook as per the previous instructions. Once again, check the documentation
    for the finer details. Amazon has a pay-per-resource model, so it is important
    you monitor what resources you are using to ensure you do not receive any unnecessary
    or unexpected charges.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: AWS是最初的云计算平台，以其高度可扩展的架构而闻名。它提供了广泛的产品。我们需要开始的是一个EC2实例。这可以从AWS控制面板的服务选项卡中访问。从那里，选择EC2，然后启动实例。在这里，您可以选择所需的机器映像。AWS提供了几种专门用于深度学习的机器映像类型。可以随意尝试任何其中的一个，但我们将在此使用的是适用于Ubuntu版本10的深度学习AMI。它预装了PyTorch和TensorFlow的环境。选择完毕后，您可以选择其他选项。默认的T2微型实例，配备2GB内存，对于实验来说应该足够了；然而，如果您需要GPU加速，您将需要使用T2中型实例类型。最后，在启动实例时，系统将提示您创建和下载公共-私有密钥对。然后，您可以使用SSH客户端连接到服务器实例，并按照先前的说明进行到Jupyter
    Notebook的隧道。再次检查文档以获取更详细的信息。亚马逊采用按资源付费的模式，因此重要的是您监控您正在使用的资源，以确保不会收到任何不必要或意外的费用。
- en: Basic PyTorch operations
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: PyTorch的基本操作
- en: Tensors are the workhorse of PyTorch. If you know linear algebra, they are equivalent
    to a matrix. Torch tensors are effectively an extension of the `numpy.array` object.
    Tensors are an essential conceptual component in deep learning systems, so having
    a good understanding of how they work is important.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 张量是PyTorch的核心工具。如果您了解线性代数，它们相当于矩阵。Torch张量实际上是`numpy.array`对象的扩展。张量是深度学习系统中重要的概念组成部分，因此理解它们的工作原理至关重要。
- en: 'In our first example, we will be looking at tensors of size 2 x 3\. In PyTorch,
    we can create tensors in the same way that we create NumPy arrays. For example,
    we can pass them nested lists, as shown in the following code:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的第一个示例中，我们将查看大小为2 x 3的张量。在PyTorch中，我们可以像创建NumPy数组一样创建张量。例如，我们可以传递嵌套列表，如下面的代码所示：
- en: '![](img/a1697600-13b3-4e70-9ffb-5a1412001b98.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a1697600-13b3-4e70-9ffb-5a1412001b98.png)'
- en: 'Here we have created two tensors, each with dimensions of 2 x 3\. You can see
    that we have created a simple linear function (more about linear functions in
    [Chapter 2](fc03f00c-2991-4e13-af19-6afbf2eb6ded.xhtml), *Deep Learning Fundamentals*)
    and applied it to `x` and `y` and printed out the result. We can visualize this
    with the following diagram:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们创建了两个维度为2 x 3的张量。您可以看到，我们创建了一个简单的线性函数（有关线性函数的更多信息，请参见[第2章](fc03f00c-2991-4e13-af19-6afbf2eb6ded.xhtml)，*深度学习基础*），并将其应用于*x*和*y*，然后打印出结果。我们可以使用以下图表可视化这一点：
- en: '![](img/55081296-704a-40a9-a97e-93144dd284d4.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![](img/55081296-704a-40a9-a97e-93144dd284d4.png)'
- en: As you may know from linear algebra, matrix multiplication and addition occur
    element-wise so that for the first element of *x*, let's write this as *X[00]*.
    This is multiplied by two and added to the first element of *y*, written as *Y[00]*,
    giving *F[00] = 9\. X[01] = 2* and *Y[01] = 8 so f[01] = 4 + 12*. Notice that
    the indices start at zero.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您可能从线性代数中知道的那样，矩阵乘法和加法是按元素进行的，因此对于*x*的第一个元素，我们将其写为*X[00]*。这与*Y[00]*相乘并加到*y*的第一个元素上，写为*Y[01]
    = 8，所以*f[01] = 4 + 12*。请注意，索引从零开始。
- en: If you have never seen any linear algebra, don't worry too much about this,
    as we are going to brush up on these concepts in [Chapter 2](2d1384b3-ec8a-40f0-96d0-5ac061f08a65.xhtml), *Deep
    Learning Fundamentals*, and you will get to practice with Python indexing shortly.
    For now, just consider our 2 x 3 tensors as tables with numbers in them.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你从未见过任何线性代数，不要太担心，因为我们将在《深度学习基础》[第2章](2d1384b3-ec8a-40f0-96d0-5ac061f08a65.xhtml)中进行概述，并且很快你将开始使用
    Python 索引。现在，只需将我们的 2 x 3 张量视为其中带有数字的表即可。
- en: Default value initialization
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 默认值初始化
- en: 'There are many cases where we need to initialize torch tensors to default values.
    Here, we create three 2 x 3 tensors, filling them with zeros, ones, and random
    floating point numbers:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多情况下我们需要将 torch 张量初始化为默认值。在这里，我们创建了三个 2 x 3 的张量，分别用零、一和随机浮点数填充它们：
- en: '![](img/f3f7a218-5282-4259-8555-dca6b25c49d1.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f3f7a218-5282-4259-8555-dca6b25c49d1.png)'
- en: 'An important point to consider when we are initializing random arrays is the
    so-called seed of reproducibility. See what happens when you run the preceding
    code several times. You get a different array of random numbers each time. Often
    in machine learning, we need to be able to reproduce results. We can achieve this
    by using a random seed. This is demonstrated in the following code:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在初始化随机数组时需要考虑的一个重要点是所谓的可重复性种子。看看当你多次运行上述代码时会发生什么。每次都会得到不同的随机数数组。在机器学习中经常需要能够重现结果。我们可以通过使用随机种子来实现这一点。这在下面的代码中进行了演示：
- en: '![](img/6e5870c7-2d17-4a52-b52e-de2adc34d8c1.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6e5870c7-2d17-4a52-b52e-de2adc34d8c1.png)'
- en: Notice that when you run this code many times, the tensor values stay the same.
    If you remove the seed by deleting the first line, the tensor values will be different
    each time the code is run. It does not matter what number you use to seed the
    random number generator, as long as it is consistently, achieves reproducible
    results.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，当你多次运行这段代码时，张量的值保持不变。如果删除第一行中的种子，每次运行代码时张量的值将不同。不管你使用什么数字来种子随机数生成器，只要它是一致的，就能实现可重现的结果。
- en: Converting between tensors and NumPy arrays
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 张量和 NumPy 数组之间的转换
- en: 'Converting a NumPy array is as simple as performing an operation on it with
    a torch tensor. The following code should make this clear:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 将 NumPy 数组转换为张量就像对其执行一个操作一样简单。下面的代码应该清楚地表明这一点：
- en: '![](img/059d7741-b2c3-4413-9141-b188c5376cbf.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![](img/059d7741-b2c3-4413-9141-b188c5376cbf.png)'
- en: 'We can see the result of the type torch tensor. In many cases, we can use NumPy
    arrays interchangeably with tensors and always be sure the result is a tensor.
    However, there are times when we need to explicitly create a tensor from an array.
    This is done with the `torch.from_numpy` function:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到 torch 张量的类型结果。在许多情况下，我们可以互换地使用 NumPy 数组和张量，并始终确保结果是张量。然而，有时我们需要显式地从数组创建张量。这可以通过
    `torch.from_numpy` 函数来实现：
- en: '![](img/c7a6a214-68bf-40bc-babb-467509972702.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c7a6a214-68bf-40bc-babb-467509972702.png)'
- en: 'To convert from a tensor to a NumPy array, simply call the `torch.numpy()`
    function:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 要从张量转换为 NumPy 数组，只需调用 `torch.numpy()` 函数：
- en: '![](img/2c22ace0-a823-47f6-a80b-06fb404f96a1.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2c22ace0-a823-47f6-a80b-06fb404f96a1.png)'
- en: 'Notice that we use Python''s built-in `type()` function, as in `type(object)`,
    rather than the `tensor.type()` we used previously. The NumPy arrays do not have
    a `type` attribute. Another important thing to understand is that NumPy arrays
    and PyTorch tensors share the same memory space. For example, see what happens
    when we change a variables value as demonstrated by the following code:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们使用了 Python 内置的 `type()` 函数，如 `type(object)`，而不是我们之前使用的 `tensor.type()`。NumPy
    数组没有 `type` 属性是另一个重要的理解点。另外一个要注意的是，NumPy 数组和 PyTorch 张量共享同一内存空间。例如，看看当我们像下面的代码演示一样改变一个变量的值时会发生什么：
- en: '![](img/27ffc71b-ccc7-49f0-8ec5-1db41a3ba746.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![](img/27ffc71b-ccc7-49f0-8ec5-1db41a3ba746.png)'
- en: 'Note also that when we print a tensor, it returns a tuple consisting of the
    tensor itself and also its `dtype`, or data type attribute. It''s important here
    because there are certain `dtype` arrays that cannot be turned into tensors. For
    example, consider the following code:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 还要注意，当我们打印一个张量时，它返回一个元组，包含张量本身和其 `dtype`，或数据类型属性。这在这里非常重要，因为有些 `dtype` 的数组不能转换成张量。例如，考虑下面的代码：
- en: '![](img/4f5282bd-e7be-4cb5-ba0d-b0fa815e2d17.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4f5282bd-e7be-4cb5-ba0d-b0fa815e2d17.png)'
- en: 'This will generate an error message telling us that only supported `dtype`
    are able to be converted into tensors. Clearly, `int8` is not one of these supported
    types. We can fix this by converting our `int8` array to an `int64` array before
    passing it to `torch.from_numpy`. We do this with the `numpy.astype` function,
    as the following code demonstrates:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成一个错误消息，告诉我们只有支持的`dtype`能够被转换为张量。显然，`int8`不是其中之一。我们可以通过在传递给`torch.from_numpy`之前将我们的`int8`数组转换为`int64`数组来修复这个问题。我们可以使用`numpy.astype`函数来完成，如下面的代码所示：
- en: '![](img/9def7a81-8194-483d-8b8c-b3e1ba2a5503.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9def7a81-8194-483d-8b8c-b3e1ba2a5503.png)'
- en: 'It is also important to understand how `numpy dtype` arrays convert to torch
    `dtype`. In the previous example, `numpy int32` converts to `IntTensor`. The following
    table lists the torch `dtype` and their `numpy` equivalents:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 了解`numpy dtype`数组如何转换为torch `dtype`也非常重要。在前面的示例中，`numpy int32`转换为`IntTensor`。下表列出了torch
    `dtype`及其对应的`numpy`类型：
- en: '| **Numpy type** | **dtype** | **Torch type** | **Description** |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| **NumPy类型** | **dtype** | **Torch类型** | **描述** |'
- en: '| `int64` | `torch.int64` `torch.float` | `LongTensor` | 64 bit integer |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| `int64` | `torch.int64` `torch.float` | `LongTensor` | 64位整数 |'
- en: '| `int32` | `torch.int32` `torch.int` | `IntegerTensor` | 32 bit signed integer
    |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| `int32` | `torch.int32` `torch.int` | `IntegerTensor` | 32位有符号整数 |'
- en: '| `uint8 ` | `torch.uint8`  | `ByteTensor` | 8 bit unsigned integer |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| `uint8 ` | `torch.uint8`  | `ByteTensor` | 8位无符号整数 |'
- en: '| `float64 double` | `torch.float64` `torch.double` | `DoubleTensor` | 64 bit
    floating point |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| `float64 double` | `torch.float64` `torch.double` | `DoubleTensor` | 64位浮点数
    |'
- en: '| `float32` | `torch.float32` `torch.float` | `FloatTensor` | 32 bit floating
    point |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| `float32` | `torch.float32` `torch.float` | `FloatTensor` | 32位浮点数 |'
- en: '|  | `torch.int16` `torch.short` | `ShortTensor` | 16 bit signed integer |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '|  | `torch.int16` `torch.short` | `ShortTensor` | 16位有符号整数 |'
- en: '|  | `torch.int8` | `CharTensor` | 6 bit signed integer |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '|  | `torch.int8` | `CharTensor` | 6位有符号整数 |'
- en: 'The default `dtype` for tensors is `FloatTensor`; however, we can specify a
    particular data type by using the tensor''s `dtype` attribute. For an example,
    see the following code:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 张量的默认`dtype`是`FloatTensor`；但是，我们可以使用张量的`dtype`属性指定特定的数据类型。例如，请看下面的代码：
- en: '![](img/b7cc75b7-2a08-4dc3-a313-5df73209c0fb.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b7cc75b7-2a08-4dc3-a313-5df73209c0fb.png)'
- en: Slicing and indexing and reshaping
  id: totrans-110
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 切片、索引和重塑
- en: '`torch.Tensor` have most of the attributes and functionality of NumPy. For
    example, we can slice and index tensors in the same way as NumPy arrays:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '`torch.Tensor` 具有大部分与NumPy相同的属性和功能。例如，我们可以像NumPy数组一样对张量进行切片和索引：'
- en: '![](img/584f1b15-510a-4415-beaf-b2aa132d370f.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![](img/584f1b15-510a-4415-beaf-b2aa132d370f.png)'
- en: Here, we have printed out the first element of `x`, written as *x[0]*, and in
    the second example, we have printed out a slice of the second element of `x`; in
    this case, *x[11]* and *x[12]*.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们打印了`x`的第一个元素，写作*x[0]*，在第二个示例中，我们打印了`x`的第二个元素的一个切片；在这种情况下，*x[11]*和*x[12]*。
- en: If you have not come across slicing and indexing, you may want to look at this
    again. Note that indexing begins at `0`, not `1`, and we have kept our subscript
    notation consistent with this. Notice also that the slice `[1][0:2]` is the elements
    *x[10]* and *x[11]*, inclusive. It excludes the ending index, index `2`, specified
    in the slice.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您还没有接触过切片和索引，可能需要再看一次。请注意，索引从`0`开始，而不是`1`，我们的下标符号保持与此一致。还请注意，切片`[1][0:2]`是元素*x[10]*和*x[11]*，包括*x[12]*。不包括切片结束索引`2`。
- en: 'We can can create a reshaped copy of an existing tensor using the `view()`
    function. The following are three examples:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`view()`函数创建现有张量的重塑副本。以下是三个示例：
- en: '![](img/788c12a0-63ac-4461-a840-c6c29bc848ff.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![](img/788c12a0-63ac-4461-a840-c6c29bc848ff.png)'
- en: 'It is pretty clear what (`3`,`2`) and (`6`,`1`) do, but what about the `–1`
    in the first example? This is useful if you know how many columns you require,
    but do not know how many rows this will fit into. Indicating `–1` here is telling
    PyTorch to calculate the number of rows required. Using it without another dimension
    simply creates a tensor of a single row. You could rewrite example two mentioned
    previously, as follows, if you did not know the input tensor''s shape but know
    that it needs to have three rows:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: (`3`,`2`)和(`6`,`1`)很明显，但是第一个示例中的`–1`是什么意思？如果您知道需要多少列，但不知道需要多少行，这非常有用。在这里使用`–1`告诉PyTorch计算所需的行数。在没有其他维度的情况下使用它将创建一个单行张量。如果您不知道输入张量的形状，但知道它需要有三行，您可以像以下示例两样重新编写：
- en: '![](img/08d1e9bd-f6be-4e5f-8986-f245cc2ad3a7.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![](img/08d1e9bd-f6be-4e5f-8986-f245cc2ad3a7.png)'
- en: 'An important operation is swapping axes or transposing. For a two-dimensional
    tensor, we a can use `tensor.transpose()`, passing it the axis we want to transpose.
    In this example, the original 2 x 3 tensor becomes a 3 x 2 tensor. The rows simply
    become the columns:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/af234137-04cd-46c9-b648-fb67489a12e8.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
- en: 'In PyTorch, `transpose()` can only swap two axes at once. We could use `transpose`
    in multiple steps; however, a more convenient way is to use `permute()`, passing
    it the axes we want to swap. The following example should make this clear:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ae328fc7-ef5a-4580-aa7d-e03727ee5716.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
- en: When we are considering tensors in two dimensions, we can visualize them as
    flat tables. When we move to higher dimensions, this visual representation becomes
    impossible. We simply run out of spatial dimensions. Part of the magic of deep
    learning is that it does not matter much in terms of the mathematics involved.
    Real-world features are each encoded into a dimension of a data structure. So,
    we may be dealing with tensors of potentially thousands of dimensions. Although
    it might be disconcerting, most of the ideas that can be illustrated in two or
    three dimensions work just as well in higher dimensions.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: In place operations
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'It is important to understand the difference between in place and assignment
    operations. When, for example, we use `transpose(x)`, a value is returned but
    the value of `x` does not change. In all the examples up until now, we have been
    performing operations by assignment. That is, we have been assigning a variable
    to the result of an operation, or simply printing it to the output, as in the
    preceding example. In either case, the original variable remains untouched. Alternatively,
    we may need to apply an operation in place. We can, of course, assign a variable
    to itself, such as in `x = x.transpose(0,1)`; however, a more convenient way to
    do this is with in place operations. In general, in place operations in PyTorch
    have a trailing underscore. For an example, see the following code:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7ca2c271-9c18-47b5-bb20-79974476688d.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
- en: 'As another example, here is the linear function we started this chapter with
    using in place operations on `y`:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f6c09eef-fdf6-43d9-b41d-a9dbf0c29950.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
- en: Loading data
  id: totrans-129
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Most of the time you will spend on a deep learning project will be spent working
    with data and one of the main reasons that a deep learning project will fail is
    because of bad, or poorly understood data. This issue is often overlooked when
    we are working with well-known and well-constructed datasets. The focus here is
    on learning the models. The algorithms that make deep learning models work are
    complex enough themselves without this complexity being compounded by something
    that is only partially known, such as an unfamiliar dataset. Real-world data is
    noisy, incomplete, and error prone. These axes of confoundedness mean that if
    a deep learning algorithm is not giving sensible results, after errors of logic
    in the code are eliminated, bad data, or errors in our understanding of the data,
    are the likely culprit.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数时间你会在深度学习项目上花费在处理数据上，一个深度学习项目失败的主要原因之一是因为糟糕或理解不足的数据。当我们使用众所周知且构建良好的数据集时，这个问题常常被忽视。这里的重点是学习模型。使深度学习模型工作的算法本身就足够复杂，不需要由于某些仅部分了解的东西（如不熟悉的数据集）而增加这种复杂性。现实世界的数据是嘈杂的、不完整的和容易出错的。这些混乱的轴意味着，如果一个深度学习算法在消除代码逻辑错误后仍未给出合理结果，那么糟糕的数据或对数据理解的错误很可能是问题的根源。
- en: So putting aside our wrestle with data, and with an understanding that deep
    learning can provide valuable real-world insights, how do we learn deep learning?
    Our starting point is to eliminate as many of the variables that we can. This
    can be achieved by using data that is well known and representative of a specific
    problem; say, for example, classification. This enables us to have both a starting
    point for deep learning tasks, as well as a standard to test model ideas.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，暂时搁置我们与数据的斗争，并理解深度学习可以提供宝贵的现实世界见解，我们如何学习深度学习？我们的起点是尽可能消除我们能消除的变量。这可以通过使用众所周知且代表特定问题的数据来实现；例如分类问题。这使我们能够在深度学习任务中有一个起点，同时也有一个测试模型想法的标准。
- en: One of the most well-known datasets is the MNIST dataset of hand-written digits,
    where the usual task is to correctly classify each of the digits, from zero through
    nine. The best models get an error rate of around 0.2%. We could apply this well-performing
    model with a few adjustments, to any visual classification task, with varying
    results. It is unlikely we will get results anywhere near 0.2% and the reason
    is because the data is different. Understanding how to tweek a deep learning model
    to take into account these sometimes subtle differences in data, is one of the
    key skills of a successful deep learning practitioner.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 最著名的数据集之一是手写数字的MNIST数据集，通常的任务是正确分类每个数字，从零到九。最好的模型的错误率约为0.2%。我们可以对任何视觉分类任务应用这个表现良好的模型，并且会得到不同的结果。我们几乎不可能获得接近0.2%的结果，原因在于数据的差异。理解如何调整深度学习模型以考虑数据中这些有时微妙的差异，是成功的深度学习从业者的关键技能之一。
- en: Consider an image classification task of facial recognition from color photographs.
    The task is still classification but the differences in that data type and structure
    dictate how the model will need to change to take this into account. How this
    is done is at the heart of machine learning. For example, if we are working with
    color images, as opposed to black and white images, we will need two extra input
    channels. We will also need output channels for each of the possible classes.
    In a handwriting classification task, we need 10 output channels; one channel
    for each of the digits. For a facial recognition task, we would consider having
    an output channel for each target face (say, for criminals in a police database).
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一个从彩色照片中进行面部识别的图像分类任务。任务仍然是分类，但数据类型和结构的差异决定了模型需要如何改变以考虑这一点。如何做到这一点是机器学习的核心。例如，如果我们处理彩色图像而不是黑白图像，我们将需要额外的两个输入通道。对于每个可能的类别，我们还需要输出通道。在手写分类任务中，我们需要10个输出通道，即每个数字一个通道。对于面部识别任务，我们会考虑为每个目标面孔（比如警方数据库中的罪犯）设置一个输出通道。
- en: Clearly, an important consideration is data types and structures. The way image
    data is structured in an image is vastly different to that of, say, an audio signal,
    or output from a medical device. What if we are trying to classify people's names
    by the sound of their voice, or classify a disease by its symptoms? They are all
    classification tasks; however, in each specific case, the models that represent
    each of these will be vastly different. In order to build suitable models in each
    case, we will need to become intimately acquainted with the data we are using.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，数据类型和结构是重要考虑因素。图像数据在图像中的结构方式与音频信号或医疗设备输出的方式大不相同。如果我们试图通过声音来分类人名，或者通过症状来分类疾病会怎样？它们都是分类任务；然而，在每种具体情况下，代表每种情况的模型将大不相同。为了在每种情况下构建合适的模型，我们需要深入了解正在使用的数据。
- en: It is beyond the scope of this book to discuss the nuances and subtleties of
    each data type, format, and structure. What we can do is give you a brief insight
    into the tools, techniques, and best practice of data handling in PyTorch. Deep
    learning datasets are often very large and it is an important consideration to
    see how they are handled in memory. We need to be able to transform data, output
    data in batches, shuffle data, and perform many other operations on data before
    we feed it to a model. We need to be able to do all these things without loading
    the entire dataset into memory, since many datasets are simply too large. PyTorch
    takes an object approach when working with data, creating class objects for each
    specific activity. We will examine this in more detail in the coming sections.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 本书不讨论每种数据类型、格式和结构的微妙和细微差别。我们能做的是为您提供有关PyTorch数据处理工具、技术和最佳实践的简要见解。深度学习数据集通常非常庞大，在内存中处理它们是一项重要考虑因素。我们需要能够转换数据、批量输出数据、洗牌数据，并在将数据馈送给模型之前执行许多其他操作。由于许多数据集太大，无法将整个数据集加载到内存中，因此我们需要能够执行所有这些操作。在处理数据时，PyTorch采用对象方法，为每个特定的活动创建类对象。我们将在接下来的部分中更详细地讨论这一点。
- en: PyTorch dataset loaders
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: PyTorch 数据集加载器
- en: 'Pytorch includes data loaders for several datasets to help you get started.
    The `torch.dataloader` is the class used for loading datasets. The following is
    a list of the included torch datasets and a brief description:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch 包括几个数据集的数据加载器，帮助您快速入门。`torch.dataloader` 是用于加载数据集的类。以下是包括的torch数据集及其简要描述：
- en: '| **MNIST** | Handwritten digits 1–9\. A subset of NIST dataset of handwritten
    characters. Contains a training set of 60,000 test images and a test set of 10,000.
    |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| **MNIST** | 手写数字1-9。是NIST手写字符数据集的一个子集。包含60,000张训练图像和10,000张测试图像。'
- en: '| **Fashion- MNIST** | A drop-in dataset for MNIST. Contains images of fashion
    items; for example, T-shirt, trousers, pullover. |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| **Fashion-MNIST** | 用于MNIST的一种替代数据集。包含时尚物品的图像；例如T恤、裤子、套头衫。'
- en: '| **EMNIST** | Based on NIST handwritten characters, including letters and
    numbers and split for 47, 26, and 10 class classification problems. |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| **EMNIST** | 基于NIST手写字符，包括字母和数字，并分为47、26和10类分类问题。'
- en: '| **COCO** | Over 100,000 images classified into everyday objects; for example,
    person, backpack, and bicycle. Each image can have more than one class. |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| **COCO** | 超过100,000张分类为日常物体的图像；例如人、背包和自行车。每张图像可以有多个类别。'
- en: '| **LSUN** | Used for large-scale scene classification of images; for example,
    bedroom, bridge, church. |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| **LSUN** | 用于大规模场景图像分类；例如卧室、桥梁、教堂。'
- en: '| **Imagenet-12** | Large-scale visual recognition dataset containing 1.2 million
    images and 1,000 categories. Implemented with `ImageFolder` class, where each
    class is in a folder. |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| **Imagenet-12** | 大规模视觉识别数据集，包含120万张图像和1000个类别。使用 `ImageFolder` 类实现，其中每个类别都在一个文件夹中。'
- en: '| **CIFAR** | 60,000 low-res (32 32) color images in 10 mutually exclusive
    classes; for example, airplane, truck, and car. |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| **CIFAR** | 60,000张低分辨率（32x32）彩色图像，分为10个相互排斥的类别；例如飞机、卡车和汽车。'
- en: '| **STL10** | Similar to CIFAR but with higher resolution and larger number
    of unlabeled images. |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| **STL10** | 类似于CIFAR，但分辨率更高，并有更多未标记的图像。'
- en: '| **SVHN** | 600,000 images of street numbers obtained from Google Street View.
    Used for recognition of digits in real-world settings. |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| **SVHN** | 从谷歌街景获得的60万张街道数字图像。用于识别现实世界中的数字。'
- en: '| **PhotoTour** | Learning Local Image descriptors. Consists of gray scale
    images composed of 126 patches accompanied with a descriptor text file. Used for
    pattern recognition. |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| **PhotoTour** | 学习本地图像描述符。由126个补丁组成的灰度图像，附带有描述符文本文件。用于模式识别。 |'
- en: 'Here is a typical example of how we load one of these datasets into PyTorch:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个典型的示例，展示了如何将其中一个数据集加载到PyTorch中：
- en: '![](img/93a99bb6-b520-4f86-b15f-e7e6122a5413.png)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![](img/93a99bb6-b520-4f86-b15f-e7e6122a5413.png)'
- en: '`CIFAR10` is a `torch.utils.dataset` object. Here, we are passing it four arguments.
    We specify a root directory relative to where the code is running, a Boolean,
    `train`, indicating if we want the test or training set loaded, a Boolean that,
    if set to `True`, will check to see if the dataset has previously been downloaded
    and if not download it, and a callable transform. In this case, the transform
    we select is `ToTensor()`. This is an inbuilt class of `torchvision.transforms`
    that makes the class return a tensor. We will discuss transforms in more detail
    later in the chapter.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '`CIFAR10`是一个`torch.utils.dataset`对象。在这里，我们传递了四个参数。我们指定了一个相对于代码运行位置的根目录，一个布尔值`train`，表示我们想要加载的是测试集还是训练集，一个布尔值，如果设置为`True`，将检查数据集是否已经下载，如果没有则下载，以及一个可调用的transform。在这种情况下，我们选择的transform是`ToTensor()`。这是`torchvision.transforms`中的一个内置类，使得该类返回一个tensor。我们将在本章的后面更详细地讨论transforms。'
- en: 'The contents of the dataset can be retrieved by a simple index lookup. We can
    also check the length of the entire dataset with the `len` function. We can also
    loop through the dataset in order. The following code demonstrates this:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过简单的索引查找来获取数据集的内容。我们还可以使用`len`函数检查整个数据集的长度。我们也可以按顺序遍历数据集。以下代码演示了这一点：
- en: '![](img/4565604a-7750-4bd0-a56e-86d46624c8d2.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4565604a-7750-4bd0-a56e-86d46624c8d2.png)'
- en: Displaying an image
  id: totrans-153
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 显示图像
- en: 'The `CIFAR10` dataset object returns a tuple containing an image object and
    a number representing the label of the image. We see from the size of the image
    data, that each sample is a 3 x 32 x 32 tensor, representing three color values
    for each of the 322 pixels in the image. It is important to know that this is
    not quite the same format used for `matplotlib`. A tensor treats an image in the
    format of `[color, height, width]`, whereas a `numpy` image is in the format `[height,
    width, color]`. To plot an image, we need to swap axes using the `permute()` function,
    or alternatively convert it to a NumPy array and using the `transpose` function.
    Note that we do not need to convert the image to a NumPy array, as `matplotlib`
    will display the correctly permuted tensor. The following code should make this
    clear:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '`CIFAR10`数据集对象返回一个元组，包含一个图像对象和表示图像标签的数字。从图像数据的大小可以看出，每个样本是一个3 x 32 x 32的张量，代表图像中322个像素的三种颜色值。需要注意的是，这与`matplotlib`使用的格式不完全相同。张量处理的图像格式是`[颜色，高度，宽度]`，而`numpy`图像的格式是`[高度，宽度，颜色]`。要绘制图像，我们需要使用`permute()`函数交换轴，或者将其转换为NumPy数组并使用`transpose`函数。请注意，我们不需要将图像转换为NumPy数组，因为`matplotlib`将正确显示调整后的张量。以下代码应该能够清楚地表明这一点：'
- en: '![](img/4a8d5854-1b40-444c-a7a8-4bee92184871.png)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4a8d5854-1b40-444c-a7a8-4bee92184871.png)'
- en: DataLoader
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: DataLoader
- en: We will see that in a deep learning model, we may not always want to load images
    one at a time or load them in the same order each time. For this, and other reasons,
    it is often better to use the `torch.utils.data.DataLoader` object. `DataLoader`
    provides a multipurpose iterator to sample the data in a specified way, such as
    in batches, or shuffled. It is also a convenient place to assign workers in multiprocessor
    environments.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在深度学习模型中，我们可能并不总是希望一次加载一个图像，或者每次以相同顺序加载它们。出于这个原因等等，使用`torch.utils.data.DataLoader`对象通常更好。`DataLoader`提供了一个多功能迭代器，可以按指定的方式对数据进行采样，例如按批次或随机顺序。它还是在多处理器环境中分配工作线程的便利位置。
- en: 'In the following example, we sample the dataset in batches of four samples
    each:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的示例中，我们以每批四个样本的方式对数据集进行采样：
- en: '![](img/ae7f3089-5874-489b-92e3-dfdb1d30db51.png)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ae7f3089-5874-489b-92e3-dfdb1d30db51.png)'
- en: Here `DataLoader` returns a tuple of two tensors. The first tensor contains
    the image data of all four images in the batch. The second tensor are the images
    labels. Each batch consists of four image label, pairs, or samples. Calling `next()`
    on the iterator generates the next set of four samples. In machine learning terminology,
    each pass over the entire dataset is called an epoch. This technique is used extensively,
    as we will see to train and test deep learning models.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 这里 `DataLoader` 返回一个包含两个张量的元组。第一个张量包含批次中所有四个图像的图像数据。第二个张量是图像的标签。每个批次由四个图像标签对或样本组成。在迭代器上调用
    `next()` 生成下一组四个样本。在机器学习术语中，对整个数据集的每次遍历称为一个 epoch。正如我们将看到的，这种技术被广泛用于训练和测试深度学习模型。
- en: Creating a custom dataset
  id: totrans-161
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建自定义数据集
- en: 'The `Dataset` class is an abstract class representing a dataset. Its purpose
    is to have a consistent way of representing the specific characteristics of a
    dataset. When we are working with unfamiliar datasets, creating a `Dataset` object
    is a good way to understand and represent the structure of the data. It is used
    with a `data loader` class to draw samples from a dataset in a clean and efficient
    manner. The following diagram illustrates how these classes are used:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '`Dataset` 类是表示数据集的抽象类。它的目的是以一致的方式表示数据集的特定特征。当我们使用不熟悉的数据集时，创建一个 `Dataset` 对象是理解和表示数据结构的好方法。它与
    `data loader` 类一起使用，以清晰和高效的方式从数据集中抽取样本。下图说明了这些类的使用方式：'
- en: '![](img/e03c0f94-a8ed-42fe-96a0-1eb2956445be.png)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e03c0f94-a8ed-42fe-96a0-1eb2956445be.png)'
- en: Common actions we perform with a `Dataset` class include checking the data for
    consistency, applying transform methods, dividing the data into training and test
    sets, and loading individual samples.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 `Dataset` 类执行的常见操作包括检查数据的一致性，应用转换方法，将数据分为训练集和测试集，并加载单个样本。
- en: In the following example, we are using a small toy dataset consisting of images
    of objects that are classified as either toys or not toys. This is representative
    of a simple image classification problem where a model is trained on a set of
    labeled images. A deep learning model will need the data with various transformations
    applied in a consistent manner. Samples may need to be drawn in batches and the
    dataset shuffled. Having a framework for representing these data tasks greatly
    simplifies and enhances deep learning models.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下示例中，我们使用一个小型玩具数据集，其中包含被分类为玩具或非玩具的对象图像。这代表了一个简单的图像分类问题，其中模型在一组标记图像上进行训练。深度学习模型需要以一致的方式应用各种转换后的数据。样本可能需要分批抽取并对数据集进行洗牌。拥有表示这些数据任务的框架极大地简化和增强了深度学习模型。
- en: The complete dataset is available at [http://www.vision.caltech.edu/pmoreels/Datasets/Giuseppe_Toys_03/](http://www.vision.caltech.edu/pmoreels/Datasets/Giuseppe_Toys_03/).
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 完整的数据集可在 [http://www.vision.caltech.edu/pmoreels/Datasets/Giuseppe_Toys_03/](http://www.vision.caltech.edu/pmoreels/Datasets/Giuseppe_Toys_03/)
    上找到。
- en: 'For this example, I have created a smaller subset of the dataset, together
    with a `labels.csv` file. This is available in the `data/GiuseppeToys` folder
    in the GitHub repository for this book. The class representing this dataset is
    as follows:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本示例，我创建了数据集的一个较小子集，以及一个 `labels.csv` 文件。这在本书的 GitHub 仓库中的 `data/GiuseppeToys`
    文件夹中可以找到。表示这个数据集的类如下所示：
- en: '![](img/9b8f0b82-c247-4279-a34a-3cc29bba6b52.png)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9b8f0b82-c247-4279-a34a-3cc29bba6b52.png)'
- en: The `__init__` function is where we initialize all the properties of the class. Since
    it is only called once when we first create the instance to do all the things,
    we perform all the housekeeping functions, such as reading CSV files, setting
    the variables, and checking data for consistency. We only perform operations that
    occur across the entire dataset, so we do not download the payload (in this example,
    an image), but we make sure that the critical information about the dataset, such
    as directory paths, filenames, and dataset labels are stored in variables.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '`__init__` 函数是我们初始化类的所有属性的地方。因为它仅在我们首次创建实例时调用一次来执行所有操作，所以我们执行所有的日常管理功能，例如读取
    CSV 文件，设置变量并检查数据的一致性。我们只执行整个数据集都会发生的操作，因此我们不下载负载（在这个例子中是图像），但是我们确保数据集的关键信息，如目录路径、文件名和数据集标签被存储在变量中。'
- en: The `__len__` function simply allows us to call Python's built-in `len()` function
    on the dataset. Here, we simply return the length of the list of label tuples,
    indicating the number of images in the dataset. We want to make sure that stays
    as simple and reliable as possible because we depend on it to correctly iterate
    through the dataset.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '`__len__`函数简单地允许我们在数据集上调用Python的内置`len()`函数。在这里，我们只需返回标签元组列表的长度，指示数据集中的图像数量。我们希望保持其尽可能简单和可靠，因为我们依赖它正确迭代数据集。'
- en: The `__getitem__` function is an built-in Python function that we override in
    our `Dataset` class definition. This gives the `Dataset` class the functionality
    of Python sequence types, such as the use of indexing and slicing. This method
    gets called often—every time we do an index lookup—so make sure it only does what
    it needs to do to retrieve the sample.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '`__getitem__`函数是我们在`Dataset`类定义中覆盖的内置Python函数。这使得`Dataset`类具有Python序列类型的功能，例如索引和切片的使用。这个方法经常被调用——每当我们进行索引查找时都会调用一次，因此确保它只执行检索样本所需的操作。'
- en: 'To harness this functionality into our own dataset, we need to create an instance
    of our custom dataset as follows:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 要将此功能应用于我们自己的数据集中，我们需要创建我们自定义数据集的实例，如下所示：
- en: '![](img/be95d815-120b-4704-94e2-d16de15b2dca.png)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![](img/be95d815-120b-4704-94e2-d16de15b2dca.png)'
- en: Transforms
  id: totrans-174
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 转换
- en: 'As well as the `ToTensor()` transform, the `torchvision` package includes a
    number of transforms specifically for Python imaging library images. We can apply
    multiple transforms to a dataset object using the `compose` function as follows:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 除了`ToTensor()`转换之外，`torchvision`包还包含一些专门用于Python图像库图像的转换。我们可以使用`compose`函数将多个转换应用于数据集对象，如下所示：
- en: '![](img/6ca9d98a-c422-44d1-98d8-62de1fd2f9e6.png)'
  id: totrans-176
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6ca9d98a-c422-44d1-98d8-62de1fd2f9e6.png)'
- en: Compose objects are essentially a list of transforms that can then be passed
    to the dataset as a single variable. It is important to note that the image transforms can
    only be applied to PIL image data, not tensors. Since transforms in a compose
    are applied in the order that they are listed, it is important that the `ToTensor` transform occurs
    last. If it is placed before the PIL transforms in the `Compose` list, an error
    will be generated.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '`Compose`对象本质上是可以作为单个变量传递给数据集的一系列转换。重要的是要注意图像转换只能应用于PIL图像数据，而不能应用于张量。由于在`Compose`列表中按照列出的顺序应用转换，因此`ToTensor`转换放置在PIL转换之前会生成错误。'
- en: 'Finally, we can check that it all works by using `DataLoader` to load a batch
    of images with transforms, as we did before:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以通过使用`DataLoader`加载带有转换的图像批次来检查所有功能是否正常，就像之前做的那样：
- en: '![](img/b49c0780-2f05-4868-abd1-42ec7ea38454.png)'
  id: totrans-179
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b49c0780-2f05-4868-abd1-42ec7ea38454.png)'
- en: ImageFolder
  id: totrans-180
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ImageFolder
- en: 'We can see that the main function of the dataset object is to take a sample
    from a dataset, and the function of `DataLoader` is to deliver a sample, or a
    batch of samples, to a deep learning model for evaluation. One of the main things
    to consider when writing our own dataset object is how do we build a data structure
    in accessible memory from data that is organized in files on a disk. A common
    way we might want to organize data is in folders named by class. Let''s say that,
    for this example, we have three folders named `toy`, `notoy`, and `scenes`, contained
    in a parent folder, `images`. Each of these folders represent the label of the
    files contained within them. We need to be able to load them while retaining them
    as separate labels. Happily, there is a class for this, and like most things in
    PyTorch, it is very easy to use. The class is `torchvision.datasets.ImageFolder`
    and it is used as follows:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到数据集对象的主要功能是从数据集中获取样本，而`DataLoader`函数的功能是向深度学习模型提供样本或样本批次进行评估。在编写自己的数据集对象时，需要考虑的主要事项之一是如何从磁盘上组织的文件中的数据构建可访问内存中的数据结构。我们可能希望组织数据的常见方式是按类别命名的文件夹。假设在这个例子中，我们有三个名为`toy`、`notoy`和`scenes`的文件夹，包含在名为`images`的父文件夹中。每个文件夹表示其中包含的文件的标签。我们需要能够加载它们同时保持它们作为单独的标签。幸运的是，有一个专门用于此的类，并且像大多数PyTorch中的东西一样，它非常易于使用。这个类是`torchvision.datasets.ImageFolder`，使用方法如下：
- en: '![](img/bc47c911-404e-4f29-b1fd-602847da1f6f.png)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bc47c911-404e-4f29-b1fd-602847da1f6f.png)'
- en: Within the `data/GiuseppeToys/images` folder, there are three folders, `toys`,
    `notoys`, and `scenes`, containing images with their folder names indicating labels.
    Notice that the retrieved labels using `DataLoader` are represented by integers.
    Since, in this example, we have three folders, representing three labels, `DataLoader`
    returns integers `1` to `3`, representing the image labels.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 在`data/GiuseppeToys/images`文件夹中，有三个文件夹，`toys`、`notoys`和`scenes`，其中包含以其文件夹名称表示标签的图像。请注意，使用`DataLoader`检索的标签由整数表示。由于本示例中有三个文件夹，表示三个标签，`DataLoader`返回整数`1`到`3`，表示图像标签。
- en: Concatenating datasets
  id: totrans-184
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 连接数据集
- en: 'It is clear that the need will arise to join datasets—we can do this with the
    `torch.utils.data.ConcatDataset` class. `ConcatDataset` takes a list of datasets
    and returns a concatenated dataset. In the following example, we add two more
    transforms, removing the blue and green color channel. We then create two more
    dataset objects, applying these transforms and, finally, concatenating all three
    datasets into one, as shown in the following code:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 很明显，将需要连接数据集——我们可以使用`torch.utils.data.ConcatDataset`类来实现这一点。`ConcatDataset`接受一个数据集列表，并返回一个连接后的数据集。在以下示例中，我们添加了两个额外的转换，去除蓝色和绿色通道。然后，我们创建了两个应用了这些转换的数据集对象，并最终将这三个数据集连接成一个，如下所示的代码所示：
- en: '![](img/e4e36b79-d23c-4c4e-94ae-78717d5962ab.png)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e4e36b79-d23c-4c4e-94ae-78717d5962ab.png)'
- en: Summary
  id: totrans-187
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we have introduced some of the features and operations of PyTorch.
    We gave an overview of the installation platforms and procedures. You have hopefully
    gained some knowledge of tensor operations and how to perform them in PyTorch.
    You should be clear about the distinction between in place and by assignment operations
    and should also now understand the fundamentals of indexing and slicing tensors.
    In the second half of this chapter, we looked at loading data into PyTorch. We
    discussed the importance of data and how to create a `dataset` object to represent
    custom datasets. We looked at the inbuilt data loaders in PyTorch and discussed
    representing data in folders using the `ImageFolder` object. Finally, we looked
    at how to concatenate datasets.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了PyTorch的一些特性和操作。我们概述了安装平台和流程。您现在应该对张量操作有所了解，并了解如何在PyTorch中执行这些操作。您应该清楚地区分了就地操作和通过赋值操作，并且现在应该理解张量索引和切片的基础知识。在本章的后半部分，我们看了如何将数据加载到PyTorch中。我们讨论了数据的重要性，以及如何创建表示自定义数据集的`dataset`对象。我们查看了PyTorch中的内置数据加载器，并讨论了如何使用`ImageFolder`对象表示文件夹中的数据。最后，我们看了如何连接数据集。
- en: In the next chapter, we will take a whirlwind tour of deep learning fundamentals
    and their place in the machine learning landscape. We will get you up to speed
    with the mathematical concepts involved, including looking at linear systems and
    common techniques for solving them.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将快速浏览深度学习基础知识及其在机器学习中的地位。我们将带您快速了解涉及的数学概念，包括查看线性系统及其常见解决技术。
