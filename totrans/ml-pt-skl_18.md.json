["```py\npip install networkx \n```", "```py\n>>> import numpy as np\n>>> import networkx as nx\n>>> G = nx.Graph()\n... # Hex codes for colors if we draw graph\n>>> blue, orange, green = \"#1f77b4\", \"#ff7f0e\", \"#2ca02c\"\n>>> G.add_nodes_from([\n...     (1, {\"color\": blue}),\n...     (2, {\"color\": orange}),\n...     (3, {\"color\": blue}),\n...     (4, {\"color\": green})\n... ])\n>>> G.add_edges_from([(1,2), (2,3), (1,3), (3,4)])\n>>> A = np.asarray(nx.adjacency_matrix(G).todense())\n>>> print(A)\n[[0 1 1 0]\n[1 0 1 0]\n[1 1 0 1]\n[0 0 1 0]]\n>>> def build_graph_color_label_representation(G, mapping_dict):\n...     one_hot_idxs = np.array([mapping_dict[v] for v in\n...         nx.get_node_attributes(G, 'color').values()])\n>>>     one_hot_encoding = np.zeros(\n...         (one_hot_idxs.size, len(mapping_dict)))\n>>>     one_hot_encoding[\n...         np.arange(one_hot_idxs.size), one_hot_idxs] = 1\n>>>     return one_hot_encoding\n>>> X = build_graph_color_label_representation(\n...     G, {green: 0, blue: 1, orange: 2})\n>>> print(X)\n[[0., 1., 0.],\n[0., 0., 1.],\n[0., 1., 0.],\n[1., 0., 0.]] \n```", "```py\n>>> color_map = nx.get_node_attributes(G, 'color').values()\n>>> nx.draw(G,with_labels=True, node_color=color_map) \n```", "```py\n>>> f_in, f_out = X.shape[1], 6\n>>> W_1 = np.random.rand(f_in, f_out)\n>>> W_2 = np.random.rand(f_in, f_out)\n>>> h = np.dot(X, W_1)+ np.dot(np.dot(A,X), W_2) \n```", "```py\nimport networkx as nx\nimport torch\nfrom torch.nn.parameter import Parameter\nimport numpy as np\nimport math\nimport torch.nn.functional as F\nclass NodeNetwork(torch.nn.Module):\n    def __init__(self, input_features):\n        super().__init__()\n        self.conv_1 = BasicGraphConvolutionLayer (\n            input_features, 32)\n        self.conv_2 = BasicGraphConvolutionLayer(32, 32)\n        self.fc_1 = torch.nn.Linear(32, 16)\n        self.out_layer = torch.nn.Linear(16, 2)\n    def forward(self, X, A, batch_mat):\n        x = F.relu(self.conv_1(X, A))\n        x = F.relu(self.conv_2(x, A))\n        output = global_sum_pool(x, batch_mat)\n        output = self.fc_1(output)\n        output = self.out_layer(output)\n        return F.softmax(output, dim=1) \n```", "```py\nclass BasicGraphConvolutionLayer(torch.nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.W2 = Parameter(torch.rand(\n            (in_channels, out_channels), dtype=torch.float32))\n        self.W1 = Parameter(torch.rand(\n            (in_channels, out_channels), dtype=torch.float32))\n\n        self.bias = Parameter(torch.zeros(\n                out_channels, dtype=torch.float32))\n    def forward(self, X, A):\n        potential_msgs = torch.mm(X, self.W2)\n        propagated_msgs = torch.mm(A, potential_msgs)\n        root_update = torch.mm(X, self.W1)\n        output = propagated_msgs + root_update + self.bias\n        return output \n```", "```py\n>>> print('X.shape:', X.shape)X.shape: (4, 3)\n>>> print('A.shape:', A.shape)\nA.shape: (4, 4)\n>>> basiclayer = BasicGraphConvolutionLayer(3, 8)\n>>> out = basiclayer(\n...     X=torch.tensor(X, dtype=torch.float32),\n...     A=torch.tensor(A, dtype=torch.float32)\n... )\n>>> print('Output shape:', out.shape)\nOutput shape: torch.Size([4, 8]) \n```", "```py\ndef global_sum_pool(X, batch_mat):\n    if batch_mat is None or batch_mat.dim() == 1:\n        return torch.sum(X, dim=0).unsqueeze(0)\n    else:\n        return torch.mm(batch_mat, X) \n```", "```py\ndef get_batch_tensor(graph_sizes):\n    starts = [sum(graph_sizes[:idx])\n              for idx in range(len(graph_sizes))]\n    stops = [starts[idx] + graph_sizes[idx]\n             for idx in range(len(graph_sizes))]\n    tot_len = sum(graph_sizes)\n    batch_size = len(graph_sizes)\n    batch_mat = torch.zeros([batch_size, tot_len]).float()\n    for idx, starts_and_stops in enumerate(zip(starts, stops)):\n        start = starts_and_stops[0]\n        stop = starts_and_stops[1]\n        batch_mat[idx,start:stop] = 1\n    return batch_mat \n```", "```py\n# batch is a list of dictionaries each containing\n# the representation and label of a graph\ndef collate_graphs(batch):\n    adj_mats = [graph['A'] for graph in batch]\n    sizes = [A.size(0) for A in adj_mats]\n    tot_size = sum(sizes)\n    # create batch matrix\n    batch_mat = get_batch_tensor(sizes)\n    # combine feature matrices\n    feat_mats = torch.cat([graph['X'] for graph in batch], dim=0)\n    # combine labels\n    labels = torch.cat([graph['y'] for graph in batch], dim=0)\n    # combine adjacency matrices\n    batch_adj = torch.zeros([tot_size, tot_size], dtype=torch.float32)\n    accum = 0\n    for adj in adj_mats:\n        g_size = adj.shape[0]\n        batch_adj[accum:accum+g_size,accum:accum+g_size] = adj\n        accum = accum + g_size\n    repr_and_label = {'A': batch_adj,\n            'X': feat_mats, 'y': labels,\n            'batch': batch_mat}\n    return repr_and_label \n```", "```py\ndef get_graph_dict(G, mapping_dict):\n    # Function builds dictionary representation of graph G\n    A = torch.from_numpy(\n        np.asarray(nx.adjacency_matrix(G).todense())).float()\n    # build_graph_color_label_representation()\n    # was introduced with the first example graph\n    X = torch.from_numpy(\n      build_graph_color_label_representation(\n               G, mapping_dict)).float()\n    # kludge since there is not specific task for this example\n    y = torch.tensor([[1,0]]).float()\n    return {'A': A, 'X': X, 'y': y, 'batch': None} \n```", "```py\n>>> # building 4 graphs to treat as a dataset\n>>> blue, orange, green = \"#1f77b4\", \"#ff7f0e\",\"#2ca02c\"\n>>> mapping_dict= {green:0, blue:1, orange:2}\n>>> G1 = nx.Graph()\n>>> G1.add_nodes_from([\n...     (1,{\"color\": blue}),\n...     (2,{\"color\": orange}),\n...     (3,{\"color\": blue}),\n...     (4,{\"color\": green})\n... ])\n>>> G1.add_edges_from([(1, 2), (2, 3), (1, 3), (3, 4)])\n>>> G2 = nx.Graph()\n>>> G2.add_nodes_from([\n...     (1,{\"color\": green}),\n...     (2,{\"color\": green}),\n...     (3,{\"color\": orange}),\n...     (4,{\"color\": orange}),\n...     (5,{\"color\": blue})\n... ])\n>>> G2.add_edges_from([(2, 3),(3, 4),(3, 1),(5, 1)])\n>>> G3 = nx.Graph()\n>>> G3.add_nodes_from([\n...     (1,{\"color\": orange}),\n...     (2,{\"color\": orange}),\n...     (3,{\"color\": green}),\n...     (4,{\"color\": green}),\n...     (5,{\"color\": blue}),\n...     (6,{\"color\":orange})\n... ])\n>>> G3.add_edges_from([(2,3), (3,4), (3,1), (5,1), (2,5), (6,1)])\n>>> G4 = nx.Graph()\n>>> G4.add_nodes_from([\n...     (1,{\"color\": blue}),\n...     (2,{\"color\": blue}),\n...     (3,{\"color\": green})\n... ])\n>>> G4.add_edges_from([(1, 2), (2, 3)])\n>>> graph_list = [get_graph_dict(graph, mapping_dict) for graph in\n...     [G1, G2, G3, G4]] \n```", "```py\nfrom torch.utils.data import Dataset\nclass ExampleDataset(Dataset):\n    # Simple PyTorch dataset that will use our list of graphs\n    def __init__(self, graph_list):\n        self.graphs = graph_list\n    def __len__(self):\n        return len(self.graphs)\n    def __getitem__(self,idx):\n        mol_rep = self.graphs[idx]\n        return mol_rep \n```", "```py\n>>> from torch.utils.data import DataLoader\n>>> dset = ExampleDataset(graph_list)\n>>> # Note how we use our custom collate function\n>>> loader = DataLoader(\n...     dset, batch_size=2, shuffle=False,\n...     collate_fn=collate_graphs) \n```", "```py\n>>> node_features = 3\n>>> net = NodeNetwork(node_features)\n>>> batch_results = []\n>>> for b in loader:\n...     batch_results.append(\n...         net(b['X'], b['A'], b['batch']).detach()) \n```", "```py\n>>> G1_rep = dset[1]\n>>> G1_single = net(\n...     G1_rep['X'], G1_rep['A'], G1_rep['batch']).detach() \n```", "```py\n>>> G1_batch = batch_results[0][1]\n>>> torch.all(torch.isclose(G1_single, G1_batch))\ntensor(True) \n```", "```py\npip install torch-scatter==2.0.9\npip install torch-sparse==0.6.12\npip install torch-geometric==2.0.2 \n```", "```py\n>>> # For all examples in this section we use the following imports.\n>>> # Note that we are using torch_geometric's DataLoader.\n>>> import torch\n>>> from torch_geometric.datasets import QM9\n>>> from torch_geometric.loader import DataLoader\n>>> from torch_geometric.nn import NNConv, global_add_pool\n>>> import torch.nn.functional as F\n>>> import torch.nn as nn\n>>> import numpy as np\n>>> # let's load the QM9 small molecule dataset\n>>> dset = QM9('.')\n>>> len(dset)\n130831\n>>> # Here's how torch geometric wraps data\n>>> data = dset[0]\n>>> data\nData(edge_attr=[8, 4], edge_index=[2, 8], idx=[1], name=\"gdb_1\", pos=[5, 3], x=[5, 11], y=[1, 19], z=[5])\n>>> # can access attributes directly\n>>> data.z\ntensor([6, 1, 1, 1, 1])\n>>> # the atomic number of each atom can add attributes\n>>> data.new_attribute = torch.tensor([1, 2, 3])\n>>> data\nData(edge_attr=[8, 4], edge_index=[2, 8], idx=[1], name=\"gdb_1\", new_attribute=[3], pos=[5, 3], x=[5, 11], y=[1, 19], z=[5])\n>>> # can move all attributes between devices\n>>> device = torch.device(\n...     \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n... )\n>>> data.to(device)\n>>> data.new_attribute.is_cuda\nTrue \n```", "```py\nclass ExampleNet(torch.nn.Module):\n    def __init__(self, num_node_features, num_edge_features):\n        super().__init__()\n        conv1_net = nn.Sequential(\n            nn.Linear(num_edge_features, 32),\n            nn.ReLU(),\n            nn.Linear(32, num_node_features*32))\n        conv2_net = nn.Sequential(\n            nn.Linear(num_edge_features, 32),\n            nn.ReLU(),\n            nn.Linear(32, 32*16))\n        self.conv1 = NNConv(num_node_features, 32, conv1_net)\n        self.conv2 = NNConv(32,16, conv2_net)\n        self.fc_1 = nn.Linear(16, 32)\n        self.out = nn.Linear(32, 1)\n    def forward(self, data):\n        batch, x, edge_index, edge_attr = (\n            data.batch, data.x, data.edge_index, data.edge_attr)\n        # First graph conv layer\n        x = F.relu(self.conv1(x, edge_index, edge_attr))\n        # Second graph conv layer\n        x = F.relu(self.conv2(x, edge_index, edge_attr))\n        x = global_add_pool(x,batch)\n        x = F.relu(self.fc_1(x))\n        output = self.out(x)\n        return output \n```", "```py\n>>> from torch.utils.data import random_split\n>>> train_set, valid_set, test_set = random_split(\n...     dset,[110000, 10831, 10000])\n>>> trainloader = DataLoader(train_set, batch_size=32, shuffle=True)\n>>> validloader = DataLoader(valid_set, batch_size=32, shuffle=True)\n>>> testloader = DataLoader(test_set, batch_size=32, shuffle=True) \n```", "```py\n>>> # initialize a network\n>>> qm9_node_feats, qm9_edge_feats = 11, 4\n>>> net = ExampleNet(qm9_node_feats, qm9_edge_feats)\n>>> # initialize an optimizer with some reasonable parameters\n>>> optimizer = torch.optim.Adam(\n...     net.parameters(), lr=0.01)\n>>> epochs = 4\n>>> target_idx = 1 # index position of the polarizability label\n>>> device = torch.device(\"cuda:0\" if\n...                       torch.cuda.is_available() else \"cpu\")\n>>> net.to(device) \n```", "```py\n>>> for total_epochs in range(epochs):\n...     epoch_loss = 0\n...     total_graphs = 0\n...     net.train()\n...     for batch in trainloader:\n...         batch.to(device)\n...         optimizer.zero_grad()\n...         output = net(batch)\n...         loss = F.mse_loss(\n...             output,batch.y[:, target_idx].unsqueeze(1))\n...         loss.backward()\n...         epoch_loss += loss.item()\n...         total_graphs += batch.num_graphs\n...         optimizer.step()\n...     train_avg_loss = epoch_loss / total_graphs\n...     val_loss = 0\n...     total_graphs = 0\n...     net.eval()\n...     for batch in validloader:\n...         batch.to(device)\n...         output = net(batch)\n...         loss = F.mse_loss(\n...             output,batch.y[:, target_idx].unsqueeze(1))\n...         val_loss += loss.item()\n...         total_graphs += batch.num_graphs\n...     val_avg_loss = val_loss / total_graphs\n...     print(f\"Epochs: {total_epochs} | \"\n...           f\"epoch avg. loss: {train_avg_loss:.2f} | \"\n...           f\"validation avg. loss: {val_avg_loss:.2f}\")\nEpochs: 0 | epoch avg. loss: 0.30 | validation avg. loss: 0.10\nEpochs: 1 | epoch avg. loss: 0.12 | validation avg. loss: 0.07\nEpochs: 2 | epoch avg. loss: 0.10 | validation avg. loss: 0.05\nEpochs: 3 | epoch avg. loss: 0.09 | validation avg. loss: 0.07 \n```", "```py\n>>> net.eval()\n>>> predictions = []\n>>> real = []\n>>> for batch in testloader:\n...     output = net(batch.to(device))\n...     predictions.append(output.detach().cpu().numpy())\n...     real.append(\n...             batch.y[:,target_idx] .detach().cpu().numpy())\n>>> real = np.concatenate(real)\n>>> predictions = np.concatenate(predictions) \n```", "```py\n>>> import matplotlib.pyplot as plt\n>>> plt.scatter(real[:500], predictions[:500])\n>>> plt.xlabel('Isotropic polarizability')\n>>> plt.ylabel('Predicted isotropic polarizability') \n```"]