["```py\nIn:  (0, 0, 0, 0, 1, 0, 1, 0, 1, 0)\nOut:  3\n```", "```py\ndef step(s, x, U, W):\n    return x * U + s * W\n```", "```py\ndef forward(X, U, W):\n    # Initialize the state activation for each sample along the sequence\n    S = np.zeros((number_of_samples, sequence_length+1))\n    # Update the states over the sequence\n    for t in range(0, sequence_length):\n        S[:,t+1] = step(S[:,t], X[:,t], U, W)  # step function\n    return S\n```", "```py\ncost = np.sum((targets â€“ y)**2)\n```", "```py\ndef backward(X, S, targets, W):\n    # Compute gradient of output\n    y = S[:,-1]  # Output `y` is last activation of sequence\n    # Gradient w.r.t. cost function at final state\n    gS = 2.0 * (y - targets)\n    # Accumulate gradients backwards\n    gU, gW = 0, 0  # Set the gradient accumulations to 0    \n    for k in range(sequence_len, 0, -1):\n        # Compute the parameter gradients and accumulate the results.\n        gU += np.sum(gS * X[:,k-1])\n        gW += np.sum(gS * S[:,k-1])\n        # Compute the gradient at the output of the previous layer\n        gS = gS * W\n    return gU, gW\n```", "```py\nlearning_rate = 0.0005\n# Set initial parameters\nparameters = (-2, 0)  # (U, W)\n# Perform iterative gradient descent\nfor i in range(number_iterations):\n    # Perform forward and backward pass to get the gradients\n    S = forward(X, parameters(0), parameters(1))\n    gradients = backward(X, S, targets, parameters(1))\n    # Update each parameter `p` by p = p - (gradient * learning_rate).\n    # `gp` is the gradient of parameter `p`\n    parameters = ((p - gp * learning_rate) \n                  for p, gp in zip(parameters, gradients))\n```", "```py\ninputs = tf.placeholder(tf.int32, (batch_size, sequence_length))\ntargets = tf.placeholder(tf.int32, (batch_size, sequence_length))\n```", "```py\none_hot_inputs = tf.one_hot(inputs, depth=number_of_characters)\n```", "```py\ncell_list = (tf.nn.rnn_cell.LSTMCell(lstm_size) for lstm_size in lstm_sizes)\n```", "```py\nmulti_cell_lstm = tf.nn.rnn_cell.MultiRNNCell(cell_list)\n```", "```py\ninitial_state = self.multi_cell_lstm.zero_state(batch_size, tf.float32)\n# Convert to variables so that the state can be stored between batches\nstate_variables = tf.python.util.nest.pack_sequence_as(\n    self.initial_state,\n    (tf.Variable(var, trainable=False) \n     for var in tf.python.util.nest.flatten(initial_state)))\n```", "```py\nlstm_output, final_state = tf.nn.dynamic_rnn(\n    cell=multi_cell_lstm, inputs=one_hot_inputs,    \n    initial_state=state_variable)\n```", "```py\nstore_states = (\n    state_variable.assign(new_state)\n    for (state_variable, new_state) in zip(\n        tf.python.util.nest.flatten(self.state_variables),\n        tf.python.util.nest.flatten(final_state)))\nwith tf.control_dependencies(store_states):\n    lstm_output = tf.identity(lstm_output)\n```", "```py\noutput_flat = tf.reshape(lstm_output, (-1, lstm_sizes(-1)))\n```", "```py\n# Define output layer\nlogit_weights = tf.Variable(\n    tf.truncated_normal((lstm_sizes(-1), number_of_characters), stddev=0.01))\nlogit_bias = tf.Variable(tf.zeros((number_of_characters)))\n# Apply last layer transformation\nlogits_flat = tf.matmul(output_flat, self.logit_weights) + self.logit_bias\nprobabilities_flat = tf.nn.softmax(logits_flat)\n# Reshape to original batch and sequence length\nprobabilities = tf.reshape(\n    probabilities_flat, (batch_size, -1, number_of_characters))\n```", "```py\n# Flatten the targets to be compatible with the flattened logits\ntargets_flat = tf.reshape(targets, (-1, ))\n# Get the loss over all outputs\nloss = tf.nn.sparse_softmax_cross_entropy_with_logits(\n     logits_flat, targets_flat)\n# Reduce the loss to single value over all outputs\nloss = tf.reduce_mean(loss)\n```", "```py\n# Get all variables that need to be optimised\ntrainable_variables = tf.trainable_variables()\n# Compute and clip the gradients\ngradients = tf.gradients(loss, trainable_variables)\ngradients, _ = tf.clip_by_global_norm(gradients, 5)\n# Apply the gradients to those variables with the Adam optimisation algorithm.\noptimizer = tf.train.AdamOptimizer(learning_rate=2e-3)\ntrain_op = optimizer.apply_gradients(zip(gradients, trainable_variables))\n```", "```py\nwith tf.Session() as session:\n    session.run(tf.initialize_all_variables())\n    for i in range(minibatch_iterations):\n        input_batch, target_batch = next(data_feeder)\n        loss, _ = sess.run(\n            (loss, train_op),\n            feed_dict={ inputs: input_batch,targets: target_batch})\n    # Reset initial state every 100 minibatches\n        if i % 100 == 0 and i != 0:\n            for state in tf.python.util.nest.flatten(\n                    state_variables):\n                session.run(state.initializer)\n```", "```py\n# Initialize state with priming string\nfor character in prime_string:\n    character_idx = label_map(character)\n    # Get output distribution of next character\n    output_distribution = session.run(\n        probabilities, \n        feed_dict={inputs: np.asarray(((character_idx)))})\n# Start sampling for sample_length steps\nfor _ in range(sample_length):\n    # Sample next character according to output distribution\n    sample_label = np.random.choice(\n        labels, size=(1), p=output_distribution(0, 0))\n    output_sample += sample_label\n    # Get output distribution of next character\n    output_distribution = session.run(\n       probabilities,\n       feed_dict={inputs: np.asarray((label_map(character))))\n```"]