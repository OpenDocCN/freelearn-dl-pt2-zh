- en: Preface
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Artificial intelligence** (**AI**) is here and has become a powerful force
    that is fueling modern applications that are used on a daily basis. Much like
    the discovery/invention of fire, the wheel, oil, electricity, and electronics,
    AI is reshaping our world in ways that we could only fantasize about. AI has been
    historically a niche computer science subject, offered by a handful of labs. But
    because of the explosion of excellent theory, an increase in computing power,
    and the availability of data, the field started growing exponentially in the 2000s
    and has shown no sign of slowing down anytime soon.'
  prefs: []
  type: TYPE_NORMAL
- en: AI has proven again and again that given the right algorithm and enough amount
    of data, it can learn a task by itself with limited human intervention and produce
    results that rival human judgement and sometimes even surpass them. Whether you
    are a rookie learning the ropes or a veteran driving a large organization, there
    is every reason to understand how AI works. **Neural networks** (**NNs**) are
    some of the most flexible types of AI algorithms that have been adapted to a vast
    range of applications, including structured data, text, and vision domains.
  prefs: []
  type: TYPE_NORMAL
- en: This book starts with the basics of NNs and covers over 40 applications of computer
    vision using **PyTorch**. By mastering these applications, you will be well-equipped
    to build NNs for a variety of use cases in various domains, such as automotive,
    security, back-offices of finance, healthcare, and beyond. The skills acquired
    will empower you to not only implement state-of-the-art solutions but also innovate
    and develop new applications that address more real-world challenges.
  prefs: []
  type: TYPE_NORMAL
- en: Ultimately, this book serves as a bridge between academic learning and practical
    application, enabling you to move forward with confidence and make significant
    contributions throughout your professional career.
  prefs: []
  type: TYPE_NORMAL
- en: Who this book is for
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This book is for newcomers to PyTorch and intermediate-level machine learning
    practitioners who are looking to become well-versed in CV techniques using deep
    learning and PyTorch. Those who are just getting started with NNs will also find
    this book useful. Basic knowledge of the Python programming language and machine
    learning is all you need to get started with this book.
  prefs: []
  type: TYPE_NORMAL
- en: What this book covers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Chapter 1*, *Artificial Neural Network Fundamentals*, gives you the complete
    details of how an NN works. You will start by learning the key terminology associated
    with NNs. Next, you will understand the working details of the building blocks
    and build an NN from scratch on a toy dataset. By the end of this chapter, you
    will be confident about how an NN works.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Chapter 2*, *PyTorch Fundamentals*, introduces you to working with PyTorch.
    You will learn about the ways of creating and manipulating tensor objects before
    learning about the different ways of building a neural network model using PyTorch.
    You will still work with a toy dataset so that you understand the specifics of
    working with PyTorch.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Chapter 3*, *Building a Deep Neural Network with PyTorch*, combines all that
    has been covered in the previous chapters to understand the impact of various
    NN hyperparameters on model accuracy. By the end of this chapter, you will be
    confident about working with NNs on a realistic dataset.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Chapter 4*, *Introducing Convolutional Neural Networks*, details the challenges
    of using a vanilla neural network and you will be exposed to the reason why convolutional
    neural networks (CNNs) overcome the various limitations of traditional neural
    networks. You will dive deep into the working details of CNN and understand the
    various components in it. Next, you will learn the best practices of working with
    images. In this chapter, you will start working with real-world images and learn
    the intricacies of how CNNs help in image classification.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Chapter 5*, *Transfer Learning for Image Classification*, exposes you to solving
    image classification problems in real-world. You will learn about multiple transfer
    learning architectures and also understand how they help significantly improve
    image classification accuracy. Next, you will leverage transfer learning to implement
    the use cases of facial keypoint detection and age and gender estimation.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Chapter 6*, *Practical Aspects of Image Classification*, provides insight
    into the practical aspects to take care of while building and deploying image
    classification models. You will practically see the advantages of leveraging data
    augmentation and batch normalization on real-world data. Further, you will learn
    about how class activation maps help to explain the reason why the CNN model predicted
    a certain outcome. By the end of this chapter, you will be able to confidently
    tackle the majority of image classification problems and leverage the models discussed
    in the previous three chapters on your custom dataset.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Chapter 7*, *Basics of Object Detection,* lays the foundation for object detection
    where you will learn about the various techniques that are used to build an object
    detection model. Next, you will learn about region proposal-based object-detection
    techniques through a use case where you will implement a model to locate trucks
    and buses in an image.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Chapter 8*, *Advanced Object Detection*, exposes you to the limitations of
    region-proposal-based architectures. You will then learn about the working details
    of more advanced architectures like YOLO and SSD that address the issues of region
    proposal-based architectures. You will implement all the architectures on the
    same dataset (trucks versus buses detection) so that you can contrast how each
    architecture works.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Chapter 9*, *Image Segmentation*, builds upon the learnings in previous chapters
    and will help you build models that pinpoint the location of the objects of various
    classes as well as instances of objects in an image. You will implement the use
    cases on images of a road and also on images of a common household. By the end
    of this chapter, you will be able to confidently tackle any image classification
    and object detection/segmentation problem, and solve it by building a model using
    PyTorch.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Chapter 10*, *Applications of Object Detection and Segmentation*, sums up
    what we’ve learned in all the previous chapters and moves on to implementing object
    detection and segmentation in a few lines of code and implementing models to perform
    human crowd counting and image colorization. Next, you will learn about 3D object
    detection on a real-world dataset. Finally, you will learn about performing action
    recognition on a video.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Chapter 11*, *Autoencoders and Image Manipulation*, lays the foundation for
    modifying an image. You will start by learning about various autoencoders that
    help in compressing an image and also generating novel images. Next, you will
    learn about adversarial attacks that fool a model before implementing neural style
    transfer. Finally, you will implement an autoencoder to generate deep fake images.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Chapter 12*, *Image Generation Using GANs*, starts by giving you a deep dive
    into how GANs work. Next, you will implement fake facial image generation and
    generate images of interest using GANs.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Chapter 13*, *Advanced GANs to Manipulate Images*, takes image manipulation
    to the next level. You will implement GANs to convert objects from one class to
    another, generate images from sketches, and manipulate custom images so that we
    can generate an image in a specific style. By the end of this chapter, you will
    be able to confidently perform image manipulation using a combination of autoencoders
    and GANs.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Chapter 14*, *Combining Computer Vision and Reinforcement Learning*, starts
    by exposing you to the terminology of reinforcement learning (RL) and also the
    way to assign value to a state. You will appreciate how RL and NNs can be combined
    as you learn about Deep Q-Learning. Using this knowledge, you will implement an
    agent to play the game of Pong and also an agent to implement a self-driving car.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Chapter 15*, *Combining Computer Vision and NLP Techniques*, gives you the
    working details of transformers, using which you will implement applications like
    image classification, handwriting recognition, key-value extraction in passport
    images, and finally, visual question answering on images. In this process, you
    will learn a variety of ways of customizing/leveraging transformer architecture.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Chapter 16*, *Foundation Models in Computer Vision,* starts by strengthening
    your understanding of combining image and text using CLIP model. Next, you will
    discuss the Segment Anything Model (SAM), which helps with a variety of tasks
    – segmentation, recognition, and tracking without any training. Finally, you will
    understand the working details of diffusion models before you learn the importance
    of prompt engineering and the impact of bigger pre-trained models like SDXL.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Chapter 17*, *Applications of Stable Diffusion,* extends what you learned
    in the previous chapters by walking you through how a variety of Stable Diffusion
    applications (image in-painting, ControlNet, DepthNet, SDXL Turbo, and text-to-video)
    are trained and then walking you through leveraging different models to perform
    different tasks.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Chapter 18*, *Moving a Model to Production*, describes the best practices
    for moving a model to production. You will first learn about deploying a model
    on a local server before moving it to the AWS public cloud. Next, you will learn
    about the impact of half-precision on latency, and finally, you will learn about
    leveraging vector stores (for instance, FAISS) and identifying data drift once
    a model is moved to production.'
  prefs: []
  type: TYPE_NORMAL
- en: As the field evolves, we will periodically add valuable supplements to the GitHub
    repository. Do check the `supplementary_sections` folder within each chapter’s
    directory for new and useful content.
  prefs: []
  type: TYPE_NORMAL
- en: To get the most out of this book
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '| **Software/hardware covered in the book** | **OS requirements** |'
  prefs: []
  type: TYPE_TB
- en: '| Minimum 128 GB storageMinimum 8 GB RAMIntel i5 processor or betterNVIDIA
    8+ GB graphics card – GTX1070 or betterMinimum 50 Mbps internet speed | Windows,
    Linux, and macOS |'
  prefs: []
  type: TYPE_TB
- en: '| Python 3.6 and above | Windows, Linux, and macOS |'
  prefs: []
  type: TYPE_TB
- en: '| PyTorch 2.1 | Windows, Linux, and macOS |'
  prefs: []
  type: TYPE_TB
- en: '| Google Colab (can run in any browser) | Windows, Linux, and macOS |'
  prefs: []
  type: TYPE_TB
- en: Do note that almost all the code in the book can be run using Google Colab by
    clicking the **Open Colab** button in each of the notebooks for the chapters on
    GitHub.
  prefs: []
  type: TYPE_NORMAL
- en: If you are using the digital version of this book, we advise you to type the
    code yourself or access the code via the GitHub repository (link available in
    the next section). Doing so will help you avoid any potential errors related to
    the copying and pasting of code.
  prefs: []
  type: TYPE_NORMAL
- en: Download the example code files
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The code bundle for the book is hosted on GitHub at [https://github.com/PacktPublishing/Modern-Computer-Vision-with-PyTorch-2E](https://github.com/PacktPublishing/Modern-Computer-Vision-with-PyTorch-2E).
    We also have other code bundles from our rich catalog of books and videos available
    at [https://github.com/PacktPublishing/](https://github.com/PacktPublishing/).
    Check them out!
  prefs: []
  type: TYPE_NORMAL
- en: Download the color images
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We also provide a PDF file that has color images of the screenshots/diagrams
    used in this book. You can download it here: [https://packt.link/gbp/9781803231334](https://packt.link/gbp/9781803231334).'
  prefs: []
  type: TYPE_NORMAL
- en: Conventions used
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are a number of text conventions used throughout this book.
  prefs: []
  type: TYPE_NORMAL
- en: '`CodeInText`: Indicates code words in the text, database table names, folder
    names, filenames, file extensions, pathnames, dummy URLs, user input, and Twitter
    handles. Here is an example: “We are creating an object of the `FMNISTDataset`
    class named `val`, in addition to the `train` object that we saw earlier.”'
  prefs: []
  type: TYPE_NORMAL
- en: 'A block of code is set as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'When we wish to draw your attention to a particular part of a code block, the
    relevant lines or items are set in bold:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Any command-line input or output is written as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '**Bold**: Indicates a new term, an important word, or words that you see onscreen.
    For example, words in menus or dialog boxes appear in the text like this. Here
    is an example: “We will apply gradient descent (after a feedforward pass) using
    one **batch** at a time until we exhaust all data points within **one epoch of
    training**.”'
  prefs: []
  type: TYPE_NORMAL
- en: Warnings or important notes appear like this.
  prefs: []
  type: TYPE_NORMAL
- en: Tips and tricks appear like this.
  prefs: []
  type: TYPE_NORMAL
- en: Get in touch
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Feedback from our readers is always welcome.
  prefs: []
  type: TYPE_NORMAL
- en: '**General feedback**: Email `feedback@packtpub.com`, and mention the book’s
    title in the subject of your message. If you have questions about any aspect of
    this book, please email us at `questions@packtpub.com`.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Errata**: Although we have taken every care to ensure the accuracy of our
    content, mistakes do happen. If you have found a mistake in this book we would
    be grateful if you would report this to us. Please visit, [http://www.packtpub.com/submit-errata](http://www.packtpub.com/submit-errata),
    selecting your book, clicking on the Errata Submission Form link, and entering
    the details.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Piracy**: If you come across any illegal copies of our works in any form
    on the Internet, we would be grateful if you would provide us with the location
    address or website name. Please contact us at `copyright@packtpub.com` with a
    link to the material.'
  prefs: []
  type: TYPE_NORMAL
- en: '**If you are interested in becoming an author**: If there is a topic that you
    have expertise in and you are interested in either writing or contributing to
    a book, please visit [http://authors.packtpub.com](http://authors.packtpub.com).'
  prefs: []
  type: TYPE_NORMAL
- en: Share your thoughts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once you’ve read *Modern Computer Vision with PyTorch, Second Edition*, we’d
    love to hear your thoughts! Please [click here to go straight to the Amazon review](https://packt.link/r/1803231335)
    page for this book and share your feedback.
  prefs: []
  type: TYPE_NORMAL
- en: Your review is important to us and the tech community and will help us make
    sure we’re delivering excellent quality content.
  prefs: []
  type: TYPE_NORMAL
- en: Download a free PDF copy of this book
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Thanks for purchasing this book!
  prefs: []
  type: TYPE_NORMAL
- en: Do you like to read on the go but are unable to carry your print books everywhere?
  prefs: []
  type: TYPE_NORMAL
- en: Is your eBook purchase not compatible with the device of your choice?
  prefs: []
  type: TYPE_NORMAL
- en: Don’t worry, now with every Packt book you get a DRM-free PDF version of that
    book at no cost.
  prefs: []
  type: TYPE_NORMAL
- en: Read anywhere, any place, on any device. Search, copy, and paste code from your
    favorite technical books directly into your application.
  prefs: []
  type: TYPE_NORMAL
- en: The perks don’t stop there, you can get exclusive access to discounts, newsletters,
    and great free content in your inbox daily.
  prefs: []
  type: TYPE_NORMAL
- en: 'Follow these simple steps to get the benefits:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Scan the QR code or visit the link below:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B18457_Free_PDF_QR.png)'
  prefs: []
  type: TYPE_IMG
- en: '[https://packt.link/free-ebook/9781803231334](https://packt.link/free-ebook/9781803231334)'
  prefs: []
  type: TYPE_NORMAL
- en: Submit your proof of purchase.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: That’s it! We’ll send your free PDF and other benefits to your email directly.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
