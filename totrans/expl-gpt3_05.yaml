- en: '*Chapter 3*: Working with the OpenAI Playground'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第3章*：使用 OpenAI Playground'
- en: In the last chapter, we briefly introduced the Playground. Chances are, you'll
    be spending a lot of time in the Playground because it's a great tool, both for
    learning and for rapidly prototyping and testing prompts and settings. So, in
    this chapter, we're going to take a closer look at the Playground with an emphasis
    on the Playground settings. We'll also look at other OpenAI developer tools and
    resources that you'll want to be aware of.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们简要介绍了 Playground。很可能您将花费大量时间在 Playground 中，因为它是一个非常好的工具，既用于学习也用于快速原型设计和测试提示和设置。因此，在本章中，我们将更深入地了解
    Playground，重点放在 Playground 设置上。我们还将介绍其他您需要了解的 OpenAI 开发者工具和资源。
- en: 'The topics we will be covering in this chapter are as follows:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涉及的主题如下：
- en: Exploring the OpenAI developer console
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索 OpenAI 开发者控制台
- en: Diving deeper into the Playground
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更深入地探索 Playground
- en: Working with presets
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用预设设置
- en: Technical requirements
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: This chapter requires you to have access to the **OpenAI API**. You can request
    access by visiting [https://openapi.com](https://openapi.com).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 本章需要您可以访问**OpenAI API**。您可以通过访问 [https://openapi.com](https://openapi.com) 来请求访问权限。
- en: Exploring the OpenAI developer console
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索 OpenAI 开发者控制台
- en: The Playground is part of the OpenAI developer console. The developer console
    is a private web-based portal that provides developer resources and tools – the
    Playground being one of them. To access the developer console, you'll need a valid
    OpenAI developer account. While this chapter will largely focus on the Playground
    and, more specifically, the Playground settings, it's worth taking a minute to
    review some of the other resources available in the OpenAI developer console,
    starting with the developer documentation.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: Playground 是 OpenAI 开发者控制台的一部分。开发者控制台是一个提供开发者资源和工具的私人网站门户，其中 Playground 是其中之一。要访问开发者控制台，您需要有效的
    OpenAI 开发者帐户。虽然本章主要关注 Playground，特别是 Playground 设置，但值得花一分钟查看 OpenAI 开发者控制台中的其他资源，从开发者文档开始。
- en: Developer documentation
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 开发者文档
- en: When you're working with new technologies, good documentation is very often
    not available. Fortunately, that's not the case with GPT-3\. The OpenAI documentation
    is extremely well done. It's complete, easy to follow, and provides a number of
    very useful examples. We looked at one of those examples – a classification prompt
    example – in [*Chapter 1*](B16854_01_ePub_AM.xhtml#_idTextAnchor016), *Introducing
    GPT 3 and the OpenAI API*. But let's take a look at another great example from
    the documentation, the Factual responses example.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 当您使用新技术时，很多时候好的文档并不容易找到。幸运的是，GPT-3 并不符合这种情况。OpenAI 的文档做得非常出色。内容完整，易于理解，并提供了许多非常有用的示例。我们在[*第1章*](B16854_01_ePub_AM.xhtml#_idTextAnchor016)，*介绍
    GPT 3 和 OpenAI API* 中查看了其中一个示例 - 分类提示示例。但让我们再看看文档中的另一个很好的例子，即事实性回答示例。
- en: Factual responses example
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 事实性回答示例
- en: The following prompt example is from the OpenAI developer documentation. It
    is located at [https://beta.openai.com/docs/introduction/prompt-design-101](https://beta.openai.com/docs/introduction/prompt-design-101).
    It provides an example QA prompt that shows the model that a question mark should
    be returned for questions it likely doesn't have the correct answer to. This directs
    the model to *not* make up an answer, which it would likely do by default. This
    is an important example because although GPT-3 responses are almost always grammatically
    correct, they are very often not factual. So, even though they might sound good,
    they could be completely fabricated.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个提示示例来自 OpenAI 开发者文档。它位于 [https://beta.openai.com/docs/introduction/prompt-design-101](https://beta.openai.com/docs/introduction/prompt-design-101)。它提供了一个示例问答提示，向模型显示对于它可能没有正确答案的问题应返回一个问号。这告诉模型
    *不要* 来编造答案，这通常情况下它可能会默认这样做。这是一个重要的示例，因为尽管 GPT-3 的回答几乎总是语法正确的，但它们往往不是事实性的。因此，即使它们听起来不错，它们可能是完全虚构的。
- en: 'The key thing to note in the following prompt is that the examples provided
    show GPT-3 how to deal with questions that don''t have a factual answer, or that
    GPT-3 doesn''t know how to answer. There are also some settings used to help ensure
    a factual response, but we''ll talk about the settings a bit later in this chapter:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个提示中需要注意的关键点是所提供的示例向 GPT-3 展示如何处理没有事实答案的问题，或者 GPT-3 不知道如何回答的问题。也有一些设置用于帮助确保事实回答，但我们将在本章稍后讨论这些设置：
- en: '[PRE0]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The point of highlighting the OpenAI documentation, as you can hopefully see,
    is because it can be an extremely valuable resource. But it's just one of many.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 突出OpenAI文档的要点，正如您所期望的那样，是因为它可能是一个极其有价值的资源。但这只是众多资源中的一种。
- en: Developer resources
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 开发者资源
- en: 'The documentation is just one of the available resources in the developer portal.
    Other resources are available, including the following:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 文档仅是开发者门户中的可用资源之一。还有其他资源可用，包括以下：
- en: '**FAQs**'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**常见问题解答**'
- en: '**Pricing Details**'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**定价详细信息**'
- en: '**Video Tutorials**'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**视频教程**'
- en: '**Community Examples**'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**社区示例**'
- en: '**Interactive Tools**'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**交互工具**'
- en: '**Guidelines and Legal Documents**'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**指南和法律文件**'
- en: '**Logo Assets**'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**标志资产**'
- en: As you become familiar with GPT-3 and the OpenAI API, you'll want to spend time
    reviewing all of the available developer resources. We will dive deeper into a
    few of them, but they are all valuable and worth reviewing.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 随着您熟悉GPT-3和OpenAI API，您需要花时间审阅所有可用的开发者资源。我们将更深入地研究其中一些，但它们都是有价值且值得审阅的。
- en: Accounts and organizations
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 账户与组织
- en: Another important area to point out in the developer console is the account
    profile section. This is where you edit your developer account and organization
    details.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 开发者控制台中另一个重要的区域是账户资料部分。这是您编辑开发者账户和组织详细信息的地方。
- en: Developer accounts are used to authenticate and identify individual developers.
    By default, when a developer account is created, an organization named Personal
    is also created. An organization is used for billing purposes and grouping users,
    meaning that users can create, or be associated with, multiple organizations that
    each get billed separately.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 开发者账户用于认证和识别个别开发者。默认情况下，创建开发者帐户时，还会创建一个名为Personal的组织。组织用于计费目的和用户分组，这意味着用户可以创建或关联多个组织，每个组织都将单独计费。
- en: Each organization has a title (name) that you can specify and an organization
    ID that is automatically generated. The organization ID is a unique identifier
    used to associate usage with the proper organization for billing purposes. So,
    when you're logged in to the developer console, any usage will be associated with
    the organization you're working under. We'll discuss the organization ID again
    in [*Chapter 4*](B16854_04_ePub_AM.xhtml#_idTextAnchor074), *Working with the
    OpenAI API*, where we'll look at associating API calls with a specific organization,
    but you can also associate usage with an organization in the developer console.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 每个组织都有一个您可以指定的标题（名称），以及一个自动生成的组织ID。组织ID是用于将使用情况与正确组织关联以进行计费目的的唯一标识符。因此，当您登录到开发者控制台时，任何使用情况将与您所在的组织相关联。我们将在[*第4章*](B16854_04_ePub_AM.xhtml#_idTextAnchor074)中再次讨论组织ID，*使用OpenAI
    API*，在那里我们将探讨如何将API调用与特定组织关联，但您也可以在开发者控制台中将使用情况与组织关联。
- en: 'The following screenshot shows how to see the organizations your account is
    associated with and how to switch between organizations in the developer console:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 以下屏幕截图显示了如何查看您的账户关联的组织以及如何在开发者控制台中切换不同组织之间：
- en: '![Figure 3.1 – Switching between organizations'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.1 – 在不同组织之间切换'
- en: '](img/B16854_03_001.jpg)'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16854_03_001.jpg)'
- en: Figure 3.1 – Switching between organizations
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.1 – 在不同组织之间切换
- en: 'As mentioned, organizations are used for billing purposes, and an organization
    named **Personal** is created along with your user account. You can change the
    organization title to something other than **Personal** if you prefer. The following
    screenshot shows where you can change the name of your personal organization:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，组织用于计费目的，与您的用户账户一起创建了一个名为**Personal**的组织。如果您喜欢，您可以将组织名称更改为除**Personal**之外的其他内容。下面的屏幕截图显示了您可以更改个人组织名称的位置：
- en: '![Figure 3.2 – Personal organization'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.2 – 个人组织'
- en: '](img/B16854_03_002.jpg)'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16854_03_002.jpg)'
- en: Figure 3.2 – Personal organization
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.2 – 个人组织
- en: Of course, you're the owner of your personal organization and this is the organization
    you would set up billing for if you're using the API for your own individual use.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，您是个人组织的所有者，如果您是为自己的个人使用而使用API，那么这就是您为其设置计费的组织。
- en: Pricing and billing
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定价和计费
- en: Before we get into pricing, it's important to note that pricing could change
    at any time, so you'll want to visit https://beta.openai.com/pricing for the most
    current pricing details. With that disclaimer out of the way, let's continue.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在进入定价细节之前，有一点很重要，那就是定价可能随时变动，因此您需要访问https://beta.openai.com/pricing 获取最新的定价详情。有了这个免责声明，让我们继续。
- en: For starters, the OpenAI API is priced on a per-usage basis. So, you only pay
    for the resources that you use. There are no setup fees or recurring charges.
    The usage fees are based on tokens used. The cost per token depends on the engine
    you're using. We discussed tokens and introduced the available engines in [*Chapter
    1*](B16854_01_ePub_AM.xhtml#_idTextAnchor016), *Introducing GPT-3 and the OpenAI
    API.*
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，OpenAI API 的定价是按使用量计费的。因此，你只需支付你使用的资源。没有设置费用或重复费用。使用费用是基于使用的令牌。每个令牌的成本取决于你使用的引擎。我们在[*第1章*](B16854_01_ePub_AM.xhtml#_idTextAnchor016)，*介绍
    GPT-3 和 OpenAI API* 中讨论了令牌并介绍了可用的引擎。
- en: Davinci is the largest model and the most capable engine, hence, it is also
    the most expensive engine to use. At the other end of the price spectrum is ada.
    This is the smallest model, which limits its capabilities. However, ada is the
    most efficient engine, and therefore the least expensive one to use.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: DaVinci 是最大的模型和最能干的引擎，因此，它也是使用成本最高的引擎。在价格范围的另一端是 Ada。这是最小的模型，限制了它的功能。不过，Ada
    是最高效的引擎，因此使用成本最低。
- en: 'The following screenshot shows the pricing per engine at the time this book
    was published. Again, the pricing could change at any time, so be sure to verify
    the current pricing as it may very well have changed:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了本书出版时每个引擎的定价。再次说明，价格随时可能发生变化，所以请务必核实当前价格，因为它很可能已经变化了：
- en: '![Figure 3.3 – Pricing'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.3 – 定价'
- en: '](img/B16854_03_003.jpg)'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16854_03_003.jpg)'
- en: Figure 3.3 – Pricing
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.3 – 定价
- en: Pay-per-usage pricing is nice because if you're not doing anything, it's not
    costing you anything. That said, it can also be a bit scary not knowing what your
    bill might be. Thankfully, however, you can set a hard limit or a soft limit to
    manage your spending. This is done in your billing settings. The hard limit prevents
    the API from using more tokens once the limit is met. Of course, this will render
    the API unusable, which could be a problem in production apps. So, there is also
    the option of setting a soft limit. This will send an email alert when usage limits
    are hit.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 按使用量计费很好，因为如果你什么都没做，也就不会花费什么。话虽如此，不知道账单会是多少也可能有点可怕。不过，幸运的是，你可以设置一个硬限制或软限制来管理你的支出。这可以在你的计费设置中完成。硬限制防止
    API 在达到限制后继续使用更多的令牌。当然，这会使 API 无法使用，这在生产应用中可能会成为问题。因此，还有设置软限制的选项。这会在达到使用限制时发送电子邮件提醒。
- en: Usage reporting
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用报告
- en: 'In addition to setting hard or soft limits to manage your costs, you also have
    access to usage reporting. You''ll find usage reporting in the organization settings
    under the **Usage** menu. The following screenshot shows an example usage report:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 除了设置硬限制或软限制来管理你的成本外，你还可以访问使用报告。在**使用**菜单下的组织设置中找到使用报告。以下截图显示了一个示例使用报告：
- en: '![Figure 3.4 – Usage reporting'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.4 – 使用报告'
- en: '](img/B16854_03_004.jpg)'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16854_03_004.jpg)'
- en: Figure 3.4 – Usage reporting
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.4 – 使用报告
- en: The main chart in usage reporting defaults to show the total tokens used per
    day for the current month. Each bar also shows the tokens used for prompts and
    completions. From this chart, you can also view usage by a dollar amount and display
    the cumulative total rather than daily totals. In addition, below the main chart,
    you can view the total usage along with detailed usage per day by engine.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 使用报告中的主要图表默认显示本月每天使用的总令牌数。每个柱状图还显示了用于提示和完成的令牌数。通过这个图表，你还可以查看按金额使用情况，并显示累计总数而不是每日总数。此外，在主要图表下方，你可以查看总使用量以及每天按引擎的详细使用情况。
- en: Member management
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 成员管理
- en: 'As mentioned, when you get a developer account, an organization is set up for
    your personal use. But you might also want to have an organization for a team
    of users. To do that, you can request an organization account for multiple users
    by sending an email to `support@openai.com`. When a new organization is created,
    you''ll be able to invite other users to the organization. This is done under
    the **Members** menu within the organization. The following screenshot shows the
    member management page for an organization. From this page, you can invite new
    members, remove members, or change member permissions:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，当你获得开发者帐户时，会为你的个人使用设置一个组织。但你可能还想为一个用户团队拥有一个组织。为此，你可以通过发送电子邮件到 `support@openai.com`
    请求一个多用户组织帐户。当新组织创建时，你将能够邀请其他用户加入组织。这可以在组织的**成员**菜单下完成。以下截图显示了一个组织的成员管理页面。从这个页面，你可以邀请新成员，删除成员或更改成员权限：
- en: '![Figure 3.5 – Member management'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.5 – 成员管理'
- en: '](img/B16854_03_005.jpg)'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16854_03_005.jpg)'
- en: Figure 3.5 – Member management
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.5 – 成员管理
- en: Outside of the Playground, that should cover the essential things you'll need
    to know about the developer console. So, let's get back to the Playground and
    take a closer look.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在游乐场之外，这应该涵盖了你需要了解开发者控制台的基本内容。所以，让我们回到游乐场，仔细看一看。
- en: Diving deeper into the Playground
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深入了解游乐场
- en: At this point, you should understand the basics of using the Playground. But
    we're going to cover the Playground in more depth now and discuss all of the available
    options and settings. [*Chapter 2*](B16854_02_ePub_AM.xhtml#_idTextAnchor038),
    *GPT 3 Applications and Use Cases*, provided a quick overview of the available
    settings, but let's take a closer look at each of them.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，你应该已经了解了如何使用游乐场的基础知识。但是我们现在要更深入地讨论游乐场，并讨论所有可用的选项和设置。[*第二章*](B16854_02_ePub_AM.xhtml#_idTextAnchor038)，*GPT
    3 应用和用例*，提供了可用设置的快速概述，但让我们更仔细地看看每一个。
- en: 'The following screenshot shows the settings in the Playground. They are located
    just to the right of the large text input box:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了游乐场中的设置。它们位于大型文本输入框的右侧：
- en: '![Figure 3.6 – Playground settings'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.6 – 游乐场设置'
- en: '](img/B16854_03_006.jpg)'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16854_03_006.jpg)'
- en: Figure 3.6 – Playground settings
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.6 – 游乐场设置
- en: The first setting is the **Engine** setting, so we'll start there.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个设置是**引擎**设置，所以我们从那里开始。
- en: Choosing the right engine
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 选择正确的引擎
- en: Generally, we refer to the OpenAI language model as just GPT-3\. But, as you'll
    recall from [*Chapter 1*](B16854_01_ePub_AM.xhtml#_idTextAnchor016), *Introducing
    GPT-3 and the OpenAI API*, there are multiple models/engines.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，我们只把 OpenAI 语言模型称为 GPT-3。但是，正如你在[*第一章*](B16854_01_ePub_AM.xhtml#_idTextAnchor016)中所记得的那样，*介绍
    GPT-3 和 OpenAI API*，有多个模型/引擎。
- en: When you first open the Playground, the davinci engine is selected by default.
    This will usually be the engine you'll want to start testing prompts with. The
    reason you'll want to start with davinci is that it's the largest model and therefore
    the most capable engine. The davinci engine can do anything that any of the other
    engines can do. However, other engines might be able to perform the specific tasks
    faster or more cost-effectively. So, an alternative approach could be to start
    with the least expensive engine first and then test the next most expensive engine
    when a less expensive engine is unable to complete the task.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 当你第一次打开游乐场时，默认选择达芬奇引擎。这通常是你想要开始测试提示的引擎。你会想要从达芬奇开始的原因是它是最大的模型，因此是最有能力的引擎。达芬奇引擎可以做任何其他引擎可以做的事情。然而，其他引擎可能能够更快地或更具成本效益地执行特定任务。因此，另一种方法可能是先从最便宜的引擎开始，然后在较便宜的引擎无法完成任务时测试下一个价格更昂贵的引擎。
- en: So, start with davinci. Then, when you're getting the results you want from
    davinci, test your prompt with the other engines to see whether you're also able
    to get acceptable results. Or start with ada, the least expensive engine, and
    then progress up if you fail to obtain acceptable results. Let's look at an example
    using a simple classification task.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，从达芬奇开始。然后，当你从达芬奇获得想要的结果时，请尝试将你的提示与其他引擎一起测试，看看你是否也能获得可接受的结果。或者从ada开始，这是最便宜的引擎，如果无法获得可接受的结果，则逐步升级。让我们看一个使用简单分类任务的示例。
- en: 'The following is a prompt classifying items as a tool, food, clothing, or something
    else:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是将项目分类为工具、食物、服装或其他的提示：
- en: '[PRE1]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The following screenshot shows the results when davinci is used as the engine.
    Note that the new items added to the list (**Shirt**, **Hammer**, **Apple**, and
    **Airplane**) are all categorized correctly:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了使用达芬奇引擎时的结果。请注意，新增加的项目（**衬衫**、**锤子**、**苹果**和**飞机**）都被正确分类：
- en: '![Figure 3.7 – Classification example with the davinci engine'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.7 – 使用达芬奇引擎的分类示例'
- en: '](img/B16854_03_007.jpg)'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16854_03_007.jpg)'
- en: Figure 3.7 – Classification example with the davinci engine
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.7 – 使用达芬奇引擎的分类示例
- en: 'Now, let''s look at the results when the engine is changed from davinci to
    ada. You''ll notice in the following screenshot that the new items added to the
    list (**Socks**, **Pliers**, **Hamburger**, and **House**) are also correctly
    classified by ada:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看当引擎从达芬奇更改为ada时的结果。您会注意到在以下截图中，新增加的项目（**袜子**、**钳子**、**汉堡**和**房子**）也被ada正确分类：
- en: '![Figure 3.8 – Classification example with the ada engine'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.8 – 使用ada引擎的分类示例'
- en: '](img/B16854_03_008.jpg)'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16854_03_008.jpg)'
- en: Figure 3.8 – Classification example with the ada engine
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.8 – 使用ada引擎的分类示例
- en: So, as you can see from the previous example, there will be tasks that don't
    require davinci to get acceptable results. If that's the case, choosing another
    engine will reduce your usage costs and often also improve response times. Of
    course, if costs and performance aren't a concern, you can always stick with davinci.
    But again, depending on the task, davinci might not be the only option.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，正如你从上面的例子可以看到的那样，有些任务并不需要davinci来获得可接受的结果。如果是这种情况，选择另一个引擎将减少你的使用成本，通常还会提高响应时间。当然，如果成本和性能不是问题，你也可以始终坚持使用davinci。但再次提醒，根据任务的不同，davinci可能并不是唯一的选择。
- en: 'The following list provides an idea of what each engine does generally well.
    These aren''t hard and fast rules, merely a guideline. So, you''ll always want
    to test to determine the best fit based on the results:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 以下列表提供了每个引擎一般擅长的内容。这并不是硬性规定，只是一个指导方针。因此，你总是需要测试以确定基于结果的最佳选择：
- en: '**Davinci**: Complex intent, cause and effect, summarization for age.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Davinci**: 复杂意图，因果关系，针对年龄的摘要。'
- en: '**Curie**: Language translation, complex classification, text sentiment, summarization.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**居里**: 语言翻译，复杂分类，文本情感，摘要。'
- en: '**Babbage**: Moderate classification, semantic search classification.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**巴贝奇**: 适度分类，语义搜索分类。'
- en: '**Ada**: Text parsing, simple classification, address correction, keywords.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**艾达**: 文本解析，简单分类，地址校正，关键词。'
- en: Response length
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 响应长度
- en: The response length setting is fairly self-explanatory. It controls the length
    of the completion that will be generated. The main thing to keep in mind with
    the response length is that the value relates to a number of tokens to be returned.
    Recall from [*Chapter 1*](B16854_01_ePub_AM.xhtml#_idTextAnchor016), *Introducing
    GPT-3 and the OpenAI API*, that tokens can represent words or parts of words.
    So, don't mistake the response length for a word count or character count.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 响应长度设置相当容易理解。它控制将生成的完成的长度。要记住的主要事情是，该值涉及要返回的令牌数量。请记住来自[*第1章*](B16854_01_ePub_AM.xhtml#_idTextAnchor016)，*介绍GPT-3和OpenAI
    API*，令牌可以代表单词或单词的部分。因此，不要把响应长度误认为是单词数或字符数。
- en: The other thing to keep in mind is that you get billed for tokens used – including
    tokens that are used for completions, meaning the larger your response length,
    the more tokens you'll use. So, if you're trying to optimize costs, set the response
    length as short as possible for the given task. For example, if the task is to
    provide sentiment analysis on a block of text, the response length only needs
    to be long enough to display the sentiment result.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 另一点需要记住的是，你会被计费所使用的令牌 – 包括用于完成的令牌，这意味着你的响应长度越长，你将使用的令牌就越多。因此，如果你尝试优化成本，针对给定任务设置响应长度尽可能短。例如，如果任务是对一段文本进行情感分析，那么响应长度只需要足够长以显示情感结果即可。
- en: Temperature and Top P
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 温度和Top P
- en: The next two settings are **Temperature** and **Top P**. These are two of the
    most important settings, but they can also be the most confusing ones to understand.
    At a high level, they both influence the randomness or diversity of the response
    that is generated. But knowing how and when to use one or the other can be tricky.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的两个设置是**温度**和**Top P**。这两个设置是最重要的设置之一，但也可能是最难理解的。在更高的层面上，它们都会影响所生成响应的随机性或多样性。但了解何时使用其中一个而不是另一个可能会很棘手。
- en: To make sense of the temperature and Top P settings, it's helpful to know that
    machine learning systems could process the same input differently. This means
    that the output can vary even when the input provided hasn't changed. This is
    because machine learning systems such as GPT-3 use heuristics (educated guesses)
    rather than concrete logic to generate results. So, instead of trying to find
    the perfect solution, machine learning systems try to identify the best possible
    options based on the data it was trained with.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解温度和Top P设置的意义，了解机器学习系统可以以不同方式处理相同的输入很有帮助。这意味着即使输入没有改变，输出也可能会有所不同。这是因为像GPT-3这样的机器学习系统使用启发式（教育猜测）而不是具体的逻辑来生成结果。因此，机器学习系统不是试图找到完美的解决方案，而是根据其训练过的数据来确定最佳选择。
- en: In the case of GPT-3, the dataset it was trained on is extremely large and diverse.
    Therefore, most inputs (prompts) will result in a variety of possible completions.
    Again, this could be a benefit or a challenge depending on the task. For example,
    if you're using GPT-3 to generate ideas for a book title, you want a lot of different
    options to choose from. However, if you want GPT-3 to accurately answer history
    questions, you want responses that are consistent and factual. This is where the
    temperature and Top P settings come in. The temperature and Top P settings can
    be used to help control the variability and number of options that are used to
    generate a completion.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 对于GPT-3来说，它训练所使用的数据集非常庞大且多样化。因此，大多数输入（提示）会导致多种可能的完成结果。这可能是一种好处，也可能是一种挑战，具体取决于任务。例如，如果你使用GPT-3为一本书的标题生成想法，你想要很多不同的选择。然而，如果你希望GPT-3能准确回答历史问题，你希望得到一致和事实准确的回应。这就是温度和Top
    P设置发挥作用的地方。温度和Top P设置可以帮助控制用于生成完成结果的变化性和选项数量。
- en: Temperature
  id: totrans-95
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 温度
- en: The temperature setting influences how deterministic the model will be when
    generating a result. So, the temperature provides some control over how likely
    the results are to vary. A lower value will direct the model to be more deterministic
    (less variable), while a higher value will cause the model to be less deterministic,
    or more variable. The range can be between 0 and 1\. To see the effects of the
    temperature setting let's look at some examples.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 温度设置影响模型在生成结果时的确定性程度。因此，温度提供了一定程度上控制结果变化的能力。较低的数值会让模型更趋向确定性（较少变量），而较高的数值会使模型更趋向不确定性或者更多变。其范围可以在0到1之间。为了看到温度设置的效果，让我们来看一些例子。
- en: 'We''ll start with an example that uses the default Playground temperature of
    **0.7**. In this example, we''ll look at the default stochastic (random) nature
    of most completions. We''ll start with a prompt that contains the words **Once
    upon a time** and nothing else, like the prompt shown in the following screenshot:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从一个使用默认Playground温度为**0.7**的示例开始。在这个示例中，我们将研究大多数完成结果的默认随机性。我们将从一个包含词组**很久以前**但没有其他内容的提示开始，就像下面的截图所示的提示：
- en: '![Figure 3.9 – Temperature example 1'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.9 – 温度示例1'
- en: '](img/B16854_03_009.jpg)'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16854_03_009.jpg)'
- en: Figure 3.9 – Temperature example 1
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.9 – 温度示例1
- en: As you might guess, there are a lot of possible completions for this prompt.
    So, when we submit the prompt three times, we get the following three completions,
    and each one is different.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所猜测的，这个提示可能有很多可能的完成结果。因此，当我们重复提交这个提示三次时，我们得到以下三个完成结果，每一个都不同。
- en: '*Once upon a time*, a little princess was born.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*很久以前*，有一个小公主诞生了。'
- en: '*Once upon a time*, there were three little pigs.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*很久以前*，有三只小猪。'
- en: '*Once upon a time*, there was a girl who saw a boy run past her house every
    day.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*很久以前*，有一个女孩，她每天都看到一个男孩从她家门前跑过。'
- en: This example is a simple one and the results aren't surprising. But understanding
    why the same prompt resulted in three different completions is important. So,
    let's talk a bit more about our first example.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子很简单，结果并不令人惊讶。但理解为什么同样的提示会导致三种不同的完成结果很重要。所以，让我们更详细地谈谈我们的第一个例子。
- en: There are actually three reasons why we got different responses in our previous
    example. The first reason is that the underlying model can come up with a lot
    of different ways to complete this prompt. That's because there are a lot of stories
    that start with *Once upon a time* and the data used to train the model contains
    plenty of examples of those stories.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，我们之所以在前一个例子中得到不同的回应，有三个原因。第一个原因是底层模型可以想出很多不同的方式来完成这个提示。这是因为有很多以*很久以前*开头的故事，而训练模型使用的数据包含了这些故事的许多例子。
- en: The second reason is that the default temperature setting is relatively high
    (0.7 out of 1). So, the model is being directed to take more risks and to be more
    random when generating the response.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个原因是默认的温度设置相对较高（0.7占1）。因此，在生成回应时，模型被指示要冒更多的风险，并更加随机。
- en: The last reason has to do with the Top P setting, but we'll talk about that
    a little later.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一个原因与Top P设置有关，但我们稍后再谈。
- en: 'Now, let''s consider the same example again, but this time we''ll change the
    temperature setting to 0\. Again, we''ll submit the prompt three times, but this
    time, the results are as follows – the same each time:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们再次考虑同样的示例，但这次我们将把温度设置为0\. 再次，我们提交相同的提示三次，但这次结果如下 – 每次都相同：
- en: '*Once upon a time*, there was a little girl who was very sad.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从前，有一个非常难过的小女孩。
- en: '*Once upon a time*, there was a little girl who was very sad.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从前，有一个非常难过的小女孩。
- en: '*Once upon a time*, there was a little girl who was very sad.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从前，有一个非常难过的小女孩。
- en: So, what's happening? The lower temperature value is telling GPT-3 to be less
    variable in how it processes the prompt, so the completion is staying consistent.
    Because we're using zero for the temperature (the lowest value), the result will
    likely always be the same. However, you can use a value between zero and one (for
    example 0.2) to gain more control over the randomness of the result. However,
    changing the temperature won't always affect the completion because again, the
    completion also depends on the examples in the data the model was trained on.
    To illustrate this, let's look at another example.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，到底发生了什么？较低的温度值告诉GPT-3在处理提示时要更少地变化，因此完成结果保持一致。因为我们使用零作为温度值（最低值），结果很可能始终相同。但是，您可以使用介于零和一之间的值（例如0.2）来更好地控制结果的随机性。然而，改变温度并不总是会影响完成，因为完成结果还取决于模型训练时的数据示例。为了说明这一点，让我们看看另一个例子。
- en: 'For this example, we''ll use a prompt that just includes the words **A robot
    may not injure** with the default temperature setting of **0.7**, as we have in
    the following screenshot:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个示例，我们将使用默认温度设置为**0.7**的提示，只包括单词**A robot may not injure**，如下图所示：
- en: '![ Figure 3.10 – Temperature example 2'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '![ 图3.10 – 温度示例2'
- en: '](img/B16854_03_010.jpg)'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16854_03_010.jpg)'
- en: Figure 3.10 – Temperature example 2
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.10 – 温度示例2
- en: 'This time, when we submit the prompt in the previous screenshot three times,
    we get the following results – the same completion each time:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 这一次，当我们多次提交前一个屏幕截图中的提示时，我们得到了以下结果-每次都是相同的完成结果：
- en: '*A robot may not injure* a human being or, through inaction, allow a human
    being to come to harm.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*A robot may not injure* a human being or, through inaction, allow a human
    being to come to harm.'
- en: '*A robot may not injure* a human being or, through inaction, allow a human
    being to come to harm.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*A robot may not injure* a human being or, through inaction, allow a human
    being to come to harm.'
- en: '*A robot may not injure* a human being or, through inaction, allow a human
    being to come to harm.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*A robot may not injure* a human being or, through inaction, allow a human
    being to come to harm.'
- en: So, now you might be wondering what's going on. Shouldn't the completion have
    varied because of the higher temperature setting? Again, the completion also depends
    on the data the model was trained on. In this case, the reason the completion
    isn't changing (and probably wouldn't irrespective of what the temperature setting
    was) is because the five words (or five tokens), *A robot may not injure*, are
    most often seen as part of **Isaac Asimov**'s **laws of robotics**. So, because
    of the training, regardless of the temperature, the best possible result is almost
    always the same. So, keep in mind that the temperature setting will only have
    a noticeable effect when there are a variety of different ways in which a prompt
    could be completed.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，现在你可能想知道发生了什么。由于设定了较高的温度，完成结果难道不应该变化吗？同样，完成结果还取决于模型训练时的数据。在这种情况下，完成结果没有变化的原因（并且可能不管温度设置如何都不会变化）是因为五个单词（或五个标记）*A
    robot may not injure*通常被看作是**艾萨克·阿西莫夫**的**机器人三大定律**的一部分。因此，由于模型的训练，无论温度如何，最佳可能的结果几乎总是相同的。因此，请记住，只有在有各种不同的方式可以完成提示时，温度设置才会产生显着效果。
- en: Top P
  id: totrans-123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Top P
- en: While the temperature controls the randomness of results generated based on
    the model, the Top P setting controls how many of those results (or tokens) are
    considered for completion. The value can be between 0-1, where a higher value
    considers a higher number of tokens. For example, a value of 1 would consider
    all of the likely options, whereas a value of 0.5 would limit the options by half.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然温度控制了基于模型生成的结果的随机性，但Top P设置控制了考虑用于完成的结果（或标记）的数量。该值可介于0-1之间，其中较高的值考虑较多的标记。例如，值为1将考虑所有可能的选项，而值为0.5将将选项减少一半。
- en: 'Like temperature, Top P can be used to increase or limit the seeming randomness
    of a completion. However, unlike the temperature, it''s influencing the randomness
    by limiting the scope of the possible results that should be considered. To illustrate
    the point, imagine that 100 potential token options could be selected as the next
    token in a completion. A Top P value of 0.1 could be used to limit the options
    to 10, thereby reducing the number of tokens that could be selected. But this
    is still dependent on the number of possible token options derived from the model.
    So, if there were only 10 potential options, a 0.5 Top P setting would limit that
    to five options – reducing the variability. Furthermore, a Top P value of 0 will
    always reduce the options to the top token, meaning that even if there are a lot
    of possible options and the temperature setting was 1 (which will generate the
    most options), if the Top P setting is 0, only the best option will be selected,
    which will have the same effect as setting the temperature to 0 – you''ll most
    likely always get the same result. To illustrate this, let''s look at our **Once
    upon a time** prompt again. This time, we''ll set the temperature to 1 and the
    Top P value to 0, as we have in the following screenshot:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于温度，Top P 可以被用来增加或限制完成的看似随机性。然而，与温度不同的是，它通过限制应该考虑的可能结果的范围来影响随机性。为了说明这一点，想象一下，在完成中可能有100个潜在的标记选项可以被选为下一个标记。Top
    P 值为0.1 可以用于将选项限制为10个，从而减少可以选择的标记数量。但这仍然取决于从模型派生出的可能的标记选项的数量。因此，如果只有10个潜在选项，0.5
    的 Top P 设置将把它限制为5个选项 – 减少了变异性。此外，Top P 值为0将总是将选项减少到顶部标记，这意味着即使可能有很多的选项并且温度设置为1（这会生成最多的选项），如果
    Top P 设置为0，只有最佳选项会被选择，这将与将温度设置为0的效果相同 – 你很可能总是得到相同的结果。为了说明这一点，让我们再次看一下我们的**从前，有一段时间**的提示。这一次，我们将温度设置为1，Top
    P 值设置为0，就像我们在下面的截图中所做的那样：
- en: '![Figure 3.11 – Top P example'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.11 – Top P 示例'
- en: '](img/B16854_03_011.jpg)'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16854_03_011.jpg)'
- en: Figure 3.11 – Top P example
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.11 – Top P 示例
- en: 'If we submit the prompt with the settings in the previous screenshot three
    times, we get the following results (the same completion), even though the temperature
    is set to 1\. This is because Top P is limiting the options:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们使用前面截图中的设置三次提交提示，我们会得到以下结果（相同的完成），即使温度设置为1。这是因为 Top P 限制了选项：
- en: '*Once upon a time*, there was a little girl who was very sad.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '* 从前，*有一个很伤心的小女孩。'
- en: '*Once upon a time*, there was a little girl who was very sad.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '* 从前，*有一个很伤心的小女孩。'
- en: '*Once upon a time*, there was a little girl who was very sad.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '* 从前，*有一个很伤心的小女孩。'
- en: So, although the temperature and Top P settings both influence the seeming randomness
    of a completion, they are interrelated, and each can affect the other. This is
    what makes them a bit confusing if you're not clear on how they work. Because
    of this, you're usually best off using each setting separately. So, if you want
    to influence the randomness with the temperature, make the Top P setting 1 and
    only vary the temperature. If you want to influence the randomness with the Top
    P value, set the temperature to 1.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，尽管温度和 Top P 设置都影响完成的看似随机性，它们是相互关联的，每一个都可以影响另一个。如果你不清楚它们是如何工作的，这就使它们有些令人困惑。因此，你最好单独使用每个设置。所以，如果你想用温度影响随机性，就把
    Top P 设置为1，只改变温度。如果你想用 Top P 值影响随机性，就把温度设置为1。
- en: Frequency and presence penalty
  id: totrans-134
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 频率和存在惩罚
- en: The **Frequency** and **Presence Penalty** settings can also be a bit confusing
    because they can seem similar to temperature or Top P in that they are settings
    to control variability. However, rather than considering the model, the frequency
    and presence penalty settings consider the prompt text and previous completion
    text to influence the tokens that are selected for the next completion. So, these
    two settings can provide some control over what new text is generated based on
    existing text.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '**频率**和**存在惩罚**设置也可能会有些令人迷惑，因为它们似乎类似于温度或者 Top P，它们都是用来控制变化性的设置。然而，与考虑模型不同，频率和存在惩罚设置考虑的是提示文本和之前的完成文本，以影响选择下一段文本的标记。因此，这两个设置可以在现有文本的基础上，对生成的新文本进行一些控制。'
- en: The frequency and presence penalty settings can be useful for preventing the
    same completion text from being repeated across multiple requests. The two settings
    are very similar to one another, with the only difference being that the frequency
    penalty is applied if the text exists multiple times, whereas the presence penalty
    is applied if the text exists at all. Let's take a look at another example.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 频率和存在惩罚设置对于防止同一完成文本在多个请求中重复使用非常有用。这两个设置非常相似，唯一的区别在于，如果文本存在多次，则应用频率惩罚，而如果文本存在，则应用存在惩罚。让我们看另一个例子。
- en: 'The following screenshot shows the results of the **Once upon a time example**
    with a temperature setting of 1, a Top P setting of 0, and no frequency or presence
    penalty. The submit button was clicked 5 times and each completion generated a
    new sentence. While no sentences are repeated verbatim, there are a number of
    repeated token sequences – notice that each completion sentence begins with the
    words **She was sad because she had no**:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了**从前有座山**示例的结果，温度设置为1，Top P设置为0，并且没有频率或存在惩罚。单击提交按钮5次，每个完成生成一个新句子。虽然没有重复的句子，但有许多重复的标记序列—请注意每个完成句子都以**她很伤心因为她没有**开头：
- en: '![Figure 3.12 – Frequency and presence example 1'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.12 – 频率和存在示例1'
- en: '](img/B16854_03_012.jpg)'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16854_03_012.jpg)'
- en: Figure 3.12 – Frequency and presence example 1
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.12 – 频率和存在示例1
- en: For the previous example, we could have added the presence or frequency penalty
    to limit the likelihood that each completion would be so similar.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 对于上一个示例，我们可以添加存在或频率惩罚以限制每个完成项如此相似的可能性。
- en: 'The next screenshot shows the results after adding a presence penalty and clicking
    **Submit** five times (like we did for the last example). This time, you can see
    that the completion sentences are not as similar:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 下一张截图显示了在添加存在惩罚并单击**提交**五次后的结果（就像我们在上一个示例中所做的那样）。这次，您可以看到完成句子不太相似：
- en: '![Figure 3.13 – Frequency and presence example 2'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.13 – 频率和存在示例2'
- en: '](img/B16854_03_013.jpg)'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16854_03_013.jpg)'
- en: Figure 3.13 – Frequency and presence example 2
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.13 – 频率和存在示例2
- en: The frequency penalty penalizes new tokens based on how often the token already
    exists in the text. The presence penalty, on the other hand, penalizes tokens
    if they exist in the text at all. In both cases, the value can be between 0 and
    1, and a higher value increases the penalty, thereby reducing the likelihood of
    duplications.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 频率惩罚根据标记在文本中已经存在的频率来惩罚新标记。另一方面，存在惩罚如果标记在文本中存在则对其进行惩罚。在这两种情况下，值可以介于0和1之间，较高的值增加惩罚，从而减少重复的可能性。
- en: Best of
  id: totrans-147
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 最佳选择
- en: The **best of** setting will cause the model to generate multiple completions
    on the server side and return the best of *x* completions (where *x* is the *best
    of* value). This can be used to help get the best quality results without having
    to make multiple requests to the API. However, the thing to consider when using
    *best of* is that you get charged for the tokens used for each of the completions
    generated. For example, if your response length was 50 and you set the best of
    value to 10, the response would consume 500 tokens. So, if you're providing a
    best of value, make sure to set the response length value as low as possible to
    minimize the number of tokens used. You can also use the stop sequence setting
    to help limit unnecessary tokens being used.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '**最佳选择**设置将使模型在服务器端生成多个完成项，并返回*x*个完成项中的最佳选择（其中*x*是最佳选择的值）。这可以帮助获得最高质量的结果，而无需向API发出多个请求。但是，在使用*最佳选择*时需要考虑的事项是，您将为生成的每个完成项使用的标记收费。例如，如果您的响应长度为50，并且将最佳选择值设置为10，则响应将消耗500个标记。因此，如果您提供了最佳选择值，请务必将响应长度值设置得尽可能低，以最小化使用的标记数。您还可以使用停止序列设置来帮助限制不必要的标记使用。'
- en: Stop sequence
  id: totrans-149
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 停止序列
- en: A **stop sequence** is a text sequence that will cause a completion to end when
    the sequence is encountered in the completion. You can provide up to four sequences.
    For example, if you wanted to limit a completion to text that came before a period
    followed by a carriage return, you would provide a period and a return as stop
    sequences.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 一个**停止序列**是一个文本序列，当在完成中遇到该序列时，将导致完成结束。您最多可以提供四个序列。例如，如果您想要将完成限制在句号后和回车之前的文本上，您可以提供句号和回车作为停止序列。
- en: 'In the Playground, you enter a stop sequence by typing the stop sequences followed
    by the tab button to complete your entry. The following screenshot shows a carriage
    return as a stop sequence. For this example, the return button was entered followed
    by the tab key:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在Playground中，您通过键入停止序列，然后按下tab键来完成您的输入。以下屏幕截图显示了换行符作为停止序列。在这个例子中，输入了回车键，然后是tab键：
- en: '![Figure 3.14 – Stop sequence'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.14 – 停止序列'
- en: '](img/B16854_03_014.jpg)'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16854_03_014.jpg)'
- en: Figure 3.14 – Stop sequence
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.14 – 停止序列
- en: Let's move on to the next section!
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续下一节！
- en: Inject Start Text and Inject Restart Text
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 注入起始文本和注入重新开始文本
- en: 'The **Inject Start Text** and **Inject Restart Text** inputs insert text at
    the beginning or end of a completion, respectively. These settings can be used
    to help ensure that the desired pattern is continued as part of a completion.
    Often, these settings are most helpful when they are used in conjunction with
    a stop sequence. Let''s take a look at an example. For example, let''s start with
    the following prompt:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '**注入起始文本**和**注入重新开始文本**输入分别在完成的开头或结尾插入文本。这些设置可以用来确保所需的模式作为完成的一部分继续。通常，在与停止序列一起使用时，这些设置最有帮助。让我们看一个例子。例如，让我们从以下提示开始：'
- en: '[PRE2]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'With the default Playground settings, the completions might look something
    like the completion in the following screenshot:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 使用默认的Playground设置，完成可能看起来像以下截图中的完成：
- en: '![Figure 3.15 – Default settings'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.15 – 默认设置'
- en: '](img/B16854_03_015.jpg)'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16854_03_015.jpg)'
- en: Figure 3.15 – Default settings
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.15 – 默认设置
- en: 'In the previous screenshot, you can see that the engine did a good job figuring
    out that this was a conversation and continued with a dialog. However, suppose
    you don''t want the completion to generate the human side of the conversation
    and you want to use the label `AI:` rather than `Assistant:`? If that was the
    case, you could use a stop sequence to end the completion before the human side
    of the conversation is generated. Then you could use an inject restart text value
    to prompt for the human input. Finally, the inject start text value could be set
    to a carriage return followed by `AI:` to begin the assistant''s response. The
    following screenshot shows what a completion might look like with those settings:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一张屏幕截图中，您可以看到引擎很好地判断出这是一段对话，并继续了对话。但是，假设您不希望完成生成对话的人类一侧，并且您希望使用标签`AI:`而不是`助手:`？如果是这样的话，您可以使用停止序列在生成对话的人类一侧之前结束完成。然后，您可以使用注入重新开始文本值提示人类输入。最后，注入起始文本值可以设置为换行符，然后是`AI:`来开始助手的回应。以下截屏显示了使用这些设置完成可能会看起来如何：
- en: '![Figure 3.16 – Using Stop Sequences, Inject Start Text, and Inject Restart
    Text together'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.16 – 使用停止序列、注入起始文本和一起注入重新开始文本'
- en: '](img/B16854_03_016.jpg)'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16854_03_016.jpg)'
- en: Figure 3.16 – Using Stop Sequences, Inject Start Text, and Inject Restart Text
    together
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.16 – 使用停止序列、注入起始文本和一起注入重新开始文本
- en: With the settings used in the previous screenshot, you can see that the completion
    ends before the human side of the conversation is generated. Then, the restart
    text, **Human:**, is appended to the completion, prompting human input.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 通过上一张截图中使用的设置，您可以看到完成在生成对话的人类一侧之前结束。然后，重新开始的文本**Human:**被附加到完成中，提示人类输入。
- en: Show Probabilities
  id: totrans-168
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 显示概率
- en: 'In the playground, the **Show Probabilities** option toggles on text highlighting,
    showing how likely a token was to be generated. This lets you examine the options
    that could have been used in the completion, which can be helpful when you''re
    trying to troubleshoot a completion. It can also help see alternative options
    that you might want to use. To use show probabilities, you toggle it on by selecting
    one of the following settings:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 在游乐场中，**显示概率**选项切换文本突出显示，显示一个标记生成的可能性有多大。当您尝试排查完成时，这可以让您检查可能使用的选项。它还可以帮助您查看您可能想使用的替代选项。要使用显示概率，您可以通过选择以下设置之一切换它打开：
- en: '**Most Likely**'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**最可能**'
- en: '**Least Likely**'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**最不可能**'
- en: '**Full Spectrum**'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**全光谱**'
- en: 'The **most likely** value will show the most likely tokens to be selected,
    **least likely** will show the least likely tokens that could have been selected,
    and **full spectrum** will show the range of tokens that could have been selected.
    The following screenshot shows an example. In this example, the input prompt was
    just **Hi,**. The settings used were the defaults, except the response length,
    which was set to 1, and the show probabilities were set to **Most Likely**. You
    can see that the completion was the word **my**, but some other likely options
    were considered:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '**最有可能**的值将显示最有可能被选中的标记，**最不可能**的将显示可能被选中的最不可能的标记，而**完整光谱**将显示可能被选中的标记范围。以下截图显示了一个示例。在这个示例中，输入提示只是**Hi，**。使用的设置是默认设置，除了响应长度设置为1，以及显示概率设置为**最有可能**。你可以看到完成的词是**my**，但也考虑了一些其他可能的选项：'
- en: '![Figure 3.17 – Show Probabilities – most likely tokens'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.17 – 显示概率 – 最有可能的标记'
- en: '](img/B16854_03_017.jpg)'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16854_03_017.jpg)'
- en: Figure 3.17 – Show Probabilities – most likely tokens
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.17 – 显示概率 – 最有可能的标记
- en: The settings provide a lot of control over how a completion is generated, but
    selecting the right setting can take a bit of trial and error. Thankfully, the
    Playground includes presets to help you understand how to best select the right
    combination of settings for a given task.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 设置提供了对完成生成的控制，但是选择正确的设置可能需要一些试错。幸运的是，Playground 包含了预设，可以帮助你了解如何为给定的任务选择正确的设置组合。
- en: Working with presets
  id: totrans-178
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用预设
- en: In [*Chapter 2*](B16854_02_ePub_AM.xhtml#_idTextAnchor038), *GPT 3 Applications
    and Use Cases*, we briefly introduced presets in the Playground. Specifically,
    we looked at the English to French preset, but that's just one of many. Presets
    are like templates that provide an example prompt, along with the Playground settings.
    They are a great starting point for creating new prompts or as a tool for getting
    familiar with prompt design and setting usage.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第二章*](B16854_02_ePub_AM.xhtml#_idTextAnchor038)，*GPT 3 应用与用例*，我们简要介绍了 Playground
    中的预设。具体来说，我们看了英语到法语的预设，但那只是众多预设中的一个。预设就像提供了示例提示以及 Playground 设置的模板。它们是创建新提示的绝佳起点，或者作为熟悉提示设计和设置使用的工具。
- en: 'There are a number of presets available, including the following:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '有许多可用的预设，包括以下内容:'
- en: '**Chat**'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**聊天**'
- en: '**Q&A**'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**问与答**'
- en: '**Grammatical Standard English**'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**语法标准英语**'
- en: '**Summarize for a 2nd grader**'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**给二年级生总结**'
- en: '**Text to command**'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文本转命令**'
- en: '**English to French**'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**英语到法语**'
- en: '**Parse unstructured data**'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**解析非结构化数据**'
- en: '**Classification**'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分类**'
- en: 'You''ll find a drop-down list of the presets in the Playground just above the
    large input box. The following screenshot shows the location:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '在 Playground 的大输入框上方会找到预设的下拉列表。以下截图显示了位置:'
- en: '![Figure 3.18 – Presets'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.18 – 预设'
- en: '](img/B16854_03_018.jpg)'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16854_03_018.jpg)'
- en: Figure 3.18 – Presets
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.18 – 预设
- en: We won't review all of the presets, but let's take a look at a few to see how
    settings are used to help get the best possible completion from a prompt. The
    first one we'll review is the Grammatical Standard English preset.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不会审查所有的预设，但让我们看看其中一些，以了解如何使用设置来帮助从提示中获得最佳完成。我们将首先审查的是语法标准英语预设。
- en: Grammatical Standard English
  id: totrans-194
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 语法标准英语
- en: 'The **Grammatical Standard English** preset demonstrates a use case where non-standard
    US English text is transformed into standard US English text. The following is
    the preset''s prompt text:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '**语法标准英语**预设展示了一个用例，其中非标准的美式英语文本被转换为标准的美式英语文本。以下是该预设的提示文本:'
- en: '[PRE3]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: As mentioned, presets also include settings. So, after selecting the Grammatical
    Standard English preset, you'll notice that some of the default Playground settings
    have changed.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，预设还包括设置。因此，在选择语法标准英语预设后，你会注意到一些默认的 Playground 设置已经发生了变化。
- en: 'The default Playground settings are as follows:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: '默认的 Playground 设置如下:'
- en: '*Engine*: davinci'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*引擎*: davinci'
- en: '*Response* *Length*: 64'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*响应* *长度*: 64'
- en: '*Temperature*: 0.7'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*温度*: 0.7'
- en: '*Top* *P*: 1'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*顶部* *P*: 1'
- en: '*Frequency Penalty*: 0'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*频率惩罚*: 0'
- en: '*Presence Penalty*: 0'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*存在惩罚*: 0'
- en: '*Best Of*: 1'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*最佳选项*: 1'
- en: '*Stop Sequences*: empty'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*停止序列*: 空'
- en: '*Inject Start Text*: empty'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*注入开始文本*: 空'
- en: '*Inject Restart Text*: empty'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*注入重新开始文本*: 空'
- en: '*Show Probabilities*: Off'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*显示概率*: 关闭'
- en: 'But when you select a preset, some of the defaults will be updated. For the
    Grammatical Standard English preset, the following settings are used:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '但是当你选择一个预设时，一些默认设置会更新。对于语法标准英语预设，使用的设置如下:'
- en: '*Response Length*: 120'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*响应长度*: 120'
- en: '*Temperature*: 1'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*温度*：1'
- en: '*Top P*: 0.7'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Top P*：0.7'
- en: '*Stop Sequences*:'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*停止序列*：'
- en: '*Inject Start Text*: Standard American English:'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*注入开始文本*：标准美国英语：'
- en: '*Inject Restart Text*: Non-standard English:'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*注入重启文本*：非标准英语：'
- en: Note that the temperature is set to 1 and Top P is used to limit the results
    considered to 70% of the possible options. Also notice that the stop sequence
    is used along with the inject start text and inject restart text to keep the completion
    short while continuing the prompt pattern for the next phrase to standardize.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，温度设置为1，Top P用于限制考虑的结果达到了可能选项的70％。 还请注意，停止序列与注入开始文本和注入重新启动文本一起使用，以使完成保持简短，同时继续下一个短语的提示模式以使其标准化。
- en: Text to command
  id: totrans-218
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 文本转命令
- en: 'The **Text to command** preset provides an example that shows how an English
    command could be converted to a machine command to send a message. The following
    is the prompt text for the Text to command preset:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '**文本转命令**预设提供了一个示例，展示了如何将英语命令转换为机器命令以发送消息。 以下是“文本转命令”预设的提示文本：'
- en: '[PRE4]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The updated settings are as follows:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 更新的设置如下：
- en: '*Response Length*: 100'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*响应长度*：100'
- en: '*Temperature*: 0.5'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*温度*：0.5'
- en: '*Top P*: 1'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Top P*：1'
- en: '*Frequency Penalty*: 0.2'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*频率惩罚*：0.2'
- en: '*Stop Sequences*:'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*停止序列*：'
- en: '*Inject Start Text*: A:'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*注入开始文本*：A：'
- en: '*Inject Restart Text*: Q:'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*注入重启文本*：Q：'
- en: In this preset, notice that the temperature is set to 0.5 and a slight frequency
    penalty of 0.2 is used.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个预设中，注意到温度设置为0.5，并且使用了轻微的频率惩罚0.2。
- en: Parse unstructured data
  id: totrans-230
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解析非结构化数据
- en: 'The **Parse unstructured data** preset provides an example that shows how to
    extract values from unstructured text. The prompt provides a block of text, instructions,
    and a couple of examples:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: '**解析非结构化数据**预设提供了一个示例，展示了如何从非结构化文本中提取值。 提示提供了一段文本，说明和一些示例：'
- en: '[PRE5]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The settings used for the Parse unstructured data preset are as follows:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 解析非结构化数据预设中使用的设置如下：
- en: '*Response Length*: 100'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*响应长度*：100'
- en: '*Temperature*: 0'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*温度*：0'
- en: '*Top P*: 1'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Top P*：1'
- en: '*Stop Sequences*:'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*停止序列*：'
- en: The settings worth noting in this preset are the temperature and Top P settings.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个预设中，值得注意的设置是温度和Top P设置。
- en: Summary
  id: totrans-239
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we provided an overview of the tools and resources available
    in the OpenAI developer console. We also took a closer look at the Playground
    and reviewed the Playground settings in more depth. We learned how to select the
    right engine, and also learned about using temperature and Top P, as well as frequency
    and presence penalties, along with other options. Finally, we looked at some of
    the presets to further understand how the settings can be used.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们简要介绍了OpenAI开发者控制台中可用的工具和资源。 我们还更深入地了解了“游乐场“，并深入了解了“游乐场”设置。 我们学会了如何选择合适的引擎，还了解了如何使用温度和Top
    P，以及频率和存在惩罚，以及其他选项。 最后，我们看了一些预设，以进一步了解这些设置如何使用。
- en: In the next chapter, we will move beyond the Playground and start looking at
    using the OpenAI API.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将超越“游乐场”，开始学习如何使用Open AI API。
