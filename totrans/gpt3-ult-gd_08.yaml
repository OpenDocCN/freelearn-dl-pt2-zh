- en: 'Chapter 3: GPT-3 and Programming'
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: 第三章：GPT-3与编程
- en: Almost all of GPT-3’s NLP capabilities are created in the Python programming
    language. But to enable wider accessibility, the API comes with pre-built support
    for all the major programming languages, so users can build GPT-3 powered applications
    using the programming language of their choice.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 几乎所有GPT-3的NLP功能都是使用Python编程语言创建的。但为了实现更广泛的可访问性，该API提供了对所有主要编程语言的预构建支持，因此用户可以选择自己喜欢的编程语言构建基于GPT-3的应用程序。
- en: In this section, we will illustrate how this works by replicating an example
    with different programming languages.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将通过使用不同的编程语言复制一个示例来说明这是如何工作的。
- en: 'Just a heads-up: In each language-specific chapter, we assume you have a basic
    understanding of the programming language being discussed. If you don’t, you can
    safely skip the section.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 提示：在每个特定于语言的章节中，我们假设您对所讨论的编程语言有基本的了解。如果您没有，您可以安全地跳过该部分。
- en: How to use OpenAI API with Python?
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 如何使用Python与OpenAI API？
- en: Python is the most popular language for data science and machine learning tasks.
    Compared to conventional data-science programming languages like R and Stata,
    Python shines because it’s scalable and integrates well with databases. It is
    widely used and has a flourishing community of developers keeping its ecosystem
    up to date. Python is easy to learn and comes with useful data science libraries
    like Numpy and Pandas.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: Python是数据科学和机器学习任务中最流行的语言。与传统的数据科学编程语言如R和Stata相比，Python因其可扩展性和与数据库的良好集成而脱颖而出。它被广泛使用，并且有着发展壮大的开发者社区，使其生态系统保持最新。Python易于学习，并且附带有像Numpy和Pandas这样的有用的数据科学库。
- en: 'You can pair GPT-3 with Python using a library called [Chronology](https://github.com/OthersideAI/chronology)
    that provides a simple, intuitive interface. Chronology can mitigate the monotonous
    work of writing all of your code from scratch every time. Its features include:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用名为[Chronology](https://github.com/OthersideAI/chronology)的库将GPT-3与Python配对，该库提供了一个简单直观的接口。Chronology可以缓解每次都从头开始编写所有代码的单调工作。它的功能包括：
- en: ●        It calls the OpenAI API asynchronously, allowing you to generate multiple
    prompt completions at the same time.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: ●        它异步调用OpenAI API，允许您同时生成多个提示完成。
- en: ●        You can create and modify training prompts easily; for example, modifying
    a training prompt used by a different example is fairly straightforward.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ●        您可以轻松地创建和修改训练提示；例如，修改不同示例使用的训练提示相当简单。
- en: ●        It allows you to chain prompts together by plugging the output of one
    prompt into another.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ●        它允许您通过将一个提示的输出插入到另一个提示中来链接提示。
- en: 'Chronology is hosted on PyPI and supports Python 3.6 and above. To install
    the library, you can run the following command:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: Chronology托管在PyPI上，支持Python 3.6及以上版本。要安装库，您可以运行以下命令：
- en: (base) PS D:\GPT-3 Python> pip install chronological
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: （基础）PS D：\GPT-3 Python> pip install chronological
- en: After installing the Python library via PyPI, let’s look at an example of how
    to prime GPT-3 to summarize a given text document at a second-grade reading level.
    We’ll show you to call the API, send the training prompt as a request, and get
    the summarized completion as an output. We’ve posted the code for you in a [Github
    repository.](https://github.com/Shubhamsaboo/kairos_gpt3/tree/master/Programming_with_GPT-3/GPT-3_Python).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 通过PyPI安装Python库后，让我们看一个示例，说明如何使用GPT-3来以二年级阅读水平总结给定的文本文档。我们会展示如何调用API，将训练提示作为请求发送，以及获取汇总的完成作为输出。我们已经将代码发布在[Github存储库](https://github.com/Shubhamsaboo/kairos_gpt3/tree/master/Programming_with_GPT-3/GPT-3_Python)中。
- en: 'In this example, we will use the following training prompt:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在本示例中，我们将使用以下训练提示：
- en: 'My second-grader asked me what this passage means:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我的二年级学生问我这段话是什么意思：
- en: '"""'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '"""'
- en: Olive oil is a liquid fat obtained from olives (the fruit of Olea europaea;
    family Oleaceae)...
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 橄榄油是从橄榄（欧洲油橄榄的果实；橄榄科）中获取的液态脂肪...
- en: '"""'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '"""'
- en: 'I rephrased it for him, in plain language a second grader can understand:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我用浅显易懂的语言为他重新表述了一遍：
- en: '"""'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '"""'
- en: 'First, import the following dependencies:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，导入以下依赖项：
- en: Importing Dependencies
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 导入依赖项
- en: from chronological import read_prompt, cleaned_completion, main
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: from chronological import read_prompt, cleaned_completion, main
- en: 'Now we can create a function that reads the training prompt and provides the
    completion output. We have made this function asynchronous, which allows us to
    carry out parallel function calls. We will use the following configuration for
    the API parameters:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以创建一个函数，读取训练提示并提供完成的输出。我们将此函数设置为异步的，这样我们就可以进行并行函数调用。我们将使用以下配置进行 API 参数设置：
- en: ●        Maximum tokens=100
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: ●        最大 token 数=100
- en: ●        Execution Engine="Davinci"
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: ●        执行引擎="Davinci"
- en: ●        Temperature=0.5
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: ●        温度=0.5
- en: ●        Top-p=1
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: ●        Top-p=1
- en: ●        Frequency Penalty = 0.2
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: ●        频率惩罚 = 0.2
- en: ●        Stop Sequence = ["\n\n"]
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: ●        停止序列 = ["\n\n"]
- en: Takes in the training prompt and returns the completed response
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 接受训练提示并返回完成的响应
- en: 'async def summarization_example():'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 'async def summarization_example():'
- en: '# Takes in a text file(summarize_for_a_2nd_grader) as the input prompt'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '# 接受一个文本文件（summarize_for_a_2nd_grader）作为输入提示'
- en: prompt_summarize = read_prompt('summarize_for_a_2nd_grader')
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: prompt_summarize = read_prompt('summarize_for_a_2nd_grader')
- en: '# Calling the completion method along with the specific GPT-3 parameters'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '# 调用 completion 方法以及特定的 GPT-3 参数'
- en: completion_summarize = await cleaned_completion(prompt_summarize, max_tokens=100,
    engine="davinci", temperature=0.5, top_p=1, frequency_penalty=0.2, stop=["\n\n"])
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: completion_summarize = await cleaned_completion(prompt_summarize, max_tokens=100,
    engine="davinci", temperature=0.5, top_p=1, frequency_penalty=0.2, stop=["\n\n"])
- en: '# Return the completion response'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '# 返回完成的响应'
- en: return completion_summarize
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 返回完成的摘要
- en: 'Now we can create an asynchronous workflow, invoke that workflow using the
    ‘main’ function provided by the library, and print the output in the console:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以创建一个异步工作流程，使用库提供的 ‘main’ 函数调用该工作流程，并在控制台中打印输出：
- en: Designing the end-to-end async workflow, capable of running multiple prompts
    in parallel
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设计端到端的异步工作流程，能够并行运行多个提示。
- en: 'async def workflow():'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 异步函数工作流程：
- en: '# Making async call to the summarization function'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '# 调用摘要函数进行异步调用'
- en: text_summ_example = await summarization_example()
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: text_summ_example = await summarization_example()
- en: '# Printing the result in console'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '# 在控制台中打印结果'
- en: print('-------------------------')
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: print('-------------------------')
- en: 'print(''Basic Example Response: {0}''.format(text_summ_example))'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 'print(''基本示例响应: {0}''.format(text_summ_example))'
- en: print('-------------------------')
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: print('-------------------------')
- en: invoke Chronology by using the main function to run the async workflow
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用主函数调用 Chronology 来运行异步工作流
- en: main(workflow)
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: main(workflow)
- en: 'Save it as a Python script with the following name ‘text_summarization.py’
    and run it from the terminal to generate the output. You can run the following
    command from your root folder:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 将其保存为名为 ‘text_summarization.py’ 的 Python 脚本，并从终端运行以生成输出。您可以从根目录运行以下命令：
- en: (base) PS D:\GPT-3 Python> python text_summarization.py
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: (base) PS D:\GPT-3 Python> python text_summarization.py
- en: 'Once you execute the script, your console should print  the following summary
    of the prompt:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 执行脚本后，您的控制台应该打印出以下提示的摘要：
- en: '-------------------------'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '-------------------------'
- en: 'Basic Example Response: Olive oil is a liquid fat that comes from olives. Olives
    grow on a tree called an olive tree. The olive tree is the most common tree in
    the Mediterranean. People use the oil to cook with, to put on their salads, and
    as a fuel for lamps.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '基本示例响应: 橄榄油是一种来自橄榄的液态脂肪。橄榄生长在一种叫做橄榄树的树上。橄榄树是地中海最常见的树。人们用这种油来烹饪，放在沙拉上，还用作灯的燃料。'
- en: '-------------------------'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '-------------------------'
- en: If you are not well versed in Python and want to chain different prompts without
    writing code, you can use the [no-code interface](https://chronology-ui.vercel.app/)
    built on top of the [Chronology library](https://github.com/OthersideAI/chronology-ui)
    to create the prompt workflow using drag-and-drop. See our GitHub [repository](https://github.com/Shubhamsaboo/kairos_gpt3/tree/master/Programming_with_GPT-3/GPT-3_Python)
    for more examples of how you can use Python programming to interact with GPT-3.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您不熟悉 Python 并且想要在不编写代码的情况下链接不同的提示，您可以使用基于 [Chronology library](https://github.com/OthersideAI/chronology-ui)
    构建的 [无代码界面](https://chronology-ui.vercel.app/) 来使用拖放创建提示工作流程。查看我们的 GitHub [仓库](https://github.com/Shubhamsaboo/kairos_gpt3/tree/master/Programming_with_GPT-3/GPT-3_Python)
    获取更多关于如何使用 Python 编程与 GPT-3 交互的示例。
- en: How to use OpenAI API with Go?
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 如何使用 Go 来调用 OpenAI API？
- en: Go is an open-source programming language that incorporates elements from other
    languages to create a powerful, efficient, and user-friendly tool. Many developers
    refer to it as a modern version of C.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: Go 是一个开源的编程语言，融合了其他语言的元素，创建了一个功能强大、高效且用户友好的工具。许多开发人员将其称为 C 的现代版本。
- en: 'Go is the language of preference for building projects that require high security,
    high speed, and high modularity. This makes it an attractive option for many projects
    in the fintech industry. Key features of Go are as follows:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: Go 语言是构建需要高安全性、高速度和高可扩展性的项目的首选语言。这使得它成为金融科技行业许多项目的吸引人选项。Go 语言的主要特点如下：
- en: ●        Ease of use
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: ●        易用性
- en: ●        State-of-the-art productivity
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: ●        现代生产力
- en: ●        High-level efficiency Static typing
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: ●        高级效率的静态类型
- en: ●        Advanced performance for networking
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: ●        网络高级性能
- en: ●        Full use of multi-core power
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: ●        充分利用多核能力
- en: If you are completely new to Go and want to give it a try, you can [follow the
    documentation](https://golang.org/doc/install) to get started.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你完全不懂Go并且想试一试，你可以[查阅文档](https://golang.org/doc/install)开始入门。
- en: Once you are done with the installation and understand the basics of Go programming,
    you can follow these steps to u use the [Go API wrapper for GPT-3](https://github.com/sashabaranov/go-gpt3).
    To learn more about creating Go modules, see [this tutorial](https://golang.org/doc/tutorial/create-module).
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 安装完成并且了解了Go编程的基础知识后，你可以按照以下步骤使用[Go的GPT-3 API包装器](https://github.com/sashabaranov/go-gpt3)。要了解更多有关创建Go模块的信息，请参阅[本教程](https://golang.org/doc/tutorial/create-module)。
- en: 'First, you’ll create a module to track and import code dependencies. Create
    and initialize the “gogpt” module using the following command:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，您将创建一个模块来跟踪和导入代码依赖项。使用以下命令创建并初始化“gogpt”模块：
- en: D:\GPT-3 Go> go mod init gogpt
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: D:\GPT-3 Go> go mod init gogpt
- en: 'After creating the “gogpt” module, let’s point it to [this github repository](http://github.com/sashabaranov/go-gpt3)
    to download the necessary dependencies and packages for working with the API.
    Use the following command:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 创建“gogpt”模块之后，让我们将其指向[此 GitHub 存储库](http://github.com/sashabaranov/go-gpt3)，以下载处理
    API 的必要依赖项和包。使用以下命令：
- en: D:\GPT-3 Go> go get github.com/sashabaranov/go-gpt3
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: D:\GPT-3 Go> go get github.com/sashabaranov/go-gpt3
- en: 'go get: added github.com/sashabaranov/go-gpt3 v0.0.0-20210606183212-2be4a268a894'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: go get：添加了 github.com/sashabaranov/go-gpt3 v0.0.0-20210606183212-2be4a268a894
- en: We’ll use the same text summarization example as in the previous section. (You
    can find all the code at the following [repository](https://github.com/Shubhamsaboo/kairos_gpt3/tree/master/Programming_with_GPT-3/GPT-3_Go).)
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用与上一节相同的文本摘要示例。（你可以在以下[存储库](https://github.com/Shubhamsaboo/kairos_gpt3/tree/master/Programming_with_GPT-3/GPT-3_Go)中找到所有代码。）
- en: 'Let’s import the necessary dependencies and packages for starters:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先导入必要的依赖项和包：
- en: Calling the package main
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 调用 package main
- en: package main
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: package main
- en: Importing Dependencies
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 导入依赖项
- en: import (
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: import (
- en: '"fmt"'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '"fmt"'
- en: '"io/ioutil"'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '"io/ioutil"'
- en: '"context"'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '"context"'
- en: gogpt "github.com/sashabaranov/go-gpt3"
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: gogpt "github.com/sashabaranov/go-gpt3"
- en: )
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: )
- en: Go programming organizes source files into system directories called packages,
    which make it easier to reuse code across Go applications. In the first line of
    the code we call the package "main" and tell the Go compiler that the package
    should compile as an executable program instead of a shared library.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: Go 编程将源文件组织成系统目录，称为包，这使得在 Go 应用程序中跨应用程序重用代码更加容易。在代码的第一行中，我们调用了包“main”，并告诉 Go
    编译器，这个包应该编译为可执行程序，而不是共享库。
- en: 'NOTE: In Go, you create a package as a shared library for reusable code, and
    the "main" package for executable programs. The "main" function within the package
    serves as the entry point for the program.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：在 Go 语言中，你可以创建一个可复用的共享库作为包，创建一个可执行程序的“main”包。包内的“main”函数作为程序的入口点。
- en: 'Now you’ll create a main function that will host the entire logic of reading
    the training prompt and providing the completion output. Use the following configuration
    for the API parameters:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你将创建一个主函数，用于托管读取训练提示和提供完成输出的整个逻辑。使用以下配置设置 API 参数：
- en: ●        Maximum tokens=100
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: ●        最大标记=100
- en: ●        Execution Engine="davinci"
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: ●        执行引擎="davinci"
- en: ●        Temperature=0.5
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: ●        温度=0.5
- en: ●        Top-p=1
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: ●        Top-p=1
- en: ●        Frequency Penalty = 0.2
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: ●        频率惩罚=0.2
- en: ●        Stop Sequence = ["\n\n"]
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: ●        结束序列= ["\n\n"]
- en: func main() {
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: func main() {
- en: c := gogpt.NewClient("OPENAI-API-KEY")
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: c := gogpt.NewClient("OPENAI-API-KEY")
- en: ctx := context.Background()
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: ctx := context.Background()
- en: prompt, err := ioutil.ReadFile("prompts/summarize_for_a_2nd_grader.txt")
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: prompt, err := ioutil.ReadFile("prompts/summarize_for_a_2nd_grader.txt")
- en: req := gogpt.CompletionRequest{
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: req := gogpt.CompletionRequest{
- en: 'MaxTokens: 100,'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 'MaxTokens: 100，'
- en: 'Temperature: 0.5,'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 温度：0.5，
- en: 'TopP: 1.0,'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 'TopP: 1.0,'
- en: 'Stop: []string{"\n\n"},'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 'Stop: []string{"\n\n"},'
- en: 'FrequencyPenalty: 0.2,'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 频率惩罚：0.2，
- en: 'Prompt: string(prompt),'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 提示：string(prompt),
- en: '}'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '}'
- en: resp, err := c.CreateCompletion(ctx, "davinci", req)
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: resp, err := c.CreateCompletion(ctx, "davinci", req)
- en: if err != nil {
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 如果出现错误 {
- en: return
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '}'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '}'
- en: fmt.Println("-------------------------")
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: fmt.Println("-------------------------")
- en: fmt.Println(resp.Choices[0].Text)
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: fmt.Println(resp.Choices[0].Text)
- en: fmt.Println("-------------------------")
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: fmt.Println("-------------------------")
- en: '}'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '}'
- en: 'This code performs the following tasks:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '此代码执行以下任务:'
- en: Sets up a new API client by providing it with the API token and then leaves
    it to run in the background.
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过提供 API 令牌设置新的 API 客户端，然后将其留在后台运行。
- en: Reads the prompt “” in the form of a text file from the prompts folder.
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以文本文件的形式读取提示“”从 prompts 文件夹。
- en: Creates a completion request by providing the training prompt and specifying
    the value API parameters (like temperature, top-p, stop sequence, and so forth).
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过提供训练提示并指定值 API 参数（如温度、顶部-p、停止序列等）创建完成请求。
- en: Calls the create completion function and provides it with the API client, completion
    request, and execution engine.
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 调用 create completion 函数并提供 API 客户端、完成请求和执行引擎。
- en: Generates a response in the form of a completion, which prints towards the end
    in the console.
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成一个以完成形式的响应，最终在控制台朝着结尾打印。
- en: 'You can then save the code file as ‘text_summarization.go’ and run it from
    the terminal to generate the output. Use the following command to run the file
    from your root folder:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '然后，您可以将代码文件保存为''text_summarization.go''并从终端运行它以生成输出。 使用以下命令从您的根文件夹运行文件:'
- en: (base) PS D:\GPT-3 Go> go run text_summarization.go
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: (base) PS D:\GPT-3 Go> go run text_summarization.go
- en: 'Once you execute the file, your console will print the following output:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '一旦执行文件，您的控制台将打印以下输出:'
- en: '-------------------------'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '-------------------------'
- en: Olive oil is a liquid fat that comes from olives. Olives grow on a tree called
    an olive tree. The olive tree is the most common tree in the Mediterranean. People
    use the oil to cook with, to put on their salads, and as a fuel for lamps.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 橄榄油是一种来自橄榄的液态脂肪。 橄榄生长在一种被称为橄榄树的树上。 橄榄树是地中海最常见的树木。 人们用这种油来烹饪、放在沙拉上，还用作灯的燃料。
- en: '-------------------------'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '-------------------------'
- en: For more examples of how you can use Go programming to interact with GPT-3,
    please visit our GitHub [repository](https://github.com/Shubhamsaboo/kairos_gpt3/tree/master/Programming_with_GPT-3/GPT-3_Go).
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解如何使用 Go 编程与 GPT-3 进行交互的更多示例，请访问我们的 GitHub [仓库](https://github.com/Shubhamsaboo/kairos_gpt3/tree/master/Programming_with_GPT-3/GPT-3_Go)。
- en: How to use OpenAI API with Java?
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 如何使用 Java 使用 OpenAI API？
- en: Java is one of the oldest and most popular programming languages for developing
    conventional software systems; it is also a platform that comes with a runtime
    environment. It was developed by Sun Microsystems (now a subsidiary of Oracle)
    in 1995, and as of today, more than 3 billion devices run on it. It is a general-purpose,
    class-based, object-oriented programming language designed to have fewer implementation
    dependencies. Its syntax is similar to that of C and C++. Two-thirds of the software
    industry still uses Java as its core programming language.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: Java 是用于开发传统软件系统的最古老和最流行的编程语言之一； 它还是一个带有运行时环境的平台。 它由 Sun Microsystems（现在是 Oracle
    的子公司）在 1995 年开发，截至今日，超过 30 亿台设备运行在其上。 它是一种通用的、基于类的、面向对象的编程语言，旨在具有较少的实现依赖性。 其语法与
    C 和 C++ 相似。 三分之二的软件行业仍然使用 Java 作为其核心编程语言。
- en: Let’s use our olive-oil text summarization example once more. As we did with
    Python and Go, we’ll show you how to call the API, send the training prompt as
    a request, and get the summarized completion as an output using Java.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再次使用橄榄油文本摘要示例。 与我们在 Python 和 Go 中所做的一样，我们将向您展示如何调用 API，将训练提示作为请求发送，并使用 Java
    将摘要完成作为输出。
- en: For a step-by-step code walkthrough on your local machine, clone our GitHub
    [repository](https://github.com/Shubhamsaboo/kairos_gpt3). In the cloned repository
    go to Programming_with_GPT-3 folder and open the GPT-3_Java folder.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 要在本地计算机上逐步演示代码，请克隆我们的 GitHub [仓库](https://github.com/Shubhamsaboo/kairos_gpt3)。
    在克隆的仓库中转到 Programming_with_GPT-3 文件夹，然后打开 GPT-3_Java 文件夹。
- en: 'First, import all the relevant dependencies:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '首先，导入所有相关的依赖项:'
- en: package example;
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 包示例;
- en: // Importing Dependencies
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: // 导入依赖项
- en: import java.util.*;
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 导入 java.util.*;
- en: import java.io.*;
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 导入 java.io.*;
- en: import com.theokanning.openai.OpenAiService;
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 导入 com.theokanning.openai.OpenAiService;
- en: import com.theokanning.openai.completion.CompletionRequest;
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 导入 com.theokanning.openai.completion.CompletionRequest;
- en: import com.theokanning.openai.engine.Engine;
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 导入 com.theokanning.openai.engine.Engine;
- en: 'Now you’ll create a class named OpenAiApiExample. All of your code will be
    a part of it. Under that class, first create an OpenAiService object using the
    API token:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你将创建一个名为 OpenAiApiExample 的类。你所有的代码都将是它的一部分。在这个类下面，首先使用 API 令牌创建一个 OpenAiService
    对象：
- en: class OpenAiApiExample {
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: class OpenAiApiExample {
- en: public static void main(String... args) throws FileNotFoundException {
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: public static void main(String... args) throws FileNotFoundException {
- en: String token = "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";
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: String token = "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";
- en: OpenAiService service = new OpenAiService(token);
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAiService service = new OpenAiService(token);
- en: 'The connection to OpenAI API is now established in the form of a service object.
    Read the training prompt from the prompts folder:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 现在已经建立了与 OpenAI API 的连接，形成了一个服务对象。从 prompts 文件夹中读取训练提示：
- en: // Reading the training prompt from the prompts folder
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: // 从 prompts 文件夹中读取训练提示
- en: File file = new File("D:\\GPT-3 Book\\Programming with GPT-3\\GPT-3
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: File file = new File("D:\\GPT-3 Book\\Programming with GPT-3\\GPT-3
- en: Java\\example\\src\\main\\java\\example\\prompts\\summarize_for_a_2nd_grader.txt");
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: Java\\example\\src\\main\\java\\example\\prompts\\summarize_for_a_2nd_grader.txt");
- en: Scanner sc = new Scanner(file);
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: Scanner sc = new Scanner(file);
- en: // we just need to use \\Z as delimiter
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: // 我们只需要使用 \\Z 作为分隔符
- en: sc.useDelimiter("\\Z");
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: sc.useDelimiter("\\Z");
- en: // pp is the string consisting of the training prompt
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: // pp 是由训练提示组成的字符串
- en: String pp = sc.next();
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: String pp = sc.next();
- en: '​Then  you can create a completion request with the following configuration
    for the API parameters:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，您可以使用以下配置为 API 参数创建完成请求：
- en: ●        Maximum tokens=100
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: ●        最大标记=100
- en: ●        Execution Engine="Davinci"
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: ●        执行引擎="Davinci"
- en: ●        Temperature=0.5
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: ●        温度=0.5
- en: ●        Top-p=1
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: ●        Top-p=1
- en: ●        Frequency Penalty = 0.2
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: ●        频率惩罚=0.2
- en: ●        Stop Sequence = ["\n\n"]
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: ●        停止序列 = ["\n\n"]
- en: // Creating a list of strings to used as stop sequence
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: // 创建一个字符串列表，用作停止序列
- en: List<String> li = new ArrayList<String>();
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: List<String> li = new ArrayList<String>();
- en: li.add("\n\n'''");
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: li.add("\n\n'''");
- en: // Creating a completion request with the API parameters
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: // 创建一个包含 API 参数的完成请求
- en: CompletionRequest completionRequest = CompletionRequest.builder().prompt(pp).maxTokens(100).temperature(0.5).topP(1.0).frequencyPenalty(0.2).stop(li).echo(true).build();
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: CompletionRequest completionRequest = CompletionRequest.builder().prompt(pp).maxTokens(100).temperature(0.5).topP(1.0).frequencyPenalty(0.2).stop(li).echo(true).build();
- en: // Using the service object to fetch the completion response
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: // 使用服务对象获取完成响应
- en: service.createCompletion("davinci",completionRequest).getChoices().forEach(System.out::println);
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: service.createCompletion("davinci",completionRequest).getChoices().forEach(System.out::println);
- en: 'Save the code file as ‘text_summarization.java’ and run it from the terminal
    to generate the output. You can use the following command to run the file from
    your root folder:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 将代码文件保存为 'text_summarization.java'，并在终端中运行它以生成输出。你可以使用以下命令从根目录运行文件：
- en: (base) PS D:\GPT-3 Java> ./gradlew example:run
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: (base) PS D:\GPT-3 Java> ./gradlew example:run
- en: Your console should print the same summary as it did with the previous examples.For
    more examples of how you can use Java programming to interact with GPT-3, see
    our GitHub [repository](https://github.com/Shubhamsaboo/kairos_gpt3/tree/master/Programming_with_GPT-3/GPT-3_Java).
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 你的控制台应该打印出与之前示例相同的摘要。要了解如何使用 Java 编程与 GPT-3 交互的更多示例，请参阅我们的 GitHub [仓库](https://github.com/Shubhamsaboo/kairos_gpt3/tree/master/Programming_with_GPT-3/GPT-3_Java)。
- en: GPT-3 Sandbox Powered by Streamlit
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-3 Sandbox Powered by Streamlit
- en: In this section we will walk you through the GPT-3 Sandbox, an open-source tool
    we’ve created to help you turn your ideas into reality with just a few lines of
    Python code. We’ll show you how to use it and how to customize it for your specific
    application.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将带领您了解 GPT-3 Sandbox，这是一个我们创建的开源工具，可以帮助您只需几行 Python 代码就能将您的想法变成现实。我们将向您展示如何使用它以及如何为您的特定应用程序进行定制。
- en: The goal of our sandbox is to empower you to create cool web applications, no
    matter what your technical background. It is built on top of the Streamlit framework.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的沙箱的目标是让您能够创建酷炫的 Web 应用程序，无论您的技术背景如何。它建立在 Streamlit 框架之上。
- en: To accompany this book, we have also created a [video series](https://www.youtube.com/playlist?list=PLHdP3OXYnDmi1m3EQ76IrLoyJj3CHhC4M)
    with a step-by-step instructions for creating and deploying your GPT-3 application,
    which you can access by scanning the QR code in Figure 3-1.  Please follow it
    as you read this chapter.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 为了配合本书，我们还创建了一个 [视频系列](https://www.youtube.com/playlist?list=PLHdP3OXYnDmi1m3EQ76IrLoyJj3CHhC4M)，其中包含逐步说明如何创建和部署您的
    GPT-3 应用的说明，您可以通过扫描第 3-1 图中的 QR 码来访问。请在阅读本章时参考它。
- en: '![](img/image-0-24.jpg)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image-0-24.jpg)'
- en: Figure 3-1\. QR code for GPT-3 Sandbox video series
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3-1\. GPT-3 沙盒视频系列的 QR 码
- en: 'We use VSCode as the IDE for our examples, but feel free to use any IDE. You’ll
    need to install the IDE before you start. Please also make sure you are running
    Python version 3.7 or above. You can confirm which version you have installed
    by running the following command:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在示例中使用 VSCode 作为 IDE，但请随意使用任何 IDE。在开始之前，你需要安装 IDE。请确保你正在运行 Python 版本 3.7 或更高版本。你可以通过运行以下命令确认你安装了哪个版本：
- en: python --version
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: python --version
- en: 'Clone the code from this [repository](https://github.com/Shubhamsaboo/kairos_gpt3)
    by opening a new terminal in your IDE and using the following command:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在你的 IDE 中打开新的终端并使用以下命令，从这个 [仓库](https://github.com/Shubhamsaboo/kairos_gpt3)
    克隆代码：
- en: git clone [https://github.com/Shubhamsaboo/kairos_gpt3](https://github.com/Shubhamsaboo/kairos_gpt3)
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: git clone [https://github.com/Shubhamsaboo/kairos_gpt3](https://github.com/Shubhamsaboo/kairos_gpt3)
- en: 'After cloning the repository the code structure in your IDE should now look
    as follows:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 克隆仓库后，你的 IDE 中的代码结构现在应该如下所示：
- en: '![](img/image-0-25.jpg)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image-0-25.jpg)'
- en: Figure 3-2\. Sandbox file directory structure
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3-2\. 沙盒文件目录结构
- en: Everything you need to create and deploy a web application is already present
    in the code. You just need to tweak a few files to customize the sandbox for your
    specific use case.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要创建和部署 Web 应用所需的一切都已经在代码中了。你只需要调整一些文件以自定义沙盒以满足你特定的用例。
- en: Create a [Python virtual environment](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/),
    which you’ll name env. Then you can install the required dependencies.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个 [Python 虚拟环境](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/)，你将其命名为
    env。然后你可以安装所需的依赖项。
- en: 'Go to the email_generation folder. Your path should look like this:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 前往 email_generation 文件夹。你的路径应该像这样：
- en: (env) kairos_gpt3\GPT-3 Sandbox\email_generation>
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: (env) kairos_gpt3\GPT-3 Sandbox\email_generation>
- en: 'From there, run the following command:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，运行以下命令：
- en: (env) kairos_gpt3\GPT-3 Sandbox\email_generation> pip install -r requirements.txt
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: (env) kairos_gpt3\GPT-3 Sandbox\email_generation> pip install -r requirements.txt
- en: Now you can start customizing the sandbox code. The first file that you need
    to look at is training_data.py. Open that file and replace the default prompt
    with the training prompt you want to use. You can use the GPT-3 playground to
    experiment with different training prompts (see chapter 2 and our [video](https://www.youtube.com/watch?v=YGKY9Mc24MA&list=PLHdP3OXYnDmi1m3EQ76IrLoyJj3CHhC4M&index=3)
    for more on customizing the sandbox).
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你可以开始定制沙盒代码了。你需要查看的第一个文件是 training_data.py。打开该文件并用你想要使用的训练提示替换默认提示。你可以使用 GPT-3
    游乐场来尝试不同的训练提示（有关自定义沙盒的更多信息，请参见第 2 章以及我们的 [视频](https://www.youtube.com/watch?v=YGKY9Mc24MA&list=PLHdP3OXYnDmi1m3EQ76IrLoyJj3CHhC4M&index=3)）。
- en: You’re now ready to tweak the API parameters (Maximum tokens, Execution Engine,
    Temperature, Top-p, Frequency Penalty, Stop Sequence) as per the requirements
    of your application use case. We recommend experimenting with different values
    of API parameters for a given training prompt in the playground to determine what
    values will work best for your use case. Once you get satisfactory results then
    you can alter the values in the training_service.py file.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你可以根据你的应用用例的要求调整 API 参数（最大标记、执行引擎、温度、Top-p、频率惩罚、停止序列）。我们建议在游乐场中为给定的训练提示尝试不同的
    API 参数值，以确定哪些值最适合你的用例。一旦你获得了满意的结果，然后你可以在 training_service.py 文件中更改值。
- en: 'That’s it! Your GPT-3 based web application is now ready. You can run it locally
    using the following command:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样！你的基于 GPT-3 的 Web 应用现在已经准备好了。你可以使用以下命令在本地运行它：
- en: (env) kairos_gpt3\GPT-3 Sandbox\email_generation> streamlit run gpt_app.py
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: (env) kairos_gpt3\GPT-3 Sandbox\email_generation> streamlit run gpt_app.py
- en: Check to make sure it works, and then you can deploy the application to the
    internet using Streamlit sharing to showcase it to a wider audience. Our [video](https://www.youtube.com/watch?v=IO2ndhOoTfc&list=PLHdP3OXYnDmi1m3EQ76IrLoyJj3CHhC4M&index=4)
    offers a full deployment walkthrough.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 检查确保它能正常工作，然后你可以使用 Streamlit 分享将应用程序部署到互联网上，向更广泛的受众展示它。我们的 [视频](https://www.youtube.com/watch?v=IO2ndhOoTfc&list=PLHdP3OXYnDmi1m3EQ76IrLoyJj3CHhC4M&index=4)
    提供了完整的部署步骤。
- en: 'Note: This application follows a simple workflow, where the training prompt
    receives single input from the UI and comes up with the response. If your application
    requires a more complex workflow, where the training prompt takes in multiple
    inputs, customize the UI elements by going through the scripts app1.py, app2.py,
    and gpt_app.py. For details, refer to the [Streamlit documentation](https://docs.streamlit.io).'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：本应用程序遵循简单的工作流程，其中训练提示从UI接收单个输入并生成响应。如果您的应用程序需要更复杂的工作流程，其中训练提示接收多个输入，请通过查看脚本app1.py、app2.py和gpt_app.py来自定义UI元素。有关详细信息，请参阅[Streamlit文档](https://docs.streamlit.io)。
- en: In the next few chapters, we will explore different applications of GPT-3 and
    leverage this sandbox to create easily deployable web applications.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的几章中，我们将探索GPT-3的不同应用，并利用这个沙箱创建易于部署的Web应用程序。
- en: Conclusion
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 结论
- en: In this chapter, we learned how to use the OpenAI API with the programming languages
    Python, Go, and Java. We also walked through a low-code sandbox environment created
    using Streamlit that will help you to quickly turn your idea into an application.
    Lastly, we looked at the key requirements to go live with a GPT-3 application.
    This chapter provided you with the programming outlook of the API; going forward
    we’ll dive deeper into the burgeoning ecosystem empowered by GPT-3.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了如何使用编程语言Python、Go和Java与OpenAI API。我们还通过使用Streamlit创建的低代码沙箱环境进行了演示，这将帮助您快速将您的想法转化为应用程序。最后，我们看了一下上线GPT-3应用程序的关键要求。本章为您提供了API的编程视角；未来我们将深入探讨由GPT-3赋能的蓬勃发展的生态系统。
