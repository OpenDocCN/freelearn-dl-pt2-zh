["```py\nSummarize: A developer can be seen typing on her keyboard. Another developer enters the room and offers her a cup of coffee. She declines, but he insists. They chat about her sleep and the coffee. \n```", "```py\nimport matplotlib.pyplot as plt\ndef draw_scatterplot \n```", "```py\nimport matplotlib.pyplot as plt\ndef draw_scatterplot(x, y):\n    plt.scatter(x, y)\n    plt.xlabel('x')\n    plt.ylabel('y')\n    plt.show()\ndraw_scatterplot([1, 2, 3, 4, 5], [1, 4, 9, 16, 25]) \n```", "```py\n/* draw 50 small ping pong balls of all sorts of colors */\nvar balls = [];\nfor (var i = 0; i < 50; i++) {\n  var ball = document.createElement('div');\n  ball.style.width = '10px';\n  ball.style.height = '10px';\n  ball.style.backgroundColor = 'hsl(' + Math.random() * 360 + ', 100%, 50%)';\n  ball.style.position = 'absolute';\n  ball.style.left = Math.random() * window.innerWidth + 'px';\n  ball.style.top = Math.random() * window.innerHeight + 'px';\n  document.body.appendChild(ball);\n  balls.push(ball);\n}\n/* Make the balls round */\nfor (var i = 0; i < balls.length; i++) {\n  balls[i].style.borderRadius = '50%';\n} \n```", "```py\n`Make all of the balls move inside the window` \n```", "```py\n/* make all of the balls move inside the window. */\nvar moveBalls = function() {\n  for (var i = 0; i < balls.length; i++) {\n    var ball = balls[i];\n    ball.style.left = (parseInt(ball.style.left) + Math.random() * 10 - 5) + 'px';\n    ball.style.top = (parseInt(ball.style.top) + Math.random() * 10 - 5) + 'px';\n  }\n  window.requestAnimationFrame(moveBalls);\n};\nmoveBalls(); \n```", "```py\n    try:\n      import openai\n    except:\n      !pip install openai\n      import openai \n    ```", "```py\n    openai.api_key=\"[YOUR_KEY]\" \n    ```", "```py\nimport pandas as pd\ndf = pd.read_csv('tracking.csv', index_col=0) \n```", "```py\nprint(df) \n```", "```py\n Time Product  User  Score        Summary   Text     \nId                                                                    \n1     01/01/2016 06:30   WH001  C001      4        on time   AGV1     \n2     01/01/2016 06:30   WH001  C001      8           late     R1  NaN\n3     01/01/2016 06:30   WH001  C001      2          early    R15  NaN\n4     01/01/2016 06:30   WH001  C001     10  not delivered    R20  NaN\n5     01/01/2016 06:30   WH001  C001      1        on time     R3  NaN\n...                ...     ...   ...    ...            ...    ...  ...\n1049  01/01/2016 06:30   WH003  C002      9        on time   AGV5  NaN\n1050  01/01/2016 06:30   WH003  C002      2           late  AGV10  NaN\n1051  01/01/2016 06:30   WH003  C002      1          early   AGV5  NaN\n1052  01/01/2016 06:30   WH003  C002      6  not delivered   AGV2  NaN\n1053  01/01/2016 06:30   WH003  C002      3        on time   AGV2  NaN\n[1053 rows x 7 columns] \n```", "```py\ndf['combined'] = df.Summary.str.strip()+ \"-\" + df.Product.str.strip()\nprint(df) \n```", "```py\n Time Product  User  ... Text           combined\nId                                    ...                                 \n1     01/01/2016 06:30 WH001  C001  ... AGV1             on time-WH001\n2     01/01/2016 06:30 WH001  C001  ... R1  NaN           late-WH001\n3     01/01/2016 06:30 WH001  C001  ... R15  NaN          early-WH001\n4     01/01/2016 06:30 WH001  C001  ... R20  NaN  not delivered-WH001\n5     01/01/2016 06:30 WH001  C001  ... R3  NaN        on time-WH001\n...                ...     ...   ...  ...    ...  ...                  ...\n1049  01/01/2016 06:30 WH003  C002  ... AGV5  NaN        on time-WH003\n1050  01/01/2016 06:30 WH003  C002  ... AGV10  NaN         late-WH003\n1051  01/01/2016 06:30 WH003  C002  ... AGV5  NaN          early-WH003\n1052  01/01/2016 06:30 WH003  C002  ... AGV2  NaN  not delivered-WH003\n1053  01/01/2016 06:30 WH003  C002  ... AGV2  NaN        on time-WH003\n[1053 rows x 8 columns] \n```", "```py\nimport time\nimport datetime\n# start time\nstart = time.time()\ndef get_embedding(text, engine=\"davinci-similarity\"):\n   text = text.replace(\"\\n\", \" \")\n   return openai.Engine(id=engine).embeddings(input = [text])['data'][0]['embedding']\ndf['davinci_similarity'] = df.combined.apply(lambda x: get_embedding(x, engine='davinci-similarity'))\n# end time\nend = time.time()\netime=end-start\nconversion = datetime.timedelta(seconds=etime)\nprint(conversion)\nprint(df) \n```", "```py\n0:04:44.188250\n                  Time  ...                                 davinci_similarity\nId                      ...                                                   \n1     01/01/2016 06:30  ...  [-0.0047378824, 0.011997132, -0.017249448, -0....\n2     01/01/2016 06:30  ...  [-0.009643857, 0.0031537763, -0.012862709, -0....\n3     01/01/2016 06:30  ...  [-0.0077407444, 0.0035147679, -0.014401976, -0...\n4     01/01/2016 06:30  ...  [-0.007547746, 0.013380095, -0.018411927, -0.0...\n5     01/01/2016 06:30  ...  [-0.0047378824, 0.011997132, -0.017249448, -0....\n...                ...  ...                                                ...\n1049  01/01/2016 06:30  ...  [-0.0027823148, 0.013289047, -0.014368941, -0....\n1050  01/01/2016 06:30  ...  [-0.0071367626, 0.0046446105, -0.010336877, 0....\n1051  01/01/2016 06:30  ...  [-0.0050991694, 0.006131069, -0.0138306245, -0...\n1052  01/01/2016 06:30  ...  [-0.0066779135, 0.014575769, -0.017257102, -0....\n1053  01/01/2016 06:30  ...  [-0.0027823148, 0.013289047, -0.014368941, -0....\n[1053 rows x 9 columns] \n```", "```py\n#creating a matrix\nimport numpy as np\nmatrix = np.vstack(df.davinci_similarity.values)\nmatrix.shape \n```", "```py\n(1053, 12288) \n```", "```py\nfrom sklearn.cluster import KMeans \n```", "```py\nn_clusters = 4\nkmeans = KMeans(n_clusters = n_clusters,init='k-means++',random_state=42)\nkmeans.fit(matrix)\nlabels = kmeans.labels_\ndf['Cluster'] = labels\ndf.groupby('Cluster').Score.mean().sort_values() \n```", "```py\nCluster\n2    5.297794\n0    5.323529\n1    5.361345\n3    5.741697 \n```", "```py\nprint(labels) \n```", "```py\n[2 3 0 ... 0 1 2] \n```", "```py\nfrom sklearn.manifold import TSNE\nimport matplotlib\nimport matplotlib.pyplot as plt \n```", "```py\n#t-SNE\ntsne = TSNE(n_components=2, perplexity=15, random_state=42, init='random', learning_rate=200)\nvis_dims2 = tsne.fit_transform(matrix) \n```", "```py\nx = [x for x,y in vis_dims2]\ny = [y for x,y in vis_dims2]\nfor category, color in enumerate(['purple', 'green', 'red', 'blue']):\n    xs = np.array(x)[df.Cluster==category]\n    ys = np.array(y)[df.Cluster==category]\n    plt.scatter(xs, ys, color=color, alpha=0.3)\n    avg_x = xs.mean()\n    avg_y = ys.mean()\n\n    plt.scatter(avg_x, avg_y, marker='x', color=color, s=100)\nplt.title(\"Clusters of embeddings-t-SNE\") \n```", "```py\nimport os\nimport openai\nos.environ['OPENAI_API_KEY'] ='[YOUR_API_KEY]'\nprint(os.getenv('OPENAI_API_KEY'))\nopenai.api_key = os.getenv(\"OPENAI_API_KEY\")\nresponse = openai.Completion.create(\n  engine=\"davinci-instruct-beta\",\n  prompt=\"Explain how to set up parent control in Edge.\\n\\n\\nACTIONS:\",\n  temperature=0,\n  max_tokens=120,\n  top_p=1,\n  frequency_penalty=0,\n  presence_penalty=0\n)\nr = (response[\"choices\"][0])\nprint(r[\"text\"]) \n```", "```py\n1\\. Start Internet Explorer.\n2\\. Click on the tools menu.\n3\\. Click on the Internet options.\n4\\. Click on the advanced tab.\n5\\. Click to clear or select the enable personalized favorite menu check box. \n```", "```py\ncontent = \"Small and fat children should not play basketball at school.\" \n```", "```py\nresponse = openai.Completion.create(\n      en      prompt = \"<|endoftext|>\"+content+\"\\n--\\nLabel:\",\n      temperature=0,\n      max_tokens=1,\n      top_p=1,\n      frequency gine=\"content-filter-alpha\",\n_penalty=0,\n      presence_penalty=0,\n      logprobs=10\n    ) \n```", "```py\nr = (response[\"choices\"][0])\nprint(\"Content filter level:\", r[\"text\"]) \n```", "```py\nContent filter level: 2 \n```", "```py\n A,B,C,D,E,F     \nR = ql.matrix([ [0,0,0,0,1,0],   A \n                [0,0,0,1,0,1],   B \n                [0,0,100,1,0,0], C \n                [0,1,1,0,1,0],   D \n                [1,0,0,1,0,0],   E \n                [0,1,0,0,0,0]])  F \n```", "```py\nR = ql.matrix([ [0,0,0,0,1,0],    \n                [0,0,0,1,0,1],    \n                [0,0,100,1,0,0],  \n                [0,1,1,0,1,0],    \n                [1,0,0,1,0,0],    \n                [0,1,0,0,0,0]]) \n```", "```py\n `# The Bellman MDP based Q function`\n `Q[current_state, action] = R[current_state, action] + gamma * MaxValue` \n```", "```py\n `A       B       C       D       E       F`\n`[[  0\\.      0\\.      0\\.      0\\.    258.44    0\\.   ]  A`\n `[  0\\.      0\\.      0\\.    321.8     0\\.    207.752]  B`\n `[  0\\.      0\\.    500\\.    321.8     0\\.      0\\.   ]  C`\n `[  0\\.    258.44  401\\.      0\\.    258.44    0\\.   ]  D`\n `[207.752   0\\.      0\\.    321.8     0\\.      0\\.   ]  E`\n `[  0\\.    258.44    0\\.      0\\.      0\\.      0\\.   ]] F` \n```", "```py\n\"\"\" Simulating a decision-making process\"\"\"\nf = open(\"kant.txt\", \"w\") \n```", "```py\nconceptcode=[\"A\",\"B\",\"C\",\"D\",\"E\",\"F\"]\nNow the number of sequences is set to 10,000:\nmaxv=10000 \n```", "```py\norigin=ql.random.randint(0,6) \n```", "```py\n`FBDC EDC EDC DC BDC AEDC AEDC BDC BDC AEDC BDC AEDC EDC BDC AEDC DC AEDC DC…/…` \n```", "```py\nfill_mask(\"Human thinking involves human<mask>.\") \n```", "```py\nfill_mask(\"BDC<mask>.\") \n```", "```py\n[{'score': 0.00036507684853859246,\n  'sequence': 'BDC FBDC.',\n  'token': 265,\n  'token_str': ' FBDC'},\n {'score': 0.00023987806343939155,\n  'sequence': 'BDC DC.',\n  'token': 271,\n  'token_str': ' DC'}] \n```", "```py\n# Show some images with their labels.\nimages, labels = batch['image'][0][:9], batch['label'][0][:9]\ntitles = map(make_label_getter(dataset), labels.argmax(axis=1))\nshow_img_grid(images, titles) \n```", "```py\n# Same as above, but with train images.\n# Note how images are cropped/scaled differently.\n# Check out input_pipeline.get_data() in the editor at your right to see how the\n# images are preprocessed differently.\nbatch = next(iter(ds_train.as_numpy_iterator()))\nimages, labels = batch['image'][0][:9], batch['label'][0][:9]\ntitles = map(make_label_getter(dataset), labels.argmax(axis=1))\nshow_img_grid(images, titles) \n```"]