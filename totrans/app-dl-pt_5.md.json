["```py\n    import numpy as np\n    import torch\n    from torch import nn, optim\n    from PIL import Image\n    import matplotlib.pyplot as plt\n    from torchvision import transforms, models\n    ```", "```py\n    imsize = 224\n    loader = transforms.Compose([\n             transforms.Resize(imsize), \n             transforms.ToTensor(),\n             transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n    ```", "```py\n    def image_loader(image_name):\n        image = Image.open(image_name)\n        image = loader(image).unsqueeze(0)\n        return image\n    ```", "```py\n    content_img = image_loader(\"images/dog.jpg\")\n    style_img = image_loader(\"images/matisse.jpg\")\n    ```", "```py\n    unloader = transforms.Compose([\n               transforms.Normalize((-0.485/0.229, -0.456/0.224,            -0.406/0.225), (1/0.229, 1/0.224, 1/0.225)),\n               transforms.ToPILImage()])\n    ```", "```py\n    def tensor2image(tensor):\n        image = tensor.clone() \n        image = image.squeeze(0)  \n        image = unloader(image)\n        return image\n    ```", "```py\n    plt.figure()\n    plt.imshow(tensor2image(content_img))\n    plt.title(\"Content Image\")\n    plt.show()\n    plt.figure()\n    plt.imshow(tensor2image(style_img))\n    plt.title(\"Style Image\")\n    plt.show()\n    ```", "```py\n    model = models.vgg19(pretrained=True).features\n    ```", "```py\n    for param in model.parameters():\n        param.requires_grad_(False)\n    ```", "```py\n    print(model)\n    ```", "```py\n    relevant_layers = {'0': 'conv1_1', '5': 'conv2_1', '10': 'conv3_1', '19': 'conv4_1', '21': 'conv4_2', '28': 'conv5_1'}\n    ```", "```py\n    def features_extractor(x, model, layers):\n        features = {}\n        for index, layer in model._modules.items():\n            if index in layers:\n                x = layer(x)\n                features[layers[index]] = x\n        return features\n    ```", "```py\n    content_features = features_extractor(content_img, model,                                       relevant_layers)\n    style_features = features_extractor(style_img, model, relevant_layers)\n    ```", "```py\n    style_grams = {}\n    for i in style_features:\n        layer = style_features[i]\n        _, d1, d2, d3 = layer.shape\n        features = layer.view(d1, d2 * d3)\n        gram = torch.mm(features, features.t())\n        style_grams[i] = gram\n    ```", "```py\n    target_img = content_img.clone().requires_grad_(True)\n    ```", "```py\n    plt.figure()\n    plt.imshow(tensor2image(target_img))\n    plt.title(\"Target Image\")\n    plt.show()\n    ```", "```py\n    style_weights = {'conv1_1': 1., 'conv2_1': 0.8, 'conv3_1': 0.6, 'conv4_1': 0.4, 'conv5_1': 0.2}\n    ```", "```py\n    alpha = 1\n    beta = 1e6\n    ```", "```py\n    print_statement = 500\n    optimizer = torch.optim.Adam([target_img], lr=0.001)\n    iterations = 2000\n    ```", "```py\n        for i in range(1, iterations+1):\n        target_features = features_extractor(target_img, model, relevant_    layers)\n        content_loss = torch.mean((target_features['conv4_2'] - content_    features['conv4_2'])**2)\n        style_losses = 0\n        for layer in style_weights:\n        target_feature = target_features[layer]\n            _, d1, d2, d3 = target_feature.shape\n        target_reshaped = target_feature.view(d1, d2 * d3)\n        target_gram = torch.mm(target_reshaped, target_reshaped.t())\n        style_gram = style_grams[layer]\n        style_loss = style_weights[layer] * torch.mean((target_gram -     style_gram)**2)\n        style_losses += style_loss / (d1 * d2 * d3)\n        total_loss = alpha * content_loss + beta * style_loss\n        optimizer.zero_grad()\n        total_loss.backward()\n        optimizer.step()\n        if  i % print_statement == 0 or i == 1:\n        print('Total loss: ', total_loss.item())\n        plt.imshow(tensor2image(target_img))\n        plt.show()\n    ```", "```py\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n    ax1.imshow(tensor2image(content_img))\n    ax2.imshow(tensor2image(target_img))\n    plt.show()\n    ```"]