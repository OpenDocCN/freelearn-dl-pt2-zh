- en: '*Chapter 2*: GPT-3 Applications and Use Cases'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第2章*：GPT-3的应用和用例'
- en: GPT-3 was designed to be a general-purpose language processing model, meaning
    it wasn't explicitly trained for any one type of language processing task. So,
    possible use cases include virtually any natural language processing task you
    can imagine and others that probably haven't been imagined yet. New use cases
    for GPT-3 are constantly being discovered and that is a big part of the allure
    for many users. Sure, it does better with some tasks than others, but still, there
    are hundreds of possible uses. In this chapter, we'll break down some general
    use cases, and see how you can get started testing prompts of your own.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-3被设计为通用语言处理模型，这意味着它并未专门针对任何一种语言处理任务进行训练。因此，可能的应用包括几乎任何您能想象到的自然语言处理任务，以及可能还有一些尚未被想象到的任务。新的GPT-3用例不断被发现，这对很多用户来说是其魅力的一大部分。当然，它在某些任务上表现更好，但仍然有数百种可能的用途。在本章中，我们将分解一些通用用例，并看看如何开始测试自己的提示。
- en: 'Our topics for this chapter are as follows:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的主题如下：
- en: Understanding general GPT-3 use cases
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解通用GPT-3用例
- en: Introducing the Playground
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍游乐场
- en: Handling text generation and classification tasks
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理文本生成和分类任务
- en: Understanding semantic search
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解语义搜索
- en: Technical requirements
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: This chapter requires you to have access to the OpenAI API. You can register
    for API access by visiting [https://openapi.com](https://openapi.com).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本章需要您访问OpenAI API。您可以通过访问[https://openapi.com](https://openapi.com)注册API访问权限。
- en: Understanding general GPT-3 use cases
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解通用GPT-3用例
- en: 'In the last chapter, you learned that the OpenAI API is a *text in, text out*
    interface. So, it always returns a text response (called a **completion**) to
    a text input (called a **prompt**). The completion might be generating new text,
    classifying text, or providing results for a semantic search. The general-purpose
    nature of GPT-3 means it could be used for almost any language processing task.
    To keep us focused, we''re going to look at the following general use cases: text
    generation, classification, and semantic search:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，您了解到OpenAI API是一个*文本输入，文本输出*接口。因此，它总是对文本输入（称为**提示**）返回一个文本响应（称为**完成**）。完成可能是生成新文本，分类文本，或为语义搜索提供结果。GPT-3的通用性意味着它可以用于几乎任何语言处理任务。为了让我们集中精力，我们将看一下以下常见用例：文本生成，分类和语义搜索。
- en: '**Text generation**: Text generation tasks are tasks for creating new, original
    text content. Examples include article writing and chatbots.'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文本生成**：文本生成任务是创建新的原创文本内容的任务。例如包括文章写作和聊天机器人。'
- en: '**Classification**: Classification tasks tag or classify text. Examples of
    classification tasks include things such as sentiment analysis and content filtering.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分类**：分类任务标记或分类文本。分类任务的例子包括情感分析和内容过滤。'
- en: '**Semantic search**: Semantic search tasks match a query with documents that
    are semantically related. For example, the query might be a question that gets
    matched to one or more documents that provide answers.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**语义搜索**：语义搜索任务将查询与语义相关的文档进行匹配。例如，查询可能是一个问题，会匹配一个或多个提供答案的文档。'
- en: To illustrate different use cases, we'll be using the OpenAI **Playground**.
    So, before we dive into different example use cases, let's get acquainted with
    the Playground.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明不同的用例，我们将使用OpenAI **Playground**。因此，在我们深入研究不同的示例用例之前，让我们先熟悉一下游乐场。
- en: Introducing the Playground
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍游乐场
- en: To get started with GPT-3, OpenAI provides the Playground. The Playground is
    a web-based tool that makes it easy to test prompts and get familiar with how
    the API works. Just about everything you could do by calling the API (which we'll
    discuss in more detail later), you can also do in the Playground. Best of all,
    with the Playground, you can start using GPT-3 without writing a single line of
    code – you just provide a text input (the prompt) in plain English.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始使用GPT-3，OpenAI提供了游乐场。游乐场是一个基于Web的工具，它可以方便地测试提示，并熟悉API的工作原理。几乎你可以通过调用API来做的每件事情（我们稍后将更详细地讨论），你也可以在游乐场中完成。最重要的是，通过游乐场，你可以开始使用GPT-3而不需要编写一行代码-你只需提供一个用简单英语编写的文本输入（提示）。
- en: Getting started with the Playground
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 开始使用游乐场
- en: To access the Playground, you log in at [https://openai.com](https://openai.com).
    After you've authenticated, you'll be able to navigate to the Playground from
    the main menu.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问游乐场，您需要登录[https://openai.com](https://openai.com)。在验证登录后，您将能够从主菜单中导航到游乐场。
- en: The Playground is super simple to use. Mostly, it's made up of a large text
    input. You can start testing GPT-3 by simply entering text into the large text
    input box and then clicking the **Submit** button.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: After clicking the **Submit** button, you'll see additional text added just
    after the text you originally entered – this is the completion text generated
    by GPT-3\.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: Each subsequent time the **Submit** button is clicked, GPT-3 will append an
    additional completion to the text input box. The additional completion uses your
    original text, along with the previous completion, as the prompt for the next
    completion.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: 'The following screenshot shows the Playground with the initial prompt text:
    **If today is Monday, tomorrow is**. You''ll notice that the original prompt text
    is displayed in bold, and the completion is displayed as normal text. In this
    example, the **Submit** button was clicked multiple times to illustrate how each
    completion is building on the last:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.1 – Playground window'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16854_02_001.jpg)'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.1 – Playground window
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: In addition to the large text input for the prompt and completion text, the
    Playground also lets you specify various API settings that provide some control
    over how GPT-3 will process the prompt. We'll discuss the settings in more detail
    later, but if you look at the screenshot in *Figure 2.1*, you'll see a **Response
    Length** setting. This is the length of the response that will be returned. So,
    each time you click the **Submit** button, a new response of that length will
    be added to the textbox.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: 'Again, we''ll get into all of the settings in more detail later. For now, here
    is a quick introduction to what each setting does:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: '**Engine**: The language model that will be used'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Response Length**: How much text will be included in the completion'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Temperature**: Controls the randomness of the result'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Top P**: An alternative to **Temperature** for controlling randomness'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Frequency Penalty**: Decreases the model''s likelihood of repeating the same
    line verbatim'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Presence Penalty**: Increases the model''s likelihood of talking about new
    topics'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Best Of**: Setting to only return the *best* of *n* completions'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Stop Sequence**: A sequence of characters to end a completion'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Inject Start Text**: Text that will be included before the prompt'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Inject Restart Text**: Text that will be included after the completion'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Show Probabilities**: Shows the weight for each word/token in the completion'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Getting familiar with the Playground is all you need to get started with GPT-3\.
    From there, you can start experimenting with how you can use prompts to *program*
    GPT-3 to handle different types of language processing tasks, such as text generation
    and classification tasks.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: Now that we've seen how to start using the Playground, let's learn a bit more
    about text generation and classification tasks.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: Handling text generation and classification tasks
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Text generation and text classification are two common categories of natural
    language processing tasks. Each of these categories covers a number of possible
    use cases that GPT-3 can handle quite well. Let's look at some of them, starting
    with text generation use cases.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 文本生成和文本分类是自然语言处理任务的两个常见类别。每个类别都涵盖了许多GPT-3处理得非常出色的潜在用例。让我们看看其中一些，从文本生成用例开始。
- en: Text generation
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 文本生成
- en: 'Of all the things GPT-3 can do, text generation is its superpower. There are
    a lot of potential use cases for generating text, so we''ll break text generation
    down further into three sub-topics: generating text, summarizing text, and transforming
    text.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 关于GPT-3可以做的所有事情中，文本生成是它的超能力。文本生成有很多潜在的用例，所以我们将进一步将文本生成分为三个子主题：生成文本、总结文本和转换文本。
- en: Generating text
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 生成文本
- en: GPT-3 can generate original text content that is usually indistinguishable from
    human-written text. This could be used for a variety of applications, from creating
    web content to brainstorming, conversational applications, poetry, songwriting,
    writing code, and creating data lists. Let's take a look at some examples.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-3能够生成通常与人工书写的文本难以区分的原始文本内容。这可以用于各种应用，从创造网页内容到头脑风暴、对话应用、诗歌、歌词创作、写作编码和创建数据列表。让我们看一些例子。
- en: Content creation
  id: totrans-47
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 内容创建
- en: 'Content creation is one of the coolest things GPT-3 can do. With the right
    prompt, GPT-3 can create articles, blog posts, or content for social media. The
    following screenshot shows the results of a prompt that directs GPT-3 to create
    a list of tips for first-time home buyers. However, this general approach could
    be used to create content for just about any topic:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 内容创建是GPT-3所能做的最酷的事情之一。有了正确的提示，GPT-3可以创建文章、博客文章或社交媒体内容。下面的截图显示了一个提示的结果，引导GPT-3创建首次购房者的建议清单。然而，这种通用方法可以用于创建几乎任何主题的内容：
- en: '![Figure 2.2 – Text generation example – tips for first-time home buyers'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '![图2.2 – 文本生成示例 – 首次购房者的建议'
- en: '](img/B16854_02_002.jpg)'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16854_02_002.jpg)'
- en: Figure 2.2 – Text generation example – tips for first-time home buyers
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.2 – 文本生成示例 – 首次购房者的建议
- en: Again, you can use GPT-3 to create a list on just about any topic, so there
    are tons of possibilities. Another great example use case is idea generation.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，你可以使用GPT-3来创建几乎任何主题的列表，因此有很多可能性。另一个很好的示例用例是创意生成。
- en: Idea generation
  id: totrans-53
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 创意生成
- en: 'GPT-3 can also be a great tool for brainstorming. The following prompt and
    subsequent screenshot show GPT-3 being used to generate 3D printing project ideas
    for a maker day event. Of course, this could have been a list of ideas for just
    about anything:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-3还可以是头脑风暴的一个好工具。以下提示和随后的截图显示了GPT-3被用于生成3D打印项目创意的制造者日活动。当然，这也可以是几乎任何事情的想法清单：
- en: '[PRE0]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The result is shown in the following screenshot:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 结果显示在以下截图中：
- en: '![Figure 2.3 – Text generation example – 3D print project ideas'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '![图2.3 – 文本生成示例 – 3D打印项目创意'
- en: '](img/B16854_02_003.jpg)'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16854_02_003.jpg)'
- en: Figure 2.3 – Text generation example – 3D print project ideas
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.3 – 文本生成示例 – 3D打印项目创意
- en: The bold text in *Figure 2.3* is the prompt that was provided, and the regular
    text was generated by GPT-3\. Pretty cool, right? Here is another cool example
    – conversational applications.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '*图2.3*中的粗体文本是提供的提示，常规文本是由GPT-3生成的。很酷，对吧？这里还有另一个很酷的例子——对话应用。'
- en: Conversational applications
  id: totrans-61
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 对话应用
- en: 'Conversational applications are also a potential use case for GPT-3, for example,
    in chatbots, IVRs, and voice assistants. The following text can be used to prompt
    GPT-3 to simulate a dialog between an AI support assistant and a customer:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 对话应用也是GPT-3的一个潜在用例，例如在聊天机器人、IVR和语音助手中。下面的文本可以用来提示GPT-3模拟AI支持助手与客户之间的对话：
- en: '[PRE1]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The results from the preceding prompt are shown in the following screenshot.
    In this case, GPT-3 is generating both sides of the conversation, but in a real-world
    application, the user side of the conversation would come from an actual customer:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 前面提示的结果显示在以下截图中。在这种情况下，GPT-3生成了对话的两端，但在现实世界的应用中，对话的用户端会来自实际的客户：
- en: '![Figure 2.4 – Text generation example – customer support AI assistant'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '![图2.4 – 文本生成示例 – 客服AI助手'
- en: '](img/B16854_02_004.jpg)'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16854_02_004.jpg)'
- en: Figure 2.4 – Text generation example – customer support AI assistant
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.4 – 文本生成示例 – 客服AI助手
- en: There are a number of techniques you can use to help direct GPT-3 on how to
    respond. For example, in *Figure 2.4* you'll notice the prompt includes `The`
    `assistant` `is` `helpful` `creative,` `clever,` `and` `very` `friendly`. - this
    guides GPT-3 on the overall style and tone of the response. We'll get into this
    in more detail throughout the following chapters but for now, let's move on and
    look at using GPT-3 for list generation.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用多种技术来帮助引导GPT-3如何作出回应。例如，在*图2.4*中，您会注意到提示包括 `The` `assistant` `is` `helpful`
    `creative,` `clever,` `and` `very` `friendly` - 这指导了GPT-3关于回应的整体风格和语调。我们将在接下来的章节中更详细地讨论这一点，但现在，让我们继续并看看如何使用GPT-3生成列表。
- en: List generation
  id: totrans-69
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 列表生成
- en: 'The following screenshot shows GPT-3 being used to create a list of companies
    and the category they fall into. You can see from the prompt that it''s continuing
    the pattern that was started. So, you can generate just about any list this way:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了GPT-3正在用于创建一份公司及其所属类别的列表。您可以从提示中看到，它正在继续之前开始的模式。所以，您可以用这种方式生成几乎任何列表：
- en: '[PRE2]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The result for the previous prompt is shown in the following screenshot:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 上一个提示的结果如下截图所示：
- en: '![Figure 2.5 – Text generation example – list generation'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '![图2.5 – 文本生成示例 – 列表生成'
- en: '](img/B16854_02_005.jpg)'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16854_02_005.jpg)'
- en: Figure 2.5 – Text generation example – list generation
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.5 – 文本生成示例 – 列表生成
- en: In *Figure 2.5*, you'll notice that not only are more companies added to the
    list, GPT-3 is also able to accurately classify the companies by industry. Keep
    it mind, GPT-3 isn't pulling this information from a database – it's generating
    it! But as impressive that that is, GPT-3 can complete a lot more complex generation
    tasks. For instance, in the next example we'll look at using GPT-3 to generate
    a quiz.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图2.5*中，您会注意到不仅添加了更多公司到列表中，GPT-3也能够准确地按行业对公司进行分类。记住，GPT-3并不是从数据库中提取这些信息 - 而是生成它！但令人印象深刻的是，GPT-3还能完成更复杂的生成任务。例如，在下一个示例中，我们将看看如何使用GPT-3生成一份测验。
- en: Quiz generation
  id: totrans-77
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 测验生成
- en: 'GPT-3 can generate quizzes, too. For example, the following prompt could be
    used to compile questions and possible answers for a quiz that tests a student''s
    ability to identify words that rhyme:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-3也能够生成测验。例如，下面的提示可以用于编制测试问题和可能的答案，以测试学生识别押韵单词的能力：
- en: '[PRE3]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The following screenshot shows the completion that GT-3 generated from the
    previous prompt:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了GT-3从先前提示生成的完成状态：
- en: '![Figure 2.6 – Text generation example – quiz generation'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '![图2.6 – 文本生成示例 – 测验生成'
- en: '](img/B16854_02_006.jpg)'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16854_02_006.jpg)'
- en: Figure 2.6 – Text generation example – quiz generation
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.6 – 文本生成示例 – 测验生成
- en: Content creation, idea generation, conversational applications, creating lists,
    and generating quizzes are just a few of the possible text generation use cases.
    But text generation isn't just about creating new content; it can also be used
    for other use cases such as summarizing existing content.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 内容创建，创意生成，对话应用程序，创建列表和生成测验只是可能文本生成用例中的一小部分。但文本生成不仅仅是关于创建新内容；还可以用于其他用例，如总结现有内容。
- en: Summarizing text
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 总结文本
- en: In addition to creating new original text, you can also use GPT-3 to create
    summaries of documents. There are multiple ways you can go about summarizing text.
    You can use basic summaries, one-sentence summaries, grade-level adjusted summaries,
    or summarize by extracting key points from a document. Let's take a quick look
    at each of these approaches.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 除了创作新的原始文本，您还可以使用GPT-3创建文档摘要。有多种方法可以用于总结文本。您可以使用基本摘要、一句话总结、年级调整的摘要，或者通过从文档中提取关键点进行总结。让我们快速看一下每种方法。
- en: Basic summary
  id: totrans-87
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 基本摘要
- en: 'The easiest way to create a summary is to just add `tl;dr:` after the text
    you want to summarize. This will prompt GPT-3 to summarize the preceding text.
    It''s not a reliable way to summarize in every case, but it works quite well for
    many cases. For instance, the following prompt provides text about quantum mechanics,
    which was copied from [https://en.wikipedia.org/wiki/Quantum_mechanics](https://en.wikipedia.org/wiki/Quantum_mechanics):'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 创建摘要的最简单方法就是在想要总结的文本后加上`tl;dr:`。这将提示GPT-3总结前面的文本。在每种情况下这并不是一种可靠的总结方法，但对许多情况来说都很有效。例如，下面的提示提供了有关量子力学的文本，该文本是从
    [https://en.wikipedia.org/wiki/Quantum_mechanics](https://en.wikipedia.org/wiki/Quantum_mechanics)
    复制的：
- en: '[PRE4]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The result from the previous prompt is shown in *Figure 2.7*:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 上一个提示的结果如*图2.7*所示：
- en: '![Figure 2.7 – Text generation example – tl;dr: summary'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '![图2.7 – 文本生成示例 – tl;dr:摘要'
- en: '](img/B16854_02_007.jpg)'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.7 – Text generation example – tl;dr: summary'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: You will notice that the original text consisted of three paragraphs, but the
    resulting summary is just a few sentences. You can also direct GPT-3 to summarize
    the text in a single sentence.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: One-sentence summary
  id: totrans-95
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Another way to summarize text is to add **one-sentence summary:** after the
    text you'd like to summarize. This, along with setting the **Stop Sequence** to
    a period, results in a single sentence summary of the provided text.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: 'The following prompt will create a single-sentence summary of a paragraph from
    the OpenAI Terms of Use page located at https://beta.openai.com/terms-of-use:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The following screenshot shows the results of the preceding one-sentence summary
    prompt:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.8 – Text generation example – one-sentence summary'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16854_02_008.jpg)'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.8 – Text generation example – one-sentence summary
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: Depending on the text you want to summarize, a single sentence can be very helpful
    in simplifying content for you. Another way to simplify content is to rewrite
    it with simpler text. This can be done with grade-level summaries.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: Grade-level summary
  id: totrans-104
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'To summarize text using language that would be appropriate for someone of a
    certain age, you can use grade-level summaries. This can be done by following
    the text you want to summarize with something like the last sentence in the following
    example prompt. In this example, we''re using text that was copied from [https://en.wikipedia.org/wiki/Milky_Way](https://en.wikipedia.org/wiki/Milky_Way):'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'In the following screenshot, you can see the results of the previous prompt:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.9 – Text generation example – grade-level summarization'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16854_02_009.jpg)'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.9 – Text generation example – grade-level summarization
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: Note that the summary shown in *Figure 2.9* is written in a way that would likely
    be understood by a third grader. In this case, GPT-3 is translating the text (in
    a way) for a younger reader. But you can also use GPT-3 to translate text into
    different languages.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: Transforming text
  id: totrans-112
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You can also use GPT-3 to transform text, for example, from one language to
    another, or from English to something else, such as emojis or software code. Let's
    take a look at a language translation example first.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: Translation
  id: totrans-114
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In the following screenshot, GPT-3 is being used to translate English to French.
    This is a **preset** that is provided in the Playground; we''ll talk more about
    presets in the next chapter:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.10 – Text generation example – translation from English to French'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16854_02_010.jpg)'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.10 – Text generation example – translation from English to French
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: 'You can see in *Figure 2.10* that a few translation examples were used in the
    prompt. This is helpful for some language translation tasks, but for many simple
    translations, you don''t even need examples. For example, the following prompt
    would likely be completed with the correct translation:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Language translations are impressive for sure. But what if you want to translate
    between English and something other than another natural language? For instance,
    what about converting English to emoji text?
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: Conversion
  id: totrans-122
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'This is another example that is provided by OpenAI. In this example, the prompt
    is used to convert the name of a movie into an emoji form. This works because
    emojis are just text characters, so they are part of the underlying GPT-3 training
    data. Notice that some of the emoji versions don''t just use the words in the
    title. For example, **Transformers** has a car and a robot emoji, which makes
    sense if you''ve seen the movie but not if you''re just looking at the word *transformers*.
    So, what''s going on? GPT-3 isn''t just using what''s provided in the prompt;
    it''s also using information from its massive model, which contains additional
    details about each of the movies:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.11 – Text generation example – conversion from text to emoji'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16854_02_011.jpg)'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.11 – Text generation example – conversion from text to emoji
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: So, there are a lot of possibilities for text generation use cases but remember,
    GPT-3 is a general-purpose language processing system. So, generating text is
    just the beginning. Another common NLP use case is text classification.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: Text classification
  id: totrans-128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Text classification involves evaluating some provided text and assigning it
    a label, score, or some other attribute that classifies the text. Sentiment analysis
    is a common text classification use case, but that's just one of many text classifications
    tasks GPT-3 could be used for.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: There are multiple ways to go about getting GPT-3 to classify text. In the simplest
    cases, you don't even need to provide examples; this is referred to as zero-shot
    classification and it is an easy way to do basic classifications, such as sentiment
    analysis.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: Zero-shot classification
  id: totrans-131
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Recall from the last chapter that a zero-shot prompt doesn't provide any examples.
    Similarly, a **zero-shot classification** is a classification task with no examples.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an example of a zero-shot classification prompt. In this example, the
    goal is to perform sentiment analysis to determine whether a Twitter post is positive,
    neutral, or negative:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'You can see from the following screenshot the sentiment classification result
    from the zero-shot classification example:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.12 – Text generation example – zero-shot classification'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16854_02_012.jpg)'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.12 – Text generation example – zero-shot classification
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is another zero-shot classification example. This example shows that GPT-3
    can even comprehend text for a classification task. Notice the prompt provides
    a question and GPT-3 classifies the travel type:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The following is a screenshot that shows the results:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.13 – Text generation example – zero-shot classification'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16854_02_013.jpg)'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.13 – Text generation example – zero-shot classification
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: Zero-shot classification is about as simple as it gets and can be very useful
    for a variety of classification tasks. But sometimes classification tasks are
    a bit more complex and will require examples. For those cases, you'll use few-shot
    classifications.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: Few-shot classification
  id: totrans-146
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Another way to do classifications is with examples; this is referred to as **few-shot
    classification**. When you provide examples of how to classify text, the model
    can learn how to label the text based on the samples you provide. If the model
    is not able to classify your text correctly, providing examples will likely improve
    the results. This could be used for situations where you're using different terminology
    – for example, *emotion* instead of *sentiment*.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: 'The following prompt and subsequent screenshot show an example of a few-shot
    classification for classifying *animal lovers*:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The results from the previous prompt are shown in the following screenshot:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.14 – Text generation example – few-shot classification'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16854_02_014.jpg)'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.14 – Text generation example – few-shot classification
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: Notice in *Figure 2.14* how just a few examples are enough for GPT-3 to understand
    how to classify any animal type. In that example, the classifications are being
    done one at a time, but GPT-3 can also do batch classifications.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: Batch classification
  id: totrans-155
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If you're able to successfully classify text using few-shot classification prompts,
    you can also show the model how to classify a list of items. This is referred
    to as **batch classification**.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: 'The following prompt shows an example of a prompt for doing batch classification.
    Notice that both classification examples and a batch classification example are
    provided in the prompt:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Now that we've seen what GPT-3 can do for text generation and classification,
    let's look at how GPT-3 can be used for semantic search.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: Understanding semantic search
  id: totrans-160
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A semantic search matches a search term or query words with semantically similar
    documents containing any amount of text. A simple keyword search might just look
    for words in the query that match words in the documents. However, a semantic
    search goes way beyond that. It looks at the meaning of words and ranks the documents
    with the highest-ranking document representing the document that is most semantically
    similar to the query. For example, suppose we have the query an animal with wings
    and five one-word documents: *dog, cat, snake, rabbit, eagle*. A semantic search
    would rank each of the five documents and assign the highest rank to the document
    containing the word eagle because it is most semantically similar to the query.'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: Every time you query Google, you're using semantic search and like Google, GPT
    3 can also search over documents. However, rather than searching documents on
    the web, the documents are provided as part of the request to the OpenAI API or
    in a pre-uploaded file.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: The search query might be a question, a statement, or just a few words. The
    query gets evaluated against the provided documents and a score is provided in
    the results for each document. The score is usually between 0 and 300 but can
    sometimes go higher. A higher score, above 200, usually means the document is
    semantically similar to the query.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 搜索查询可能是一个问题、一个陈述或只是几个词。查询会针对提供的文档进行评估，并在每个文档的结果中提供一个分数。分数通常在0和300之间，但有时可能会更高。较高的分数，超过200，通常意味着文档在语义上与查询类似。
- en: When documents are provided with the API request, up to 200 documents can be
    included. However, you can go beyond the 200 document limit by uploading a documents
    file or sending multiple requests with the same query but different documents.
    We'll look at how that works in more detail in [*Chapter 4*](B16854_04_ePub_AM.xhtml#_idTextAnchor074)*,
    Working with the OpenAI API*.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 当API请求附带文档时，最多可以包含200个文档。但是，您可以通过上传文档文件或发送多个具有相同查询但不同文档的请求来超出200文档限制。我们将在[*第4章*](B16854_04_ePub_AM.xhtml#_idTextAnchor074)*，使用OpenAI
    API*中更详细地了解其工作原理。
- en: Another consideration when using GPT 3 for semantic search is the engine you
    select. Recall from the last chapter that while davinci is the largest and most
    capable engine in terms of the tasks it can handle, other engines often perform
    better and cost less to use for certain tasks. When it comes to semantic search,
    the trade-off in terms of accuracy is often minimal. So, it makes sense to test
    the faster and more efficient engines like ada or babbage, which you can do using
    the **Semantic Search tool**.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用GPT 3进行语义搜索时，另一个考虑因素是选择的引擎。回想一下上一章中提到的，尽管davinci是最大、最能胜任任务的引擎，但其他引擎在某些任务上往往表现更好且成本更低。在语义搜索方面，准确性方面的折衷通常很小。因此，测试更快、更高效的引擎如ada或babbage是有意义的，您可以使用**语义搜索工具**来完成这项任务。
- en: The Semantic Search tool
  id: totrans-166
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 语义搜索工具
- en: 'The Playground is used for testing prompts and completions. However, the Semantic
    Search tool can be used to test search queries. You can access the Semantic Search
    tool by visiting [https://gpttools.com/semanticsearch](https://gpttools.com/semanticsearch).
    It''s a simple web-based application (like the Playground) that lets you test
    semantic searches using the different engines. The following screenshot shows
    the Semantic Search tool:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: Playground用于测试提示和补全。但是，语义搜索工具可用于测试搜索查询。您可以通过访问[https://gpttools.com/semanticsearch](https://gpttools.com/semanticsearch)来访问语义搜索工具。这是一个简单的基于Web的应用程序（类似于Playground），让您可以使用不同的引擎测试语义搜索。下面的截图显示了语义搜索工具：
- en: '![Figure 2.15 – The Semantic Search tool'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '![图2.15 – 语义搜索工具'
- en: '](img/B16854_02_015.jpg)'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16854_02_015.jpg)'
- en: Figure 2.15 – The Semantic Search tool
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.15 – 语义搜索工具
- en: You'll notice that the Semantic Search tool requires an OpenAI **API key**.
    You can get your API key from the OpenAI API Keys page located at [https://beta.openai.com/account/api-keys](https://beta.openai.com/account/api-keys).You
    will need to be logged in to access the API Keys page. We will talk more about
    API keys in [*Chapter 4*](B16854_04_ePub_AM.xhtml#_idTextAnchor074), *Working
    with the OpenAI API*, but for now, the most important thing to know is that you
    should keep your API key private and never share it with others.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 您会注意到语义搜索工具需要一个OpenAI **API密钥**。您可以从[https://beta.openai.com/account/api-keys](https://beta.openai.com/account/api-keys)的OpenAI
    API Keys页面获取您的API密钥。您需要登录才能访问API Keys页面。我们将在[*第4章*](B16854_04_ePub_AM.xhtml#_idTextAnchor074)中更多地讨论API密钥，但目前，最重要的是您应该保持API密钥私密，并不与他人分享。
- en: 'The following screenshot shows the API Keys page (with the API key intentionally
    blurred out) where you can copy your API key for the Semantic Search tool:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的截图显示了API Keys页面（API密钥被有意地模糊掉了），您可以在这里复制您的语义搜索工具的API密钥：
- en: '![Figure 2.16 – The OpenAI API Keys page'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '![图2.16 – OpenAI API Keys页面'
- en: '](img/B16854_02_016.jpg)'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16854_02_016.jpg)'
- en: Figure 2.16 – The OpenAI API Keys page
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.16 – OpenAI API Keys页面
- en: 'The Semantic Search tool also provides presets, which are templates to help
    you get familiar with different semantic search examples. The following screenshot
    shows the Semantic Search tool with the results of a search using the **Directors
    and Movies** preset:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 语义搜索工具还提供了预设，这些是帮助您熟悉不同语义搜索示例的模板。下面的截图显示了使用**导演和电影**预设进行搜索的语义搜索工具的结果：
- en: '![Figure 2.17 – Text generation example – Semantic Search tool'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '![图2.17 – 文本生成示例 – 语义搜索工具'
- en: '](img/B16854_02_017.jpg)'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16854_02_017.jpg)'
- en: Figure 2.17 – Text generation example – Semantic Search tool
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: As you can hopefully see at this point, the possible use-cases for GPT 3 are
    pretty broad. We haven't even scratched the surface of what's possible or discussed
    how GPT 3 might be used in production applications. We will dive deeper into more
    specific examples and use-cases throughout the book. But in addition, there is
    a rapidly growing number of GPT 3 powered applications and examples online that
    you should check out for additional use-cases and inspiration. The range of online
    applications is impressive to say the least. You can start by Googling the term
    list of apps using GPT-3\. You'll find a growing number of curated lists and videos
    that highlighting a wide variety of GPT-3 powered apps and prompt examples. GPT-3
    Demo located at [https://gpt3demo.com/](https://gpt3demo.com/) is one worth checking
    out. There is also a blog post from OpenAI located at [https://openai.com/blog/gpt-3-apps/](https://openai.com/blog/gpt-3-apps/)
    that lists applications and industry use-cases and a number of usage and prompt
    example at [https://beta.openai.com/examples](https://beta.openai.com/examples).
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-181
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we looked at different potential use cases for GPT-3\. We discussed
    using GPT-3 for text generation, classification, and semantic search, and looked
    at examples of each. We introduced the Playground web-based testing tool and covered
    how to access it and get started using it. We looked at different ways to write
    prompts for text generation and text classification and how GPT-3 supports semantic
    search.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will dive deeper into the Playground and look at how
    different engines and API settings influence completion results.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
