- en: '*Chapter 2*: GPT-3 Applications and Use Cases'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: GPT-3 was designed to be a general-purpose language processing model, meaning
    it wasn't explicitly trained for any one type of language processing task. So,
    possible use cases include virtually any natural language processing task you
    can imagine and others that probably haven't been imagined yet. New use cases
    for GPT-3 are constantly being discovered and that is a big part of the allure
    for many users. Sure, it does better with some tasks than others, but still, there
    are hundreds of possible uses. In this chapter, we'll break down some general
    use cases, and see how you can get started testing prompts of your own.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our topics for this chapter are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding general GPT-3 use cases
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introducing the Playground
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Handling text generation and classification tasks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding semantic search
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter requires you to have access to the OpenAI API. You can register
    for API access by visiting [https://openapi.com](https://openapi.com).
  prefs: []
  type: TYPE_NORMAL
- en: Understanding general GPT-3 use cases
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the last chapter, you learned that the OpenAI API is a *text in, text out*
    interface. So, it always returns a text response (called a **completion**) to
    a text input (called a **prompt**). The completion might be generating new text,
    classifying text, or providing results for a semantic search. The general-purpose
    nature of GPT-3 means it could be used for almost any language processing task.
    To keep us focused, we''re going to look at the following general use cases: text
    generation, classification, and semantic search:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Text generation**: Text generation tasks are tasks for creating new, original
    text content. Examples include article writing and chatbots.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Classification**: Classification tasks tag or classify text. Examples of
    classification tasks include things such as sentiment analysis and content filtering.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Semantic search**: Semantic search tasks match a query with documents that
    are semantically related. For example, the query might be a question that gets
    matched to one or more documents that provide answers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To illustrate different use cases, we'll be using the OpenAI **Playground**.
    So, before we dive into different example use cases, let's get acquainted with
    the Playground.
  prefs: []
  type: TYPE_NORMAL
- en: Introducing the Playground
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To get started with GPT-3, OpenAI provides the Playground. The Playground is
    a web-based tool that makes it easy to test prompts and get familiar with how
    the API works. Just about everything you could do by calling the API (which we'll
    discuss in more detail later), you can also do in the Playground. Best of all,
    with the Playground, you can start using GPT-3 without writing a single line of
    code – you just provide a text input (the prompt) in plain English.
  prefs: []
  type: TYPE_NORMAL
- en: Getting started with the Playground
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To access the Playground, you log in at [https://openai.com](https://openai.com).
    After you've authenticated, you'll be able to navigate to the Playground from
    the main menu.
  prefs: []
  type: TYPE_NORMAL
- en: The Playground is super simple to use. Mostly, it's made up of a large text
    input. You can start testing GPT-3 by simply entering text into the large text
    input box and then clicking the **Submit** button.
  prefs: []
  type: TYPE_NORMAL
- en: After clicking the **Submit** button, you'll see additional text added just
    after the text you originally entered – this is the completion text generated
    by GPT-3\.
  prefs: []
  type: TYPE_NORMAL
- en: Each subsequent time the **Submit** button is clicked, GPT-3 will append an
    additional completion to the text input box. The additional completion uses your
    original text, along with the previous completion, as the prompt for the next
    completion.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following screenshot shows the Playground with the initial prompt text:
    **If today is Monday, tomorrow is**. You''ll notice that the original prompt text
    is displayed in bold, and the completion is displayed as normal text. In this
    example, the **Submit** button was clicked multiple times to illustrate how each
    completion is building on the last:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.1 – Playground window'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16854_02_001.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.1 – Playground window
  prefs: []
  type: TYPE_NORMAL
- en: In addition to the large text input for the prompt and completion text, the
    Playground also lets you specify various API settings that provide some control
    over how GPT-3 will process the prompt. We'll discuss the settings in more detail
    later, but if you look at the screenshot in *Figure 2.1*, you'll see a **Response
    Length** setting. This is the length of the response that will be returned. So,
    each time you click the **Submit** button, a new response of that length will
    be added to the textbox.
  prefs: []
  type: TYPE_NORMAL
- en: 'Again, we''ll get into all of the settings in more detail later. For now, here
    is a quick introduction to what each setting does:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Engine**: The language model that will be used'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Response Length**: How much text will be included in the completion'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Temperature**: Controls the randomness of the result'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Top P**: An alternative to **Temperature** for controlling randomness'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Frequency Penalty**: Decreases the model''s likelihood of repeating the same
    line verbatim'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Presence Penalty**: Increases the model''s likelihood of talking about new
    topics'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Best Of**: Setting to only return the *best* of *n* completions'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Stop Sequence**: A sequence of characters to end a completion'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Inject Start Text**: Text that will be included before the prompt'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Inject Restart Text**: Text that will be included after the completion'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Show Probabilities**: Shows the weight for each word/token in the completion'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Getting familiar with the Playground is all you need to get started with GPT-3\.
    From there, you can start experimenting with how you can use prompts to *program*
    GPT-3 to handle different types of language processing tasks, such as text generation
    and classification tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we've seen how to start using the Playground, let's learn a bit more
    about text generation and classification tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Handling text generation and classification tasks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Text generation and text classification are two common categories of natural
    language processing tasks. Each of these categories covers a number of possible
    use cases that GPT-3 can handle quite well. Let's look at some of them, starting
    with text generation use cases.
  prefs: []
  type: TYPE_NORMAL
- en: Text generation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Of all the things GPT-3 can do, text generation is its superpower. There are
    a lot of potential use cases for generating text, so we''ll break text generation
    down further into three sub-topics: generating text, summarizing text, and transforming
    text.'
  prefs: []
  type: TYPE_NORMAL
- en: Generating text
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: GPT-3 can generate original text content that is usually indistinguishable from
    human-written text. This could be used for a variety of applications, from creating
    web content to brainstorming, conversational applications, poetry, songwriting,
    writing code, and creating data lists. Let's take a look at some examples.
  prefs: []
  type: TYPE_NORMAL
- en: Content creation
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Content creation is one of the coolest things GPT-3 can do. With the right
    prompt, GPT-3 can create articles, blog posts, or content for social media. The
    following screenshot shows the results of a prompt that directs GPT-3 to create
    a list of tips for first-time home buyers. However, this general approach could
    be used to create content for just about any topic:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.2 – Text generation example – tips for first-time home buyers'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16854_02_002.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.2 – Text generation example – tips for first-time home buyers
  prefs: []
  type: TYPE_NORMAL
- en: Again, you can use GPT-3 to create a list on just about any topic, so there
    are tons of possibilities. Another great example use case is idea generation.
  prefs: []
  type: TYPE_NORMAL
- en: Idea generation
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'GPT-3 can also be a great tool for brainstorming. The following prompt and
    subsequent screenshot show GPT-3 being used to generate 3D printing project ideas
    for a maker day event. Of course, this could have been a list of ideas for just
    about anything:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.3 – Text generation example – 3D print project ideas'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16854_02_003.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.3 – Text generation example – 3D print project ideas
  prefs: []
  type: TYPE_NORMAL
- en: The bold text in *Figure 2.3* is the prompt that was provided, and the regular
    text was generated by GPT-3\. Pretty cool, right? Here is another cool example
    – conversational applications.
  prefs: []
  type: TYPE_NORMAL
- en: Conversational applications
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Conversational applications are also a potential use case for GPT-3, for example,
    in chatbots, IVRs, and voice assistants. The following text can be used to prompt
    GPT-3 to simulate a dialog between an AI support assistant and a customer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The results from the preceding prompt are shown in the following screenshot.
    In this case, GPT-3 is generating both sides of the conversation, but in a real-world
    application, the user side of the conversation would come from an actual customer:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.4 – Text generation example – customer support AI assistant'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16854_02_004.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.4 – Text generation example – customer support AI assistant
  prefs: []
  type: TYPE_NORMAL
- en: There are a number of techniques you can use to help direct GPT-3 on how to
    respond. For example, in *Figure 2.4* you'll notice the prompt includes `The`
    `assistant` `is` `helpful` `creative,` `clever,` `and` `very` `friendly`. - this
    guides GPT-3 on the overall style and tone of the response. We'll get into this
    in more detail throughout the following chapters but for now, let's move on and
    look at using GPT-3 for list generation.
  prefs: []
  type: TYPE_NORMAL
- en: List generation
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The following screenshot shows GPT-3 being used to create a list of companies
    and the category they fall into. You can see from the prompt that it''s continuing
    the pattern that was started. So, you can generate just about any list this way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The result for the previous prompt is shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.5 – Text generation example – list generation'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16854_02_005.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.5 – Text generation example – list generation
  prefs: []
  type: TYPE_NORMAL
- en: In *Figure 2.5*, you'll notice that not only are more companies added to the
    list, GPT-3 is also able to accurately classify the companies by industry. Keep
    it mind, GPT-3 isn't pulling this information from a database – it's generating
    it! But as impressive that that is, GPT-3 can complete a lot more complex generation
    tasks. For instance, in the next example we'll look at using GPT-3 to generate
    a quiz.
  prefs: []
  type: TYPE_NORMAL
- en: Quiz generation
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'GPT-3 can generate quizzes, too. For example, the following prompt could be
    used to compile questions and possible answers for a quiz that tests a student''s
    ability to identify words that rhyme:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The following screenshot shows the completion that GT-3 generated from the
    previous prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.6 – Text generation example – quiz generation'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16854_02_006.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.6 – Text generation example – quiz generation
  prefs: []
  type: TYPE_NORMAL
- en: Content creation, idea generation, conversational applications, creating lists,
    and generating quizzes are just a few of the possible text generation use cases.
    But text generation isn't just about creating new content; it can also be used
    for other use cases such as summarizing existing content.
  prefs: []
  type: TYPE_NORMAL
- en: Summarizing text
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In addition to creating new original text, you can also use GPT-3 to create
    summaries of documents. There are multiple ways you can go about summarizing text.
    You can use basic summaries, one-sentence summaries, grade-level adjusted summaries,
    or summarize by extracting key points from a document. Let's take a quick look
    at each of these approaches.
  prefs: []
  type: TYPE_NORMAL
- en: Basic summary
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The easiest way to create a summary is to just add `tl;dr:` after the text
    you want to summarize. This will prompt GPT-3 to summarize the preceding text.
    It''s not a reliable way to summarize in every case, but it works quite well for
    many cases. For instance, the following prompt provides text about quantum mechanics,
    which was copied from [https://en.wikipedia.org/wiki/Quantum_mechanics](https://en.wikipedia.org/wiki/Quantum_mechanics):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The result from the previous prompt is shown in *Figure 2.7*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.7 – Text generation example – tl;dr: summary'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16854_02_007.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.7 – Text generation example – tl;dr: summary'
  prefs: []
  type: TYPE_NORMAL
- en: You will notice that the original text consisted of three paragraphs, but the
    resulting summary is just a few sentences. You can also direct GPT-3 to summarize
    the text in a single sentence.
  prefs: []
  type: TYPE_NORMAL
- en: One-sentence summary
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Another way to summarize text is to add **one-sentence summary:** after the
    text you'd like to summarize. This, along with setting the **Stop Sequence** to
    a period, results in a single sentence summary of the provided text.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following prompt will create a single-sentence summary of a paragraph from
    the OpenAI Terms of Use page located at https://beta.openai.com/terms-of-use:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The following screenshot shows the results of the preceding one-sentence summary
    prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.8 – Text generation example – one-sentence summary'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16854_02_008.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.8 – Text generation example – one-sentence summary
  prefs: []
  type: TYPE_NORMAL
- en: Depending on the text you want to summarize, a single sentence can be very helpful
    in simplifying content for you. Another way to simplify content is to rewrite
    it with simpler text. This can be done with grade-level summaries.
  prefs: []
  type: TYPE_NORMAL
- en: Grade-level summary
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'To summarize text using language that would be appropriate for someone of a
    certain age, you can use grade-level summaries. This can be done by following
    the text you want to summarize with something like the last sentence in the following
    example prompt. In this example, we''re using text that was copied from [https://en.wikipedia.org/wiki/Milky_Way](https://en.wikipedia.org/wiki/Milky_Way):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'In the following screenshot, you can see the results of the previous prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.9 – Text generation example – grade-level summarization'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16854_02_009.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.9 – Text generation example – grade-level summarization
  prefs: []
  type: TYPE_NORMAL
- en: Note that the summary shown in *Figure 2.9* is written in a way that would likely
    be understood by a third grader. In this case, GPT-3 is translating the text (in
    a way) for a younger reader. But you can also use GPT-3 to translate text into
    different languages.
  prefs: []
  type: TYPE_NORMAL
- en: Transforming text
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You can also use GPT-3 to transform text, for example, from one language to
    another, or from English to something else, such as emojis or software code. Let's
    take a look at a language translation example first.
  prefs: []
  type: TYPE_NORMAL
- en: Translation
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In the following screenshot, GPT-3 is being used to translate English to French.
    This is a **preset** that is provided in the Playground; we''ll talk more about
    presets in the next chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.10 – Text generation example – translation from English to French'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16854_02_010.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.10 – Text generation example – translation from English to French
  prefs: []
  type: TYPE_NORMAL
- en: 'You can see in *Figure 2.10* that a few translation examples were used in the
    prompt. This is helpful for some language translation tasks, but for many simple
    translations, you don''t even need examples. For example, the following prompt
    would likely be completed with the correct translation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Language translations are impressive for sure. But what if you want to translate
    between English and something other than another natural language? For instance,
    what about converting English to emoji text?
  prefs: []
  type: TYPE_NORMAL
- en: Conversion
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'This is another example that is provided by OpenAI. In this example, the prompt
    is used to convert the name of a movie into an emoji form. This works because
    emojis are just text characters, so they are part of the underlying GPT-3 training
    data. Notice that some of the emoji versions don''t just use the words in the
    title. For example, **Transformers** has a car and a robot emoji, which makes
    sense if you''ve seen the movie but not if you''re just looking at the word *transformers*.
    So, what''s going on? GPT-3 isn''t just using what''s provided in the prompt;
    it''s also using information from its massive model, which contains additional
    details about each of the movies:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.11 – Text generation example – conversion from text to emoji'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16854_02_011.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.11 – Text generation example – conversion from text to emoji
  prefs: []
  type: TYPE_NORMAL
- en: So, there are a lot of possibilities for text generation use cases but remember,
    GPT-3 is a general-purpose language processing system. So, generating text is
    just the beginning. Another common NLP use case is text classification.
  prefs: []
  type: TYPE_NORMAL
- en: Text classification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Text classification involves evaluating some provided text and assigning it
    a label, score, or some other attribute that classifies the text. Sentiment analysis
    is a common text classification use case, but that's just one of many text classifications
    tasks GPT-3 could be used for.
  prefs: []
  type: TYPE_NORMAL
- en: There are multiple ways to go about getting GPT-3 to classify text. In the simplest
    cases, you don't even need to provide examples; this is referred to as zero-shot
    classification and it is an easy way to do basic classifications, such as sentiment
    analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Zero-shot classification
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Recall from the last chapter that a zero-shot prompt doesn't provide any examples.
    Similarly, a **zero-shot classification** is a classification task with no examples.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an example of a zero-shot classification prompt. In this example, the
    goal is to perform sentiment analysis to determine whether a Twitter post is positive,
    neutral, or negative:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'You can see from the following screenshot the sentiment classification result
    from the zero-shot classification example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.12 – Text generation example – zero-shot classification'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16854_02_012.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.12 – Text generation example – zero-shot classification
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is another zero-shot classification example. This example shows that GPT-3
    can even comprehend text for a classification task. Notice the prompt provides
    a question and GPT-3 classifies the travel type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is a screenshot that shows the results:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.13 – Text generation example – zero-shot classification'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16854_02_013.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.13 – Text generation example – zero-shot classification
  prefs: []
  type: TYPE_NORMAL
- en: Zero-shot classification is about as simple as it gets and can be very useful
    for a variety of classification tasks. But sometimes classification tasks are
    a bit more complex and will require examples. For those cases, you'll use few-shot
    classifications.
  prefs: []
  type: TYPE_NORMAL
- en: Few-shot classification
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Another way to do classifications is with examples; this is referred to as **few-shot
    classification**. When you provide examples of how to classify text, the model
    can learn how to label the text based on the samples you provide. If the model
    is not able to classify your text correctly, providing examples will likely improve
    the results. This could be used for situations where you're using different terminology
    – for example, *emotion* instead of *sentiment*.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following prompt and subsequent screenshot show an example of a few-shot
    classification for classifying *animal lovers*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The results from the previous prompt are shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.14 – Text generation example – few-shot classification'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16854_02_014.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.14 – Text generation example – few-shot classification
  prefs: []
  type: TYPE_NORMAL
- en: Notice in *Figure 2.14* how just a few examples are enough for GPT-3 to understand
    how to classify any animal type. In that example, the classifications are being
    done one at a time, but GPT-3 can also do batch classifications.
  prefs: []
  type: TYPE_NORMAL
- en: Batch classification
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If you're able to successfully classify text using few-shot classification prompts,
    you can also show the model how to classify a list of items. This is referred
    to as **batch classification**.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following prompt shows an example of a prompt for doing batch classification.
    Notice that both classification examples and a batch classification example are
    provided in the prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Now that we've seen what GPT-3 can do for text generation and classification,
    let's look at how GPT-3 can be used for semantic search.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding semantic search
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A semantic search matches a search term or query words with semantically similar
    documents containing any amount of text. A simple keyword search might just look
    for words in the query that match words in the documents. However, a semantic
    search goes way beyond that. It looks at the meaning of words and ranks the documents
    with the highest-ranking document representing the document that is most semantically
    similar to the query. For example, suppose we have the query an animal with wings
    and five one-word documents: *dog, cat, snake, rabbit, eagle*. A semantic search
    would rank each of the five documents and assign the highest rank to the document
    containing the word eagle because it is most semantically similar to the query.'
  prefs: []
  type: TYPE_NORMAL
- en: Every time you query Google, you're using semantic search and like Google, GPT
    3 can also search over documents. However, rather than searching documents on
    the web, the documents are provided as part of the request to the OpenAI API or
    in a pre-uploaded file.
  prefs: []
  type: TYPE_NORMAL
- en: The search query might be a question, a statement, or just a few words. The
    query gets evaluated against the provided documents and a score is provided in
    the results for each document. The score is usually between 0 and 300 but can
    sometimes go higher. A higher score, above 200, usually means the document is
    semantically similar to the query.
  prefs: []
  type: TYPE_NORMAL
- en: When documents are provided with the API request, up to 200 documents can be
    included. However, you can go beyond the 200 document limit by uploading a documents
    file or sending multiple requests with the same query but different documents.
    We'll look at how that works in more detail in [*Chapter 4*](B16854_04_ePub_AM.xhtml#_idTextAnchor074)*,
    Working with the OpenAI API*.
  prefs: []
  type: TYPE_NORMAL
- en: Another consideration when using GPT 3 for semantic search is the engine you
    select. Recall from the last chapter that while davinci is the largest and most
    capable engine in terms of the tasks it can handle, other engines often perform
    better and cost less to use for certain tasks. When it comes to semantic search,
    the trade-off in terms of accuracy is often minimal. So, it makes sense to test
    the faster and more efficient engines like ada or babbage, which you can do using
    the **Semantic Search tool**.
  prefs: []
  type: TYPE_NORMAL
- en: The Semantic Search tool
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The Playground is used for testing prompts and completions. However, the Semantic
    Search tool can be used to test search queries. You can access the Semantic Search
    tool by visiting [https://gpttools.com/semanticsearch](https://gpttools.com/semanticsearch).
    It''s a simple web-based application (like the Playground) that lets you test
    semantic searches using the different engines. The following screenshot shows
    the Semantic Search tool:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.15 – The Semantic Search tool'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16854_02_015.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.15 – The Semantic Search tool
  prefs: []
  type: TYPE_NORMAL
- en: You'll notice that the Semantic Search tool requires an OpenAI **API key**.
    You can get your API key from the OpenAI API Keys page located at [https://beta.openai.com/account/api-keys](https://beta.openai.com/account/api-keys).You
    will need to be logged in to access the API Keys page. We will talk more about
    API keys in [*Chapter 4*](B16854_04_ePub_AM.xhtml#_idTextAnchor074), *Working
    with the OpenAI API*, but for now, the most important thing to know is that you
    should keep your API key private and never share it with others.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following screenshot shows the API Keys page (with the API key intentionally
    blurred out) where you can copy your API key for the Semantic Search tool:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.16 – The OpenAI API Keys page'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16854_02_016.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.16 – The OpenAI API Keys page
  prefs: []
  type: TYPE_NORMAL
- en: 'The Semantic Search tool also provides presets, which are templates to help
    you get familiar with different semantic search examples. The following screenshot
    shows the Semantic Search tool with the results of a search using the **Directors
    and Movies** preset:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.17 – Text generation example – Semantic Search tool'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16854_02_017.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.17 – Text generation example – Semantic Search tool
  prefs: []
  type: TYPE_NORMAL
- en: As you can hopefully see at this point, the possible use-cases for GPT 3 are
    pretty broad. We haven't even scratched the surface of what's possible or discussed
    how GPT 3 might be used in production applications. We will dive deeper into more
    specific examples and use-cases throughout the book. But in addition, there is
    a rapidly growing number of GPT 3 powered applications and examples online that
    you should check out for additional use-cases and inspiration. The range of online
    applications is impressive to say the least. You can start by Googling the term
    list of apps using GPT-3\. You'll find a growing number of curated lists and videos
    that highlighting a wide variety of GPT-3 powered apps and prompt examples. GPT-3
    Demo located at [https://gpt3demo.com/](https://gpt3demo.com/) is one worth checking
    out. There is also a blog post from OpenAI located at [https://openai.com/blog/gpt-3-apps/](https://openai.com/blog/gpt-3-apps/)
    that lists applications and industry use-cases and a number of usage and prompt
    example at [https://beta.openai.com/examples](https://beta.openai.com/examples).
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we looked at different potential use cases for GPT-3\. We discussed
    using GPT-3 for text generation, classification, and semantic search, and looked
    at examples of each. We introduced the Playground web-based testing tool and covered
    how to access it and get started using it. We looked at different ways to write
    prompts for text generation and text classification and how GPT-3 supports semantic
    search.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will dive deeper into the Playground and look at how
    different engines and API settings influence completion results.
  prefs: []
  type: TYPE_NORMAL
