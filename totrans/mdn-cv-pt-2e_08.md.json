["```py\n    %%writefile kaggle.json\n    {\"username\":\"XX\",\"key\":\"XX\"}\n    !pip install -q kaggle\n    !mkdir -p ~/.kaggle\n    !cp kaggle.json ~/.kaggle/\n    !ls ~/.kaggle\n    !chmod 600 /root/.kaggle/kaggle.json\n    !kaggle datasets download -d iarunava/cell-images-for-detecting-malaria\n    %pip install -U -q torch_snippets\n    !unzip -qq cell_images.zip\n    import os\n    from torch_snippets import * \n    ```", "```py\n    id2int = {'Parasitized': 0, 'Uninfected': 1} \n    ```", "```py\n    from torchvision import transforms as T\n    trn_tfms = T.Compose([\n                    T.ToPILImage(),\n                    T.Resize(128),\n                    T.CenterCrop(128),\n                    T.ColorJitter(brightness=(0.95,1.05), \n                                  contrast=(0.95,1.05), \n                                  saturation=(0.95,1.05), \n                                  hue=0.05),\n                    T.RandomAffine(5, translate=(0.01,0.1)),\n                    T.ToTensor(),\n                    T.Normalize(mean=[0.5, 0.5, 0.5], \n                                std=[0.5, 0.5, 0.5]),\n                ]) \n    ```", "```py\n    val_tfms = T.Compose([\n                    T.ToPILImage(),\n                    T.Resize(128),\n                    T.CenterCrop(128),\n                    T.ToTensor(),\n                    T.Normalize(mean=[0.5, 0.5, 0.5], \n                                std=[0.5, 0.5, 0.5]),\n                ]) \n    ```", "```py\n    class MalariaImages(Dataset):\n        def __init__(self, files, transform=None):\n            self.files = files\n            self.transform = transform\n            logger.info(len(self))\n        def __len__(self):\n            return len(self.files)\n        def __getitem__(self, ix):\n            fpath = self.files[ix]\n            clss = fname(parent(fpath))\n            img = read(fpath, 1)\n            return img, clss\n        def choose(self):\n            return self[randint(len(self))]\n        def collate_fn(self, batch):\n            _imgs, classes = list(zip(*batch))\n            if self.transform:\n                imgs = [self.transform(img)[None] for img in _imgs]\n            classes = [torch.tensor([id2int[clss]]) for class in classes]\n            imgs, classes = [torch.cat(i).to(device) for i in [imgs, classes]]\n            return imgs, classes, _imgs \n    ```", "```py\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    all_files = Glob('cell_images/*/*.png')\n    np.random.seed(10)\n    np.random.shuffle(all_files)\n    from sklearn.model_selection import train_test_split\n    trn_files, val_files = train_test_split(all_files, random_state=1)\n    trn_ds = MalariaImages(trn_files, transform=trn_tfms)\n    val_ds = MalariaImages(val_files, transform=val_tfms)\n    trn_dl = DataLoader(trn_ds, 32, shuffle=True, \n                        collate_fn=trn_ds.collate_fn)\n    val_dl = DataLoader(val_ds, 32, shuffle=False, \n                        collate_fn=val_ds.collate_fn) \n    ```", "```py\n    def convBlock(ni, no):\n        return nn.Sequential(\n            nn.Dropout(0.2),\n            nn.Conv2d(ni, no, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.BatchNorm2d(no),\n            nn.MaxPool2d(2),\n        )\n\n    class MalariaClassifier(nn.Module):\n        def __init__(self):\n            super().__init__()\n            self.model = nn.Sequential(\n                convBlock(3, 64),\n                convBlock(64, 64),\n                convBlock(64, 128),\n                convBlock(128, 256),\n                convBlock(256, 512),\n                convBlock(512, 64),\n                nn.Flatten(),\n                nn.Linear(256, 256),\n                nn.Dropout(0.2),\n                nn.ReLU(inplace=True),\n                nn.Linear(256, len(id2int))\n            )\n            self.loss_fn = nn.CrossEntropyLoss()\n        def forward(self, x):\n            return self.model(x)\n        def compute_metrics(self, preds, targets):\n            loss = self.loss_fn(preds, targets)\n            acc =(torch.max(preds, 1)[1]==targets).float().mean()\n            return loss, acc \n    ```", "```py\n    def train_batch(model, data, optimizer, criterion):\n        model.train()\n        ims, labels, _ = data\n        _preds = model(ims)\n        optimizer.zero_grad()\n        loss, acc = criterion(_preds, labels)\n        loss.backward()\n        optimizer.step()\n        return loss.item(), acc.item()\n    @torch.no_grad()\n    def validate_batch(model, data, criterion):\n        model.eval()\n        ims, labels, _ = data\n        _preds = model(ims)\n        loss, acc = criterion(_preds, labels)\n        return loss.item(), acc.item() \n    ```", "```py\n    model = MalariaClassifier().to(device)\n    criterion = model.compute_metrics\n    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n    n_epochs = 2\n    log = Report(n_epochs)\n    for ex in range(n_epochs):\n        N = len(trn_dl)\n        for bx, data in enumerate(trn_dl):\n            loss, acc = train_batch(model, data, optimizer, criterion)\n            log.record(ex+(bx+1)/N,trn_loss=loss,trn_acc=acc, end='\\r')\n        N = len(val_dl)\n        for bx, data in enumerate(val_dl):\n            loss, acc = validate_batch(model, data, criterion)\n            log.record(ex+(bx+1)/N,val_loss=loss,val_acc=acc, end='\\r')\n\n        log.report_avgs(ex+1) \n    ```", "```py\n    im2fmap = nn.Sequential(*(list(model.model[:5].children())+ \\\n                            list(model.model[5][:2].children()))) \n    ```", "```py\n    def im2gradCAM(x):\n        model.eval()\n        logits = model(x)\n        heatmaps = []\n        activations = im2fmap(x)\n        print(activations.shape)\n        pred = logits.max(-1)[-1]\n        # get the model's prediction\n        model.zero_grad()\n        # compute gradients with respect to \n        # model's most confident logit\n        logits[0,pred].backward(retain_graph=True)\n        # get the gradients at the required featuremap location\n        # and take the avg gradient for every featuremap\n        pooled_grads = model.model[-6][1].weight.grad.data.mean((1,2,3))\n        # multiply each activation map with \n        # corresponding gradient average\n        for i in range(activations.shape[1]):\n            activations[:,i,:,:] *= pooled_grads[i]\n        # take the mean of all weighted activation maps\n        # (that has been weighted by avg. grad at each fmap)\n        heatmap =torch.mean(activations, dim=1)[0].cpu().detach()\n        return heatmap, 'Uninfected' if pred.item() else 'Parasitized' \n    ```", "```py\n    SZ = 128\n    def upsampleHeatmap(map, img):\n        m,M = map.min(), map.max()\n        map = 255 * ((map-m) / (M-m))\n        map = np.uint8(map)\n        map = cv2.resize(map, (SZ,SZ))\n        map = cv2.applyColorMap(255-map, cv2.COLORMAP_JET)\n        map = np.uint8(map)\n        map = np.uint8(map*0.7 + img*0.3)\n        return map \n    ```", "```py\n    N = 20\n    _val_dl = DataLoader(val_ds, batch_size=N, shuffle=True, \\\n                         collate_fn=val_ds.collate_fn)\n    x,y,z = next(iter(_val_dl))\n    for i in range(N):\n        image = resize(z[i], SZ)\n        heatmap, pred = im2gradCAM(x[i:i+1])\n        if(pred=='Uninfected'):\n            continue\n        heatmap = upsampleHeatmap(heatmap, image)\n        subplots([image, heatmap], nc=2, figsize=(5,3), suptitle=pred) \n    ```", "```py\n    import os\n    if not os.path.exists('GTSRB'):\n        %pip install -U -q torch_snippets\n        !wget -qq https://sid.erda.dk/public/archives/\n            daaeac0d7ce1152aea9b61d9f1e19370/\n            GTSRB_Final_Training_Images.zip\n        !wget -qq https://sid.erda.dk/public/archives/\n            daaeac0d7ce1152aea9b61d9f1e19370/\n            GTSRB_Final_Test_Images.zip\n        !unzip -qq GTSRB_Final_Training_Images.zip\n        !unzip -qq GTSRB_Final_Test_Images.zip\n        !wget https://raw.githubusercontent.com/georgesung/\n         traffic_sign_classification_german/master/signnames.csv\n        !rm GTSRB_Final_Training_Images.zip \n           GTSRB_Final_Test_Images.zip\n    from torch_snippets import * \n    ```", "```py\n    classIds = pd.read_csv('signnames.csv')\n    classIds.set_index('ClassId', inplace=True)\n    classIds = classIds.to_dict()['SignName']\n    classIds = {f'{k:05d}':v for k,v in classIds.items()}\n    id2int = {v:ix for ix,(k,v) in enumerate(classIds.items())} \n    ```", "```py\n    from torchvision import transforms as T\n    trn_tfms = T.Compose([\n                    T.ToPILImage(),\n                    T.Resize(32),\n                    T.CenterCrop(32),\n                    # T.ColorJitter(brightness=(0.8,1.2), \n                    # contrast=(0.8,1.2), \n                    # saturation=(0.8,1.2), \n                    # hue=0.25),\n                    # T.RandomAffine(5,  #translate=(0.01,0.1)),\n                    **T.ToTensor(),**\n     **T.Normalize(mean=[****0.485****,** **0.456****,** **0.406****],** \n     **std=[****0.229****,** **0.224****,** **0.225****]),**\n                ])\n    val_tfms = T.Compose([\n                    T.ToPILImage(),\n                    T.Resize(32),\n                    T.CenterCrop(32),\n                    T.ToTensor(),\n                    T.Normalize(mean=[0.485, 0.456, 0.406], \n                                std=[0.229, 0.224, 0.225]),\n                ]) \n    ```", "```py\n    class GTSRB(Dataset):\n        def __init__(self, files, transform=None):\n            self.files = files\n            self.transform = transform\n            logger.info(len(self))\n        def __len__(self):\n            return len(self.files)\n        def __getitem__(self, ix):\n            fpath = self.files[ix]\n            clss = fname(parent(fpath))\n            img = read(fpath, 1)\n            return img, classIds[clss]\n        def choose(self):\n            return self[randint(len(self))]\n        def collate_fn(self, batch):\n            imgs, classes = list(zip(*batch))\n            if self.transform:\n                imgs =[self.transform(img)[None] for img in imgs]\n            classes = [torch.tensor([id2int[clss]]) for clss in classes]\n            imgs, classes = [torch.cat(i).to(device) for i in [imgs, classes]]\n            return imgs, classes \n    ```", "```py\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    all_files = Glob('GTSRB/Final_Training/Images/*/*.ppm')\n    np.random.seed(10)\n    np.random.shuffle(all_files)\n    from sklearn.model_selection import train_test_split\n    trn_files, val_files = train_test_split(all_files, random_state=1)\n    trn_ds = GTSRB(trn_files, transform=trn_tfms)\n    val_ds = GTSRB(val_files, transform=val_tfms)\n    trn_dl = DataLoader(trn_ds, 32, shuffle=True, \\\n                        collate_fn=trn_ds.collate_fn)\n    val_dl = DataLoader(val_ds, 32, shuffle=False, \\\n                        collate_fn=val_ds.collate_fn)\n    Define the SignClassifier model:\n    import torchvision.models as models\n    def convBlock(ni, no):\n        return nn.Sequential(\n                    nn.Dropout(0.2),\n                    nn.Conv2d(ni, no, kernel_size=3, padding=1),\n                    nn.ReLU(inplace=True),\n                    #nn.BatchNorm2d(no),\n                    nn.MaxPool2d(2),\n                )\n\n    class SignClassifier(nn.Module):\n        def __init__(self):\n            super().__init__()\n            self.model = nn.Sequential(\n                            convBlock(3, 64),\n                            convBlock(64, 64),\n                            convBlock(64, 128),\n                            convBlock(128, 64),\n                            nn.Flatten(),\n                            nn.Linear(256, 256),\n                            nn.Dropout(0.2),\n                            nn.ReLU(inplace=True),\n                            nn.Linear(256, len(id2int))\n                        )\n            self.loss_fn = nn.CrossEntropyLoss()\n        def forward(self, x):\n            return self.model(x)\n        def compute_metrics(self, preds, targets):\n            ce_loss = self.loss_fn(preds, targets)\n            acc =(torch.max(preds, 1)[1]==targets).float().mean()\n            return ce_loss, acc \n    ```", "```py\n    def train_batch(model, data, optimizer, criterion):\n        model.train()\n        ims, labels = data\n        _preds = model(ims)\n        optimizer.zero_grad()\n        loss, acc = criterion(_preds, labels)\n        loss.backward()\n        optimizer.step()\n        return loss.item(), acc.item()\n    @torch.no_grad()\n    def validate_batch(model, data, criterion):\n        model.eval()\n        ims, labels = data\n        _preds = model(ims)\n        loss, acc = criterion(_preds, labels)\n        return loss.item(), acc.item() \n    ```", "```py\n    model = SignClassifier().to(device)\n    criterion = model.compute_metrics\n    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n    n_epochs = 50\n    log = Report(n_epochs)\n    for ex in range(n_epochs):\n        N = len(trn_dl)\n        for bx, data in enumerate(trn_dl):\n            loss, acc = train_batch(model, data, optimizer, criterion)\n            log.record(ex+(bx+1)/N,trn_loss=loss, trn_acc=acc, end='\\r')\n        N = len(val_dl)\n        for bx, data in enumerate(val_dl):\n            loss, acc = validate_batch(model, data, criterion)\n            log.record(ex+(bx+1)/N, val_loss=loss, val_acc=acc, end='\\r')\n\n        log.report_avgs(ex+1)\n        if ex == 10: optimizer = optim.Adam(model.parameters(), lr=1e-4) \n    ```"]