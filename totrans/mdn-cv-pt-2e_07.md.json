["```py\n    import torchvision\n    import torch.nn as nn\n    import torch\n    import torch.nn.functional as F\n    from torchvision import transforms,models,datasets\n    !pip install torch_summary\n    from torchsummary import summary\n    device = 'cuda' if torch.cuda.is_available() else 'cpu' \n    ```", "```py\n    model = models.vgg16(pretrained=True).to(device) \n    ```", "```py\n    summary(model, torch.zeros(1,3,224,224)); \n    ```", "```py\n{1,2},{3,4,5},{6,7},{8,9,10},{11,12},{13,14},{15,16,17},{18,19},{20,21},{22,23,24},{25,26},{27,28},{29,30,31,32},{33,34,35},{36,37,38],{39} \n```", "```py\nmodel \n```", "```py\n    import torch\n    import torchvision\n    import torch.nn as nn\n    import torch.nn.functional as F\n    from torchvision import transforms,models,datasets\n    import matplotlib.pyplot as plt\n    from PIL import Image\n    from torch import optim\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    import cv2, glob, numpy as np, pandas as pd\n    from glob import glob\n    import torchvision.transforms as transforms\n    from torch.utils.data import DataLoader, Dataset \n    ```", "```py\n    !pip install -q kaggle\n    from google.colab import files\n    files.upload()\n    !mkdir -p ~/.kaggle\n    !cp kaggle.json ~/.kaggle/\n    !ls ~/.kaggle\n    !chmod 600 /root/.kaggle/kaggle.json \n    ```", "```py\n    !kaggle datasets download -d tongpython/cat-and-dog\n    !unzip cat-and-dog.zip \n    ```", "```py\n    train_data_dir = 'training_set/training_set'\n    test_data_dir = 'test_set/test_set' \n    ```", "```py\n    class CatsDogs(Dataset):\n        def __init__(self, folder):\n            cats = glob(folder+'/cats/*.jpg')\n            dogs = glob(folder+'/dogs/*.jpg')\n            self.fpaths = cats**[:****500****]****[:****500****]** + dogs\n     **self.normalize = transforms.Normalize(mean=[****0.485****,** \n    **0.456****,** **0.406****],std=[****0.229****,** **0.224****,** **0.225****])**\n            from random import shuffle, seed; seed(10); \n            shuffle(self.fpaths)\n            self.targets = [fpath.split('/')[-1].startswith('dog') for fpath \\\n                                                               in self.fpaths]\n        def __len__(self): return len(self.fpaths)\n        def __getitem__(self, ix):\n            f = self.fpaths[ix]\n            target = self.targets[ix]\n            im = (cv2.imread(f)[:,:,::-1])\n            im = cv2.resize(im, (224,224))\n            im = torch.tensor(im/255)\n            im = im.permute(2,0,1)\n            **im = self.normalize(im)** \n            return (\n                im.float().to(device), \n                torch.tensor([target]).float().to(device)\n            ) \n    ```", "```py\n    data = CatsDogs(train_data_dir) \n    ```", "```py\n    im, label = data[200]\n    plt.imshow(im.permute(1,2,0).cpu())\n    print(label) \n    ```", "```py\n    # tensor([0.], device='cuda:0') \n    ```", "```py\n    def get_model():\n        model = models.vgg16(pretrained=True) \n    ```", "```py\n     for param in model.parameters():\n            param.requires_grad = False \n    ```", "```py\n     model.avgpool = nn.AdaptiveAvgPool2d(output_size=(1,1)) \n    ```", "```py\n     model.classifier = nn.Sequential(nn.Flatten(),\n                                        nn.Linear(512, 128),\n                                        nn.ReLU(),\n                                        nn.Dropout(0.2),\n                                        nn.Linear(128, 1),\n                                        nn.Sigmoid()) \n    ```", "```py\n     loss_fn = nn.BCELoss()\n        optimizer = torch.optim.Adam(model.parmeters(),lr= 1e-3)\n        return model.to(device), loss_fn, optimizer \n    ```", "```py\n    !pip install torch_summary\n    from torchsummary import summary\n    model, criterion, optimizer = get_model()\n    summary(model, torch.zeros(1,3,224,224)) \n    ```", "```py\n    def train_batch(x, y, model, opt, loss_fn):\n        model.train()\n        prediction = model(x)\n        batch_loss = loss_fn(prediction, y)\n        batch_loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n        return batch_loss.item() \n    ```", "```py\n    @torch.no_grad()\n    def accuracy(x, y, model):\n        model.eval()\n        prediction = model(x)\n        is_correct = (prediction > 0.5) == y\n        return is_correct.cpu().numpy().tolist() \n    ```", "```py\n    def get_data():\n        train = CatsDogs(train_data_dir)\n        trn_dl = DataLoader(train, batch_size=32, huffle=True, \\\n                                              drop_last = True)\n        val = CatsDogs(test_data_dir)\n        val_dl = DataLoader(val, batch_size=32, huffle=True, drop_last = True)\n        return trn_dl, val_dl \n    ```", "```py\n    trn_dl, val_dl = get_data()\n    model, loss_fn, optimizer = get_model() \n    ```", "```py\n    train_losses, train_accuracies = [], []\n    val_accuracies = []\n    for epoch in range(5):\n        print(f\" epoch {epoch + 1}/5\")\n        train_epoch_losses, train_epoch_accuracies = [], []\n        val_epoch_accuracies = []\n        for ix, batch in enumerate(iter(trn_dl)):\n            x, y = batch\n            batch_loss = train_batch(x, y, modl, optimizer, loss_fn)\n            train_epoch_losses.append(batch_loss) \n        train_epoch_loss = np.array(train_epoch_losses).mean()\n        for ix, batch in enumerate(iter(trn_dl)):\n            x, y = batch\n            is_correct = accuracy(x, y, model)\n            train_epoch_accuracies.extend(is_correct)\n        train_epoch_accuracy = np.mean(train_epoch_accuracies)\n        for ix, batch in enumerate(iter(val_dl)):\n            x, y = batch\n            val_is_correct = accuracy(x, y, model)\n            val_epoch_accuracies.extend(val_is_correct)\n        val_epoch_accuracy = np.mean(val_epoch_accuracies)\n        train_losses.append(train_epoch_loss)\n        train_accuracies.append(train_epoch_accuracy)\n        val_accuracies.append(val_epoch_accuracy) \n    ```", "```py\n    epochs = np.arange(5)+1\n    import matplotlib.ticker as mtick\n    import matplotlib.pyplot as plt\n    import matplotlib.ticker as mticker\n    %matplotlib inline\n    plt.plot(epochs, train_accuracies, 'bo', \n             label='Training accuracy')\n    plt.plot(epochs, val_accuracies, 'r', \n             label='Validation accuracy')\n    plt.gca().xaxis.set_major_locator(mticker.MultipleLocator(1))\n    plt.title('Training and validation accuracy \\\n    with VGG16 \\nand 1K training data points')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.ylim(0.95,1)\n    plt.gca().set_yticklabels(['{:.0f}%'.format(x*100) \\\n                               for x in plt.gca().get_yticks()]) \n    plt.legend()\n    plt.grid('off')\n    plt.show() \n    ```", "```py\n    class ResLayer(nn.Module):\n         def __init__(self,ni,no,kernel_size,stride=1):\n            super(ResLayer, self).__init__()\n            padding = kernel_size - 2\n            self.conv = nn.Sequential( \\\n                            nn.Conv2d(ni, no, kernel_size, stride,\n                                      padding=padding),\n                            nn.ReLU()\n            ) \n    ```", "```py\n     def forward(self, x):\n             x = self.conv(x) + x\n             return x \n    ```", "```py\n    model = models.resnet18(pretrained=True).to(device)\n    model \n    ```", "```py\n    def get_model():\n        model = models.resnet18(pretrained=True)\n        for param in model.parameters():\n            param.requires_grad = False\n        model.avgpool = nn.AdaptiveAvgPool2d(output_size=(1,1))\n        model.fc = nn.Sequential(nn.Flatten(),\n        nn.Linear(512, 128),\n        nn.ReLU(),\n        nn.Dropout(0.2),\n        nn.Linear(128, 1),\n        nn.Sigmoid())\n        loss_fn = nn.BCELoss()\n        optimizer = torch.optim.Adam(model.parameter(),lr= 1e-3)\n        return model.to(device), loss_fn, optimizer \n    ```", "```py\n    import torchvision\n    import torch.nn as nn\n    import torch\n    import torch.nn.functional as F\n    from torchvision import transforms, models, datasets\n    from torchsummary import summary\n    import numpy as np, pandas as pd, os, glob, cv2\n    from torch.utils.data import TensorDataset,DataLoader,Dataset\n    from copy import deepcopy\n    from mpl_toolkits.mplot3d import Axes3D\n    import matplotlib.pyplot as plt\n    %matplotlib inline\n    from sklearn import cluster\n    device = 'cuda' if torch.cuda.is_available() else 'cpu' \n    ```", "```py\n    !git clone https://github.com/udacity/P1_Facial_Keypoints.git\n    !cd P1_Facial_Keypoints\n    root_dir = 'P1_Facial_Keypoints/data/training/'\n    all_img_paths = glob.glob(os.path.join(root_dir, '*.jpg'))\n    data = pd.rea_csv('P1_Facial_Keypoints/data/training_frames_keypoints.csv') \n    ```", "```py\n    class FacesData(Dataset): \n    ```", "```py\n     def __init__(self, df):\n            super(FacesData).__init__()\n            self.df = df \n    ```", "```py\n     self.normalize = transforms.Normalize(\n                                    mean=[0.485, 0.456, 0.406], \n                                    std=[0.229, 0.224, 0.225]) \n    ```", "```py\n     def __len__(self): return len(self.df) \n    ```", "```py\n     def __getitem__(self, ix):\n            img_path = 'P1_Facial_Keypoints/data/training/' + self.df.iloc[ix,0] \n    ```", "```py\n     img = cv2.imread(img_path)/255. \n    ```", "```py\n     kp = deepcopy(self.df.iloc[ix,1:].tolist())\n            kp_x = (np.array(kp[0::2])/img.shape[1]).tolist()\n            kp_y = (np.array(kp[1::2])/img.shape[0]).tolist() \n    ```", "```py\n     kp2 = kp_x + kp_y\n            kp2 = torch.tensor(kp2) \n            img = self.preprocess_input(img)\n            return img, kp2 \n    ```", "```py\n     def preprocess_input(self, img):\n            img = cv2.resize(img, (224,224))\n            img = torch.tensor(img).permute(2,0,1)\n            img = self.normalize(img).float()\n            return img.to(device) \n    ```", "```py\n     def load_img(self, ix):\n            img_path = 'P1_Facial_Keypoints/data/training/' + self.df.iloc[ix,0]\n            img = cv2.imread(img_path)\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)/255.\n            img = cv2.resize(img, (224,224))\n            return img \n    ```", "```py\n    from sklearn.model_selection import train_test_split\n    train, test = train_test_split(data, tst_size=0.2, random_state=101)\n    train_dataset = FacesData(train.reset_index(drop=True))\n    test_dataset = FacesData(test.reset_index(drop=True))\n    train_loader = DataLoader(train_dataset, batch_size=32)\n    test_loader = DataLoader(test_dataset, batch_size=32) \n    ```", "```py\n    def get_model():\n        model = models.vgg16(pretrained=True) \n    ```", "```py\n     for param in model.parameters():\n            param.requires_grad = False \n    ```", "```py\n     model.avgpool = nn.Sequential( nn.Conv2d(512,512,3),\n                                          nn.MaxPool2d(2),\n                                          nn.Flatten())\n        model.classifier = nn.Sequential(\n                                          nn.Linear(2048, 512),\n                                          nn.ReLU(),\n                                          nn.Dropout(0.5),\n                                          nn.Linear(512, 136),\n                                          nn.Sigmoid()\n                                        ) \n    ```", "```py\n     criterion = nn.L1Loss()\n        optimizer = torch.optim.Adam(mode.parameters(), lr=1e-4)\n        return model.to(device), criterion, optimizer \n    ```", "```py\n    model, criterion, optimizer = get_model() \n    ```", "```py\n    def train_batch(img, kps, model, optimizer, criterion):\n        model.train()\n        optimizer.zero_grad()\n        _kps = model(img.to(device))\n        loss = criterion(_kps, kps.to(device))\n        loss.backward()\n        optimizer.step()\n        return loss \n    ```", "```py\n    def validate_batch(img, kps, model, criterion):\n        model.eval()\n        _kps = model(img.to(device))\n        loss = criterion(_kps, kps.to(device))\n        return _kps, loss \n    ```", "```py\n    train_loss, test_loss = [], []\n    n_epochs = 50\n    for epoch in range(n_epochs):\n        print(f\" epoch {epoch+ 1} : 50\")\n        epoch_train_loss, epoch_test_loss = 0, 0\n        for ix, (img,kps) in enumerate(train_loader):\n            loss = train_batch(img, kps, mdel, optimizer, criterion)\n            epoch_train_loss += loss.item() \n        epoch_train_loss /= (ix+1)\n        for ix,(img,kps) in enumerate(test_loadr):\n           ps,  loss = validate_batch(img, kps, model, criterion)\n            epoch_test_loss += loss.item() \n        epoch_test_loss /= (ix+1)\n        train_loss.append(epoch_train_loss)\n        test_loss.append(epoch_test_loss) \n    ```", "```py\n    epochs = np.arange(50)+1\n    import matplotlib.ticker as mtick\n    import matplotlib.pyplot as plt\n    import matplotlib.ticker as mticker\n    %matplotlib inline\n    plt.plot(epochs, train_loss, 'bo', label='Training loss')\n    plt.plot(epochs, test_loss, 'r', label='Test loss')\n    plt.title('Training and Test loss over increasing epochs')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.grid('off')\n    plt.show() \n    ```", "```py\n    ix = 0\n    plt.figure(figsize=(10,10))\n    plt.subplot(221)\n    plt.title('Original image')\n    im = test_dataset.load_img(ix)\n    plt.imshow(im)\n    plt.grid(False)\n    plt.subplot(222)\n    plt.title('Image with facial keypoints')\n    x, _ = test_dataset[ix]\n    plt.imshow(im)\n    kp = model(x[None]).flatten().detach().cpu()\n    plt.scatter(kp[:68]*224, kp[68:]*224, c='r')\n    plt.grid(False)\n    plt.show() \n    ```", "```py\n    !pip install -qU face-alignment\n    import face_alignment, cv2 \n    ```", "```py\n    !wget https://www.dropbox.com/s/2s7x/Hema.JPG \n    ```", "```py\n    fa = face_alignment.FaceAlignment(face_alignment.LandmarksType.TWO_D, \n                        flip_input=False, device='cpu') \n    ```", "```py\n    input = cv2.imread('Hema.JPG')\n    preds = fa.get_landmarks(input)[0]\n    print(preds.shape)\n    # (68,2) \n    ```", "```py\n    import matplotlib.pyplot as plt\n    %matplotlib inline\n    fig,ax = plt.subplots(figsize=(5,5))\n    plt.imshow(cv2.cvtColor(cv2.imread('Hema.JPG'), cv2.COLOR_BGR2RGB))\n    ax.scatter(preds[:,0], preds[:,1], marker='+', c='r')\n    plt.show() \n    ```", "```py\n    fa = face_alignment.FaceAlignment(face_alignment.**LandmarksType.THREE_D**, \n                              flip_input=False, device='cpu')\n    input = cv2.imread('Hema.JPG')\n    preds = fa.get_landmarks(input)[0]\n    import pandas as pd\n    df = pd.DataFrame(preds)\n    df.columns = ['x','y','z']\n    import plotly.express as px\n    fig = px.scatter_3d(df, x = 'x', y = 'y', z = 'z')\n    fig.show() \n    ```", "```py\n    import torch\n    import numpy as np, cv2, pandas as pd, glob, time\n    import matplotlib.pyplot as plt\n    %matplotlib inline\n    import torch.nn as nn\n    from torch import optim\n    import torch.nn.functional as F\n    from torch.utils.data import Dataset, DataLoader\n    import torchvision\n    from torchvision import transforms, models, datasets\n    device = 'cuda' if torch.cuda.is_available() else 'cpu' \n    ```", "```py\n    from pydrive.auth import GoogleAuth\n    from pydrive.drive import GoogleDrive\n    from google.colab import auth\n    from oauth2client.client import GoogleCredentials\n    auth.authenticate_user()\n    gauth = GoogleAuth()\n    gauth.credentials=GoogleCredentials.get_application_default()\n    drive = GoogleDrive(gauth)\n    def getFile_from_drive( file_id, name ):\n        downloaded = drive.CreateFile({'id': file_id})\n        downloaded.GetContentFile(name)\n    getFile_from_drive('1Z1RqRo0_JiavaZw2yzZG6WETdZQ8qX86', \n                       'fairface-img-margin025-trainval.zip')\n    getFile_from_drive('1k5vvyREmHDW5TSM9QgB04Bvc8C8_7dl-', \n                                'fairface-label-train.csv')\n    getFile_from_drive('1_rtz1M1zhvS0d5vVoXUamnohB6cJ02iJ', \n                                  'fairface-label-val.csv')\n    !unzip -qq fairface-img-margin025-trainval.zip \n    ```", "```py\n    trn_df = pd.read_csv('fairface-label-train.csv')\n    val_df = pd.read_csv('fairface-label-val.csv')\n    trn_df.head() \n    ```", "```py\n    IMAGE_SIZE = 224\n    class GenderAgeClass(Dataset):\n        def __init__(self, df, tfms=None):\n            self.df = df\n            self.normalize = transforms.Normalize(\n                                    mean=[0.485, 0.456, 0.406], \n                                    std=[0.229, 0.224, 0.225]) \n    ```", "```py\n     def __len__(self): return len(self.df) \n    ```", "```py\n     def __getitem__(self, ix):\n            f = self.df.iloc[ix].squeeze()\n            file = f.file\n            gen = f.gender == 'Female'\n            age = f.age\n            im = cv2.imread(file)\n            im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n            return im, age, gen \n    ```", "```py\n     def preprocess_image(self, im):\n            im = cv2.resize(im, (IMAGE_SIZE, IMAGE_SIZE))\n            im = torch.tensor(im).permute(2,0,1)\n            im = self.normalize(im/255.)\n            return im[None] \n    ```", "```py\n     def collate_fn(self, batch):\n            'preprocess images, ages and genders'\n            ims, ages, genders = [], [], []\n            for im, age, gender in batch:\n                im = self.preprocess_image(im)\n                ims.append(im)\n                ages.append(float(int(age)/80))\n                genders.append(float(gender))\n            ages, genders = [torch.tensor(x).to(device).float() \\\n                                for x in [ages, genders]]\n            ims = torch.cat(ims).to(device)\n            return ims, ages, genders \n    ```", "```py\n    trn = GenderAgeClass(trn_df)\n    val = GenderAgeClass(val_df) \n    ```", "```py\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    train_loader = DataLoader(trn, batch_size=32, shuffle=True, \n                              drop_last=True,collate_fn=trn.collate_fn)\n    test_loader = DataLoader(val, batch_size=32, \n                             collate_fn=val.collate_fn)\n    a,b,c, = next(iter(train_loader))\n    print(a.shape, b.shape, c.shape) \n    ```", "```py\n    def get_model():\n        model = models.vgg16(pretrained = True) \n    ```", "```py\n     for param in model.parameters():\n            param.requires_grad = False \n    ```", "```py\n     model.avgpool = nn.Sequential(\n                            nn.Conv2d(512,512, kernel_size=3),\n                            nn.MaxPool2d(2),\n                            nn.ReLU(),\n                            nn.Flatten()\n                           ) \n    ```", "```py\n     class ageGenderClassifier(nn.Module):\n            def __init__(self):\n                super(ageGenderClassifier, self).__init__() \n    ```", "```py\n     self.intermediate = nn.Sequential(\n                                        nn.Linear(2048,512),\n                                        nn.ReLU(),\n                                        nn.Dropout(0.4),\n                                        nn.Linear(512,128),\n                                        nn.ReLU(),\n                                        nn.Dropout(0.4),\n                                        nn.Linear(128,64),\n                                        nn.ReLU(),\n                                      ) \n    ```", "```py\n     self.age_classifier = nn.Sequential(\n                                            nn.Linear(64, 1),\n                                            nn.Sigmoid()\n                                        )\n                self.gender_classifier = nn.Sequential(\n                                            nn.Linear(64, 1),\n                                            nn.Sigmoid()\n                                           ) \n    ```", "```py\n     def forward(self, x):\n                x = self.intermediate(x)\n                age = self.age_classifier(x)\n                gender = self.gender_classifier(x)\n                return gender, age \n    ```", "```py\n     model.classifier = ageGenderClassifier() \n    ```", "```py\n     gender_criterion = nn.BCELoss()\n        age_criterion = nn.L1Loss()\n        loss_functions = gender_criterion, age_criterion\n        optimizer = torch.optim.Adam(modelparameters(),lr= 1e-4)\n        return model.to(device), loss_functions, optimizer \n    ```", "```py\n    model, criterion, optimizer = get_model() \n    ```", "```py\n    def train_batch(data, model, optimizer, criteria): \n    ```", "```py\n     model.train()\n        ims, age, gender = data\n        optimizer.zero_grad()\n        pred_gender, pred_age = model(ims) \n    ```", "```py\n     gender_criterion, age_criterion = criteria\n        gender_loss = gender_criterion(predgender.squeeze(), gender)\n        age_loss = age_criterion(pred_age.squeeze(), age) \n    ```", "```py\n     total_loss = gender_loss + age_loss\n        total_loss.backward()\n        optimizer.step()\n        return total_loss \n    ```", "```py\n    def validate_batch(data, model, criteria): \n    ```", "```py\n     model.eval()\n        with torch.no_grad():\n            pred_gender, pred_age = model(img) \n    ```", "```py\n     gender_criterion, age_criterion = criteria\n        gender_loss = gender_criterion(prd_gender.squeeze(), gender)\n        age_loss = age_criterion(pred_age.squeeze(), age) \n    ```", "```py\n     total_loss = gender_loss + age_loss\n        pred_gender = (pred_gender > 0.5).squeeze()\n        gender_acc = (pred_gender == gender).float().sum()\n        age_mae = torch.abs(age - pred_age).float().sum()\n        return total_loss, gender_acc, age_mae \n    ```", "```py\n    import time\n    model, criteria, optimizer = get_model()\n    val_gender_accuracies = []\n    val_age_maes = []\n    train_losses = []\n    val_losses = []\n    n_epochs = 5\n    best_test_loss = 1000\n    start = time.time() \n    ```", "```py\n    for epoch in range(n_epochs):\n        epoch_train_loss, epoch_test_loss = 0, 0\n        val_age_mae, val_gender_acc, ctr = 0, 0, 0\n        _n = len(train_loader) \n    ```", "```py\n     for ix, data in enumerate(train_loader):\n            loss = train_batch(data, model, optimizer, criteria)\n            epoch_train_loss += loss.item() \n    ```", "```py\n     for ix, data in enumerate(test_loader):\n            loss, gender_acc, age_mae  validate_batch(data, model, criteria)\n            epoch_test_loss += loss.item()\n            val_age_mae += age_mae\n            val_gender_acc += gender_acc\n            ctr += len(data[0]) \n    ```", "```py\n     val_age_mae /= ctr\n        val_gender_acc /= ctr\n        epoch_train_loss /= len(train_loader)\n        epoch_test_loss /= len(test_loader) \n    ```", "```py\n     elapsed = time.time()-start\n        best_test_loss = min(best_test_loss, epoch_test_loss)\n        print('{}/{} ({:.2f}s - {:.2f}s remaining)'.format(\\\n                        epoch+1, n_epchs, time.time()-start, \\\n                        (n_epochs-epoch)*(elapsed/(epoch+1))))\n        info = f'''Epoch: {epoch+1:03d}\n                    \\tTrain Loss: {epoch_train_loss:.3f}\n                    \\tTest:\\{epoch_test_loss:.3f}\n                    \\tBest Test Loss: {best_test_loss:.4f}'''\n        info += f'\\nGender Accuracy: \n                    {val_gender_acc*100:.2f}%\\tAge MAE: \\\n                                        {val_age_mae:.2f}\\n'\n        print(info) \n    ```", "```py\n     val_gender_accuracies.append(val_gender_acc)\n        val_age_maes.append(val_age_mae) \n    ```", "```py\n    epochs = np.arange(1,(n_epochs+1))\n    fig,ax = plt.subplots(1,2,figsize=(10,5))\n    ax = ax.flat\n    ax[0].plot(epochs, val_gender_accuracies, 'bo')\n    ax[1].plot(epochs, val_age_maes, 'r')\n    ax[0].set_xlabel('Epochs')  ; ax[1].set_xlabel('Epochs')\n    ax[0].set_ylabel('Accuracy'); ax[1].set_ylabel('MAE')\n    ax[0].set_title('Validation Gender Accuracy')\n    ax[0].set_title('Validation Age Mean-Absolute-Error')\n    plt.show() \n    ```", "```py\n    !wget https://www.dropbox.com/s/6kzr8/Sindhura.JPG \n    ```", "```py\n    im = cv2.imread('/content/Sindhura.JPG')\n    im = trn.preprocess_image(im).to(device) \n    ```", "```py\n    gender, age = model(im)\n    pred_gender = gender.to('cpu').detach().numpy()\n    pred_age = age.to('cpu').detach().numpy() \n    ```", "```py\n    im = cv2.imread('/content/Sindhura.JPG')\n    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n    plt.imshow(im)\n    print('predicted gender:',np.here(pred_gender[0][0]<0.5, 'Male','Female'),\n          '; Predicted age', int(pred_age[0][0]*80)) \n    ```", "```py\n    !pip install torch_snippets\n    from torch_snippets import * \n    ```", "```py\n    class GenderAgeClass(Dataset):\n        ...\n        def __getitem__(self, ix):\n            ...\n            age = f.age\n            **im = read(file,** **1****)**\n            return im, age, gen\n        def preprocess_image(self, im):\n            **im = resize(im, IMAGE_SIZE)**\n            im = torch.tensor(im).permute(2,0,1)\n            ... \n    ```", "```py\n    trn = GenderAgeClass(trn_df)\n    val = GenderAgeClass(val_df)\n    train_loader = DataLoader(trn, batch_size=32, shuffle=rue, \\\n                              drop_last=True, collate_fn=trn.collate_fn)\n    test_loader = DataLoader(val, batch_siz=32, collate_fn=val.collate_fn)\n    im, gen, age = trn[0]\n    **show(im, title=****f'Gender:** **{gen}****\\nAge:** **{age}****'****, sz=****5****)** \n    ```", "```py\n    train_loader = DataLoader(trn, batch_size=32, shuffleTrue, \\\n                              drop_last=True, collate_fn=trn.collate_fn)\n    test_loader = DataLoader(val, batch_sie=32, \\\n                             collate_fn=val.collate_fn)\n    ims, gens, ages = next(iter(train_loader))\n    **inspect(ims, gens, ages)** \n    ```", "```py\n============================================================\nTensor Shape: torch.Size([32, 3, 224, 224]) Min: -2.118 Max: 2.640 Mean: 0.133 dtype: torch.float32\n============================================================\nTensor Shape: torch.Size([32]) Min: 0.000 Max: 1.000 Mean: 0.594 dtype: torch.float32 \n============================================================\nTensor Shape: torch.Size([32]) Min: 0.087 Max: 0.925 Mean: 0.400 dtype: torch.float32 \n============================================================ \n```", "```py\nmodel, criterion, optimizer = get_model()\nn_epochs = 5\n**log = Report(n_epochs)**\nfor epoch in range(n_epochs):\n    N = len(train_loader)\n    for ix, data in enumerate(train_loader):\n        total_loss,gender_loss,age_loss = train_batch(data, \n                                  model, optimizer, criterion)\n        **log.record(epoch+(ix+****1****)/N, trn_loss=total_loss, end=****'\\r'****)**\n    N = len(test_loader)\n    for ix, data in enumerate(test_loader):\n        total_loss,gender_acc,age_mae = validate_batc(data, \\\n                                           model, criterion)\n        gender_acc /= len(data[0])\n        age_mae /= len(data[0])\n        **log.record(epoch+(ix+****1****)/N, val_loss=total_loss,** \n **val_gender_acc=gender_acc,** \n **val_age_mae=age_mae, end=****'\\r'****)**\n    **log.report_avgs(epoch+****1****)**\n**log.plot_epochs()** \n```", "```py\n    !wget -q https://www.dropbox.com/s/6kzr8/5_9.JPG\n    IM = read('/content/5_9.JPG', 1)\n    im = trn.preprocess_image(IM).to(device)\n    gender, age = model(im)\n    pred_gender = gender.to('cpu').detach().numpy()\n    pred_age = age.to('cpu').detach().numpy()\n    info = f'predicted gender: {np.where(pred_gender[0[0]<0.5, \\\n    \"Male\",\"Female\")}\\n Predicted age {int(pred_age[0][0]*80)}'\n    show(IM, title=info, sz=10) \n    ```"]