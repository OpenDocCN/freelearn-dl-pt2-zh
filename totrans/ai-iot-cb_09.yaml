- en: Deploying to the Edge
  prefs: []
  type: TYPE_NORMAL
- en: Performing **machine learning and operations** (**MLOps**) on a single computer
    can be challenging. When we think about training, deploying, and maintaining models
    across thousands of computers, the complexity of doing so can be daunting. Luckily,
    there are ways of reducing this complexity using tools such as containerization
    and **continuous integration/continuous deployment** (**CI/CD**) pipelines. In
    this chapter, we are going to discuss deploying models in a way that is secure,
    updatable, and optimized for the hardware at hand.
  prefs: []
  type: TYPE_NORMAL
- en: In terms of building updatable models, we are going to discuss using Azure IoT
    Hub Edge devices to enable **over-the-air** (**OTA**) updates across a single management
    plane. We are also going to use device twins to maintain the fleet and push configuration
    settings going to our models. In addition, we'll learn how to train a model on
    one type of computer architecture, such as x86, and run it on ARM. Finally, we
    are going to discuss how to use fog computing to perform distributed machine learning
    across different types of devices.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter consist of the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: OTA updating MCUs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying modules with IoT Edge
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Offloading to the web with TensorFlow.js
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying mobile models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Maintaining your fleet with device twins
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Enabling distributed machine learning with fog computing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's get started!
  prefs: []
  type: TYPE_NORMAL
- en: OTA updating MCUs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: OTA updates are essential for deploying security updates, new functionality,
    and updating models. There are two different techniques for OTA updates. The first
    is building a custom program that, ideally, runs on its own program or thread
    that is different than the main program you are trying to update. This software
    downloads the new firmware to the flash memory and registers and starts the new
    firmware. If the new firmware fails to start, the custom software can then start
    up the working version of the software. This usually involves saving half of the
    flash memory available for OTA updates.
  prefs: []
  type: TYPE_NORMAL
- en: The second way is to use a system such as Azure IoT Edge to update the Docker
    containers on the device. This requires a device that is running a full operating
    system, such as Raspbian, Ubuntu, or Windows. The majority of IoT devices do not
    have the compute needed to support IoT Edge. In this recipe, we will talk about
    OTA updates on MCUs, while in the next, we will discuss OTA updates with IoT Edge.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this recipe, we are going to use an ESP32 to do an OTA update for a small
    MCU device. With the ESP32, we are going to be programming in the IDF framework. **Espressif
    IoT Development Framework** (**ESP-IDF**) is a low-level programming framework.
    It has fewer pre-built components than the Arduino framework but is faster and
    more geared to industrial applications.
  prefs: []
  type: TYPE_NORMAL
- en: 'For development, we are going to be using VS Code with the **PlatformIO** extension
    added. We can create a project by going to the **PlatformIO** home page and selecting
    **+ New Project**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/66a3ab03-88e2-4e4b-83d2-092966f5c1f2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'From there, add a project name, and then select the development board and the
    development framework you will be using. In my case, I am using the NodeMCU-32S
    as my development board:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/23760114-2ef8-489f-bca8-2d76c1939978.png)'
  prefs: []
  type: TYPE_IMG
- en: Then, rename `empty.c` to `main.c` in your root directory and start coding.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The steps for this recipe are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the necessary libraries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Set the firmware version, certificates, and buffer size:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Create an HTTP event handler:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we are going to create an infinite loop (for the sake of brevity, we
    will forget the machine learning algorithm):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Check for OTA updates. Doing so will download the manifest. Then, if the version
    is different than the current version, it triggers a download and restarts the
    device:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Initialize the Wi-Fi:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'In the main loop, initiate the Wi-Fi and create two tasks (the OTA update task
    and our mock machine learning task):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The program has three tasks. The first task is to set up and ensure that it
    is connected to the Wi-Fi. It will not do anything else until it establishes a
    connection. This program uses Free RTOS as its real-time operating system. RTOS
    allows threads to execute independently. This allows us to have two non-blocking
    threads. Our first thread performs a machine learning task, while the second performs
    an update task. The update task allows us to poll our web server on a less frequent
    basis.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The OTA updater in this recipe needs a manifest so that it can check against
    its current version and find the file to download. The following is a `.json`
    file example of the manifest:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: OTA updates are an important thing for any IoT device. Most manufactures of
    silicon devices, such as the ESP32 or STM32, have solved this OTA update issue.
    These manufacturers usually have sample code that will help you quickly start
    your project.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying modules with IoT Edge
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Deploying models to the edge can be risky. In the previous recipe, we made a
    simple update to a small IoT device. If the update bricked the entire fleet of
    devices, they may be lost forever. If we had a more powerful device, then we could
    spin up separate programs that work independently of each other. If the update
    failed, the program could revert to a version that worked. That is where IoT Edge
    comes in. IoT Edge specifically handles the problem of running multiple programs
    on an IoT device by using Docker technology. This, for example, could be mining
    equipment that needs to perform geofencing operations, machine learning for device
    failure predictions, and reinforcement learning for self-driving cars. Any one
    of these programs could be updated without impacting the other modules.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we are going to use Azure's IoT Hub and IoT Edge capabilities.
    This will involve using Docker and IoT Hub to push models down to devices.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For this recipe, you will need an Azure IoT Hub and an Azure Container Registry
    in the cloud. You will also need **Visual Studio Code** (**VS Code**) with the
    Azure IoT extension installed and a Raspberry Pi. There are three main components
    you will need for this recipe. The first is our Raspberry Pi, which must be set
    up. This will involve installing Moby, a lightweight version of Docker. Next is
    writing the code. In our case, we will be writing the code on an x86-based laptop
    and deploying the models to an ARM-based Raspberry Pi. Finally, we will be deploying
    the code to a device or series of devices.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up our Raspberry Pi
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'For this recipe, we are going to code on the Raspberry Pi remotely from a laptop
    computer. To do that, we are going to need to allow SSH and then connect to the
    Raspberry Pi via VS Code. On the Raspberry Pi, you will need to go to **Menu**
    | **Preferences** | **Raspberry Pi Configuration**. Then, click on **Interfaces**
    and enable **SSH**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/cb11cffd-7d55-40a5-ba0a-4fe5b62e4659.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In a Terminal window, type in the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: This will give you the IP address of your Raspberry Pi. Take that IP address
    and, back on your desktop computer, in VS Code, install the SSH plugin and connect
    to the Raspberry Pi. Then, connect to the Raspberry Pi using VS Code by using
    the Connect to SSH button. From there, follow the wizard to connect to the Raspberry
    Pi using the device's IP address and password. Once you've done this, you can
    create a new project on the device.
  prefs: []
  type: TYPE_NORMAL
- en: Also, while you are on the device, you will need to install the IoT Edge agent.
    To do this, follow the instructions at [https://docs.microsoft.com/en-us/azure/iot-edge/how-to-install-iot-edge-linux](https://docs.microsoft.com/en-us/azure/iot-edge/how-to-install-iot-edge-linux).
  prefs: []
  type: TYPE_NORMAL
- en: Coding setup
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Now, create a new IoT Edge project. To do this, open Visual Studio and install
    the Azure IoT Edge extension, as well as the Docker extension. Then, using *Ctrl*
    + *Shift* + *P*, open the command window, type `Azure IoT Edge:` into the **Search**
    bar, and select **Azure IoT Edge: New IoT Edge Solution**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a8bc36ae-632c-4008-a118-eefd631831f7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Once you''ve done this, you will see a wizard that asks you to name the project.
    Then, the wizard will have you add a module. A project can have numerous modules
    that do different tasks. These modules can be written in different languages or
    use Azure Machine Learning Services to incorporate prebuilt models on that platform.
    In our case, we are making a custom Python module. It will then ask you for the
    location of the Azure Container Registry for the module, so provide the location
    as required, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b929f143-77c2-4aef-b529-0156265686b1.png)'
  prefs: []
  type: TYPE_IMG
- en: From here, we can develop against the Raspberry Pi. One thing to note on developing
    machine learning on a Raspberry Pi is that tasks such as environmental builds
    can take 10 times longer. A machine learning Docker build that takes minutes on
    a 16-core desktop with 32 GB RAM can take 10 times the duration when it is forced
    to compile on 1 core with 2 GB RAM.
  prefs: []
  type: TYPE_NORMAL
- en: At this point, VS Code's code generator has created a `main.py` file that has
    a starter template that receives a message from IoT Hub and echoes it back. In
    the *How to do it...* section, we will modify that to include a stub out for your
    machine learning code. In the *There's more...* section, we are going to talk
    about building the module for the ARM32 environment.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The steps for this recipe are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the `main.py` file, import the necessary libraries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a stub for your ML code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a message-sending function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a message-receiving function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Start our message sender thread and our message receiver thread:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Set the standard Python main program entry point:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this recipe, we learned how to prepare a device and development environment
    for developing an edge module that you can deploy your code on. The IoT Edge coding
    paradigm works on receiving messages, performing actions, and then sending messages.
    In the code for this recipe, we separated these actions into different tasks that
    can be run independently of each other. This allows us to perform actions such
    as getting and sending messages in a slow time loop and evaluating our data in
    a faster loop. To do this, we used `asyncio`, which is a library that facilitates
    multi-threading in Python. Once you have your code ready, you can build a Docker
    container and deploy that to other devices with the edge module installed or an
    entire fleet of devices. In the *There's more...* section, we will discuss how
    to do that.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now that you have added the code to the device, you will need to build the
    code locally on the device''s architecture. Once you''ve ensured that the device
    image is working, you can upload it to your container registry. This ensures you
    have the devices within your IoT Hub. To do this, go into your Visual Studio project
    and right-click on the `module.json` file. A new context menu will appear that
    will allow you to either build locally or build and push to your container registry:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4738f3a5-a696-416c-86a3-68b0a25b0cef.png)'
  prefs: []
  type: TYPE_IMG
- en: 'From here, you can create a deployment manifest by right-clicking on the `deployment.template.json`
    file and selecting **Generate IoT Edge Deployment Manifest**. VS Code will generate
    a `config` folder with a `deployment.arm32.json` file inside it:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b130fb83-f807-4ea8-9ff4-b94a9b89fd18.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Locate and right-click on the `deployemtn.arm32.json` file; a new context menu
    will appear that will allow you to deploy to a single device or a fleet of devices:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4031812e-bf3f-48df-94f9-cbd7891399fc.png)'
  prefs: []
  type: TYPE_IMG
- en: This very same menu allows you to also push to a fleet of devices. Once you've
    deployed your update, you can view the update in the portal. If you have that
    deployment update the device twins, you can use that to query the status of the
    deployments across your fleet.
  prefs: []
  type: TYPE_NORMAL
- en: Offloading to the web with TensorFlow.js
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the biggest drivers of failures in IoT is cost. Often, devices are sold
    at a low fixed price and then have a reoccurring cost for the device manufacturer.
    There are multiple ways of reducing reoccurring costs. One of these is to offload
    some of the machine learning compute to the device or application accessing the
    data. In this recipe, we are going to use TensorFlow.js to offload the expensive
    compute to the browser of the person looking at the web page.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For this recipe, we are going to be building off of the *Implementing LSTM to
    predict device failure* recipe from [Chapter 4](a40f2c07-0e51-46c6-a3cf-66d5c46477c4.xhtml),
    *Deep Learning for Predictive Maintenance*, where we looked at the NASA *Turbofan
    Run to Failure* dataset. You can find the Databricks notebooks in the repository
    for this chapter. For this recipe, we are going to be using the MLflow experiment
    to retrieve our model. We will convert that model into one that can be run on
    the frontend using TensorFlow.js. Before we get started with TensorFlow.js, you
    will need to run `pip install tensorflowjs`.
  prefs: []
  type: TYPE_NORMAL
- en: 'From there, you will need to find the model you downloaded from the MLflow
    artifact; that is, the saved Keras model. To do this, run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Here, `model.h5` is the saved Keras LSTM model from the predictive maintenance
    dataset and `tfjs_model` is the folder that the model will be placed in.
  prefs: []
  type: TYPE_NORMAL
- en: From there, open Visual Studio. Here, we will be writing two files. The first
    will be an HTML file, while the second will be a JavaScript file. Once you've
    created these files, you can run them locally with the `webserver.py` file in
    the GitHub repository for this chapter. This will run your `index.html` file and
    any other files in your web browser at `http://localhost:8080/index.html`. Something
    else that's in the GitHub repository for this chapter is a `data.json` file that
    represents a web service where data is returned to the web page.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The steps for this recipe are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the `index.js` file, add a `GetData` function that gets the data from `data.json`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Make a function that pulls in the model and evaluates the data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Create an `index.html` file that will call your `js` file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this recipe, we took a pre-trained model written for Python and, using a
    conversion utility, converted it into something that will work on the web. Then,
    we pulled in data from a web service and evaluated it against the machine learning
    model. Finally, we displayed the text `"Needs Maintenance"` when our machine learning
    model has 80% confidence that the Turbofan engine is nearing the end of its remaining
    useful life.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In recent years, web browsers have taken on vastly increased functionality.
    One aspect of this is the ability to handle data and process it in the background.
    An example of this can be found in the GitHub repository for this book. It's called
    `Dexie` and shows an example of adding data to a browser's database. You can also
    use service workers in modern web browsers. **Service workers** are background
    jobs that can be run on web browsers in the background. They can even work when
    a page is not active.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying mobile models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Many IoT scenarios require that you have a graphical user interface; that is,
    a high level of compute, Bluetooth, and Wi-Fi and a cellular network. Most modern
    cell phones have these. An inexpensive IoT device can talk to an app on a smartphone
    via Bluetooth and use that app to perform ML and talk to the cloud.
  prefs: []
  type: TYPE_NORMAL
- en: Using cell phones can cut the time to market for IoT devices. These devices
    can use a secure and easily updatable app to send data to the cloud. The portability
    of cell phones is an appeal but also a drawback. Having a device constantly communicating
    with the cloud can drain a cell phone's battery so that it lasts for as little
    as 8 hours. Because of this, companies often look to edge processing to perform
    compute tasks such as machine learning. This allows the device to send data less
    frequently.
  prefs: []
  type: TYPE_NORMAL
- en: How cell phones are used for IoT is ubiquitous. Companies such as Fitbit and
    Tile use low-power **Bluetooth Low Energy** (**BLE**) to send data to consumer
    cell phones. The IoT devices themselves can be low power and offload most of the
    work to the attached cell phones. Other devices, such as patient heart monitors,
    warehouse inventory tools, and voice-activated kiosks, can have dedicated smart
    devices designed specifically for the needs of the application.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we are going to show you how to use TensorFlow Lite on Android.
    We are going to learn how to use a simple Android kiosk keyword-activated application
    and deploy it to a device. We are then going to learn how to sideload it into
    a device.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this recipe, we are going to create a simple Android Studio application
    and add machine learning code to it. For this, you will need to download and install
    Android Studio. From there, create a new project and follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Upon opening Android Studio, from the Start menu, select **+ Start a new Android
    Studio project**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/f76be9d6-6b6b-418f-b499-c4b04de03bb9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Then, you will need to select a UI template. In this recipe, we are going to
    select an empty activity:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/0f95da9e-f2e3-4e84-b7a8-e9d9c238382d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'On the next screen, you will see a wizard that gives you the option to give
    the project a name and select a language for it. For this project, we will be
    selecting **Java** as our language:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/b90d24b6-8d7a-4f0b-902f-8a1d0b3e6b1c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'With that, a new project will open. Now, we need to import TensorFlow Lite
    into our project. To do this, go to the **build.gradle (Module: app)** section
    under **Gradle Scripts**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/19679e74-2352-4d71-932b-04918ac0f9b1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In the `build.gradle` JSON file under the `dependencies` section, add a reference
    to TensorFlow Lite (`implementation ''org.tensorflow:tensorflow-lite:+''`):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/e9e58f0e-c894-4dc2-acea-9a211f0980b8.png)'
  prefs: []
  type: TYPE_IMG
- en: 'From there, in Android Studio, right-click on the **app** folder, select **New**,
    then select **Folder** and then **Assets folder**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/f2b96f78-93a0-489d-aa5f-9d8f2e93e614.png)'
  prefs: []
  type: TYPE_IMG
- en: This is where we will put our trained model. Just as we used a `tfliteJS` conversion
    tool in the *Offloading to the web with TensorFlow.js* recipe, we can use the
    `tflite` conversion tool to convert our model.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The steps for this recipe are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the header section of the `MainActivity.java` file, add the necessary reference
    to TensorFlow:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'In the `variables` section, initialize the `tflite` interpreter:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'In the `OnCreate` method, add the code that will load the model from the file
    into the `tflite` interpreter:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, create a method that will load the model file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'In a method that is called from a Bluetooth data feed, perform the necessary
    inference:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Similar to the *Offloading to the web with TensorFlow.js* recipe, this recipe
    takes in a TensorFlow Lite model, performs inference, and returns the probability.
    The TensorFlow Lite model works on small devices such as Android and can be used
    in applications and services.
  prefs: []
  type: TYPE_NORMAL
- en: Maintaining your fleet with device twins
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A device twin is a set of tools designed to help us work with a fleet. They
    can be used to pass information down to a device, such as what model that device
    should be using. They can be used to pass more stateful information back to the
    cloud, such as the model's actual error rate.
  prefs: []
  type: TYPE_NORMAL
- en: Device twins have two sides. On the device side, there is a JSON file that acts
    like a writable configuration file, while on the cloud side, there is a writable
    database of properties. These two sides sync in an orderly way to allow you to
    reason about your fleet.
  prefs: []
  type: TYPE_NORMAL
- en: One advantage of a device twin is that you can see if model deployment actually
    worked. Often, machine learning models are updated with information changes, and
    new models are pushed down to the devices. These models can trigger out-of-memory
    exceptions and fail; they can also brick the device. Often, in an IoT product's
    life cycle, hardware may be substituted if a manufacture changes or certain components
    are no longer available.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we get started, we need to go over some basic concepts. We will do more
    of a deep dive on this topic in the *How it works...* section. A device twin consists
    of three parts:'
  prefs: []
  type: TYPE_NORMAL
- en: A **tags area**, which is responsible for generic tags such as the device's
    name, location, or owner. The tags area's data is set by the cloud.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The next is the **desired properties**. The desired properties section is also
    set by the cloud. Conceptually, it is what state the cloud wishes the device to
    be in. This, for example, could be a model version or a threshold.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The final property is a **reported property**. This property is set by the device.
    It can be a data value or the response to the desired property.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If, for example, the desired property or model version changes, we can attempt
    to update to the latest version and set our reported property to the desired version
    if the update worked. If it does not work, then we can query for that in the cloud.
    We can also use the tag section to update our devices in sets called **update
    rings**. We can use an update ring to obtain a rolling update, which allows us
    to update very few devices at first and multiple devices later. We can also use
    it to deploy different models depending on certain characteristics of a device,
    such as location and owner.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this recipe, we are going to use Azure IoT Hub and Python. The Python version
    in our example needs to be above 3.6\. We will need to install the following libraries:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'You will also need to get a device connection string from IoT Hub. In the *Setting
    up an IoT Hub* recipe of [Chapter 1](a6e87d27-4456-40a7-a006-5fdb54960858.xhtml),
    *Setting Up the IoT and AI Environment*, we showed you how to set up IoT Hub in
    Azure. From there, you need to get a key for that individual device. To do this,
    navigate to the IoT Hub you created and click on the **IoT Devices** menu item
    in the left panel. Then, click the **+** button and add a device with symmetric
    key authentication:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b797a507-52b5-46cd-9754-f01c9fd5bc8e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'From here, you will see the device appear in the device list, as shown in the
    following screenshot. You can click on that item and get the device key:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f218bac9-7686-4b9e-ab0a-ae728af66fe6.png)'
  prefs: []
  type: TYPE_IMG
- en: You will also need to go into the shared access policy menu item and copy the
    service policy connection string. This connection string is for connecting to
    IoT Hub so that you can manage your fleet of devices. The previous key was for
    an individual device.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The steps for this recipe are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'On the device side, import the necessary libraries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a `main()` function and connect to the device:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a twin listener:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a listen task:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Listen for a quit signal:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Wait for the user finish signal and disconnect:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Use `asyncio` to run the loop:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'On the cloud side (this is the computer helping you manage the fleet) use the
    following code to set the desired machine learning model version. First, import
    the necessary libraries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Connect to IoT Hub with the service connection string:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Set the desired property so that it''s the model version:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Later, in another Python file, we will query to see if the versions were updated.
    First, we import the necessary libraries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'We can then query for all of the devices with reported properties that do not
    match our desired properties:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This recipe had three different code segments. The first was on the device side.
    This code gathers any changes that were made to the device via the device twin.
    In the next section, we instructed IoT Hub to update a reported property on a
    specific device. We then queried our fleet of devices and checked if all of our
    devices are updated to the model we wanted to use.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A device twin is basically a large JSON file that resides on both the cloud
    and device side. It can be used to adjust settings, control the device, and set
    metadata about the device. There is another service that builds upon a device
    twin. It is called a **digital twin**. Digital twins have the same JSON file sync
    between devices and the cloud. They also have the additional benefit of connecting
    devices in a graph. A graph is a way of linking devices to each other. This can
    be done geographically. In other words, you can link devices by their locations.
    It can also link devices together locally. This is useful when you have devices
    that are related. A smart city, for example, would want devices that are related
    geographically. In this smart city, we would want to know if all the intersections
    in a geographic location had stopped traffic. In a factory, there could be manufacturing
    lines that contain related data. These manufacturing lines could contain dozens
    of IoT devices that provide different types of readings. Digital twins can help
    us diagnose problems with root cause analysis on slow assembly lines.
  prefs: []
  type: TYPE_NORMAL
- en: Enabling distributed ML with fog computing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Working in IoT generally means working with large data. Sensors can be verbose
    and the devices can be large as well. The CERN's particle accelerator, for example,
    generates over a petabyte a second. Sending this raw data to a central repository would
    be impractical. Many companies facing extremely large datasets or extremely fast-moving
    datasets can face challenges when it comes to dealing with their data.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we are going to distribute a workload across several systems,
    thereby allowing one system to take an image and another to process it. A small
    device, in our example, could take the image and stream it to an industrial PC
    or a set of servers in a factory. We are going to use `docker` and `docker-compose`
    here, while for our algorithm, we are going to use YOLO's (an image classification
    algorithm) OpenCV implementation.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This recipe will be quite verbose in terms of the amount of code we'll be seeing,
    but everything will be done in Docker. You can use VS Code's Docker extension
    to work directly within the Docker container. You will also need a device with
    a webcam attached to it. This could be a laptop or a Raspberry Pi with a webcam
    – it doesn't really matter. For this recipe, we are going to set up a machine
    learning service, a camera streaming service, and a service that allows the devices
    to know where other devices are, and allow you to view your classification across
    your entire fleet of devices.
  prefs: []
  type: TYPE_NORMAL
- en: Although this is fairly simple, listing the code for all of the containers would
    take dozens of pages. For the sake of brevity, in this recipe, we are going to
    show the computer vision module. The rest of the modules can be run using Docker
    and the code in the GitHub repository for this book.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The steps for this recipe are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'On your compute device, download the machine learning model files for YOLO:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a `CPU` folder and create an `__init__.py` file inside it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a `manifest.py` file that will send the capabilities of the compute
    server to a centralized server:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a `Yolo.py` file and import the necessary libraries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Initialize the page as a Flask page:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Initialize our drawing variables:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'Import the model class names:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a helper function to get the output layers:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a helper function that will draw a rectangle around the identified objects
    and insert the classification text:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a `Yolo` method that takes in an image and a neural network and then
    downscales the image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Set the image as the input on the neural network and perform the YOLO analysis:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'Initialize the variables and set the confidence threshold:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Turn the machine learning result set into a set of coordinates we can apply
    to the image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'Suppress any of our bounding boxes that do not meet the threshold criteria:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'Get the bounding boxes and draw them inside the images:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Return the image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a function called `gen` that will import the model and continuously
    pull images from the camera device:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'Resize and color adjust the image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'Perform the machine learning algorithm and stream back the results:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a web address that will grab the URL parameters and put them through
    the algorithm:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'Back inside the root folder, create a `manifest.json` file that will broadcast
    the capabilities of the machine we are using:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a `runcpu.py` file. This will be the file that starts the Flask server
    and registers the other code files:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This fog computing recipe shows how several different types of systems can be
    brought together to work as one. In this recipe, we showed the device code that
    grabs a video stream from a different system, perform a compute on it, and then
    passes it along to another system. Our final system in this case is a web application.
  prefs: []
  type: TYPE_NORMAL
- en: For different systems to communicate, there needs to be centralized state management.
    In this recipe, we used Flask and Redis. Every machine on our cluster registers
    its state and capabilities every 10 minutes. This allows the other machines to
    utilize machines that are on a network, thereby not bottlenecking on one machine.
    When a new machine comes online, it simply registers its state with our state
    server; as long as it keeps broadcasting, it is available to use.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This recipe is dependent on other components. These components are in the GitHub
    repository for this chapter, under `AI_Benchtest`. You can start the programs
    by going into their respective folders and running `docker` or `docker-compose`.
    To run the camera server in a Terminal, go into the `AI_Benchtest_API` folder
    and run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, you must run the `AI_Benchtest_Cam` module. In a Terminal, `CD` into
    the `AI_Benchtest_Cam` folder and run the same `docker-compose` command that you
    ran to get the API server running. At this point, both the camera and compute
    servers will be up and running and transmitting their status to the API server.
    Next, you will need to run a UI server so that you can give commands to the other
    servers. To do this, `CD` into the `AI_Benchtest_API` folder and run the following
    `docker` command to start the UI application:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
