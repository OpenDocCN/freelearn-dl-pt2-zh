- en: Diving Deep into Neural Networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will explore the different modules of deep learning architectures
    that are used to solve real-world problems. In the previous chapter, we used low-level
    operations of PyTorch to build modules such as a network architecture, a loss
    function, and an optimizer. In this chapter, we will explore some of the important
    components of neural networks required to solve real-world problems, along with
    how PyTorch abstracts away a lot of complexity by providing a lot of high-level
    functions. Toward the end of the chapter, we will build algorithms that solve
    real-world problems, such as regression, binary classification, and multi-class
    classification.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will go through the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Diving into the various building blocks of neural networks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Non-linear activations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: PyTorch non-linear activations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Image classification using deep learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Diving into the building blocks of neural networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As we learned in the previous chapter, training a deep learning algorithm requires
    the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Building a data pipeline
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Building a network architecture
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Evaluating the architecture using a loss function
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Optimizing the network architecture weights using an optimization algorithm
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the previous chapter, the network was composed of a simple linear model built
    using PyTorch numerical operations. Though building a neural architecture for
    a dummy problem using numerical operations is easier, it quickly becomes complicated
    when we try to build architectures required to solve complex problems in different
    areas, such as computer vision and **natural language processing** (**NLP**).
  prefs: []
  type: TYPE_NORMAL
- en: 'Most of the deep learning frameworks, such as PyTorch, TensorFlow, and Apache
    MXNet, provide higher-level functionalities that abstract a lot of this complexity.
    These higher-level functionalities are called **layers** across the deep learning
    frameworks. They accept input data, apply transformations like the ones we saw
    in the previous chapter, and output the data. To solve real-world problems, deep
    learning architectures consist of a number of layers ranging from 1 to 150, or
    sometimes more than that. Abstracting low-level operations and training deep learning
    algorithms would look like the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ed4b0c80-1533-41b5-a9db-2277ca598964.png)'
  prefs: []
  type: TYPE_IMG
- en: Any deep learning training involves getting data, building an architecture (which, in
    general, means putting a bunch of layers together), evaluating the accuracy of
    the model using a loss function, and then optimizing the algorithm by optimizing
    the weights of our network. Before looking at solving some real-world problems,
    we will come to understand higher-level abstractions provided by PyTorch for building
    layers, loss functions, and optimizers.
  prefs: []
  type: TYPE_NORMAL
- en: Layers – the fundamental blocks of neural networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Throughout the rest of the chapter, we will come across different types of
    layers. To begin, let''s try to understand one of the most important layers, the
    linear layer, which does exactly what our network architecture from the previous
    chapter does. The linear layer applies a linear transformation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d2a33a05-36e5-470b-ad68-5bceb4bb555f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'What makes it powerful is the fact that the entire function that we wrote in
    the previous chapter can be written in a single line of code, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The `linear_layer` function, in the preceding code, will accept a tensor of
    size 5 and outputs a tensor of size 3 after applying linear transformation. Let''s
    look at a simple example of how to do that:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'We can access the trainable parameters of the layer using the weights:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'This will give the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/12c92313-c6e1-4dd2-898c-49259174fd6d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In the same way, we can access the trainable parameters of the layer using
    the `bias` attributes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'This will give the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b714e1e0-402d-41ac-8e0d-2dd5d0208f13.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Linear layers are called by different names, such as **dense** or **fully connected**
    layers, across different frameworks. Deep learning architectures used for solving
    real-world use cases generally contain more than one layer. In PyTorch, we can
    do it in a simple approach by passing the output of one layer to another layer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'This will give the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/90faf1d2-6128-4d96-9db1-288c87a33548.png)'
  prefs: []
  type: TYPE_IMG
- en: Each layer will have its own learnable parameters. The idea behind using multiple
    layers is that each layer will learn some kind of pattern that the later layers
    will build on. There is a problem with adding just linear layers together, as
    they fail to learn anything new beyond a simple representation of a linear layer.
    Let's see, through a simple example, why it does not make sense to stack multiple
    linear layers together.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s say we have two linear layers with the following weights:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Layers** | **Weight1** |'
  prefs: []
  type: TYPE_TB
- en: '| Layer1 | 3.0 |'
  prefs: []
  type: TYPE_TB
- en: '| Layer2 | 2.0 |'
  prefs: []
  type: TYPE_TB
- en: 'The preceding architecture with two different layers can be simply represented
    as a single layer with a different layer. Hence, just stacking multiple linear
    layers will not help our algorithms to learn anything new. Sometimes, this can
    be unclear, so we can visualize the architecture with the following mathematical
    formulas:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f0e265b2-53da-4c84-bcf9-6c568a2be009.png)'
  prefs: []
  type: TYPE_IMG
- en: To solve this problem, we have different non-linearity functions that help in
    learning different relationships, rather than only focusing on linear relationships.
  prefs: []
  type: TYPE_NORMAL
- en: There are many different non-linear functions available in deep learning. PyTorch
    provides these non-linear functionalities as layers and we will be able to use
    them the same way we used the linear layer.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some of the popular non-linear functions are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Sigmoid
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tanh
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ReLU
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Leaky ReLU
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Non-linear activations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Non-linear activations are functions that take inputs and then apply a mathematical
    transformation and produce an output. There are several non-linear operations
    that we come across in practice. We will go through some of the popular non-linear
    activation functions.
  prefs: []
  type: TYPE_NORMAL
- en: Sigmoid
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The sigmoid activation function has a simple mathematical form, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b2eb43b2-87c7-4245-883c-3898cd47c06b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The sigmoid function intuitively takes a real-valued number and outputs a number
    in the range between 0 and 1\. For a large negative number, it returns close to
    0 and for a large positive number, it returns close to 1\. The following plot
    represents different sigmoid function outputs:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8ee76a76-bb32-4261-b9e8-f0424a3d61da.png)'
  prefs: []
  type: TYPE_IMG
- en: The sigmoid function has been historically used across different architectures,
    but in recent times, it has gone out of popularity as it has one major drawback.
    When the output of the sigmoid function is close to 0 or 1, the gradients for
    the layers before the sigmoid function are close to 0 and, hence, the learnable
    parameters of the previous layer get gradients close to 0 and the weights do not
    get adjusted often, resulting in dead neurons.
  prefs: []
  type: TYPE_NORMAL
- en: Tanh
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The tanh non-linearity function squashes a real-valued number in the range
    of -1 and 1\. The tanh also faces the same issue of saturating gradients when
    tanh outputs extreme values close to -1 and 1\. However, it is preferred to sigmoid,
    as the output of tanh is zero-centered:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d26c7062-fb82-4cf8-9999-73a93a483eac.png)'
  prefs: []
  type: TYPE_IMG
- en: ReLU
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'ReLU has become more popular in recent years; we can find either its usage
    or one of its variants'' usages in almost any modern architecture. It has a simple
    mathematical formulation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/492e8a00-e58c-41ff-a641-3ed489af1375.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Simply put, ReLU squashes any input that is negative to 0 and leaves positive
    numbers as they are. We can visualize the ReLU function as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1f30c721-5738-431b-86f0-901db482758c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Some of the pros and cons of using ReLU are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: It helps the optimizer to find the right set of weights sooner. More technically,
    it makes the convergence of stochastic gradient descent faster.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is computationally inexpensive, as we are just thresholding and not calculating
    anything, as we did for the sigmoid and tangent functions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'ReLU has one disadvantage: when a large gradient passes through it during backward
    propagation, it often becomes non-responsive; these are called **dead neutrons**,
    which can be controlled by carefully choosing the learning rate. We will discuss
    how to choose learning rates when we discuss the different ways to adjust the
    learning rate in [Chapter 4](bfebc11a-90af-4c67-ab9a-3118061abaf3.xhtml), *Deep
    Learning for Computer Vision*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Leaky ReLU
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Leaky ReLU is an attempt to solve a dying problem where, instead of saturating
    to 0, we saturate to a very small number such as 0.001\. For some use cases, this
    activation function provides a superior performance to others, but it is not consistent.
  prefs: []
  type: TYPE_NORMAL
- en: PyTorch non-linear activations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'PyTorch has most of the common non-linear activation functions implemented
    for us already and it can be used like any other layer. Let''s look at a quick
    example of how to use the ReLU function in PyTorch:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'This will result in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b21f9cf1-b94d-41d2-8a31-f993a2af681e.png)'
  prefs: []
  type: TYPE_IMG
- en: In the preceding example, we take a tensor with two positive values and two
    negative values and apply a ReLU on it, which thresholds the negative numbers
    to 0 and retains the positive numbers as they are.
  prefs: []
  type: TYPE_NORMAL
- en: Now we have covered most of the details required for building a network architecture,
    let's build a deep learning architecture that can be used to solve real-world
    problems. In the previous chapter, we used a simple approach so that we could
    focus only on how a deep learning algorithm works. We will not be using that style
    to build our architecture anymore; rather, we will be building the architecture
    in the way it is supposed to be built in PyTorch.
  prefs: []
  type: TYPE_NORMAL
- en: The PyTorch way of building deep learning algorithms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'All networks in PyTorch are implemented as classes, subclassing a PyTorch class
    called `nn.Module`, and should implement the `__init__` and `forward` methods.
    Inside the `init` function, we initialize any layers, such as the linear layer,
    which we covered in the previous section. In the `forward` method, we pass our
    input data into the layers that we initialized in our `init` method and return
    our final output. The non-linear functions are often directly used in the `forward`
    function and some use it in the `init` method too. The following code snippet
    shows how a deep learning architecture is implemented in PyTorch:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: If you are new to Python, some of the preceding code could be difficult to understand,
    but all it is doing is inheriting a parent class and implementing two methods
    in it. In Python, we subclass by passing the parent class as an argument to the
    class name. The `init` method acts as a constructor in Python and `super` is used
    to pass on arguments of the child class to the parent class, which in our case
    is `nn.Module`.
  prefs: []
  type: TYPE_NORMAL
- en: Model architecture for different machine learning problems
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The kind of problem we are solving will decide mostly what layers we will use,
    starting from a linear layer to **long short-term memory** (**LSTM**) for sequential
    data. Based on the type of the problem you are trying to solve, your last layer
    is determined. There are three problems that we generally solve using any machine
    learning or deep learning algorithms. Let''s look at what the last layer would
    look like:'
  prefs: []
  type: TYPE_NORMAL
- en: For a regression problem, such as predicting the price of a t-shirt to sell,
    we would use the last layer as a linear layer with an output of 1, which outputs
    a continuous value.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To classify a given image as a t-shirt or shirt, you would use a sigmoid activation
    function, as it outputs values either closer to 1 or 0, which is generally called
    a **binary classification problem**.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For multi-class classification, where we have to classify whether a given image
    is a t-shirt, a jeans, a shirt, or a dress, we would use a softmax layer at the
    end of our network. Let's try to understand intuitively what softmax does without
    going into the math of it. It takes inputs from the previous linear layer, for
    example, and outputs the probabilities for a given number of examples. In our
    example, it would be trained to predict four probabilities for each type of image.
    Remember, all these probabilities always add up to 1.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Loss functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once we have defined our network architecture, we are left with two important
    steps. One is calculating how good our network is at performing a particular task
    of regression, classification, and the next is optimizing the weight.
  prefs: []
  type: TYPE_NORMAL
- en: The optimizer (gradient descent) generally accepts a scalar value, so our loss
    function should generate a scalar value that has to be minimized during our training.
    Certain use cases, such as predicting where an obstacle is on the road and classifying
    it as a pedestrian or not, would require two or more loss functions. Even in such
    scenarios, we need to combine the losses into a single scalar for the optimizer
    to minimize. We will discuss examples of combining multiple losses into a single
    scalar in detail with a real-world example in [Chapter 8](aeec9e18-7c1d-4ae2-b362-ea7a9d94dd22.xhtml), *Transfer
    Learning with Modern Network Architectures*.
  prefs: []
  type: TYPE_NORMAL
- en: In the previous chapter, we defined our own loss function. PyTorch provides
    several implementations of commonly used loss functions. Let's take a look at
    the loss functions used for regression and classification.
  prefs: []
  type: TYPE_NORMAL
- en: 'The commonly used loss function for regression problems is **mean square error**
    (**MSE**). It is the same loss function we implemented in our previous chapter.
    We can use the loss function implemented in PyTorch, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'For classification, we use cross-entropy loss. Before looking at the math for
    cross-entropy, let''s understand what cross-entropy loss does. It calculates the
    loss of a classification network, predicting the probabilities, which should sum
    up to 1, like our softmax layer. Cross-entropy loss increases when the predicted
    probability diverges from the correct probability. For example, if our classification
    algorithm predicts 0.1 probability of the following image being a cat, but it
    is actually a panda, then the cross-entropy loss will be higher. If it predicts
    similar to the actual labels, then the cross-entropy loss will be lower:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b768541b-eb8e-4c54-be93-bc7503bf92f7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s look at a sample implementation of how this actually happens in Python
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'To use cross-entropy loss in a classification problem, we really do not need
    to be worried about what happens inside—all we have to remember is that the loss
    will be high when our predictions are bad and low when predictions are good. PyTorch
    provides us with an implementation of the loss, which we can use, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Some of the other loss functions that come as part of PyTorch are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '| L1 loss | Mostly used as a regularizer; we will discuss it further in [Chapter
    4](bfebc11a-90af-4c67-ab9a-3118061abaf3.xhtml), *Deep Learning for Computer Vision*
    |'
  prefs: []
  type: TYPE_TB
- en: '| MSE loss | Used as a loss function for regression problems |'
  prefs: []
  type: TYPE_TB
- en: '| Cross-entropy loss | Used for binary and multi-class classification problems
    |'
  prefs: []
  type: TYPE_TB
- en: '| NLL Loss | Used for classification problems and allows us to use specific
    weights to handle imbalanced datasets |'
  prefs: []
  type: TYPE_TB
- en: '| NLL Loss2d | Used for pixel-wise classification, mostly for problems related
    to image segmentation |'
  prefs: []
  type: TYPE_TB
- en: Optimizing network architecture
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Once we have calculated the loss of our network, we will optimize the weights
    to reduce the loss, thus improving the accuracy of the algorithm. For the sake
    of simplicity, let''s see these optimizers as black boxes that take loss functions
    and all the learnable parameters and move them slightly to improve our performance.
    PyTorch provides most of the commonly used optimizers required in deep learning.
    If you want to explore what happens inside these optimizers and have a mathematical
    background, I would strongly recommend the following blogs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[http://ruder.io/optimizing-gradient-descent/](http://ruder.io/optimizing-gradient-descent/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://medium.com/datadriveninvestor/overview-of-different-optimizers-for-neural-networks-e0ed119440c3](https://medium.com/datadriveninvestor/overview-of-different-optimizers-for-neural-networks-e0ed119440c3)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Some of the optimizers that PyTorch provides are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`ASGD`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Adadelta`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Adagrad`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Adam`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Adamax`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`LBFGS`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`RMSprop`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Rprop`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`SGD`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`SparseAdam`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We will get into the details of some of the algorithms in [Chapter 4](bfebc11a-90af-4c67-ab9a-3118061abaf3.xhtml),
    *Deep Learning for Computer Vision*, along with some of the advantages and trade-offs.
    Let''s walk through some of the important steps in creating any optimizer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding example, we created an SGD optimizer that takes all the learnable
    parameters of your network as the first argument and a learning rate that determines
    what ratio of change can be made to the learnable parameters. In [Chapter 4](bfebc11a-90af-4c67-ab9a-3118061abaf3.xhtml),
    *Deep Learning for Computer Vision*, we will get into more details of learning
    rates and momentum, which is an important parameter of optimizers. Once you create
    an optimizer object, we need to call `zero_grad()` inside our loop, as the parameters
    will accumulate the gradients created during the previous optimizer call:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Once we call backward on the loss function, which calculates the gradients (the
    quantity by which learnable parameters need to change), we call `optimizer.step()`,
    which makes the actual changes to our learnable parameter.
  prefs: []
  type: TYPE_NORMAL
- en: Now we have covered most of the components required to help a computer see or
    recognize images. Let's build a complex deep learning model that can differentiate
    between dogs and cats to put all the theory into practice.
  prefs: []
  type: TYPE_NORMAL
- en: Image classification using deep learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The most important step in solving any real-world problem is getting the data.
    In order to test our deep learning algorithms in this chapter, we will use a dataset
    provided in a GitHub repository from an user called `ardamavi`. We will use this
    dataset again in [Chapter 4](bfebc11a-90af-4c67-ab9a-3118061abaf3.xhtml), *Deep
    Learning for Computer Vision*, which will be on **convolution neural networks**
    (**CNNs**) and some of the advanced techniques that we can use to improve the
    performance of our image recognition models.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can download the data from the following link: [https://github.com/ardamavi/Dog-Cat-Classifier/tree/master/Data/Train_Data](https://github.com/ardamavi/Dog-Cat-Classifier/tree/master/Data/Train_Data).
    The dataset contains images of dogs and cats. The preprocessing of data and the
    creation of training, validation, and testing splits are some of the important
    steps that need to be performed before we can implement an algorithm.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Most frameworks make it easier to read images and tag them to their labels
    when provided in the following format. That means that each class should have
    a separate folder of its images. Here, all cat images should be in the `cat` folder
    and dog images in the `dog` folder:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4bc4e6f1-acf8-44c1-8ae2-825002378119.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Python makes it easy to put the data into the right format. Let''s quickly
    take a look at the code and then we will go through the important parts of it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a shuffled index that can be used to create a validation dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a validation directory for holding training and validation images:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Copy a small subset of images into the validation folder:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Copy a small subset of images into the training folder:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: All the preceding code does is retrieve all the files and pick a sample of images
    for creating a testing and validation set. It segregates all the images into the
    two categories of cats and dogs. It is a common and important practice to create
    a separate validation set, as it is not fair to test our algorithms on the same
    data it is trained on. To create a dataset, we create a list of numbers that are
    in the range of the length of the images in a shuffled order. The shuffled numbers
    act as an index for us to pick a bunch of images to create our dataset. Let's
    go through each section of the code in detail.
  prefs: []
  type: TYPE_NORMAL
- en: 'We use the `glob` method to return all the files in the particular path:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: When there are a huge number of images, we can also use `iglob`, which returns
    an iterator, instead of loading the names into memory. In our case, the volume
    of images we are working with is low and we can easily fit them into memory so
    it is not necessary.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can shuffle our files using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: The preceding code returns numbers in the range of 0 to 1,399 in a shuffled
    order, which we will use as an index for selecting a subset of images to create
    a dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can create testing and validation code, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: The preceding code creates folders based on categories (cats and dogs) inside
    the `train` and `valid` directories.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can shuffle an index with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code, we use our shuffled index to randomly pick 250 different
    images for our validation set. We do something similar for the training data to
    segregate the images in the `train` directory.
  prefs: []
  type: TYPE_NORMAL
- en: As we have the data in the format we need, let's quickly look at how to load
    the images as PyTorch tensors.
  prefs: []
  type: TYPE_NORMAL
- en: Loading data into PyTorch tensors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The PyTorch `torchvision.datasets` package provides a utility class called
    `ImageFolder` that can be used to load images along with their associated labels
    when data is presented in the aforementioned format. It is a common practice to
    perform the following preprocessing steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Resize all the images to the same size. Most deep learning architectures expect
    the images to be of the same size.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Normalize the dataset with the mean and standard deviation of the dataset.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Convert the image dataset to a PyTorch tensor.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'PyTorch makes a lot of these preprocessing steps easier by providing a lot
    of utility functions in the `transforms` module. For our example, let''s apply
    three transformations:'
  prefs: []
  type: TYPE_NORMAL
- en: Scale to a 256 x 256 image size
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Convert to a PyTorch tensor
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Normalize the data (we will talk about how we arrived at the mean and standard
    deviation in the next section)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following code demonstrates how transformations can be applied and images
    are loaded using the `ImageFolder` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'The `train` object holds all the images and associated labels for the dataset.
    It contains two important attributes: one that gives a mapping between classes
    and the associated index used in the dataset and another one that gives a list
    of classes:'
  prefs: []
  type: TYPE_NORMAL
- en: '`train.class_to_idx - {''cat'': 0, ''dog'': 1}`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`train.classes - [''cat'', ''dog'']`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'It is often a best practice to visualize the data loaded into tensors. To visualize
    the tensors, we have to reshape the tensors and denormalize the values. The following
    function does that for us:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can pass our tensor to the preceding `imshow` function, which converts
    it into an image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code generates the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/760e81b6-5830-4c63-b683-7d3057befe04.png)'
  prefs: []
  type: TYPE_IMG
- en: Loading PyTorch tensors as batches
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'It is a common practice in deep learning or machine learning to batch samples
    of images, as modern **graphics processing units** (**GPUs**) and CPUs are optimized
    to run operations faster on a batch of images. The batch size generally varies
    depending on the kind of GPU we use. Each GPU has its own memory, which can vary
    from 2 GB to 12 GB, and sometimes more for commercial GPUs. PyTorch provides the
    `DataLoader` class, which takes in a dataset and returns a batch of images. It
    abstracts a lot of complexities in batching, such as the usage of multi-workers
    for applying transformation. The following code converts the previous `train`
    and `valid` datasets into data loaders:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'The `DataLoader` class provides us with a lot of options and some of the most
    commonly used ones are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`shuffle`: When true, this shuffles the images every time the data loader is
    called.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_workers`: This is responsible for parallelization. It is common practice
    to use a number of workers fewer than the number of cores available in your machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building the network architecture
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For most real-world use cases, particularly in computer vision, we rarely build
    our own architecture. There are different architectures that can be quickly used
    to solve our real-world problems. For our example, we'll use a popular deep learning
    algorithm called **ResNet**, which won the first prize in 2015 in different competitions,
    such as ImageNet, related to computer vision.
  prefs: []
  type: TYPE_NORMAL
- en: 'For a simpler understanding, let''s assume that this algorithm is a bunch of
    different PyTorch layers carefully tied together and not focus on what happens
    inside this algorithm. We will see some of the key building blocks of the ResNet
    algorithm when we learn about CNNs. PyTorch makes it easier to use a lot of these
    popular algorithms by providing them off the shelf in the `torchvision.models`
    module. So, for this example, let''s quickly take a look at how to use this algorithm
    and then walk through each line of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'The `models.resnet18(pertrained = True)` object creates an instance of the
    algorithm, which is a collection of PyTorch layers. We can take a quick look at
    what constitutes the ResNet algorithm by printing `pretrained_resnet`. A small
    portion of the algorithm looks like the following screenshot (I am not including
    the full algorithm as it could run for several pages):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9b4f58df-36b3-4f70-979f-b3f8d1097a8d.png)'
  prefs: []
  type: TYPE_IMG
- en: As we can see, the ResNet architecture is a collection of layers, namely `Conv2d`,
    `BatchNorm2d`, and `MaxPool2d`, stitched in a particular way. All these algorithms
    will accept an argument called `pretrained`. When `pretrained` is `True`, the
    weights of the algorithm are already tuned for a particular ImageNet classification
    problem of predicting 1,000 different categories, which include cars, ships, fish,
    cats, and dogs. This algorithm is trained to predict the 1,000 ImageNet categories
    and the weights are adjusted to a certain point where the algorithm achieves state-of-the-art
    accuracy. These weights are stored and shared with the model that we are using
    for the use case. Algorithms tend to work better when started with fine-tuned
    weights, rather than when started with random weights. So, for our use case, we'll
    start with pretrained weights.
  prefs: []
  type: TYPE_NORMAL
- en: 'The ResNet algorithm cannot be used directly, as it is trained to predict one
    of the 1,000 categories. For our use case, we need to predict only one of the
    two categories of dogs and cats. To achieve this, we take the last layer of the
    ResNet model, which is a linear layer, and change the output features to `4`,
    as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'If you are running this algorithm on a GPU-based machine, then to make the
    algorithm run on a GPU, we call the `cuda` method on the model. It is strongly
    recommended that you run these programs on a GPU-powered machine; it is easy to
    spin a cloud instance with a GPU for less than a dollar. The last line in the
    following code snippet tells PyTorch to run the code on the GPU:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Training the model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the previous sections, we created some `DataLoader` instances and algorithms.
    Now let''s train the model. To do this, we need a loss function and an optimizer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code, we created our loss function based on `CrossEntropyLoss`
    and the optimizer based on `SGD`. The `StepLR` function helps in dynamically changing
    the learning rate. We will discuss different strategies available to tune the
    learning rate in [Chapter 4](bfebc11a-90af-4c67-ab9a-3118061abaf3.xhtml), *Deep
    Learning for Computer Vision*.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following `train_my_model` function takes in a model and tunes the weights
    of our algorithm by running multiple epochs and reducing the loss:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Each epoch has a training and validation phase:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Iterate over the data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'The function can be run as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding function does the following:'
  prefs: []
  type: TYPE_NORMAL
- en: It passes the images through the model and calculates the loss.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It backpropagates during the training phase. For the validation/testing phase,
    it does not adjust the weights.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The loss is accumulated across batches for each epoch.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The best model is stored and validation accuracy is printed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The preceding model, after running for 20 epochs, results in a validation accuracy
    of 87%.
  prefs: []
  type: TYPE_NORMAL
- en: In the coming chapters, we will learn more advanced techniques that will help
    us in training more accurate models in a much faster way. The preceding model
    took around 30 minutes to run on a Titan X GPU. We will cover different techniques
    that will help in training the model faster.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we explored the complete life cycle of a neural network in
    PyTorch, starting from constituting different types of layers, adding activations,
    calculating cross-entropy loss, and finally, optimizing network performance (that
    is, minimizing loss), by adjusting the weights of layers using the SGD optimizer.
  prefs: []
  type: TYPE_NORMAL
- en: We studied how to apply the popular ResNet architecture to binary or multi-class
    classification problems.
  prefs: []
  type: TYPE_NORMAL
- en: While doing this, we tried to solve the real-world image classification problem
    of classifying a cat image as a cat and a dog image as a dog. This knowledge can
    be applied to classify different categories/classes of entities, such as classifying
    species of fish, identifying different kinds of dogs, categorizing plant seedlings,
    grouping together cervical cancer into Type 1, Type 2, and Type 3, and much more.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will go through the fundamentals of machine learning.
  prefs: []
  type: TYPE_NORMAL
