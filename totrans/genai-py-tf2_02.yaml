- en: '2'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Setting Up a TensorFlow Lab
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that you have seen all the amazing applications of generative models in
    *Chapter 1*, *An Introduction to Generative AI: "Drawing" Data from Models*, you
    might be wondering how to get started with implementing these projects that use
    these kinds of algorithms. In this chapter, we will walk through a number of tools
    that we will use throughout the rest of the book to implement the deep neural
    networks that are used in various generative AI models. Our primary tool is the
    *TensorFlow 2.0* framework, developed by Google^(1 2); however, we will also use
    a number of additional resources to make the implementation process easier (summarized
    in *Table 2.1*).'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: 'We can broadly categorize these tools:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: Resources for replicable dependency management (Docker, Anaconda)
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exploratory tools for data munging and algorithm hacking (Jupyter)
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Utilities to deploy these resources to the cloud and manage their lifecycle
    (Kubernetes, Kubeflow, Terraform)
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '| Tool | Project site | Use |'
  id: totrans-7
  prefs: []
  type: TYPE_TB
- en: '| Docker | [https://www.docker.com/](https://www.docker.com/) | Application
    runtime dependency encapsulation |'
  id: totrans-8
  prefs: []
  type: TYPE_TB
- en: '| Anaconda | [https://www.anaconda.com/](https://www.anaconda.com/) | Python
    language package management |'
  id: totrans-9
  prefs: []
  type: TYPE_TB
- en: '| Jupyter | [https://jupyter.org/](https://jupyter.org/) | Interactive Python
    runtime and plotting / data exploration tool |'
  id: totrans-10
  prefs: []
  type: TYPE_TB
- en: '| Kubernetes | [https://kubernetes.io/](https://kubernetes.io/) | Docker container
    orchestration and resource management |'
  id: totrans-11
  prefs: []
  type: TYPE_TB
- en: '| Kubeflow | [https://www.kubeflow.org/](https://www.kubeflow.org/) | Machine
    learning workflow engine developed on Kubernetes |'
  id: totrans-12
  prefs: []
  type: TYPE_TB
- en: '| Terraform | [https://www.terraform.io/](https://www.terraform.io/) | Infrastructure
    scripting language for configurable and consistent deployments of Kubeflow and
    Kubernetes |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
- en: '| VSCode | [https://code.visualstudio.com/](https://code.visualstudio.com/)
    | Integrated development environment (IDE) |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
- en: 'Table 2.1: Tech stack for generative adversarial model development'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: On our journey to bring our code from our laptops to the cloud in this chapter,
    we will first describe some background on how TensorFlow works when running locally.
    We will then describe a wide array of software tools that will make it easier
    to run an end-to-end TensorFlow lab locally or in the cloud, such as notebooks,
    containers, and cluster managers. Finally, we will walk through a simple practical
    example of setting up a reproducible research environment, running local and distributed
    training, and recording our results. We will also examine how we might parallelize
    TensorFlow across multiple CPU/GPU units within a machine (vertical scaling) and
    multiple machines in the cloud (horizontal scaling) to accelerate training. By
    the end of this chapter, we will be all ready to extend this laboratory framework
    to tackle implementing projects using various generative AI models.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: First, let's start by diving more into the details of TensorFlow, the library
    we will use to develop models throughout the rest of this book. What problem does
    TensorFlow solve for neural network model development? What approaches does it
    use? How has it evolved over the years? To answer these questions, let us review
    some of the history behind deep neural network libraries that led to the development
    of TensorFlow.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们深入了解 TensorFlow 的细节，这是本书剩余部分将用于开发模型的库。 TensorFlow 解决了神经网络模型开发中的哪些问题？它采用了哪些方法？它在多年来如何发展？为了回答这些问题，让我们回顾一些促成
    TensorFlow 发展的深度神经网络库的历史。
- en: Deep neural network development and TensorFlow
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度神经网络的发展和 TensorFlow
- en: As we will see in *Chapter 3*, *Building Blocks of Deep Neural Networks*, a
    deep neural network in essence consists of matrix operations (addition, subtraction,
    multiplication), nonlinear transformations, and gradient-based updates computed
    by using the derivatives of these components.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们将在 *第 3 章* *深度神经网络的构建模块* 中看到的那样，深度神经网络本质上由矩阵运算（加法、减法、乘法）、非线性变换和使用这些组件的导数进行的基于梯度的更新组成。
- en: 'In the world of academia, researchers have historically often used efficient
    prototyping tools such as MATLAB³ to run models and prepare analyses. While this
    approach allows for rapid experimentation, it lacks elements of industrial software
    development, such as **object-oriented** (**OO**) development, that allow for
    reproducibility and clean software abstractions that allow tools to be adopted
    by large organizations. These tools also had difficulty scaling to large datasets
    and could carry heavy licensing fees for such industrial use cases. However, prior
    to 2006, this type of computational tooling was largely sufficient for most use
    cases. However, as the datasets being tackled with deep neural network algorithms
    grew, groundbreaking results were achieved such as:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在学术界，研究人员通常使用诸如 MATLAB³ 这样的高效原型工具来运行模型和准备分析。虽然这种方法允许进行快速实验，但它缺乏工业软件开发的元素，例如
    **面向对象**（**OO**）开发，它可以实现可重现性和干净的软件抽象，从而使工具可以被大型组织所采用。这些工具对于大型数据集的扩展也存在困难，并且对于此类工业用途可能会带来繁重的许可费用。然而，在
    2006 年之前，这种计算工具在大多数情况下仍然足够。然而，随着应用深度神经网络算法处理的数据集的增长，取得了突破性的成果，如：
- en: Image classification on the ImageNet dataset⁴
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ImageNet 数据集上的图像分类⁴
- en: Large-scale unsupervised discovery of image patterns in YouTube videos⁵
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 YouTube 视频中大规模无监督地发现图像模式⁵
- en: The creation of artificial agents capable of playing Atari video games and the Asian
    board game GO with human-like skill^(6 7)
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创造了能够像人类一样能够玩雅达利视频游戏和围棋的人工智能代理^(6 7)
- en: State-of-the-art language translation via the BERT model developed by Google⁸
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过 Google 开发的 BERT 模型实现的最先进的语言翻译⁸
- en: The models developed in these studies exploded in complexity along with the
    size of the datasets they were applied to (see *Table 2.2* to get a sense of the
    immense scale of some of these models). As industrial use cases required robust
    and scalable frameworks to develop and deploy new neural networks, several academic
    groups and large technology companies invested in the development of generic toolkits
    for the implementation of deep learning models. These software libraries codified
    common patterns into reusable abstractions, allowing even complex models to be
    often embodied in relatively simple experimental scripts.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些研究中开发的模型随着它们应用到的数据集的规模而变得复杂起来（*请参阅*表 2.2 *以了解其中一些模型的巨大规模*）。由于工业用例需要稳健且可扩展的框架来开发和部署新的神经网络，一些学术团体和大型技术公司投资于通用工具包的开发，用于实现深度学习模型。这些软件库将常见模式编码为可重用的抽象，使即使复杂的模型通常也可以体现在相对简单的实验脚本中。
- en: '| Model Name | Year | # Parameters |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| 模型名称 | 年份 | # 参数 |'
- en: '| AlexNet | 2012 | 61M |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| AlexNet | 2012 | 61M |'
- en: '| YouTube CNN | 2012 | 1B |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| YouTube CNN | 2012 | 1B |'
- en: '| Inception | 2014 | 5M |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| Inception | 2014 | 5M |'
- en: '| VGG-16 | 2014 | 138M |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| VGG-16 | 2014 | 138M |'
- en: '| BERT | 2018 | 340M |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| BERT | 2018 | 340M |'
- en: '| GPT-3 | 2020 | 175B |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| GPT-3 | 2020 | 175B |'
- en: 'Table 2.2: Number of parameters by model by year'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2.2：按年份分类的模型参数数量
- en: Some of the early examples of these frameworks include Theano,⁹ a Python package
    developed at the University of Montreal, and Torch,^(10) a library written in
    the Lua language that was later ported to Python by researchers at Facebook, and
    TensorFlow, a C++ runtime with Python bindings developed by Google^(11).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这些框架的早期示例包括Theano，⁹ 蒙特利尔大学开发的Python包，以及Torch，^(10) 由Facebook的研究人员在Lua语言中编写，后来被转移到Python，以及由Google^(11)开发的具有Python绑定的C++运行时的TensorFlow。
- en: In this book, we will primarily use TensorFlow 2.0, due to its widespread adoption
    and its convenient high-level interface, **Keras**, which abstracts much of the
    repetitive plumbing of defining routine layers and model architectures.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们将主要使用TensorFlow 2.0，因为它被广泛采用，并且它具有方便的高级界面**Keras**，可以抽象出大部分关于定义常规层和模型架构的重复工作。
- en: TensorFlow is an open-source version of an internal tool developed at Google
    called **DistBelief**.^(12) The DistBeliefframework consisted of distributed workers
    (independent computational processes running on a cluster of machines) that would
    compute forward and backward gradient descent passes on a network (a common way
    to train neural networks we will discuss in *Chapter 3*,*Building Blocks of Deep
    Neural Networks*), and send the results to a **Parameter Server** that aggregated
    the updates. The neural networks in the DistBelief framework were represented
    as a **Directed Acyclic Graph** (**DAG**), terminating in a loss function that
    yielded a scalar (numerical value) comparing the network predictions with the
    observed target (such as image class or the probability distribution over a vocabulary
    representing the most probable next word in a sentence in a translation model).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow是Google内部称为**DistBelief**的工具的开源版本。^(12)DistBelief框架由分布式工作者（在一组机器上运行的独立计算过程）组成，这些工作者会对网络进行正向和反向梯度下降处理（我们将在*第3章*，*深度神经网络的构建基块*中讨论训练神经网络的常见方式），并将结果发送给**参数服务器**进行更新。DistBelief框架中的神经网络被表示为一个**有向无环图**（**DAG**），以损失函数结束，产生与观察目标（如图像类别或代表翻译模型中句子中最可能的下一个词的词汇概率分布）进行比较的标量（数值）。
- en: A DAG is a software data structure consisting of nodes (**operations**) and
    data (**edges**) where information only flows in a single direction along the
    edges (thus `directed`) and where there are no loops (hence `acyclic`).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: DAG是一种软件数据结构，由节点（**操作**）和数据（**边**）组成，信息仅沿着边的单向流动（因此`有向`），而且没有循环（因此`无环`）。
- en: 'While DistBelief allowed Google to productionize several large models, it had
    limitations:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管DistBelief允许Google生产出多个大型模型，但它有一些限制：
- en: First, the Python scripting interface was developed with a set of pre-defined
    layers corresponding to underlying implementations in C++; adding novel layer
    types required coding in C++, which represented a barrier to productivity.
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，Python脚本接口是使用一组对应C++中底层实现的预定义层开发的；添加新颖的层类型需要在C++中编码，这对生产力构成了障碍。
- en: Secondly, while the system was well adapted for training feed-forward networks
    using basic **Stochastic Gradient Descent** (**SGD**) (an algorithm we will describe
    in more detail in *Chapter 3*,*Building Blocks of Deep Neural Networks*) on large-scale
    data, it lacked flexibility for accommodating recurrent, reinforcement learning,
    or adversarial learning paradigms – the latter of which is crucial to many of
    the algorithms we will implement in this book.
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其次，虽然该系统非常适合使用基本的**随机梯度下降**（**SGD**）（我们将在*第3章*，*深度神经网络的构建基块*中更详细地描述的算法）在大规模数据上训练前馈网络，但它缺乏灵活性，无法容纳循环、强化学习或对抗学习范式
    —— 后者对于我们在本书中实现的许多算法贯穿全文非常重要。
- en: Finally, this system was difficult to *scale down* – to run the same job, for
    example, on a desktop with GPUs as well as a distributed environment with multiple
    cores per machine, and deployment also required a different technical stack.
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，这个系统难以*缩小规模*，比如在具有GPU的台式机和具有多个核心的分布式环境中运行相同的作业，部署还需要不同的技术栈。
- en: 'Jointly, these considerations prompted the development of TensorFlow as a generic
    deep learning computational framework: one that could allow scientists to flexibly
    experiment with new layer architectures or cutting-edge training paradigms, while
    also allowing this experimentation to be run with the same tools on both a laptop
    (for early-stage work) and a computing cluster (to scale up more mature models),
    while also easing the transition between research and development code by providing
    a common runtime for both.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: Though both libraries share the concept of the computation graph (networks represented
    as a graph of operations (nodes) and data (edges)) and a dataflow programming
    model (where matrix operations pass through the directed edges of a graph and
    have operations applied to them), TensorFlow, unlike DistBelief, was designed
    with the edges of the graph being tensors (n-dimensional matrices) and nodes of
    the graph being atomic operations (addition, subtraction, nonlinear convolution,
    or queues and other advanced operations) rather than fixed layer operations –
    this allows for much greater flexibility in defining new computations and even
    allowing for mutation and stateful updates (these being simply additional nodes
    in the graph).
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: The dataflow graph in essence serves as a "placeholder" where data is slotted
    into defined variables and can be executed on single or multiple machines. TensorFlow
    optimizes the constructed dataflow graph in the C++ runtime upon execution, allowing
    optimization, for example, in issuing commands to the GPU. The different computations
    of the graph can also be executed across multiple machines and hardware, including
    CPUs, GPUs, and TPUs (custom tensor processing chips developed by Google and available
    in the Google Cloud computing environment)^(11), as the same computations described
    at a high level in TensorFlow are implemented to execute on multiple backend systems.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: Because the dataflow graph allows mutable state, in essence, there is also no
    longer a centralized parameter server as was the case for DistBelief (though TensorFlow
    can also be run in a distributed manner with a parameter server configuration),
    since different nodes that hold state can execute the same operations as any other
    worker nodes. Further, control flow operations such as loops allow for the training
    of variable-length inputs such as in recurrent networks (see *Chapter 3*, *Building
    Blocks of Deep Neural Networks*). In the context of training neural networks,
    the gradients of each layer are simply represented as additional operations in
    the graph, allowing optimizations such as velocity (as in the RMSProp or ADAM
    optimizers, described in *Chapter 3*, *Building Blocks of Deep Neural Networks*)
    to be included using the same framework rather than modifying the parameter server
    logic. In the context of distributed training, TensorFlow also has several checkpointing
    and redundancy mechanisms ("backup" workers in case of a single task failure)
    that make it suited to robust training in distributed environments.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 因为数据流图允许可变状态，本质上，不再像DistBelief那样有一个集中的参数服务器（尽管TensorFlow也可以以参数服务器配置的方式分布式运行），因为持有状态的不同节点可以执行与任何其他工作节点相同的操作。此外，控制流操作（例如循环）允许对可变长度输入进行训练，例如在循环网络中（参见*第3章*，*深度神经网络的构建模块*）。在训练神经网络的情况下，每一层的梯度简单地表示为图中的附加操作，允许使用相同框架包含像速度这样的优化（如RMSProp或ADAM优化器，在*第3章*，*深度神经网络的构建模块*中描述）而不是修改参数服务器逻辑。在分布式训练的情况下，TensorFlow还具有几个检查点和冗余机制（“备份”工作节点以防单个任务失败），使其适用于在分布式环境中进行稳健的训练。
- en: TensorFlow 2.0
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: TensorFlow 2.0
- en: While representing operations in the dataflow graph as primitives allows flexibility
    in defining new layers within the Python client API, it also can result in a lot
    of "boilerplate" code and repetitive syntax. For this reason, the high-level API
    *Keras*^(14) was developed to provide a high-level abstraction; layers are represented
    using Python classes, while a particular runtime environment (such as TensorFlow
    or Theano) is a "backend" that executes the layer, just as the atomic TensorFlow
    operators can have different underlying implementations on CPUs, GPUs, or TPUs.
    While developed as a framework-agnostic library, Keras has been included as part
    of TensorFlow's main release in version 2.0\. For the purposes of readability,
    we will implement most of our models in this book in Keras, while reverting to
    the underlying TensorFlow 2.0 code where it is necessary to implement particular
    operations or highlight the underlying logic. Please see *Table 2.3* for a comparison
    between how various neural network algorithm concepts are implemented at a low
    (TensorFlow) or high (Keras) level in these libraries.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管在数据流图中表示操作原语可以灵活定义Python客户端API内的新层，但也可能导致大量“样板”代码和重复的语法。出于这个原因，高级API *Keras*^(14)被开发出来提供高级抽象；层使用Python类表示，而特定运行环境（例如TensorFlow或Theano）是执行该层的“后端”，就像原子TensorFlow运算符可以在CPU、GPU或TPU上具有不同的底层实现一样。尽管作为与框架无关的库开发，Keras已包含在TensorFlow
    2.0版本的主要发布中。为了可读性的目的，我们将在本书中大部分模型使用Keras来实现，而在需要实现特定操作或突出基础逻辑时，将恢复到底层的TensorFlow
    2.0代码。请参阅*表2.3*以比较这些库在低（TensorFlow）或高（Keras）级别上如何实现各种神经网络算法概念。
- en: '| Object | TensorFlow implementation | Keras implementation |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| 对象 | TensorFlow实现 | Keras实现 |'
- en: '| Neural network layer | Tensor computation | Python layer classes |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| 神经网络层 | 张量计算 | Python层类 |'
- en: '| Gradient calculation | Graph runtime operator | Python optimizer class |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| 梯度计算 | 图运行操作符 | Python优化器类 |'
- en: '| Loss function | Tensor computation | Python loss function |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| 损失函数 | 张量计算 | Python损失函数 |'
- en: '| Neural network model | Graph runtime session | Python model class instance
    |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| 神经网络模型 | 图运行会话 | Python模型类实例 |'
- en: 'Table 2.3: TensorFlow and Keras comparison'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 表2.3：TensorFlow和Keras比较
- en: To show you the difference between the abstraction that Keras makes versus TensorFlow
    1.0 in implementing basic neural network models, let's look at an example of writing
    a convolutional layer (see *Chapter 3*,*Building Blocks of Deep Neural Networks*)
    using both of these frameworks. In the first case, in TensorFlow 1.0, you can
    see that a lot of the code involves explicitly specifying variables, functions,
    and matrix operations, along with the gradient function and runtime session to
    compute the updates to the networks.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: 'This is a multilayer perceptron in TensorFlow 1.0^(15):'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: In contrast, the implementation of the same convolutional layer in Keras is
    vastly simplified through the use of abstract concepts embodied in Python classes,
    such as layers, models, and optimizers. Underlying details of the computation
    are encapsulated in these classes, making the logic of the code more readable.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: Note also that in TensorFlow 2.0 the notion of running sessions (**lazy execution**,
    in which the network is only computed if explicitly compiled and called) has been
    dropped in favor of eager execution, in which the session and graph are called
    dynamically when network functions such as `call` and `compile` are executed,
    with the network behaving like any other Python class without explicitly creating
    a `session` scope. The notion of a global namespace in which variables are declared
    with `tf.Variable()` has also been replaced with a **default garbage collection
    mechanism**.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: 'This is a multilayer perceptron layer in Keras^(15):'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Now that we have covered some of the details of what the TensorFlow library
    is and why it is well-suited to the development of deep neural network models
    (including the generative models we will implement in this book), let's get started
    building up our research environment. While we could simply use a Python package
    manager such as pip to install TensorFlow on our laptop, we want to make sure
    our process is as robust and reproducible as possible – this will make it easier
    to package our code to run on different machines, or keep our computations consistent
    by specifying the exact versions of each Python library we use in an experiment.
    We will start by installing an **Integrated Development Environment** (**IDE**)
    that will make our research easier – VSCode.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: VSCode
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Visual Studio Code** (**VSCode**) is an open-source code editor developed
    by Microsoft Corporation which can be used with many programming languages, including
    Python. It allows debugging and is integrated with version control tools such
    as Git; we can even run Jupyter notebooks (which we will describe later in this
    chapter) within VSCode. Instructions for installation vary by whether you are
    using a Linux, macOS, or Windows operating system: please see individual instructions
    at [https://code.visualstudio.com](https://code.visualstudio.com) for your system.
    Once installed, we need to clone a copy of the source code for the projects in
    this book using Git, with the command:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This command will copy the source code for the projects in this book to our
    laptop, allowing us to locally run and modify the code. Once you have the code
    copied, open the GitHub repository for this book using VSCode (*Figure 2.1*).
    We are now ready to start installing some of the tools we will need; open the
    file `install.sh`.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 此命令将把本书项目的源代码复制到我们的笔记本电脑上，允许我们本地运行和修改代码。一旦您复制了代码，请使用VSCode打开此书的GitHub存储库（*图2.1*）。我们现在准备开始安装我们将需要的一些工具；打开`install.sh`文件。
- en: '![](img/B16176_02_01.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B16176_02_01.png)'
- en: 'Figure 2.1: VSCode IDE'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.1：VSCode IDE
- en: 'One feature that will be of particular use to us is the fact that VSCode has
    an integrated (*Figure 2.2*) terminal where we can run commands: you can access
    this by selecting **View**, then **Terminal** from the drop-down list, which will
    open a command-line prompt:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们来说特别有用的一个功能是，VSCode具有集成（*图2.2*）终端，我们可以在其中运行命令：您可以通过选择**View**，然后从下拉列表中选择**Terminal**来访问此功能，这将打开一个命令行提示：
- en: '![](img/B16176_02_02.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B16176_02_02.png)'
- en: 'Figure 2.2: VSCode terminal'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.2：VSCode终端
- en: Select the **TERMINAL** tab, and **bash** for the interpreter; you should now
    be able to enter normal commands. Change the directory to `Chapter_2`, where we
    will run our installation script, which you can open in VSCode.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 选择**TERMINAL**选项卡，并选择解释器为**bash**；现在您应该能够输入正常的命令。将目录更改为`Chapter_2`，我们将在其中运行我们的安装脚本，您可以在VSCode中打开该脚本。
- en: The installation script we will run will download and install the various components
    we will need in our end-to-end TensorFlow lab; the overarching framework we will
    use for these experiments will be the `Kubeflow` library, which handles the various
    data and training pipelines that we will utilize for our projects in the later
    chapters of this volume. In the rest of this chapter, we will describe how Kubeflow
    is built on Docker and Kubernetes, and how to set up Kubeflow on several popular
    cloud providers.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将运行的安装脚本将下载并安装我们在最后几章中将使用到的各种组件；我们将使用的全面框架是`Kubeflow`库，它处理我们在本卷的后几章中将使用到的各种数据和培训流水线。在本章的其余部分，我们将介绍Kubeflow是如何构建在Docker和Kubernetes之上的，以及如何在几个流行的云提供商上设置Kubeflow。
- en: '**Kubernetes**, the technology which Kubeflow is based on, is fundamentally
    a way to manage containerized applications created using **Docker**, which allows
    for reproducible, lightweight execution environments to be created and persisted
    for a variety of applications. While we will make use of Docker for creating reproducible
    experimental runtimes, to understand its place in the overall landscape of virtualization
    solutions (and why it has become so important to modern application development),
    let us take a detour to describe the background of Docker in more detail.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '**Kubernetes**（Kubeflow基于此技术）本质上是一种管理使用**Docker**创建的容器化应用程序的方式，它允许创建和持久化可重现、轻量级的执行环境以适用于各种应用。虽然我们将使用Docker创建可重复的实验运行时，以了解其在虚拟化解决方案整体景观中的位置以及为什么它对现代应用程序开发如此重要，让我们稍微偏离一下，详细描述Docker的背景。'
- en: 'Docker: A lightweight virtualization solution'
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Docker：一个轻量级的虚拟化解决方案
- en: 'A consistent challenge in developing robust software applications is to make
    them run the same on a machine different than the one on which they are developed.
    These differences in environments could encompass a number of variables: operating systems,
    programming language library versions, and hardware such as CPU models.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 开发强大的软件应用程序的一个持续挑战是使它们在与开发它们的机器不同的机器上运行相同。这些环境上的差异可能涵盖多个变量：操作系统、编程语言库版本和硬件，如CPU型号。
- en: 'Traditionally, one approach to dealing with this heterogeneity has been to
    use a **Virtual Machine** (**VM**). While VMs are useful to run applications on
    diverse hardware and operating systems, they are also limited by being **resource-intensive**
    (*Figure 2.3*): each VM running on a host requires the overhead resources to run
    a completely separate operating system, along with all the applications or dependencies
    within the guest system.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理这种异构性时，传统上一种方法是使用**虚拟机**（**VM**）。虽然虚拟机能够在多样化的硬件和操作系统上运行应用程序，但它们也受到资源密集型的限制（*图2.3*）：每个运行在主机上的虚拟机都需要资源开销来运行完全独立的操作系统，以及所有来宾系统中的应用程序或依赖项。
- en: '![](img/B16176_02_03.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B16176_02_03.png)'
- en: 'Figure 2.3: Virtual machines versus containers^(16)'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.3：虚拟机与容器^(16)
- en: However, in some cases this is an unnecessary level of overhead; we do not necessarily
    need to run an entirely separate operating system, rather than just a consistent
    environment, including libraries and dependencies within a single operating system.
    This need for a **lightweight framework** to specify runtime environments prompted
    the creation of the **Docker project** for containerization in 2013\. In essence,
    a container is an environment for running an application, including all dependencies
    and libraries, allowing reproducible deployment of web applications and other
    programs, such as a database or the computations in a machine learning pipeline.
    For our use case, we will use it to provide a reproducible Python execution environment
    (Python language version and libraries) to run the steps in our generative machine
    learning pipelines.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: 'We will need to have Docker installed for many of the examples that will appear
    in the rest of this chapter and the projects in this book. For instructions on
    how to install Docker for your particular operating system, please refer to the
    directions at ([https://docs.docker.com/install/](https://docs.docker.com/install/)).
    To verify that you have installed the application successfully, you should be
    able to run the following command on your terminal, which will print the available
    options:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Important Docker commands and syntax
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To understand how Docker works, it is useful to walk through the template used
    for all Docker containers, a **Dockerfile**. As an example, we will use the TensorFlow
    container notebook example from the Kubeflow project ([https://github.com/kubeflow/kubeflow/blob/master/components/example-notebook-servers/jupyter-tensorflow-full/cpu.Dockerfile](https://github.com/kubeflow/kubeflow/blob/master/components/example-notebook-servers/jupyter-tensorf)).
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: 'This file is a set of instructions for how Docker should take a base operating
    environment, add dependencies, and execute a piece of software once it is packaged:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'While the exact commands will differ between containers, this will give you
    a flavor for the way we can use containers to manage an application – in this
    case running a Jupyter notebook for interactive machine learning experimentation
    using a consistent set of libraries. Once we have installed the Docker runtime
    for our particular operating system, we would execute such a file by running:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'When we do this, a number of things happen. First, we retrieve the `base` filesystem,
    or `image`, from a remote repository, which is not unlike the way we collect JAR
    files from Artifactory when using Java build tools such as Gradle or Maven, or
    Python''s pip installer. With this filesystem or `image`, we then set required
    variables for the Docker `build` command such as the username and TensorFlow version,
    and runtime environment variables for the container. We determine what shell program
    will be used to run the command, then we install dependencies we will need to
    run TensorFlow and the notebook application, and we specify the command that is
    run when the Docker container is started. Then we save this snapshot with an identifier
    composed of a base `image name` and one or more `tags` (such as version numbers,
    or, in many cases, simply a timestamp to uniquely identify this image). Finally,
    to actually start the notebook server running this container, we would issue the
    command:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们这样做时，会发生一些事情。首先，我们从远程存储库中检索`base`文件系统或 `image`，这有点类似于我们在使用 Java 构建工具（如 Gradle
    或 Maven）或 Python 的 pip 安装程序时，从 Artifactory 收集 JAR 文件的方式。有了这个文件系统或 `image`，然后我们为
    Docker `build` 命令设置所需的变量，比如用户名和 TensorFlow 版本，以及容器的运行时环境变量。我们确定将用于运行命令的 shell
    程序，然后安装我们需要运行 TensorFlow 和笔记本应用程序的依赖项，并指定在启动 Docker 容器时要运行的命令。然后，我们使用由基本 `image
    名称`和一个或多个 `tags`（比如版本号，或者在许多情况下，简单地用时间戳来唯一标识这个 image）组成的标识符保存这个快照。最后，要实际启动运行这个容器的笔记本服务器，我们将发出以下命令：
- en: '[PRE6]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'By default, Docker will run the executable command in the `Dockerfile` file;
    in our present example, that is the command to start the notebook server. However,
    this does not have to be the case; we could have a `Dockerfile` that simply builds
    an execution environment for an application, and issue a command to run within
    that environment. In that case, the command would look like:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，Docker 会运行在 `Dockerfile` 文件中的可执行命令；在我们目前的示例中，这是启动笔记本服务器的命令。然而，并非一定如此；我们也可以有一个
    `Dockerfile`，它只是为应用程序构建一个执行环境，并发出在该环境内运行的命令。在这种情况下，命令看起来会像这样：
- en: '[PRE7]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The `Docker` run commands allow us to test that our application can successfully
    run within the environment specified by the `Dockerfile`; however, we usually
    want to run this application in the cloud where we can take advantage of distributed
    computing resources or the ability to host web applications exposed to the world
    at large, not locally. To do so, we need to move our image we have built to a
    remote repository, which may or may not be the same one we pulled the initial
    image from, using the push command:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '`Docker` run 命令允许我们测试我们的应用程序是否可以成功在 `Dockerfile` 指定的环境中运行；然而，通常我们希望在云中运行此应用程序，以便利用分布式计算资源或能够托管向全球公开的
    Web 应用程序，而不是在本地。要做到这一点，我们需要将构建的镜像移到一个远程存储库，使用 push 命令，这个远程存储库可能与我们最初拉取初始镜像的存储库相同，也可能不同。'
- en: '[PRE8]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Note that the image name can contain a reference to a particular registry, such
    as a local registry or one hosted on one of the major cloud providers such as
    **Elastic Container Service** (**ECS**) on AWS, **Azure Kubernetes Service** (**AKS**),
    or Google Container Registry. Publishing to a remote registry allows developers
    to share images, and us to make containers accessible to deploy in the cloud.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，image 名称可以包含对特定注册表的引用，比如本地注册表或在主要云提供商（如 AWS 的 **弹性容器服务（ECS）**，Azure 的 **Azure
    Kubernetes 服务（AKS）** 或 Google 的容器注册表）上托管的注册表。将镜像发布到远程注册表允许开发人员共享镜像，并使我们可以在云中部署容器。
- en: Connecting Docker containers with docker-compose
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Docker-compose 连接 Docker 容器
- en: 'So far we have only discussed a few basic Docker commands, which would allow
    us to run a single service in a single container. However, you can probably appreciate
    that in the "real world" we usually need to have one or more applications running
    concurrently – for example, a website will have both a web application that fetches
    and processes data in response to activity from an end user and a database instance
    to log that information. In complex applications, the website might even be composed
    of multiple small web applications or **microservices** that are specialized to
    particular use cases such as the front end, user data, or an order management
    system. For these kinds of applications, we will need to have more than one container
    communicating with each other. The docker-compose tool ([https://docs.docker.com/compose/](https://docs.docker.com/compose/))
    is written with such applications in mind: it allows us to specify several Docker
    containers in an application file using the `YAML` format. For example, a configuration
    for a website with an instance of the Redis database might look like:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们只讨论了一些基本的Docker命令，这些命令可以让我们在单个容器中运行单个服务。然而，你也许能够理解，在“现实世界”中，我们通常需要同时运行一个或多个应用程序
    – 例如，一个网站将同时有一个获取和处理用户活动数据的网络应用程序和一个用于记录信息的数据库实例。在复杂的应用程序中，网站甚至可能由多个专门用于特定用例的小型网络应用程序或**微服务**组成，比如前端、用户数据或订单管理系统。对于这些类型的应用程序，我们需要多个容器彼此通信。Docker-compose工具（[https://docs.docker.com/compose/](https://docs.docker.com/compose/)）就是为此类应用程序而设计的：它允许我们使用`YAML`格式在应用文件中指定多个Docker容器。例如，一个具有Redis数据库实例的网站配置可能如下：
- en: '[PRE9]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Code 2.1: A yaml input file for Docker Compose'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 代码 2.1：Docker Compose的yaml输入文件
- en: 'The two application containers here are `web` and the `redis` database. The
    file also specified the volumes (disks) linked to these two applications. Using
    this configuration, we can run the command:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的两个应用程序容器分别是`web`和`redis`数据库。文件还指定了与这两个应用程序相关联的卷（磁盘）。使用这个配置，我们可以运行以下命令：
- en: '[PRE10]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: This starts all the containers specified in the YAML file and allows them to
    communicate with each other. However, even though Docker containers and docker-compose
    allow us to construct complex applications using consistent execution environments,
    we may potentially run into issues with robustness when we deploy these services
    to the cloud. For example, in a web application, we cannot be assured that the
    virtual machines that the application is running on will persist over long periods
    of time, so we need processes to manage self-healing and redundancy. This is also
    relevant to distributed machine learning pipelines, in which we do not want to
    have to kill an entire job because one node in a cluster goes down, which requires
    us to have backup logic to restart a sub-segment of work. Also, while Docker has
    the docker-compose functionality to link together several containers in an application,
    it does not have robust rules for how communication should happen among those
    containers, or how to manage them as a unit. For these purposes, we turn to the
    Kubernetes library.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 这将启动YAML文件中指定的所有容器，并允许它们彼此通信。然而，即使Docker容器和docker-compose允许我们使用一致的执行环境构建复杂的应用程序，当我们将这些服务部署到云端时，我们可能会遇到鲁棒性问题。例如，在一个网站应用程序中，我们无法保证应用程序运行的虚拟机会持续长时间，因此我们需要管理自愈和冗余的进程。这也与分布式机器学习流水线有关，其中我们不希望因为集群中的一个节点出现问题就不得不终止整个作业，因此我们需要备份逻辑来重新启动工作的一部分。此外，虽然Docker具有docker-compose功能来链接应用程序中的几个容器，但它没有健壮的规则来控制这些容器之间的通信，或者如何将它们作为一个单元进行管理。出于这些目的，我们转向Kubernetes库。
- en: 'Kubernetes: Robust management of multi-container applications'
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kubernetes：强大的多容器应用程序管理
- en: The Kubernetes project – sometimes abbreviated as k8s – was born out of an internal
    container management project at Google known as **Borg**. Kubernetes comes from
    the Greek word for navigator, as denoted by the seven-spoke wheel of the project's
    logo.^(18) Kubernetes is written in the Go programming language and provides a
    robust framework to deploy and manage Docker container applications on the underlying
    resources managed by cloud providers (such as **Amazon Web Services** (**AWS**),
    Microsoft Azure, and **Google Cloud Platform** (**GCP**)).
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: 'Kubernetes is fundamentally a tool to control applications composed of one
    or more Docker containers deployed in the cloud; this collection of containers
    is known as a **pod**. Each pod can have one or more copies (to allow redundancy),
    which is known as a **replicaset**. The two main components of a Kubernetes deployment
    are a **control plane** and **nodes**. The control plane hosts the centralized
    logic for deploying and managing pods, and consists of (*Figure 2.4*):'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16176_02_04.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.4: Kubernetes components^(18)'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: '**Kube-api-server**: This is the main application that listens to commands
    from the user to deploy or update a pod, or manages external access to pods via
    `ingress`.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Kube-controller-manager**: An application to manage functions such as controlling
    the number of replicas per pod.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cloud-controller-manager**: Manages functions particular to a cloud provider.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Etcd**: A key-value store that maintains the environment and state variables
    of different pods.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Kube-scheduler**: An application that is responsible for finding workers
    to run a pod.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While we could set up our own control plane, in practice we will usually have
    this function managed by our cloud provider, such as Google's **Google Kubernetes
    Engine** (**GKE**) or Amazon's **Elastic Kubernetes Services** (**EKS**). The
    Kubernetes nodes – the individual machines in the cluster – each run an application
    known as a **kubelet**, which monitors the pod(s) running on that node.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have a high-level view of the Kubernetes system, let's look at the
    important commands you will need to interact with a Kubernetes cluster, update
    its components, and start and stop applications.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: Important Kubernetes commands
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In order to interact with a Kubernetes cluster running in the cloud, we typically
    utilize the **Kubernetes command-line tool** (**kubectl**). Instructions for installing
    kubectl for your operating system can be found at ([https://kubernetes.io/docs/tasks/tools/install-kubectl/](https://kubernetes.io/docs/tasks/tools/install-kubectl/)).
    To verify that you have successfully installed kubectl, you can again run the
    `help` command in the terminal:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Like Docker, kubectl has many commands; the important one that we will use
    is the `apply` command, which, like `docker-compose`, takes in a YAML file as
    input and communicates with the Kubernetes control plane to start, update, or
    stop pods:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'As an example of how the `apply` command works, let us look at a YAML file
    for deploying a web server (`nginx`) application:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The resources specified in this file are created on the Kubernetes cluster nodes
    in the order in which they are listed in the file. First, we create the load balancer,
    which routes external traffic between copies of the `nginx` web server. The `metadata`
    is used to tag these applications for querying later using kubectl. Secondly,
    we create a set of `3` `replicas` of the `nginx` pod, using a consistent container
    (image `1.7.9`), which uses port `80` on their respective containers.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: The same set of physical resources of a Kubernetes cluster can be shared among
    several **virtual** clusters using **namespaces** – this allows us to segregate
    resources among multiple users or groups. This can allow, for example, each team
    to run their own set of applications and logically behave as if they are the only
    users. Later, in our discussion of **Kubeflow**, we will see how this feature
    can be used to logically partition projects on the same Kubeflow instance.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: Kustomize for configuration management
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Like most code, we most likely want to ultimately store the YAML files we use
    to issue commands to Kubernetes in a version control system such as Git. This
    leads to some cases where this format might not be ideal: for example, in a machine
    learning pipeline, we might perform hyperparameter searches where the same application
    is being run with slightly different parameters, leading to a glut of duplicate
    command files.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: Or, we might have arguments, such as AWS account keys, that for security reasons
    we do not want to store in a text file. We might also want to increase reuse by
    splitting our command into a `base` and additions; for example, in the YAML file
    shown in *Code 2.1*, if we wanted to run ngnix alongside different databases,
    or specify file storage in the different cloud object stores provided by Amazon,
    Google, and Microsoft Azure.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: 'For these use cases, we will make use of the Kustomize tool ([https://kustomize.io](https://kustomize.io)),
    which is also available through kubectl as:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Alternatively, we could use the Kustomize command-line tool. A `kustomization.yaml`
    is a template for a Kubernetes application; for example, consider the following
    template for the training job in the Kubeflow example repository ([https://github.com/kubeflow/pipelines/blob/master/manifests/kustomize/sample/kustomization.yaml](https://github.com/kubeflow/pipelines/blob/master/manifests/kustomize/sample/kustomization.yaml)):'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We can see that this file refers to a `base` set of configurations in a separate
    `kustomization.yaml` file located at the relative path `../base`. To edit variables
    in this file, for instance, to change the namespace for the application, we would
    `run`:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'We could also add configuration maps to pass to the training job, using a key-value
    format, for example:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Finally, when we are ready to execute these commands on Kubernetes, we can `build`
    the necessary `kubectl` command dynamically and apply it, assuming `kustomization.yaml`
    is in the current directory.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Hopefully, these examples demonstrate how Kustomize provides a flexible way
    to generate the YAML we need for kubectl using a template; we will make use of
    it often in the process of parameterizing our workflows later in this book.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have covered how Kubernetes manages Docker applications in the cloud,
    and how Kustomize can allow us to flexibly reuse `kubectl yaml` commands, let's
    look at how these components are tied together in Kubeflow to run the kinds of
    experiments we will be undertaking later to create generative AI models in TensorFlow.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: 'Kubeflow: an end-to-end machine learning lab'
  id: totrans-138
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As was described at the beginning of this chapter, there are many components
    of an end-to-end `lab` for machine learning research and development (*Table 2.1*),
    such as:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: A way to manage and version library dependencies, such as TensorFlow, and package
    them for a reproducible computing environment
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Interactive research environments where we can visualize data and experiment
    with different settings
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A systematic way to specify the steps of a pipeline – data processing, model
    tuning, evaluation, and deployment
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Provisioning of resources to run the modeling process in a distributed manner
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Robust mechanisms for snapshotting historical versions of the research process
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As we described earlier in this chapter, TensorFlow was designed to utilize
    distributed resources for training. To leverage this capability, we will use the
    Kubeflow projects. Built on top of Kubernetes, Kubeflow has several components
    that are useful in the end-to-end process of managing machine learning applications.
    To install Kubeflow, we need to have an existing Kubernetes control plane instance
    and use kubectl to launch Kubeflow's various components. The steps for setup differ
    slightly depending upon whether we are using a local instance or one of the major
    cloud providers.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: Running Kubeflow locally with MiniKF
  id: totrans-146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If we want to get started quickly or prototype our application locally, we can
    avoid setting up a cloud account and instead use virtual machines to simulate
    the kind of resources we would provision in the cloud. To set up Kubeflow locally,
    we first need to install VirtualBox ([https://www.virtualbox.org/wiki/Downloads](https://www.virtualbox.org/wiki/Downloads))
    to run virtual machines, and Vagrant to run configurations for setting up a Kubernetes
    control plane and Kubeflow on VirtualBox VMs ([https://www.vagrantup.com/downloads.html](https://www.vagrantup.com/downloads.html)).
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: 'Once you have these two dependencies installed, create a new directory, change
    into it, and run:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'This initializes the VirtualBox configuration and brings up the application.
    You can now navigate to `http://10.10.10.10/` and follow the instructions to launch
    Kubeflow and Rok (a storage volume for data used in experiments on Kubeflow created
    by Arrikto). Once these have been provisioned, you should see a screen like this
    (*Figure 2.5*):'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16176_02_05.png)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.5: MiniKF install screen in virtualbox^(19)'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: 'Log in to Kubeflow to see the dashboard with the various components (*Figure
    2.6*):'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16176_02_06.png)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.6: Kubeflow dashboard in MiniKF'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: We will return to these components later and go through the various functionalities
    available on Kubeflow, but first, let's walk through how to install Kubeflow in
    the cloud.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: Installing Kubeflow in AWS
  id: totrans-157
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In order to run Kubeflow in AWS, we need a Kubernetes control plane available
    in the cloud. Fortunately, Amazon provides a managed service called EKS, which
    provides an easy way to provision a control plane to deploy Kubeflow. Follow the
    following steps to deploy Kubeflow on AWS:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: '**Register for an AWS account and install the AWS Command Line Interface**'
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'This is needed to interact with the various AWS services, following the instructions
    for your platform located at [https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-install.html](https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-install.html).
    Once it is installed, enter:'
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-161
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: to set up your account and key information to provision resources.
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Install eksctl**'
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This command-line utility allows us to provision a Kubernetes control plane
    in Amazon from the command line. Follow instructions at [https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-install.html](https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-install.html)
    to install.
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Install iam-authenticator**'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To allow kubectl to interact with EKS, we need to provide the correct permissions
    using the IAM authenticator to modify our kubeconfig. Please see the installation
    instructions at [https://docs.aws.amazon.com/eks/latest/userguide/install-aws-iam-authenticator.html](https://docs.aws.amazon.com/eks/latest/userguide/install-aws-iam-authenticator.html).
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Download the Kubeflow command-line tool**'
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Links are located at the Kubeflow releases page ([https://github.com/kubeflow/kubeflow/releases/tag/v0.7.1](https://github.com/kubeflow/kubeflow/releases/tag/v0.7.1)).
    Download one of these directories and unpack the tarball using:'
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '**Build the configuration file**'
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'After entering environment variables for the Kubeflow application director
    (`${KF_DIR}`), the name of the deployment (`${KF_NAME}`), and the path to the
    base configuration file for the deployment (`${CONFIG_URI}`), which is located
    at [https://raw.githubusercontent.com/kubeflow/manifests/v0.7-branch/kfdef/kfctl_aws.0.7.1.yaml](https://raw.githubusercontent.com/kubeflow/manifests/v0.7-branch/kfdef/kfctl_aws.0.7.1.yaml)
    for AWS deployments, run the following to generate the configuration file:'
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-172
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'This will generate a local configuration file locally named `kfctl_aws.0.7.1.yaml`.
    If this looks like Kustomize, that''s because `kfctl` is using Kustomize under
    the hood to build the configuration. We also need to add an environment variable
    for the location of the local config file, `${CONFIG_FILE}`, which in this case
    is:'
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '**Launch Kubeflow on EKS**'
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Use the following commands to launch Kubeflow:'
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'It will take a while for all the Kubeflow components to become available; you can
    check the progress by using the following command:'
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Once they are all available, we can get the URL address for the Kubeflow dashboard
    using:'
  id: totrans-180
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: This will take us to the dashboard view shown in the MiniKF examples above.
    Note that in the default configuration, this address is open to the public; for
    secure applications, we need to add authentication using the instructions at [https://www.kubeflow.org/docs/aws/authentication/](https://www.kubeflow.org/docs/aws/authentication/).
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: Installing Kubeflow in GCP
  id: totrans-183
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Like AWS, **Google Cloud Platform** (**GCP**) provides a managed Kubernetes
    control plane, GKE. We can install Kubeflow in GCP using the following steps:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: '**Register for a GCP account and create a project on the console**'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This project will be where the various resources associated with Kubeflow will
    reside.
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Enable required services**'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The services required to run Kubeflow on GCP are:'
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Compute Engine API
  id: totrans-189
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Kubernetes Engine API
  id: totrans-190
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Identity and Access Management (IAM) API
  id: totrans-191
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Deployment Manager API
  id: totrans-192
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Cloud Resource Manager API
  id: totrans-193
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Cloud Filestore API
  id: totrans-194
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: AI Platform Training & Prediction API
  id: totrans-195
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Set up OAuth (optional)**'
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If you wish to make a secure deployment, then, as with AWS, you must follow
    instructions to add authentication to your installation, located at ([https://www.kubeflow.org/docs/gke/deploy/oauth-setup/](https://www.kubeflow.org/docs/gke/deploy/oauth-setup/)).
    Alternatively, you can just use the name and password for your GCP account.
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Set up the GCloud CLI**'
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'This is parallel to the AWS CLI covered in the previous section. Installation
    instructions are available at [https://cloud.google.com/sdk/](https://cloud.google.com/sdk/).
    You can verify your installation by running:'
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-200
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '**Download the kubeflow command-line tool**'
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Links are located on the Kubeflow releases page ([https://github.com/kubeflow/kubeflow/releases/tag/v0.7.1](https://github.com/kubeflow/kubeflow/releases/tag/v0.7.1)).
    Download one of these directories and unpack the tarball using:'
  id: totrans-202
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-203
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '**Log in to GCloud and create user credentials**'
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We next need to create a login account and credential token we will use to interact
    with resources in our account.
  id: totrans-205
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '**Set up environment variable and deploy Kubeflow**'
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'As with AWS, we need to enter values for a few key environment variables: the
    application containing the Kubeflow configuration files (`${KF_DIR}`), the name
    of the Kubeflow deployment (`${KF_NAME}`), the path to the base configuration
    URI (`${CONFIG_URI}` – for GCP this is [https://raw.githubusercontent.com/kubeflow/manifests/v0.7-branch/kfdef/kfctl_gcp_iap.0.7.1.yaml](https://raw.githubusercontent.com/kubeflow/manifests/v0.7-branch/kfdef/kfctl_gcp_iap.0.7.1.yaml)),
    the name of the Google project (`${PROJECT}`), and the zone it runs in (`${ZONE}`).'
  id: totrans-208
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Launch Kubeflow**'
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The same as AWS, we use Kustomize to build the template file and launch Kubeflow:'
  id: totrans-210
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Once Kubeflow is launched, you can get the URL to the dashboard using:'
  id: totrans-212
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-213
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Installing Kubeflow on Azure
  id: totrans-214
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Azure is Microsoft Corporation's cloud offering, and like AWS and GCP, we can
    use it to install Kubeflow leveraging a Kubernetes control plane and computing
    resources residing in the Azure cloud.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: '**Register an account on Azure**'
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Sign up at [https://azure.microsoft.com](https://azure.microsoft.com) – a free
    tier is available for experimentation.
  id: totrans-217
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Install the Azure command-line utilities**'
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'See instructions for installation on your platform at [https://docs.microsoft.com/en-us/cli/azure/install-azure-cli?view=azure-cli-latest](https://docs.microsoft.com/en-us/cli/azure/install-azure-cli?view=azure-cli-latest).
    You can verify your installation by running the following on the command line
    on your machine:'
  id: totrans-219
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'This should print a list of commands that you can use on the console. To start,
    log in to your account with:'
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-222
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'And enter the account credentials you registered in *Step 1*. You will be redirected
    to a browser to verify your account, after which you should see a response like
    the following:'
  id: totrans-223
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-224
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '**Create the resource group for a new cluster**'
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We first need to create the resource group where our new application will live,
    using the following command:'
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-227
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '**Create a Kubernetes resource on AKS**'
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now deploy the Kubernetes control plane on your resource group:'
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE36]'
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '**Install Kubeflow**'
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'First, we need to obtain credentials to install Kubeflow on our AKS resource:'
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE37]'
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '**Install kfctl**'
  id: totrans-234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Install and unpack the tarball directory:'
  id: totrans-235
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE38]'
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '**Set environment variables**'
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'As with AWS, we need to enter values for a few key environment variables: the
    application containing the Kubeflow configuration files (`${KF_DIR}`), the name
    of the Kubeflow deployment (`${KF_NAME}`), and the path to the base configuration
    URI (`${CONFIG_URI}` – for Azure, this is [https://raw.githubusercontent.com/kubeflow/manifests/v0.7-branch/kfdef/kfctl_k8s_istio.0.7.1.yaml](https://raw.githubusercontent.com/kubeflow/manifests/v0.7-branch/kfdef/kfctl_k8s_istio.0.7.1.yaml)).'
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Launch Kubeflow**'
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The same as AWS, we use Kustomize to build the template file and launch Kubeflow:'
  id: totrans-240
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE39]'
  id: totrans-241
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Once Kubeflow is launched, you can use port forwarding to redirect traffic
    from local port `8080` to port `80` in the cluster to access the Kubeflow dashboard
    at `localhost:8080` using the following command:'
  id: totrans-242
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE40]'
  id: totrans-243
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Installing Kubeflow using Terraform
  id: totrans-244
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For each of these cloud providers, you'll probably notice that we have a common
    set of commands; creating a Kubernetes cluster, installing Kubeflow, and starting
    the application. While we can use scripts to automate this process, it would be
    desirable to, like our code, have a way to version control and persist different
    infrastructure configurations, allowing a reproducible recipe for creating the
    set of resources we need to run Kubeflow. It would also help us potentially move
    between cloud providers without completely rewriting our installation logic.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: The template language **Terraform** ([https://www.terraform.io/](https://www.terraform.io/))
    was created by HashiCorp as a tool for **Infrastructure as a Service** (**IaaS**).
    In the same way that Kubernetes has an API to update resources on a cluster, **Terraform**
    allows us to abstract interactions with different underlying cloud providers using
    an API and a template language using a command-line utility and core components
    written in GoLang (*Figure 2.7*). Terraform can be extended using user-written
    plugins.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16176_02_07.png)'
  id: totrans-247
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.7: Terraform architecture^(20)'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s look at one example of installing Kubeflow using Terraform instructions
    on AWS, located at [https://github.com/aws-samples/amazon-eks-machine-learning-with-terraform-and-kubeflow](https://github.com/aws-samples/amazon-eks-machine-learning-with-terraform-and-kubeflow).
    Once you have established the required AWS resources and installed terraform on
    an EC2 container, the `aws-eks-cluster-and-nodegroup.tf` Terraform file is used
    to create the Kubeflow cluster using the command:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'In this file are a few key components. One is variables that specify aspects
    of the deployment:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Another is a specification for which cloud provider we are using:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'And another is resources such as the EKS cluster:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: Every time we run the Terraform `apply` command, it walks through this file
    to determine what resources to create, which underlying AWS services to call to
    create them, and with which set of configuration they should be provisioned. This
    provides a clean way to orchestrate complex installations such as Kubeflow in
    a versioned, extensible template language.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have successfully installed Kubeflow either locally or on a managed
    Kubernetes control plane in the cloud, let us take a look at what tools are available
    on the platform.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
- en: A brief tour of Kubeflow's components
  id: totrans-259
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we have installed Kubeflow locally or in the cloud, let us take a
    look again at the Kubeflow dashboard (*Figure 2.8*):'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16176_02_08.png)'
  id: totrans-261
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.8: The Kubeflow dashboard'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s walk through what is available in this toolkit. First, notice in the
    upper panel we have a dropdown with the name `anonymous` specified – this is the
    `namespace` for Kubernetes referred to earlier. While our default is `anonymous`,
    we could create several namespaces on our Kubeflow instance to accommodate different
    users or projects. This can be done at login, where we set up a profile (*Figure
    2.9*):'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16176_02_09_a+b.png)'
  id: totrans-264
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.9: Kubeflow login page'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
- en: 'Alternatively, as with other operations in Kubernetes, we can apply a namespace
    using a YAML file:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Using the `kubectl` command:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: What can we do once we have a namespace? Let us look through the available tools.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
- en: Kubeflow notebook servers
  id: totrans-271
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We can use Kubeflow to start a Jupyter notebook server in a namespace, where
    we can run experimental code; we can start the notebook by clicking the **Notebook
    Servers** tab in the user interface and selecting **NEW SERVER** (*Figure 2.10*):'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16176_02_10.png)'
  id: totrans-273
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.10: Kubeflow notebook creation'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
- en: We can then specify parameters, such as which container to run (which could
    include the TensorFlow container we examined earlier in our discussion of Docker),
    and how many resources to allocate (*Figure 2.11*).
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16176_02_11.png)'
  id: totrans-276
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.11: Kubeflow Docker resources panel'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
- en: You can also specify a **Persistent Volume** (**PV**) to store data that remains
    even if the notebook server is turned off, and special resources such as GPUs.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
- en: Once started, if you have specified a container with TensorFlow resources, you
    can begin running models in the notebook server.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
- en: Kubeflow pipelines
  id: totrans-280
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For notebook servers, we gave an example of a single container (the notebook
    instance) application. Kubeflow also gives us the ability to run multi-container
    application workflows (such as input data, training, and deployment) using the
    **pipelines** functionality. Pipelinesare Python functions that follow a **Domain
    Specific Language** (**DSL**) to specify components that will be compiled into
    containers.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
- en: 'If we click pipelines on the UI, we are brought to a dashboard (*Figure 2.12*):'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16176_02_12.png)'
  id: totrans-283
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.12: Kubeflow pipelines sashboard'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
- en: Selecting one of these pipelines, we can see a visual overview of the component
    containers (*Figure 2.13*).
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16176_02_13.png)'
  id: totrans-286
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.13: Kubeflow pipelines visualization'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
- en: After creating a new run, we can specify parameters for a particular instance
    of this pipeline (*Figure 2.14*).
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16176_02_14.png)'
  id: totrans-289
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.14: Kubeflow pipelines parameters'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the pipeline is created, we can use the user interface to visualize the
    results (*Figure 2.15*):'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16176_02_15+16.png)'
  id: totrans-292
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.15: Kubeflow pipeline results visualization'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
- en: 'Under the hood, the Python code to generate this pipeline is compiled using
    the pipelines SDK. We could specify the components to come either from a container
    with Python code:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  id: totrans-295
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'For a pure Python function, we could turn this into an operation with the compiler:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'We then use the `dsl.pipeline` decorator to add this operation to a pipeline:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  id: totrans-299
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'We compile it using the following code:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  id: totrans-301
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'and run it with this code:'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  id: totrans-303
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: We can also upload this ZIP file to the pipelines UI, where Kubeflow can use
    the generated YAML from compilation to instantiate the job.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have seen the process for generating results for a single pipeline,
    our next problem is how to generate the optimal parameters for such a pipeline.
    As you will see in *Chapter 3*, *Building Blocks of Deep Neural Networks*, neural
    network models typically have a number of configurations, known as **hyperparameters**,
    which govern their architecture (such as number of layers, layer size, and connectivity)
    and training paradigm (such as learning rate and optimizer algorithm). Kubeflow
    has a built-in utility for optimizing models for such parameter grids, called
    **Katib**.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
- en: Using Kubeflow Katib to optimize model hyperparameters
  id: totrans-306
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Katib is a framework for running multiple instances of the same job with differing
    inputs, such as in neural architecture search (for determining the right number
    and size of layers in a neural network) and hyperparameter search (finding the
    right learning rate, for example, for an algorithm). Like the other Kustomize
    templates we have seen, the TensorFlow job specifies a generic TensorFlow job,
    with placeholders for the parameters:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'which we can run using the familiar `kubectl` syntax:'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  id: totrans-310
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'or through the UI (*Figure 2.16*):'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16176_02_16.png)'
  id: totrans-312
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.16: Katib UI on Kubeflow'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
- en: where you can see a visual of the outcome of these multi-parameter experiments,
    or a table (*Figures 2.17* and *2.18*).
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16176_02_17.png)'
  id: totrans-315
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.17: Kubeflow visualization for multi-dimensional parameter optimization'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16176_02_18.png)'
  id: totrans-317
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.18: Kubeflow UI for multi-outcome experiments'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-319
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have covered an overview of what TensorFlow is and how it
    serves as an improvement over earlier frameworks for deep learning research. We
    also explored setting up an IDE, VSCode, and the foundation of reproducible applications,
    Docker containers. To orchestrate and deploy Docker containers, we discussed the
    Kubernetes framework, and how we can scale groups of containers using its API.
    Finally, I described Kubeflow, a machine learning framework built on Kubernetes
    which allows us to run end-to-end pipelines, distributed training, and parameter
    search, and serve trained models. We then set up a Kubeflow deployment using Terraform,
    an IaaS technology.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
- en: Before jumping into specific projects, we will next cover the basics of neural
    network theory and the TensorFlow and Keras commands that you will need to write
    basic training jobs on Kubeflow.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
- en: References
  id: totrans-322
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Abadi, Martín, et al. (2016) *TensorFlow: Large-Scale Machine Learning on Heterogeneous
    Distributed Systems*. arXiv:1603.04467\. [https://arxiv.org/abs/1603.04467](https://arxiv.org/abs/1603.04467).'
  id: totrans-323
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Google. *TensorFlow*. Retrieved April 26, 2021, from [https://www.tensorflow.org/](https://www.tensorflow.org/)
  id: totrans-324
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'MATLAB, Natick, Massachusetts: The MathWorks Inc. [https://www.mathworks.com/products/matlab.html](https://www.mathworks.com/products/matlab.html)'
  id: totrans-325
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Krizhevsky A., Sutskever I., & Hinton G E. *ImageNet Classification with Deep
    Convolutional Neural Networks*. [https://papers.nips.cc/paper/4824-imagenet-classification-with-deepconvolutional-neural-networks.pdf](https://papers.nips.cc/paper/4824-imagenet-classification-with-deepconvolutional-neural-networks.pdf)
  id: totrans-326
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Dean J., Ng A., (2012, Jun 26). *Using large-scale brain simulations for machine
    learning and A.I.*. Google | The Keyword. [https://blog.google/technology/ai/using-large-scale-brain-simulations-for/](https://blog.google/technology/ai/using-large-scale-brain-simulations-for/)
  id: totrans-327
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Mnih, V., Kavukcuoglu, K., Silver, D., Graves, A., Antonoglou, I., Wierstra,
    D., Riedmiller, M. (2013). *Playing Atari with Deep Reinforcement Learning*. arXiv:1312.5602\.
    [https://arxiv.org/abs/1312.5602](https://arxiv.org/abs/1312.5602)
  id: totrans-328
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Silver D, Schrittwieser J, Simonyan K, Antonoglou I, Huang A, Guez A, Hubert
    T, Baker L, Lai M, Bolton A, Chen Y, Lillicrap T, Hui F, Sifre L, van den Driessche
    G, Graepel T, Hassabis D. (2017) *Mastering the game of Go without human knowledge*.
    *Nature*. 550(7676):354-359\. [https://pubmed.ncbi.nlm.nih.gov/29052630/](https://pubmed.ncbi.nlm.nih.gov/29052630/)
  id: totrans-329
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2018). *Bert: Pre-training
    of deep bidirectional transformers for language understanding*. arXiv:1810.04805\.
    [https://arxiv.org/abs/1810.04805](https://arxiv.org/abs/1810.04805)'
  id: totrans-330
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Al-Rfou, R., et al. (2016). *Theano: A Python framework for fast computation
    of mathematical expressions*. arXiv. [https://arxiv.org/pdf/1605.02688.pdf](https://arxiv.org/pdf/1605.02688.pdf)'
  id: totrans-331
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Collobert R., Kavukcuoglu K., & Farabet C. (2011). *Torch7: A Matlab-like Environment
    for Machine Learning*. [http://ronan.collobert.com/pub/matos/2011_torch7_nipsw.pdf](http://ronan.collobert.com/pub/matos/2011_torch7_nipsw.pdf)'
  id: totrans-332
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Abadi M., et al. (2015). *TensorFlow: Large-Scale Machine Learning on Heterogeneous
    Distributed Systems*. [download.tensorflow.org/paper/whitepaper2015.pdf](http://download.tensorflow.org/paper/whitepaper2015.pdf)'
  id: totrans-333
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Abadi, Martín, et al. (2016) *TensorFlow: Large-Scale Machine Learning on Heterogeneous
    Distributed Systems*. arXiv:1603.04467\. [https://arxiv.org/abs/1603.04467](https://arxiv.org/abs/1603.04467
    )'
  id: totrans-334
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Jouppi, N P, et al. (2017). *In-Datacenter Performance Analysis of a Tensor
    Processing Unit*. arXiv:1704.04760\. [https://arxiv.org/abs/1704.04760](https://arxiv.org/abs/1704.04760)
  id: totrans-335
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'van Merriënboer, B., Bahdanau, D., Dumoulin, V., Serdyuk, D., Warde-Farley,
    D., Chorowski, J., Bengio, Y. (2015). *Blocks and Fuel: Frameworks for deep learning*.
    arXiv:1506.00619\. [https://arxiv.org/pdf/1506.00619.pdf](https://arxiv.org/pdf/1506.00619.pdf)'
  id: totrans-336
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[https://stackoverflow.com/questions/57273888/keras-vs-TensorFlow-code-comparison-sources](https://stackoverflow.com/questions/57273888/keras-vs-TensorFlow-code-comparison-sources)'
  id: totrans-337
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Harris M. (2016). *Docker vs. Virtual Machine*. Nvidia developer blog. [https://developer.nvidia.com/blog/nvidia-docker-gpu-server-application-deployment-made-easy/vm_vs_docker/](https://developer.nvidia.com/blog/nvidia-docker-gpu-server-application-deployment-made-easy/vm_vs_do)
  id: totrans-338
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'A visual play on words — the project''s original code name was *Seven of Nine*,
    a Borg character from the series Star Trek: Voyager'
  id: totrans-339
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Kubernetes Components. (2021, March 18) Kubernetes. [https://kubernetes.io/docs/concepts/overview/components/](https://kubernetes.io/docs/concepts/overview/components/)
  id: totrans-340
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Pavlou C. (2019). *An end-to-end ML pipeline on-prem: Notebooks & Kubeflow
    Pipelines on the new MiniKF*. Medium | Kubeflow. [https://medium.com/kubeflow/an-end-to-end-ml-pipeline-on-prem-notebooks-kubeflow-pipelines-on-the-new-minikf-33b7d8e9a836](https://medium.com/kubeflow/an-end-to-end-ml-pipeline-on-prem-notebooks-kubeflow-pipelines-on-the-ne)'
  id: totrans-341
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Vargo S. (2017). *Managing Google Calendar with Terraform*. HashiCorp. [https://www.hashicorp.com/blog/managing-google-calendar-with-terraform](https://www.hashicorp.com/blog/managing-google-calendar-with-terraform)
  id: totrans-342
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
