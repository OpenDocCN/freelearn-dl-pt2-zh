- en: '2'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '2'
- en: Setting Up a TensorFlow Lab
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置 TensorFlow 实验室
- en: 'Now that you have seen all the amazing applications of generative models in
    *Chapter 1*, *An Introduction to Generative AI: "Drawing" Data from Models*, you
    might be wondering how to get started with implementing these projects that use
    these kinds of algorithms. In this chapter, we will walk through a number of tools
    that we will use throughout the rest of the book to implement the deep neural
    networks that are used in various generative AI models. Our primary tool is the
    *TensorFlow 2.0* framework, developed by Google^(1 2); however, we will also use
    a number of additional resources to make the implementation process easier (summarized
    in *Table 2.1*).'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经在 *第一章* 中看到了生成模型的所有令人惊叹的应用，你可能想知道如何开始实施这些使用这些算法的项目。在本章中，我们将介绍一些工具，这些工具将在本书的其余部分中用于实现各种生成式
    AI 模型中使用的深度神经网络。我们的主要工具是由 Google^(1 2) 开发的 *TensorFlow 2.0* 框架；然而，我们还将使用其他一些资源来简化实现过程（在 *2.1
    表格* 中总结）。
- en: 'We can broadly categorize these tools:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以广泛分类这些工具：
- en: Resources for replicable dependency management (Docker, Anaconda)
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于可复制的依赖管理的资源（Docker，Anaconda）
- en: Exploratory tools for data munging and algorithm hacking (Jupyter)
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据整理和算法开发的探索性工具（Jupyter）
- en: Utilities to deploy these resources to the cloud and manage their lifecycle
    (Kubernetes, Kubeflow, Terraform)
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署这些资源到云端并管理其生命周期的工具（Kubernetes，Kubeflow，Terraform）
- en: '| Tool | Project site | Use |'
  id: totrans-7
  prefs: []
  type: TYPE_TB
  zh: '| 工具 | 项目网址 | 用途 |'
- en: '| Docker | [https://www.docker.com/](https://www.docker.com/) | Application
    runtime dependency encapsulation |'
  id: totrans-8
  prefs: []
  type: TYPE_TB
  zh: '| Docker | [https://www.docker.com/](https://www.docker.com/) | 应用程序运行时依赖封装
    |'
- en: '| Anaconda | [https://www.anaconda.com/](https://www.anaconda.com/) | Python
    language package management |'
  id: totrans-9
  prefs: []
  type: TYPE_TB
  zh: '| Anaconda | [https://www.anaconda.com/](https://www.anaconda.com/) | Python
    语言包管理 |'
- en: '| Jupyter | [https://jupyter.org/](https://jupyter.org/) | Interactive Python
    runtime and plotting / data exploration tool |'
  id: totrans-10
  prefs: []
  type: TYPE_TB
  zh: '| Jupyter | [https://jupyter.org/](https://jupyter.org/) | 交互式 Python 运行时和绘图/数据探索工具
    |'
- en: '| Kubernetes | [https://kubernetes.io/](https://kubernetes.io/) | Docker container
    orchestration and resource management |'
  id: totrans-11
  prefs: []
  type: TYPE_TB
  zh: '| Kubernetes | [https://kubernetes.io/](https://kubernetes.io/) | Docker 容器编排和资源管理
    |'
- en: '| Kubeflow | [https://www.kubeflow.org/](https://www.kubeflow.org/) | Machine
    learning workflow engine developed on Kubernetes |'
  id: totrans-12
  prefs: []
  type: TYPE_TB
  zh: '| Kubeflow | [https://www.kubeflow.org/](https://www.kubeflow.org/) | 基于 Kubernetes
    开发的机器学习工作流引擎 |'
- en: '| Terraform | [https://www.terraform.io/](https://www.terraform.io/) | Infrastructure
    scripting language for configurable and consistent deployments of Kubeflow and
    Kubernetes |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
  zh: '| Terraform | [https://www.terraform.io/](https://www.terraform.io/) | 用于可配置和一致部署
    Kubeflow 和 Kubernetes 的基础设施脚本语言 |'
- en: '| VSCode | [https://code.visualstudio.com/](https://code.visualstudio.com/)
    | Integrated development environment (IDE) |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
  zh: '| VSCode | [https://code.visualstudio.com/](https://code.visualstudio.com/)
    | 集成开发环境（IDE） |'
- en: 'Table 2.1: Tech stack for generative adversarial model development'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 2.1：用于生成对抗模型开发的技术栈
- en: On our journey to bring our code from our laptops to the cloud in this chapter,
    we will first describe some background on how TensorFlow works when running locally.
    We will then describe a wide array of software tools that will make it easier
    to run an end-to-end TensorFlow lab locally or in the cloud, such as notebooks,
    containers, and cluster managers. Finally, we will walk through a simple practical
    example of setting up a reproducible research environment, running local and distributed
    training, and recording our results. We will also examine how we might parallelize
    TensorFlow across multiple CPU/GPU units within a machine (vertical scaling) and
    multiple machines in the cloud (horizontal scaling) to accelerate training. By
    the end of this chapter, we will be all ready to extend this laboratory framework
    to tackle implementing projects using various generative AI models.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将在我们将我们的代码从笔记本电脑移到云端的旅程中，首先描述一些有关 TensorFlow 在本地运行时的背景知识。然后，我们将描述一系列软件工具，这些工具将使在本地或云端运行全面的
    TensorFlow 实验更加容易，如笔记本、容器和集群管理器等。最后，我们将通过一个简单的实例来介绍如何建立一个可重现的研究环境，运行本地和分布式训练，并记录我们的结果。我们还将探讨如何在一台机器内的多个
    CPU/GPU 单元（纵向扩展）和云端的多台机器（横向扩展）上并行化 TensorFlow 以加速训练。通过本章的学习，我们将准备好扩展这个实验室框架，用各种生成式
    AI 模型来实施项目。
- en: First, let's start by diving more into the details of TensorFlow, the library
    we will use to develop models throughout the rest of this book. What problem does
    TensorFlow solve for neural network model development? What approaches does it
    use? How has it evolved over the years? To answer these questions, let us review
    some of the history behind deep neural network libraries that led to the development
    of TensorFlow.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们深入了解 TensorFlow 的细节，这是本书剩余部分将用于开发模型的库。 TensorFlow 解决了神经网络模型开发中的哪些问题？它采用了哪些方法？它在多年来如何发展？为了回答这些问题，让我们回顾一些促成
    TensorFlow 发展的深度神经网络库的历史。
- en: Deep neural network development and TensorFlow
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度神经网络的发展和 TensorFlow
- en: As we will see in *Chapter 3*, *Building Blocks of Deep Neural Networks*, a
    deep neural network in essence consists of matrix operations (addition, subtraction,
    multiplication), nonlinear transformations, and gradient-based updates computed
    by using the derivatives of these components.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们将在 *第 3 章* *深度神经网络的构建模块* 中看到的那样，深度神经网络本质上由矩阵运算（加法、减法、乘法）、非线性变换和使用这些组件的导数进行的基于梯度的更新组成。
- en: 'In the world of academia, researchers have historically often used efficient
    prototyping tools such as MATLAB³ to run models and prepare analyses. While this
    approach allows for rapid experimentation, it lacks elements of industrial software
    development, such as **object-oriented** (**OO**) development, that allow for
    reproducibility and clean software abstractions that allow tools to be adopted
    by large organizations. These tools also had difficulty scaling to large datasets
    and could carry heavy licensing fees for such industrial use cases. However, prior
    to 2006, this type of computational tooling was largely sufficient for most use
    cases. However, as the datasets being tackled with deep neural network algorithms
    grew, groundbreaking results were achieved such as:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在学术界，研究人员通常使用诸如 MATLAB³ 这样的高效原型工具来运行模型和准备分析。虽然这种方法允许进行快速实验，但它缺乏工业软件开发的元素，例如
    **面向对象**（**OO**）开发，它可以实现可重现性和干净的软件抽象，从而使工具可以被大型组织所采用。这些工具对于大型数据集的扩展也存在困难，并且对于此类工业用途可能会带来繁重的许可费用。然而，在
    2006 年之前，这种计算工具在大多数情况下仍然足够。然而，随着应用深度神经网络算法处理的数据集的增长，取得了突破性的成果，如：
- en: Image classification on the ImageNet dataset⁴
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ImageNet 数据集上的图像分类⁴
- en: Large-scale unsupervised discovery of image patterns in YouTube videos⁵
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 YouTube 视频中大规模无监督地发现图像模式⁵
- en: The creation of artificial agents capable of playing Atari video games and the Asian
    board game GO with human-like skill^(6 7)
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创造了能够像人类一样能够玩雅达利视频游戏和围棋的人工智能代理^(6 7)
- en: State-of-the-art language translation via the BERT model developed by Google⁸
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过 Google 开发的 BERT 模型实现的最先进的语言翻译⁸
- en: The models developed in these studies exploded in complexity along with the
    size of the datasets they were applied to (see *Table 2.2* to get a sense of the
    immense scale of some of these models). As industrial use cases required robust
    and scalable frameworks to develop and deploy new neural networks, several academic
    groups and large technology companies invested in the development of generic toolkits
    for the implementation of deep learning models. These software libraries codified
    common patterns into reusable abstractions, allowing even complex models to be
    often embodied in relatively simple experimental scripts.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些研究中开发的模型随着它们应用到的数据集的规模而变得复杂起来（*请参阅*表 2.2 *以了解其中一些模型的巨大规模*）。由于工业用例需要稳健且可扩展的框架来开发和部署新的神经网络，一些学术团体和大型技术公司投资于通用工具包的开发，用于实现深度学习模型。这些软件库将常见模式编码为可重用的抽象，使即使复杂的模型通常也可以体现在相对简单的实验脚本中。
- en: '| Model Name | Year | # Parameters |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| 模型名称 | 年份 | # 参数 |'
- en: '| AlexNet | 2012 | 61M |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| AlexNet | 2012 | 61M |'
- en: '| YouTube CNN | 2012 | 1B |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| YouTube CNN | 2012 | 1B |'
- en: '| Inception | 2014 | 5M |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| Inception | 2014 | 5M |'
- en: '| VGG-16 | 2014 | 138M |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| VGG-16 | 2014 | 138M |'
- en: '| BERT | 2018 | 340M |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| BERT | 2018 | 340M |'
- en: '| GPT-3 | 2020 | 175B |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| GPT-3 | 2020 | 175B |'
- en: 'Table 2.2: Number of parameters by model by year'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2.2：按年份分类的模型参数数量
- en: Some of the early examples of these frameworks include Theano,⁹ a Python package
    developed at the University of Montreal, and Torch,^(10) a library written in
    the Lua language that was later ported to Python by researchers at Facebook, and
    TensorFlow, a C++ runtime with Python bindings developed by Google^(11).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这些框架的早期示例包括Theano，⁹ 蒙特利尔大学开发的Python包，以及Torch，^(10) 由Facebook的研究人员在Lua语言中编写，后来被转移到Python，以及由Google^(11)开发的具有Python绑定的C++运行时的TensorFlow。
- en: In this book, we will primarily use TensorFlow 2.0, due to its widespread adoption
    and its convenient high-level interface, **Keras**, which abstracts much of the
    repetitive plumbing of defining routine layers and model architectures.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们将主要使用TensorFlow 2.0，因为它被广泛采用，并且它具有方便的高级界面**Keras**，可以抽象出大部分关于定义常规层和模型架构的重复工作。
- en: TensorFlow is an open-source version of an internal tool developed at Google
    called **DistBelief**.^(12) The DistBeliefframework consisted of distributed workers
    (independent computational processes running on a cluster of machines) that would
    compute forward and backward gradient descent passes on a network (a common way
    to train neural networks we will discuss in *Chapter 3*,*Building Blocks of Deep
    Neural Networks*), and send the results to a **Parameter Server** that aggregated
    the updates. The neural networks in the DistBelief framework were represented
    as a **Directed Acyclic Graph** (**DAG**), terminating in a loss function that
    yielded a scalar (numerical value) comparing the network predictions with the
    observed target (such as image class or the probability distribution over a vocabulary
    representing the most probable next word in a sentence in a translation model).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow是Google内部称为**DistBelief**的工具的开源版本。^(12)DistBelief框架由分布式工作者（在一组机器上运行的独立计算过程）组成，这些工作者会对网络进行正向和反向梯度下降处理（我们将在*第3章*，*深度神经网络的构建基块*中讨论训练神经网络的常见方式），并将结果发送给**参数服务器**进行更新。DistBelief框架中的神经网络被表示为一个**有向无环图**（**DAG**），以损失函数结束，产生与观察目标（如图像类别或代表翻译模型中句子中最可能的下一个词的词汇概率分布）进行比较的标量（数值）。
- en: A DAG is a software data structure consisting of nodes (**operations**) and
    data (**edges**) where information only flows in a single direction along the
    edges (thus `directed`) and where there are no loops (hence `acyclic`).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: DAG是一种软件数据结构，由节点（**操作**）和数据（**边**）组成，信息仅沿着边的单向流动（因此`有向`），而且没有循环（因此`无环`）。
- en: 'While DistBelief allowed Google to productionize several large models, it had
    limitations:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管DistBelief允许Google生产出多个大型模型，但它有一些限制：
- en: First, the Python scripting interface was developed with a set of pre-defined
    layers corresponding to underlying implementations in C++; adding novel layer
    types required coding in C++, which represented a barrier to productivity.
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，Python脚本接口是使用一组对应C++中底层实现的预定义层开发的；添加新颖的层类型需要在C++中编码，这对生产力构成了障碍。
- en: Secondly, while the system was well adapted for training feed-forward networks
    using basic **Stochastic Gradient Descent** (**SGD**) (an algorithm we will describe
    in more detail in *Chapter 3*,*Building Blocks of Deep Neural Networks*) on large-scale
    data, it lacked flexibility for accommodating recurrent, reinforcement learning,
    or adversarial learning paradigms – the latter of which is crucial to many of
    the algorithms we will implement in this book.
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其次，虽然该系统非常适合使用基本的**随机梯度下降**（**SGD**）（我们将在*第3章*，*深度神经网络的构建基块*中更详细地描述的算法）在大规模数据上训练前馈网络，但它缺乏灵活性，无法容纳循环、强化学习或对抗学习范式
    —— 后者对于我们在本书中实现的许多算法贯穿全文非常重要。
- en: Finally, this system was difficult to *scale down* – to run the same job, for
    example, on a desktop with GPUs as well as a distributed environment with multiple
    cores per machine, and deployment also required a different technical stack.
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，这个系统难以*缩小规模*，比如在具有GPU的台式机和具有多个核心的分布式环境中运行相同的作业，部署还需要不同的技术栈。
- en: 'Jointly, these considerations prompted the development of TensorFlow as a generic
    deep learning computational framework: one that could allow scientists to flexibly
    experiment with new layer architectures or cutting-edge training paradigms, while
    also allowing this experimentation to be run with the same tools on both a laptop
    (for early-stage work) and a computing cluster (to scale up more mature models),
    while also easing the transition between research and development code by providing
    a common runtime for both.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这些考虑共同促使TensorFlow作为一种通用的深度学习计算框架的发展：一种可以让科学家灵活地尝试新的层架构或前沿的训练范式，同时还允许这种实验在笔记本电脑（用于早期工作）和计算集群（用于扩展更成熟的模型）上使用相同的工具运行，同时还通过为两者提供一个公共运行时来简化研究和开发代码之间的过渡。
- en: Though both libraries share the concept of the computation graph (networks represented
    as a graph of operations (nodes) and data (edges)) and a dataflow programming
    model (where matrix operations pass through the directed edges of a graph and
    have operations applied to them), TensorFlow, unlike DistBelief, was designed
    with the edges of the graph being tensors (n-dimensional matrices) and nodes of
    the graph being atomic operations (addition, subtraction, nonlinear convolution,
    or queues and other advanced operations) rather than fixed layer operations –
    this allows for much greater flexibility in defining new computations and even
    allowing for mutation and stateful updates (these being simply additional nodes
    in the graph).
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这两个库都共享计算图的概念（将网络表示为操作（节点）和数据（边缘）的图形）和数据流编程模型（其中矩阵操作通过图的有向边缘传递并对其应用操作），但TensorFlow与DistBelief不同，设计为图的边缘是张量（n维矩阵），图的节点是原子操作（加法、减法、非线性卷积或队列和其他高级操作），而不是固定的层操作——这允许在定义新计算时具有更大的灵活性，甚至允许进行突变和有状态更新（这些仅是图中的附加节点）。
- en: The dataflow graph in essence serves as a "placeholder" where data is slotted
    into defined variables and can be executed on single or multiple machines. TensorFlow
    optimizes the constructed dataflow graph in the C++ runtime upon execution, allowing
    optimization, for example, in issuing commands to the GPU. The different computations
    of the graph can also be executed across multiple machines and hardware, including
    CPUs, GPUs, and TPUs (custom tensor processing chips developed by Google and available
    in the Google Cloud computing environment)^(11), as the same computations described
    at a high level in TensorFlow are implemented to execute on multiple backend systems.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 数据流图本质上充当一个“占位符”，其中数据被插入到定义的变量中，并可以在单台或多台机器上执行。TensorFlow在C++运行时优化构建的数据流图，允许优化，例如向GPU发送命令。图的不同计算也可以在多台机器和硬件上执行，包括CPU、GPU和TPU（Google开发的自定义张量处理芯片，在Google
    Cloud计算环境中可用）^(11)，因为在TensorFlow中以高层次描述的相同计算被实现为在多个后端系统上执行。
- en: Because the dataflow graph allows mutable state, in essence, there is also no
    longer a centralized parameter server as was the case for DistBelief (though TensorFlow
    can also be run in a distributed manner with a parameter server configuration),
    since different nodes that hold state can execute the same operations as any other
    worker nodes. Further, control flow operations such as loops allow for the training
    of variable-length inputs such as in recurrent networks (see *Chapter 3*, *Building
    Blocks of Deep Neural Networks*). In the context of training neural networks,
    the gradients of each layer are simply represented as additional operations in
    the graph, allowing optimizations such as velocity (as in the RMSProp or ADAM
    optimizers, described in *Chapter 3*, *Building Blocks of Deep Neural Networks*)
    to be included using the same framework rather than modifying the parameter server
    logic. In the context of distributed training, TensorFlow also has several checkpointing
    and redundancy mechanisms ("backup" workers in case of a single task failure)
    that make it suited to robust training in distributed environments.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 因为数据流图允许可变状态，本质上，不再像DistBelief那样有一个集中的参数服务器（尽管TensorFlow也可以以参数服务器配置的方式分布式运行），因为持有状态的不同节点可以执行与任何其他工作节点相同的操作。此外，控制流操作（例如循环）允许对可变长度输入进行训练，例如在循环网络中（参见*第3章*，*深度神经网络的构建模块*）。在训练神经网络的情况下，每一层的梯度简单地表示为图中的附加操作，允许使用相同框架包含像速度这样的优化（如RMSProp或ADAM优化器，在*第3章*，*深度神经网络的构建模块*中描述）而不是修改参数服务器逻辑。在分布式训练的情况下，TensorFlow还具有几个检查点和冗余机制（“备份”工作节点以防单个任务失败），使其适用于在分布式环境中进行稳健的训练。
- en: TensorFlow 2.0
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: TensorFlow 2.0
- en: While representing operations in the dataflow graph as primitives allows flexibility
    in defining new layers within the Python client API, it also can result in a lot
    of "boilerplate" code and repetitive syntax. For this reason, the high-level API
    *Keras*^(14) was developed to provide a high-level abstraction; layers are represented
    using Python classes, while a particular runtime environment (such as TensorFlow
    or Theano) is a "backend" that executes the layer, just as the atomic TensorFlow
    operators can have different underlying implementations on CPUs, GPUs, or TPUs.
    While developed as a framework-agnostic library, Keras has been included as part
    of TensorFlow's main release in version 2.0\. For the purposes of readability,
    we will implement most of our models in this book in Keras, while reverting to
    the underlying TensorFlow 2.0 code where it is necessary to implement particular
    operations or highlight the underlying logic. Please see *Table 2.3* for a comparison
    between how various neural network algorithm concepts are implemented at a low
    (TensorFlow) or high (Keras) level in these libraries.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管在数据流图中表示操作原语可以灵活定义Python客户端API内的新层，但也可能导致大量“样板”代码和重复的语法。出于这个原因，高级API *Keras*^(14)被开发出来提供高级抽象；层使用Python类表示，而特定运行环境（例如TensorFlow或Theano）是执行该层的“后端”，就像原子TensorFlow运算符可以在CPU、GPU或TPU上具有不同的底层实现一样。尽管作为与框架无关的库开发，Keras已包含在TensorFlow
    2.0版本的主要发布中。为了可读性的目的，我们将在本书中大部分模型使用Keras来实现，而在需要实现特定操作或突出基础逻辑时，将恢复到底层的TensorFlow
    2.0代码。请参阅*表2.3*以比较这些库在低（TensorFlow）或高（Keras）级别上如何实现各种神经网络算法概念。
- en: '| Object | TensorFlow implementation | Keras implementation |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| 对象 | TensorFlow实现 | Keras实现 |'
- en: '| Neural network layer | Tensor computation | Python layer classes |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| 神经网络层 | 张量计算 | Python层类 |'
- en: '| Gradient calculation | Graph runtime operator | Python optimizer class |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| 梯度计算 | 图运行操作符 | Python优化器类 |'
- en: '| Loss function | Tensor computation | Python loss function |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| 损失函数 | 张量计算 | Python损失函数 |'
- en: '| Neural network model | Graph runtime session | Python model class instance
    |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| 神经网络模型 | 图运行会话 | Python模型类实例 |'
- en: 'Table 2.3: TensorFlow and Keras comparison'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 表2.3：TensorFlow和Keras比较
- en: To show you the difference between the abstraction that Keras makes versus TensorFlow
    1.0 in implementing basic neural network models, let's look at an example of writing
    a convolutional layer (see *Chapter 3*,*Building Blocks of Deep Neural Networks*)
    using both of these frameworks. In the first case, in TensorFlow 1.0, you can
    see that a lot of the code involves explicitly specifying variables, functions,
    and matrix operations, along with the gradient function and runtime session to
    compute the updates to the networks.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 为了向您展示 Keras 和 TensorFlow 1.0 在实现基本神经网络模型时所做的抽象的区别，让我们看一下使用这两个框架编写卷积层的示例（请参阅*第
    3 章*，*深度神经网络的构建块*）。在第一种情况下，在 TensorFlow 1.0 中，您可以看到很多代码涉及显式指定变量、函数和矩阵操作，以及梯度函数和运行时会话来计算网络的更新。
- en: 'This is a multilayer perceptron in TensorFlow 1.0^(15):'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 这是 TensorFlow 1.0 中的多层感知器^(15)：
- en: '[PRE0]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: In contrast, the implementation of the same convolutional layer in Keras is
    vastly simplified through the use of abstract concepts embodied in Python classes,
    such as layers, models, and optimizers. Underlying details of the computation
    are encapsulated in these classes, making the logic of the code more readable.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，Keras 中相同卷积层的实现通过使用在 Python 类中体现的抽象概念（如层、模型和优化器）大大简化了。这些类封装了计算的底层细节，使代码逻辑更易读。
- en: Note also that in TensorFlow 2.0 the notion of running sessions (**lazy execution**,
    in which the network is only computed if explicitly compiled and called) has been
    dropped in favor of eager execution, in which the session and graph are called
    dynamically when network functions such as `call` and `compile` are executed,
    with the network behaving like any other Python class without explicitly creating
    a `session` scope. The notion of a global namespace in which variables are declared
    with `tf.Variable()` has also been replaced with a **default garbage collection
    mechanism**.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 还要注意，在 TensorFlow 2.0 中，运行会话的概念（**惰性执行**，即仅在显式编译和调用时才计算网络）已经被弃用，而采用了渴望执行的方式，在调用网络函数（如
    `call` 和 `compile`）时动态调用会话和图，网络行为就像任何其他 Python 类一样，而无需显式创建 `session` 作用域。使用 `tf.Variable()`
    声明变量的全局命名空间概念也已被替换为**默认垃圾收集机制**。
- en: 'This is a multilayer perceptron layer in Keras^(15):'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这是 Keras 中的多层感知器层^(15)：
- en: '[PRE1]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Now that we have covered some of the details of what the TensorFlow library
    is and why it is well-suited to the development of deep neural network models
    (including the generative models we will implement in this book), let's get started
    building up our research environment. While we could simply use a Python package
    manager such as pip to install TensorFlow on our laptop, we want to make sure
    our process is as robust and reproducible as possible – this will make it easier
    to package our code to run on different machines, or keep our computations consistent
    by specifying the exact versions of each Python library we use in an experiment.
    We will start by installing an **Integrated Development Environment** (**IDE**)
    that will make our research easier – VSCode.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了 TensorFlow 库的一些细节以及它为深度神经网络模型的开发（包括我们将在本书中实现的生成模型）而非常合适的原因，让我们开始建立我们的研究环境。虽然我们可以简单地使用像
    pip 这样的 Python 包管理器在我们的笔记本电脑上安装 TensorFlow，但我们希望确保我们的过程尽可能健壮和可复制 - 这将使我们更容易将我们的代码打包到不同的机器上运行，或者通过指定我们在实验中使用的每个
    Python 库的确切版本来保持我们的计算一致。我们将首先安装一个**集成开发环境**（**IDE**），这将使我们的研究更容易 - VSCode。
- en: VSCode
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: VSCode
- en: '**Visual Studio Code** (**VSCode**) is an open-source code editor developed
    by Microsoft Corporation which can be used with many programming languages, including
    Python. It allows debugging and is integrated with version control tools such
    as Git; we can even run Jupyter notebooks (which we will describe later in this
    chapter) within VSCode. Instructions for installation vary by whether you are
    using a Linux, macOS, or Windows operating system: please see individual instructions
    at [https://code.visualstudio.com](https://code.visualstudio.com) for your system.
    Once installed, we need to clone a copy of the source code for the projects in
    this book using Git, with the command:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '**Visual Studio Code**（**VSCode**）是由微软公司开发的开源代码编辑器，可用于许多编程语言，包括 Python。它允许调试，并与诸如
    Git 等版本控制工具集成; 我们甚至可以在 VSCode 中运行 Jupyter 笔记本（我们将在本章后面描述）。安装说明因您使用的是 Linux、macOS
    还是 Windows 操作系统而异：请查看您系统的单独说明，网址为 [https://code.visualstudio.com](https://code.visualstudio.com)。安装完成后，我们需要使用
    Git 克隆本书项目的源代码副本，命令如下：'
- en: '[PRE2]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This command will copy the source code for the projects in this book to our
    laptop, allowing us to locally run and modify the code. Once you have the code
    copied, open the GitHub repository for this book using VSCode (*Figure 2.1*).
    We are now ready to start installing some of the tools we will need; open the
    file `install.sh`.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 此命令将把本书项目的源代码复制到我们的笔记本电脑上，允许我们本地运行和修改代码。一旦您复制了代码，请使用VSCode打开此书的GitHub存储库（*图2.1*）。我们现在准备开始安装我们将需要的一些工具；打开`install.sh`文件。
- en: '![](img/B16176_02_01.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B16176_02_01.png)'
- en: 'Figure 2.1: VSCode IDE'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.1：VSCode IDE
- en: 'One feature that will be of particular use to us is the fact that VSCode has
    an integrated (*Figure 2.2*) terminal where we can run commands: you can access
    this by selecting **View**, then **Terminal** from the drop-down list, which will
    open a command-line prompt:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们来说特别有用的一个功能是，VSCode具有集成（*图2.2*）终端，我们可以在其中运行命令：您可以通过选择**View**，然后从下拉列表中选择**Terminal**来访问此功能，这将打开一个命令行提示：
- en: '![](img/B16176_02_02.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B16176_02_02.png)'
- en: 'Figure 2.2: VSCode terminal'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.2：VSCode终端
- en: Select the **TERMINAL** tab, and **bash** for the interpreter; you should now
    be able to enter normal commands. Change the directory to `Chapter_2`, where we
    will run our installation script, which you can open in VSCode.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 选择**TERMINAL**选项卡，并选择解释器为**bash**；现在您应该能够输入正常的命令。将目录更改为`Chapter_2`，我们将在其中运行我们的安装脚本，您可以在VSCode中打开该脚本。
- en: The installation script we will run will download and install the various components
    we will need in our end-to-end TensorFlow lab; the overarching framework we will
    use for these experiments will be the `Kubeflow` library, which handles the various
    data and training pipelines that we will utilize for our projects in the later
    chapters of this volume. In the rest of this chapter, we will describe how Kubeflow
    is built on Docker and Kubernetes, and how to set up Kubeflow on several popular
    cloud providers.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将运行的安装脚本将下载并安装我们在最后几章中将使用到的各种组件；我们将使用的全面框架是`Kubeflow`库，它处理我们在本卷的后几章中将使用到的各种数据和培训流水线。在本章的其余部分，我们将介绍Kubeflow是如何构建在Docker和Kubernetes之上的，以及如何在几个流行的云提供商上设置Kubeflow。
- en: '**Kubernetes**, the technology which Kubeflow is based on, is fundamentally
    a way to manage containerized applications created using **Docker**, which allows
    for reproducible, lightweight execution environments to be created and persisted
    for a variety of applications. While we will make use of Docker for creating reproducible
    experimental runtimes, to understand its place in the overall landscape of virtualization
    solutions (and why it has become so important to modern application development),
    let us take a detour to describe the background of Docker in more detail.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '**Kubernetes**（Kubeflow基于此技术）本质上是一种管理使用**Docker**创建的容器化应用程序的方式，它允许创建和持久化可重现、轻量级的执行环境以适用于各种应用。虽然我们将使用Docker创建可重复的实验运行时，以了解其在虚拟化解决方案整体景观中的位置以及为什么它对现代应用程序开发如此重要，让我们稍微偏离一下，详细描述Docker的背景。'
- en: 'Docker: A lightweight virtualization solution'
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Docker：一个轻量级的虚拟化解决方案
- en: 'A consistent challenge in developing robust software applications is to make
    them run the same on a machine different than the one on which they are developed.
    These differences in environments could encompass a number of variables: operating systems,
    programming language library versions, and hardware such as CPU models.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 开发强大的软件应用程序的一个持续挑战是使它们在与开发它们的机器不同的机器上运行相同。这些环境上的差异可能涵盖多个变量：操作系统、编程语言库版本和硬件，如CPU型号。
- en: 'Traditionally, one approach to dealing with this heterogeneity has been to
    use a **Virtual Machine** (**VM**). While VMs are useful to run applications on
    diverse hardware and operating systems, they are also limited by being **resource-intensive**
    (*Figure 2.3*): each VM running on a host requires the overhead resources to run
    a completely separate operating system, along with all the applications or dependencies
    within the guest system.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理这种异构性时，传统上一种方法是使用**虚拟机**（**VM**）。虽然虚拟机能够在多样化的硬件和操作系统上运行应用程序，但它们也受到资源密集型的限制（*图2.3*）：每个运行在主机上的虚拟机都需要资源开销来运行完全独立的操作系统，以及所有来宾系统中的应用程序或依赖项。
- en: '![](img/B16176_02_03.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B16176_02_03.png)'
- en: 'Figure 2.3: Virtual machines versus containers^(16)'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.3：虚拟机与容器^(16)
- en: However, in some cases this is an unnecessary level of overhead; we do not necessarily
    need to run an entirely separate operating system, rather than just a consistent
    environment, including libraries and dependencies within a single operating system.
    This need for a **lightweight framework** to specify runtime environments prompted
    the creation of the **Docker project** for containerization in 2013\. In essence,
    a container is an environment for running an application, including all dependencies
    and libraries, allowing reproducible deployment of web applications and other
    programs, such as a database or the computations in a machine learning pipeline.
    For our use case, we will use it to provide a reproducible Python execution environment
    (Python language version and libraries) to run the steps in our generative machine
    learning pipelines.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在某些情况下，这是一种不必要的开销级别；我们不一定需要运行一个完全独立的操作系统，而只需要一个一致的环境，包括一个操作系统内的库和依赖项。对于指定运行时环境的**轻量级框架**的需求促使了
    2013 年**Docker 项目**的创建，用于容器化。本质上，容器是运行应用程序的环境，包括所有依赖项和库，允许可重现部署 Web 应用程序和其他程序，例如数据库或机器学习流水线中的计算。对于我们的用例，我们将使用它提供一个可重现的
    Python 执行环境（Python 语言版本和库）来运行我们生成式机器学习流水线中的步骤。
- en: 'We will need to have Docker installed for many of the examples that will appear
    in the rest of this chapter and the projects in this book. For instructions on
    how to install Docker for your particular operating system, please refer to the
    directions at ([https://docs.docker.com/install/](https://docs.docker.com/install/)).
    To verify that you have installed the application successfully, you should be
    able to run the following command on your terminal, which will print the available
    options:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 本章余下部分的许多示例和本书中的项目需要安装 Docker。有关如何为您的特定操作系统安装 Docker 的说明，请参阅[此处](https://docs.docker.com/install/)的指南。要验证您已成功安装该应用程序，请在终端上运行以下命令，该命令将打印出可用的选项：
- en: '[PRE3]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Important Docker commands and syntax
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 重要的 Docker 命令和语法
- en: To understand how Docker works, it is useful to walk through the template used
    for all Docker containers, a **Dockerfile**. As an example, we will use the TensorFlow
    container notebook example from the Kubeflow project ([https://github.com/kubeflow/kubeflow/blob/master/components/example-notebook-servers/jupyter-tensorflow-full/cpu.Dockerfile](https://github.com/kubeflow/kubeflow/blob/master/components/example-notebook-servers/jupyter-tensorf)).
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解 Docker 的工作原理，了解用于所有 Docker 容器的模板**Dockerfile**是有用的。作为示例，我们将使用 Kubeflow 项目中的
    TensorFlow 容器笔记本示例（[链接](https://github.com/kubeflow/kubeflow/blob/master/components/example-notebook-servers/jupyter-tensorflow-full/cpu.Dockerfile)）。
- en: 'This file is a set of instructions for how Docker should take a base operating
    environment, add dependencies, and execute a piece of software once it is packaged:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 此文件是 Docker 应如何采用基本操作环境、添加依赖项并在打包后执行软件的一组说明：
- en: '[PRE4]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'While the exact commands will differ between containers, this will give you
    a flavor for the way we can use containers to manage an application – in this
    case running a Jupyter notebook for interactive machine learning experimentation
    using a consistent set of libraries. Once we have installed the Docker runtime
    for our particular operating system, we would execute such a file by running:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然容器之间的确切命令会有所不同，但这将让您了解我们可以如何使用容器来管理应用程序——在这种情况下，使用一致的库集运行 Jupyter 笔记本进行交互式机器学习实验。一旦我们为我们的特定操作系统安装了
    Docker 运行时，我们将通过运行以下命令来执行这样一个文件：
- en: '[PRE5]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'When we do this, a number of things happen. First, we retrieve the `base` filesystem,
    or `image`, from a remote repository, which is not unlike the way we collect JAR
    files from Artifactory when using Java build tools such as Gradle or Maven, or
    Python''s pip installer. With this filesystem or `image`, we then set required
    variables for the Docker `build` command such as the username and TensorFlow version,
    and runtime environment variables for the container. We determine what shell program
    will be used to run the command, then we install dependencies we will need to
    run TensorFlow and the notebook application, and we specify the command that is
    run when the Docker container is started. Then we save this snapshot with an identifier
    composed of a base `image name` and one or more `tags` (such as version numbers,
    or, in many cases, simply a timestamp to uniquely identify this image). Finally,
    to actually start the notebook server running this container, we would issue the
    command:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们这样做时，会发生一些事情。首先，我们从远程存储库中检索`base`文件系统或 `image`，这有点类似于我们在使用 Java 构建工具（如 Gradle
    或 Maven）或 Python 的 pip 安装程序时，从 Artifactory 收集 JAR 文件的方式。有了这个文件系统或 `image`，然后我们为
    Docker `build` 命令设置所需的变量，比如用户名和 TensorFlow 版本，以及容器的运行时环境变量。我们确定将用于运行命令的 shell
    程序，然后安装我们需要运行 TensorFlow 和笔记本应用程序的依赖项，并指定在启动 Docker 容器时要运行的命令。然后，我们使用由基本 `image
    名称`和一个或多个 `tags`（比如版本号，或者在许多情况下，简单地用时间戳来唯一标识这个 image）组成的标识符保存这个快照。最后，要实际启动运行这个容器的笔记本服务器，我们将发出以下命令：
- en: '[PRE6]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'By default, Docker will run the executable command in the `Dockerfile` file;
    in our present example, that is the command to start the notebook server. However,
    this does not have to be the case; we could have a `Dockerfile` that simply builds
    an execution environment for an application, and issue a command to run within
    that environment. In that case, the command would look like:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，Docker 会运行在 `Dockerfile` 文件中的可执行命令；在我们目前的示例中，这是启动笔记本服务器的命令。然而，并非一定如此；我们也可以有一个
    `Dockerfile`，它只是为应用程序构建一个执行环境，并发出在该环境内运行的命令。在这种情况下，命令看起来会像这样：
- en: '[PRE7]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The `Docker` run commands allow us to test that our application can successfully
    run within the environment specified by the `Dockerfile`; however, we usually
    want to run this application in the cloud where we can take advantage of distributed
    computing resources or the ability to host web applications exposed to the world
    at large, not locally. To do so, we need to move our image we have built to a
    remote repository, which may or may not be the same one we pulled the initial
    image from, using the push command:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '`Docker` run 命令允许我们测试我们的应用程序是否可以成功在 `Dockerfile` 指定的环境中运行；然而，通常我们希望在云中运行此应用程序，以便利用分布式计算资源或能够托管向全球公开的
    Web 应用程序，而不是在本地。要做到这一点，我们需要将构建的镜像移到一个远程存储库，使用 push 命令，这个远程存储库可能与我们最初拉取初始镜像的存储库相同，也可能不同。'
- en: '[PRE8]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Note that the image name can contain a reference to a particular registry, such
    as a local registry or one hosted on one of the major cloud providers such as
    **Elastic Container Service** (**ECS**) on AWS, **Azure Kubernetes Service** (**AKS**),
    or Google Container Registry. Publishing to a remote registry allows developers
    to share images, and us to make containers accessible to deploy in the cloud.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，image 名称可以包含对特定注册表的引用，比如本地注册表或在主要云提供商（如 AWS 的 **弹性容器服务（ECS）**，Azure 的 **Azure
    Kubernetes 服务（AKS）** 或 Google 的容器注册表）上托管的注册表。将镜像发布到远程注册表允许开发人员共享镜像，并使我们可以在云中部署容器。
- en: Connecting Docker containers with docker-compose
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Docker-compose 连接 Docker 容器
- en: 'So far we have only discussed a few basic Docker commands, which would allow
    us to run a single service in a single container. However, you can probably appreciate
    that in the "real world" we usually need to have one or more applications running
    concurrently – for example, a website will have both a web application that fetches
    and processes data in response to activity from an end user and a database instance
    to log that information. In complex applications, the website might even be composed
    of multiple small web applications or **microservices** that are specialized to
    particular use cases such as the front end, user data, or an order management
    system. For these kinds of applications, we will need to have more than one container
    communicating with each other. The docker-compose tool ([https://docs.docker.com/compose/](https://docs.docker.com/compose/))
    is written with such applications in mind: it allows us to specify several Docker
    containers in an application file using the `YAML` format. For example, a configuration
    for a website with an instance of the Redis database might look like:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们只讨论了一些基本的Docker命令，这些命令可以让我们在单个容器中运行单个服务。然而，你也许能够理解，在“现实世界”中，我们通常需要同时运行一个或多个应用程序
    – 例如，一个网站将同时有一个获取和处理用户活动数据的网络应用程序和一个用于记录信息的数据库实例。在复杂的应用程序中，网站甚至可能由多个专门用于特定用例的小型网络应用程序或**微服务**组成，比如前端、用户数据或订单管理系统。对于这些类型的应用程序，我们需要多个容器彼此通信。Docker-compose工具（[https://docs.docker.com/compose/](https://docs.docker.com/compose/)）就是为此类应用程序而设计的：它允许我们使用`YAML`格式在应用文件中指定多个Docker容器。例如，一个具有Redis数据库实例的网站配置可能如下：
- en: '[PRE9]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Code 2.1: A yaml input file for Docker Compose'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 代码 2.1：Docker Compose的yaml输入文件
- en: 'The two application containers here are `web` and the `redis` database. The
    file also specified the volumes (disks) linked to these two applications. Using
    this configuration, we can run the command:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的两个应用程序容器分别是`web`和`redis`数据库。文件还指定了与这两个应用程序相关联的卷（磁盘）。使用这个配置，我们可以运行以下命令：
- en: '[PRE10]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: This starts all the containers specified in the YAML file and allows them to
    communicate with each other. However, even though Docker containers and docker-compose
    allow us to construct complex applications using consistent execution environments,
    we may potentially run into issues with robustness when we deploy these services
    to the cloud. For example, in a web application, we cannot be assured that the
    virtual machines that the application is running on will persist over long periods
    of time, so we need processes to manage self-healing and redundancy. This is also
    relevant to distributed machine learning pipelines, in which we do not want to
    have to kill an entire job because one node in a cluster goes down, which requires
    us to have backup logic to restart a sub-segment of work. Also, while Docker has
    the docker-compose functionality to link together several containers in an application,
    it does not have robust rules for how communication should happen among those
    containers, or how to manage them as a unit. For these purposes, we turn to the
    Kubernetes library.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 这将启动YAML文件中指定的所有容器，并允许它们彼此通信。然而，即使Docker容器和docker-compose允许我们使用一致的执行环境构建复杂的应用程序，当我们将这些服务部署到云端时，我们可能会遇到鲁棒性问题。例如，在一个网站应用程序中，我们无法保证应用程序运行的虚拟机会持续长时间，因此我们需要管理自愈和冗余的进程。这也与分布式机器学习流水线有关，其中我们不希望因为集群中的一个节点出现问题就不得不终止整个作业，因此我们需要备份逻辑来重新启动工作的一部分。此外，虽然Docker具有docker-compose功能来链接应用程序中的几个容器，但它没有健壮的规则来控制这些容器之间的通信，或者如何将它们作为一个单元进行管理。出于这些目的，我们转向Kubernetes库。
- en: 'Kubernetes: Robust management of multi-container applications'
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kubernetes：强大的多容器应用程序管理
- en: The Kubernetes project – sometimes abbreviated as k8s – was born out of an internal
    container management project at Google known as **Borg**. Kubernetes comes from
    the Greek word for navigator, as denoted by the seven-spoke wheel of the project's
    logo.^(18) Kubernetes is written in the Go programming language and provides a
    robust framework to deploy and manage Docker container applications on the underlying
    resources managed by cloud providers (such as **Amazon Web Services** (**AWS**),
    Microsoft Azure, and **Google Cloud Platform** (**GCP**)).
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes项目-有时缩写为k8s-诞生于谷歌内部称为**Borg**的容器管理项目。Kubernetes来自希腊词navigator，如项目标识的七条辐射轮所示。^(18)
    Kubernetes使用Go编程语言编写，提供了一个强大的框架，在由云提供商管理的底层资源上部署和管理Docker容器应用程序（例如**亚马逊网络服务**（**AWS**）、Microsoft
    Azure和**Google云平台**（**GCP**））。
- en: 'Kubernetes is fundamentally a tool to control applications composed of one
    or more Docker containers deployed in the cloud; this collection of containers
    is known as a **pod**. Each pod can have one or more copies (to allow redundancy),
    which is known as a **replicaset**. The two main components of a Kubernetes deployment
    are a **control plane** and **nodes**. The control plane hosts the centralized
    logic for deploying and managing pods, and consists of (*Figure 2.4*):'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes基本上是用来控制由一个或多个部署在云中的Docker容器组成的应用程序的工具；这个容器的集合称为**Pod**。每个Pod可以有一个或多个副本（以实现冗余），这称为**资源副本集**。Kubernetes部署的两个主要组件是**控制平面**和**节点**。控制平面承载了部署和管理Pod的集中逻辑，由(*图2.4*)组成：
- en: '![](img/B16176_02_04.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B16176_02_04.png)'
- en: 'Figure 2.4: Kubernetes components^(18)'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.4：Kubernetes组件^(18)
- en: '**Kube-api-server**: This is the main application that listens to commands
    from the user to deploy or update a pod, or manages external access to pods via
    `ingress`.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Kube-api-server**：这是主要的应用程序，它侦听用户的命令以部署或更新Pod，或通过`ingress`管理对Pod的外部访问。'
- en: '**Kube-controller-manager**: An application to manage functions such as controlling
    the number of replicas per pod.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Kube-controller-manager**：管理每个Pod副本数量等功能的应用程序。'
- en: '**Cloud-controller-manager**: Manages functions particular to a cloud provider.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Cloud-controller-manager**：管理特定于云提供商的功能。'
- en: '**Etcd**: A key-value store that maintains the environment and state variables
    of different pods.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Etcd**：维护不同Pod的环境和状态变量的键值存储。'
- en: '**Kube-scheduler**: An application that is responsible for finding workers
    to run a pod.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Kube-scheduler**：负责找到运行Pod的工作进程的应用程序。'
- en: While we could set up our own control plane, in practice we will usually have
    this function managed by our cloud provider, such as Google's **Google Kubernetes
    Engine** (**GKE**) or Amazon's **Elastic Kubernetes Services** (**EKS**). The
    Kubernetes nodes – the individual machines in the cluster – each run an application
    known as a **kubelet**, which monitors the pod(s) running on that node.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们可以设置自己的控制平面，但在实践中，通常我们会将此功能由我们的云提供商管理，例如谷歌的**Google Kubernetes引擎**（**GKE**）或亚马逊的**弹性Kubernetes服务**（**EKS**）。Kubernetes节点-集群中的各个单独的机器-每个都运行一个名为**kubelet**的应用程序，该应用程序监视运行在该节点上的Pod。
- en: Now that we have a high-level view of the Kubernetes system, let's look at the
    important commands you will need to interact with a Kubernetes cluster, update
    its components, and start and stop applications.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经对Kubernetes系统有了一个高层次的了解，接下来让我们来看一下你将需要与Kubernetes集群进行交互、更新其组件以及启动和停止应用程序的重要命令。
- en: Important Kubernetes commands
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 重要的Kubernetes命令
- en: 'In order to interact with a Kubernetes cluster running in the cloud, we typically
    utilize the **Kubernetes command-line tool** (**kubectl**). Instructions for installing
    kubectl for your operating system can be found at ([https://kubernetes.io/docs/tasks/tools/install-kubectl/](https://kubernetes.io/docs/tasks/tools/install-kubectl/)).
    To verify that you have successfully installed kubectl, you can again run the
    `help` command in the terminal:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 为了与在云中运行的Kubernetes集群进行交互，我们通常使用**Kubernetes命令行工具**（**kubectl**）。有关在您的操作系统上安装kubectl的说明可以在[https://kubernetes.io/docs/tasks/tools/install-kubectl/](https://kubernetes.io/docs/tasks/tools/install-kubectl/)找到。要验证您是否成功安装了kubectl，可以在终端中再次运行`help`命令：
- en: '[PRE11]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Like Docker, kubectl has many commands; the important one that we will use
    is the `apply` command, which, like `docker-compose`, takes in a YAML file as
    input and communicates with the Kubernetes control plane to start, update, or
    stop pods:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 与Docker一样，kubectl有许多命令；我们将使用的一个重要命令是`apply`命令，它与`docker-compose`类似，它将一个YAML文件作为输入并与Kubernetes控制平面通信以启动、更新或停止Pod：
- en: '[PRE12]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'As an example of how the `apply` command works, let us look at a YAML file
    for deploying a web server (`nginx`) application:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 作为 `apply` 命令运行方式的示例，让我们看一下用于部署 web 服务器 (`nginx`) 应用程序的 YAML 文件：
- en: '[PRE13]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The resources specified in this file are created on the Kubernetes cluster nodes
    in the order in which they are listed in the file. First, we create the load balancer,
    which routes external traffic between copies of the `nginx` web server. The `metadata`
    is used to tag these applications for querying later using kubectl. Secondly,
    we create a set of `3` `replicas` of the `nginx` pod, using a consistent container
    (image `1.7.9`), which uses port `80` on their respective containers.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 此文件中指定的资源将按照文件中列出的顺序在 Kubernetes 集群节点上创建。首先，我们创建负载均衡器，它在`nginx` web 服务器的副本之间路由外部流量。`metadata`
    用于为这些应用程序打标签，以便稍后使用 kubectl 进行查询。其次，我们使用一致的容器（镜像为 `1.7.9`）创建一组 `3` 个 `nginx` pod
    的副本，它们分别使用其容器上的端口 `80`。
- en: The same set of physical resources of a Kubernetes cluster can be shared among
    several **virtual** clusters using **namespaces** – this allows us to segregate
    resources among multiple users or groups. This can allow, for example, each team
    to run their own set of applications and logically behave as if they are the only
    users. Later, in our discussion of **Kubeflow**, we will see how this feature
    can be used to logically partition projects on the same Kubeflow instance.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 集群的同一组物理资源可以在多个**虚拟**集群中共享，使用**命名空间** – 这使我们可以将资源分隔到多个用户或组之间。例如，这可以让每个团队运行自己的一组应用程序，并在逻辑上表现得好像他们是唯一的用户。稍后，在我们对
    **Kubeflow** 的讨论中，我们将看到如何使用此功能在同一 Kubeflow 实例上逻辑分区项目。
- en: Kustomize for configuration management
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 用于配置管理的 Kustomize
- en: 'Like most code, we most likely want to ultimately store the YAML files we use
    to issue commands to Kubernetes in a version control system such as Git. This
    leads to some cases where this format might not be ideal: for example, in a machine
    learning pipeline, we might perform hyperparameter searches where the same application
    is being run with slightly different parameters, leading to a glut of duplicate
    command files.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 像大多数代码一样，我们最终可能希望将用于向 Kubernetes 发出命令的 YAML 文件存储在版本控制系统中，例如 Git。这导致一些情况下这种格式可能不理想：例如，在机器学习管道中，我们可能执行超参数搜索，其中相同的应用程序以稍微不同的参数运行，导致大量重复的命令文件。
- en: Or, we might have arguments, such as AWS account keys, that for security reasons
    we do not want to store in a text file. We might also want to increase reuse by
    splitting our command into a `base` and additions; for example, in the YAML file
    shown in *Code 2.1*, if we wanted to run ngnix alongside different databases,
    or specify file storage in the different cloud object stores provided by Amazon,
    Google, and Microsoft Azure.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，我们可能有一些参数，例如 AWS 账户密钥，出于安全原因，我们不希望将其存储在文本文件中。我们还可能希望通过将我们的命令拆分为 `base` 和附加部分来增加重用性；例如，在
    *代码 2.1* 中显示的 YAML 文件中，如果我们想要在不同的数据库中运行 ngnix，或者指定 Amazon、Google 和 Microsoft Azure
    提供的不同云对象存储中的文件存储。
- en: 'For these use cases, we will make use of the Kustomize tool ([https://kustomize.io](https://kustomize.io)),
    which is also available through kubectl as:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这些用例，我们将使用 Kustomize 工具（[https://kustomize.io](https://kustomize.io)），也可通过
    kubectl 使用：
- en: '[PRE14]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Alternatively, we could use the Kustomize command-line tool. A `kustomization.yaml`
    is a template for a Kubernetes application; for example, consider the following
    template for the training job in the Kubeflow example repository ([https://github.com/kubeflow/pipelines/blob/master/manifests/kustomize/sample/kustomization.yaml](https://github.com/kubeflow/pipelines/blob/master/manifests/kustomize/sample/kustomization.yaml)):'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，我们可以使用 Kustomize 命令行工具。`kustomization.yaml` 是一个 Kubernetes 应用程序的模板；例如，考虑以下模板，用于
    Kubeflow 示例存储库中的训练作业（[https://github.com/kubeflow/pipelines/blob/master/manifests/kustomize/sample/kustomization.yaml](https://github.com/kubeflow/pipelines/blob/master/manifests/kustomize/sample/kustomization.yaml)）：
- en: '[PRE15]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We can see that this file refers to a `base` set of configurations in a separate
    `kustomization.yaml` file located at the relative path `../base`. To edit variables
    in this file, for instance, to change the namespace for the application, we would
    `run`:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到此文件引用了位于相对路径 `../base` 的单独的 `kustomization.yaml` 文件中的 `base` 配置集。要编辑此文件中的变量，例如，要更改应用程序的命名空间，我们将执行：
- en: '[PRE16]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'We could also add configuration maps to pass to the training job, using a key-value
    format, for example:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以添加配置映射以传递给训练作业，使用键-值格式，例如：
- en: '[PRE17]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Finally, when we are ready to execute these commands on Kubernetes, we can `build`
    the necessary `kubectl` command dynamically and apply it, assuming `kustomization.yaml`
    is in the current directory.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，当我们准备在Kubernetes上执行这些命令时，我们可以动态地`build`并应用所需的`kubectl`命令，假设`kustomization.yaml`在当前目录中。
- en: '[PRE18]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Hopefully, these examples demonstrate how Kustomize provides a flexible way
    to generate the YAML we need for kubectl using a template; we will make use of
    it often in the process of parameterizing our workflows later in this book.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 希望这些示例演示了Kustomize如何提供一种灵活的方式来使用模板生成我们在本书后面的工作流程中经常需要的kubectl YAML；我们将经常利用它来参数化我们的工作流程。
- en: Now that we have covered how Kubernetes manages Docker applications in the cloud,
    and how Kustomize can allow us to flexibly reuse `kubectl yaml` commands, let's
    look at how these components are tied together in Kubeflow to run the kinds of
    experiments we will be undertaking later to create generative AI models in TensorFlow.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了Kubernetes如何在云中管理Docker应用程序，以及Kustomize如何允许我们灵活地重用`kubectl yaml`命令，让我们看看这些组件如何在Kubeflow中联系在一起，以运行我们稍后将进行的创建TensorFlow生成式AI模型的实验。
- en: 'Kubeflow: an end-to-end machine learning lab'
  id: totrans-138
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kubeflow：一个端到端的机器学习实验室
- en: 'As was described at the beginning of this chapter, there are many components
    of an end-to-end `lab` for machine learning research and development (*Table 2.1*),
    such as:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 正如本章开始时所描述的，端到端机器学习研究和开发的`lab`有许多组件（*表2.1*），例如：
- en: A way to manage and version library dependencies, such as TensorFlow, and package
    them for a reproducible computing environment
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管理和版本化库依赖，例如TensorFlow，并将其打包为可复现的计算环境
- en: Interactive research environments where we can visualize data and experiment
    with different settings
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可视化数据并尝试不同设置的交互式研究环境
- en: A systematic way to specify the steps of a pipeline – data processing, model
    tuning, evaluation, and deployment
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指定管道步骤的系统化方式 – 数据处理、模型调优、评估和部署
- en: Provisioning of resources to run the modeling process in a distributed manner
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分布式运行建模过程所需资源的供应
- en: Robust mechanisms for snapshotting historical versions of the research process
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 具有快照历史版本的研究过程的强大机制
- en: As we described earlier in this chapter, TensorFlow was designed to utilize
    distributed resources for training. To leverage this capability, we will use the
    Kubeflow projects. Built on top of Kubernetes, Kubeflow has several components
    that are useful in the end-to-end process of managing machine learning applications.
    To install Kubeflow, we need to have an existing Kubernetes control plane instance
    and use kubectl to launch Kubeflow's various components. The steps for setup differ
    slightly depending upon whether we are using a local instance or one of the major
    cloud providers.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在本章前面所描述的，TensorFlow被设计用于利用分布式资源进行训练。为了利用这一能力，我们将使用Kubeflow项目。Kubeflow建立在Kubernetes之上，具有几个在管理端到端机器学习应用程序过程中有用的组件。要安装Kubeflow，我们需要拥有现有的Kubernetes控制平面实例，并使用kubectl启动Kubeflow的各个组件。设置步骤会略有不同，取决于我们是使用本地实例还是主要云服务提供商之一。
- en: Running Kubeflow locally with MiniKF
  id: totrans-146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过MiniKF在本地运行Kubeflow
- en: If we want to get started quickly or prototype our application locally, we can
    avoid setting up a cloud account and instead use virtual machines to simulate
    the kind of resources we would provision in the cloud. To set up Kubeflow locally,
    we first need to install VirtualBox ([https://www.virtualbox.org/wiki/Downloads](https://www.virtualbox.org/wiki/Downloads))
    to run virtual machines, and Vagrant to run configurations for setting up a Kubernetes
    control plane and Kubeflow on VirtualBox VMs ([https://www.vagrantup.com/downloads.html](https://www.vagrantup.com/downloads.html)).
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想快速开始或在本地原型化我们的应用程序，我们可以避免设置云账户，而是使用虚拟机模拟我们在云中配置资源的方式。要在本地设置Kubeflow，我们首先需要安装VirtualBox
    ([https://www.virtualbox.org/wiki/Downloads](https://www.virtualbox.org/wiki/Downloads))
    以运行虚拟机，以及Vagrant以在VirtualBox虚拟机上运行配置，用于设置Kubernetes控制平面和Kubeflow（[https://www.vagrantup.com/downloads.html](https://www.vagrantup.com/downloads.html)）。
- en: 'Once you have these two dependencies installed, create a new directory, change
    into it, and run:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 安装了这两个依赖项后，创建一个新目录，切换到该目录并运行：
- en: '[PRE19]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'This initializes the VirtualBox configuration and brings up the application.
    You can now navigate to `http://10.10.10.10/` and follow the instructions to launch
    Kubeflow and Rok (a storage volume for data used in experiments on Kubeflow created
    by Arrikto). Once these have been provisioned, you should see a screen like this
    (*Figure 2.5*):'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 这将初始化VirtualBox配置并启动应用程序。现在，您可以导航到`http://10.10.10.10/`并按照说明启动Kubeflow和Rok（Arrikto创建，用于Kubeflow实验中使用的数据的存储卷）。一旦这些被提供，你应该看到一个像这样的屏幕（*图2.5*）：
- en: '![](img/B16176_02_05.png)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B16176_02_05.png)'
- en: 'Figure 2.5: MiniKF install screen in virtualbox^(19)'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.5：在虚拟盒子中的MiniKF安装界面^(19)
- en: 'Log in to Kubeflow to see the dashboard with the various components (*Figure
    2.6*):'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 登录到Kubeflow查看各个组件的仪表板（*图2.6*）：
- en: '![](img/B16176_02_06.png)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B16176_02_06.png)'
- en: 'Figure 2.6: Kubeflow dashboard in MiniKF'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.6：MiniKF中的Kubeflow仪表板
- en: We will return to these components later and go through the various functionalities
    available on Kubeflow, but first, let's walk through how to install Kubeflow in
    the cloud.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在后面回到这些组件，并了解Kubeflow提供的各种功能，但首先，让我们一起看看如何在云中安装Kubeflow。
- en: Installing Kubeflow in AWS
  id: totrans-157
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在AWS中安装Kubeflow
- en: 'In order to run Kubeflow in AWS, we need a Kubernetes control plane available
    in the cloud. Fortunately, Amazon provides a managed service called EKS, which
    provides an easy way to provision a control plane to deploy Kubeflow. Follow the
    following steps to deploy Kubeflow on AWS:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在AWS上运行Kubeflow，我们需要在云中提供一个Kubernetes控制平面。幸运的是，亚马逊提供了一个名为EKS的托管服务，它可以方便地提供一个控制平面来部署Kubeflow。按照以下步骤在AWS上部署Kubeflow：
- en: '**Register for an AWS account and install the AWS Command Line Interface**'
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**注册AWS账户并安装AWS命令行界面**'
- en: 'This is needed to interact with the various AWS services, following the instructions
    for your platform located at [https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-install.html](https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-install.html).
    Once it is installed, enter:'
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是与各种AWS服务进行交互所需的，根据您平台上的说明位于[https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-install.html](https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-install.html)。安装完成后，输入：
- en: '[PRE20]'
  id: totrans-161
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: to set up your account and key information to provision resources.
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为了设置您的账户和密钥信息来提供资源。
- en: '**Install eksctl**'
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**安装eksctl**'
- en: This command-line utility allows us to provision a Kubernetes control plane
    in Amazon from the command line. Follow instructions at [https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-install.html](https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-install.html)
    to install.
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这个命令行实用程序允许我们从命令行在亚马逊中提供一个Kubernetes控制平面。按照[https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-install.html](https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-install.html)上的说明进行安装。
- en: '**Install iam-authenticator**'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**安装iam-authenticator**'
- en: To allow kubectl to interact with EKS, we need to provide the correct permissions
    using the IAM authenticator to modify our kubeconfig. Please see the installation
    instructions at [https://docs.aws.amazon.com/eks/latest/userguide/install-aws-iam-authenticator.html](https://docs.aws.amazon.com/eks/latest/userguide/install-aws-iam-authenticator.html).
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为了允许kubectl与EKS进行交互，我们需要使用IAM验证器提供正确的权限来修改我们的kubeconfig。请参考[https://docs.aws.amazon.com/eks/latest/userguide/install-aws-iam-authenticator.html](https://docs.aws.amazon.com/eks/latest/userguide/install-aws-iam-authenticator.html)上的安装说明。
- en: '**Download the Kubeflow command-line tool**'
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**下载Kubeflow命令行工具**'
- en: 'Links are located at the Kubeflow releases page ([https://github.com/kubeflow/kubeflow/releases/tag/v0.7.1](https://github.com/kubeflow/kubeflow/releases/tag/v0.7.1)).
    Download one of these directories and unpack the tarball using:'
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 链接位于Kubeflow发布页面([https://github.com/kubeflow/kubeflow/releases/tag/v0.7.1](https://github.com/kubeflow/kubeflow/releases/tag/v0.7.1))。下载其中一个目录，并使用以下命令解压tarball：
- en: '[PRE21]'
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '**Build the configuration file**'
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**构建配置文件**'
- en: 'After entering environment variables for the Kubeflow application director
    (`${KF_DIR}`), the name of the deployment (`${KF_NAME}`), and the path to the
    base configuration file for the deployment (`${CONFIG_URI}`), which is located
    at [https://raw.githubusercontent.com/kubeflow/manifests/v0.7-branch/kfdef/kfctl_aws.0.7.1.yaml](https://raw.githubusercontent.com/kubeflow/manifests/v0.7-branch/kfdef/kfctl_aws.0.7.1.yaml)
    for AWS deployments, run the following to generate the configuration file:'
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输入Kubeflow应用程序目录（`${KF_DIR}`）、部署名称（`${KF_NAME}`）和部署的基本配置文件的路径（`${CONFIG_URI}`）的环境变量，位于[https://raw.githubusercontent.com/kubeflow/manifests/v0.7-branch/kfdef/kfctl_aws.0.7.1.yaml](https://raw.githubusercontent.com/kubeflow/manifests/v0.7-branch/kfdef/kfctl_aws.0.7.1.yaml)用于AWS部署，运行以下命令生成配置文件：
- en: '[PRE22]'
  id: totrans-172
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'This will generate a local configuration file locally named `kfctl_aws.0.7.1.yaml`.
    If this looks like Kustomize, that''s because `kfctl` is using Kustomize under
    the hood to build the configuration. We also need to add an environment variable
    for the location of the local config file, `${CONFIG_FILE}`, which in this case
    is:'
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将在本地生成一个名为`kfctl_aws.0.7.1.yaml`的本地配置文件。如果这看起来像 Kustomize，那是因为`kfctl`在内部使用
    Kustomize 来构建配置。我们还需要为本地配置文件的位置添加一个环境变量`${CONFIG_FILE}`，在这种情况下是：
- en: '[PRE23]'
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '**Launch Kubeflow on EKS**'
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**在 EKS 上启动 Kubeflow**'
- en: 'Use the following commands to launch Kubeflow:'
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用以下命令启动 Kubeflow：
- en: '[PRE24]'
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'It will take a while for all the Kubeflow components to become available; you can
    check the progress by using the following command:'
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 所有 Kubeflow 组件变为可用将需要一些时间；您可以通过使用以下命令来检查进度：
- en: '[PRE25]'
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Once they are all available, we can get the URL address for the Kubeflow dashboard
    using:'
  id: totrans-180
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一旦它们都可用，我们可以使用以下命令获取 Kubeflow 仪表板的 URL 地址：
- en: '[PRE26]'
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: This will take us to the dashboard view shown in the MiniKF examples above.
    Note that in the default configuration, this address is open to the public; for
    secure applications, we need to add authentication using the instructions at [https://www.kubeflow.org/docs/aws/authentication/](https://www.kubeflow.org/docs/aws/authentication/).
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 这将带我们到上面的 MiniKF 示例中显示的仪表盘视图。请注意，在默认配置中，此地址对公众开放；对于安全应用程序，我们需要按照[https://www.kubeflow.org/docs/aws/authentication/](https://www.kubeflow.org/docs/aws/authentication/)中的说明添加身份验证。
- en: Installing Kubeflow in GCP
  id: totrans-183
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 GCP 中安装 Kubeflow
- en: 'Like AWS, **Google Cloud Platform** (**GCP**) provides a managed Kubernetes
    control plane, GKE. We can install Kubeflow in GCP using the following steps:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 像 AWS 一样，**Google 云平台**（**GCP**）提供了一个托管的 Kubernetes 控制平面 GKE。我们可以使用以下步骤在 GCP
    中安装 Kubeflow：
- en: '**Register for a GCP account and create a project on the console**'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**注册 GCP 账户并在控制台上创建一个项目**'
- en: This project will be where the various resources associated with Kubeflow will
    reside.
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 该项目将是与 Kubeflow 相关的各种资源所在的位置。
- en: '**Enable required services**'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**启用所需服务**'
- en: 'The services required to run Kubeflow on GCP are:'
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在 GCP 上运行 Kubeflow 所需的服务包括：
- en: Compute Engine API
  id: totrans-189
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算引擎 API
- en: Kubernetes Engine API
  id: totrans-190
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes 引擎 API
- en: Identity and Access Management (IAM) API
  id: totrans-191
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 身份和访问管理（IAM）API
- en: Deployment Manager API
  id: totrans-192
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署管理器 API
- en: Cloud Resource Manager API
  id: totrans-193
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 云资源管理器 API
- en: Cloud Filestore API
  id: totrans-194
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 云文件存储 API
- en: AI Platform Training & Prediction API
  id: totrans-195
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: AI 平台培训和预测 API
- en: '**Set up OAuth (optional)**'
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**设置 OAuth（可选）**'
- en: If you wish to make a secure deployment, then, as with AWS, you must follow
    instructions to add authentication to your installation, located at ([https://www.kubeflow.org/docs/gke/deploy/oauth-setup/](https://www.kubeflow.org/docs/gke/deploy/oauth-setup/)).
    Alternatively, you can just use the name and password for your GCP account.
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果您希望进行安全的部署，那么，与 AWS 一样，您必须按照说明添加身份验证到您的安装中，位于([https://www.kubeflow.org/docs/gke/deploy/oauth-setup/](https://www.kubeflow.org/docs/gke/deploy/oauth-setup/))。或者，您可以只使用
    GCP 账户的用户名和密码。
- en: '**Set up the GCloud CLI**'
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**设置 GCloud CLI**'
- en: 'This is parallel to the AWS CLI covered in the previous section. Installation
    instructions are available at [https://cloud.google.com/sdk/](https://cloud.google.com/sdk/).
    You can verify your installation by running:'
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这类似于前一节中涵盖的 AWS CLI。安装指南可在[https://cloud.google.com/sdk/](https://cloud.google.com/sdk/)找到。您可以通过运行以下命令来验证您的安装：
- en: '[PRE27]'
  id: totrans-200
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '**Download the kubeflow command-line tool**'
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**下载 Kubeflow 命令行工具**'
- en: 'Links are located on the Kubeflow releases page ([https://github.com/kubeflow/kubeflow/releases/tag/v0.7.1](https://github.com/kubeflow/kubeflow/releases/tag/v0.7.1)).
    Download one of these directories and unpack the tarball using:'
  id: totrans-202
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 链接位于 Kubeflow 发行版页面（[https://github.com/kubeflow/kubeflow/releases/tag/v0.7.1](https://github.com/kubeflow/kubeflow/releases/tag/v0.7.1)）。下载其中一个目录并使用以下命令解压
    tar 文件：
- en: '[PRE28]'
  id: totrans-203
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '**Log in to GCloud and create user credentials**'
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**登录 Google 云并创建用户凭据**'
- en: We next need to create a login account and credential token we will use to interact
    with resources in our account.
  id: totrans-205
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 接下来，我们需要创建一个登录账户和凭据令牌，用于与我们的账户中的资源进行交互。
- en: '[PRE29]'
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '**Set up environment variable and deploy Kubeflow**'
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**设置环境变量并部署 Kubeflow**'
- en: 'As with AWS, we need to enter values for a few key environment variables: the
    application containing the Kubeflow configuration files (`${KF_DIR}`), the name
    of the Kubeflow deployment (`${KF_NAME}`), the path to the base configuration
    URI (`${CONFIG_URI}` – for GCP this is [https://raw.githubusercontent.com/kubeflow/manifests/v0.7-branch/kfdef/kfctl_gcp_iap.0.7.1.yaml](https://raw.githubusercontent.com/kubeflow/manifests/v0.7-branch/kfdef/kfctl_gcp_iap.0.7.1.yaml)),
    the name of the Google project (`${PROJECT}`), and the zone it runs in (`${ZONE}`).'
  id: totrans-208
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 与AWS一样，我们需要为一些关键环境变量输入值：包含Kubeflow配置文件的应用程序（`${KF_DIR}`），Kubeflow部署的名称（`${KF_NAME}`），基本配置URI的路径（`${CONFIG_URI}`-
    对于GCP，这是[https://raw.githubusercontent.com/kubeflow/manifests/v0.7-branch/kfdef/kfctl_gcp_iap.0.7.1.yaml](https://raw.githubusercontent.com/kubeflow/manifests/v0.7-branch/kfdef/kfctl_gcp_iap.0.7.1.yaml)），Google项目的名称（`${PROJECT}`）以及它所在的区域（`${ZONE}`）。
- en: '**Launch Kubeflow**'
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**启动Kubeflow**'
- en: 'The same as AWS, we use Kustomize to build the template file and launch Kubeflow:'
  id: totrans-210
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 与AWS一样，我们使用Kustomize构建模板文件并启动Kubeflow：
- en: '[PRE30]'
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Once Kubeflow is launched, you can get the URL to the dashboard using:'
  id: totrans-212
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一旦启动了Kubeflow，您可以使用以下命令获取仪表板的URL：
- en: '[PRE31]'
  id: totrans-213
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Installing Kubeflow on Azure
  id: totrans-214
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在Azure上安装Kubeflow
- en: Azure is Microsoft Corporation's cloud offering, and like AWS and GCP, we can
    use it to install Kubeflow leveraging a Kubernetes control plane and computing
    resources residing in the Azure cloud.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: Azure是微软公司的云服务，和AWS和GCP一样，我们可以利用它来安装Kubeflow，利用在Azure云中驻留的Kubernetes控制平面和计算资源。
- en: '**Register an account on Azure**'
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**在Azure上注册账户**'
- en: Sign up at [https://azure.microsoft.com](https://azure.microsoft.com) – a free
    tier is available for experimentation.
  id: totrans-217
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在[https://azure.microsoft.com](https://azure.microsoft.com)注册账号-可用于实验的免费层。
- en: '**Install the Azure command-line utilities**'
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**安装Azure命令行实用程序**'
- en: 'See instructions for installation on your platform at [https://docs.microsoft.com/en-us/cli/azure/install-azure-cli?view=azure-cli-latest](https://docs.microsoft.com/en-us/cli/azure/install-azure-cli?view=azure-cli-latest).
    You can verify your installation by running the following on the command line
    on your machine:'
  id: totrans-219
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 请参阅[https://docs.microsoft.com/en-us/cli/azure/install-azure-cli?view=azure-cli-latest](https://docs.microsoft.com/en-us/cli/azure/install-azure-cli?view=azure-cli-latest)上平台的安装说明。您可以通过在本地计算机的命令行上运行以下命令来验证安装：
- en: '[PRE32]'
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'This should print a list of commands that you can use on the console. To start,
    log in to your account with:'
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这应该会打印出您可以在控制台上使用的命令列表。首先，通过以下命令登录您的帐户：
- en: '[PRE33]'
  id: totrans-222
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'And enter the account credentials you registered in *Step 1*. You will be redirected
    to a browser to verify your account, after which you should see a response like
    the following:'
  id: totrans-223
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 并输入您在*步骤1*中注册的帐户凭据。您将被重定向到浏览器以验证您的帐户，之后您应该会看到类似以下的响应：
- en: '[PRE34]'
  id: totrans-224
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '**Create the resource group for a new cluster**'
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**为新集群创建资源组**'
- en: 'We first need to create the resource group where our new application will live,
    using the following command:'
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们首先需要创建新应用所在的资源组，使用以下命令：
- en: '[PRE35]'
  id: totrans-227
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '**Create a Kubernetes resource on AKS**'
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**在AKS上创建Kubernetes资源**'
- en: 'Now deploy the Kubernetes control plane on your resource group:'
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在，在您的资源组上部署Kubernetes控制平面：
- en: '[PRE36]'
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '**Install Kubeflow**'
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**安装Kubeflow**'
- en: 'First, we need to obtain credentials to install Kubeflow on our AKS resource:'
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 首先，我们需要获取凭据以在我们的AKS资源上安装Kubeflow：
- en: '[PRE37]'
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '**Install kfctl**'
  id: totrans-234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**安装kfctl**'
- en: 'Install and unpack the tarball directory:'
  id: totrans-235
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 安装并解压缩tarball目录：
- en: '[PRE38]'
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '**Set environment variables**'
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**设置环境变量**'
- en: 'As with AWS, we need to enter values for a few key environment variables: the
    application containing the Kubeflow configuration files (`${KF_DIR}`), the name
    of the Kubeflow deployment (`${KF_NAME}`), and the path to the base configuration
    URI (`${CONFIG_URI}` – for Azure, this is [https://raw.githubusercontent.com/kubeflow/manifests/v0.7-branch/kfdef/kfctl_k8s_istio.0.7.1.yaml](https://raw.githubusercontent.com/kubeflow/manifests/v0.7-branch/kfdef/kfctl_k8s_istio.0.7.1.yaml)).'
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 与AWS一样，我们需要为一些关键环境变量输入值：包含Kubeflow配置文件的应用程序（`${KF_DIR}`），Kubeflow部署的名称（`${KF_NAME}`），和基本配置URI的路径（`${CONFIG_URI}`-
    对于Azure，这是[https://raw.githubusercontent.com/kubeflow/manifests/v0.7-branch/kfdef/kfctl_k8s_istio.0.7.1.yaml](https://raw.githubusercontent.com/kubeflow/manifests/v0.7-branch/kfdef/kfctl_k8s_istio.0.7.1.yaml)）。
- en: '**Launch Kubeflow**'
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**启动Kubeflow**'
- en: 'The same as AWS, we use Kustomize to build the template file and launch Kubeflow:'
  id: totrans-240
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 与AWS一样，我们使用Kustomize构建模板文件并启动Kubeflow：
- en: '[PRE39]'
  id: totrans-241
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Once Kubeflow is launched, you can use port forwarding to redirect traffic
    from local port `8080` to port `80` in the cluster to access the Kubeflow dashboard
    at `localhost:8080` using the following command:'
  id: totrans-242
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一旦启动Kubeflow，您可以使用端口转发将本地端口`8080`的流量重定向到集群中的端口`80`，以使用以下命令在`localhost:8080`上访问Kubeflow仪表板：
- en: '[PRE40]'
  id: totrans-243
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Installing Kubeflow using Terraform
  id: totrans-244
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Terraform安装Kubeflow
- en: For each of these cloud providers, you'll probably notice that we have a common
    set of commands; creating a Kubernetes cluster, installing Kubeflow, and starting
    the application. While we can use scripts to automate this process, it would be
    desirable to, like our code, have a way to version control and persist different
    infrastructure configurations, allowing a reproducible recipe for creating the
    set of resources we need to run Kubeflow. It would also help us potentially move
    between cloud providers without completely rewriting our installation logic.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这些云提供商，你可能会注意到我们有一套共同的命令；创建一个Kubernetes集群，安装Kubeflow，并启动应用程序。虽然我们可以使用脚本来自动化这个过程，但想要像我们的代码一样，有一种方法来版本控制和持久化不同的基础设施配置，允许创建运行Kubeflow所需资源集合的可重现的配方，这将是可取的。这也有助于我们在不完全重写安装逻辑的情况下，潜在地在不同的云提供商之间移动。
- en: The template language **Terraform** ([https://www.terraform.io/](https://www.terraform.io/))
    was created by HashiCorp as a tool for **Infrastructure as a Service** (**IaaS**).
    In the same way that Kubernetes has an API to update resources on a cluster, **Terraform**
    allows us to abstract interactions with different underlying cloud providers using
    an API and a template language using a command-line utility and core components
    written in GoLang (*Figure 2.7*). Terraform can be extended using user-written
    plugins.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 模板语言**Terraform** ([https://www.terraform.io/](https://www.terraform.io/))是由HashiCorp创建的一种用于**基础设施即服务**（**IaaS**）的工具。就像Kubernetes有一个API来更新集群上的资源一样，**Terraform**允许我们使用API和模板语言来抽象不同的底层云提供商的交互，使用命令行工具和用GoLang编写的核心组件。Terraform可以使用用户编写的插件进行扩展。
- en: '![](img/B16176_02_07.png)'
  id: totrans-247
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B16176_02_07.png)'
- en: 'Figure 2.7: Terraform architecture^(20)'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.7：Terraform架构^(20)
- en: 'Let''s look at one example of installing Kubeflow using Terraform instructions
    on AWS, located at [https://github.com/aws-samples/amazon-eks-machine-learning-with-terraform-and-kubeflow](https://github.com/aws-samples/amazon-eks-machine-learning-with-terraform-and-kubeflow).
    Once you have established the required AWS resources and installed terraform on
    an EC2 container, the `aws-eks-cluster-and-nodegroup.tf` Terraform file is used
    to create the Kubeflow cluster using the command:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: '让我们以安装Kubeflow在AWS上使用Terraform指南的一个例子，位于[https://github.com/aws-samples/amazon-eks-machine-learning-with-terraform-and-kubeflow](https://github.com/aws-samples/amazon-eks-machine-learning-with-terraform-and-kubeflow)上。一旦你在EC2容器上建立所需的AWS资源并安装了terraform，`aws-eks-cluster-and-nodegroup.tf`
    Terraform文件用于使用命令创建Kubeflow集群： '
- en: '[PRE41]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'In this file are a few key components. One is variables that specify aspects
    of the deployment:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 这个文件中有一些关键组件。一个是指定部署方面的变量：
- en: '[PRE42]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Another is a specification for which cloud provider we are using:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个是指定我们正在使用的云提供商的规范：
- en: '[PRE43]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'And another is resources such as the EKS cluster:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 还有另一个是诸如EKS集群这样的资源：
- en: '[PRE44]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: Every time we run the Terraform `apply` command, it walks through this file
    to determine what resources to create, which underlying AWS services to call to
    create them, and with which set of configuration they should be provisioned. This
    provides a clean way to orchestrate complex installations such as Kubeflow in
    a versioned, extensible template language.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 每次运行Terraform `apply` 命令时，它都会遍历这个文件，确定要创建哪些资源，调用哪些底层AWS服务来创建它们，以及他们应该使用哪组配置进行配置。这为编排诸如Kubeflow之类的复杂安装提供了一种清晰的方式，这是一种版本化的、可扩展的模板语言。
- en: Now that we have successfully installed Kubeflow either locally or on a managed
    Kubernetes control plane in the cloud, let us take a look at what tools are available
    on the platform.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经成功地在本地或在云端的托管Kubernetes控制面板上安装了Kubeflow，让我们看看平台上有哪些可用的工具。
- en: A brief tour of Kubeflow's components
  id: totrans-259
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kubeflow组件简介
- en: 'Now that we have installed Kubeflow locally or in the cloud, let us take a
    look again at the Kubeflow dashboard (*Figure 2.8*):'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经在本地或云端安装了Kubeflow，让我们再次看看Kubeflow仪表板（*图2.8*）：
- en: '![](img/B16176_02_08.png)'
  id: totrans-261
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B16176_02_08.png)'
- en: 'Figure 2.8: The Kubeflow dashboard'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.8：Kubeflow仪表板
- en: 'Let''s walk through what is available in this toolkit. First, notice in the
    upper panel we have a dropdown with the name `anonymous` specified – this is the
    `namespace` for Kubernetes referred to earlier. While our default is `anonymous`,
    we could create several namespaces on our Kubeflow instance to accommodate different
    users or projects. This can be done at login, where we set up a profile (*Figure
    2.9*):'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看这个工具包提供了什么。首先，注意到在上面的面板中，我们有一个下拉菜单，其中指定了名称为`anonymous` – 这是前面提到的 Kubernetes
    的`namespace`。虽然我们的默认值是`anonymous`，但我们可以在我们的 Kubeflow 实例上创建多个命名空间，以容纳不同的用户或项目。这可以在登录时完成，我们在那里设置一个个人资料（*图
    2.9*）：
- en: '![](img/B16176_02_09_a+b.png)'
  id: totrans-264
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B16176_02_09_a+b.png)'
- en: 'Figure 2.9: Kubeflow login page'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.9：Kubeflow 登录页面
- en: 'Alternatively, as with other operations in Kubernetes, we can apply a namespace
    using a YAML file:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，与 Kubernetes 中的其他操作一样，我们可以使用 YAML 文件应用一个命名空间：
- en: '[PRE45]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Using the `kubectl` command:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`kubectl`命令：
- en: '[PRE46]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: What can we do once we have a namespace? Let us look through the available tools.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了命名空间，我们可以做些什么呢？让我们看看可用的工具。
- en: Kubeflow notebook servers
  id: totrans-271
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kubeflow 笔记本服务器
- en: 'We can use Kubeflow to start a Jupyter notebook server in a namespace, where
    we can run experimental code; we can start the notebook by clicking the **Notebook
    Servers** tab in the user interface and selecting **NEW SERVER** (*Figure 2.10*):'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 Kubeflow 在一个命名空间中启动一个 Jupyter 笔记本服务器，在这里我们可以运行实验性的代码；我们可以通过用户界面中的**Notebook
    Servers**选项卡并选择**NEW SERVER**来启动笔记本（*图 2.10*）：
- en: '![](img/B16176_02_10.png)'
  id: totrans-273
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B16176_02_10.png)'
- en: 'Figure 2.10: Kubeflow notebook creation'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.10：Kubeflow 笔记本创建
- en: We can then specify parameters, such as which container to run (which could
    include the TensorFlow container we examined earlier in our discussion of Docker),
    and how many resources to allocate (*Figure 2.11*).
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以指定参数，比如要运行哪个容器（可能包括我们在之前关于 Docker 讨论中检查过的 TensorFlow 容器），以及分配多少资源（*图 2.11*）。
- en: '![](img/B16176_02_11.png)'
  id: totrans-276
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B16176_02_11.png)'
- en: 'Figure 2.11: Kubeflow Docker resources panel'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.11：Kubeflow Docker 资源面板
- en: You can also specify a **Persistent Volume** (**PV**) to store data that remains
    even if the notebook server is turned off, and special resources such as GPUs.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以指定一个**持久卷**（**PV**）来存储数据，即使笔记本服务器被关闭，数据仍然保留，以及特殊资源，比如 GPU。
- en: Once started, if you have specified a container with TensorFlow resources, you
    can begin running models in the notebook server.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦启动，如果您已经指定了一个包含 TensorFlow 资源的容器，您可以在笔记本服务器中开始运行模型。
- en: Kubeflow pipelines
  id: totrans-280
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kubeflow 流水线
- en: For notebook servers, we gave an example of a single container (the notebook
    instance) application. Kubeflow also gives us the ability to run multi-container
    application workflows (such as input data, training, and deployment) using the
    **pipelines** functionality. Pipelinesare Python functions that follow a **Domain
    Specific Language** (**DSL**) to specify components that will be compiled into
    containers.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 对于笔记本服务器，我们举了一个单一容器（笔记本实例）应用的例子。Kubeflow 还通过**pipelines**功能为我们提供了运行多容器应用工作流（如输入数据、训练和部署）的能力。Pipelines
    是遵循**领域特定语言**（**DSL**）的 Python 函数，用于指定将编译为容器的组件。
- en: 'If we click pipelines on the UI, we are brought to a dashboard (*Figure 2.12*):'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们在用户界面上点击 pipelines，我们会被带到一个仪表盘（*图 2.12*）：
- en: '![](img/B16176_02_12.png)'
  id: totrans-283
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B16176_02_12.png)'
- en: 'Figure 2.12: Kubeflow pipelines sashboard'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.12：Kubeflow 流水线仪表盘
- en: Selecting one of these pipelines, we can see a visual overview of the component
    containers (*Figure 2.13*).
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 选择其中一个流水线，我们可以看到组件容器的视觉概览（*图 2.13*）。
- en: '![](img/B16176_02_13.png)'
  id: totrans-286
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B16176_02_13.png)'
- en: 'Figure 2.13: Kubeflow pipelines visualization'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.13：Kubeflow 流水线可视化
- en: After creating a new run, we can specify parameters for a particular instance
    of this pipeline (*Figure 2.14*).
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 创建新的运行之后，我们可以为该流水线的特定实例指定参数（*图 2.14*）。
- en: '![](img/B16176_02_14.png)'
  id: totrans-289
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B16176_02_14.png)'
- en: 'Figure 2.14: Kubeflow pipelines parameters'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.14：Kubeflow 流水线参数
- en: 'Once the pipeline is created, we can use the user interface to visualize the
    results (*Figure 2.15*):'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦流水线创建完毕，我们可以使用用户界面来可视化结果（*图 2.15*）：
- en: '![](img/B16176_02_15+16.png)'
  id: totrans-292
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B16176_02_15+16.png)'
- en: 'Figure 2.15: Kubeflow pipeline results visualization'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.15：Kubeflow 流水线结果可视化
- en: 'Under the hood, the Python code to generate this pipeline is compiled using
    the pipelines SDK. We could specify the components to come either from a container
    with Python code:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 在幕后，用于生成此流水线的 Python 代码是使用流水线 SDK 编译的。我们可以指定组件来自具有 Python 代码的容器：
- en: '[PRE47]'
  id: totrans-295
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'For a pure Python function, we could turn this into an operation with the compiler:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 对于纯 Python 函数，我们可以使用编译器将其转换为一个操作：
- en: '[PRE48]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'We then use the `dsl.pipeline` decorator to add this operation to a pipeline:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们使用 `dsl.pipeline` 装饰器将此操作添加到流水线中：
- en: '[PRE49]'
  id: totrans-299
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'We compile it using the following code:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用以下代码进行编译：
- en: '[PRE50]'
  id: totrans-301
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'and run it with this code:'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 运行此代码：
- en: '[PRE51]'
  id: totrans-303
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: We can also upload this ZIP file to the pipelines UI, where Kubeflow can use
    the generated YAML from compilation to instantiate the job.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以将此 ZIP 文件上传到流水线 UI，在那里 Kubeflow 可以使用编译生成的 YAML 实例化作业。
- en: Now that you have seen the process for generating results for a single pipeline,
    our next problem is how to generate the optimal parameters for such a pipeline.
    As you will see in *Chapter 3*, *Building Blocks of Deep Neural Networks*, neural
    network models typically have a number of configurations, known as **hyperparameters**,
    which govern their architecture (such as number of layers, layer size, and connectivity)
    and training paradigm (such as learning rate and optimizer algorithm). Kubeflow
    has a built-in utility for optimizing models for such parameter grids, called
    **Katib**.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经看到了生成单个流水线结果的过程，我们下一个问题是如何生成这样一个流水线的最佳参数。正如你将在*第3章*，*深度神经网络的构建模块*中看到的那样，神经网络模型通常具有多个配置，称为**超参数**，它们管理着它们的体系结构（例如层数、层大小和连接性）和训练范式（例如学习率和优化器算法）。Kubeflow
    具有用于优化此类参数网格的内置实用程序，称为**Katib**。
- en: Using Kubeflow Katib to optimize model hyperparameters
  id: totrans-306
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Kubeflow Katib 优化模型超参数
- en: 'Katib is a framework for running multiple instances of the same job with differing
    inputs, such as in neural architecture search (for determining the right number
    and size of layers in a neural network) and hyperparameter search (finding the
    right learning rate, for example, for an algorithm). Like the other Kustomize
    templates we have seen, the TensorFlow job specifies a generic TensorFlow job,
    with placeholders for the parameters:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: Katib 是一个框架，用于使用不同的输入运行同一作业的多个实例，例如神经架构搜索（用于确定神经网络中正确的层数和大小）和超参数搜索（例如为算法找到正确的学习率）。与我们见过的其他
    Kustomize 模板一样，TensorFlow 作业指定了一个通用的 TensorFlow 作业，并为参数留有占位符：
- en: '[PRE52]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'which we can run using the familiar `kubectl` syntax:'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用熟悉的 `kubectl` 语法来运行它：
- en: '[PRE53]'
  id: totrans-310
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'or through the UI (*Figure 2.16*):'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 或通过 UI（*图2.16*）：
- en: '![](img/B16176_02_16.png)'
  id: totrans-312
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B16176_02_16.png)'
- en: 'Figure 2.16: Katib UI on Kubeflow'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.16：Kubeflow 上的 Katib UI
- en: where you can see a visual of the outcome of these multi-parameter experiments,
    or a table (*Figures 2.17* and *2.18*).
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里你可以看到这些多参数实验的结果可视化，或者一个表格（*图2.17*和*2.18*）。
- en: '![](img/B16176_02_17.png)'
  id: totrans-315
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B16176_02_17.png)'
- en: 'Figure 2.17: Kubeflow visualization for multi-dimensional parameter optimization'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.17：Kubeflow 多维参数优化的可视化
- en: '![](img/B16176_02_18.png)'
  id: totrans-317
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B16176_02_18.png)'
- en: 'Figure 2.18: Kubeflow UI for multi-outcome experiments'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.18：Kubeflow 多结果实验的 UI
- en: Summary
  id: totrans-319
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we have covered an overview of what TensorFlow is and how it
    serves as an improvement over earlier frameworks for deep learning research. We
    also explored setting up an IDE, VSCode, and the foundation of reproducible applications,
    Docker containers. To orchestrate and deploy Docker containers, we discussed the
    Kubernetes framework, and how we can scale groups of containers using its API.
    Finally, I described Kubeflow, a machine learning framework built on Kubernetes
    which allows us to run end-to-end pipelines, distributed training, and parameter
    search, and serve trained models. We then set up a Kubeflow deployment using Terraform,
    an IaaS technology.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们概述了 TensorFlow 是什么，以及它如何作为深度学习研究的改进，我们还探讨了设置 IDE、VSCode 和可重现应用程序的基础，Docker
    容器。为了编排和部署 Docker 容器，我们讨论了 Kubernetes 框架，以及如何使用其 API 扩展容器组。最后，我描述了 Kubeflow，一个建立在
    Kubernetes 上的机器学习框架，它允许我们运行端到端的流水线、分布式训练和参数搜索，并为训练后的模型提供服务。然后，我们使用 Terraform，一种
    IaaS 技术，设置了 Kubeflow 部署。
- en: Before jumping into specific projects, we will next cover the basics of neural
    network theory and the TensorFlow and Keras commands that you will need to write
    basic training jobs on Kubeflow.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入具体项目之前，我们将介绍神经网络理论的基础知识以及你需要编写基本训练作业的 TensorFlow 和 Keras 命令，在 Kubeflow 上。
- en: References
  id: totrans-322
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考资料
- en: 'Abadi, Martín, et al. (2016) *TensorFlow: Large-Scale Machine Learning on Heterogeneous
    Distributed Systems*. arXiv:1603.04467\. [https://arxiv.org/abs/1603.04467](https://arxiv.org/abs/1603.04467).'
  id: totrans-323
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Abadi, Martín 等（2016年）*TensorFlow：异构分布式系统上的大规模机器学习*。arXiv:1603.04467。[https://arxiv.org/abs/1603.04467](https://arxiv.org/abs/1603.04467)。
- en: Google. *TensorFlow*. Retrieved April 26, 2021, from [https://www.tensorflow.org/](https://www.tensorflow.org/)
  id: totrans-324
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 谷歌。*TensorFlow*。检索日期为2021年4月26日，网址：[https://www.tensorflow.org/](https://www.tensorflow.org/)
- en: 'MATLAB, Natick, Massachusetts: The MathWorks Inc. [https://www.mathworks.com/products/matlab.html](https://www.mathworks.com/products/matlab.html)'
  id: totrans-325
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: MATLAB，马萨诸塞州南提克：The MathWorks Inc。[https://www.mathworks.com/products/matlab.html](https://www.mathworks.com/products/matlab.html)
- en: Krizhevsky A., Sutskever I., & Hinton G E. *ImageNet Classification with Deep
    Convolutional Neural Networks*. [https://papers.nips.cc/paper/4824-imagenet-classification-with-deepconvolutional-neural-networks.pdf](https://papers.nips.cc/paper/4824-imagenet-classification-with-deepconvolutional-neural-networks.pdf)
  id: totrans-326
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Krizhevsky A., Sutskever I., & Hinton G E. *使用深度卷积神经网络的ImageNet分类*。[https://papers.nips.cc/paper/4824-imagenet-classification-with-deepconvolutional-neural-networks.pdf](https://papers.nips.cc/paper/4824-imagenet-classification-with-deepconvolutional-neural-networks.pdf)
- en: Dean J., Ng A., (2012, Jun 26). *Using large-scale brain simulations for machine
    learning and A.I.*. Google | The Keyword. [https://blog.google/technology/ai/using-large-scale-brain-simulations-for/](https://blog.google/technology/ai/using-large-scale-brain-simulations-for/)
  id: totrans-327
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Dean J., Ng A. (2012年6月26日)。*利用大规模脑模拟进行机器学习和AI*。Google | The Keyword。[https://blog.google/technology/ai/using-large-scale-brain-simulations-for/](https://blog.google/technology/ai/using-large-scale-brain-simulations-for/)
- en: Mnih, V., Kavukcuoglu, K., Silver, D., Graves, A., Antonoglou, I., Wierstra,
    D., Riedmiller, M. (2013). *Playing Atari with Deep Reinforcement Learning*. arXiv:1312.5602\.
    [https://arxiv.org/abs/1312.5602](https://arxiv.org/abs/1312.5602)
  id: totrans-328
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Mnih, V., Kavukcuoglu, K., Silver, D., Graves, A., Antonoglou, I., Wierstra,
    D., Riedmiller, M. (2013)。*使用深度强化学习玩Atari游戏*。arXiv:1312.5602。[https://arxiv.org/abs/1312.5602](https://arxiv.org/abs/1312.5602)
- en: Silver D, Schrittwieser J, Simonyan K, Antonoglou I, Huang A, Guez A, Hubert
    T, Baker L, Lai M, Bolton A, Chen Y, Lillicrap T, Hui F, Sifre L, van den Driessche
    G, Graepel T, Hassabis D. (2017) *Mastering the game of Go without human knowledge*.
    *Nature*. 550(7676):354-359\. [https://pubmed.ncbi.nlm.nih.gov/29052630/](https://pubmed.ncbi.nlm.nih.gov/29052630/)
  id: totrans-329
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Silver D, Schrittwieser J, Simonyan K, Antonoglou I, Huang A, Guez A, Hubert
    T, Baker L, Lai M, Bolton A, Chen Y, Lillicrap T, Hui F, Sifre L, van den Driessche
    G, Graepel T, Hassabis D. (2017)。*在没有人类知识的情况下掌握围棋*。*自然*。550(7676)：354-359。[https://pubmed.ncbi.nlm.nih.gov/29052630/](https://pubmed.ncbi.nlm.nih.gov/29052630/)
- en: 'Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2018). *Bert: Pre-training
    of deep bidirectional transformers for language understanding*. arXiv:1810.04805\.
    [https://arxiv.org/abs/1810.04805](https://arxiv.org/abs/1810.04805)'
  id: totrans-330
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2018)。*Bert：用于语言理解的深度双向transformers的预训练*。arXiv:1810.04805。[https://arxiv.org/abs/1810.04805](https://arxiv.org/abs/1810.04805)
- en: 'Al-Rfou, R., et al. (2016). *Theano: A Python framework for fast computation
    of mathematical expressions*. arXiv. [https://arxiv.org/pdf/1605.02688.pdf](https://arxiv.org/pdf/1605.02688.pdf)'
  id: totrans-331
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Al-Rfou, R.,等人 (2016)。*Theano：快速计算数学表达的Python框架*。arXiv。[https://arxiv.org/pdf/1605.02688.pdf](https://arxiv.org/pdf/1605.02688.pdf)
- en: 'Collobert R., Kavukcuoglu K., & Farabet C. (2011). *Torch7: A Matlab-like Environment
    for Machine Learning*. [http://ronan.collobert.com/pub/matos/2011_torch7_nipsw.pdf](http://ronan.collobert.com/pub/matos/2011_torch7_nipsw.pdf)'
  id: totrans-332
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Collobert R., Kavukcuoglu K., & Farabet C. (2011)。*Torch7：一个类似Matlab的机器学习环境*。[http://ronan.collobert.com/pub/matos/2011_torch7_nipsw.pdf](http://ronan.collobert.com/pub/matos/2011_torch7_nipsw.pdf)
- en: 'Abadi M., et al. (2015). *TensorFlow: Large-Scale Machine Learning on Heterogeneous
    Distributed Systems*. [download.tensorflow.org/paper/whitepaper2015.pdf](http://download.tensorflow.org/paper/whitepaper2015.pdf)'
  id: totrans-333
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Abadi M.,等人 (2015)。*TensorFlow：异构分布式系统上的大规模机器学习*。[download.tensorflow.org/paper/whitepaper2015.pdf](http://download.tensorflow.org/paper/whitepaper2015.pdf)
- en: 'Abadi, Martín, et al. (2016) *TensorFlow: Large-Scale Machine Learning on Heterogeneous
    Distributed Systems*. arXiv:1603.04467\. [https://arxiv.org/abs/1603.04467](https://arxiv.org/abs/1603.04467
    )'
  id: totrans-334
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Abadi, Martín，等人 (2016)。*TensorFlow：异构分布式系统上的大规模机器学习*。arXiv:1603.04467。[https://arxiv.org/abs/1603.04467](https://arxiv.org/abs/1603.04467
    )
- en: Jouppi, N P, et al. (2017). *In-Datacenter Performance Analysis of a Tensor
    Processing Unit*. arXiv:1704.04760\. [https://arxiv.org/abs/1704.04760](https://arxiv.org/abs/1704.04760)
  id: totrans-335
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Jouppi, N P，等人 (2017)。*数据中心张量处理单元的性能分析*。arXiv:1704.04760。[https://arxiv.org/abs/1704.04760](https://arxiv.org/abs/1704.04760)
- en: 'van Merriënboer, B., Bahdanau, D., Dumoulin, V., Serdyuk, D., Warde-Farley,
    D., Chorowski, J., Bengio, Y. (2015). *Blocks and Fuel: Frameworks for deep learning*.
    arXiv:1506.00619\. [https://arxiv.org/pdf/1506.00619.pdf](https://arxiv.org/pdf/1506.00619.pdf)'
  id: totrans-336
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: van Merriënboer, B., Bahdanau, D., Dumoulin, V., Serdyuk, D., Warde-Farley,
    D., Chorowski, J., Bengio, Y. (2015)。*Blocks和Fuel：深度学习框架*。arXiv:1506.00619。[https://arxiv.org/pdf/1506.00619.pdf](https://arxiv.org/pdf/1506.00619.pdf)
- en: '[https://stackoverflow.com/questions/57273888/keras-vs-TensorFlow-code-comparison-sources](https://stackoverflow.com/questions/57273888/keras-vs-TensorFlow-code-comparison-sources)'
  id: totrans-337
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://stackoverflow.com/questions/57273888/keras-vs-TensorFlow-code-comparison-sources](https://stackoverflow.com/questions/57273888/keras-vs-TensorFlow-code-comparison-sources)'
- en: Harris M. (2016). *Docker vs. Virtual Machine*. Nvidia developer blog. [https://developer.nvidia.com/blog/nvidia-docker-gpu-server-application-deployment-made-easy/vm_vs_docker/](https://developer.nvidia.com/blog/nvidia-docker-gpu-server-application-deployment-made-easy/vm_vs_do)
  id: totrans-338
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Harris M. (2016). *Docker vs. 虚拟机*. Nvidia developer blog. [https://developer.nvidia.com/blog/nvidia-docker-gpu-server-application-deployment-made-easy/vm_vs_docker/](https://developer.nvidia.com/blog/nvidia-docker-gpu-server-application-deployment-made-easy/vm_vs_do)
- en: 'A visual play on words — the project''s original code name was *Seven of Nine*,
    a Borg character from the series Star Trek: Voyager'
  id: totrans-339
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个视觉双关语 - 该项目的原始代码名称为 *Seven of Nine*，来自电视剧星际迷航：航海家号中的博格角色。
- en: Kubernetes Components. (2021, March 18) Kubernetes. [https://kubernetes.io/docs/concepts/overview/components/](https://kubernetes.io/docs/concepts/overview/components/)
  id: totrans-340
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Kubernetes 组件。 (2021年3月18日) Kubernetes. [https://kubernetes.io/docs/concepts/overview/components/](https://kubernetes.io/docs/concepts/overview/components/)
- en: 'Pavlou C. (2019). *An end-to-end ML pipeline on-prem: Notebooks & Kubeflow
    Pipelines on the new MiniKF*. Medium | Kubeflow. [https://medium.com/kubeflow/an-end-to-end-ml-pipeline-on-prem-notebooks-kubeflow-pipelines-on-the-new-minikf-33b7d8e9a836](https://medium.com/kubeflow/an-end-to-end-ml-pipeline-on-prem-notebooks-kubeflow-pipelines-on-the-ne)'
  id: totrans-341
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Pavlou C. (2019). *在本地端到端的 ML 管道：Notebooks 和 Kubeflow Pipelines 在新 MiniKF 上*.
    Medium | Kubeflow. [https://medium.com/kubeflow/an-end-to-end-ml-pipeline-on-prem-notebooks-kubeflow-pipelines-on-the-new-minikf-33b7d8e9a836](https://medium.com/kubeflow/an-end-to-end-ml-pipeline-on-prem-notebooks-kubeflow-pipelines-on-the-ne)
- en: Vargo S. (2017). *Managing Google Calendar with Terraform*. HashiCorp. [https://www.hashicorp.com/blog/managing-google-calendar-with-terraform](https://www.hashicorp.com/blog/managing-google-calendar-with-terraform)
  id: totrans-342
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Vargo S. (2017). *使用 Terraform 管理 Google 日历*. HashiCorp. [https://www.hashicorp.com/blog/managing-google-calendar-with-terraform](https://www.hashicorp.com/blog/managing-google-calendar-with-terraform)
