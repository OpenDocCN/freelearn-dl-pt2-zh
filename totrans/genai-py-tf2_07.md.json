["```py\ndef downsample_block(incoming_layer,\n                     num_filters,\n                     kernel_size=4,\n                     batch_normalization=True):\n    downsample_layer = Conv2D(num_filters,\n                              kernel_size=kernel_size,\n                              strides=2, padding='same')(incoming_layer)\n    downsample_layer = LeakyReLU(alpha=0.2)(downsample_layer)\n    if batch_normalization:\n        downsample_layer = BatchNormalization(momentum=0.8)(downsample_layer)\n    return downsample_layer \n```", "```py\nupsample_block function:\n```", "```py\ndef upsample_block(incoming_layer,\n                   skip_input_layer,\n                   num_filters,\n                   kernel_size=4,\n                   dropout_rate=0):\n    upsample_layer = UpSampling2D(size=2)(incoming_layer)\n    upsample_layer = Conv2D(num_filters,\n                            kernel_size=kernel_size,\n                            strides=1,\n                            padding='same',\n                            activation='relu')(upsample_layer)\n    if dropout_rate:\n        upsample_layer = Dropout(dropout_rate)(upsample_layer)\n    upsample_layer = BatchNormalization(momentum=0.8)(upsample_layer)\n    upsample_layer = Concatenate()([upsample_layer, skip_input_layer])\n    return upsample_layer \ndownsample_block(). We stack seven such blocks with an increasing number of filters.\n```", "```py\ndef build_generator(img_shape,channels=3,num_filters=64):\n    # Image input\n    input_layer = Input(shape=img_shape)\n    # Downsampling\n    down_sample_1 = downsample_block(input_layer, \n                                     num_filters, \n                                     batch_normalization=False)\n    # rest of the downsampling blocks have batch_normalization=true\n    down_sample_2 = downsample_block(down_sample_1, num_filters*2)\n    down_sample_3 = downsample_block(down_sample_2, num_filters*4)\n    down_sample_4 = downsample_block(down_sample_3, num_filters*8)\n    down_sample_5 = downsample_block(down_sample_4, num_filters*8)\n    down_sample_6 = downsample_block(down_sample_5, num_filters*8)\n    down_sample_7 = downsample_block(down_sample_6, num_filters*8)\n    # Upsampling blocks with skip connections\n    upsample_1 = upsample_block(down_sample_7, down_sample_6, \n                                               num_filters*8)\n    upsample_2 = upsample_block(upsample_1, down_sample_5, \n                                            num_filters*8)\n    upsample_3 = upsample_block(upsample_2, down_sample_4, \n                                            num_filters*8)\n    upsample_4 = upsample_block(upsample_3, down_sample_3, \n                                            num_filters*8)\n    upsample_5 = upsample_block(upsample_4, down_sample_2, \n                                            num_filters*2)\n    upsample_6 = upsample_block(upsample_5, down_sample_1, num_filters)\n    upsample_7 = UpSampling2D(size=2)(upsample_6)\n    output_img = Conv2D(channels, \n                        kernel_size=4, \n                        strides=1, \n                        padding='same', \n                        activation='tanh')(upsample_7)\n    return Model(input_layer, output_img) \n```", "```py\nN x *N* input:\n```", "```py\ndef get_receptive_field(output_size, ksize, stride):\n    return (output_size - 1) * stride + ksize\nlast_layer = get_receptive_field(output_size=1, ksize=4, stride=1)\n# Receptive field: 4\nfourth_layer = get_receptive_field(output_size=last_layer, ksize=4, stride=1)\n# Receptive field: 7\nthird_layer = get_receptive_field(output_size=fourth_layer, ksize=4, stride=2)\n# Receptive field: 16\nsecond_layer = get_receptive_field(output_size=third_layer, ksize=4, stride=2)\n# Receptive field: 34\nfirst_layer = get_receptive_field(output_size=second_layer, ksize=4, stride=2)\n# Receptive field: 70\nprint(first_layer) \n```", "```py\ndef discriminator_block(incoming_layer,\n                        num_filters,\n                        kernel_size = 4,\n                        batch_normalization=True):\n\n    disc_layer = Conv2D(num_filters,\n                        kernel_size = kernel_size,\n                        strides=2,\n                        padding='same')(incoming_layer)\n    disc_layer = LeakyReLU(alpha = 0.2)(disc_layer)\n    if batch_normalization:\n        disc_layer = BatchNormalization(momentum = 0.8)(disc_layer)\n    return disc_layer \n```", "```py\ndef build_discriminator(img_shape,num_filters=64):\n    input_img = Input(shape=img_shape)\n    cond_img = Input(shape=img_shape)\n    # Concatenate input and conditioning image by channels \n    # as input for discriminator\n    combined_input = Concatenate(axis=-1)([input_img, cond_img])\n    # First discriminator block does not use batch_normalization\n    disc_block_1 = discriminator_block(combined_input, \n                                       num_filters, \n                                       batch_normalization=False)\n    disc_block_2 = discriminator_block(disc_block_1, num_filters*2)\n    disc_block_3 = discriminator_block(disc_block_2, num_filters*4)\n    disc_block_4 = discriminator_block(disc_block_3, num_filters*8)\n    output = Conv2D(1, kernel_size=4, strides=1, padding='same')(disc_block_4)\n    return Model([input_img, cond_img], output) \n```", "```py\ndef train(generator, \n          discriminator, \n          gan, \n          patch_gan_shape, \n          epochs,\n          path='/content/maps',\n          batch_size = 1, \n          sample_interval = 50):\n\n    # Ground truth shape/Patch-GAN outputs\n    real_y = np.ones((batch_size,) + patch_gan_shape)\n    fake_y = np.zeros((batch_size,) + patch_gan_shape)\n    for epoch in range(epochs):\n      print(\"Epoch={}\".format(epoch))\n      for idx, (imgs_source, imgs_cond) in enumerate(batch_generator(path=path, batch_size=batch_size,\n                     img_res=[IMG_HEIGHT, IMG_WIDTH])):\n            # train discriminator\n            # generator generates outputs based on \n            # conditioned input images\n            fake_imgs = generator.predict([imgs_cond])\n            # calculate discriminator loss on real samples\n            disc_loss_real = discriminator.train_on_batch([imgs_source,\n                                                           imgs_cond], \n                                                           real_y)\n            # calculate discriminator loss on fake samples\n            disc_loss_fake = discriminator.train_on_batch([fake_imgs, \n                                                           imgs_cond], \n                                                           fake_y)\n            # overall discriminator loss\n            discriminator_loss = 0.5 * np.add(disc_loss_real, \n                                              disc_loss_fake)\n            # train generator\n            gen_loss = gan.train_on_batch([imgs_source, imgs_cond],\n                                          [real_y, imgs_source])\n            # training updates every 50 iterations\n            if idx % 50 == 0:\n              print (\"[Epoch {}/{}] [Discriminator loss: {}, accuracy: {}] [Generator loss: {}]\".format(epoch, epochs,                                         discriminator_loss[0],                                         100*discriminator_loss[1],\n                                        gen_loss[0]))\n            # Plot and Save progress every few iterations\n            if idx % sample_interval == 0:\n              plot_sample_images(generator=generator,\n                                 path=path,\n                                 epoch=epoch,\n                                 batch_num=idx,\n                                 output_dir='images') \n```", "```py\nIMG_WIDTH = 256\nIMG_HEIGHT = 256\n# build discriminator\ndiscriminator = build_discriminator(img_shape=(IMG_HEIGHT,IMG_WIDTH,3),\n                                    num_filters=64)\ndiscriminator.compile(loss='mse',\n                      optimizer=Adam(0.0002, 0.5),\n                      metrics=['accuracy'])\n# build generator and GAN objects\ngenerator = build_generator(img_shape=(IMG_HEIGHT,IMG_WIDTH,3),\n                            channels=3,\n                            num_filters=64)\nsource_img = Input(shape=(IMG_HEIGHT,IMG_WIDTH,3))\ncond_img = Input(shape=(IMG_HEIGHT,IMG_WIDTH,3))\nfake_img = generator(cond_img)\ndiscriminator.trainable = False\noutput = discriminator([fake_img, cond_img])\ngan = Model(inputs=[source_img, cond_img], outputs=[output, fake_img])\ngan.compile(loss=['mse', 'mae'],\n            loss_weights=[1, 100],\n            optimizer=Adam(0.0002, 0.5)) \n```", "```py\ndownsample_block() prepares a stack composed of a convolutional layer followed by leaky ReLU activation and an instance normalization layer. The function takes the number of filters and kernel size as inputs:\n```", "```py\ndef downsample_block(incoming_layer,\n                     num_filters,\n                     kernel_size=4):\n    downsample_layer = Conv2D(num_filters,\n                              kernel_size=kernel_size,\n                              strides=2, padding='same')(incoming_layer)\n    downsample_layer = LeakyReLU(alpha=0.2)(downsample_layer)\n    downsample_layer = InstanceNormalization()(downsample_layer)\n    return downsample_layer \nupsample_block() function. This function prepares a stack consisting of an upsampling layer followed by a convolutional layer, optional dropout, and instance normalization layer. Each upsampling block takes input from the previous layer as well as a skip connection as input:\n```", "```py\ndef upsample_block(incoming_layer,\n                   skip_input_layer,\n                   num_filters,\n                   kernel_size=4,\n                   dropout_rate=0):\n\n    upsample_layer = UpSampling2D(size=2)(incoming_layer)\n    upsample_layer = Conv2D(num_filters,\n                            kernel_size=kernel_size,\n                            strides=1,\n                            padding='same',\n                            activation='relu')(upsample_layer)\n    if dropout_rate:\n        upsample_layer = Dropout(dropout_rate)(upsample_layer)\n    upsample_layer = InstanceNormalization()(upsample_layer)\n    upsample_layer = Concatenate()([upsample_layer, skip_input_layer])\n    return upsample_layer \n```", "```py\ndef build_generator(img_shape, channels=3, num_filters=32):\n    # Image input\n    input_layer = Input(shape=img_shape)\n    # Downsampling\n    down_sample_1 = downsample_block(input_layer, num_filters)\n    down_sample_2 = downsample_block(down_sample_1, num_filters*2)\n    down_sample_3 = downsample_block(down_sample_2,num_filters*4)\n    down_sample_4 = downsample_block(down_sample_3,num_filters*8)\n    # Upsampling\n    upsample_1 = upsample_block(down_sample_4, down_sample_3, \n                                               num_filters*4)\n    upsample_2 = upsample_block(upsample_1, down_sample_2, \n                                            num_filters*2)\n    upsample_3 = upsample_block(upsample_2, down_sample_1, num_filters)\n    upsample_4 = UpSampling2D(size=2)(upsample_3)\n    output_img = Conv2D(channels, \n                        kernel_size=4, \n                        strides=1, \n                        padding='same', \n                        activation='tanh')(upsample_4)\n    return Model(input_layer, output_img) \n```", "```py\ndef discriminator_block(incoming_layer,\n                        num_filters,\n                        kernel_size=4,\n                        instance_normalization=True):\n\n    disc_layer = Conv2D(num_filters,\n                        kernel_size=kernel_size,\n                        strides=2,\n                        padding='same')(incoming_layer)\n    disc_layer = LeakyReLU(alpha=0.2)(disc_layer)\n    if instance_normalization:\n        disc_layer = InstanceNormalization()(disc_layer)\n    return disc_layer\ndef build_discriminator(img_shape,num_filters=64):\n    input_layer = Input(shape=img_shape)\n    disc_block_1 = discriminator_block(input_layer, \n                                       num_filters, \n                                       instance_normalization=False)\n    disc_block_2 = discriminator_block(disc_block_1, num_filters*2)\n    disc_block_3 = discriminator_block(disc_block_2, num_filters*4)\n    disc_block_4 = discriminator_block(disc_block_3, num_filters*8)\n    output = Conv2D(1, kernel_size=4, strides=1, padding='same')(disc_block_4)\n    return Model(input_layer, output) \n```", "```py\ngenerator_filters = 32\ndiscriminator_filters = 64\n# input shape\nchannels = 3\ninput_shape = (IMG_HEIGHT, IMG_WIDTH, channels)\n# Loss weights\nlambda_cycle = 10.0            \nlambda_identity = 0.1 * lambda_cycle\noptimizer = Adam(0.0002, 0.5)\npatch = int(IMG_HEIGHT / 2**4)\npatch_gan_shape = (patch, patch, 1)\n# Discriminators\ndisc_A = build_discriminator(input_shape,discriminator_filters)\ndisc_A.compile(loss='mse',\n    optimizer=optimizer,\n    metrics=['accuracy'])\ndisc_B = build_discriminator(input_shape,discriminator_filters)\ndisc_B.compile(loss='mse',\n    optimizer=optimizer,\n    metrics=['accuracy'])\n# Generators\ngen_AB = build_generator(input_shape,channels, generator_filters)\ngen_BA = build_generator(input_shape, channels, generator_filters)\n# CycleGAN\nimg_A = Input(shape=input_shape)\nimg_B = Input(shape=input_shape)\n# generate fake samples from both generators\nfake_B = gen_AB(img_A)\nfake_A = gen_BA(img_B)\n# reconstruct original samples from both generators\nreconstruct_A = gen_BA(fake_B)\nreconstruct_B = gen_AB(fake_A)\n# generate identity samples\nidentity_A = gen_BA(img_A)\nidentity_B = gen_AB(img_B)\n# disable discriminator training\ndisc_A.trainable = False\ndisc_B.trainable = False\n# use discriminator to classify real vs fake\noutput_A = disc_A(fake_A)\noutput_B = disc_B(fake_B)\n# Combined model trains generators to fool discriminators\ngan = Model(inputs=[img_A, img_B],\n            outputs=[output_A, output_B,\n                     reconstruct_A, reconstruct_B,\n                     identity_A, identity_B ])\ngan.compile(loss=['mse', 'mse','mae', 'mae','mae', 'mae'],\n            loss_weights=[1, 1,\n                          lambda_cycle, lambda_cycle,\n                          lambda_identity, lambda_identity ],\n            optimizer=optimizer) \n```", "```py\ndef train(gen_AB, \n          gen_BA, \n          disc_A, \n          disc_B, \n          gan, \n          patch_gan_shape, \n          epochs, \n          path='/content/{}'.format(dataset_name),\n          batch_size=1, \n          sample_interval=50):\n    # Adversarial loss ground truths\n    real_y = np.ones((batch_size,) + patch_gan_shape)\n    fake_y = np.zeros((batch_size,) + patch_gan_shape)\n    for epoch in range(epochs):\n        print(\"Epoch={}\".format(epoch))\n        for idx, (imgs_A, imgs_B) in enumerate(batch_generator(path,\n                                                         batch_size,\n                                image_res=[IMG_HEIGHT, IMG_WIDTH])):\n            # train discriminators\n            # generate fake samples from both generators\n            fake_B = gen_AB.predict(imgs_A)\n            fake_A = gen_BA.predict(imgs_B)\n            # Train the discriminators \n            # (original images = real / translated = Fake)\n            disc_A_loss_real = disc_A.train_on_batch(imgs_A, real_y)\n            disc_A_loss_fake = disc_A.train_on_batch(fake_A, fake_y)\n            disc_A_loss = 0.5 * np.add(disc_A_loss_real, \n                                       disc_A_loss_fake)\n            disc_B_loss_real = disc_B.train_on_batch(imgs_B, real_y)\n            disc_B_loss_fake = disc_B.train_on_batch(fake_B, fake_y)\n            disc_B_loss = 0.5 * np.add(disc_B_loss_real, \n                                       disc_B_loss_fake)\n            # Total disciminator loss\n            discriminator_loss = 0.5 * np.add(disc_A_loss, disc_B_loss)\n            # train generator\n            gen_loss = gan.train_on_batch([imgs_A, imgs_B],\n                                          [\n                                           real_y, real_y,\n                                           imgs_A, imgs_B,\n                                           imgs_A, imgs_B\n                                           ]\n                                          )\n            # training updates every 50 iterations\n            if idx % 50 == 0:\n              print (\"[Epoch {}/{}] [Discriminator loss: {}, accuracy: {}][Generator loss: {}, Adversarial Loss: {}, Reconstruction Loss: {}, Identity Loss: {}]\".format(idx, \n                           epoch,\n                           discriminator_loss[0], \n                           100*discriminator_loss[1],\n                           gen_loss[0],\n                           np.mean(gen_loss[1:3]),\n                           np.mean(gen_loss[3:5]),\n                           np.mean(gen_loss[5:6])))\n\n            # Plot and Save progress every few iterations\n            if idx % sample_interval == 0:\n              plot_sample_images(gen_AB,\n                                 gen_BA,\n                                 path=path,\n                                 epoch=epoch,\n                                 batch_num=idx,\n                                 output_dir='images') \n```"]