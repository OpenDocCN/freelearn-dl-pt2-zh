["```py\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nimport tensorflow as tf\n\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Dense\ntf.logging.set_verbosity(tf.logging.ERROR)\n\n#plotting\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n#dataset\nfrom tensorflow.keras.datasets import mnist\n```", "```py\n(x_train, _), (x_test, _) = mnist.load_data()\n```", "```py\nx_train = x_train.astype('float32') / 255\nx_test = x_test.astype('float32') / 255\n```", "```py\nprint(x_train.shape, x_test.shape)\n\n((60000, 28, 28), (10000, 28, 28))\n```", "```py\nx_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\nx_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n```", "```py\nprint(x_train.shape, x_test.shape)\n\n((60000, 784), (10000, 784))\n```", "```py\nencoding_dim = 32\n```", "```py\ninput_image = Input(shape=(784,))\n```", "```py\nencoder  = Dense(encoding_dim, activation='relu')(input_image)\n```", "```py\ndecoder = Dense(784, activation='sigmoid')(encoder)\n```", "```py\nmodel = Model(inputs=input_image, outputs=decoder)\n```", "```py\nmodel.summary()\n\n________________________________________________________________\nLayer (type)                Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         (None, 784)               0         \n_________________________________________________________________\ndense (Dense)                (None, 32)                25120     \n_________________________________________________________________\ndense_1 (Dense)              (None, 784)               25872     \n=================================================================\nTotal params: 50,992\nTrainable params: 50,992\nNon-trainable params: 0\n_________________________________________________________________\n```", "```py\nmodel.compile(optimizer='adadelta', loss='binary_crossentropy')\n```", "```py\nmodel.fit(x_train, x_train, epochs=50, batch_size=256, shuffle=True, validation_data=(x_test, x_test))\n```", "```py\nreconstructed_images = model.predict(x_test)\n```", "```py\nn = 7\nplt.figure(figsize=(20, 4))\nfor i in range(n):\n\n    ax = plt.subplot(1, n, i+1)\n    plt.imshow(x_test[i].reshape(28, 28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\nplt.show() \n```", "```py\nn = 7\nplt.figure(figsize=(20, 4))\nfor i in range(n):\n    ax = plt.subplot(2, n, i + n + 1)\n    plt.imshow(reconstructed_images[i].reshape(28, 28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n\nplt.show() \n```", "```py\nimport warnings\nwarnings.filterwarnings('ignore')\n\n#modelling\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\nfrom tensorflow.keras import backend as K\n\n#plotting\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n#dataset\nfrom keras.datasets import mnist\nimport numpy as np\n```", "```py\n(x_train, _), (x_test, _) = mnist.load_data()\n\n# Normalize the dataset\n\nx_train = x_train.astype('float32') / 255.\nx_test = x_test.astype('float32') / 255.\n\n# reshape\n\nx_train = np.reshape(x_train, (len(x_train), 28, 28, 1)) \nx_test = np.reshape(x_test, (len(x_test), 28, 28, 1)) \n```", "```py\ninput_image = Input(shape=(28, 28, 1))  \n```", "```py\nx = Conv2D(16, (3, 3), activation='relu', padding='same')(input_image)\nx = MaxPooling2D((2, 2), padding='same')(x)\n```", "```py\nx = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\nx = MaxPooling2D((2, 2), padding='same')(x)\n```", "```py\nx = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\nencoder = MaxPooling2D((2, 2), padding='same')(x)\n```", "```py\nx = Conv2D(8, (3, 3), activation='relu', padding='same')(encoder)\nx = UpSampling2D((2, 2))(x)\n```", "```py\nx = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\nx = UpSampling2D((2, 2))(x)\n```", "```py\nx = Conv2D(16, (3, 3), activation='relu')(x)\nx = UpSampling2D((2, 2))(x)\ndecoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n```", "```py\nmodel = Model(input_image, decoder)\n```", "```py\nmodel.compile(optimizer='adadelta', loss='binary_crossentropy')\n```", "```py\nmodel.fit(x_train, x_train, epochs=50,batch_size=128, shuffle=True, validation_data=(x_test, x_test))\n```", "```py\nreconstructed_images = model.predict(x_test)\n```", "```py\nn = 7\nplt.figure(figsize=(20, 4))\nfor i in range(n):\n\n    ax = plt.subplot(1, n, i+1)\n    plt.imshow(x_test[i].reshape(28, 28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\nplt.show() \n```", "```py\nn = 7\nplt.figure(figsize=(20, 4))\nfor i in range(n):\n    ax = plt.subplot(2, n, i + n + 1)\n    plt.imshow(reconstructed_images[i].reshape(28, 28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n\nplt.show() \n```", "```py\nnoise_factor = 1\n```", "```py\nx_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape) \nx_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape)\n```", "```py\nx_train_noisy = np.clip(x_train_noisy, 0., 1.)\nx_test_noisy = np.clip(x_test_noisy, 0., 1.)\n```", "```py\nmodel.fit(x_train_noisy, x_train, epochs=50,batch_size=128, shuffle=True, validation_data=(x_test_noisy, x_test))\n```", "```py\nreconstructed_images = model.predict(x_test_noisy)\n```", "```py\nn = 7\nplt.figure(figsize=(20, 4))\nfor i in range(n):\n\n    ax = plt.subplot(1, n, i+1)\n    plt.imshow(x_test_noisy[i].reshape(28, 28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\nplt.show() \n```", "```py\nn = 7\nplt.figure(figsize=(20, 4))\nfor i in range(n):\n    ax = plt.subplot(2, n, i + n + 1)\n    plt.imshow(reconstructed_images[i].reshape(28, 28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n\nplt.show()\n```", "```py\ndef sparse_regularizer(activation_matrix):\n```", "```py\nrho = 0.05\n```", "```py\nrho_hat = K.mean(activation_matrix) \n```", "```py\nKL_divergence = K.sum(rho*(K.log(rho/rho_hat)) + (1-rho)*(K.log(1-rho/1-rho_hat)))\n```", "```py\n    sum = K.sum(KL_divergence) \n```", "```py\n    return beta * sum\n```", "```py\ndef sparse_regularizer(activation_matrix):\n    p = 0.01\n    beta = 3\n    p_hat = K.mean(activation_matrix)  \n    KL_divergence = p*(K.log(p/p_hat)) + (1-p)*(K.log(1-p/1-p_hat))\n    sum = K.sum(KL_divergence) \n\n    return beta * sum\n```", "```py\nMSE = K.mean(K.square(actual - predicted), axis=1)\n```", "```py\nweights = K.variable(value=model.get_layer('encoder_layer').get_weights()[0]) \nweights = K.transpose(weights) \n```", "```py\nh = model.get_layer('encoder_layer').output\n```", "```py\npenalty_term =  K.sum(((h * (1 - h))**2) * K.sum(weights**2, axis=1), axis=1)\n```", "```py\nLoss = MSE + (lambda * penalty_term)\n```", "```py\ndef contractive_loss(y_pred, y_true):\n\n    lamda = 1e-4\n\n    MSE = K.mean(K.square(y_true - y_pred), axis=1)\n\n    weights = K.variable(value=model.get_layer('encoder_layer').get_weights()[0]) \n    weights = K.transpose(weights) \n\n    h = model.get_layer('encoder_layer').output\n\n    penalty_term = K.sum(((h * (1 - h))**2) * K.sum(weights**2, axis=1), axis=1)\n\n    Loss = MSE + (lambda * penalty_term)\n\n    return Loss\n```", "```py\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\nfrom tensorflow.keras.layers import Input, Dense, Lambda\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras import metrics\nfrom tensorflow.keras.datasets import mnist\n\nimport tensorflow as tf\ntf.logging.set_verbosity(tf.logging.ERROR)\n```", "```py\n(x_train, _), (x_test, _) = mnist.load_data()\n```", "```py\nx_train = x_train.astype('float32') / 255.\nx_test = x_test.astype('float32') / 255.\n```", "```py\nx_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\nx_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n```", "```py\nbatch_size = 100\noriginal_dim = 784\nlatent_dim = 2\nintermediate_dim = 256\nepochs = 50\nepsilon_std = 1.0\n```", "```py\nx = Input(shape=(original_dim,))\n```", "```py\nh = Dense(intermediate_dim, activation='relu')(x)\n```", "```py\nz_mean = Dense(latent_dim)(h)\nz_log_var = Dense(latent_dim)(h)\n```", "```py\ndef sampling(args):\n    z_mean, z_log_var = args\n    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), mean=0., stddev=epsilon_std)\n    return z_mean + K.exp(z_log_var / 2) * epsilon\n```", "```py\nz = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n```", "```py\ndecoder_hidden = Dense(intermediate_dim, activation='relu')\ndecoder_reconstruct = Dense(original_dim, activation='sigmoid')\n```", "```py\ndecoded = decoder_hidden(z)\nreconstructed = decoder_reconstruct(decoded)\n```", "```py\nvae = Model(x, reconstructed)\n```", "```py\nReconstruction_loss = original_dim * metrics.binary_crossentropy(x, reconstructed)\n```", "```py\nkl_divergence_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n```", "```py\ntotal_loss = K.mean(Reconstruction_loss + kl_divergence_loss)\n```", "```py\nvae.add_loss(total_loss)\nvae.compile(optimizer='rmsprop')\nvae.summary()\n```", "```py\nvae.fit(x_train,\n        shuffle=True,\n        epochs=epochs,\n        batch_size=batch_size,\n        verbose=2,\n        validation_data=(x_test, None))\n```", "```py\ndecoder_input = Input(shape=(latent_dim,))\n_decoded = decoder_hidden(decoder_input)\n\n_reconstructed = decoder_reconstruct(_decoded)\ngenerator = Model(decoder_input, _reconstructed)\n```", "```py\nn = 7 \ndigit_size = 28\nfigure = np.zeros((digit_size * n, digit_size * n))\n\ngrid_x = norm.ppf(np.linspace(0.05, 0.95, n))\ngrid_y = norm.ppf(np.linspace(0.05, 0.95, n))\n\nfor i, yi in enumerate(grid_x):\n    for j, xi in enumerate(grid_y):\n        z_sample = np.array([[xi, yi]])\n        x_decoded = generator.predict(z_sample)\n        digit = x_decoded[0].reshape(digit_size, digit_size)\n        figure[i * digit_size: (i + 1) * digit_size,\n               j * digit_size: (j + 1) * digit_size] = digit\n\nplt.figure(figsize=(4, 4), dpi=100)\nplt.imshow(figure, cmap='Greys_r')\nplt.show()\n```"]