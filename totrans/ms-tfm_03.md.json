["```py\n    bash Terminal./FilePath/For/Anaconda.sh\n    ```", "```py\nconda create -n Transformer\n```", "```py\nconda activate Transformer\n```", "```py\nconda install -c conda-forge tensorflow\nconda install -c conda-forge pytorch\nconda install -c conda-forge Transformer\n```", "```py\n!pip install Transformer\n```", "```py\n>>> from Transformer import BERTTokenizer\n>>> tokenizer = \\\nBERTTokenizer.from_pretrained('BERT-base-uncased')\n```", "```py\n>>> text = \"Using Transformer is easy!\"\n>>> tokenizer(text)\n```", "```py\n{'input_ids': [101, 2478, 19081, 2003, 3733, 999, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}\n```", "```py\n>>> encoded_input = tokenizer(text, return_tensors=\"pt\")\n```", "```py\n>>> from Transformer import BERTModel\n>>> model = BERTModel.from_pretrained(\"BERT-base-uncased\")\n```", "```py\n>>> output = model(**encoded_input)\n```", "```py\nfrom Transformer import BERTTokenizer, TFBERTModel\ntokenizer = \\\nBERTTokenizer.from_pretrained('BERT-base-uncased')\nmodel = TFBERTModel.from_pretrained(\"BERT-base-uncased\")\ntext = \" Using Transformer is easy!\"\nencoded_input = tokenizer(text, return_tensors='tf')\noutput = model(**encoded_input)\n```", "```py\n>>> from Transformer import pipeline\n>>> unmasker = \\\npipeline('fill-mask', model='BERT-base-uncased')\n>>> unmasker(\"The man worked as a [MASK].\")\n```", "```py\n[{'score': 0.09747539460659027,  'sequence': 'the man worked as a carpenter.',  'token': 10533,  'token_str': 'carpenter'}, {'score': 0.052383217960596085,  'sequence': 'the man worked as a waiter.',  'token': 15610,  'token_str': 'waiter'}, {'score': 0.049627091735601425,  'sequence': 'the man worked as a barber.',  'token': 13362,  'token_str': 'barber'}, {'score': 0.03788605332374573,  'sequence': 'the man worked as a mechanic.',  'token': 15893,  'token_str': 'mechanic'}, {'score': 0.03768084570765495,  'sequence': 'the man worked as a salesman.',  'token': 18968,  'token_str': 'salesman'}]\n```", "```py\n>>> pd.DataFrame(unmasker(\"The man worked as a [MASK].\"))\n```", "```py\n>>> from Transformer import pipeline\n>>> classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n>>> sequence_to_classify = \"I am going to france.\"\n>>> candidate_labels = ['travel', 'cooking', 'dancing']\n>>> classifier(sequence_to_classify, candidate_labels)\n```", "```py\n{'labels': ['travel', 'dancing', 'cooking'], 'scores': [0.9866883158683777, 0.007197578903287649, 0.006114077754318714], 'sequence': 'I am going to france.'}\n```", "```py\npip install datasets\n```", "```py\nfrom datasets import load_dataset\ncola = load_dataset('glue', 'cola')\ncola['train'][25:28]\n```", "```py\nfrom pprint import pprint\nfrom datasets import list_datasets, list_metrics\nall_d = list_datasets()\nmetrics = list_metrics()\nprint(f\"{len(all_d)} datasets and {len(metrics)} metrics exist in the hub\\n\")\npprint(all_d[:20], compact=True)\npprint(metrics, compact=True)\n```", "```py\n661 datasets and 21 metrics exist in the hub.\n['acronym_identification', 'ade_corpus_v2', 'adversarial_qa', 'aeslc', 'afrikaans_ner_corpus', 'ag_news', 'ai2_arc', 'air_dialogue', 'ajgt_twitter_ar', 'allegro_reviews', 'allocine', 'alt', 'amazon_polarity', 'amazon_reviews_multi', 'amazon_us_reviews', 'ambig_qa', 'amttl', 'anli', 'app_reviews', 'aqua_rat']\n['accuracy', 'BERTscore', 'bleu', 'bleurt', 'comet', 'coval', 'f1', 'gleu', 'glue', 'indic_glue', 'meteor', 'precision', 'recall', 'rouge', 'sacrebleu', 'sari', 'seqeval', 'squad', 'squad_v2', 'wer', 'xnli']\n```", "```py\n>>> cola = load_dataset('glue', 'cola')\n>>> cola\nDatasetDict({\ntrain: Dataset({\nfeatures: ['sentence', 'label', 'idx'],\n        num_rows: 8551 })    \nvalidation: Dataset({\nfeatures: ['sentence', 'label', 'idx'],\n        num_rows: 1043 })\ntest: Dataset({\n      features: ['sentence', 'label', 'idx'], \n       num_rows: 1063  })\n}) \ncola['train'][12]\n{'idx': 12, 'label':1,'sentence':'Bill rolled out of the room.'}\n>>> cola['validation'][68]\n{'idx': 68, 'label': 0, 'sentence': 'Which report that John was incompetent did he submit?'}\n>>> cola['test'][20]\n{'idx': 20, 'label': -1, 'sentence': 'Has John seen Mary?'}\n```", "```py\n>>> print(\"1#\",cola[\"train\"].description)\n>>> print(\"2#\",cola[\"train\"].citation)\n>>> print(\"3#\",cola[\"train\"].homepage)\n1# GLUE, the General Language Understanding Evaluation benchmark(https://gluebenchmark.com/) is a collection of resources for training,evaluating, and analyzing natural language understanding systems.2# @article{warstadt2018neural,  title={Neural Network Acceptability Judgments},  author={Warstadt, Alex and Singh, Amanpreet and Bowman, Samuel R},  journal={arXiv preprint arXiv:1805.12471},  year={2018}}@inproceedings{wang2019glue,  title={{GLUE}: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding},  author={Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R.},  note={In the Proceedings of ICLR.},  year={2019}}3# https://nyu-mll.github.io/CoLA/\n```", "```py\n>>> mrpc = load_dataset('glue', 'mrpc')\n```", "```py\n>>> load_dataset('glue', 'XYZ')\n```", "```py\n>>> glue=['cola', 'sst2', 'mrpc', 'qqp', 'stsb', 'mnli',\n       'mnli_mismatched', 'mnli_matched', 'qnli', 'rte',\n       'wnli', 'ax']\n>>> for g in glue: \n        _=load_dataset('glue', g)\n```", "```py\n>>> en_de = load_dataset('xtreme', 'MLQA.en.de')\n>>> en_de \\\nDatasetDict({\ntest: Dataset({features: ['id', 'title', 'context', 'question', 'answers'], num_rows: 4517\n}) validation: Dataset({ features: ['id', 'title', 'context', 'question', 'answers'], num_rows: 512})})\n```", "```py\n>>> import pandas as pd\n>>> pd.DataFrame(en_de['test'][0:4])\n```", "```py\n>>> cola_train = load_dataset('glue', 'cola', split ='train')\n```", "```py\n>>> cola_sel = load_dataset('glue', 'cola', split = 'train[:300]+validation[-30:]')\n```", "```py\n    split='train[:100]+validation[:100]'\n    ```", "```py\n    split='train[:50%]+validation[-30%:]'\n    ```", "```py\n    split='train[:20%]+validation[30:50]'\n    ```", "```py\n>>> cola_sel.sort('label')['label'][:15]\n[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n>>> cola_sel.sort('label')['label'][-15:]\n[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n```", "```py\n>>> cola_sel[6,19,44]\n{'idx': [6, 19, 44], \n'label': [1, 1, 1],\n 'sentence':['Fred watered the plants flat.',\n  'The professor talked us into a stupor.',  \n  'The trolley rumbled through the tunnel.']}\n```", "```py\n>>> cola_sel.shuffle(seed=42)[2:5]\n{'idx': [159, 1022, 46], \n'label': [1, 0, 1], \n'sentence': ['Mary gets depressed if she listens to the Grateful Dead.',\n'It was believed to be illegal by them to do that.',  \n'The bullets whistled past the house.']}\n```", "```py\n>>> cola_sel.cache_files\n[{'filename': '/home/savas/.cache/huggingface...,'skip': 0,  'take': 300}, {'filename': '/home/savas/.cache/huggingface...','skip': 1013,  'take': 30}]\n```", "```py\n>>> cola_sel = load_dataset('glue', 'cola', split='train[:100%]+validation[-30%:]')\n>>> cola_sel.filter(lambda s: \"kick\" in s['sentence'])[\"sentence\"][:3]\n['Jill kicked the ball from home plate to third base.', 'Fred kicked the ball under the porch.', 'Fred kicked the ball behind the tree.']\n```", "```py\n>>> cola_sel.filter(lambda s: s['label']== 1 )[\"sentence\"][:3]\n[\"Our friends won't buy this analysis, let alone the next one we propose.\", \n\"One more pseudo generalization and I'm giving up.\", \n\"One more pseudo generalization or I'm giving up.\"]\n```", "```py\n>>> cola_sel.filter(lambda s: s['label']== cola_sel.features['label'].str2int('acceptable'))[\"sentence\"][:3]\n```", "```py\n>>> cola_new=cola_sel.map(lambda e:{'len': len(e['sentence'])})\n>>> pd.DataFrame(cola_new[0:3])\n```", "```py\n>>> cola_cut=cola_new.map(lambda e: {'sentence': e['sentence'][:20]+ '_'})\n```", "```py\nfrom datasets import load_dataset\ndata1 = load_dataset('csv', data_files='../data/a.csv', delimiter=\"\\t\")\ndata2 = load_dataset('csv', data_files=['../data/a.csv','../data/b.csv', '../data/c.csv'], delimiter=\"\\t\")\ndata3 = load_dataset('csv', data_files={'train':['../data/a.csv','../data/b.csv'], 'test':['../data/c.csv']}, delimiter=\"\\t\")\n```", "```py\n>>> data_json = load_dataset('json', data_files='a.json')\n>>> data_text = load_dataset('text', data_files='a.txt')\n```", "```py\nfrom Transformer import DistilBERTTokenizer\ntokenizer = \\ DistilBERTTokenizer.from_pretrained('distilBERT-base-uncased')\nencoded_data3 = data3.map(lambda e: tokenizer( e['sentence'], padding=True, truncation=True, max_length=12), batched=True, batch_size=1000)\n```", "```py\n>>> data3\nDatasetDict({    \ntrain: Dataset({\n   features: ['sentence','label'], num_rows: 199 })    \ntest: Dataset({\n   features: ['sentence','label'], num_rows: 100 })})\n>>> encoded_data3\nDatasetDict({    \ntrain: Dataset({\n  features: ['attention_mask', 'input_ids', 'label',   'sentence'],\n   num_rows: 199 })\ntest: Dataset({\nfeatures: ['attention_mask', 'input_ids', 'label', 'sentence'],\n num_rows: 100 })})\n>>> pprint(encoded_data3['test'][12])\n{'attention_mask': [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0], 'input_ids': [101, 2019, 5186, 16010, 2143, 1012, 102, 0, 0, 0, 0, 0], 'label': 0, 'sentence': 'an extremely unpleasant film . '}\n```", "```py\n>>> import torch\n>>> print(f\"The GPU total memory is {torch.cuda.get_device_properties(0).total_memory /(1024**3)} GB\")\nThe GPU total memory is 2.94921875 GB\n```", "```py\nfrom Transformer import PyTorchBenchmark, PyTorchBenchmarkArguments\nmodels= [\"BERT-base-uncased\",\"distilBERT-base-uncased\",\"distilroBERTa-base\", \"distilBERT-base-german-cased\"]\nbatch_sizes=[4]\nsequence_lengths=[32,64, 128, 256,512]\nargs = PyTorchBenchmarkArguments(models=models, batch_sizes=batch_sizes, sequence_lengths=sequence_lengths, multi_process=False)\nbenchmark = PyTorchBenchmark(args)\n```", "```py\n>>> results = benchmark.run() \n```", "```py\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(8,8))\nt=sequence_lengths\nmodels_perf=[list(results.time_inference_result[m]['result'][batch_sizes[0]].values()) for m in models]\nplt.xlabel('Seq Length')\nplt.ylabel('Time in Second')\nplt.title('Inference Speed Result')\nplt.plot(t, models_perf[0], 'rs--', t, models_perf[1], 'g--.', t, models_perf[2], 'b--^', t, models_perf[3], 'c--o')\nplt.legend(models) \nplt.show()\n```"]