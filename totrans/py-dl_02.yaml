- en: Chapter 2. Neural Networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we described several machine learning algorithms and
    we introduced different techniques to analyze data to make predictions. For example,
    we suggested how machines can use data of home selling prices to make predictions
    on the price for new houses. We described how large companies, such as Netflix,
    use machine learning techniques in order to suggest to users new movies they may
    like based on movies they have liked in the past, using a technique that is widely
    utilized in e-commerce by giants such as Amazon or Walmart. Most of these techniques,
    however, necessitate labeled data in order to make predictions on new data, and,
    in order to improve their performance, need humans to describe the data in terms
    of features that make sense.
  prefs: []
  type: TYPE_NORMAL
- en: 'Humans are able to quickly extrapolate patterns and infer rules without having
    the data cleaned and prepared for them. It would then be desirable if machines
    could learn to do the same. As we have discussed, Frank Rosenblatt invented the
    perceptron back in 1957, over 50 years ago. The perceptron is to modern deep neural
    nets what unicellular organisms are to complex multi-cellular lifeforms, and yet
    it is quite important to understand and become familiar with how an artificial
    neuron works to better understand and appreciate the complexity we can generate
    by grouping many neurons together on many different layers to create deep neural
    networks. Neural nets are an attempt to mimic the functioning of a human brain
    and its ability to abstract new rules through simple observations. Though we are
    still quite far from understanding how human brains organize and process information,
    we already have a good understanding of how single human neurons work. Artificial
    neural networks attempt to mimic the same functionality, trading chemical and
    electrical messaging for numerical values and functions. Much progress has been
    made in the last decade, after neural networks had become popular and then been
    forgotten at least twice before: such resurgence is due in part to having computers
    that are getting faster, the use of **GPUs** (**Graphical Processing Units**)
    versus the most traditional use of **CPUs** (**Computing Processing Units**),
    better algorithms and neural nets design, and increasingly large datasets, as
    we will see in this book.'
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will formally introduce what neural networks are, we will
    thoroughly describe how a neuron works, and we will see how we can stack many
    layers to create and use deep feed-forward neural networks.
  prefs: []
  type: TYPE_NORMAL
- en: Why neural networks?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Neural networks have been around for many years, and they have gone through
    several periods during which they have fallen in and out of favor. However, in
    recent years, they have steadily gained ground over many other competing machine
    learning algorithms. The reason for this is that advanced neural net architecture
    has shown accuracy in many tasks that has far surpassed that of other algorithms.
    For example, in the field of image recognition, accuracy may be measured against
    a database of 16 million images named ImageNet.
  prefs: []
  type: TYPE_NORMAL
- en: Prior to the introduction of deep neural nets, accuracy had been improving at
    a slow rate, but after the introduction of deep neural networks, accuracy dropped
    from an error rate of 40% in 2010 to less than 7% in 2014, and this value is still
    falling. The human recognition rate is still lower, but only at about 5%. Given
    the success of deep neural networks, all entrants to the ImageNet competition
    in 2013 used some form of deep neural network. In addition, deep neural nets "learn"
    a representation of the data, that is, not only learn to recognize an object,
    but also learn what the important features that uniquely define the identified
    object are. By learning to automatically identify features, deep neural nets can
    be successfully used in unsupervised learning, by naturally classifying objects
    with similar features together, without the need for laborious human labeling.
    Similar advances have also been reached in other fields, such as signal processing.
    Deep learning and using deep neural networks is now ubiquitously used, for example,
    in Apple's Siri. When Google introduced a deep learning algorithm for its Android
    operating system, it achieved a 25% reduction in word recognition error. Another
    dataset used for image recognition is the MNIST dataset that comprises examples
    of digits written in different handwriting. The use of deep neural networks for
    digit recognition can now achieve an accuracy of 99.79%, comparable to a human's
    accuracy. In addition, deep neural network algorithms are the closest artificial
    example of how the human brain works. Despite the fact that they are still probably
    a much more simplified and elementary version of our brain, they contain more
    than any other algorithm, the seed of human intelligence, and the rest of this
    book will be dedicated to studying different neural networks and several examples
    of different applications of neural networks will be provided.
  prefs: []
  type: TYPE_NORMAL
- en: Fundamentals
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the first chapter, we talked about three different approaches to machine
    learning: supervised learning, unsupervised learning, and reinforcement learning.
    Classical neural networks are a type of supervised machine learning, though we
    will see later that deep learning popularity is instead due to the fact that modern
    deep neural networks can be used in unsupervised learning tasks as well. In the
    next chapter, we will highlight the main differences between classical shallow
    neural networks and deep neural nets. For now, however, we will mainly concentrate
    on classical feed-forward networks that work in a supervised way. Our first question
    is, what exactly is a neural network? Probably the best way to interpret a neural
    network is to describe it as a mathematical model for information processing.
    While this may seem rather vague, it will become much clearer in the next chapters.
    A neural net is not a fixed program, but rather a model, a system that processes
    information, or inputs, in a somewhat bland analogy to how information is thought
    to be processed by biological entities. We can identify three main characteristics
    for a neural net:'
  prefs: []
  type: TYPE_NORMAL
- en: '**The neural net architecture**: This describes the set of connections (feed-forward,
    recurrent, multi- or single-layered, and so on) between the neurons, the number
    of layers, and the number of neurons in each layer.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The learning**: This describes what is commonly defined as the training.
    Whether we use back-propagation or some kind of energy level training, it identifies
    how we determine the weights between neurons.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The activity function**: This describes the function we use on the activation
    value that is passed onto each neuron, the neuron''s internal state, and it describes
    how the neuron works (stochastically, linearly, and so on) and under what conditions
    it will activate or fire, and the output it will pass on to neighboring neurons.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It should be noted, however, that some researchers would consider the activity
    function as part of the architecture; it may be easier, however, for a beginner
    to separate these two aspects for now. It needs to be remarked that artificial
    neural nets represent only an approximation of how a biological brain works. A
    biological neural net is a much more complex model; however, this should not be
    a concern. Artificial neural nets can still perform many useful tasks, in fact,
    as we will show later, an artificial neural net can indeed approximate to any
    degree we wish any function of the input onto the output.
  prefs: []
  type: TYPE_NORMAL
- en: 'The development of neural nets is based on the following assumptions:'
  prefs: []
  type: TYPE_NORMAL
- en: Information processing occurs, in its simplest form, over simple elements, called
    neurons
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Neurons are connected and exchange signals between them along connection links
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Connection links between neurons can be stronger or weaker, and this determines
    how information is processed
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each neuron has an internal state that is determined by all the incoming connections
    from other neurons
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each neuron has a different activity function that is calculated on the neuron
    internal state and determines its output signal
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the next section, we shall define in detail how a neuron works and how it
    interacts with other neurons.
  prefs: []
  type: TYPE_NORMAL
- en: Neurons and layers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: What is a neuron? A neuron is a processing unit that takes an input value and,
    according to predefined rules, outputs a different value.
  prefs: []
  type: TYPE_NORMAL
- en: '![Neurons and layers](img/00027.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: In 1943, Warren McCullock and Walter Pitts published an article (W. S. McCulloch
    and W. Pitts. A Logical Calculus of the Ideas Immanent in Nervous Activity, The
    Bulletin of Mathematical Biophysics, 5(4):115–133, 1943) in which they described
    the functioning of a single biological neuron. The components of a biological
    neuron are the dendrites, the soma (the cell body), the axons, and the synaptic
    gaps. Under different names, these are also parts of an artificial neuron.
  prefs: []
  type: TYPE_NORMAL
- en: 'The dendrites bring the input from other neurons to the soma, the neuron''s
    body. The soma is where the inputs are processed and summed together. If the input
    is over a certain threshold, the neuron will "fire" and transmit a single output
    that is electrically sent through the axons. Between the axons of the transmitting
    neurons and the dendrites of the receiving neurons lies the synaptic gap that
    mediates chemically such impulses, altering their frequencies. In an artificial
    neural net, we model the frequency through a numerical weight: the higher the
    frequency, the higher the impulse and, therefore, the higher the weight. We can
    then establish an equivalence table between biological and artificial neurons
    (this is a very simplified description, but it works for our purposes):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Neurons and layers](img/00028.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Schematic correspondence between a biological and an artificial neuron
  prefs: []
  type: TYPE_NORMAL
- en: 'We can therefore describe an artificial neuron schematically as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Neurons and layers](img/00029.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: At the center of this picture we have the neuron, or the soma, which gets an
    input (the activation) and sets the neuron's internal state that triggers an output
    (the activity function). The input comes from other neurons and it is mediated
    in intensity by the weights (the synaptic gap).
  prefs: []
  type: TYPE_NORMAL
- en: The simple activation value for a neuron is given by ![Neurons and layers](img/00030.jpeg),
    where *x*[i] is the value of each input neuron, and *w*[i] is the value of the
    connection between the neuron *i* and the output. In the first chapter, in our
    introduction to neural networks, we introduced the bias. If we include the bias
    and want to make its presence explicit, we can rewrite the preceding equation
    as ![Neurons and layers](img/00031.jpeg). The bias effect is to translate the
    hyperplane defined by the weights so it will not necessarily go through the origin
    (and hence its name). We should interpret the activation value as the neuron's
    internal state value.
  prefs: []
  type: TYPE_NORMAL
- en: As we mentioned in the previous chapter, the activation value defined previously
    can be interpreted as the dot product between the vector *w* and the vector *x*.
    A vector *x* will be perpendicular to the weight vector *w* if *<w,x> = 0*, therefore
    all vectors *x* such that *<w,x> = 0* define a hyper-plane in **R**^n (where n
    is the dimension of *x*).
  prefs: []
  type: TYPE_NORMAL
- en: Hence, any vector *x* satisfying *<w,x> > 0* is a vector on the side of the
    hyper-plane defined by *w*. A neuron is therefore a linear classifier, which,
    according to this rule, activates when the input is above a certain threshold
    or, geometrically, when the input is on one side of the hyper-plane defined by
    the vector of the weights.
  prefs: []
  type: TYPE_NORMAL
- en: '![Neurons and layers](img/00032.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: A single neuron is a linear classifier
  prefs: []
  type: TYPE_NORMAL
- en: A neural network can have an indefinite number of neurons, but regardless of
    their number, in classical networks all the neurons will be ordered in layers.
    The input layer represents the dataset, the initial conditions. For example, if
    the input is a grey-scale image, the input layer is represented for each pixel
    by an input neuron with the inner value the intensity of the pixel. It should
    be noted, however, that the neurons in the input layer are not neurons as the
    others, as their output is constant and is equal to the value of their internal
    state, and therefore the input layer is not generally counted. A 1-layer neural
    net is therefore a simple neural net with just one layer, the output, besides
    the input layer. From each input neuron we draw a line connecting it with each
    output neuron and this value is mediated by the artificial synaptic gap, that
    is the weight *w*[i,j] connecting the input neuron *x*i to the output neuron *y*[j].
    Typically, each output neuron represents a class, for example, in the case of
    the MNIST dataset, each neuron represents a digit. The 1-layer neural net can
    therefore be used to make a prediction such as which digit the input image is
    representing. In fact, the set of output values can be regarded as a measure of
    the probability that the image represents the given class, and therefore the output
    neuron with the highest value will represent the prediction of the neural net.
  prefs: []
  type: TYPE_NORMAL
- en: 'It must be noted that neurons in the same layer are never connected to one
    another, as in the following figure; instead they are all connected to each of
    the neurons in the next layer, and so on:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Neurons and layers](img/00033.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'An example of a 1-layer neural network: the neurons on the left represent the
    input with bias b, the middle column represents the weights for each connection,
    while the neurons on the right represent the output given the weights *w*.'
  prefs: []
  type: TYPE_NORMAL
- en: This is one of the necessary and defining conditions for classical neural networks,
    the absence of intra-layers connections, while neurons connect to each and every
    neuron in adjacent layers. In the preceding figure, we explicitly show the weights
    for each connection between neurons, but usually the edges connecting neurons
    implicitly represent the weights. The **1** represents the bias unit, the value
    1 neuron with connecting weight equal to the bias that we have introduced earlier.
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned many times, 1-layer neural nets can only classify linearly separable
    classes; however, there is nothing that can prevent us from introducing more layers
    between the input and the output. These extra layers are called hidden layers.
  prefs: []
  type: TYPE_NORMAL
- en: '![Neurons and layers](img/00034.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Shown is a 3-layer neural network with two hidden layers. The input layer has
    k input neurons, the first hidden layer has n hidden neurons, and the second hidden
    layer has m hidden neurons. In principle it is possible to have as many hidden
    layers as desired. The output, in this example, is the two classes, *y*[1] and
    *y*[2]. On top the on always-on bias neuron. Each connection has its own weight
    w (not depicted for simplicity).
  prefs: []
  type: TYPE_NORMAL
- en: Different types of activation function
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Biologically, neuroscience has identified hundreds, perhaps more than a thousand
    different types of neurons (refer *The Future of the Brain*", by Gary Marcus and
    Jeremy Freeman) and therefore we should be able to model at least some different
    types of artificial neurons. This can be done by using different types of activity
    functions, that is, the function defined on the internal state of the neuron represented
    by the activation ![Different types of activation function](img/00030.jpeg) calculated
    on the input from all the input neurons.
  prefs: []
  type: TYPE_NORMAL
- en: 'The activity function is a function defined on *a(x)* and it defines the output
    of the neuron. The most common activity functions used are:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Different types of activation function](img/00035.jpeg): This function lets
    the activation value go through and it is called the identity function'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Different types of activation function](img/00036.jpeg) : This function activates
    the neuron if the activation is above a certain value and it is called the threshold
    activity function'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Different types of activation function](img/00037.jpeg): This function is
    one of the most commonly used as its output, which is bounded between 0 and 1,
    and it can be interpreted stochastically as the probability for the neuron to
    activate, and it is commonly called the logistic function or the logistic sigmoid.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Different types of activation function](img/00038.jpeg): This activity function
    is called the bipolar sigmoid, and it is simply a logistic sigmoid rescaled and
    translated to have a range in (-1, 1).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Different types of activation function](img/00039.jpeg): This activity function
    is called the hyperbolic tangent.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Different types of activation function](img/00040.jpeg): This activity function
    is probably the closest to its biological counterpart, it is a mix of the identity
    and the threshold function, and it is called the rectifier, or **ReLU**, as in
    **Rectfied Linear Unit**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'What are the main differences between these activation functions? Often, different
    activation functions work better for different problems. In general, the identity
    activity function or threshold function, while widely used at the inception of
    neural networks with such implementations such as the *perceptron* or the *Adaline*
    (adaptive linear neuron), has recently lost traction in favor of the logistic
    sigmoid, the hyperbolic tangent, or the ReLU. While the identity function and
    the threshold function are much simpler, and therefore were the preferred functions
    when computers did not have quite as much calculation power, it is often preferable
    to use non-linear functions, such as the sigmoid functions or the ReLU. It should
    also be noted that if we only used the linear activity function there is no point
    in adding extra hidden layers, as the composition of linear functions is still
    just a linear function. The last three activity functions differ in the following
    ways:'
  prefs: []
  type: TYPE_NORMAL
- en: Their range is different
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Their gradient may vanish as we increase x
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The fact that the gradient may vanish as we increase *x* and why it is important
    will be clearer later; for now, let's just mention that the gradient (for example,
    the derivative) of the function is important for the training of the neural network.
    This is similar to how, in the linear regression example we introduced in the
    first chapter, we were trying to minimize the function following it along the
    direction opposite to its derivative.
  prefs: []
  type: TYPE_NORMAL
- en: The range for the logistic function is (0,1), which is one reason why this is
    the preferred function for stochastic networks, that is, networks with neurons
    that may activate based on a probability function. The hyperbolic function is
    very similar to the logistic function, but its range is (-1, 1). In contrast,
    the ReLU has a range of (0, ![Different types of activation function](img/00041.jpeg)),
    so it can have a very large output.
  prefs: []
  type: TYPE_NORMAL
- en: However, more importantly, let's look at the derivative for each of the three
    functions. For a logistic function *f*, the derivative is *f * (1-f)*, while if
    *f* is the hyperbolic tangent, its derivative is *(1+f) * (1-f)*.
  prefs: []
  type: TYPE_NORMAL
- en: If *f* is the ReLU, the derivative is much simpler and it is simply ![Different
    types of activation function](img/00042.jpeg).
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let''s briefly see how we can calculate the derivative of the logistic sigmoid
    function. This can be quickly calculated by simply noticing that the derivative
    with respect to *a* of the ![Different types of activation function](img/00043.jpeg)
    function is given by the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Different types of activation function](img/00044.jpeg)![Different types
    of activation function](img/00045.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: When we will talk about back-propagation, we will see that one of the problems
    for deep networks is that of the *vanishing gradient* (as mentioned previously),
    and the advantage of the ReLU activity function is that the derivative is constant
    and does not tend to *0* as *a* becomes large.
  prefs: []
  type: TYPE_NORMAL
- en: Typically all neurons in the same layer have the same activity function, but
    different layers may have different activity functions. But why are neural networks
    more than 1-layer deep (2-layer or more) so important? As we have seen, the importance
    of neural networks lies in their predictive power, that is, in their ability to
    approximate a function defined on the input with the required output. There exists
    a theorem, called the Universal Approximation Theorem, which states that any continuous
    functions on compact subsets of *R*[n] can be approximated by a neural network
    with at least one hidden layer. While the formal proof of such a theorem is too
    complex to be explained here, we will attempt to give an intuitive explanation
    only using some basic mathematics, and for this we will make use of the logistic
    sigmoid as our activity function.
  prefs: []
  type: TYPE_NORMAL
- en: 'The logistic sigmoid is defined as ![Different types of activation function](img/00046.jpeg)
    where ![Different types of activation function](img/00031.jpeg). Let''s now assume
    that we have only one neuron *x=x*[i]:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Different types of activation function](img/00047.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: On the left is a standard sigmoid with weight 1 and bias 0\. In the center is
    a sigmoid with weight 10, while on the right is a sigmoid with weight 10 and bias
    50.
  prefs: []
  type: TYPE_NORMAL
- en: Then it can be easily shown that if *w* is very large, the logistic function
    becomes close to a step function. The larger *w* is, the more it resembles a step
    function at 0 with height 1\. On the other hand, *b* will simply translate the
    function, and the translation will be equal to the negative of the ratio *b/w*.
    Let's call *t = -b/w.*
  prefs: []
  type: TYPE_NORMAL
- en: 'With this in mind, let''s now consider a simple neural net with one input neuron
    and one hidden layer with two neurons and only one output neuron in the output
    layer:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Different types of activation function](img/00048.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: X is mapped on the two hidden neurons with weights and biases such that on the
    top hidden neuron the ratio *–b/w* is *t*[1] while on the bottom hidden neuron
    it is *t*[2]. Both hidden neurons use the logistic sigmoid activation function.
  prefs: []
  type: TYPE_NORMAL
- en: The input x is mapped to two neurons, one with weight and bias such that the
    ratio is *t*[1] and the other such that the ratio is *t**[2]*. Then the two hidden
    neurons can be mapped to the output neuron with weights *w* and *–w*, respectively.
    If we apply the logistic sigmoid activity function to each hidden neuron, and
    the identity function to the output neuron (with no bias), we will get a step
    function, from *t*[1] to *t*[2], and height *w*, like the one depicted in the
    following figure*.* Since the series of step functions like the one in the figure
    can approximate any continuous function on a compact subset of **R**, this gives
    an intuition of why the Universal Approximation Theorem holds (this is, in simplified
    terms, the content of a mathematical theorem called "The simple function approximation
    theorem").
  prefs: []
  type: TYPE_NORMAL
- en: With a little more effort, this can be generalized to **R**[n].
  prefs: []
  type: TYPE_NORMAL
- en: '![Different types of activation function](img/00049.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'The code to produce the preceding figure is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The back-propagation algorithm
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We have seen how neural networks can map inputs onto determined outputs, depending
    on fixed weights. Once the *architecture* of the neural network has been defined
    (feed-forward, number of hidden layers, number of neurons per layer), and once
    the activity function for each neuron has been chosen, we will need to set the
    weights that in turn will define the internal states for each neuron in the network.
    We will see how to do that for a 1-layer network and then how to extend it to
    a deep feed-forward network. For a deep neural network the algorithm to set the
    weights is called the back-propagation algorithm, and we will discuss and explain
    this algorithm for most of this section, as it is one of the most important topics
    for multi-layer feed-forward neural networks. First, however, we will quickly
    discuss this for 1-layer neural networks.
  prefs: []
  type: TYPE_NORMAL
- en: 'The general concept we need to understand is the following: every neural network
    is an approximation of a function, therefore each neural network will not be equal
    to the desired function, and instead it will differ by some value. This value
    is called the error and the aim is to minimize this error. Since the error is
    a function of the weights in the neural network, we want to minimize the error
    with respect to the weights. The error function is a function of many weights;
    it is therefore a function of many variables. Mathematically, the set of points
    where this function is zero represents therefore a hypersurface and to find a
    minimum on this surface we want to pick a point and then follow a curve in the
    direction of the minimum.'
  prefs: []
  type: TYPE_NORMAL
- en: Linear regression
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We have already introduced linear regression in the first chapter, but since
    we are now dealing with many variables, to simplify things we are going to introduce
    matrix notation. Let *x* be the input; we can think of *x* as a vector. In the
    case of linear regression, we are going to consider a single output neuron *y*;
    the set of weights *w* is therefore a vector of dimension the same as the dimension
    of *x*. The activation value is then defined as the inner product *<x, w>*.
  prefs: []
  type: TYPE_NORMAL
- en: Let's say that for each input value *x*, we want to output a target value *t*,
    while for each *x* the neural network will output a value *y*, defined by the
    activity function chosen, in this case the absolute value of the difference (*y-t*)
    represents the difference between the predicted value and the actual value for
    the specific input example *x*. If we have *m* input values *x*[i], each of them
    will have a target value *t*[i]. In this case, we calculate the error using the
    mean squared error ![Linear regression](img/00050.jpeg), where each *y*[i] is
    a function of *w*. The error is therefore a function of *w* and it is usually
    denoted with *J(w)*.
  prefs: []
  type: TYPE_NORMAL
- en: 'As mentioned previously, this represents a hyper-surface of dimension equal
    to the dimension of *w* (we are implicitly also considering the bias), and for
    each *w*[j] we need to find a curve that will lead towards the minimum of the
    surface. The direction in which a curve increases in a certain direction is given
    by its derivative with respect to that direction, in this case by the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Linear regression](img/00051.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: And in order to move towards the minimum we need to move in the opposite direction
    set by ![Linear regression](img/00052.jpeg) for each *w*[j].
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s calculate the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Linear regression](img/00053.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: If ![Linear regression](img/00054.jpeg), then ![Linear regression](img/00055.jpeg)
    and therefore
  prefs: []
  type: TYPE_NORMAL
- en: '![Linear regression](img/00056.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The notation can sometimes be confusing, especially the first time one sees
    it. The input is given by vectors **x**^i, where the superscript indicates the
    i^(th) example. Since **x** and **w** are vectors, the subscript indicates the
    *j*^(th) coordinate of the vector. *y*^i then represents the output of the neural
    network given the input *x*^i, while *t*^i represents the target, that is, the
    desired value corresponding to the input **x**[i].
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to move towards the minimum, we need to move each weight in the direction
    of its derivative by a small amount l, called the *learning rate*, typically much
    smaller than 1, (say 0.1 or smaller). We can therefore redefine in the derivative
    and incorporate the "2 in the learning rate, to get the update rule given by the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Linear regression](img/00057.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Or, more generally, we can write the update rule in matrix form as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Linear regression](img/00058.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Here, ![Linear regression](img/00059.jpeg) (also called nabla) represents the
    vector of partial derivatives. This process is what is often called gradient descent.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![Linear regression](img/00060.jpeg) is a vector of partial derivatives. Instead
    of writing the update rule for *w* separately for each of its components *wj*,
    we can write the update rule in matrix form where, instead of writing the partial
    derivative for each *j*, we use ![Linear regression](img/00061.jpeg) to indicate
    each partial derivative, for each *j*.'
  prefs: []
  type: TYPE_NORMAL
- en: One last note; the update can be done after having calculated all the input
    vectors, however, in some cases, the weights can be updated after each example
    or after a defined preset number of examples.
  prefs: []
  type: TYPE_NORMAL
- en: Logistic regression
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In logistic regression, the output is not continuous; rather it is defined as
    a set of classes. In this case, the activation function is not going to be the
    identity function like before, rather we are going to use the logistic sigmoid
    function. The logistic sigmoid function, as we have seen before, outputs a real
    value in (0,1) and therefore it can be interpreted as a probability function,
    and that is why it can work so well in a 2-class classification problem. In this
    case, the target can be one of two classes, and the output represents the probability
    that it be one of those two classes (say *t=1*).
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Again, the notation can be confusing. *t* is our target, and it can have, in
    this example, two values. These two values are often defined to be class 0 and
    class 1\. These values 0 and 1 are not to be confused with the values of the logistic
    sigmoid function, which is a continuous real-valued function between 0 and 1\.
    The real value of the sigmoid function represents the probability that the output
    be in class 0 or class 1.
  prefs: []
  type: TYPE_NORMAL
- en: 'If *a* is the neuron activation value as defined previously, let''s denote
    with the s(*a*) the logistic sigmoid function, therefore, for each example x,
    the probability that the output be the class *y*, given the weights *w*, is:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Logistic regression](img/00062.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'We can write that equation more succinctly as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Logistic regression](img/00063.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'And since for each sample *x*^i the probabilities *P(t*[i]*|x*[i]*, w)* are
    independent, the global probability is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Logistic regression](img/00064.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'If we take the natural log of the preceding equation (to turn products into
    sums), we get the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Logistic regression](img/00065.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The object is now to maximize this log to obtain the highest probability of
    predicting the correct results. Usually, this is obtained, as in the previous
    case, by using gradient descent to minimize the cost function *J(w)* defined by
    *J(w)= -log(P(y¦* **x** *,w))*.
  prefs: []
  type: TYPE_NORMAL
- en: 'As before, we calculate the derivative of the cost function with respect to
    the weights *w*[j] to obtain:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Logistic regression](img/00066.jpeg)![Logistic regression](img/00067.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To understand the last equality, let''s remind the reader of the following
    facts:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Logistic regression](img/00068.jpeg)![Logistic regression](img/00069.jpeg)![Logistic
    regression](img/00070.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Therefore, by the chain rule:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Logistic regression](img/00071.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Similarly:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Logistic regression](img/00072.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'In general, in case of a multi-class output **t**, with **t** a vector (*t*[1],
    *…, t*[n]), we can generalize this equation using ![Logistic regression](img/00073.jpeg)
    = ![Logistic regression](img/00074.jpeg) that brings to the update equation for
    the weights:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Logistic regression](img/00075.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: This is similar to the update rule we have seen for linear regression.
  prefs: []
  type: TYPE_NORMAL
- en: Back-propagation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the case of 1-layer, weight-adjustment is easy, as we can use linear or logistic
    regression and adjust the weights simultaneously to get a smaller error (minimizing
    the cost function). For multi-layer neural networks we can use a similar argument
    for the weights used to connect the last hidden layer to the output layer, as
    we know what we would like the output layer to be, but we cannot do the same for
    the hidden layers, as, a priori, we do not know what the values for the neurons
    in the hidden layers ought to be. What we do, instead, is calculate the error
    in the last hidden layer and estimate what it would be in the previous layer,
    propagating the error back from the last to the first layer, hence the name back-propagation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Back-propagation is one of the most difficult algorithms to understand at first,
    but all is needed is some knowledge of basic differential calculus and the chain
    rule. Let''s introduce some notation first. We denote with *J* the cost (error)*,*
    with *y* the activity function that is defined on the activation value *a* (for
    example, y could be the logistic sigmoid)*,* which is a function of the weights
    *w* and the input *x*. Let''s also define *w*[i,j], the weight between the *i*^(th)
    input value, and the *j*th output. Here we define input and output more generically
    than for a 1-layer network: if *w*[i,j] connects a pair of successive layers in
    a feed-forward network, we denote as "input" the neurons on the first of the two
    successive layers, and "output" the neurons on the second of the two successive
    layers. In order not to make the notation too heavy, and have to denote on which
    layer each neuron is, we assume that the *i*th input *y*[i] is always in the layer
    preceding the layer containing the *j*^(th) output *y*[j].'
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Note that the letter *y* is used to both denote an input and the output of the
    activity function. *y*[j] is the input to the next layer, and *y*[j] is the output
    of the activity function, but it is then also the input to the next layer. Therefore
    we can think of the *y*[j]*'s* as functions of the *y*[j]*'s*.
  prefs: []
  type: TYPE_NORMAL
- en: We also use subscripts *i* and *j*, where we always have the element with subscript
    *i* belonging to the layer preceding the layer containing the element with subscript
    *j*.
  prefs: []
  type: TYPE_NORMAL
- en: '![Back-propagation](img/00076.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10
  prefs: []
  type: TYPE_NORMAL
- en: In this example, layer 1 represents the input, and *layer 2* the output, so
    *w*[i,j] is a number connecting the *y*[j]value in a layer, and the *y*[j] value
    in the following layer.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using this notation, and the chain-rule for derivatives, for the last layer
    of our neural network we can write the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Back-propagation](img/00077.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Since we know that ![Back-propagation](img/00078.jpeg), we have the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Back-propagation](img/00079.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: If *y* is the logistic sigmoid defined previously, we get the same result we
    have already calculated at the end of the previous section, since we know the
    cost function and we can calculate all derivatives.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the previous layers the same formula holds:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Back-propagation](img/00077.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: In fact, *a* *j* is the activity function, which, as we know, is a function
    of the weights. The *y*[j] value, which is the activity function of the neuron
    in the "second" layer, is a function of its activation value, and, of course,
    the cost function is a function of the activity function we have chosen.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Even though we have several layers, we always concentrate on pairs of successive
    layers and so, perhaps abusing the notation somewhat, we always have a "first"
    layer and a "second" layer, as in *Figure 10*, which is the "input" layer and
    the "output" layer.
  prefs: []
  type: TYPE_NORMAL
- en: Since we know that ![Back-propagation](img/00078.jpeg) and we know that ![Back-propagation](img/00080.jpeg)
    is the derivative of the activity function that we can calculate, all we need
    to calculate is the derivative ![Back-propagation](img/00081.jpeg). Let's notice
    that this is the derivative of the error with respect to the activation function
    in the "second" layer, and, if we can calculate this derivative for the last layer,
    and have a formula that allows us to calculate the derivative for one layer assuming
    we can calculate the derivative for the next, we can calculate all the derivatives
    starting from the last layer and move backwards.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us notice that, as we defined by the *y[j]*, they are the activation values
    for the neurons in the "second" layer, but they are also the activity functions,
    therefore functions of the activation values in the first layer. Therefore, applying
    the chain rule, we have the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Back-propagation](img/00082.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: And once again we can calculate both ![Back-propagation](img/00080.jpeg) and
    ![Back-propagation](img/00083.jpeg), so once we know ![Back-propagation](img/00081.jpeg)
    we can calculate ![Back-propagation](img/00084.jpeg), and since we can calculate
    ![Back-propagation](img/00081.jpeg) for the last layer, we can move backward and
    calculate ![Back-propagation](img/00084.jpeg) for any layer and therefore ![Back-propagation](img/00085.jpeg)
    for any layer.
  prefs: []
  type: TYPE_NORMAL
- en: To summarize, if we have a sequence of layers where
  prefs: []
  type: TYPE_NORMAL
- en: '![Back-propagation](img/00086.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: We then have these two fundamental equations, where the summation in the second
    equation should read as the sum over all the outgoing connections from *y* *j*
    to any neuron ![Back-propagation](img/00087.jpeg) in the successive layer.
  prefs: []
  type: TYPE_NORMAL
- en: '![Back-propagation](img/00077.jpeg)![Back-propagation](img/00088.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: By using these two equations we can calculate the derivatives for the cost with
    respect to each layer.
  prefs: []
  type: TYPE_NORMAL
- en: If we set ![Back-propagation](img/00089.jpeg), ![Back-propagation](img/00090.jpeg)
    represents the variation of the cost with respect to the activation value, and
    we can think of ![Back-propagation](img/00090.jpeg) as the error at the *y*[j]
    neuron. We can then rewrite
  prefs: []
  type: TYPE_NORMAL
- en: '![Back-propagation](img/00091.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'This implies that ![Back-propagation](img/00092.jpeg). These two equations
    give an alternate way of seeing back-propagation, as the variation of the cost
    with respect to the activation value, and provide a formula to calculate this
    variation for any layer once we know the variation for the following layer:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Back-propagation](img/00093.jpeg)![Back-propagation](img/00094.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'We can also combine these equations and show that:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Back-propagation](img/00095.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The back-propagation algorithm for updating the weights is then given on each
    layer by
  prefs: []
  type: TYPE_NORMAL
- en: '![Back-propagation](img/00096.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: In the last section, we will provide a code example that will help understand
    and apply these concepts and formulas.
  prefs: []
  type: TYPE_NORMAL
- en: Applications in industry
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We mentioned in the previous chapter some examples where machine learning finds
    its applications. Neural networks, in particular, have many similar applications.
    We will review some of the applications for which they were used when they became
    popular in the late 1980's and early 1990's, after back-propagation had been discovered
    and deeper neural networks could be trained.
  prefs: []
  type: TYPE_NORMAL
- en: Signal processing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There are many applications of neural networks in the area of signal processing.
    One of the first applications of neural nets was to suppress echo on a telephone
    line, especially on intercontinental calls, as developed starting from 1957 by
    Bernard Widrow and Marcian Hoff. The *Adaline* makes use of the identity function
    as its activity function for training and seeks to minimize the mean squared error
    between the activation and the target value. The Adaline is trained to remove
    the echo from the signal on the telephone line by applying the input signal both
    to the *Adaline* (the filter) and the telephone line. The difference between the
    output from the telephone line and the output from the *Adaline* is the error,
    which is used to train the network and remove the noise (echo) from the signal.
  prefs: []
  type: TYPE_NORMAL
- en: Medical
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The instant physician was developed by Anderson in 1986 and the idea behind
    it was to store a large number of medical records containing information about
    symptoms, diagnosis, and treatment for each case. The network is trained to make
    predictions on best diagnosis and treatment on different symptoms.
  prefs: []
  type: TYPE_NORMAL
- en: More recently, using deep neural networks, IBM worked on a neural network that
    could make predictions on possible heart failures, reading doctor's notes, similarly
    to an experienced cardiologist.
  prefs: []
  type: TYPE_NORMAL
- en: Autonomous car driving
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Nguyen and Widrow in 1989, and Miller, Sutton, and Werbos in 1990, developed
    a neural network that could provide steering directions to a large trailer truck
    backing up to a loading dock. The neural net is made up of two modules: the first
    module is able to calculate new positions using a neural net with several layers,
    by learning how the truck responds to different signals. This neural net is called
    the emulator. A second module, called the controller, learns to give the correct
    commands using the emulator to know its position. In recent years, autonomous
    car driving has made huge strides and it is a reality, though much more complex
    deep learning neural networks are used in conjunction with inputs from cameras,
    GPS, lidar, and sonar units.'
  prefs: []
  type: TYPE_NORMAL
- en: Business
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In 1988, Collins, Ghosh, and Scofield developed a neural net that could be used
    to assess whether mortgage loans should be approved and given. Using data from
    mortgage evaluators, neural networks were trained to determine whether applicants
    should be given a loan. The input was a number of features, such as the number
    of years the applicant had been employed, income level, number of dependents,
    appraised value of the property, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Pattern recognition
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We have discussed this problem many times. One of the areas where neural networks
    have been applied is the recognition of characters. This, for example, can be
    applied to the recognition of digits, and it can be used for recognizing hand-written
    postal codes.
  prefs: []
  type: TYPE_NORMAL
- en: Speech production
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In 1986, Sejnowski and Rosenberg produced the widely known example of NETtalk
    that produced spoken words by reading written text. NETtalk's requirement is a
    set of examples of the written words and their pronunciation. The input includes
    both the letter being pronounced and the letters preceding it and following it
    (usually three) and the training is made using the most widely spoken words and
    their phonetic transcription. In its implementation, the net learns first to recognize
    vowels from consonants, then to recognize word beginnings and endings. It typically
    takes many passes before the words pronounced can become intelligible, and its
    progress sometimes resembles children's learning on how to pronounce words.
  prefs: []
  type: TYPE_NORMAL
- en: Code example of a neural network for the function xor
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It is a well-known fact, and something we have already mentioned, that 1-layer
    neural networks cannot predict the function XOR. 1-layer neural nets can only
    classify linearly separable sets, however, as we have seen, the Universal Approximation
    Theorem states that a 2-layer network can approximate any function, given a complex
    enough architecture. We will now create a neural network with two neurons in the
    hidden layer and we will show how this can model the XOR function. However, we
    will write code that will allow the reader to simply modify it to allow for any
    number of layers and neurons in each layer, so that the reader can try simulating
    different scenarios. We are also going to use the hyperbolic tangent as the activity
    function for this network. To train the network, we will implement the back-propagation
    algorithm discussed earlier.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will only need to import one library, `numpy`, though if the reader wished
    to visualize the results, we also recommend importing `matplotlib`. The first
    lines of code are therefore:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Next we define our activity function and its derivative (we use `tanh(x)` in
    this example):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Next we define the `NeuralNetwork` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'To follow Python syntax, anything inside the `NeuralNetwork` class will have
    to be indented. We define the "constructor" of the `NeuralNetwork` class, that
    is its variables, which in this case will be the neural network architecture,
    that is, how many layers and how many neurons per layer, and we will also initialize
    at random the weights to be between negative 1 and positive 1\. `net_arch` will
    be a 1-dimensional array containing the number of neurons per each layer: for
    example [2,4,1] means an input layer with two neurons, a hidden layer with four
    neurons, and an output layer with one neuron.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Since we are studying the XOR function, for the input layer we need to have
    two neurons, and for the output layer only one neuron:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'In this code, we have defined the activity function to be the hyperbolic tangent
    and we have defined its derivative. We have also defined how many training steps
    there should be per epoch. Finally, we have initialized the weights, making sure
    we also initialize the weights for the biases that we will add later. Next, we
    need to define the `fit` function, the function that will train our network. In
    the last line, `nn` represents the `NeuralNetwork` class and `predict` is the
    function in the `NeuralNetwork` class that we will define later:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'All we have done here is to add a "1" to the input data (the always-on bias
    neuron) and set up code to print the result at the end of each epoch to keep track
    of our progress. We will now go ahead and set up our feed-forward propagation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: We are going to update our weights after each step, so we randomly select one
    of the input data points, then we set up feed-forward propagation by setting up
    the activation for each neuron, then applying the `tanh(x)` on the activation
    value. Since we have a bias, we add the bias to our matrix y that keeps track
    of each neuron output value.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we do our back-propagation of the error to adjust the weights:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'This concludes our back-propagation algorithm; all that is left to do is to
    write a predict function to check the results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'At this point we just need to write the main function as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Notice the use of `numpy.random.seed(0)`.This is simply to ensure that the weight
    initialization is consistent across runs to be able to compare results, but it
    is not necessary for the implementation of a neural net.
  prefs: []
  type: TYPE_NORMAL
- en: 'This ends the code, and the output should be a four-dimensional array, such
    as: (0.003032173692499, 0.9963860761357, 0.9959034563937, 0.0006386449217567)
    showing that the neural network is learning that the output should be (0,1,1,0).'
  prefs: []
  type: TYPE_NORMAL
- en: The reader can slightly modify the code we created in the `plot_decision_regions
    function` used earlier in this book and see how different neural networks separate
    different regions depending on the architecture chosen.
  prefs: []
  type: TYPE_NORMAL
- en: The output picture will look like the following figures. The circles represent
    the (**True**, **True**) and (**False**, **False**) inputs, while the triangles
    represent the (**True**, **False**) and (**False**, **True**) inputs for the XOR
    function.
  prefs: []
  type: TYPE_NORMAL
- en: '![Code example of a neural network for the function xor](img/00097.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The same figure, on the left zoomed out, and on the right zoomed in on the selected
    inputs. The neural network learns to separate those points, creating a band containing
    the two **True** output values.
  prefs: []
  type: TYPE_NORMAL
- en: Different neural network architectures (for example, implementing a network
    with a different number of neurons in the hidden layer, or with more than just
    one hidden layer) may produce a different separating region. In order to do this,
    the reader can simply change the line in the code `nn = NeuralNetwork([2,2,1]).`
    While the first `2` must be kept (the input does not change), the second `2` can
    be modified to denote a different number of neurons in the hidden layer. Adding
    another integer will add a new hidden layer with as many neurons as indicated
    by the added integer. The last `1` cannot be modified. For example, `([2,4,3,1])`
    will represent a 3-layer neural network, with four neurons in the first hidden
    layer and three neurons in the second hidden layer.
  prefs: []
  type: TYPE_NORMAL
- en: 'The reader would then see that, while the solution is always the same, the
    curves separating the regions will be quite different depending on the architecture
    chosen. In fact, choosing `nn = NeuralNetwork([2,4,3,1])` will give the following
    figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Code example of a neural network for the function xor](img/00098.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'While choosing `nn = NeuralNetwork([2,4,1])`, for example, would produce the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Code example of a neural network for the function xor](img/00099.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The architecture of the neural network defines therefore the way the neural
    net goes about to solve the problem at hand, and different architectures provide
    different approaches (though they may all give the same result) similarly to how
    human thought processes can follow different paths to reach the same conclusion.
    We are now ready to start looking more closely at what deep neural nets are and
    their applications.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have introduced neural networks in detail and we have mentioned
    their success over other competing algorithms. Neural networks are comprised of
    the "units", or neurons, that belong to them or their connections, or weights,
    that characterize the strength of the communication between different neurons
    and their activity functions, that is, how the neurons process the information.
    We have discussed how we can create different architectures, and how a neural
    network can have many layers, and why inner (hidden) layers are important. We
    have explained how the information flows from the input to the output by passing
    from each layer to the next based on the weights and the activity function defined,
    and finally we have shown how we can define a method called back-propagation to
    "tune" the weights to improve the desired level of accuracy. We have also mentioned
    many of the areas where neural networks are and have been employed.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will continue discussing deep neural networks, and in
    particular we will explain the meaning of "deep", as in deep learning, by explaining
    that it not only refers to the number of hidden layers in the network, but more
    importantly to the quality of the learning of the neural network. For this purpose,
    we will show how neural networks learn to recognize features and put them together
    as representations of the objects recognized, which will open the way to use neural
    networks for unsupervised learning. We will also describe a few important deep
    learning libraries, and finally, we will provide a concrete example where we can
    apply neural networks for digit recognition.
  prefs: []
  type: TYPE_NORMAL
