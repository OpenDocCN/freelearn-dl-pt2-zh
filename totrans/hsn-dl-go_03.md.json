["```py\ntype nn struct {\n    g *ExprGraph\n    w0, w1 *Node\n\n    pred *Node\n}\n```", "```py\npackage main\n\nimport (\n    \"fmt\"\n    \"io/ioutil\"\n    \"log\"\n\n    . \"gorgonia.org/gorgonia\"\n    \"gorgonia.org/tensor\"\n)\n```", "```py\nvar err error\n```", "```py\ntype nn struct {\n    g *ExprGraph\n    w0, w1 *Node\n\n    pred *Node\n}\n```", "```py\nfunc newNN(g *ExprGraph) *nn {\n    // Create node for w/weight (needs fixed values replaced with random values w/mean 0)\n    wB := []float64{-0.167855599, 0.44064899, -0.99977125}\n    wT := tensor.New(tensor.WithBacking(wB), tensor.WithShape(3, 1))\n    w0 := NewMatrix(g,\n        tensor.Float64,\n        WithName(\"w\"),\n        WithShape(3, 1),\n        WithValue(wT),\n    )\n    return nn{\n        g: g,\n        w0: w0,\n    }\n}\n```", "```py\nfunc (m *nn) learnables() Nodes {\n    return Nodes{m.w0}\n}\n```", "```py\nfunc (m *nn) fwd(x *Node) (err error) {\n    var l0, l1 *Node\n\n    // Set first layer to be copy of input\n    l0 = x\n\n    // Dot product of l0 and w0, use as input for Sigmoid\n    l0dot := Must(Mul(l0, m.w0))\n\n    // Build hidden layer out of result\n    l1 = Must(Sigmoid(l0dot))\n    // fmt.Println(\"l1: \\n\", l1.Value())\n\n    m.pred = l1\n    return\n\n}\n```", "```py\nfunc main() {\n    rand.Seed(31337)\n\n    intercept Ctrl+C\n    sigChan := make(chan os.Signal, 1)\n    signal.Notify(sigChan, syscall.SIGINT, syscall.SIGTERM)\n    doneChan := make(chan bool, 1)\n\n    // Create graph and network\n    g := NewGraph()\n    m := newNN(g)\n```", "```py\n    // Set input x to network\n    xB := []float64{0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1}\n    xT := tensor.New(tensor.WithBacking(xB), tensor.WithShape(4, 3))\n    x := NewMatrix(g,\n        tensor.Float64,\n        WithName(\"X\"),\n        WithShape(4, 3),\n        WithValue(xT),\n    )\n```", "```py\n    // Define validation dataset\n    yB := []float64{0, 0, 1, 1}\n    yT := tensor.New(tensor.WithBacking(yB), tensor.WithShape(4, 1))\n    y := NewMatrix(g,\n        tensor.Float64,\n        WithName(\"y\"),\n        WithShape(4, 1),\n        WithValue(yT),\n    )\n```", "```py\n// Run forward pass\nif err = m.fwd(x); err != nil {\n    log.Fatalf(\"%+v\", err)\n}\n```", "```py\nlosses := Must(Sub(y, m.pred))\ncost := Must(Mean(losses))\n```", "```py\nvar costVal Value\nRead(cost, costVal)\n```", "```py\nioutil.WriteFile(\"pregrad.dot\", []byte(g.ToDot()), 0644)\n```", "```py\ndot -Tpng pregrad.dot  -O\n```", "```py\n  if _, err = Grad(cost, m.learnables()...); err != nil {\n    log.Fatal(err)\n  }\n```", "```py\n// Instantiate VM and Solver\nvm := NewTapeMachine(g, BindDualValues(m.learnables()...))\nsolver := NewVanillaSolver(WithLearnRate(0.001), WithClip(5))\n// solver := NewRMSPropSolver()\n```", "```py\n    for i := 0; i < 10000; i++ {\n        if err = vm.RunAll(); err != nil {\n            log.Fatalf(\"Failed at inter %d: %v\", i, err)\n        }\n        solver.Step(NodesToValueGrads(m.learnables()))\n        fmt.Println(\"\\nState at iter\", i)\n        fmt.Println(\"Cost: \\n\", cost.Value())\n        fmt.Println(\"Weights: \\n\", m.w0.Value())\n        // vm.Set(m.w0, wUpd)\n        // vm.Reset()\n    }\n    fmt.Println(\"Output after Training: \\n\", m.pred.Value())\n}\n```", "```py\nOutput after Training:\nC [[0.00966449][0.00786506][0.99358898][0.99211957]]\n```", "```py\nfunc step(x) {\n    if x >= 0 {\n        return 1\n    } else {\n        return 0\n    }\n}\n```", "```py\nfunc linear(x){\n   return 0.5 * x\n}\n```", "```py\nfunc relu(x){\n   return Max(0,x)\n}\n```", "```py\nfunc leaky_relu(x) {\n    if x >= 0 {\n        return x\n    } else {\n        return 0.01 * x\n    }\n}\n```", "```py\nfunc sigmoid(x){\n    return 1 / (1 + Exp(-x))\n}\n```", "```py\nfunc tanh(x){\n  return 2 * (1 + Exp(-2*x)) - 1\n}\n```", "```py\nsolver := NewVanillaSolver(WithLearnRate(0.001), WithClip(5))\n```", "```py\nnew_W = 1.00 - 0.001 * 101.338\n```", "```py\ntype Solver interface {\n                       Step([]ValueGrad) error\n                      }\n```", "```py\ntype SolverOpt func(s Solver)\n```", "```py\nvm := NewTapeMachine(g, BindDualValues(m.learnables()...))\nsolver := NewMomentum()\n```", "```py\nfunc NewMomentum(opts ...SolverOpt) *Momentum {\n            s := Momentum{\n            eta: 0.001,\n            momentum: 0.9,\n            }\n for _, opt := range opts {\n            opt(s)\n            }\n            return s\n }\n```", "```py\nsolver = NewRMSPropSolver(WithLearnRate(stepSize), WithL2Reg(l2Reg), WithClip(clip))\n```", "```py\nfunc NewRMSPropSolver(opts...SolverOpt) * RMSPropSolver {\n    s: = RMSPropSolver {\n        decay: 0.999,\n        eps: 1e-8,\n        eta: 0.001,\n    }\n\n        for _,\n    opt: = range opts {\n        opt(s)\n    }\n    return s\n}\n```"]