- en: Introduction to Deep Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Deep learning is a subset of machine learning inspired by the neural networks
    in the human brain. It has been around for a decade, but the reason it is so popular
    right now is due to the computational advancements and availability of the huge
    volume of data. With a huge volume of data, deep learning algorithms outperform
    classic machine learning. It has already been transfiguring and extensively used
    in several interdisciplinary scientific fields such as computer vision, **natural
    language processing** (**NLP**), speech recognition, and many others.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will learn about the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Fundamental concepts of deep learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Biological and artificial neurons
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Artificial neural network and its layers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Activation functions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Forward and backward propagation in ANN
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gradient checking algorithm
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building an artificial neural network from scratch
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is deep learning?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Deep learning is just a modern name for artificial neural networks with many
    layers. What is *deep* in deep learning though? It is basically due to the structure
    of the **artificial neural network** (**ANN**). ANN consists of some *n* number
    of layers to perform any computation. We can build an ANN with several layers
    where each layer is responsible for learning the intricate patterns in the data.
    Due to the computational advancements, we can build a network even with 100s or
    1000s of layers deep. Since the ANN uses deep layers to perform learning we call
    it as deep learning and when ANN uses deep layers to learn we call it as a deep
    network. We have learned that deep learning is a subset of machine learning. How
    does deep learning differ from machine learning? What makes deep learning so special
    and popular?
  prefs: []
  type: TYPE_NORMAL
- en: The success of machine learning lies in the right set of features. Feature engineering
    plays a crucial role in machine learning. If we handcraft the right set of features
    to predict a certain outcome, then the machine learning algorithms can perform
    well, but finding and engineering the right set of features is not an easy task.
  prefs: []
  type: TYPE_NORMAL
- en: With deep learning, we don't have to handcraft such features. Since deep ANNs
    employ several layers, it learns the complex intrinsic features and multi-level
    abstract representation of data by itself. Let's explore this a bit with an analogy.
  prefs: []
  type: TYPE_NORMAL
- en: Let's suppose we want to perform an image classification task. Say, we are learning
    to recognize whether an image contains a dog or not. With machine learning, we
    need to handcraft features that help the model to understand whether the image
    contains a dog. We send these handcrafted features as inputs to machine learning
    algorithms which then learn a mapping between the features and the label (dog).
    But extracting features from an image is a tedious task. With deep learning, we
    just need to feed in a bunch of images to the deep neural networks, and it will
    automatically act as a feature extractor by learning the right set of features.
    As we have learned, ANN uses multiple layers; in the first layer, it will learn
    the basic features of the image that characterize the dog, say, the body structure
    of the dog, and, in the succeeding layers, it will learn the complex features.
    Once it learns the right set of features, it will look for the presence of such
    features in the image. If those features are present then it says that the given
    image contains a dog. Thus, unlike machine learning, with DL, we don't have to
    manually engineer the features, instead, the network will itself learns the correct
    set of features required for the task.
  prefs: []
  type: TYPE_NORMAL
- en: Due to this interesting aspect of deep learning, it is substantially used in
    unstructured datasets where extracting features are difficult, such as speech
    recognition, text classification, and many more. When we have a fair amount of
    huge datasets, deep learning algorithms are good at extracting features and mapping
    the extracted features to their labels. Having said that, deep learning is not
    just throwing a bunch of data points to a deep network and getting results. It's
    not that simple either. We would have numerous hyperparameters that act as a tuning
    knob to obtain better results which we will explore in the upcoming sections.
  prefs: []
  type: TYPE_NORMAL
- en: Although deep learning performs better than conventional machine learning models,
    it is not recommended to use DL for smaller datasets. When we don't have enough
    data points or the data is very simple, then the deep learning algorithms can
    easily overfit to the training dataset and fail to generalize well on the unseen
    dataset. Thus, we should apply deep learning only when we have a significant amount
    of data points.
  prefs: []
  type: TYPE_NORMAL
- en: The applications of deep learning are numerous and almost everywhere. Some of
    the interesting applications include automatically generating captions to the
    image, adding sound to the silent movies, converting black-and-white images to
    colored images, generating text, and many more. Google's language translate, Netflix,
    Amazon, and Spotify's recommendations engines, and self-driving cars are some
    of the applications powered by deep learning. There is no doubt that deep learning
    is a disruptive technology and has achieved tremendous technological advancement
    in the past few years.
  prefs: []
  type: TYPE_NORMAL
- en: In this book, we will learn from the basic deep learning algorithms as to the
    state of the algorithms by building some of the interesting applications of deep
    learning from scratch, which includes image recognition, generating song lyrics,
    predicting bitcoin prices, generating realistic artificial images, converting
    photographs to paintings, and many more. Excited already? Let's get started!
  prefs: []
  type: TYPE_NORMAL
- en: Biological and artificial neurons
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before going ahead, first, we will explore what are neurons and how neurons
    in our brain actually work, and then we will learn about artificial neurons.
  prefs: []
  type: TYPE_NORMAL
- en: A **neuron** can be defined as the basic computational unit of the human brain.
    Neurons are the fundamental units of our brain and nervous system. Our brain encompasses
    approximately 100 billion neurons. Each and every neuron is connected to one another
    through a structure called a **synapse**, which is accountable for receiving input
    from the external environment, sensory organs for sending motor instructions to
    our muscles, and for performing other activities.
  prefs: []
  type: TYPE_NORMAL
- en: A neuron can also receive inputs from the other neurons through a branchlike
    structure called a **dendrite**. These inputs are strengthened or weakened; that
    is, they are weighted according to their importance and then they are summed together
    in the cell body called the **soma**. From the cell body, these summed inputs
    are processed and move through the **axons** and are sent to the other neurons.
  prefs: []
  type: TYPE_NORMAL
- en: 'The basic single biological neuron is shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c34c9841-5d50-4d12-ba6b-8a3437187c69.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now, let''s see how artificial neurons work. Let''s suppose we have three inputsÂ [![](img/dbdfdc31-7b1f-4278-8390-b1e98e50047b.png)],
    [![](img/99fdffc8-a9fe-4134-af1d-48fdef7ee8d7.png)], and [![](img/3799a7fd-21c3-4d2d-bbdb-252177cfa98a.png)],
    to predict output [![](img/c4d040ed-3f79-4281-8103-a5408f345d6e.png)]. These inputs
    are multiplied by weights [![](img/50e7081f-b6b0-4249-949c-349b0f28ff13.png)],
    [![](img/92e8cf78-f1fc-48f7-8a84-cd4ea925be6c.png)], and [![](img/12920197-2d25-4066-b8b0-e9bed69b3db6.png)]
    and are summed together as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3d90597b-20ae-4167-9118-36496338db66.png)'
  prefs: []
  type: TYPE_IMG
- en: 'But why are we multiplying these inputs by weights? Because all of the inputs
    are not equally important in calculating the output ![](img/799d4419-1f3d-4337-97a3-a3f0a9f6a394.png).
    Let''s say that ![](img/ff460794-7422-40a7-b2a9-57947337bd5b.png) is more important
    in calculating the output compared to the other two inputs. Then, we assign a
    higher value to [![](img/d174252e-29c4-44ba-96e6-5d7020ed6bd5.png)] than the other
    two weights. So, upon multiplying weights with inputs, [![](img/906e8174-801b-4eef-b5db-5a3142c3333a.png)]
    will have a higher value than the other two inputs. In simple terms, weights are
    used for strengthening the inputs. After multiplying inputs with the weights,
    we sum them together and we add a value called bias, ![](img/96616fe5-e29e-404a-aced-6dfe47191b40.png):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/62b24d74-3072-4188-bcb0-402c2b2c8221.png)'
  prefs: []
  type: TYPE_IMG
- en: 'If you look at the preceding equation closely, it may look familiar? Doesn''t
    [![](img/79f6816d-0766-498b-b832-1b334c9c0323.png)] look like the equation of
    linear regression? Isn''t it just the equation of a straight line? We know that
    the equation of a straight line is given as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/90183881-f6c9-4d97-addd-29b3d0efce9b.png)'
  prefs: []
  type: TYPE_IMG
- en: Here *m* is the weights (coefficients), *x* is the input, and *b* is the bias
    (intercept).
  prefs: []
  type: TYPE_NORMAL
- en: 'Well, yes. Then, what is the difference between neurons and linear regression?
    In neurons, we introduce non-linearity to the result, ![](img/79f6816d-0766-498b-b832-1b334c9c0323.png),
    by applying a function ![](img/2de94421-2982-487b-ba76-37fcbd4d91d6.png) called
    the **activation** or **transfer function**. Thus, our output becomes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bcc6610a-e632-404d-b3e0-69abb61ef764.png)'
  prefs: []
  type: TYPE_IMG
- en: 'A single artificial neuron is shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4cc8f0a1-8bf3-4fad-9844-d322c2056852.jpg)'
  prefs: []
  type: TYPE_IMG
- en: So, a neuron takes the input, *x*, multiples it by weights, *w,* and adds bias,
    *b,* forms ![](img/31ba413e-23d8-4ad1-8c7e-5e2b3f0f5d45.png), and then we apply
    the activation function on ![](img/3aa2453f-17dc-49ca-ab0a-f844a21daf3d.png) and
    get the output, ![](img/c70627ba-a0d8-4c88-b471-4e09c1c94af5.png).
  prefs: []
  type: TYPE_NORMAL
- en: ANN and its layers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While neurons are really cool, we cannot just use a single neuron to perform
    complex tasks. This is the reason our brain has billions of neurons, stacked in
    layers, forming a network. Similarly, artificial neurons are arranged in layers.
    Each and every layer will be connected in such a way that information is passed
    from one layer to another.
  prefs: []
  type: TYPE_NORMAL
- en: 'A typical ANN consists of the following layers:'
  prefs: []
  type: TYPE_NORMAL
- en: Input layer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hidden layer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Output layer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each layer has a collection of neurons, and the neurons in one layer interact
    with all the neurons in the other layers. However, neurons in the same layer will
    not interact with one another. This is simply because neurons from the adjacent
    layers have connections or edges between them; however, neurons in the same layer
    do not have any connections. We use the term **nodes** or **units** to represent
    the neurons in the artificial neural network.
  prefs: []
  type: TYPE_NORMAL
- en: 'A typical ANN is shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ada614a6-bc63-4e6c-8faa-d4289e2bd97f.png)'
  prefs: []
  type: TYPE_IMG
- en: Input layer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The **input layer** is where we feed input to the network. The number of neurons
    in the input layer is the number of inputs we feed to the network. Each input
    will have some influence on predicting the output. However, no computation is
    performed in the input layer; it is just used for passing information from the
    outside world to the network.
  prefs: []
  type: TYPE_NORMAL
- en: Hidden layer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Any layer between the input layer and the output layer is called a **hidden
    layer**. It processes the input received from the input layer. The hidden layer
    is responsible for deriving complex relationships between input and output. That
    is, the hidden layer identifies the pattern in the dataset. It is majorly responsible
    for learning the data representation and for extracting the features.
  prefs: []
  type: TYPE_NORMAL
- en: There can be any number of hidden layers; however, we have to choose a number
    of hidden layers according to our use case. For a very simple problem, we can
    just use one hidden layer, but while performing complex tasks such as image recognition,
    we use many hidden layers, where each layer is responsible for extracting important
    features. The network is called a **deep neural network** when we have many hidden
    layers.
  prefs: []
  type: TYPE_NORMAL
- en: Output layer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: After processing the input, the hidden layer sends its result to the output
    layer. As the name suggests, the output layer emits the output. The number of
    neurons in the output layer is based on the type of problem we want our network
    to solve.
  prefs: []
  type: TYPE_NORMAL
- en: If it is a binary classification, then the number of neurons in the output layer
    is one that tells us which class the input belongs to. If it is a multi-class
    classification say, with five classes, and if we want to get the probability of
    each class as an output, then the number of neurons in the output layer is five,
    each emitting the probability. If it is a regression problem, then we have one
    neuron in the output layer.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring activation functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An **activation function**, also known as a **transfer function**, plays a vital
    role in neural networks. It is used to introduce non-linearity in neural networks.
    As we learned before, we apply the activation function to the input, which is
    multiplied by weights and added to the bias, that is, ![](img/9cf85797-e709-49e7-a4c8-d7a84c9b78a2.png),
    where *z = (input * weights) + bias* and ![](img/d14376f3-d671-4abb-8956-7db1284efec4.png)
    is the activation function. If we do not apply the activation function, then a
    neuron simply resembles the linear regression. The aim of the activation function
    is to introduce a non-linear transformation to learn the complex underlying patterns
    in the data.
  prefs: []
  type: TYPE_NORMAL
- en: Now let's look at some of the interesting commonly used activation functions.
  prefs: []
  type: TYPE_NORMAL
- en: The sigmoid function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The **sigmoid function** is one of the most commonly used activation functions.
    It scales the value between 0 and 1\. The sigmoid function can be defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/85674218-0ed8-4c46-a215-d0ad662c3dac.png)'
  prefs: []
  type: TYPE_IMG
- en: 'It is an S-shaped curve shown as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7f9d30e5-1892-4249-8ae0-c82e1254e33a.png)'
  prefs: []
  type: TYPE_IMG
- en: It is differentiable, meaning that we can find the slope of the curve at any
    two points. It is **monotonic**, which implies it is either entirely non-increasing
    or non-decreasing. The sigmoid function is also known as a **logistic** function.
    As we know that probability lies between 0 and 1 and since the sigmoid function
    squashes the value between 0 and 1, it is used for predicting the probability
    of output.
  prefs: []
  type: TYPE_NORMAL
- en: 'The sigmoid function can be defined in Python as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The tanh function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A **hyperbolic tangent (tanh)** function outputs the value between -1 to +1
    and is expressed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2fd28ae8-16bc-4064-9f34-1f7ac917673f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'It also resembles the S-shaped curve. Unlike a sigmoid function which is centered
    on 0.5, the tanh function is 0 centered, as shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c6f8b6b5-e378-469d-97f4-8598b7859e13.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Similar to the sigmoid function, it is also a differentiable and monotonic
    function. The tanh function is implemented as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The Rectified Linear Unit function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The **Rectified Linear Unit** (**ReLU**) function is another one of the most
    commonly used activation functions. It outputs a value from o to infinity. It
    is basically a **piecewise** function and can be expressed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4b1830c9-1f13-4bed-ba70-be53b28c4a5e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'That is, ![](img/9b9b4d0d-62e5-4f60-9a70-b9b830397fd2.png) returns zero when
    the value of *x* is less than zero and ![](img/d8c4dc45-d54f-4539-89f5-bcd67c4e4e6b.png)
    returns *x* when the value of *x* is greater than or equal to zero. It can also
    be expressed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/54c73360-a603-4ca4-b6de-9848f839e2ba.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The ReLU function is shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9c3ebd42-c9ff-4ba7-9d14-df25c70a9125.png)'
  prefs: []
  type: TYPE_IMG
- en: 'As we can see in the preceding diagram, when we feed any negative input to
    the ReLU function, it converts it to zero. The snag for being zero for all negative
    values is a problem called **dying ReLU**, and a neuron is said to be dead if
    it always outputs zero. A ReLU function can be implemented as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The leaky ReLU function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Leaky ReLU** is a variant of the ReLU function that solves the dying ReLU
    problem. Instead of converting every negative input to zero, it has a small slope
    for a negative value as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b7cbffba-0634-45c9-9227-8ce07581d3d6.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Leaky ReLU can be expressed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7698bd93-47b2-412a-a6f8-09f95f80e988.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The value of ![](img/a29d974a-56fe-4c04-9929-20eba2e714b4.png) is typically
    set to 0.01\. The leaky ReLU function is implemented as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Instead of setting some default values to ![](img/a29d974a-56fe-4c04-9929-20eba2e714b4.png),
    we can send them as a parameter to a neural network and make the network learn
    the optimal value of ![](img/a29d974a-56fe-4c04-9929-20eba2e714b4.png). Such an
    activation function can be termed as a **Parametric ReLU** function. We can also
    set the value of ![](img/21bbeeeb-1cb8-497e-851b-064b57f8e1cc.png) to some random
    value and it is called as **Rando****mized ReLU** function.
  prefs: []
  type: TYPE_NORMAL
- en: The Exponential linear unit function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Exponential linear unit** (**ELU**), like Leaky ReLU, has a small slope for
    negative values. But instead of having a straight line, it has a log curve, as
    shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5b5db978-888c-4ed6-9281-03376d1f6737.png)'
  prefs: []
  type: TYPE_IMG
- en: 'It can be expressed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/511a1bb4-db49-4bc2-a77e-a5567616c7e9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The `ELU` function is implemented in Python as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The Swish function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The **Swish** function is a recently introduced activation function by Google.
    Unlike other activation functions, which are monotonic, Swish is a non-monotonic
    function, which means it is neither always non-increasing nor non-decreasing.
    It provides better performance than ReLU. It is simple and can be expressed as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f188d07c-c687-470f-b22a-b652e77a8d0a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, ![](img/b347a90c-363c-4b47-b023-147ee0110f4e.png) is the sigmoid function.
    The Swish function is shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2352091f-84a6-4451-96f1-7a0a18ddce2f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We can also reparametrize the Swish function and express it as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/661a40be-cffb-4345-9e47-ea0801a30812.png)'
  prefs: []
  type: TYPE_IMG
- en: When the value of ![](img/165eb486-3642-4860-96ae-5d53b69eea23.png)Â is 0, then
    we get the identity function ![](img/22835e77-9093-4d13-94c3-1abd677b0b28.png).
  prefs: []
  type: TYPE_NORMAL
- en: 'It becomes a linear function and, when the value of ![](img/165eb486-3642-4860-96ae-5d53b69eea23.png)Â tends
    to infinity, then ![](img/f199e52d-ee6f-4cdf-a12f-384e23beba5b.png) becomes ![](img/65683175-77c3-4cd5-b79d-e8770b79f073.png),
    which is basically the ReLU function multiplied by some constant value. So, the
    value of ![](img/165eb486-3642-4860-96ae-5d53b69eea23.png) acts as a good interpolation
    between a linear and a nonlinear function. The swish function can be implemented
    as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: The softmax function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The **softmax function** is basically the generalization of the sigmoid function.
    It is usually applied to the final layer of the network and while performing multi-class
    classification tasks. It gives the probabilities of each class for being output
    and thus, the sum of softmax values will always equal 1.
  prefs: []
  type: TYPE_NORMAL
- en: 'It can be represented as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e3f8ae71-6850-4e09-985a-310b056c3c02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'As shown in the following diagram, the softmax function converts their inputs
    to probabilities:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f7adea0b-6ffc-4df5-ae4e-422765495182.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The `softmax` function can be implemented in Python as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Forward propagation in ANN
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we will see how an ANN learns where neurons are stacked up
    in layers. The number of layers in a network is equal to the number of hidden
    layers plus the number of output layers. We don''t take the input layer into account
    when calculating the number of layers in a network. Consider a two-layer neural
    network with one input layer, ![](img/0ca38542-0bbd-4c1d-aab1-041856efa069.png),
    one hidden layer, ![](img/23c5a8d4-df59-46d0-bad7-4fa3019edf96.png), and one output
    layer, ![](img/414c1121-e805-4f7f-a1b4-be8e0bc102a6.png), as shown in the following
    diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9324b53f-3c67-42a9-ac50-02d9561c0e8b.png)'
  prefs: []
  type: TYPE_IMG
- en: Let's consider we have two inputs,Â ![](img/e576bc39-3496-4769-83f1-0da92a9fd56b.png)
    and ![](img/d98cc1ae-745a-4be3-b5c7-7d172de62d5b.png), and we have to predict
    the output, ![](img/00c11656-9e19-47ee-b758-117b6358ae91.png). Since we have two
    inputs, the number of neurons in the input layer will be two. We set the number
    of neurons in the hidden layer to four, and, the number of neurons in the output
    layer to one. Now, the inputs will be multiplied by weights, and then we add bias
    and propagate the resultant value to the hidden layer where the activation function
    will be applied.
  prefs: []
  type: TYPE_NORMAL
- en: Before that, we need to initialize the weight matrix. In the real world, we
    don't know which input is more important than the other so that we can weight
    them and compute the output. Therefore, we will randomly initialize weights and
    the bias value. The weight and the bias value between the input to the hidden
    layer are represented by ![](img/9439f056-b74c-40ae-b855-01f76b5f3de0.png) and
    ![](img/97fdd9d3-3eeb-416c-855c-ba075b92e1f5.png), respectively. What about the
    dimensions of the weight matrix? The dimensions of the weight matrix must be *number
    of neurons in the current layer* x *number of neurons in the next layer*. Why
    is that?
  prefs: []
  type: TYPE_NORMAL
- en: 'Because it is a basic matrix multiplication rule. To multiply any two matrices,
    *AB*, the number of columns in matrix *A* must be equal to the number of rows
    in matrix *B*. So, the dimension of the weight matrix, ![](img/1ae8dad5-6ffd-49e3-9c63-ad8f7a727b82.png),
    should be *number of neurons in the input layer* x *number of neurons in the hidden
    layer*, that is, 2 x 4:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f9845f24-bfaa-4722-b430-631c893abb1c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The preceding equation represents, ![](img/0a21b4e7-70c8-4efb-b08c-e55457170f0b.png).
    Now, this is passed to the hidden layer. In the hidden layer, we apply an activation
    function to ![](img/ccd2fedf-a381-487e-8e37-b3dedd059c0b.png). Let''s use the
    sigmoid ![](img/4d1ee602-8255-4022-b0eb-d52c6dca7c54.png) activation function.
    Then, we can write:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0864106a-31ca-4524-b408-11e3a81c346e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'After applying the activation function, we again multiply result ![](img/5c8475b6-c81e-4e05-abfb-3c0856c26635.png)Â by
    a new weight matrix and add a new bias value that is flowing between the hidden
    layer and the output layer. We can denote this weight matrix and bias as ![](img/e460863e-35ab-41d3-855a-fdaa58c780c8.png)
    and ![](img/910bb4a3-6b59-441d-a624-a2aec21c2190.png), respectively. The dimension
    of the weight matrix, ![](img/c86587a7-4639-4ad9-9777-0ce185b1dbf4.png), will
    be the *number of neurons in the hidden layer* x *the number of neurons in the
    output layer*. Since we have four neurons in the hidden layer and one neuron in
    the output layer, the ![](img/5268e1a5-2ffe-478b-b375-69e7bee62e29.png) matrix
    dimension will be 4 x 1\. So, we multiply ![](img/5c8475b6-c81e-4e05-abfb-3c0856c26635.png)
    by the weight matrix,![](img/9bbf9460-67f9-4cb8-8302-da3866a28c8c.png), and add
    bias, ![](img/8030beb2-9a44-4823-99e8-438002a73a4d.png), and pass the result ![](img/97c26ba4-4188-4326-870c-47d83b9d3535.png)
    to the next layer, which is the output layer:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d6c4af2f-65ac-4d56-a396-74add1443848.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now, in the output layer, we apply a sigmoid function to ![](img/97c26ba4-4188-4326-870c-47d83b9d3535.png),
    which will result an output value:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a2b2f8dc-6cac-4959-bfad-c41c887d1c77.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This whole process from the input layer to the output layer is known as **forward
    propagation**. Thus, in order to predict the output value, inputs are propagated
    from the input layer to the output layer. During this propagation, they are multiplied
    by their respective weights on each layer and an activation function is applied
    on top of them. The complete forward propagation steps are given as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4bd12cf0-2cc6-48ba-8f5a-d38dc68ded6b.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/0864106a-31ca-4524-b408-11e3a81c346e.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/32e542ad-cb13-401d-92b4-40e1dae62ea7.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/a2b2f8dc-6cac-4959-bfad-c41c887d1c77.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The preceding forward propagation steps can be implemented in Python as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Forward propagation is cool, isn''t it? But how do we know whether the output
    generated by the neural network is correct? We define a new function called the
    **co****st function** (![](img/5bb1b6b9-cd5d-44b2-8a3a-896a26d1e80f.png)), also
    known as the **loss function** (![](img/fbc4098e-0480-492b-8742-2e055c6fbb8e.png)),
    which tells us how well our neural network is performing. There are many different
    cost functions. We will use the mean squared error as a cost function, which can
    be defined as the mean of the squared difference between the actual output and
    the predicted output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c488ce70-38e6-4e74-b409-3334dfdf65ad.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, ![](img/50e54b3e-22b0-4fe5-9a09-4ec202021219.png) is the number of training
    samples, ![](img/cf05ae33-0d55-44f2-b238-b3e2cef84419.png) is actual output, and
    ![](img/2e0c94cb-54ad-4658-b9c7-f13cb993c739.png) is the predicted output.
  prefs: []
  type: TYPE_NORMAL
- en: Okay, so we learned that a cost function is used for assessing our neural network;
    that is, it tells us how good our neural network is at predicting the output.
    But the question is where is our network actually learning? In forward propagation,
    the network is just trying to predict the output. But how does it learn to predict
    the correct output? In the next section, we will examine this.
  prefs: []
  type: TYPE_NORMAL
- en: How does ANN learn?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If the cost or loss is very high, then it means that our network is not predicting
    the correct output. So, our objective is to minimize the cost function so that
    our neural network predictions will be better. How can we minimize the cost function?
    That is, how can we minimize the loss/cost? We learned that the neural network
    makes predictions using forward propagation. So, if we can change some values
    in the forward propagation, we can predict the correct output and minimize the
    loss. But what values can we change in the forward propagation? Obviously, we
    can't change input and output. We are now left with weights and bias values. Remember
    that we just initialized weight matrices randomly. Since the weights are random,
    they are not going to be perfect. Now, we will update these weight matrices (![](img/3e007dfd-6705-4a5f-8d63-9b8e1663031f.png)
    and ![](img/1c5358ea-4e8c-49b0-9e12-af1c8d04c16e.png) ) in such a way that our
    neural network gives a correct output. How do we update these weight matrices?
    Here comes a new technique called **gradient descent**.
  prefs: []
  type: TYPE_NORMAL
- en: With gradient descent, the neural network learns the optimal values of the randomly
    initialized weight matrices. With the optimal values of weights, our network can
    predict the correct output and minimize the loss.
  prefs: []
  type: TYPE_NORMAL
- en: Now, we will explore how the optimal values of weights are learned using gradient
    descent. Gradient descent is one of the most commonly used optimization algorithms.
    It is used for minimizing the cost function, which allows us to minimize the error
    and obtain the lowest possible error value. But how does gradient descent find
    the optimal weights? Let's begin with an analogy.
  prefs: []
  type: TYPE_NORMAL
- en: Imagine we are on top of a hill, as shown in the following diagram, and we want
    to reach the lowest point on the hill. There could be many regions that look like
    the lowest points on the hill, but we have to reach the lowest point that is actually
    the lowest of all.
  prefs: []
  type: TYPE_NORMAL
- en: 'That is, we should not be stuck at a point believing it is the lowest point
    when the global lowest point exists:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/99ca846c-c054-412d-8798-0485964e6051.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Similarly, we can represent our cost function as follows. It is a plot of cost
    against weights. Our objective is to minimize the cost function. That is, we have
    to reach the lowest point where the cost is the minimum. The solid dark point
    in the following diagram shows the randomly initialized weights. If we move this
    point downward, then we can reach the point where the cost is the minimum:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/28e3cddf-581f-4795-ba7b-5621bdb76849.png)'
  prefs: []
  type: TYPE_IMG
- en: But how can we move this point (initial weight) downward? How can we descend
    and reach the lowest point? Gradients are used for moving from one point to another.
    So, we can move this point (initial weight) by calculating a gradient of the cost
    function with respect to that point (initial weights), which is ![](img/cdaa7865-fa7e-4521-b9ac-6e2029df1e56.png).
  prefs: []
  type: TYPE_NORMAL
- en: 'Gradients are the derivatives that are actually the slope of a tangent line
    as illustrated in the following diagram. So, by calculating the gradient, we descend
    (move downward) and reach the lowest point where the cost is the minimum. Gradient
    descent is a first-order optimization algorithm, which means we only take into
    account the first derivative when performing the updates:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/cc6ee8c1-f612-4953-8e0d-41520c38fae7.png)'
  prefs: []
  type: TYPE_IMG
- en: Thus, with gradient descent, we move our weights to a position where the cost
    is minimum. But, still, how do we update the weights?
  prefs: []
  type: TYPE_NORMAL
- en: 'As a result of forward propagation, we are in the output layer. We will now
    **backpropagate** the network from the output layer to the input layer and calculate
    the gradient of the cost function with respect to all the weights between the
    output and the input layer so that we can minimize the error. After calculating
    gradients, we update our old weights using the weight update rule:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c038f863-5459-4ada-a1a6-6406f93fee39.png)'
  prefs: []
  type: TYPE_IMG
- en: This implies *weights = weights -Î± * gradients*.
  prefs: []
  type: TYPE_NORMAL
- en: What is ![](img/8179ea37-437e-40e1-a563-98346e3be569.png)? It is called the
    **learning rate**. As shown in the following diagram, if the learning rate is
    small, then we take a small step downward and our gradient descent can be slow.
  prefs: []
  type: TYPE_NORMAL
- en: 'If the learning rate is large, then we take a large step and our gradient descent
    will be fast, but we might fail to reach the global minimum and become stuck at
    a local minimum. So, the learning rate should be chosen optimally:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/975346d3-1711-4973-bacf-8bd77141ff5b.png)'
  prefs: []
  type: TYPE_IMG
- en: This whole process of backpropagating the network from the output layer to the
    input layer and updating the weights of the network using gradient descent to
    minimize the loss is called **backpropagation**. Now that we have a basic understanding
    of backpropagation, we will strengthen our understanding by learning about this
    in detail, step-by-step. We are going to look at some interesting math, so put
    on your calculus hats and follow the steps.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, we have two weights, one ![](img/ca5dfcf7-41c2-4a8a-8883-9b30519930bd.png),input
    to hidden layer weights, and the other ![](img/9576ab5d-840e-4382-8130-bd525f556023.png),
    hidden to output layer weights. We need to find the optimal values for these two
    weights that will give us the fewest errors. So, we need to calculate the derivative
    of the cost function ![](img/a803a8a5-9812-4b93-a811-5e1a6c4e8c54.png) with respect
    to these weights. Since we are backpropagating, that is, going from the output
    layer to the input layer, our first weight will be![](img/487d3133-d88e-46eb-abdf-cc4c577a5fe4.png).
    So, now we need to calculate the derivative of ![](img/a803a8a5-9812-4b93-a811-5e1a6c4e8c54.png)
    with respect to ![](img/caea536c-bf53-4095-83b8-56981f591219.png). How do we calculate
    the derivative? First, let''s recall our cost function, ![](img/a803a8a5-9812-4b93-a811-5e1a6c4e8c54.png):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/89657612-2da7-480d-9adc-4ba544bec713.png)'
  prefs: []
  type: TYPE_IMG
- en: We cannot calculate the derivative directly from the preceding equation since
    there is no
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5f7cfa6f-9a88-4dfe-834b-f8a0e432d721.png) term. So, instead of calculating
    the derivative directly, we calculate the partial derivative. Let''s recall our
    forward propagation equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/cfff4ced-f916-459e-91ec-436bb2571df5.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/35a873f3-75f8-4c90-9429-dfba3073c530.png)'
  prefs: []
  type: TYPE_IMG
- en: 'First, we will calculate a partial derivative with respect to [![](img/34155884-cff2-46fe-8289-ec304f441a2e.png)],
    and then from [![](img/28d2e95e-c6cc-4fa3-bbf5-2570bd4df04d.png)] we will calculate
    the partial derivative with respect to [![](img/1096ac8b-40a8-400d-904a-0dce7783570f.png)].
    From [![](img/f2071a3b-05b8-4315-8f6b-0cb42f3bfb29.png)], we can directly calculate
    our derivative [![](img/0895be9d-fcbd-4237-9b14-3db88a268320.png)]. It is basically
    the chain rule. So, the derivative of [![](img/c93c3c69-6d15-4f81-a049-d6c7095c5ab3.png)]
    with respect to ![](img/fc832c43-00ac-4825-8cc2-945ab173d55e.png) becomes as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2e4c510e-c439-4877-8a81-5dffd3972c41.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now, we will compute each of the terms in the preceding equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/74146337-3cbe-4c45-95b8-7043c21022bd.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/2fb19f9c-87bc-4e67-ab23-54d2e2553a41.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, ![](img/10c7ef2e-5667-46f5-a0f7-c200f50165ed.png) is the derivative of
    our sigmoid activation function. We know that the sigmoid function is [![](img/92e46632-0b6b-4fa7-80f2-80f925d761ad.png)],
    so the derivative of the sigmoid function would be [![](img/032ca043-1110-4ca5-9b24-7f617d042364.png)]:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/51925f25-3fc2-4e4d-90d5-f1e6ecb8b5a4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Thus, substituting all the preceding terms in equation *(1)* we can write:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/23f8268d-7224-44e9-9a8c-ac130056191d.png)'
  prefs: []
  type: TYPE_IMG
- en: Now we need to compute a derivative of [![](img/c93c3c69-6d15-4f81-a049-d6c7095c5ab3.png)]
    with respect to our next weight,[![](img/913e2324-d25d-4230-b0ca-dea93a027c15.png)].
  prefs: []
  type: TYPE_NORMAL
- en: 'Similarly, we cannot calculate the derivative of ![](img/092f60bc-0ed1-4a0a-887a-960a2768b4e2.png)
    directly from ![](img/c93c3c69-6d15-4f81-a049-d6c7095c5ab3.png) as we don''t have
    any ![](img/83bd97fb-7a2b-4b55-bb8e-cc8f00c7c295.png) terms in ![](img/c93c3c69-6d15-4f81-a049-d6c7095c5ab3.png).
    So, we need to use the chain rule. Let''s recall the forward propagation steps
    again:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1301fd01-bc90-4a01-aeb3-53298fbf474c.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/6cbad05b-da62-4fb0-a8da-1612262b3ba9.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/49fbf478-b44b-4544-a88d-fa38af76c837.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/dd27058f-3ed2-42c9-85f0-708b0e63134c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now, according to the chain rule, the derivative of ![](img/c93c3c69-6d15-4f81-a049-d6c7095c5ab3.png)
    with respect to![](img/0b948307-d86f-476f-b942-96b67cc16136.png) is given as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/aa8ae1ab-3d15-43a4-bbd8-96a0b90c9357.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We have already seen how to compute the first terms in the preceding equation;
    now, we will see how to compute the rest of the terms:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/238243e0-d20f-441c-b5ba-2d78d2c0f265.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/f6fb1473-f05d-4beb-b75d-f9a06d398cb1.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/40c69666-cd5e-49e2-995d-c7a662f86659.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Thus, substituting all the preceding terms in equation *(3)* we can write:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/552fd026-1f25-4a95-a947-90f8eb1a0301.png)'
  prefs: []
  type: TYPE_IMG
- en: 'After we have computed gradients for both weights, ![](img/3d784cf7-f536-456e-8515-2eb49e30e4b8.png)
    and ![](img/7a0fa5e1-2c18-4cb8-97dc-1f4c265608e5.png), we will update our initial
    weights according to the weight update rule:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7d4f9ae6-6194-43ad-b261-a74a597d85b6.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/ca8087d7-8cdd-47d7-ac17-260216c22fb7.png)'
  prefs: []
  type: TYPE_IMG
- en: That's it! This is how we update the weights of a network and minimize the loss.
    If you don't understand gradient descent yet, no worries! In [Chapter 3](28ee30be-bf81-4b2b-be0f-08ec3b03a9a7.xhtml),
    *Gradient Descent and Its Variants*, we will go into the basics and learn gradient
    descent and several variants of gradient descent in more detail. Now, let's see
    how to implement the backpropagation algorithm in Python.
  prefs: []
  type: TYPE_NORMAL
- en: 'In both the equations *(2)* and *(4)*, we have the term ![](img/e8bea459-13b0-41fa-84e4-506d4731e466.png),
    so instead of computing them again and again, we just call them `delta2`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we compute the gradient with respect to ![](img/cbc989b7-173e-4463-967d-fff236c07ffc.png).
    Refer to equation *(2)*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'We compute the gradient with respect to ![](img/0ca26aa5-e066-454a-b0ac-a0042b545572.png).
    Refer to equation *(4)*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'We will update the weights according to our weight update rule equation *(5)*
    and *(6)* as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The complete code for the backpropagation is given as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Before moving on, let''s familiarize ourselves with some of the frequently
    used terminologies in neural networks:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Forward pass**: Forward pass implies forward propagating from the input layer
    to the output layer.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Backward pass**: Backward pass implies backpropagating from the output layer
    to the input layer.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Epoch**: The epoch specifies the number of times the neural network sees
    our whole training data. So, we can say one epoch is equal to one forward pass
    and one backward pass for all training samples.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Batch size**: The batch size specifies the number of training samples we
    use in one forward pass and one backward pass.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Number of iterations**: The number of iterations implies the number of passes
    where *one pass = one forward pass + one backward pass*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Say that we have 12,000 training samples and that our batch size is 6,000\.
    It will take us two iterations to complete one epoch. That is, in the first iteration,
    we pass the first 6,000 samples and perform a forward pass and a backward pass;
    in the second iteration, we pass the next 6,000 samples and perform a forward
    pass and a backward pass. After two iterations, our neural network will see the
    whole 12,000 training samples, which makes it one epoch.
  prefs: []
  type: TYPE_NORMAL
- en: Debugging gradient descent with gradient checking
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We just learned how gradient descent works and how to code the gradient descent
    algorithm from scratch for a simple two-layer network. But implementing gradient
    descent for complex neural networks is not a simple task. Apart from implementing,
    debugging a gradient descent for complex neural network architecture is again
    a tedious task. Surprisingly, even with some buggy gradient descent implementations,
    the network will learn something. However, apparently, it will not perform well
    compared to the bug-free implementation of gradient descent.
  prefs: []
  type: TYPE_NORMAL
- en: If the model does not give us any errors and learns something even with buggy
    implementations of the gradient descent algorithm, how can we evaluate and ensure
    that our implementation is correct? That is why we use the gradient checking algorithm.
    It will help us to validate our implementation of gradient descent by numerically
    checking the derivative.
  prefs: []
  type: TYPE_NORMAL
- en: Gradient checking is basically used for debugging the gradient descent algorithm
    and to validate that we have a correct implementation.
  prefs: []
  type: TYPE_NORMAL
- en: Okay. So, how does gradient checking works? In gradient checking, we basically
    compare the numerical and analytical gradients. Wait! What are numerical and analytical
    gradients?
  prefs: []
  type: TYPE_NORMAL
- en: '**Analytical gradient** implies the gradients we calculated through backpropagation.
    **Numerical gradients** are the numerical approximation to the gradients. Let''s
    explore this with an example. Assume we have a simple square function, ![](img/2b8960b3-4692-488f-a07a-ef6e3fc3e048.png).'
  prefs: []
  type: TYPE_NORMAL
- en: 'The analytical gradient for the preceding function is computed using the power
    rule as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/421425f3-93c8-4fce-b526-90e13997f24c.png)'
  prefs: []
  type: TYPE_IMG
- en: Now, let's see how to approximate the gradient numerically. Instead of using
    the power rule to calculate gradients, we calculate gradients using a definition
    of the gradients. We know that the gradient or slope of a function basically gives
    us the steepness of the function.
  prefs: []
  type: TYPE_NORMAL
- en: 'Thus, the gradient or slope of a function is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0d706589-2d5e-4491-8114-39a488a68528.png)'
  prefs: []
  type: TYPE_IMG
- en: 'A gradient of a function can be given as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e8bc90bc-d88e-4c15-b986-c292d0c6c2e2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We use the preceding equation and approximate the gradients numerically. It
    implies that we are calculating the slope of the function manually, instead of
    using power rule as shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/91c3dccd-2d04-46ff-9f7e-7c088c80f5ab.png)'
  prefs: []
  type: TYPE_IMG
- en: Computing gradients through power rule *(7)* and approximating the gradients
    numerically *(8)* essentially gives us the same value. Let's see how *(7)* and
    *(8)* give the same value in Python.
  prefs: []
  type: TYPE_NORMAL
- en: 'Define the square function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Define the epsilon and input value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Compute the analytical gradient:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Compute the numerical gradient:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: As you may have noticed, computing numerical and analytical gradients of the
    square function essentially gave us the same value, which is `6` when *x =3*.
  prefs: []
  type: TYPE_NORMAL
- en: While backpropagating the network, we compute the analytical gradients to minimize
    the cost function. Now, we need to make sure that our computed analytical gradients
    are correct. So, let's validate that we approximate the numerical gradients of
    the cost function.
  prefs: []
  type: TYPE_NORMAL
- en: 'The gradients of ![](img/b89b62f6-a88e-4d9d-9293-b4c8e2cb0f69.png) with respect
    to ![](img/3de54252-f200-48b3-8ade-0c6e5fc5e2b3.png) can be numerically approximated
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/176aded0-ffbb-43c7-b899-b15888bcd4a3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'It is represented as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2d6e039e-148f-4c8b-a60c-03c190eef054.png)'
  prefs: []
  type: TYPE_IMG
- en: We check whether the analytical gradients and approximated numerical gradients
    are the same; if not, then there is an error in our analytical gradient computation.
    We don't want to check whether the numerical and analytical gradients are exactly
    the same; since we are only approximating the numerical gradients, we check the
    difference between the analytical and numerical gradients as an error. If the
    difference is less than or equal to a very small number say, *1e-7*, then our
    implementation is fine. If the difference is greater than *1e-7*, then our implementation
    is wrong.
  prefs: []
  type: TYPE_NORMAL
- en: 'Instead of calculating the error directly as the difference between the numerical
    gradient and the analytical gradient, we calculate the relative error. It can
    be defined as the ratio of differences to the ratio of an absolute value of the
    gradients:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b4c41974-fd9c-45ea-9fa8-49b7eca8c7a9.png)'
  prefs: []
  type: TYPE_IMG
- en: When the value of relative error is less than or equal to a small threshold
    value, say, *1e-7*, then our implementation is fine. If the relative error is
    greater than *1e-7*, then our implementation is wrong. Now let's see how to implement
    gradient checking algorithm in Python step-by-step.
  prefs: []
  type: TYPE_NORMAL
- en: First, we calculate the weights. Refer equation *(9):*
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Compute `J_plus` and `J_minus`. Refer equation *(9):*
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can compute the numerical gradient as given in *(9)* as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Analytical gradients can be obtained through backpropagation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Compute the relative error as given in equation *(10)* as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'If the relative error is less than a small threshold value, say `1e-7`, then
    our gradient descent implementation is correct; otherwise, it is wrong:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Thus, with the help of gradient checking, we make sure that our gradient descent
    algorithm is bug-free.
  prefs: []
  type: TYPE_NORMAL
- en: Putting it all together
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Putting all the concepts we have learned so far together, we will see how to
    build a neural network from scratch. We will understand how the neural network
    learns to perform the XOR gate operation. The XOR gate returns 1 only when exactly
    only one of its inputs is 1, else it returns 0 as shown in the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/27147219-0adc-49ba-a3d4-40df55825d41.png)'
  prefs: []
  type: TYPE_IMG
- en: Building a neural network from scratch
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To perform the XOR gate operation, we build a simple two-layer neural network,
    as shown in the following diagram. As you can see, we have an input layer with
    two nodes: a hidden layer with five nodes and an output layer comprising one node:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/584c586c-8500-4150-907b-f32a004254ca.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We will understand step-by-step how a neural network learns the XOR logic:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, import the libraries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Prepare the data as shown in the preceding XOR table:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Define the number of nodes in each layer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Initialize the weights and bias randomly. First, we initialize the input to
    hidden layer weights:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we initialize the hidden to output layer weights:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Define the sigmoid activation function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Define the derivative of the sigmoid function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Define the forward propagation:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Define the backward propagation:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Define the cost function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Set the learning rate and the number of training iterations:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s start training the network with the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Plot the cost function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can observe in the following plot, the loss decreases over the training
    iterations:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8491d0d9-3387-4789-944b-8315befbc019.png)'
  prefs: []
  type: TYPE_IMG
- en: Thus, in this chapter, we got an overall understanding of artificial neural
    network and how they learn.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We started off the chapter by understanding what deep learning is and how it
    differs from machine learning. Later, we learned how biological and artificial
    neurons work, and then we explored what is input, hidden, and output layer in
    the ANN, and also several types of activation functions.
  prefs: []
  type: TYPE_NORMAL
- en: Going ahead, we learned what forward propagation is and how ANN uses forward
    propagation to predict the output. After this, we learned how ANN uses backpropagation
    for learning and optimizing. We learned an optimization algorithm called gradient
    descent that helps the neural network to minimize the loss and make correct predictions.
    We also learned about gradient checking, a technique that is used to evaluate
    the gradient descent. At the end of the chapter, we implemented a neural network
    from scratch to perform the XOR gate operation.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will learn about one of the most powerful and popularly
    used deep learning libraries called **TensorFlow**.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s evaluate our newly acquired knowledge by answering the following questions:'
  prefs: []
  type: TYPE_NORMAL
- en: How does deep learning differ from machine learning?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What does the word *deep* mean in deep learning?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why do we use the activation function?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Explain dying ReLU problem.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Define forward propagation.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is back propagation?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Explain gradient checking.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You can also check out some of these resources for more information:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Understand more about gradient descent from this amazing video: [https://www.youtube.com/watch?v=IHZwWFHWa-w](https://www.youtube.com/watch?v=IHZwWFHWa-w)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Learn about implementing a neural network from scratch to recognize handwritten
    digits: [https://github.com/sar-gupta/neural-network-from-scratch](https://github.com/sar-gupta/neural-network-from-scratch)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
