["```py\n!pip install -U opencv-python scikit-image\n```", "```py\ndef download_file(url: str, filename='demo.jpg'):\n    import requests\n    response = requests.get(url)\n    with open(filename, 'wb') as f:\n        f.write(response.content)\n\ndownload_file('https://raw.githubusercontent.com/open-mmlab/mmdetection/master/demo/demo.jpg')\n```", "```py\ndownload_file('https://gist.githubusercontent.com/benman1/51b2e4b10365333f0af34f4839f86f27/raw/991b41e5d5d83174d3d75b55915033550e16adf8/keras-yolo3.py', 'keras_yolo3.py')\n```", "```py\ndownload_file('https://pjreddie.com/media/files/yolov3.weights', 'yolov3.weights')\n```", "```py\nfrom keras_yolo3 import load_model, detect\n```", "```py\nyolov3 = load_model('yolov3.weights')\n```", "```py\nfrom matplotlib import pyplot as plt\n\nplt.imshow(detect(yolov3, 'demo.jpg'))\n```", "```py\nimport cv2\nfrom skimage import color\n\ncap = cv2.VideoCapture(0)\n\nwhile(True):\n    ret, frame = cap.read()\n\n    img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)    \n    img = detect(yolov3, img)\n    cv2.imshow('frame', img)\n    if cv2.waitKey(1) & 0xFF == ord('q'):\n        break\n\ncap.release()\ncv2.destroyAllWindows()\n```", "```py\n%matplotlib notebook\nimport cv2\nimport matplotlib.pyplot as plt\n\ndef grab_frame(cap):\n    ret, frame = cap.read()\n    if not ret:\n        print('No image captured!')\n        exit()\n    return cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n\ncap = cv2.VideoCapture(0)\nfig, ax = plt.subplots(1, 1)\nim = ax.imshow(grab_frame(cap))\n\nplt.tick_params(\n    top=False, bottom=False, left=False, right=False,\n    labelleft=False, labelbottom=False\n)\nplt.show()\n\nwhile True:\n    try:\n        im.set_data(grab_frame(cap))\n        fig.canvas.draw()\n    except KeyboardInterrupt:\n        cap.release()\n        break\n```", "```py\ngit clone https://github.com/benman1/faceit\n```", "```py\n./dockerbuild.sh\n```", "```py\n./dockerrun.sh\n```", "```py\nfrom faceit import *\n\nfaceit = FaceIt('hepburn_to_ohara', 'hepburn', 'ohara')\n```", "```py\nfaceit.add('ohara', 'mclintock.mp4')\nfaceit.add('hepburn', 'who_trust.mp4')\nFaceIt.add_model(faceit)\n```", "```py\nfaceit.preprocess()\nfaceit.train()\nfaceit.convert('who_trust.mp4', face_filter=True, photos=False)\n```", "```py\nfrom keras.models import Model\nfrom keras.layers import Input, Dense, Flatten, Reshape\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.layers.convolutional import Conv2D\nfrom keras.optimizers import Adam\nfrom lib.PixelShuffler import PixelShuffler\n\nIMAGE_SHAPE = (64, 64, 3)\nENCODER_DIM = 1024\n\ndef conv(self, filters):\n    def block(x):\n    x = Conv2D(filters, kernel_size=5, strides=2, padding='same')(x)\n    x = LeakyReLU(0.1)(x)\n    return x\n return block\n\ndef upscale(self, filters):\n    def block(x):\n    x = Conv2D(filters * 4, kernel_size=3, padding='same')(x)\n    x = LeakyReLU(0.1)(x)\n    x = PixelShuffler()(x)\n    return x\n return block\n\ndef Encoder():\n    input_ = Input(shape=IMAGE_SHAPE)\n    x = input_\n    x = conv(128)(x)\n    x = conv(256)(x)\n    x = conv(512)(x)\n    x = conv(1024)(x)\n    x = Dense(ENCODER_DIM)(Flatten()(x))\n    x = Dense(4 * 4 * 1024)(x)\n    x = Reshape((4, 4, 1024))(x)\n    x = upscale(512)(x)\n    return Model(input_, x)\n\ndef Decoder():\n    input_ = Input(shape=(8, 8, 512))\n    x = input_\n    x = upscale(256)(x)\n    x = upscale(128)(x)\n    x = upscale(64)(x)\n    x = Conv2D(3, kernel_size=5, padding='same', activation='sigmoid')(x)\n    return Model(input_, x)\n```", "```py\noptimizer = Adam(lr=5e-5, beta_1=0.5, beta_2=0.999)\nx = Input(shape=IMAGE_SHAPE)\n\nencoder = Encoder()\ndecoder_A, decoder_B = Decoder(), Decoder()\nautoencoder_A = Model(x, decoder_A(encoder(x)))\nautoencoder_B = Model(x, decoder_B(encoder(x)))\n\nautoencoder_A.compile(optimizer=optimizer, loss='mean_absolute_error')\nautoencoder_B.compile(optimizer=optimizer, loss='mean_absolute_error')\n```"]