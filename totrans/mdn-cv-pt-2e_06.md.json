["```py\n    # Note that you should run the code in\n    # Batch size of 32 section in Chapter 3\n    # before running the following code\n    import matplotlib.pyplot as plt\n    %matplotlib inline\n    # ix = np.random.randint(len(tr_images))\n    ix = 24300\n    plt.imshow(tr_images[ix], cmap='gray')\n    plt.title(fmnist.classes[tr_targets[ix]]) \n    ```", "```py\n    img = tr_images[ix]/255.\n    img = img.view(28*28)\n    img = img.to(device) \n    ```", "```py\n    np_output = model(img).cpu().detach().numpy()\n    np.exp(np_output)/np.sum(np.exp(np_output)) \n    ```", "```py\n    preds = [] \n    ```", "```py\n    for px in range(-5,6): \n    ```", "```py\n     img = tr_images[ix]/255.\n        img = img.view(28, 28) \n    ```", "```py\n     img2 = np.roll(img, px, axis=1) \n    ```", "```py\n     img3 = torch.Tensor(img2).view(28*28).to(device) \n    ```", "```py\n     np_output = model(img3).cpu().detach().numpy()\n        preds.append(np.exp(np_output)/np.sum(np.exp(np_output))) \n    ```", "```py\n    import seaborn as sns\n    fig, ax = plt.subplots(1,1, figsize=(12,10))\n    plt.title('Probability of each class \\\n    for various translations')\n    sns.heatmap(np.array(preds), annot=True, ax=ax, fmt='.2f',\n    xticklabels=fmnist.classes,yticklabels=[str(i)+ \\\n    str(' pixels') for i in range(-5,6)], cmap='gray') \n    ```", "```py\n    import torch\n    from torch import nn\n    from torch.utils.data import TensorDataset, Dataset, DataLoader\n    from torch.optim import SGD, Adam\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    from torchvision import datasets\n    import numpy as np\n    import matplotlib.pyplot as plt\n    %matplotlib inline \n    ```", "```py\n    X_train = torch.tensor([[[[1,2,3,4],[2,3,4,5],\n                              [5,6,7,8],[1,3,4,5]]],\n                            [[[-1,2,3,-4],[2,-3,4,5],\n                [-5,6,-7,8],[-1,-3,-4,-5]]]]).to(device).float()\n    X_train /= 8\n    y_train = torch.tensor([0,1]).to(device).float() \n    ```", "```py\n    def get_model():\n        model = nn.Sequential(\n                    nn.Conv2d(1, 1, kernel_size=3),\n                    nn.MaxPool2d(2),\n                    nn.ReLU(),\n                    nn.Flatten(),\n                    nn.Linear(1, 1),\n                    nn.Sigmoid(),\n                ).to(device)\n        loss_fn = nn.BCELoss()\n        optimizer = Adam(model.parameters(), lr=1e-3)\n        return model, loss_fn, optimizer \n    ```", "```py\n    !pip install torch_summary\n    from torchsummary import summary\n    model, loss_fn, optimizer = get_model()\n    summary(model, X_train); \n    ```", "```py\n    def train_batch(x, y, model, opt, loss_fn):\n        model.train()\n        prediction = model(x)\n        batch_loss = loss_fn(prediction.squeeze(0), y)\n        batch_loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n        return batch_loss.item() \n    ```", "```py\n    trn_dl = DataLoader(TensorDataset(X_train, y_train)) \n    ```", "```py\n    for epoch in range(2000):\n        for ix, batch in enumerate(iter(trn_dl)):\n            x, y = batch\n            batch_loss = train_batch(x, y, model,optimizer, loss_fn) \n    ```", "```py\n    model(X_train[:1]) \n    ```", "```py\n    from torchvision import datasets\n    from torch.utils.data import Dataset, DataLoader\n    import torch\n    import torch.nn as nn\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    import numpy as np\n    import matplotlib.pyplot as plt\n    %matplotlib inline\n    data_folder = '~/data/FMNIST' # This can be any directory you\n    # want to download FMNIST to\n    fmnist = datasets.FashionMNIST(data_folder,download=True, train=True)\n    tr_images = fmnist.data\n    tr_targets = fmnist.targets \n    ```", "```py\n    class FMNISTDataset(Dataset):\n        def __init__(self, x, y):\n            x = x.float()/255\n            **x = x.view(-****1****,****1****,****28****,****28****)**\n            self.x, self.y = x, y\n        def __getitem__(self, ix):\n            x, y = self.x[ix], self.y[ix]\n            return x.to(device), y.to(device)\n        def __len__(self):\n            return len(self.x) \n    ```", "```py\n    from torch.optim import SGD, Adam\n    def get_model():\n        model = nn.Sequential(\n                    nn.Conv2d(1, 64, kernel_size=3),\n                    nn.MaxPool2d(2),\n                    nn.ReLU(),\n                    nn.Conv2d(64, 128, kernel_size=3),\n                    nn.MaxPool2d(2),\n                    nn.ReLU(),\n                    nn.Flatten(),\n                    nn.Linear(3200, 256),\n                    nn.ReLU(),\n                    nn.Linear(256, 10)\n                ).to(device)\n        loss_fn = nn.CrossEntropyLoss()\n        optimizer = Adam(model.parameters(), lr=1e-3)\n        return model, loss_fn, optimizer \n    ```", "```py\n    from torchsummary import summary\n    model, loss_fn, optimizer = get_model()\n    summary(model, torch.zeros(1,1,28,28)); \n    ```", "```py\n    preds = []\n    ix = 24300\n    for px in range(-5,6):\n        img = tr_images[ix]/255.\n        img = img.view(28, 28)\n        img2 = np.roll(img, px, axis=1)\n        plt.imshow(img2)\n        plt.show()\n        img3 = torch.Tensor(img2).view(-1,1,28,28).to(device)\n        np_output = model(img3).cpu().detach().numpy()\n        preds.append(np.exp(np_output)/np.sum(np.exp(np_output))) \n    ```", "```py\n    import seaborn as sns\n    fig, ax = plt.subplots(1,1, figsize=(12,10))\n    plt.title('Probability of each class for \\\n    various translations')\n    sns.heatmap(np.array(preds).reshape(11,10), annot=True,\n                ax=ax,fmt='.2f', xticklabels=fmnist.classes,\n                yticklabels=[str(i)+str(' pixels') \\\n                for i in range(-5,6)], cmap='gray') \n    ```", "```py\n    !wget https://www.dropbox.com/s/5jh4hpuk2gcxaaq/all.zip\n    !unzip all.zip \n    ```", "```py\n    import torch\n    from torch import nn\n    from torch.utils.data import TensorDataset,Dataset,DataLoader\n    from torch.optim import SGD, Adam\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    from torchvision import datasets\n    import numpy as np, cv2\n    import matplotlib.pyplot as plt\n    %matplotlib inline\n    from glob import glob\n    from imgaug import augmenters as iaa \n    ```", "```py\n    tfm = iaa.Sequential(iaa.Resize(28)) \n    ```", "```py\n    class XO(Dataset):\n        def __init__(self, folder):\n            self.files = glob(folder) \n    ```", "```py\n     def __len__(self): return len(self.files) \n    ```", "```py\n     def __getitem__(self, ix):\n            f = self.files[ix]\n            im = tfm.augment_image(cv2.imread(f)[:,:,0]) \n    ```", "```py\n     im = im[None] \n    ```", "```py\n     cl = f.split('/')[-1].split('@')[0] == 'x' \n    ```", "```py\n     return torch.tensor(1 - im/255).to(device).float(),\n                          torch.tensor([cl]).float().to(device) \n    ```", "```py\n    data = XO('/content/all/*') \n    ```", "```py\n    R, C = 7,7\n    fig, ax = plt.subplots(R, C, figsize=(5,5))\n    for label_class, plot_row in enumerate(ax):\n        for plot_cell in plot_row:\n            plot_cell.grid(False); plot_cell.axis('off')\n            ix = np.random.choice(1000)\n            im, label = data[ix]\n            print()\n            plot_cell.imshow(im[0].cpu(), cmap='gray')\n    plt.tight_layout() \n    ```", "```py\n    from torch.optim import SGD, Adam\n    def get_model():\n        model = nn.Sequential(\n                    nn.Conv2d(1, 64, kernel_size=3),\n                    nn.MaxPool2d(2),\n                    nn.ReLU(),\n                    nn.Conv2d(64, 128, kernel_size=3),\n                    nn.MaxPool2d(2),\n                    nn.ReLU(),\n                    nn.Flatten(),\n                    nn.Linear(3200, 256),\n                    nn.ReLU(),\n                    nn.Linear(256, 1),\n                    nn.Sigmoid()\n                ).to(device)\n        loss_fn = nn.BCELoss()\n        optimizer = Adam(model.parameters(), lr=1e-3)\n        return model, loss_fn, optimizer \n    ```", "```py\n    !pip install torch_summary\n    from torchsummary import summary\n    model, loss_fn, optimizer = get_model()\n    summary(model, torch.zeros(1,1,28,28)); \n    ```", "```py\n    def train_batch(x, y, model, opt, loss_fn):\n        model.train()\n        prediction = model(x)\n        is_correct = (prediction > 0.5) == y\n        batch_loss = loss_fn(prediction, y)\n        batch_loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n        return batch_loss.item(), is_correct[0] \n    ```", "```py\n    trn_dl = DataLoader(XO('/content/all/*'),batch_size=32, drop_last=True) \n    ```", "```py\n    model, loss_fn, optimizer = get_model() \n    ```", "```py\n    for epoch in range(5):\n        for ix, batch in enumerate(iter(trn_dl)):\n            x, y = batch\n            batch_loss = train_batch(x, y, model,optimizer, loss_fn) \n    ```", "```py\n    im, c = trn_dl.dataset[2]\n    plt.imshow(im[0].cpu())\n    plt.show() \n    ```", "```py\n    first_layer = nn.Sequential(*list(model.children())[:1])\n    intermediate_output = first_layer(im[None])[0].detach() \n    ```", "```py\n    fig, ax = plt.subplots(8, 8, figsize=(10,10))\n    for ix, axis in enumerate(ax.flat):\n        axis.set_title('Filter: '+str(ix))\n        axis.imshow(intermediate_output[ix].cpu())\n    plt.tight_layout()\n    plt.show() \n    ```", "```py\n    x, y = next(iter(trn_dl))\n    x2 = x[y==0] \n    ```", "```py\n    x2 = x2.view(-1,1,28,28) \n    ```", "```py\n    first_layer = nn.Sequential(*list(model.children())[:1]) \n    ```", "```py\n    first_layer_output = first_layer(x2).detach() \n    ```", "```py\n    n = 4\n    fig, ax = plt.subplots(n, n, figsize=(10,10))\n    for ix, axis in enumerate(ax.flat):\n        axis.imshow(first_layer_output[ix,4,:,:].cpu())\n        axis.set_title(str(ix))\n    plt.tight_layout()\n    plt.show() \n    ```", "```py\n    second_layer = nn.Sequential(*list(model.children())[:4])\n    second_intermediate_output=second_layer(im[None])[0].detach() \n    ```", "```py\n    fig, ax = plt.subplots(11, 11, figsize=(10,10))\n    for ix, axis in enumerate(ax.flat):\n        axis.imshow(second_intermediate_output[ix].cpu())\n        axis.set_title(str(ix))\n    plt.tight_layout()\n    plt.show() \n    ```", "```py\n    second_layer = nn.Sequential(*list(model.children())[:4])\n    second_intermediate_output = second_layer(x2).detach()\n    fig, ax = plt.subplots(4, 4, figsize=(10,10))\n    for ix, axis in enumerate(ax.flat):\n        axis.imshow(second_intermediate_output[ix,34,:,:].cpu())\n        axis.set_title(str(ix))\n    plt.tight_layout()\n    plt.show() \n    ```", "```py\n    custom_dl= DataLoader(XO('/content/all/*'),batch_size=2498, drop_last=True) \n    ```", "```py\n    x, y = next(iter(custom_dl))\n    x2 = x[y==0]\n    x2 = x2.view(len(x2),1,28,28) \n    ```", "```py\n    flatten_layer = nn.Sequential(*list(model.children())[:7])\n    flatten_layer_output = flatten_layer(x2).detach() \n    ```", "```py\n    plt.figure(figsize=(100,10))\n    plt.imshow(flatten_layer_output.cpu()) \n    ```", "```py\n    import torchvision\n    import torch.nn as nn\n    import torch\n    import torch.nn.functional as F\n    from torchvision import transforms,models,datasets\n    from PIL import Image\n    from torch import optim\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    import cv2, glob, numpy as np, pandas as pd\n    import matplotlib.pyplot as plt\n    %matplotlib inline\n    from glob import glob\n    !pip install torch_summary \n    ```", "```py\n    !pip install -q aggle\n    from google.colab import files\n    files.upload() \n    ```", "```py\n    !mkdir -p ~/.kaggle\n    !cp kaggle.json ~/.kaggle/\n    !ls ~/.kaggle\n    !chmod 600 /root/.kaggle/kaggle.json \n    ```", "```py\n    !kaggle datasets download -d tongpython/cat-and-dog\n    !unzip cat-and-dog.zip \n    ```", "```py\n    train_data_dir = '/content/training_set/training_set'\n    test_data_dir = '/content/test_set/test_set' \n    ```", "```py\n    from torch.utils.data import DataLoader, Dataset\n    class cats_dogs(Dataset):\n        def __init__(self, folder):\n            cats = glob(folder+'/cats/*.jpg')\n            dogs = glob(folder+'/dogs/*.jpg')\n            self.fpaths = cats + dogs \n    ```", "```py\n     from random import shuffle, seed; seed(10);\n            shuffle(self.fpaths)\n            self.targets=[fpath.split('/')[-1].startswith('dog') \\\n                          for fpath in self.fpaths] # dog=1 \n    ```", "```py\n     def __len__(self): return len(self.fpaths) \n    ```", "```py\n     def __getitem__(self, ix):\n            f = self.fpaths[ix]\n            target = self.targets[ix]\n            im = (cv2.imread(f)[:,:,::-1])\n            im = cv2.resize(im, (224,224))\n            return torch.tensor(im/255).permute(2,0,1).to(device).float(),\\\n                   torch.tensor([target]).float().to(device) \n    ```", "```py\n    data = cats_dogs(train_data_dir)\n    im, label = data[200] \n    ```", "```py\n    plt.imshow(im.permute(1,2,0).cpu())\n    print(label) \n    ```", "```py\n    def conv_layer(ni,no,kernel_size,stride=1):\n        return nn.Sequential(\n            nn.Conv2d(ni, no, kernel_size, stride),\n            nn.ReLU(),\n            nn.BatchNorm2d(no),\n            nn.MaxPool2d(2)\n        ) \n    ```", "```py\n    def get_model():\n        model = nn.Sequential(\n                  conv_layer(3, 64, 3),\n                  conv_layer(64, 512, 3),\n                  conv_layer(512, 512, 3),\n                  conv_layer(512, 512, 3),\n                  conv_layer(512, 512, 3),\n                  conv_layer(512, 512, 3),\n                  nn.Flatten(),\n                  nn.Linear(512, 1),\n                  nn.Sigmoid(),\n                ).to(device)\n        loss_fn = nn.BCELoss()\n        optimizer=torch.optim.Adam(model.parameters(), lr= 1e-3)\n        return model, loss_fn, optimizer \n    ```", "```py\n    from torchsummary import summary\n    model, loss_fn, optimizer = get_model()\n    summary(model, torch.zeros(1,3, 224, 224)); \n    ```", "```py\n    def get_data():\n        train = cats_dogs(train_data_dir)\n        trn_dl = DataLoader(train, batch_size=32, shuffle=True,\n                                              drop_last = True)\n        val = cats_dogs(test_data_dir)\n        val_dl = DataLoader(val,batch_size=32, shuffle=True, drop_last = True)\n        return trn_dl, val_dl \n    ```", "```py\n    def train_batch(x, y, model, opt, loss_fn):\n        model.train()\n        prediction = model(x)\n        batch_loss = loss_fn(prediction, y)\n        batch_loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n        return batch_loss.item() \n    ```", "```py\n    @torch.no_grad()\n    def accuracy(x, y, model):\n        prediction = model(x)\n        is_correct = (prediction > 0.5) == y\n        return is_correct.cpu().numpy().tolist() \n    ```", "```py\n    @torch.no_grad()\n    def val_loss(x, y, model):\n        prediction = model(x)\n        val_loss = loss_fn(prediction, y)\n        return val_loss.item() \n    ```", "```py\n    trn_dl, val_dl = get_data()\n    model, loss_fn, optimizer = get_model() \n    ```", "```py\n    train_losses, train_accuracies = [], []\n    val_losses, val_accuracies = [], []\n    for epoch in range(5):\n        train_epoch_losses, train_epoch_accuracies = [], []\n        val_epoch_accuracies = []\n        for ix, batch in enumerate(iter(trn_dl)):\n            x, y = batch\n            batch_loss = train_batch(x, y, model,optimizer, loss_fn)\n            train_epoch_losses.append(batch_loss)\n        train_epoch_loss = np.array(train_epoch_losses).mean()\n        for ix, batch in enumerate(iter(trn_dl)):\n            x, y = batch\n            is_correct = accuracy(x, y, model)\n            train_epoch_accuracies.extend(is_correct)\n        train_epoch_accuracy = np.mean(train_epoch_accuracies)\n        for ix, batch in enumerate(iter(val_dl)):\n            x, y = batch\n            val_is_correct = accuracy(x, y, model)\n            val_epoch_accuracies.extend(val_is_correct)\n        val_epoch_accuracy = np.mean(val_epoch_accuracies)\n        train_losses.append(train_epoch_loss)\n        train_accuracies.append(train_epoch_accuracy)\n        val_accuracies.append(val_epoch_accuracy) \n    ```", "```py\n    epochs = np.arange(5)+1\n    import matplotlib.ticker as mtick\n    import matplotlib.pyplot as plt\n    import matplotlib.ticker as mticker\n    %matplotlib inline\n    plt.plot(epochs, train_accuracies, 'bo',\n             label='Training accuracy')\n    plt.plot(epochs, val_accuracies, 'r',\n             label='Validation accuracy')\n    plt.gca().xaxis.set_major_locator(mticker.MultipleLocator(1))\n    plt.title('Training and validation accuracy \\\n    with 4K data points used for training')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.gca().set_yticklabels(['{:.0f}%'.format(x*100) \\\n                               for x in plt.gca().get_yticks()])\n    plt.legend()\n    plt.grid('off')\n    plt.show() \n    ```", "```py\n def __init__(self, folder):\n        cats = glob(folder+'/cats/*.jpg')\n        dogs = glob(folder+'/dogs/*.jpg')\n        self.fpaths = cats[:500] + dogs[:500]\n        from random import shuffle, seed; seed(10);\n            shuffle(self.fpaths)\n        self.targets = [fpath.split('/')[-1].startswith('dog') \\\n                        for fpath in self.fpaths] \n```"]