- en: Chapter 9. Anomaly Detection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [Chapter 4](part0027_split_000.html#PNV62-c1ed1b54ca0b4e9fbb9fe2b2431d634f
    "Chapter 4. Unsupervised Feature Learning"), *Unsupervised Feature Learning*,
    we saw the mechanisms of feature learning and in particular the use of auto-encoders
    as an unsupervised pre-training step for supervised learning tasks.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we are going to apply similar concepts, but for a different
    use case, anomaly detection.
  prefs: []
  type: TYPE_NORMAL
- en: One of the determinants for a good anomaly detector is finding smart data representations
    that can easily evince deviations from the normal distribution. Deep auto-encoders
    work very well in learning high-level abstractions and non-linear relationships
    of the underlying data. We will show how deep learning is a great fit for anomaly
    detection.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will start by explaining the differences and communalities
    of concepts between outlier detection and anomaly detection. The reader will be
    guided through an imaginary fraud case study followed by examples showing the
    danger of having anomalies in real-world applications and the importance of automated
    and fast detection systems.
  prefs: []
  type: TYPE_NORMAL
- en: Before to move onto the deep learning implementations, we will cover a few families
    of techniques widely used in traditional machine learning and their current limits.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will apply the architectures of deep auto-encoders seen in [Chapter 4](part0027_split_000.html#PNV62-c1ed1b54ca0b4e9fbb9fe2b2431d634f
    "Chapter 4. Unsupervised Feature Learning"), *Unsupervised* *Feature Learning*,
    but for a particular kind of semi-supervised learning, also known as novelty detection.
    We will propose two powerful approaches: one based on reconstruction errors and
    another based on low-dimensional feature compression.'
  prefs: []
  type: TYPE_NORMAL
- en: We will introduce H2O, one of the most demanded open source frameworks for building
    simple, but scalable feed-forward multi-layer neural networks.
  prefs: []
  type: TYPE_NORMAL
- en: Lastly, we will code a couple of examples of anomaly detection using the Python
    API of the H2O auto-encoder model.
  prefs: []
  type: TYPE_NORMAL
- en: The first example will reuse the MNIST digit dataset that you have seen [Chapter
    3](part0022_split_000.html#KVCC2-c1ed1b54ca0b4e9fbb9fe2b2431d634f "Chapter 3. Deep
    Learning Fundamentals"), *Deep Learning Fundamentals* and [Chapter 4](part0027_split_000.html#PNV62-c1ed1b54ca0b4e9fbb9fe2b2431d634f
    "Chapter 4. Unsupervised Feature Learning"), *Unsupervised Feature Learning*,
    but for detecting badly written digits. A second example will show how to detect
    anomalous pulsations in electrocardiogram time series.
  prefs: []
  type: TYPE_NORMAL
- en: 'To summarize, this chapter will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: What is anomaly and outlier detection?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Real-world applications of anomaly detection
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Popular shallow machine learning techniques
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Anomaly detection using deep auto-encoders
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: H2O overview
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Code examples:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: MNIST digit anomaly recognition
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Electrocardiogram pulse detection
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: What is anomaly and outlier detection?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Anomaly detection, often related to outlier detection and novelty detection,
    is the identification of items, events, or observations that deviate considerably
    from an expected pattern observed in a homogeneous dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Anomaly detection is about predicting the unknown.
  prefs: []
  type: TYPE_NORMAL
- en: 'Whenever we find a discordant observation in the data, we could call it an
    anomaly or outlier. Although the two words are often used interchangeably, they
    actual refer to two different concepts, as Ravi Parikh describes in one of his
    blog posts (`https://blog.heapanalytics.com/garbage-in-garbage-out-how-anomalies-can-wreck-your-data/`):'
  prefs: []
  type: TYPE_NORMAL
- en: '*"An outlier is a legitimate data point that''s far away from the mean or median
    in a distribution. It may be unusual, like a 9.6-second 100-meter dash, but still
    within the realm of reality. An anomaly is an illegitimate data point that''s
    generated by a different process than whatever generated the rest of the data."*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Let's try to explain the difference using a simple example of fraud detection.
  prefs: []
  type: TYPE_NORMAL
- en: In a log of transactions, we observe that a particular customer spends an average
    of $10 for their lunch every weekday. Suddenly, one day they spend $120\. This
    is certainly an outlier, but perhaps that day they decided to pay the whole bill
    with their credit card. If a few of those transactions are orders of magnitude
    higher than their expected amount, then we could identify an anomaly. An anomaly
    is when the singular rare event justification does not hold anymore, for instance,
    transactions of $120 or higher over three consecutive orders. In this scenario,
    we are talking of anomalies because a pattern of repeated and linked outliers
    have been generated from a different process, possibly credit card fraud, with
    respect to the usual behavior.
  prefs: []
  type: TYPE_NORMAL
- en: While threshold rules can solve many detection problems, discovering complicated
    anomalies requires more advanced techniques.
  prefs: []
  type: TYPE_NORMAL
- en: What if a cloned credit card makes a lot of micro-payments of the amount of
    10$? The rule-based detector would probably fail.
  prefs: []
  type: TYPE_NORMAL
- en: 'By simply looking at the measures over each dimension independently, the anomaly
    generation process could still be hidden within the average distribution. A single
    dimension signal would not trigger any alert. Let''s see what happens if we add
    a few extra dimensions to the credit card fraud example: the geo-location, the
    time of the day in the local time zone, and the day of the week.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s analyze the same fraud example in more detail. Our customer is a full-time
    employee based in Milan, but resident in Rome. Every Monday morning, he takes
    the train, goes to work, and comes back to Rome on Saturday morning to see his
    friends and family. He loves cooking at home; he only goes out for dinner a few
    times during the week. In Rome, he lives near to his relatives, so he never has
    to prepare lunch during weekends, but he often enjoys spending the night out with
    friends. The distributions of the expected behavior would be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Amount**: Between $5 and $40'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Location**: Milan 70% and Rome 30%'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Time of the day**: 70% between noon and 2 P.M. and 30% between 9 P.M. and
    11 P.M.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Day of the week**: Uniform over the week'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: One day, his credit card is cloned. The fraudulent person lives near his workplace
    and in order not to get caught, they systematically make small payments of $25
    every night around 10 P.M. in an accomplice's corner shop.
  prefs: []
  type: TYPE_NORMAL
- en: If we look at the single dimensions, the fraudulent transactions would be just
    slightly outside the expected distribution, but still acceptable. The effect on
    the distributions of the amount and the day of the week would stay more or less
    the same while the location and time of the day would slightly increase toward
    Milan at evening time.
  prefs: []
  type: TYPE_NORMAL
- en: Even if systematically repeated, a little change in his lifestyle would be a
    reasonable explanation. The fraudulent activity would soon turn into the newer
    expected behavior, the normality.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s consider the joint distribution instead:'
  prefs: []
  type: TYPE_NORMAL
- en: 70% amount around 10$ in Milan over lunch time only on weekdays
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 30% amount around 30$ in Rome at dinner time only at weekends
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this scenario, the fraudulent activity would immediately be flagged as an
    outlier at its first occurrence since transactions in Milan at night above $20
    are very rare.
  prefs: []
  type: TYPE_NORMAL
- en: Given the preceding example, we might think that considering more dimensions
    together makes our anomaly detection smarter. Just like any other machine learning
    algorithm, you need to find a trade-off between complexity and generalization.
  prefs: []
  type: TYPE_NORMAL
- en: Having too many dimensions would project all of the observations in a space
    where all of them are equally distant from each other. As a consequence, everything
    would be an "outlier", which, in the way we defined an outlier, intrinsically
    makes the whole dataset "normal". In other words, if every point looks just the
    same then you can't distinguish between the two cases. Having too few dimensions
    would not allow the model to spot an outlier from the haystack and may let it
    hide in the mass distribution for longer or maybe forever.
  prefs: []
  type: TYPE_NORMAL
- en: 'Nevertheless, only identifying outliers is not enough. Outliers can happen
    due to rare events, errors in data collection, or noise. Data is always dirty
    and full of inconsistencies. The first rule is "never assume your data is clean
    and correct". Finding outliers is just a standard routine. What would be surprising,
    instead, is finding contingent and unexplainable repeated behaviors:'
  prefs: []
  type: TYPE_NORMAL
- en: '*"Data scientists realize that their best days coincide with discovery of truly
    odd features in the data."*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*Haystacks and Needles: Anomaly Detection By: Gerhard Pilcher & Kenny Darrell,
    Data Mining Analyst, Elder Research, Inc.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The persistence of a given outlier pattern is the signal that something has
    changed in the system we are monitoring. The real anomaly detection happens when
    observing systematic deviations in the underlying data generation process.
  prefs: []
  type: TYPE_NORMAL
- en: This also has an implication in the data preprocessing step. Contrary to what
    you would do for many machine learning problems, in anomaly detection you can't
    just filter out all of the outliers! Nevertheless, you should be careful in distinguishing
    between the nature of those. You do want to filter out wrong data entries, remove
    the noise, and normalize the remaining. Ultimately, you want to detect novelties
    in your cleaned dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Real-world applications of anomaly detection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Anomalies can happen in any system. Technically, you can always find a never-seen-before
    event that could not be found in the system's historical data. The implications
    of detecting those observations in some contexts can have a great impact (positive
    and negative).
  prefs: []
  type: TYPE_NORMAL
- en: In the field of law enforcement, anomaly detection could be used to reveal criminal
    activities (supposing you are in an area where the average person is honest enough
    to identify criminals standing out of the distribution).
  prefs: []
  type: TYPE_NORMAL
- en: In a network system, anomaly detection can help at finding external intrusions
    or suspicious activities of users, for instance, an employee who is accidentally
    or intentionally leaking large amounts of data outside the company intranet. Or
    maybe a hacker opening connections on non-common ports and/or protocols. In the
    specific case of Internet security, anomaly detection could be used for stopping
    new malware from spreading out by simply looking at spikes of visitors on non-trusted
    domains. And even if cyber security is not your core business, you should protect
    your network with data-driven solutions that can monitor and alert you in case
    of unrecognized activities.
  prefs: []
  type: TYPE_NORMAL
- en: Another similar example is authentication systems for many major social networks.
    Dedicated security teams have developed solutions that can measure each single
    activity, or sequence of them, and how distant those are from the median behavior
    of other users. Every time the algorithm marks an activity as suspicious, the
    system will prompt you with additional verifications. Those techniques can dramatically
    reduce identity theft and offer greater privacy protection. Likewise, the same
    concept can be applied to financial fraud, as we have seen in the previous example.
  prefs: []
  type: TYPE_NORMAL
- en: Anomalies generated by human behavior are among the most popular applications,
    but also the toughest. It is like a chess game. On one side, you have subject
    matter experts, data scientists, and engineers developing advanced detection systems.
    On the other side, you have hackers, aware of the game, studying their opponent's
    moves. That's why those kinds of systems require a lot of domain knowledge and
    should be designed to be reactive and dynamic.
  prefs: []
  type: TYPE_NORMAL
- en: Not all of the anomalies are originated from the "bad guys". In marketing, anomalies
    can represent isolated, but highly profitable customers who can be targeted with
    tailored offers. Their different and particular interests and/or profitable profile
    can be used to detect the outlying customers. For example, during an economy recession
    period, finding a few potential customers who are increasing their profit despite
    the mass trend could be an idea for adapting your product and redesigning your
    business strategy.
  prefs: []
  type: TYPE_NORMAL
- en: Other applications are medical diagnosis, hardware fault detection, predictive
    maintenance, and many more. Those applications also require agility.
  prefs: []
  type: TYPE_NORMAL
- en: Business opportunities, just like new malware, can rise every day and their
    life cycle could be very short, from hours to a few weeks. If your system is slow
    to react, you could be too late and will never catch up to your competitors.
  prefs: []
  type: TYPE_NORMAL
- en: Human detection systems are not able to scale and generally suffer from generalization.
    Deviations from normal behavior are not always obvious and it could be hard for
    an analyst to remember the whole history to compare to, which is the core requirement
    for anomaly detection. The situation complicates if the anomaly pattern is hidden
    inside abstract and non-linear relationships of entities in your data. The need
    for intelligent and fully automated systems that can learn complex interactions
    and provide real-time and accurate monitoring is the next frontier of innovation
    in the field.
  prefs: []
  type: TYPE_NORMAL
- en: Popular shallow machine learning techniques
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Anomaly detection is not new and many techniques have been well studied. The
    modeling can be divided and combined into two phases: data modeling and detection
    modeling.'
  prefs: []
  type: TYPE_NORMAL
- en: Data modeling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Data modeling generally consists of grouping available data in the granularity
    of observations we would like to detect such that it contains all of the necessary
    information we would like the detection model to consider.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can identify three major types of data modeling techniques:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Point anomaly**: This is similar to singular outlier detection. Each row
    in our dataset corresponds to an independent observation. The goal is to classify
    each observation as "normal" or "anomaly" or, better, to provide a numerical anomaly
    score.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Contextual anomaly**: Each point is enriched with additional context information.
    A typical example is finding anomalies in a time series, where time itself represents
    the context. A spike of ice cream sales in January is not the same as in July.
    The context must be encapsulated into additional features. The time context could
    be a categorical calendar variable representing the month, quarter, day of month,
    day of week, or Boolean flags such as *is it* *a public holiday?*'
  prefs: []
  type: TYPE_NORMAL
- en: '**Collective anomaly**: Patterns of observations that represent the potential
    anomaly cause. The collective measures should be smartly aggregated into new features.
    An example is the fraud detection example described earlier. Transactions should
    be slotted into sessions or intervals and statistics should be extracted from
    the sequence such as standard deviation of payment amount, frequency, average
    interval between two consecutive transactions, spending trend, and so on.'
  prefs: []
  type: TYPE_NORMAL
- en: The same problem could be addressed with multiple hybrid approaches defining
    data points at different granularities. For example, you could initially detect
    individual anomalous transactions independently, then link them chronologically,
    encapsulate the time context, and repeat the detection over the slotted sequence.
  prefs: []
  type: TYPE_NORMAL
- en: Detection modeling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Regardless of the data type, the general input of the detection model consists
    of points in a multi-dimensional space (the feature space). Thus, with a bit of
    feature engineering, we can turn any anomaly representation into a single vector
    of features.
  prefs: []
  type: TYPE_NORMAL
- en: For this reason, we can see anomaly detection as a special case of outlier detection
    where the single point also encapsulates the context and any other information
    that can represent a pattern.
  prefs: []
  type: TYPE_NORMAL
- en: 'As any other machine learning technique, we have both supervised and unsupervised
    approaches. In addition, we also propose a semi-supervised schema:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Supervised**: Anomaly detection in a supervised manner can also be referred
    to as anomaly classification, for example, spam detection. In anomaly classification,
    we label each observation as anomaly (spam) or non-anomaly (ham) and then use
    a binary classifier to assign each point to the corresponding class. Any standard
    machine learning algorithm can be used, such as SVM, random forests, logistic
    regression, and of course neural networks even though it is not the focus of this
    chapter.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: One of the main problems with this approach is the skewness of the data. By
    definition, anomalies only represent a small percentage of the population. The
    absence of enough counter-examples during the training phase would lead to poor
    results. Moreover, some anomalies may have never been seen previously and it would
    be very hard to build a model that generalizes enough to correctly classify them.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Unsupervised**: A purely unsupervised approach means having no ground truth
    (no golden reference) of what constitutes an anomaly or not. We know there might
    be anomalies in the data, but no historical information is available about them.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In these scenarios, the detection can also be seen as a clustering problem where
    the goal is not just grouping similar observations together, but also identifying
    all of the remaining isolated points. As such, it brings all of the issues and
    considerations of clustering problems. Data modeling and distance metrics should
    be carefully selected in order to be able to rank each point as close or far from
    one of the existing "normal behavior" clusters.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Typical algorithms are k-means or density-based clustering. The major difficulties
    with clustering are the high sensitivity to noise and the well-known curse of
    dimensionality.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Semi-supervised**: Also known as novelty detection, semi-supervised learning
    might be a new term for you. It can be seen as both unsupervised learning (data
    is not labeled) and one-class supervised learning (all under the same label).
    The semi-supervision comes from the assumption that the training dataset belongs
    entirely to a single label: "the expected behavior". Instead of learning the rules
    for predicting whether it is "expected" or "anomalous", we learn the rules for
    predicting whether the observed point was generated from the same source that
    generated the training data or not. This is quite a strong assumption and it is
    what makes anomaly detection one of the hardest problems to solve in practice.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Popular techniques are SVM one-class classifier and statistical distribution
    models such as Multivariate Gaussian Distribution.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'More information on Multivariate Gaussian Distribution for anomaly detection
    can be found in this tutorial: [http://dnene.bitbucket.org/docs/mlclass-notes/lecture16.html](https://bitbucket.org/).
    The following figure shows the classic identification of outliers from the main
    distribution visualized in a two-dimensional space:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Detection modeling](img/00313.jpeg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Two-dimensional representation of normal distribution with one single outlier
    ([http://dnene.bitbucket.org/docs/mlclass-notes/lecture16.html)](https://bitbucket.org/)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Anomaly detection using deep auto-encoders
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The proposed approach using deep learning is semi-supervised and it is broadly
    explained in the following three steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Identify a set of data that represents the normal distribution. In this context,
    the word "normal" represents a set of points that we are confident to majorly
    represent non-anomalous entities and not to be confused with the Gaussian normal
    distribution.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The identification is generally historical, where we know that no anomalies
    were officially recognized. This is why this approach is not purely unsupervised.
    It relies on the assumption that the majority of observations are anomaly-free.
    We can use external information (even labels if available) to achieve a higher
    quality of the selected subset.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Learn what "normal" means from this training dataset. The trained model will
    provide a sort of metric in its mathematical definition; that is, a function mapping
    every point to a real number representing the distance from another point representing
    the normal distribution.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Detected based on a threshold, on the anomaly score. By selecting the right
    threshold we can achieve the desired trade-off between precision (fewer false
    alarms) and recall (fewer missed detections).
  prefs: []
  type: TYPE_NORMAL
- en: One of the pros of this approach is robustness to noise. We can accept a small
    portion of outliers in the normal data used for training since that model will
    try to generalize the main distribution of the population and not the single observations.
    This property gives us an enormous advantage in terms of generalization with respect
    to the supervised approach, which is limited to only what can be observed in the
    past.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, this approach can be extended to labeled data as well, making it suitable
    for every class of anomaly detection problems. Since the label information is
    not taken into account in the modeling, we can discard it from the feature space
    and consider everything to be under the same label. Labels can still be used as
    ground truth during the validation phase. We could then treat the anomaly score
    as a binary classification score and use the ROC curve, and related measures,
    as benchmarks.
  prefs: []
  type: TYPE_NORMAL
- en: 'For our use cases, we will make use of auto-encoder architecture to learn the
    distribution of the training data. As we have seen in [Chapter 4](part0027_split_000.html#PNV62-c1ed1b54ca0b4e9fbb9fe2b2431d634f
    "Chapter 4. Unsupervised Feature Learning"), *Unsupervised Feature* *Learning*,
    the network is designed to have arbitrary, but symmetric hidden layers with the
    same number of neurons in both the input layer and output layer. The whole topology
    has to be symmetric in the sense that the encoding topology on the left side is
    just mirrored to the decoding part to the right and they both share the same number
    of hidden units and activation functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Anomaly detection using deep auto-encoders](img/00314.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Auto-encoder simple representation from H2O training book (https://github.com/h2oai/h2o-training-book/blob/master/hands-on_training/images/autoencoder.png)
  prefs: []
  type: TYPE_NORMAL
- en: The loss function generally used is the **MSE** (**mean squared error**) between
    the input and the corresponding neurons in the output layer. This way, the network
    is forced to approximate an identity function via a non-linear and compressed
    representation of the original data.
  prefs: []
  type: TYPE_NORMAL
- en: Deep auto-encoders are also frequently used as a pre-training step for supervised
    learning models and for dimensionality reduction. In fact, the central layer of
    the auto-encoder could be used to represent the points in a reduced dimensionality,
    as we will see in the last example.
  prefs: []
  type: TYPE_NORMAL
- en: We can then start making analysis with the fully reconstructed representation
    that is the result of the encoding and decoding in cascade. An identity auto-encoder
    would reconstruct exactly the same values of the original point. That would not
    be very useful. In practice, auto-encoders reconstruct based on intermediate representations
    that minimize the training error. Thus, we learn those compression functions from
    the training set so that a normal point is very likely to be reconstructed correctly,
    but an outlier would have a higher **reconstruction error** (the mean squared
    error between the original point and the reconstructed one).
  prefs: []
  type: TYPE_NORMAL
- en: We can then use the reconstruction error as an anomaly score.
  prefs: []
  type: TYPE_NORMAL
- en: Alternatively, we can use a trick of setting the middle layer of the network
    small enough so that we can transform every point into a low-dimensional compressed
    representation. If we set it equal to two or three, we can even visualize the
    points. Hence, we can use auto-encoders for reducing the dimensionality followed
    by standard machine learning techniques for detection.
  prefs: []
  type: TYPE_NORMAL
- en: H2O
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we deep dive into the examples, let's spend some time justifying our
    decision of using H2O as our deep learning framework for anomaly detection.
  prefs: []
  type: TYPE_NORMAL
- en: H2O is not just a library or package to install. It is an open source, rich
    analytics platform that provides both machine learning algorithms and high-performance
    parallel computing abstractions.
  prefs: []
  type: TYPE_NORMAL
- en: H2O core technology is built around a Java Virtual Machine optimized for in-memory
    processing of distributed data collections.
  prefs: []
  type: TYPE_NORMAL
- en: The platform is usable via a web-based UI or programmatically in many languages,
    such as Python, R, Java, Scala, and JSON in a REST API.
  prefs: []
  type: TYPE_NORMAL
- en: Data can be loaded from many common data sources, such as HDFS, S3, most of
    the popular RDBMSes, and a few other NoSQL databases.
  prefs: []
  type: TYPE_NORMAL
- en: After loading, data is represented in an `H2OFrame`, making it familiar to people
    used to working with R, Spark, and Python pandas data frames.
  prefs: []
  type: TYPE_NORMAL
- en: The backend can then be switched among different engines. It can run locally
    in your machine or it can be deployed in a cluster on top of Spark or Hadoop MapReduce.
  prefs: []
  type: TYPE_NORMAL
- en: H2O will automatically handle the memory occupation and will optimize the execution
    plan for most of the data operations and model learning.
  prefs: []
  type: TYPE_NORMAL
- en: It provides a very fast scoring of data points against a trained model; it is
    advertised to run in nanoseconds.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to traditional data analysis and machine learning algorithms, it
    features a few very robust implementations of deep learning models.
  prefs: []
  type: TYPE_NORMAL
- en: The general API for building models is via the `H2OEstimator`. A dedicated `H2ODeepLearningEstimator`
    class can be used to build feed-forward multilayer artificial networks.
  prefs: []
  type: TYPE_NORMAL
- en: One of the main reasons why we choose H2O for anomaly detection is that it provides
    a built-in class very useful for our cause, the `H2OAutoEncoderEstimator`.
  prefs: []
  type: TYPE_NORMAL
- en: As you will see in the following examples, building an auto-encoder network
    only requires a few parameters to be specified and then it will self-tune the
    rest.
  prefs: []
  type: TYPE_NORMAL
- en: The output of an estimator is a model, which depending on the problem to be
    solved, can be a classification model, regression, clustering, or in our case
    an auto-encoder.
  prefs: []
  type: TYPE_NORMAL
- en: Deep learning with H2O is not exhaustive, but it is quite simple and straightforward.
    It features automatic adaptive weight initialization, adaptive learning rates,
    various regularization techniques, performance tuning, grid-search, and cross-fold
    validation just to name a few. We will explore those advanced features in [Chapter
    10](part0074_split_000.html#26I9K1-c1ed1b54ca0b4e9fbb9fe2b2431d634f "Chapter 10. Building
    a Production-Ready Intrusion Detection System"), *Building a Production-Ready
    Intrusion Detection System*.
  prefs: []
  type: TYPE_NORMAL
- en: We also hope to see RNNs and more advanced deep learning architecture soon implemented
    in the framework.
  prefs: []
  type: TYPE_NORMAL
- en: The key points of H2O are scalability, reliability, and ease of use. It is a
    good fit for enterprise environments that care about production aspects. The simplicity
    and built-in functionalities make it also well suited for research tasks and curious
    users who want to learn and experiment with deep learning.
  prefs: []
  type: TYPE_NORMAL
- en: Getting started with H2O
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: H2O in local mode can be simply installed as dependency using `pip`. Follow
    the instructions at [http://www.h2o.ai/download/h2o/python](http://www.h2o.ai/download/h2o/python).
  prefs: []
  type: TYPE_NORMAL
- en: A local instance will be automatically spun at your first initialization.
  prefs: []
  type: TYPE_NORMAL
- en: 'Open a Jupyter notebook and create an `h2o` instance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: To check whether the initialization was successful, it should print something
    like `"Checking whether` there is an H2O instance running at `http://localhost:54321`.
    `connected."`.
  prefs: []
  type: TYPE_NORMAL
- en: You are now ready to import data and start building deep learning networks.
  prefs: []
  type: TYPE_NORMAL
- en: Examples
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The following examples are proof-of-concepts of how to apply auto-encoders to
    identify anomalies. Specific tuning and advanced design considerations are out
    of the scope for this chapter. We will take for granted some results from the
    literature without going into too much theoretical ground, which has already been
    covered in previous chapters.
  prefs: []
  type: TYPE_NORMAL
- en: We recommend the reader to carefully read [Chapter 4](part0027_split_000.html#PNV62-c1ed1b54ca0b4e9fbb9fe2b2431d634f
    "Chapter 4. Unsupervised Feature Learning"), *Unsupervised* *Feature Learning*
    and the corresponding sections regarding auto-encoders.
  prefs: []
  type: TYPE_NORMAL
- en: We will use a Jupyter notebook for our examples.
  prefs: []
  type: TYPE_NORMAL
- en: Alternatively, we could have used H2O Flow (`http://www.h2o.ai/product/flow/`),
    which is a notebook-style UI for H2O pretty much like Jupyter, but we did not
    want to confuse the reader throughout the book.
  prefs: []
  type: TYPE_NORMAL
- en: We also assume that the reader has a basic idea of how the H2O framework, pandas,
    and related plotting libraries (`matplotlib` and `seaborn`) work.
  prefs: []
  type: TYPE_NORMAL
- en: In the code, we often convert an `H2OFrame` instance into a `pandas.DataFrame`
    so that we can use the standard plotting libraries. This is doable because our
    `H2OFrame` contains small data; it is not recommended when the data is large.
  prefs: []
  type: TYPE_NORMAL
- en: MNIST digit anomaly recognition
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This is a pretty standard example used for benchmarking anomaly detection models.
  prefs: []
  type: TYPE_NORMAL
- en: We have already seen this dataset in [Chapter 3](part0022_split_000.html#KVCC2-c1ed1b54ca0b4e9fbb9fe2b2431d634f
    "Chapter 3. Deep Learning Fundamentals"), *Deep Learning Fundamentals*. In this
    case though, we are not predicting which number each image represents, but whether
    the image represents a clear or an ugly handwritten digit. The goal is identifying
    badly written digit images.
  prefs: []
  type: TYPE_NORMAL
- en: In fact, in our example, we will discard the response column containing the
    label (the digit). We are not interested in which number each image represents,
    but rather how clearly this number is represented.
  prefs: []
  type: TYPE_NORMAL
- en: We are going to follow the same configurations provided in the H2O tutorial
    at `github.com/h2oai/h2o-training-book/blob/master/hands-on_training/anomaly_detection.md`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will start with some standard imports of `pandas` and `matplotlib`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we are importing the data from the H2O repository (this is a readapted
    version of the original dataset in order to make it easier to parse and load into
    H2O):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The loaded train and test datasets represent one digit image for each row and
    contain 784 columns representing grayscale values in a scale from 0 to 255 of
    each pixel of a 28 x 28 image grid plus the last column used as label (the digit
    number).
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use only the first 784 as predictors and leave the label only for validation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The H2O tutorial suggests a shallow model made of just one hidden layer of 20
    neurons using a hyperbolic tangent as an activation function and 100 epochs (100
    scans over the data).
  prefs: []
  type: TYPE_NORMAL
- en: 'The goal is not to learn how to tune the network, but rather understand the
    intuitions and concepts behind the anomaly detection approach. What we need to
    understand is that the encoder capacity depends on the number of hidden neurons.
    A too large capacity would lead to an identity function model, which would not
    learn any interesting structures. In our case, we are setting a low capacity,
    from 784 pixels to 20 nodes. This way, we will force the model to learn how to
    best approximate an identity function by only using a few features representing
    the relevant structures of the data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'After we have trained the auto-encoder model, we can predict the digits in
    the test set, reconstructed using our new reduced dimensionality representation,
    and rank them according to the reconstruction error:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s quickly describe the reconstruction error:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: We will see that it ranges between 0.01 and 1.62 with a mean of around 0.02,
    not a symmetric distribution.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s make a scatter plot of the reconstruction error for all of the test
    points:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '![MNIST digit anomaly recognition](img/00315.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: We can see that the test set contains only one obvious outlier, while the rest
    of the points fall in the range [0.0, 0.07].
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s join the test feature set, including the label, with the reconstruction
    error and grab the outlier point and try to reconstruct it using the auto-encoder
    model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'We need to define a helper function to plot a single digit image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'And plot both the original outlier and its reconstructed version:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '![MNIST digit anomaly recognition](img/00316.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The reconstructed version is very noisy even though the outlier seems to clearly
    be representing the number three. We will see that it has one particular detail
    that makes it different from the rest of the other three digits.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s zoom into the error distribution of the remaining points:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '![MNIST digit anomaly recognition](img/00317.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: From the distribution, we can split the "central bell" at 0.02 into the "good"
    digits (on the left) and the "bad" (on the right). The rightmost tail (greater
    than 0.05) could be considered the "ugly" digits or the most anomalous.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will now pick some digits of the number three from the "good" subset and
    compare them with our outlier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'In order to visualize multiple digits, we need to extend the plot util into
    a function that plots a grid of images:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now plot both the original and reconstructed values of 36 random digits
    arranged on a `6 (nx)` times `6 (ny)` grid:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '![MNIST digit anomaly recognition](img/00318.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Original good digits of number three
  prefs: []
  type: TYPE_NORMAL
- en: '![MNIST digit anomaly recognition](img/00319.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Reconstructed version of the good digits of number three
  prefs: []
  type: TYPE_NORMAL
- en: At first glance, our outlier does not look very different with the good-classified
    ones. Many of the reconstructed figures look similar to their original representation.
  prefs: []
  type: TYPE_NORMAL
- en: If we look more carefully at the figures, we can observe that none of them have
    the bottom-left shape of the digit so long to almost touch the corner.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s pick the digit with index 1, which scores 0.02, and let''s copy the
    bottom-left part (the last 16 x 10 pixels) from the outlier figure. We will recompute
    the anomaly score to the modified image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '![MNIST digit anomaly recognition](img/00320.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Magically, the MSE went up to 0.86\. The remaining contribution to the high
    anomaly score (~1.62) is probably explained by the abnormal handwriting style.
  prefs: []
  type: TYPE_NORMAL
- en: This explanation means that the model is too sensitive to noise. It marks a
    digit image as anomalous due to a licit property simply because the training data
    does not contain enough samples. This is an "outlier" of the outlier detector,
    an example of a false positive.
  prefs: []
  type: TYPE_NORMAL
- en: This problem can generally be solved using denoising auto-encoders. In order
    to discover more robust representations, we can train the model to reconstruct
    the original input from a noisy version of it. We can look at [Chapter 4](part0027_split_000.html#PNV62-c1ed1b54ca0b4e9fbb9fe2b2431d634f
    "Chapter 4. Unsupervised Feature Learning"), *Unsupervised Feature Learning*,
    for more theoretical explanations.
  prefs: []
  type: TYPE_NORMAL
- en: In our use case, we could mask each digit with a binomial sampling where we
    randomly set pixels to 0 with probability *p*. The loss function will then be
    the error of the reconstructed image from the noisy version and the original one.
    At the time of writing, H2O did not offer this feature, nor a customization of
    the loss function. Hence, implementing it on our own would have been too complicated
    for this example.
  prefs: []
  type: TYPE_NORMAL
- en: Our dataset contains labels for the digits, but unfortunately it does not have
    any assessment about the quality of them. We will have to do a manual inspection
    to gain confidence that our model works fine.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will grab the bottom 100 (good) and top 100 (ugly) points and visualize
    them in a 10 x 10 grid:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '![MNIST digit anomaly recognition](img/00321.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Reconstruction error of the top good digits
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '![MNIST digit anomaly recognition](img/00322.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Reconstruction error of the worst ugly digits
  prefs: []
  type: TYPE_NORMAL
- en: From the figures, it is easy to see that "the good" represent number one, which
    is the easiest digit to write due to its simple structure of a straight line.
    Thus, digits of number one are less prone to be miswritten.
  prefs: []
  type: TYPE_NORMAL
- en: The bottom group is clearly ugly. The round shapes make it harder to distinguish
    between similar numbers and it strongly depends on the specific person's handwriting.
    Thus, those are most likely to represent "anomalies". They are most likely to
    deviate from the majority of the population's writing style.
  prefs: []
  type: TYPE_NORMAL
- en: Please be careful that different runs may lead to different results due to randomness
    introduced for scalability reasons due to race conditions generated by the Hogwild!
    algorithm explained in the following chapter. In order to make results reproducible,
    you should specify a `seed` and set `reproducibility=True`.
  prefs: []
  type: TYPE_NORMAL
- en: Electrocardiogram pulse detection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this second example, we will take a snapshot of data of an electrocardiogram
    time series specifically prepared from H2O for the anomaly detection use case.
  prefs: []
  type: TYPE_NORMAL
- en: The prepared data is available from the H2O public repository. The original
    dataset is provided by [http://www.physionet.org/](http://www.physionet.org/).
    Additional references are available at [http://www.cs.ucr.edu/~eamonn/discords/](http://www.cs.ucr.edu/~eamonn/discords/).
  prefs: []
  type: TYPE_NORMAL
- en: The prepared dataset contains 20 ECG time series of good heartbeats plus three
    anomalous heartbeats.
  prefs: []
  type: TYPE_NORMAL
- en: Each row has 210 columns representing value samples in an ordered sequence.
  prefs: []
  type: TYPE_NORMAL
- en: 'Firstly, we load the ECG data and derive the training and test sets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s define a function that stacks and plots the time series:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'And then plot the dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '![Electrocardiogram pulse detection](img/00323.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: We can clearly see that the first 20 time series are normal while the last three
    (identified as 21, 22, and 23) are quite different from the others.
  prefs: []
  type: TYPE_NORMAL
- en: Hence, we want to train the model only on the first 20 samples. This time, we
    will use a deeper architecture made of five hidden layers of respectively 50,
    20, and 20, 50 at the edges and two neurons in the middle. Remember that auto-encoders'
    topology is always symmetric and generally with decreasing layer size. The idea
    is to learn how to encode original data into a lower-dimensional space with minimum
    information loss and then be able to reconstruct the original values from this
    compressed representation.
  prefs: []
  type: TYPE_NORMAL
- en: 'This time, we will fix the value of the seed for reproducibility:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'We can plot the reconstructed signals as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '![Electrocardiogram pulse detection](img/00324.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The reconstructed signals all look very similar. The outliers (20, 21, and 23)
    are now indistinguishable, which means they will have a higher reconstruction
    error.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s compute and plot the reconstruction error:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '![Electrocardiogram pulse detection](img/00325.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: It is very easy to identify the last three points as outliers.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let''s try to see the problem from a different perspective. By setting
    the central layer size equal to two, we can then use the encoder output to compress
    and visualize our points in a two-dimensional plot. We will use the `deepfeatures`
    API of the trained model to plot a new data frame with the 2D representation specifying
    the hidden layer index (starting from 0, the middle one is at index 2):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we visualize all of the points with the previously trained model with
    seed 1:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'If we repeat the same procedure by retraining the model with the seed set to
    2, 3, 4, 5, and 6, we obtain the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Electrocardiogram pulse detection](img/00326.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, each seed gives a totally different two-dimensional representation.
    What is more interesting is that the outlier points (marked with 20, 21, and 22)
    always have the same reconstruction error (given by their color). For the model,
    those are all valid two-dimensional compressed representations that contain the
    same amount of information and can be decoded into the original time series.
  prefs: []
  type: TYPE_NORMAL
- en: We could then use the auto-encoder for reducing the dimensionality followed
    by an unsupervised approach (for example, density-based clustering) to group similar
    points together. By repeating the clustering for each seed, we can then apply
    a Consensus Clustering to determine which are the points that mostly agree with
    each other (points that are always clustered together). This approach won't necessary
    tell you where the anomalies are, but it will help you understand your data and
    spot clusters of small dimensions that can be further investigated. The smaller
    and more isolated from the other clusters, the higher the anomaly scores.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Anomaly detection is a very common problem that can be found in many applications.
  prefs: []
  type: TYPE_NORMAL
- en: At the start of this chapter, we described a few possible use cases and highlighted
    the major types and differences according to the context and application requirements.
  prefs: []
  type: TYPE_NORMAL
- en: We briefly covered some of the popular techniques for solving anomaly detection
    using shallow machine learning algorithms. The major differences can be found
    in the way features are generated. In shallow machine learning, this is generally
    a manual task, also called feature engineering. The advantage of using deep learning
    is that it can automatically learn smart data representations in an unsupervised
    fashion. Good data representations can substantially help the detection model
    to spot anomalies.
  prefs: []
  type: TYPE_NORMAL
- en: We have provided an overview of H2O and summarized its functionalities for deep
    learning, in particular the auto-encoders.
  prefs: []
  type: TYPE_NORMAL
- en: We have implemented a couple of proof-of-concept examples in order to learn
    how to apply auto-encoders for solving anomaly detection problems.
  prefs: []
  type: TYPE_NORMAL
- en: For the digit recognition, we ranked each image according to an anomaly score
    given by the model reconstruction error.
  prefs: []
  type: TYPE_NORMAL
- en: A similar approach could also be further extended to applications such as signature
    verification, author handwriting recognition of manuscripts, or fault detection
    via image pictures.
  prefs: []
  type: TYPE_NORMAL
- en: The digit recognition example was a type of individual point outlier detection.
    It used a shallow architecture made of only one single hidden layer.
  prefs: []
  type: TYPE_NORMAL
- en: For the ECG example, we used a deeper architecture and showed an additional
    detection technique based on the compressed feature representation instead of
    the fully reconstructed one. We used the encoder part of the network to compress
    the non-linear relationships of the raw data into a smaller dimensionality space.
    The newer representation can then be used as a pre-process step in order to apply
    classic anomaly detection algorithms such as Gaussian Multivariate Distribution.
    By reducing to a two-dimensional space, we could even visualize the data points
    and identify anomalies at the frontier of the main elliptical distribution.
  prefs: []
  type: TYPE_NORMAL
- en: Nevertheless, auto-encoders are not the only way of doing anomaly detection
    using deep learning. You can also follow a supervised approach where you take
    out part of the information from your data and try to estimate based on the remaining
    information. The predicted value will represent your normal expected behavior
    and deviations from this value would represent your anomalies. For example, in
    case of time series, you could use recurrent neural networks (RNNs), or their
    evolution in long short-term memory (LSTM), as a regression model to predict what
    is going to be the next numerical value of a time sequence and then use the error
    between the predicted and observed value as an anomaly score.
  prefs: []
  type: TYPE_NORMAL
- en: We preferred to focus on this semi-supervised approach because it can be applied
    to many applications and also because it is nicely implemented in H2O.
  prefs: []
  type: TYPE_NORMAL
- en: Another important detail is that the majority of the code snippets were written
    for data analysis, manipulation, and visualization. By using H2O, we used the
    built-in classes to implement deep neural networks in just a couple of lines of
    code. This is quite impressive compared to the overhead of other frameworks. Moreover,
    the H2O estimators and models offer a wide range of customizable parameters and
    different configurations. On the other hand, we found H2O to be quite limited
    in extending its usage for scopes that are not currently supported. Overall, it
    is a very promising technology and there is much room for further improvement.
  prefs: []
  type: TYPE_NORMAL
- en: Be aware that the techniques covered in this chapter served only as proof-of-concept
    for how deep learning could be applied to anomaly detection. There are many gotchas
    and pitfalls to consider, both technical and practical, when dealing with production
    data. We will cover a few of them in [Chapter 10](part0074_split_000.html#26I9K1-c1ed1b54ca0b4e9fbb9fe2b2431d634f
    "Chapter 10. Building a Production-Ready Intrusion Detection System"), *Building
    a Production-Ready Intrusion Detection System*.
  prefs: []
  type: TYPE_NORMAL
