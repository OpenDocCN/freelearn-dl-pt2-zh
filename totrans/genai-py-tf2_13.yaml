- en: '13'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Emerging Applications in Generative AI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the preceding chapters, we have examined a large number of applications
    using generative AI, from generating pictures and text to even music. However,
    this is a large and ever-expanding field; the number of publications on Google
    Scholar matching a search for "generative adversarial networks" is 27,200, of
    which 16,200 were published in 2020! This is astonishing for a field that essentially
    started in 2014, the exponential growth of which can also be appreciated on the
    Google n-gram viewer (*Figure 13.1*):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16176_13_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13.1: Google n-gram of "generative adversarial networks"'
  prefs: []
  type: TYPE_NORMAL
- en: 'As we saw in this volume, generative adversarial networks are only one class
    of models in the broader field of generative AI, which also includes models such
    as variational autoencoders, BERT, and GPT-3\. As a single book cannot hope to
    cover all of these areas, we conclude this volume with discussion of a number
    of emerging topics in this field: drug discovery and protein folding, solving
    mathematical equations, generating video from images, and generating recipes.
    Interested readers are encouraged to consult the referenced literature for more
    detailed discussion of each topic.'
  prefs: []
  type: TYPE_NORMAL
- en: Finding new drugs with generative models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'One field that we have not covered in this volume in which generative AI is
    making a large impact is biotechnology research. We discuss two areas: drug discovery
    and predicting the structure of proteins.'
  prefs: []
  type: TYPE_NORMAL
- en: Searching chemical space with generative molecular graph networks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: At its base, a medicine – be it drugstore aspirin or an antibiotic prescribed
    by a doctor – is a *chemical graph* consisting of nodes (atoms) and edges (bonds)
    (*Figure 13.2*). Like the generative models used for textual data (*Chapters 3*,
    *9*, and *10*), graphs have the special property of not being fixed length. There
    are many ways to encode a graph, including a binary representation based on numeric
    codes for the individual fragments (*Figure 13.2*) and "SMILES" strings that are
    linearized representations of 3D molecules (*Figure 13.3*). You can probably appreciate
    that the number of potential features in a chemical graph is quite large; in fact,
    the number of potential chemical structures that are in the same size and property
    range as known drugs has been estimated¹ at 10^(60) – larger even than the number
    of papers on generative models; for reference, the number of molecules in the
    observable universe² is around 10^(78).
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16176_13_02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13.2: The chemical graph³'
  prefs: []
  type: TYPE_NORMAL
- en: One can appreciate, then, that a large challenge of drug discovery – finding
    new drugs for existing and emerging diseases – is the sheer size of the potential
    space one might need to search. While experimental approaches for "drug screening"
    – testing thousands, millions, or even billions of compounds in high-throughput
    experiments to find a chemical needle in a haystack with potential therapeutic
    properties – have been used for decades, the development of computational methods
    such as machine learning has opened the door for "virtual screening" on a far
    larger scale. Using modern computational approaches, scientists can test huge
    libraries of completely virtual compounds for their ability to interact with proteins
    of interest for disease research. How can a large library of such virtual molecules
    be generated?
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16176_13_03.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13.3: A generative model for small molecule generation⁶'
  prefs: []
  type: TYPE_NORMAL
- en: Returning to our encoding of the chemical graph, it's probably not surprising
    that we can use a generative model based on recursive neural networks, such as
    LSTMs, to sample from the huge space of possible molecular graph configurations.
    Because molecules follow particular structural motifs, this problem is more complex
    than simply independently sampling sets of atoms, as they must form a coherent
    molecule following chemical structural constraints. *Figure 13.3* illustrates
    what this process might look like; taking a 2D structure, encoding it into binary
    feature vectors (not unlike how we've seen text represented in earlier chapters),
    then running these vectors through a recursive neural network to train a model
    that predicts the next atom or bond based on the prior atoms/bonds in the sequence.
    Once the model is trained on input data, it can be utilized to generate new molecules
    by sampling new structures, one at a time, from this generator. Variational autoencoders
    (*Chapter 5*, *Painting Pictures with Neural Networks using VAEs*) have also been
    used to generate molecules⁴ (*Figure 13.4*), as have generative adversarial networks⁵
    (*Figure 13.5*), which we introduced in *Chapter 6*, *Image Generation with GANs*.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16176_13_04.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13.4: Variational autoencoders for small molecules⁶'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16176_13_05.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13.5: Generative adversarial models for small molecules⁶'
  prefs: []
  type: TYPE_NORMAL
- en: Folding proteins with generative models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Once we have the set of virtual molecules from such a model, the next challenge
    is to figure out which, if any, of them have the potential to be drugs. Scientists
    test this through "virtual docking," in which a large library of simulated molecules
    are tested to see if they fit in the pockets of protein structures also represented
    in a computer.
  prefs: []
  type: TYPE_NORMAL
- en: Molecular dynamics simulations are used to approximate the energetic attraction/repulsion
    between a potential drug and a protein that might affect a disease in the body
    based on the relative chemical structures of the protein and chemical. A challenge
    is that these protein structures against which drugs are "docked" in these simulations
    are typically derived from X-ray crystallography experiments, a painstaking process
    of diffracting X-rays through a protein structure to obtain a representation of
    its 3D form.
  prefs: []
  type: TYPE_NORMAL
- en: Further, this process is only applicable to a subset of proteins that are stable
    in liquid suspension, which excludes a huge number of molecules relevant to disease
    that are expressed on the surface of the cell, where they are surrounded and stabilized
    by the fat particles in the cell membrane.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, too, generative AI can help: the researchers at DeepMind (a research
    subsidiary of Google that was also responsible for AlphaGo and other breakthroughs)
    recently released a program called **AlphaFold** that can solve the 3D structure
    of proteins directly from their genetic sequence, allowing researchers to bypass
    the painstaking process of experimental crystallography. *Figure 13.6* illustrates
    how this is done: first a network is trained to predict the 3D inter-amino acid
    (the building block of proteins) distances within a protein from its linear sequence
    code, representing the most likely angles and distances between parts in the folded
    structure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16176_13_07.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13.6: Training a neural network to predict the distance between amino
    acids in a protein sequence⁷'
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, for proteins without a structure, AlphaFold proposes new protein fragments
    using a generative model (*Figure 13.7*), and scores which ones have a high likelihood
    of forming a stable 3D structure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16176_13_08.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13.7: Generative model to predict protein conformation⁷'
  prefs: []
  type: TYPE_NORMAL
- en: These examples show how it is possible to simulate both drugs and the structure
    of their potential targets in the human body using generative AI, taking what
    are difficult or impossible experiments in the real world and harnessing the massive
    computational capacity of new models to potentially discover new medicines.
  prefs: []
  type: TYPE_NORMAL
- en: Solving partial differential equations with generative modeling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Another field in which deep learning in general, and generative learning in
    particular, have led to recent breakthroughs is the solution of **partial differential
    equations** (**PDEs**), a kind of mathematical model used for diverse applications
    including fluid dynamics, weather prediction, and understanding the behavior of
    physical systems. More formally, a PDE imposes some condition on the partial derivatives
    of a function, and the problem is to find a function that fulfills this condition.
    Usually some set of initial or boundary conditions is placed on the function to
    limit the search space within a particular grid. As an example, consider Burger''s
    equation,⁸ which governs phenomena such as the speed of a fluid at a given position
    and time (*Figure 13.8*):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16176_13_001.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Where *u* is speed, *t* is time, *x* is a positional coordinate, and ![](img/B16176_13_006.png)
    is the viscosity ("oiliness") of the fluid. If the viscosity is 0, this simplifies
    to the *inviscid* equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16176_13_002.png)'
  prefs: []
  type: TYPE_IMG
- en: The solution of this equation depends upon the form of the function *u* and
    its initial condition at *t=0*; for example, if *u* is a linear function, it has
    a closed-form analytical solution (in other words, the solution can be derived
    using only the manipulation of mathematical formulae and variable substitutions,
    rather than requiring numerical methods to minimize an error function for potential
    solutions selection using an algorithm)⁹. In most cases, however, one needs numerical
    methods, and one popular approach is using **finite element methods** (**FEMs**)
    to divide the output (*x*, *t*) into a "grid" and solve for *u* numerically within
    each of those grids. This is analogous to the use of a "basis" set of functions
    such as cosines and sines (Fourier analysis) or wavelets to decompose complex
    functions into a sum of simpler underlying functions.^(10)
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16176_13_09.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13.8: A visualization of Burger''s equation in two dimensions^(11)'
  prefs: []
  type: TYPE_NORMAL
- en: 'However, consider the problem we now have: for a given set of conditions (the
    boundary conditions), we want to output a function value across a grid, creating
    a heatmap of the function value at each point in space and time, not unlike an
    image we''ve seen in prior generative applications! Indeed, convolutional generative
    models have been used to map boundary conditions to an output grid (*Figure 13.9*)^(12):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16176_13_10.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13.9: Solution of Burger''s inviscid equation using FEM methods (right),
    and deep learning (left)^(12)'
  prefs: []
  type: TYPE_NORMAL
- en: As described earlier, the typical strategy of using FEM is to solve numerically
    for *u* at each element in a grid, where most of the computational burden is from
    repetitively computing the solution rather than checking it^(12); thus generative
    AI can operate more efficiently by sampling a large set of possible solutions
    (with that set constrained by initial conditions or the numerical range of each
    variable) and checking if they fulfill the conditions of the PDE, completely circumventing
    the need for solving for the function in each element of the grid. *Figure 13.10*
    shows how a set of boundary conditions (*b*) and viscosity variables (*v*) can
    be input into a convolutional network that then generates the solution of the
    PDE.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16176_13_11.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13.10: DiffNet used to sample potential solutions for Burger''s Equation^(12)'
  prefs: []
  type: TYPE_NORMAL
- en: The network in this example is termed **DiffNet**. It has two terms in its error
    function; one (*L*[p], equation 4) encourages the generated grids to match the
    PDE surface (low error), while the other forces the solution to reproduce the
    desired boundary conditions on *x* and *t* (*L*[b], equation 5).
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16176_13_003.png)![](img/B16176_13_004.png)![](img/B16176_13_005.png)'
  prefs: []
  type: TYPE_IMG
- en: Together, these two constraints resemble the other adversarial generative examples
    we've seen in past chapters; one term tries to minimize error (like the discriminator)
    while another tries to approximate a distribution (here, the boundary conditions
    on the variables).
  prefs: []
  type: TYPE_NORMAL
- en: Few shot learning for creating videos from images
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In prior chapters, we have seen how GANs can generate novel photorealistic images
    after being trained on a group of example photos. This technique can also be used
    to create variations of an image, either applying "filters" or new poses or angles
    of the base image. Extending this approach to its logical limit, could we create
    a "talking head" out of a single or a limited set of images? This problem is quite
    challenging – classical (or deep learning) approaches that apply "warping" transformations
    to a set of images create noticeable artifacts that degrade the realism of the
    output ^(13,14). An alternative approach is to use generative models to sample
    potential angular and positional variations of the input images (*Figure 13.11*),
    as performed by Zakharov et al. in their paper *Few Shot Adversarial Learning
    of Realistic Neural Talking Head Models*.^(15)
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16176_13_12.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13.11: Generative architecture for creating moving frames from single
    images (based on Zakharov et al., Figure 2.)'
  prefs: []
  type: TYPE_NORMAL
- en: This architecture has three networks that process a set of input videos. The
    first generates embeddings of landmark features (a simplified representation of
    the face, such as its outline and the location of important features like the
    eyes and nose), along with the pixels of the original image, into a numerical
    vector. The second generates novel video frames with this embedding as an input
    along with the image and landmark data. Finally, the next frame in the video is
    compared with this generated image via a discriminator.
  prefs: []
  type: TYPE_NORMAL
- en: This is referred to as *few shot* learning because it uses only a small number
    of video frames to learn to generate new video sequences, which could be unbounded
    in length. This model can then be applied to input data with only a single example,
    such as still photos, generating "talking heads" from historical photos, or even
    paintings such as the Mona Lisa.^(16) Readers may refer to the cited paper for
    sample output.
  prefs: []
  type: TYPE_NORMAL
- en: 'These "living portraits" are in some way the evolution of deepfakes – rather
    than copying one image of a moving face to another, lifelike motions are simulated
    from a picture that had no prior motion data associated with it. Like the portrait
    auction we discussed in *Chapter 1*, *An Introduction to Generative AI: "Drawing"
    Data from Models*, this is an example in which generative AI is truly bringing
    new art to life.'
  prefs: []
  type: TYPE_NORMAL
- en: Generating recipes with deep learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A final example we will discuss is related to earlier examples in this book,
    on generating textual descriptions of images using GANs. A more complex version
    of this same problem is to generate a structured description of an image that
    has multiple components, such as the recipe for a food depicted in an image. This
    description is also more complex because it relies on a *particular sequence*
    of these components (instructions) in order to be coherent (*Figure 13.12*):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16176_13_13.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13.12: A recipe generated from an image of food^(17)'
  prefs: []
  type: TYPE_NORMAL
- en: As *Figure 13.13* demonstrates, this "inverse cooking" problem has also been
    studied using generative models^(17) (Salvador et al.).
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16176_13_14.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13.13: Architecture of a generative model for inverse cooking^(17)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Like many of the examples we''ve seen in prior chapters, an "encoder" network
    receives an image as input, and then "decodes" using a sequence model into text
    representations of the food components, which are combined with the image embedding
    to create a set of instructions decoded by a third layer of the network. This
    "instruction decoder" uses the transformer architecture described in *Chapter
    10*, *NLP 2.0: Using Transformers to Generate Text*, in our discussion of BERT,
    to apply weighted relevance to different portions of the image and output ingredient
    list.'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we examined a number of emerging applications of generative
    models. One is in the field of biotechnology, where they can be used to create
    large collections of new potential drug structures. Also in the biotechnology
    field, generative models are used to create potential protein folding structures
    that can be used for computational drug discovery.
  prefs: []
  type: TYPE_NORMAL
- en: We explored how generative models can be used to solve mathematical problems,
    in particular PDEs, by mapping a set of boundary conditions of a fluid dynamics
    equation to a solution grid. We also examined a challenging problem of generating
    videos from a limited set of input images, and finally generating complex textual
    descriptions (components and sequences of instructions) from images of food to
    create recipes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Well done for reaching the end of the book. As a final summary, let''s recap
    everything we''ve learned:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Chapter 1*, *An Introduction to Generative AI: "Drawing" Data from Models*:
    What generative models are'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Chapter 2*, *Setting Up a TensorFlow Lab*: How to set up a TensorFlow 2 environment
    in the cloud'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Chapter 3*, *Building Blocks of Deep Neural Networks*: The building blocks
    of neural network models used in generative AI'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Chapter 4*, *Teaching Networks to Generate Digits*: How restricted Boltzmann
    machines (some of the earliest generative models) can generate hand-drawn digits'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Chapter 5*, *Painting Pictures with Neural Networks Using VAEs*: How variational
    autoencoders can generate images from random data'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Chapter 6*, *Image Generation with GANs*: The building blocks of GANs and
    how they are used to generate high resolution images from random noise'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Chapter 7*, *Style Transfer with GANs*: How GANs (CycleGAN and pix2pix) can
    be leveraged to transfer style from one domain to another'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Chapter 8*, *Deepfakes with GANs*: Basic building blocks for deepfakes to
    generate fake photos and videos'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Chapter 9*, *The Rise of Methods for Text Generation*: The basics of language
    generation using deep learning models'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Chapter 10*, *NLP 2.0: Using Transformers to Generate Text*: How transformers
    and different state-of-the-art architectures (like GPT-x) have revolutionized
    the language generation and NLP domain in general'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Chapter 11*, *Composing Music with Generative Models*: How generative models
    can be leveraged to generate music from random data'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Chapter 12*, *Play Video Games with Generative AI: GAIL*: How generative models
    can be used to train "agents" that can navigate virtual environments through reinforcement
    learning'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Chapter 13*, *Emerging Applications in Generative AI*: Some exciting emerging
    applications of generative AI'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We hope this book has demonstrated the varied traditional and cutting-edge use
    cases to which generative modeling is being applied and that you are curious enough
    to learn more by reading the referenced background, or even trying to implement
    some of the models yourself!
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kirkpatrick, P., & Ellis, C. (2004). *Chemical space*. *Nature* 432, 823\. [https://www.nature.com/articles/432823a](https://www.nature.com/articles/432823a)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Villanueva, J.C. (2009, July 30). *How Many Atoms Are There in the Universe?*
    Universe Today. [https://www.universetoday.com/36302/atoms-in-the-universe/#:~:text=At%20this%20level%2C%20it%20is,hundred%20thousand%20quadrillion%20vigintillion%20atoms](https://www.universetoday.com/36302/atoms-in-the-universe/#:~:text=At%20this%20level%2C%20it%20is,hu)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Based on a figure from Akutsu, T., & Nagamochi, H. (2013). *Comparison and enumeration
    of chemical graphs*. Computational and Structural Biotechnology Journal, Vol.
    5 Issue 6
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Gómez-Bombarelli R., Wei, J. N., Duvenaud, D., Hernández-Lobato, J. M., Sánchez-Lengeling,
    B., Sheberla, D., Aguilera-Iparraguirre, J., Hirzel, T. D., Adams, R. P., Aspuru-Guzik,
    A. *Automatic chemical design using a data-driven continuous representation of
    molecules*. ACS central science 2018, 4, 268-276.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Blaschke, T., Olivecrona, M., Engkvist, O., Bajorath, J., Chen, H. *Application
    of generative autoencoder in de novo molecular design*. Molecular informatics
    2018, 37, 1700123.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Bian Y., & Xie, X-Q. (2020). *Generative chemistry: drug discovery with deep
    learning generative models*. arXiv. [https://arxiv.org/abs/2008.09000](https://arxiv.org/abs/2008.09000)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Senior, A., Jumper, J., Hassabis, D., & Kohli, P. (2020, January 15). *AlphaFold:
    Using AI for scientific discovery*. DeepMind blog. [https://deepmind.com/blog/article/AlphaFold-Using-AI-for-scientific-discovery](https://deepmind.com/blog/article/AlphaFold-Using-AI-for-scientific-discovery)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Cameron, M. Notes on Burgers's equation. [https://www.math.umd.edu/~mariakc/burgers.pdf](https://www.math.umd.edu/~mariakc/burgers.pdf)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Chandrasekhar, S. (1943). *On the decay of plane shock waves* (No. 423). Ballistic
    Research Laboratories.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: COMSOL Multiphysics Encyclopedia. (2016, March 15). *The Finite Element Method
    (FEM)*. [https://www.comsol.com/multiphysics/finite-element-method](https://www.comsol.com/multiphysics/finite-element-method)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Wikipedia. (2021, April 14). *Burgers' equation*. [https://en.wikipedia.org/wiki/Burgers%27_equation#%20Inviscid_Burgers'_%20equation](https://en.wikipedia.org/wiki/Burgers%27_equation#%20Inviscid_Burgers'_%20equation)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Botelho, S., Joshi, A., Khara, B., Sarkar, S., Hegde, C., Adavani, S., & Ganapathysubramanian,
    B. (2020). *Deep Generative Models that Solve PDEs: Distributed Computing for
    Training Large Data-Free Models*. arXiv. [https://arxiv.org/abs/2007.12792](https://arxiv.org/abs/2007.12792)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Averbuch-Elor, H., Cohen-Or, D., Kopf, J., & Cohen, M.F. (2017). *Bringing portraits
    to life*. ACM Transactions on Graphics (TOG), 36(6):196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Ganin, Y., Kononenko, D., Sungatullina, D., & Lempitsky, V. (2016). *DeepWarp:
    Photorealistic Image Resynthesis for Gaze Manipulation*. European Conference on
    Computer Vision, 311-326\. Springer.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Zakharov, E., Shysheya, A., Burkov, E., & Lempitsky, V. (2019). *Few-Shot Adversarial
    Learning of Realistic Neural Talking Head Models*. arXiv. [https://arxiv.org/abs/1905.08233](https://arxiv.org/abs/1905.08233)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Hodge, M. (2019, May 24). *REALLY SAYING SOMETHING Samsung’s ‘deepfake’ video
    of a TALKING Mona Lisa painting reveals the terrifying new frontier in fake news*.
    The Sun. [https://www.thesun.co.uk/news/9143575/deepfake-talking-mona-lisa-samsung/](https://www.thesun.co.uk/news/9143575/deepfake-talking-mona-lisa-samsung/)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Salvador, A., Drozdzal, M., Giro-i-Nieto, X., & Romero, A. (2019). *Inverse
    Cooking: Recipe Generation from Food Images*. arXiv. [https://arxiv.org/abs/1812.06164](https://arxiv.org/abs/1812.06164)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '| **Share your experience**Thank you for taking the time to read this book.
    If you enjoyed this book, help others to find it. Leave a review at [https://www.amazon.com/dp/1800200889](https://www.amazon.com/dp/1800200889).
    |'
  prefs: []
  type: TYPE_TB
- en: '![](img/Image34250.png)'
  prefs: []
  type: TYPE_IMG
- en: '[packt.com](http://packt.com)'
  prefs: []
  type: TYPE_NORMAL
- en: Subscribe to our online digital library for full access to over 7,000 books
    and videos, as well as industry leading tools to help you plan your personal development
    and advance your career. For more information, please visit our website.
  prefs: []
  type: TYPE_NORMAL
- en: Why subscribe?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Spend less time learning and more time coding with practical eBooks and Videos
    from over 4,000 industry professionals
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learn better with Skill Plans built especially for you
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Get a free eBook or video every month
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fully searchable for easy access to vital information
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Copy and paste, print, and bookmark content
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: At [www.Packt.com](http://www.Packt.com), you can also read a collection of
    free technical articles, sign up for a range of free newsletters, and receive
    exclusive discounts and offers on Packt books and eBooks.
  prefs: []
  type: TYPE_NORMAL
