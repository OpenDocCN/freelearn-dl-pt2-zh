["```py\n$pip install fastapi uvicorn aiofiles jinja2 \n```", "```py\n    from torch_snippets import *\n    class SDD(nn.Module):\n      classes = ['defect','non_defect']\n      def __init__(self, model, device='cpu'):\n        super().__init__()\n        self.model = model.to(device)\n        self.device = device \n    ```", "```py\n     @torch.no_grad()\n      def forward(self, x):\n        x = x.view(-1,3,224,224).to(device)\n        pred = self.model(x)\n        conf = pred[0][0]\n        clss = np.where(conf.item()<0.5,'non_defect','defect')\n        print(clss)\n        return clss.item() \n    ```", "```py\n     def predict(self, image):\n        im = (image[:,:,::-1])\n        im = cv2.resize(im, (224,224))\n        im = torch.tensor(im/255)\n        im = im.permute(2,0,1).float()\n        clss = self.forward(im)\n        return {\"class\": clss} \n    ```", "```py\n    import os, io\n    from sdd import SDD\n    from PIL import Image\n    from fastapi import FastAPI, Request, File, UploadFile \n    ```", "```py\n    # Load the model from sdd.py\n    device = 'cuda' if torch.cuda.is_availabe() else 'cpu'\n    model = SDD(torch.load('sdd.weights.pth', map_location=device) \n    ```", "```py\n    app = FastAPI() \n    ```", "```py\n    @app.post(\"/predict\")\n    def predict(request: Request, file:UploadFile=File(...)):\n        content = file.file.read()\n        image = Image.open(io.BytesIO(content)).convert('L')\n        output = model.predict(image)\n        return output \n    ```", "```py\n    $ uvicorn server:app \n    ```", "```py\n    $ curl -X POST \"http://127.0.0.1:8000/predict\" -H \"accept: application/json\" -H \"Content-Type: multipart/form-data\" -F \"file=@/home/me/Pictures/defect.png;type=image/png\" \n    ```", "```py\n    $ python3 -m venv fastapi-venv\n    $ source fastapi-env/bin/activate \n    ```", "```py\n    $ pip install fastapi uvicorn aiofiles torch torch_snippets \n    ```", "```py\n    $ pip freeze > requirements.txt \n    ```", "```py\nFROM tiangolo/uvicorn-gunicorn-fastapi:python3.7\nCOPY ./requirements.txt /app/requirements.txt\nRUN pip install --no-cache-dir -r requirements.txt\nWORKDIR /app\nCOPY . /app\nEXPOSE 5000\nCMD [\"uvicorn\", \"server:app\", \"--host\", \"0.0.0.0\"] \n```", "```py\n    $ docker build -t sdd:latest . \n    ```", "```py\n    $ docker run -p 5000:5000 sdd:latest \n    ```", "```py\n    $ aws configure\n    AWS Access Key ID [None]: **AKIAIOSFODNN7EXAMPLE**\n    AWS Secret Access Key [None]:**wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY**\n    Default region name [None]: **region**\n    Default output format [None]:**json** \n    ```", "```py\n    $ aws ecr get-login-password --region **region****aws_account_id.****region** | docker login --username AWS --password-stdin dkr.ecr..amazonaws.com \n    ```", "```py\n    $ aws ecr create-repository --repository-name sdd_app \n    ```", "```py\n    $ docker tag sdd:latest **aws_account_id****region**.dkr.ecr..amazonaws.com/sdd_app \n    ```", "```py\n    $ docker push **aws_account_id****region**.dkr.ecr..amazonaws.com/sdd_app \n    ```", "```py\n    ec2-18-221-11-226.us-east-2.compute.amazonaws.com \n    ```", "```py\n    $ ssh ec2-user@ec2-18-221-11-226.us-east-2.compute.amazonaws.com \n    ```", "```py\n    $ sudo yum install -y docker\n    $ sudo groupadd docker\n    $ sudo gpasswd -a ${USER} docker\n    $ sudo service docker restart \n    ```", "```py\n    $ aws configure\n    AWS Access Key ID [None]: **AKIAIOSFODNN7EXAMPLE**\n    AWS Secret Access Key [None]:**wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY**\n    Default region name [None]: **us-west-****2**\n    Default output format [None]:**json**\n    $ reboot \n    ```", "```py\n    $ ssh ec2-user@**ec2-****18****-****221****-****11****-****226****.us-east-****2****.compute.amazonaws.com** \n    ```", "```py\n    $ aws ecr get-login-password --region **region****aws_account_id.****region** | docker login --username AWS --password-stdin dkr.ecr..amazonaws.com \n    ```", "```py\n    $ docker pull **aws_account_id****region**.dkr.ecr..amazonaws.com/sdd_app:latest \n    ```", "```py\n    docker run -p 5000:5000 **aws_account_id****region**.dkr.ecr..amazonaws.com/sdd_app \n    ```", "```py\n    $ curl -X POST \"http://54.229.16.169:5000/predict\" -H \"accept: application/ json\" -H \"Content-Type: multipart/form-data\" -F \"file=@/home/me/Pictures/ defect.png;type=image/png\" \n    ```", "```py\n    {\"class\":\"non-defect\",\"confidence\":\"0.6488\"} \n    ```", "```py\n    %%capture\n    try:\n      from torch_snippets import *\n    except:\n      %pip install torch-snippets gitPython lovely-tensors\n      from torch_snippets import *\n    from git import Repo\n    repository_url = 'https://github.com/sizhky/quantization'\n    destination_directory = '/content/quantization'\n    if exists(destination_directory):\n      repo = Repo(destination_directory)\n    else:\n      repo = Repo.clone_from(repository_url, destination_directory)\n    %cd {destination_directory}\n    %pip install -qq -r requirements.txt \n    ```", "```py\n    # Change to `Debug=false` in the line below\n    # to train on a larger dataset\n    %env DEBUG=true\n    !make train \n    ```", "```py\n    from torch_snippets import *\n    from src.defect_classification.train import get_datasets, get_dataloaders\n    trn_ds, val_ds = get_datasets(DEBUG=True)\n    trn_dl, val_dl = get_dataloaders(trn_ds, val_ds) \n    ```", "```py\n    model = torch.load('model.pth').cuda().eval() \n    ```", "```py\n    results = []\n    for ix, batch in enumerate(iter(trn_dl)):\n      inter = model.avgpool(model.features(batch[0].cuda()))[:,:,0,0].\\\n                                                    detach().cpu().numpy()\n      results.append(inter)\n    results = np.array(results)\n    results = results.reshape(-1, 512) \n    ```", "```py\n    im = val_ds[0]['image'][None].cuda()\n    tmp = np.array(model.avgpool(model.features(im))[0,:,0,0].detach().cpu().\\\n                                                             numpy())\n    dists1 = np.sum(np.abs(results - tmp), axis=1) \n    ```", "```py\n    !wget https://as2.ftcdn.net/v2/jpg/01/42/16/37/1000_F_142163797_YxZaY95j5ckLgb6KoM5KC11Eh9QiZsYx.jpg -O /content/sample_defects.jpg\n    im = (cv2.imread(path)[:,:,::-1])\n    im = cv2.resize(im, (224,224))\n    im = torch.tensor(im/255)\n    im = im.permute(2,0,1).float().to(device)\n    im = im.view(1,3,224,224)\n    tmp = np.array(model.avgpool(model.features(im))[0,:,0,0].detach().cpu().\\\n                                                             numpy())\n    dists2 = np.sum(np.abs(results - tmp), axis=1) \n    ```", "```py\n    import seaborn as sns\n    df = pd.DataFrame(\n        {'distance': np.r_[dists1, dists2],\n         'source': ['val image']*len(dists1)+['random image']*len(dists2)})\n    # Just switch x and y\n    sns.boxplot(y=df[\"source\"], x=df[\"distance\"]) \n    ```", "```py\n    !pip install faiss-gpu \n    ```", "```py\n    import faiss\n    import numpy as np\n    index = faiss.IndexFlatL2(results.shape[1])  # L2 distance\n    index.add(results)\n    faiss.write_index(index, \"index_file.index\") \n    ```", "```py\n    im = val_ds[0]['image'][None].cuda()\n    tmp = np.array(model.avgpool(model.features(im))[0,:,0,0].detach().cpu().\\\n                                                             numpy())\n    query_vector = tmp.reshape(1,512).astype('float32') \n    ```", "```py\n    %%time\n    k = 3  # Number of nearest neighbors to retrieve\n    D, I = index.search(query_vector.astype('float32'), k) \n    ```", "```py\n    vectors = np.array(results.tolist()*10000, dtype=np.float32)\n    print(vectors.shape)\n    index = faiss.IndexFlatL2(vectors.shape[1])  # L2 distance\n    index.add(vectors)\n    faiss.write_index(index, \"index_file_960k.index\") \n    ```", "```py\n    %%time\n    k = 3  # Number of nearest neighbors to retrieve\n    D, I = index.search(query_vector.astype('float32'), k) \n    ```", "```py\n    %%time\n    distances = np.sum(np.square(query_vector - vectors), axis=1)\n    sorted_distances = np.sort(distances) \n    ```"]