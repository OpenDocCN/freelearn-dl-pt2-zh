["```py\nsudo apt-get update\nsudo apt-get upgrade\n```", "```py\nsudo raspi-config\n```", "```py\npip install open-contrib-python\n```", "```py\nimport cv2\n```", "```py\ncap = cv2.VideoCapture(0)\n```", "```py\nif not (cap.isOpened()):\n    print('Could not open video device')\n\n```", "```py\nx = 0\nwhile(True):\n    ret, frame = cap.read()\n    cv2.imshow('preview',frame)\n    time.sleep(1)\n    cv2.imwrite(f'./images/cap{x}.jpg', frame) \n    if cv2.waitKey(1) & 0xFF == ord('q'):\n        break\n```", "```py\ncap.release()\ncv2.destroyAllWindows()\n\n```", "```py\npip3 install azure-cognitiveservices-vision-customvision\n```", "```py\nimport requests\nfile = open('images/drink1/cap0.jpg', 'rb')\nurl = 'Your iteration url goes here'\nheaders = {'Prediction-Key': 'key from the prediction url', \\\n           'Content-Type':'application/octet-stream'}\nfiles = {'file': file}\nr = requests.post(url, data=file, headers=headers)\njson_data = r.json()\nprint(json_data)\n\n```", "```py\nimport cv2\nimport numpy as np\nimport imutils\n```", "```py\nnet = cv2.dnn.readNetFromCaffe(\"deploy.prototxt.txt\", \"res10_300x300_ssd_iter_140000.caffemodel\")\ncap = cv2.VideoCapture(0)\n```", "```py\ndef FaceNN(frame):\n    frame = imutils.resize(frame, width=300, height=300)\n    (h, w) = frame.shape[:2]\n    blob = cv2.dnn.blobFromImage(frame, 1.0, (300, 300), \n                                 (103.93, 116.77, 123.68))\n    net.setInput(blob)\n    detections = net.forward()\n```", "```py\nfor i in range(0, detections.shape[2]):\n    confidence = detections[0, 0, i, 2]\n    if confidence < .8:\n        continue\n    box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n    (startX, startY, endX, endY) = box.astype(\"int\")\n    text = \"{:.2f}%\".format(confidence * 100)\n    y = startY - 10 if startY - 10 > 10 else startY + 10\n    cv2.rectangle(frame, (startX, startY), (endX, endY), \n                  (0, 0, 300), 2)\n    cv2.putText(frame, text, (startX, y), cv2.FONT_HERSHEY_SIMPLEX, \n                0.45, (0, 0, 300), 2)\n```", "```py\nreturn frame\n```", "```py\nwhile True:\n    ret, frame = cap.read()\n    image = FaceNN(frame)\n    cv2.imshow('frame',image)\n    if cv2.waitKey(1) & 0xFF == ord('q'):\n        break\n```", "```py\ncap.release()\ncv2.destroyAllWindows()\n```", "```py\nwget https://pjreddie.com/media/files/yolov3.weights\n```", "```py\nimport cv2\nimport numpy as np\n```", "```py\nwith open(\"yolov3.txt\", 'r') as f:\n    classes = [line.strip() for line in f.readlines()]\ncolors = np.random.uniform(0, 300, size=(len(classes), 3))\nnet = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\ncap = cv2.VideoCapture(0)\nscale = 0.00392\nconf_threshold = 0.5\nnms_threshold = 0.4\n```", "```py\ndef get_output_layers(net):\n    layer_names = net.getLayerNames()\n    output_layers = [layer_names[i[0] - 1] for i in \\\n                      net.getUnconnectedOutLayers()]\n    return output_layers\n```", "```py\ndef create_bounding_boxes(outs,Width, Height):\n    boxes = []\n    class_ids = []\n    confidences = []\n    for out in outs:\n        for detection in out:\n            scores = detection[5:]\n            class_id = np.argmax(scores)\n            confidence = scores[class_id]\n            if confidence > conf_threshold:\n                center_x = int(detection[0] * Width)\n                center_y = int(detection[1] * Height)\n                w = int(detection[2] * Width)\n                h = int(detection[3] * Height)\n                x = center_x - w / 2\n                y = center_y - h / 2\n                class_ids.append(class_id)\n                confidences.append(float(confidence))\n                boxes.append([x, y, w, h])\n    return boxes, class_ids, confidences\n```", "```py\ndef draw_bounding_boxes(img, class_id, confidence, box): \n    x = round(box[0])\n    y = round(box[1])\n    w = round(box[2])\n    h =round(box[3])\n    x_plus_w = x+w\n    y_plus_h = y+h\n    label = str(classes[class_id])\n    color = colors[class_id]\n    cv2.rectangle(img, (x,y), (x_plus_w,y_plus_h), color, 2)\n    cv2.putText(img, label, (x-10,y-10), cv2.FONT_HERSHEY_SIMPLEX, \n                0.5, color, 2)\n```", "```py\ndef Yolo(image):\n    try:\n        Width = image.shape[1]\n        Height = image.shape[0]\n        blob = cv2.dnn.blobFromImage(image, scale, (416,416), \n                                     (0,0,0), True, crop=False)\n        net.setInput(blob)\n        outs = net.forward(get_output_layers(net))\n        boxes, class_ids, confidences = \\\n            create_bounding_boxes(outs, Width, Height)\n        indices = cv2.dnn.NMSBoxes(boxes, confidences, \n                                   conf_threshold, nms_threshold)\n\n        for i in indices:\n            i = i[0]\n            box = boxes[i]\n\n            draw_bounding_boxes(image, class_ids[i], \n                                confidences[i], box)\n    except Exception as e:\n    print('Failed dnn: '+ str(e))\n\n    return image\n```", "```py\nwhile True:\n    ret, frame = cap.read()\n    image = Yolo(frame)\n    cv2.imshow('frame',image)\n    if cv2.waitKey(1) & 0xFF == ord('q'):\n        break\n```", "```py\ncap.release()\ncv2.destroyAllWindows()\n```", "```py\nsudo apt-get update\n```", "```py\nsudo apt-get install git\nsudo apt-get install cmake\nsudo apt-get install libpython3-dev\nsudo apt-get install python3-numpygpu sbc\n```", "```py\ngit clone --recursive https://github.com/dusty-nv/jetson-inference\n```", "```py\ncd jetson-inference\nmkdir build\ncd build\n```", "```py\ncmake ../\nmake\nsudo make install\nsudo ldconfig\n```", "```py\nimport jetson.inference\nimport jetson.utils\n```", "```py\nnet = jetson.inference.detectNet(\"ssd-inception-v2\", threshold=0.5)\ncamera = jetson.utils.gstCamera(1280,720,\"/dev/video0\")\ndisplay = jetson.utils.glDisplay()\n```", "```py\nwhile display.IsOpen():\n    img, width, height = camera.CaptureRGBA()\n    detections = net.Detect(img,width, height)\n    display.RenderOnce(img,width,height)\n```", "```py\ndocker pull nvcr.io/nvidia/pytorch:20.02-py3\n```", "```py\ndocker run --gpus all -it --rm -v $(pwd):/data/ nvcr.io/nvidia/pytorch:20.02-py3 \n```", "```py\nimport torch\nprint(torch.cuda.is_available())\n```", "```py\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom torch import optim\nimport torch.nn.functional as F\nfrom torchvision import datasets, transforms, models\nfrom torch.utils.data.sampler import SubsetRandomSampler\n```", "```py\ndatadir = './data/train'\nvalid_size = .3\nepochs = 3\nsteps = 0\nrunning_loss = 0\nprint_every = 10\ntrain_losses = []\ntest_losses = []\n```", "```py\ndef print_score(torch, testloader, inputs, device, model, criterion, labels):\ntest_loss = 0\naccuracy = 0\nmodel.eval()daimen\n\nwith torch.no_grad():\n    for inputs, labels in testloader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        logps = model.forward(inputs)\n        batch_loss = criterion(logps, labels)\n        test_loss += batch_loss.item()\n\n        ps = torch.exp(logps)\n        top_p, top_class = ps.topk(1, dim=1)\n        equals = top_class == labels.view(*top_class.shape)\n        accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n\ntrain_losses.append(running_loss/len(trainloader))\ntest_losses.append(test_loss/len(testloader))\nprint(f\"Epoch {epoch+1}/{epochs} \\\n      Train loss: {running_loss/print_every:.3f} \\\n      Test loss: {test_loss/len(testloader):.3f} \\\n      Test accuracy: {accuracy/len(testloader):.3f}\")\n\n return test_loss, accuracy\n```", "```py\ntrain_transforms = transforms.Compose([transforms.Resize(224),\n                                       transforms.ToTensor()])\ntest_transforms = transforms.Compose([transforms.Resize(224),\n                                      transforms.ToTensor()])\ntrain_data = datasets.ImageFolder(datadir, \n                                  transform=train_transforms)\ntest_data = datasets.ImageFolder(datadir, \n                                 transform=test_transforms)\nnum_train = len(train_data)\nindices = list(range(num_train))\nsplit = int(np.floor(valid_size * num_train))\nnp.random.shuffle(indices)\ntrain_idx, test_idx = indices[split:], indices[:split]\ntrain_sampler = SubsetRandomSampler(train_idx)\ntest_sampler = SubsetRandomSampler(test_idx)\ntrainloader = torch.utils.data.DataLoader(train_data, \n                                          sampler=train_sampler, \n                                          batch_size=1)\ntestloader = torch.utils.data.DataLoader(test_data, \n                                         sampler=test_sampler, \n                                         batch_size=1)\n```", "```py\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = models.resnet50(pretrained=True)\n\nfor param in model.parameters():\n    param.requires_grad = False\n\nmodel.fc = nn.Sequential(nn.Linear(2048, 512), nn.ReLU(), \n                         nn.Dropout(0.2), nn.Linear(512, 10), \n                         nn.LogSoftmax(dim=1))\ncriterion = nn.NLLLoss()\noptimizer = optim.Adam(model.fc.parameters(), lr=0.003)\nmodel.to(device)\n```", "```py\nfor epoch in range(epochs):\n    for inputs, labels in trainloader:\n        steps += 1\n        inputs, labels = inputs.to(device), labels.to(device)\n        optimizer.zero_grad()\n        logps = model.forward(inputs)\n        loss = criterion(logps, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n\n        if steps % print_every == 0:\n            test_loss, accuracy = print_score(torch, testloader, \n                                              inputs, device, \n                                              model, criterion,\n                                              labels)\n            running_loss = 0\n            model.train()\n```", "```py\ntorch.save(model, 'saftey.pth')\n```"]