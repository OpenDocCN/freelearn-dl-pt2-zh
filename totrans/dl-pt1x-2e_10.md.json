["```py\nimage_size = 512 \nis_cuda = torch.cuda.is_available()\npreprocessing = transforms.Compose([transforms.Resize(image_size),\n                           transforms.ToTensor(),\n                           transforms.Lambda(lambda x: x[torch.LongTensor([2,1,0])]), \n                           transforms.Normalize(mean=[0.40760392, 0.45795686, 0.48501961], \n                                                std=[1,1,1]),\n                           transforms.Lambda(lambda x: x.mul_(255)),\n                          ])\nprocessing = transforms.Compose([transforms.Lambda(lambda x: x.mul_(1./255)),\n                           transforms.Normalize(mean=[-0.40760392, -0.45795686, -0.48501961], \n                                                std=[1,1,1]),\n                           transforms.Lambda(lambda x: x[torch.LongTensor([2,1,0])]), \n                           ])\npostprocess = transforms.Compose([transforms.ToPILImage()])\n\ndef postprocess_b(tensor): \n    t = processing(tensor)\n    t[t>1] = 1 \n    t[t<0] = 0\n    img = postprocess(t)\n    return img\n```", "```py\ndef loader(image_name):\n    image = Image.open(image_name)\n    image = Variable(preprocessing(image))\n    # fake batch dimension required to fit network's input dimensions\n    image = image.unsqueeze(0)\n    return image\n```", "```py\nstyle_image = loader(\"Images/style_image.jpg\")\ncontent_image = loader(\"Images/content_image.jpg\")\n```", "```py\noutput_image = Variable(content_image.data.clone(),requires_grad=True)\n```", "```py\nvgg = vgg19(pretrained=True).features\nfor param in vgg.parameters():\n   param.requires_grad = False\n```", "```py\ntarget_layer = dummy_fn(content_img)\nnoise_layer = dummy_fn(noise_img)\ncriterion = nn.MSELoss()\ncontent_loss = criterion(target_layer,noise_layer)\n```", "```py\nclass GramMatrix(nn.Module):\n\n   def forward(self,input):\n       b,c,h,w = input.size()\n       features = input.view(b,c,h*w)\n       gram_matrix = torch.bmm(features,features.transpose(1,2))\n       gram_matrix.div_(h*w)\n       return gram_matrix\n```", "```py\nb,c,h,w = input.size()\n```", "```py\nfeatures = input.view(b,c,h*w)\n```", "```py\ngram_matrix = torch.bmm(features,features.transpose(1,2))\n```", "```py\nclass StyleLoss(nn.Module):\n   def forward(self,inputs,targets):\n       out = nn.MSELoss()(GramMatrix()(inputs),targets)\n       return (out)\n```", "```py\nclass LayerActivations():\n   features=[]\n\n   def __init__(self,model,layer_numbers):\n\n       self.hooks = []\n       for layer_num in layer_numbers:\n           self.hooks.append(model[layer_numbers].register_forward_hook(self.hook_fn))\n\n   def hook_fn(self,module,input,output):\n       self.features.append(output)\n\n   def remove(self):\n       for hook in self.hooks:\n           hook.remove()\n```", "```py\ndef extract_layers(layers,image,model=None):\n\n   la = LayerActivations(model,layers)\n   la.features = []\n   out = model(image)\n   la.remove()\n   return la.features\n```", "```py\ncontent_targets = extract_layers(content_layers,content_img,model=vgg)\nstyle_targets = extract_layers(style_layers,style_img,model=vgg)\n```", "```py\ncontent_targets = [t.detach() for t in content_targets]\nstyle_targets = [GramMatrix()(t).detach() for t in style_targets]\n```", "```py\ntargets = style_targets + content_targets\n```", "```py\nstyle_layers = [1,6,11,20,25]\ncontent_layers = [21]\nloss_layers = style_layers + content_layers\n```", "```py\nstyle_weights = [1e3/n**2 for n in [64,128,256,512,512]]\ncontent_weights = [1e0]\nweights = style_weights + content_weights\n```", "```py\nprint(vgg)\n```", "```py\n#Results\n\nSequential(\n (0): Conv2d (3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n (1): ReLU(inplace)\n (2): Conv2d (64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n (3): ReLU(inplace)\n (4): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n (5): Conv2d (64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n (6): ReLU(inplace)\n (7): Conv2d (128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n (8): ReLU(inplace)\n (9): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n (10): Conv2d (128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n (11): ReLU(inplace)\n (12): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n (13): ReLU(inplace)\n (14): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n (15): ReLU(inplace)\n (16): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n (17): ReLU(inplace)\n (18): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n (19): Conv2d (256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n (20): ReLU(inplace)\n (21): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n (22): ReLU(inplace)\n (23): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n (24): ReLU(inplace)\n (25): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n (26): ReLU(inplace)\n (27): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n (28): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n (29): ReLU(inplace)\n (30): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n (31): ReLU(inplace)\n (32): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n (33): ReLU(inplace)\n (34): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n (35): ReLU(inplace)\n (36): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n)\n```", "```py\nloss_fns = [StyleLoss()] * len(style_layers) + [nn.MSELoss()] * len(content_layers)\n```", "```py\noptimizer = optim.LBFGS([output_image]);\n```", "```py\nmaximum_iterations = 500\nshow_iteration-1 = 50\nn_iter=[0]\n\noptimizer = optim.LBFGS([output_image]);\nn_iteration=[0]\n\nwhile n_iteration[0] <= maximum_iterations:\n\n    def closure():\n        optimizer.zero_grad()\n\n        out = extract_layers(loss_layers,output_image,model=vgg)\n        layer_losses = [weights[a] * loss_fns[a](A, targets[a]) for a,A in enumerate(out)]\n        loss = sum(layer_losses)\n        loss.backward()\n        n_iteration[0]+=1\n        if n_iteration[0]%show_iteration == (show_iteration-1):\n            print('Iteration: %d, loss: %f'%(n_iteration[0]+1, loss.data[0]))\n\n        return loss\n\n    optimizer.step(closure)\n```", "```py\ntransforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n```", "```py\nclass _net_generator(nn.Module):\n    def __init__(self):\n        super(_net_generator, self).__init__()\n\n        self.main = nn.Sequential(\n            nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False),\n            nn.BatchNorm2d(ngf * 8),\n            nn.ReLU(True),\n           nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf * 4),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf * 2),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf),\n            nn.ReLU(True),\n            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),\n            nn.Tanh()\n        )\n\n    def forward(self, input):\n        output = self.main(input)\n        return output\n\nnet_generator = _net_generator()\nnet_generator.apply(weights_inititialisation)\nprint(net_generator)\n```", "```py\ndef weights_inititialisation(m):\n   class_name = m.__class__.__name__\n   if class_name.find('Conv') != -1:\n       m.weight.data.normal_(0.0, 0.02)\n   elif class_name.find('BatchNorm') != -1:\n       m.weight.data.normal_(1.0, 0.02)\n       m.bias.data.fill_(0)\n```", "```py\nnet_generator.apply(weights_inititialisation)\n```", "```py\nclass _net_discriminator(nn.Module):\n    def __init__(self):\n        super(_net_discriminator, self).__init__()\n        self.main = nn.Sequential(\n            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ndf * 2),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ndf * 4),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ndf * 8),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n            nn.Sigmoid()\n        )\n\n    def forward(self, input):\n        output = self.main(input)\n        return output.view(-1, 1).squeeze(1)\n\nnet_discriminator = _net_discriminator()\nnet_discriminator.apply(weights_inititialisation)\nprint(net_discriminator)\n```", "```py\ncriterion = nn.BCELoss()\n\noptimizer_discriminator = optim.Adam(net_discriminator.parameters(), lr, betas=(beta1, 0.95))\noptimizer_generator = optim.Adam(net_generator.parameters(), lr, betas=(beta1, 0.95))\n```", "```py\noutput = net_discriminator(inputv)\nerr_discriminator_real = criterion(output, labelv)\nerr_discriminator_real.backward()\n```", "```py\nfake = net_generator(noisev)\noutput = net_discriminator(fake.detach())\nerr_discriminator_fake = criterion(output, labelv)\nerr_discriminator_fake.backward()\noptimizer_discriminator.step()\n```", "```py\nnet_generator.zero_grad()\nlabelv = Variable(label.fill_(real_label)) # fake labels are real for generator cost\noutput = net_discriminator(fake)\nerr_generator = criterion(output, labelv)\nerr_generator.backward()\noptimizer_generator.step()\n```", "```py\nfor epoch in range(niter):\n    for i, data in enumerate(dataloader, 0):\n        # train with real\n        net_discriminator.zero_grad()\n        real_cpu, _ = data\n        batch_size = real_cpu.size(0)\n        if torch.cuda.is_available():\n            real_cpu = real_cpu.cuda()\n        input.resize_as_(real_cpu).copy_(real_cpu)\n        label.resize_(batch_size).fill_(real_label)\n        inputv = Variable(input)\n        labelv = Variable(label)\n\n        output = net_discriminator(inputv)\n        err_discriminator_real = criterion(output, labelv)\n        err_discriminator_real.backward()\n        D_x = output.data.mean()\n\n        noise.resize_(batch_size, nz, 1, 1).normal_(0, 1)\n        noisev = Variable(noise)\n        fake = net_generator(noisev)\n        labelv = Variable(label.fill_(fake_label))\n        output = net_discriminator(fake.detach())\n        err_discriminator_fake = criterion(output, labelv)\n        err_discriminator_fake.backward()\n        D_G_z1 = output.data.mean()\n        err_discriminator = err_discriminator_real + err_discriminator_fake\n        optimizer_discriminator.step()\n\n        net_generator.zero_grad()\n        labelv = Variable(label.fill_(real_label)) # fake labels are real for generator cost\n        output = net_discriminator(fake)\n        err_generator = criterion(output, labelv)\n        err_generator.backward()\n        D_G_z2 = output.data.mean()\n        optimizer_generator.step()\n\n        print('[%d/%d][%d/%d] Loss_Discriminator: %.4f Loss_Generator: %.4f D(x): %.4f D(G(z)): %.4f / %.4f'\n              % (epoch, niter, i, len(dataloader),\n                 err_discriminator.data[0], err_generator.data[0], D_x, D_G_z1, D_G_z2))\n        if i % 100 == 0:\n            vutils.save_image(real_cpu,\n                    '%s/real_samples.png' % outf,\n                    normalize=True)\n            fake = net_generator(fixed_noise)\n            vutils.save_image(fake.data,\n                    '%s/fake_samples_epoch_%03d.png' % (outf, epoch),\n                    normalize=True)\n```"]