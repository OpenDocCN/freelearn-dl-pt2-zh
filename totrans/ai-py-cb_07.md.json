["```py\npip install scikit-image\n```", "```py\nfrom tensorflow import keras\nfrom matplotlib import pyplot as plt\n\n(train_images, train_labels), (test_images, test_labels) = keras.datasets.fashion_mnist.load_data()\ntrain_images = train_images / 255.0\ntest_images = test_images / 255.0\nplt.imshow(train_images[0])\nplt.colorbar()\nplt.grid(False)\n```", "```py\nimport skimage.transform\nimport numpy as np\n\ndef get_pyramid_features(img):\n    return np.hstack([\n        layer.reshape(-1)\n        for layer in skimage.transform.pyramids.pyramid_gaussian(img)\n    ])\n```", "```py\nfrom sklearn.svm import LinearSVC\n\ndef featurize(x_train, y_train):\n    data = []\n    labels = []\n    for img, label in zip(x_train, y_train):\n        data.append(get_pyramid_features(img))\n        labels.append(label)\n\n    data = np.array(data)\n    labels = np.array(labels)\n    return data, labels\n```", "```py\nx_train, y_train = featurize(train_images, train_labels)\nclf = LinearSVC(C=1, loss='hinge').fit(x_train, y_train)\n\nx_val, y_val = featurize(test_images, test_labels)\nprint('accuracy: {:.3f}'.format(clf.score(x_val, y_val)))\n```", "```py\nimport tensorflow as tf\nfrom tensorflow.keras.losses import SparseCategoricalCrossentropy\n\ndef compile_model(model):\n  model.summary()\n  model.compile(\n    optimizer='adam',\n    loss=SparseCategoricalCrossentropy(\n      from_logits=True\n    ),\n    metrics=['accuracy']\n  ) \n\ndef create_mlp():\n  model = tf.keras.Sequential([\n    tf.keras.layers.Flatten(input_shape=(28, 28)),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dense(10)\n  ])\n  compile_model(model)\n  return model\n```", "```py\ndef train_model(model, train_images, test_images):\n    model.fit(\n        train_images,\n        train_labels,\n        epochs=50,\n        verbose=1,\n        validation_data=(test_images, test_labels)\n    )\n    loss, accuracy = model.evaluate(test_images, test_labels, verbose=0)\n    print('loss:', loss)\n    print('accuracy:', accuracy)\n```", "```py\nfrom tensorflow.keras.layers import (\n  Conv2D, MaxPooling2D, Flatten, Dense\n)\n\ndef create_lenet():\n    model = tf.keras.Sequential([\n        Conv2D(\n            filters=6,\n            kernel_size=(5, 5),\n            padding='valid',\n            input_shape=(28, 28, 1),\n            activation='tanh'\n        ),\n        MaxPooling2D(pool_size=(2, 2)),\n        Conv2D(\n            filters=16,\n            kernel_size=(5, 5),\n            padding='valid',\n            activation='tanh'\n        ),\n        MaxPooling2D(pool_size=(2, 2)),\n        Flatten(),\n        Dense(120, activation='tanh'),\n        Dense(84, activation='tanh'),\n        Dense(10, activation='softmax')\n    ])\n    compile_model(model)\n    return model\n```", "```py\ntrain_model(\n    create_lenet(),\n    train_images.reshape(train_images.shape + (1,)),\n    test_images.reshape(test_images.shape + (1,)),\n)\n```", "```py\nbase_model = tf.keras.applications.MobileNetV2(\n    input_shape=(224, 224, 3),\n    include_top=False,\n    weights='imagenet'\n)\n```", "```py\ndef create_transfer_model():\n    base_model = tf.keras.applications.MobileNetV2(\n        input_shape=(224, 224, 3),\n        include_top=False,\n        weights='imagenet'\n    )\n    base_model.trainable = False\n    model = tf.keras.Sequential([\n      base_model,\n      tf.keras.layers.GlobalAveragePooling2D(),\n      tf.keras.layers.Dense(10)\n    ])\n    compile_model(model)\n    return model\n```", "```py\n    base_model = tf.keras.applications.MobileNetV2(\n        input_shape=(224, 224, 3),\n        include_top=False,\n        weights='imagenet'\n    )\n```", "```py\npip install --upgrade Pillow\n```", "```py\ndef discriminator_model():\n    model = Sequential([\n        Conv2D(\n            64, (5, 5),\n            padding='same',\n            input_shape=(28, 28, 1),\n            activation='tanh'\n        ),\n        MaxPooling2D(pool_size=(2, 2)),\n        Conv2D(128, (5, 5), activation='tanh'),\n        MaxPooling2D(pool_size=(2, 2)),\n        Flatten(),\n        Dense(1024, activation='tanh'),\n        Dense(1, activation='sigmoid')\n    ])\n  return model\n```", "```py\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import (\n    Dense, Reshape, Activation,\n    Flatten, BatchNormalization,\n    UpSampling2D, Conv2D, MaxPooling2D\n)\n\ndef create_generator_model():\n    model = Sequential([\n        Dense(input_dim=100, units=1024, activation='tanh'), Dense(128*7*7),\n        BatchNormalization(),\n        Activation('tanh'),\n        Reshape((7, 7, 128), input_shape=(128*7*7,)),\n        UpSampling2D(size=(2, 2)),\n        Conv2D(64, (5, 5), padding='same'),\n        Activation('tanh'),\n        UpSampling2D(size=(2, 2)),\n        Conv2D(1, (5, 5), padding='same'),\n        Activation('tanh'),\n    ])\n    model.summary()\n    return model\n```", "```py\nfrom tensorflow.keras.datasets import mnist\n\n(X_train, y_train), (X_test, y_test) = mnist.load_data()\nX_train = (X_train.astype(np.float32) - 127.5) / 127.5\nX_train = X_train[:, :, :, None]\nX_test = X_test[:, :, :, None]\n```", "```py\ndef chain_generator_discriminator(g, d):\n    model = Sequential()\n    model.add(g)\n    model.add(d)\n    return model\n```", "```py\nfrom tensorflow.keras.optimizers import SGD\n\ndef optim():\n    return SGD(\n        lr=0.0005,\n        momentum=0.9,\n        nesterov=True\n    )\n```", "```py\nd = discriminator_model()\ng = generator_model()\nd_on_g = chain_generator_discriminator(g, d)\nd_on_g.compile(loss='binary_crossentropy', optimizer=optim())\nd.compile(loss='binary_crossentropy', optimizer=optim())\n```", "```py\nimport numpy as np\n\ndef generate_images(g, batch_size):\n    noise = np.random.uniform(-1, 1, size=(batch_size, 100))\n    image_batch = X_train[index*batch_size:(index+1)*batch_size]\n    return g.predict(noise, verbose=0)\n```", "```py\ndef learn_discriminate(d, image_batch, generated_images, batch_size):\n    X = np.concatenate(\n        (image_batch, generated_images)\n    )\n    y = np.array(\n        [1] * batch_size + [0] * batch_size\n    )\n    loss = d.train_on_batch(X, y)\n    return loss\n```", "```py\ndef learn_generate(d_on_g, d, batch_size):\n    noise = np.random.uniform(-1, 1, (batch_size, 100))\n    d.trainable = False\n    targets = np.array([1] * batch_size)\n    loss = d_on_g.train_on_batch(noise, targets)\n    d.trainable = True\n    return loss\n```", "```py\nfrom PIL import Image\n\ndef save_images(generated_images, epoch, index):\n    image = combine_images(generated_images)\n    image = image*127.5+127.5\n    Image.fromarray(\n        image.astype(np.uint8)\n    ).save('{}_{}.png'.format(epoch, index))\n```", "```py\nfrom tqdm.notebook import trange\n\nbatch_size = 1024\ngenerator_losses = []\ndiscriminator_losses = []\nfor epoch in trange(100):\n    for index in trange(nbatches):\n        image_batch = X_train[index*batch_size:(index+1)*batch_size]\n        generated_images = generate_images(g, batch_size)\n        d_loss = learn_discriminate(\n            d, image_batch, generated_images, batch_size\n        )\n        g_loss = learn_generate(d_on_g, d, batch_size)\n        discriminator_losses.append(d_loss)\n        generator_losses.append(g_loss)\n        if (index % 20) == 0:\n            save_images(generated_images, epoch, index)\n```", "```py\n!pip install torchvision\n```", "```py\nuse_cuda = True\nuse_cuda = use_cuda and torch.cuda.is_available()\nprint(use_cuda)\nif use_cuda:\n    dtype = torch.cuda.FloatTensor\n    device = torch.device('cuda:0')\nelse:\n    dtype = torch.FloatTensor\n    device = torch.device('cpu')\n```", "```py\nimport numpy as np\nimport torch\nfrom torch import autograd\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, dataset\nfrom torchvision.datasets import MNIST\nimport torchvision.transforms as T\nfrom tqdm.notebook import trange\n```", "```py\nEPS = torch.finfo(torch.float32).eps\nbatch_size = 1024\nn_classes = 10\nbatch_size = 1024\nn_classes = 10\n\ntrain_loader = torch.utils.data.DataLoader(\n    MNIST(\n        'Data/',\n        train=True,\n        download=True,\n        transform=T.Compose([\n                T.transforms.ToTensor(),\n                T.Normalize((0.1307,), (0.3081,))\n        ])\n    ),\n    batch_size=batch_size,\n    shuffle=True\n)\n\nval_loader = torch.utils.data.DataLoader(\n    MNIST(\n        'Val/',\n        train=False,\n        download=True,\n        transform=T.Compose([\n                T.transforms.ToTensor(),\n                T.Normalize((0.1307,), (0.3081,))\n        ])\n    ),\n    batch_size=batch_size,\n    shuffle=False\n)\n```", "```py\ndims = 10\nclass Encoder(nn.Module):\n    def __init__(self, dim_input, dim_z):\n        super(Encoder, self).__init__()\n        self.dim_input = dim_input # image size\n        self.dim_z = dim_z\n        self.network = []\n        self.network.extend([\n            nn.Linear(self.dim_input, self.dim_input // 2),\n            nn.Dropout(p=0.2),\n            nn.ReLU(),\n            nn.Linear(self.dim_input // 2, self.dim_input // 2),\n            nn.Dropout(p=0.2),\n            nn.ReLU(),\n            nn.Linear(self.dim_input // 2, self.dim_z),\n        ])\n        self.network = nn.Sequential(*self.network)\n    def forward(self, x):\n        z = self.network(x)\n        return z\n```", "```py\nclass Decoder(nn.Module):\n    def __init__(self, dim_input , dim_z, supervised=False):\n        super(Decoder, self).__init__()\n        self.dim_input = dim_input\n        self.dim_z = dim_z\n        self.supervised = supervised\n        self.network = []\n        self.network.extend([\n            nn.Linear(self.dim_z, self.dim_input // 2) if not self.supervised\n            else nn.Linear(self.dim_z + n_classes, self.dim_input // 2),\n            nn.Dropout(p=0.2),\n            nn.ReLU(),\n            nn.Linear(self.dim_input // 2, self.dim_input // 2),\n            nn.Dropout(p=0.2),\n            nn.ReLU(),\n            nn.Linear(self.dim_input // 2, self.dim_input),\n            nn.Sigmoid(),\n        ])\n        self.network = nn.Sequential(*self.network)\n    def forward(self, z):\n        x_recon = self.network(z)\n        return x_recon\n```", "```py\nclass Discriminator(nn.Module):\n    def __init__(self, dims, dim_h):\n        super(Discriminator,self).__init__()\n        self.dim_z = dims\n        self.dim_h = dim_h\n        self.network = []\n        self.network.extend([\n            nn.Linear(self.dim_z, self.dim_h),\n            nn.Dropout(p=0.2), \n            nn.ReLU(),\n            nn.Dropout(p=0.2), \n            nn.Linear(self.dim_h, self.dim_h),\n            nn.ReLU(),\n            nn.Linear(self.dim_h, 1),\n            nn.Sigmoid(),\n        ])\n        self.network = nn.Sequential(*self.network)\n\n    def forward(self, z):\n        disc = self.network(z)\n        return disc\n```", "```py\ndef one_hot_encoding(labels, n_classes=10):\n    cat = np.array(labels.data.tolist())\n    cat = np.eye(n_classes)[cat].astype('float32')\n    cat = torch.from_numpy(cat)\n    return autograd.Variable(cat)\n```", "```py\ndef train_validate(\n        encoder,\n        decoder,\n        Disc,\n        dataloader,\n        optim_encoder,\n        optim_decoder,\n        optim_D,\n        train):\n    total_rec_loss = 0\n    total_disc_loss = 0\n    total_gen_loss = 0\n    if train:\n        encoder.train()\n        decoder.train()\n        Disc.train()\n    else:\n        encoder.eval()\n        decoder.eval()\n        Disc.eval()\n\n    iteration = 0\n    for (data, labels) in dataloader:\n        # [ training loop here, see next code segment ]\n\n    M = len(dataloader.dataset)\n    return total_rec_loss / M, total_disc_loss / M, total_gen_loss / M\n```", "```py\n    for (data, labels) in dataloader:\n        # Reconstruction loss:\n        for p in Disc.parameters():\n            p.requires_grad = False\n\n        real_data_v = autograd.Variable(data).to(device).view(-1, 784)\n        encoding = encoder(real_data_v)\n\n        if decoder.supervised:\n            categories = one_hot_encoding(labels, n_classes=10).to(device)\n            decoded = decoder(torch.cat((categories, encoding), 1))\n        else:\n            decoded = decoder(encoding)\n\n        reconstruction_loss = F.binary_cross_entropy(decoded, real_data_v)\n        total_rec_loss += reconstruction_loss.item()\n        if train:\n            optim_encoder.zero_grad()\n            optim_decoder.zero_grad()\n            reconstruction_loss.backward()\n            optim_encoder.step()\n            optim_decoder.step()\n\n        encoder.eval()\n        z_real_gauss = autograd.Variable(\n            torch.randn(data.size()[0], dims) * 5.0\n        ).to(device)\n        z_fake_gauss = encoder(real_data_v)\n        D_real_gauss = Disc(z_real_gauss)\n        D_fake_gauss = Disc(z_fake_gauss)\n\n        D_loss = -torch.mean(\n            torch.log(D_real_gauss + EPS) +\n            torch.log(1 - D_fake_gauss + EPS)\n        )\n        total_disc_loss += D_loss.item()\n\n        if train:\n            optim_D.zero_grad()\n            D_loss.backward()\n            optim_D.step()\n\n        if train:\n            encoder.train()\n        else:\n            encoder.eval()\n        z_fake_gauss = encoder(real_data_v)\n        D_fake_gauss = Disc(z_fake_gauss)\n\n        G_loss = -torch.mean(torch.log(D_fake_gauss + EPS))\n        total_gen_loss += G_loss.item()\n\n        if train:\n            optim_encoder_reg.zero_grad()\n            G_loss.backward()\n            optim_encoder_reg.step()\n\n        if (iteration % 100) == 0:\n            print(\n                'reconstruction loss: %.4f, discriminator loss: %.4f , generator loss: %.4f' %\n                (reconstruction_loss.item(), D_loss.item(), G_loss.item()))\n\n        iteration += 1\n```", "```py\nencoder = Encoder(784, dims).to(device)\ndecoder = Decoder(784, dims, supervised=True).to(device)\nDisc = Discriminator(dims, 1500).to(device)\n\nlr = 0.001\noptim_encoder = torch.optim.Adam(encoder.parameters(), lr=lr)\noptim_decoder = torch.optim.Adam(decoder.parameters(), lr=lr)\noptim_D = torch.optim.Adam(Disc.parameters(), lr=lr)\noptim_encoder_reg = torch.optim.Adam(encoder.parameters(), lr=lr * 0.1)\n```", "```py\ntrain_loss = []\nval_loss = []\nfor epoch in trange(n_epochs):\n    l1, l2, l3 = train_validate(\n        encoder, decoder, Disc,\n        train_loader, optim_encoder, optim_decoder,\n        optim_D, train=True\n    )\n    print('epoch: {} ---- training loss: {:.8f}'.format(epoch, l1))\n    train_loss.append(l1)\n\n    if (epoch % 5) == 0:\n        l1, l2, l3 = train_validate(\n            encoder, decoder, Disc,\n            val_loader, optim_encoder,\n            optim_decoder, optim_D, False\n        )\n        print('epoch: {} ---- validation loss: {:.8f}'.format(epoch, l1))\n        val_loss.append(l1)\n```", "```py\nif decoder.supervised:\n    categories = one_hot_encoding(labels, n_classes=10).to(device)\n    decoded = decoder(torch.cat((categories, encoding), 1))\nelse:\n    decoded = decoder(encoding)\n    reconstruction_loss = F.binary_cross_entropy(decoded, real_data_v)\n```", "```py\n        # i) latent representation:\n        encoder.eval()\n        z_real_gauss = autograd.Variable(\n            torch.randn(data.size()[0], dims) * 5.0\n        ).to(device)\n        z_fake_gauss = encoder(real_data_v)\n        # ii) feed into discriminator\n        D_real_gauss = Disc(z_real_gauss)\n        D_fake_gauss = Disc(z_fake_gauss)\n\n        D_loss = -torch.mean(\n            torch.log(D_real_gauss + EPS) +\n            torch.log(1 - D_fake_gauss + EPS)\n        )\n```", "```py\n        if train:\n            encoder.train()\n        else:\n            encoder.eval()\n        z_fake_gauss = encoder(real_data_v)\n        D_fake_gauss = Disc(z_fake_gauss)\n\n        G_loss = -torch.mean(torch.log(D_fake_gauss + EPS))\n        total_gen_loss += G_loss.item()\n```"]