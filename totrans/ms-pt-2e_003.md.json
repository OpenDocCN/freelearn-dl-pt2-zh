["```py\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.transforms as transforms\ntorch.use_deterministic_algorithms(True) \n```", "```py\nclass LeNet(nn.Module):\n    def __init__(self):\n        super(LeNet, self).__init__()\n        # 3 input image channel, 6 output feature maps and 5x5 conv kernel\n        self.cn1 = nn.Conv2d(3, 6, 5)\n        # 6 input image channel, 16 output feature maps and 5x5 conv kernel\n        self.cn2 = nn.Conv2d(6, 16, 5)\n        # fully connected layers of size 120, 84 and 10\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 5*5 is the spatial dimension at this layer\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n    def forward(self, x):\n        # Convolution with 5x5 kernel\n        x = F.relu(self.cn1(x))\n        # Max pooling over a (2, 2) window\n        x = F.max_pool2d(x, (2, 2))\n        # Convolution with 5x5 kernel\n        x = F.relu(self.cn2(x))\n        # Max pooling over a (2, 2) window\n        x = F.max_pool2d(x, (2, 2))\n        # Flatten spatial and depth dimensions into a single vector\n        x = x.view(-1, self.flattened_features(x))\n        # Fully connected operations\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n    def flattened_features(self, x):\n        # all except the first (batch) dimension\n        size = x.size()[1:]  \n        num_feats = 1\n        for s in size:\n            num_feats *= s\n        return num_feats\nlenet = LeNet()\nprint(lenet)\n```", "```py\ndef train(net, trainloader, optim, epoch):\n    # initialize loss\n    loss_total = 0.0\n     for i, data in enumerate(trainloader, 0):\n        # get the inputs; data is a list of [inputs, labels]\n        # ip refers to the input images, and ground_truth refers to the output classes the images belong to\n        ip, ground_truth = data\n        # zero the parameter gradients\n        optim.zero_grad()\n        # forward-pass + backward-pass + optimization -step\n        op = net(ip)\n        loss = nn.CrossEntropyLoss()(op, ground_truth)\n        loss.backward()\n        optim.step()\n        # update loss\n        loss_total += loss.item()\n         # print loss statistics\n        if (i+1) % 1000 == 0:    # print at the interval of 1000 mini-batches\n            print('[Epoch number : %d, Mini-batches: %5d] loss: %.3f' % (epoch + 1, i + 1, loss_total / 200))\n            loss_total = 0.0\n```", "```py\ndef test(net, testloader):\n    success = 0\n    counter = 0\n    with torch.no_grad():\n        for data in testloader:\n            im, ground_truth = data\n            op = net(im)\n            _, pred = torch.max(op.data, 1)\n            counter += ground_truth.size(0)\n            success += (pred == ground_truth).sum().item()\n    print('LeNet accuracy on 10000 images from test dataset: %d %%' % (100 * success / counter))\n```", "```py\n# The mean and std are kept as 0.5 for normalizing pixel values as the pixel values are originally in the range 0 to 1\ntrain_transform = transforms.Compose([transforms.RandomHorizontalFlip(),\ntransforms.RandomCrop(32, 4),\ntransforms.ToTensor(),\ntransforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\ntrainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=8, shuffle=True)\ntest_transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\ntestset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=10000, shuffle=False)\n# ordering is important\nclasses = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n```", "```py\n# define a function that displays an image\ndef imageshow(image):\n    # un-normalize the image\n    image = image/2 + 0.5     \n    npimage = image.numpy()\n    plt.imshow(np.transpose(npimage, (1, 2, 0)))\n    plt.show()\n# sample images from training set\ndataiter = iter(trainloader)\nimages, labels = dataiter.next()\n# display images in a grid\nnum_images = 4\nimageshow(torchvision.utils.make_grid(images[:num_images]))\n# print labels\nprint('    '+'  ||  '.join(classes[labels[j]] for j in range(num_images)))\n```", "```py\n# define optimizer\noptim = torch.optim.Adam(lenet.parameters(), lr=0.001)\n# training loop over the dataset multiple times\nfor epoch in range(50):  \n    train(lenet, trainloader, optim, epoch)\n    print()\n    test(lenet, testloader)\n    print()\nprint('Finished Training')\n```", "```py\nmodel_path = './cifar_model.pth'\ntorch.save(lenet.state_dict(), model_path)\n```", "```py\n# load test dataset images\nd_iter = iter(testloader)\nim, ground_truth = d_iter.next()\n# print images and ground truth\nimageshow(torchvision.utils.make_grid(im[:4]))\nprint('Label:      ', ' '.join('%5s' % classes[ground_truth[j]] for j in range(4)))\n# load model\nlenet_cached = LeNet()\nlenet_cached.load_state_dict(torch.load(model_path))\n# model inference\nop = lenet_cached(im)\n# print predictions\n_, pred = torch.max(op, 1)\nprint('Prediction: ', ' '.join('%5s' % classes[pred[j]] for j in range(4)))\n```", "```py\nsuccess = 0\ncounter = 0\nwith torch.no_grad():\n    for data in testloader:\n        im, ground_truth = data\n        op = lenet_cached(im)\n        _, pred = torch.max(op.data, 1)\n        counter += ground_truth.size(0)\n        success += (pred == ground_truth).sum().item()\nprint('Model accuracy on 10000 images from test dataset: %d %%' % (\n    100 * success / counter))\n```", "```py\nclass_sucess = list(0\\. for i in range(10))\nclass_counter = list(0\\. for i in range(10))\nwith torch.no_grad():\n    for data in testloader:\n        im, ground_truth = data\n        op = lenet_cached(im)\n        _, pred = torch.max(op, 1)\n        c = (pred == ground_truth).squeeze()\n        for i in range(10000):\n            ground_truth_curr = ground_truth[i]\n            class_sucess[ground_truth_curr] += c[i].item()\n            class_counter[ground_truth_curr] += 1\nfor i in range(10):\n    print('Model accuracy for class %5s : %2d %%' % (\n        classes[i], 100 * class_sucess[i] / class_counter[i]))\n```", "```py\nclass AlexNet(nn.Module):\n    def __init__(self, number_of_classes):\n        super(AlexNet, self).__init__()\n        self.feats = nn.Sequential(\n            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=11, stride=4, padding=5),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(in_channels=64, out_channels=192, kernel_size=5, padding=2),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(in_channels=192, out_channels=384, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        )\n        self.clf = nn.Linear(in_features=256, out_features=number_of_classes)\n    def forward(self, inp):\n        op = self.feats(inp)\n        op = op.view(op.size(0), -1)\n        op = self.clf(op)\n        return op\n```", "```py\nimport os\nimport time\nimport copy\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torchvision import datasets, models, transforms\ntorch.use_deterministic_algorithms(True) \n```", "```py\nddir = 'hymenoptera_data'\n# Data normalization and augmentation transformations for train dataset\n# Only normalization transformation for validation dataset\n# The mean and std for normalization are calculated as the mean of all pixel values for all images in the training set per each image channel - R, G and B\ndata_transformers = {\n    'train': transforms.Compose([transforms.RandomResizedCrop(224), transforms.RandomHorizontalFlip(),\n                                    transforms.ToTensor(),\n                                    transforms.Normalize([0.490, 0.449, 0.411], [0.231, 0.221, 0.230])]),\n    'val': transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize([0.490, 0.449, 0.411], [0.231, 0.221, 0.230])])}\nimg_data = {k: datasets.ImageFolder(os.path.join(ddir, k), data_transformers[k]) for k in ['train', 'val']}\ndloaders = {k: torch.utils.data.DataLoader(img_data[k], batch_size=8, shuffle=True)\n            for k in ['train', 'val']}\ndset_sizes = {x: len(img_data[x]) for x in ['train', 'val']}\nclasses = img_data['train'].classes\ndvc = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n```", "```py\ndef imageshow(img, text=None):\n    img = img.numpy().transpose((1, 2, 0))\n    avg = np.array([0.490, 0.449, 0.411])\n    stddev = np.array([0.231, 0.221, 0.230])\n    img = stddev * img + avg\n    img = np.clip(img, 0, 1)\n    plt.imshow(img)\n    if text is not None:\n        plt.title(text)\n# Generate one train dataset batch\nimgs, cls = next(iter(dloaders['train']))\n# Generate a grid from batch\ngrid = torchvision.utils.make_grid(imgs)\nimageshow(grid, text=[classes[c] for c in cls])\n```", "```py\ndef finetune_model(pretrained_model, loss_func, optim, epochs=10):\n    ...\n    for e in range(epochs):\n        for dset in ['train', 'val']:\n            if dset == 'train':\n                pretrained_model.train()  # set model to train mode (i.e. trainbale weights)\n            else:\n                pretrained_model.eval()   # set model to validation mode\n            # iterate over the (training/validation) data.\n            for imgs, tgts in dloaders[dset]:\n                ...\n                optim.zero_grad()\n                with torch.set_grad_enabled(dset == 'train'):\n                    ops = pretrained_model(imgs)\n                    _, preds = torch.max(ops, 1)\n                    loss_curr = loss_func(ops, tgts)\n                    # backward pass only if in training mode\n                    if dset == 'train':\n                        loss_curr.backward()\n                        optim.step()\n                loss += loss_curr.item() * imgs.size(0)\n                successes += torch.sum(preds == tgts.data)\n            loss_epoch = loss / dset_sizes[dset]\n            accuracy_epoch = successes.double() / dset_sizes[dset]\n            if dset == 'val' and accuracy_epoch > accuracy:\n                accuracy = accuracy_epoch\n                model_weights = copy.deepcopy(pretrained_model.state_dict())\n    # load the best model version (weights)\n    pretrained_model.load_state_dict(model_weights)\n    return pretrained_model\n```", "```py\ndef visualize_predictions(pretrained_model, max_num_imgs=4):\n    was_model_training = pretrained_model.training\n    pretrained_model.eval()\n    imgs_counter = 0\n    fig = plt.figure()\n    with torch.no_grad():\n        for i, (imgs, tgts) in enumerate(dloaders['val']):\n            imgs = imgs.to(dvc)\n            tgts = tgts.to(dvc)\n            ops = pretrained_model(imgs)\n            _, preds = torch.max(ops, 1)\n             for j in range(imgs.size()[0]):\n                imgs_counter += 1\n                ax = plt.subplot(max_num_imgs//2, 2, imgs_counter)\n                ax.axis('off')\n                ax.set_title(f'Prediction: {class_names[preds[j]]}, Ground Truth: {class_names[tgts[j]]}')\n                imshow(inputs.cpu().data[j])\n                if imgs_counter == max_num_imgs:\npretrained_model.train(mode=was_training)\n                    return\n        model.train(mode=was_training)\n```", "```py\nmodel_finetune = models.alexnet(pretrained=True)\n```", "```py\nprint(model_finetune.features)\n```", "```py\nprint(model_finetune.classifier)\n```", "```py\n# change the last layer from 1000 classes to 2 classes\nmodel_finetune.classifier[6] = nn.Linear(4096, len(classes))\n```", "```py\nloss_func = nn.CrossEntropyLoss()\noptim_finetune = optim.SGD(model_finetune.parameters(), lr=0.0001)\n# train (fine-tune) and validate the model\nmodel_finetune = finetune_model(model_finetune, loss_func, optim_finetune, epochs=10)\n```", "```py\nvisualize_predictions(model_finetune)\n```", "```py\nimport ast\nwith open('./imagenet1000_clsidx_to_labels.txt') as f:\n    classes_data = f.read()\nclasses_dict = ast.literal_eval(classes_data)\nprint({k: classes_dict[k] for k in list(classes_dict)[:5]})\n```", "```py\nmodel_finetune = models.vgg13(pretrained=True)\n```", "```py\nvisualize_predictions(model_finetune)\n```", "```py\nclass InceptionModule(nn.Module):\n    def __init__(self, input_planes, n_channels1x1, n_channels3x3red, n_channels3x3, n_channels5x5red, n_channels5x5, pooling_planes):\n        super(InceptionModule, self).__init__()\n        # 1x1 convolution branch\n        self.block1 = nn.Sequential(\n            nn.Conv2d(input_planes, n_channels1x1, kernel_size=1),nn.BatchNorm2d(n_channels1x1),nn.ReLU(True),)\n        # 1x1 convolution -> 3x3 convolution branch\n        self.block2 = nn.Sequential(\n            nn.Conv2d(input_planes, n_channels3x3red, kernel_size=1),nn.BatchNorm2d(n_channels3x3red),\n            nn.ReLU(True),nn.Conv2d(n_channels3x3red, n_channels3x3, kernel_size=3, padding=1),nn.BatchNorm2d(n_channels3x3),nn.ReLU(True),)\n        # 1x1 conv -> 5x5 conv branch\n        self.block3 = nn.Sequential(\n            nn.Conv2d(input_planes, n_channels5x5red, kernel_size=1),nn.BatchNorm2d(n_channels5x5red),nn.ReLU(True),\n            nn.Conv2d(n_channels5x5red, n_channels5x5, kernel_size=3, padding=1),nn.BatchNorm2d(n_channels5x5),nn.ReLU(True),\n            nn.Conv2d(n_channels5x5, n_channels5x5, kernel_size=3, padding=1),nn.BatchNorm2d(n_channels5x5),\n            nn.ReLU(True),)\n        # 3x3 pool -> 1x1 conv branch\n        self.block4 = nn.Sequential(\n            nn.MaxPool2d(3, stride=1, padding=1),\n            nn.Conv2d(input_planes, pooling_planes, kernel_size=1),\n            nn.BatchNorm2d(pooling_planes),\n            nn.ReLU(True),)\n    def forward(self, ip):\n        op1 = self.block1(ip)\n        op2 = self.block2(ip)\n        op3 = self.block3(ip)\n        op4 = self.block4(ip)\n        return torch.cat([op1,op2,op3,op4], 1)\n```", "```py\nclass GoogLeNet(nn.Module):\n    def __init__(self):\n        super(GoogLeNet, self).__init__()\n        self.stem = nn.Sequential(\n            nn.Conv2d(3, 192, kernel_size=3, padding=1),\n            nn.BatchNorm2d(192),\n            nn.ReLU(True),)\n        self.im1 = InceptionModule(192,  64,  96, 128, 16, 32, 32)\n        self.im2 = InceptionModule(256, 128, 128, 192, 32, 96, 64)\n        self.max_pool = nn.MaxPool2d(3, stride=2, padding=1)\n        self.im3 = InceptionModule(480, 192,  96, 208, 16,  48,  64)\n        self.im4 = InceptionModule(512, 160, 112, 224, 24,  64,  64)\n        self.im5 = InceptionModule(512, 128, 128, 256, 24,  64,  64)\n        self.im6 = InceptionModule(512, 112, 144, 288, 32,  64,  64)\n        self.im7 = InceptionModule(528, 256, 160, 320, 32, 128, 128)\n        self.im8 = InceptionModule(832, 256, 160, 320, 32, 128, 128)\n        self.im9 = InceptionModule(832, 384, 192, 384, 48, 128, 128)\n        self.average_pool = nn.AvgPool2d(7, stride=1)\n        self.fc = nn.Linear(4096, 1000)\n    def forward(self, ip):\n        op = self.stem(ip)\n        out = self.im1(op)\n        out = self.im2(op)\n        op = self.maxpool(op)\n        op = self.a4(op)\n        op = self.b4(op)\n        op = self.c4(op)\n        op = self.d4(op)\n        op = self.e4(op)\n        op = self.max_pool(op)\n        op = self.a5(op)\n        op = self.b5(op)\n        op = self.avgerage_pool(op)\n        op = op.view(op.size(0), -1)\n        op = self.fc(op)\n        return op\n```", "```py\nimport torchvision.models as models\nmodel = models.googlenet(pretrained=True)\n```", "```py\nimport torchvision.models as models\nmodel = models.inception_v3(pretrained=True)\n```", "```py\nclass BasicBlock(nn.Module):\n    multiplier=1\n    def __init__(self, input_num_planes, num_planes, strd=1):\n        super(BasicBlock, self).__init__()\n        self.conv_layer1 = nn.Conv2d(in_channels=input_num_planes, out_channels=num_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.batch_norm1 = nn.BatchNorm2d(num_planes)\n        self.conv_layer2 = nn.Conv2d(in_channels=num_planes, out_channels=num_planes, kernel_size=3, stride=1, padding=1, bias=False)\n        self.batch_norm2 = nn.BatchNorm2d(num_planes)\n        self.res_connnection = nn.Sequential()\n        if strd > 1 or input_num_planes != self.multiplier*num_planes:\n            self.res_connnection = nn.Sequential(\n                nn.Conv2d(in_channels=input_num_planes, out_channels=self.multiplier*num_planes, kernel_size=1, stride=strd, bias=False),\n                nn.BatchNorm2d(self.multiplier*num_planes))\n    def forward(self, inp):\n        op = F.relu(self.batch_norm1(self.conv_layer1(inp)))\n        op = self.batch_norm2(self.conv_layer2(op))\n        op += self.res_connnection(inp)\n        op = F.relu(op)\n        return op\n```", "```py\nimport torchvision.models as models\nmodel = models.resnet50(pretrained=True)\n```", "```py\nclass DenseBlock(nn.Module):\n    def __init__(self, input_num_planes, rate_inc):\n        super(DenseBlock, self).__init__()\n        self.batch_norm1 = nn.BatchNorm2d(input_num_planes)\n        self.conv_layer1 = nn.Conv2d(in_channels=input_num_planes, out_channels=4*rate_inc, kernel_size=1, bias=False)\n        self.batch_norm2 = nn.BatchNorm2d(4*rate_inc)\n        self.conv_layer2 = nn.Conv2d(in_channels=4*rate_inc, out_channels=rate_inc, kernel_size=3, padding=1, bias=False)\n    def forward(self, inp):\n        op = self.conv_layer1(F.relu(self.batch_norm1(inp)))\n        op = self.conv_layer2(F.relu(self.batch_norm2(op)))\n        op = torch.cat([op,inp], 1)\n        return op\nclass TransBlock(nn.Module):\n    def __init__(self, input_num_planes, output_num_planes):\n        super(TransBlock, self).__init__()\n        self.batch_norm = nn.BatchNorm2d(input_num_planes)\n        self.conv_layer = nn.Conv2d(in_channels=input_num_planes, out_channels=output_num_planes, kernel_size=1, bias=False)\n    def forward(self, inp):\n        op = self.conv_layer(F.relu(self.batch_norm(inp)))\n        op = F.avg_pool2d(op, 2)\n        return op\n```", "```py\nimport torchvision.models as models\ndensenet121 = models.densenet121(pretrained=True)\ndensenet161 = models.densenet161(pretrained=True)\ndensenet169 = models.densenet169(pretrained=True)\ndensenet201 = models.densenet201(pretrained=True)\n```", "```py\nimport torchvision.models as models\nmodel = models.mnasnet1_0()\n```", "```py\nimport torchvision.models as models\nefficientnet_b0 = models.efficientnet_b0(pretrained=True)\nefficientnet_b1 = models.efficientnet_b1(pretrained=True)\n...\nefficientnet_b7 = models.efficientnet_b7(pretrained=True) \n```", "```py\nfaster_rcnn = models.detection.fasterrcnn_resnet50_fpn()\nmask_rcnn = models.detection.maskrcnn_resnet50_fpn()\nkeypoint_rcnn = models.detection.keypointrcnn_resnet50_fpn()\n```", "```py\nresnet_3d = models.video.r3d_18()\nresnet_mixed_conv = models.video.mc3_18()\n```"]