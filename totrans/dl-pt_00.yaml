- en: Preface
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: PyTorch is grabbing the attention of data science professionals and deep learning practitioners due
    to its flexibility and ease of use. This book introduces the fundamental building
    blocks of deep learning and PyTorch. It demonstrates how to solve real-world problems
    using a practical approach. You will also learn some of the modern architectures
    and techniques that are used to crack some cutting-edge research problems.
  prefs: []
  type: TYPE_NORMAL
- en: This book provides the intuition behind various state-of-the-art deep learning
    architectures, such as ResNet, DenseNet, Inception, and Seq2Seq, without diving
    deep into the math. It also shows how to do transfer learning, how to speed up
    transfer learning using pre-computed features, and how to do text classification
    using embeddings, pretrained embeddings, LSTM, and one-dimensional convolutions.
  prefs: []
  type: TYPE_NORMAL
- en: By the end of the book, you will be a proficient deep learning practitioner
    who will be able to solve some business problems using the different techniques
    learned here.
  prefs: []
  type: TYPE_NORMAL
- en: Who this book is for
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This book is for engineers, data analysts, and data scientists, interested in
    deep learning, and those looking to explore and implement advanced algorithms
    with PyTorch. Knowledge of machine learning is helpful but not mandatory. Knowledge
    of Python programming is expected.
  prefs: []
  type: TYPE_NORMAL
- en: What this book covers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Chapter 1](14abb16b-86be-4209-8a96-79da5268b8dd.xhtml), *Getting Started with
    Deep Learning Using PyTorch*, goes over the history of **artificial intelligence**
    (**AI**) and machine learning and looks at the recent growth of deep learning.
    We will also cover how various improvements in hardware and algorithms triggered
    huge success in the implementation of deep learning across different applications.
    Finally, we will introduce the beautiful PyTorch Python library, built on top
    of Torch by Facebook.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 2](5a68470a-8fdb-4dc8-9613-e38a9b4354d5.xhtml), *Building Blocks of
    Neural Networks*, discusses the knowledge of  various building blocks of PyTorch,
    such as variables, tensors, and `nn.module`, and how they are used to develop
    neural networks.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 3](1de63bb8-4140-4d2d-b93c-5b6bdc42ec03.xhtml), *Diving Deep into
    Neural Networks*, covers the different processes involved in training a neural
    network, such as the data preparation, data loaders for batching tensors, the
    `torch.nn` package for creating network architectures and the use of PyTorch loss
    functions and optimizers.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 4](821004b7-d246-4aac-b883-9ab634ae0aea.xhtml), *Fundamentals of Machine
    Learning*, covers different types of machine learning problems, along with challenges
    such as overfitting and underfitting. We also cover different techniques such
    as data augmentation, adding dropouts, and using batch normalization to prevent
    overfitting.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 5](3cce1bbe-6d1c-4164-b1ef-8b0688126519.xhtml), *Deep Learning for
    Computer Vision*, explains the building blocks of **Convolutional Neural Networks**
    (**CNNs**), such as one-dimensional and two-dimensional convolutions, max pooling,
    average pooling, basic CNN architectures, transfer learning, and using pre-convoluted
    features to train faster.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 6](64a06d7f-a912-46cd-a059-e0e8e1092b63.xhtml), *Deep Learning with
    Sequence Data and Text*, covers word embeddings, how to use pretrained embeddings,
    RNN, LSTM, and one-dimensional convolutions for text classification on the `IMDB`
    dataset.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 7](dc189b2e-5166-41a5-8203-aff8b367b53c.xhtml), *Generative Networks*,
    explains how to use deep learning to generate artistic images, new images with
    DCGAN, and text using language modeling.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 8](dc1e2ceb-37b3-423c-9fd7-ff8e7da24fe6.xhtml), *Modern Network Architectures*,
    explores architectures such as ResNet, Inception, and DenseNet that power modern
    computer vision applications. We will have a quick introduction to encoder-decoder architectures
    that power modern systems such as language translations and image captioning.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 9](59c98b2f-bbac-4ddf-bf4e-3223f222f6c1.xhtml), *What Next?*, looks
    into the summarizes what we have learned and looks at keeping yourself updated
    in the field of deep learning.'
  prefs: []
  type: TYPE_NORMAL
- en: To get the most out of this book
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: All the chapters (except [Chapter 1](14abb16b-86be-4209-8a96-79da5268b8dd.xhtml), *Getting
    Started with Deep Learning Using PyTorch* and [Chapter 9](59c98b2f-bbac-4ddf-bf4e-3223f222f6c1.xhtml),
    *What Next*) have associated Jupyter Notebooks in the book's GitHub repository.
    The imports required for the code to run may not be included in the text to save
    space. You should be able to run all of the code from the Notebooks.
  prefs: []
  type: TYPE_NORMAL
- en: The book focuses on practical illustrations, so run the Jupyter Notebooks as
    you read the chapters.
  prefs: []
  type: TYPE_NORMAL
- en: Access to a computer with a GPU will help run the code quickly. There are companies
    such as [paperspace.com](https://www.paperspace.com/) and [www.crestle.com](https://www.crestle.com/) that
    abstract a lot of the complexity required to run deep learning algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Download the example code files
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can download the example code files for this book from your account at [www.packtpub.com](http://www.packtpub.com).
    If you purchased this book elsewhere, you can visit [www.packtpub.com/support](http://www.packtpub.com/support)
    and register to have the files emailed directly to you.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can download the code files by following these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Log in or register at [www.packtpub.com](http://www.packtpub.com/support).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the SUPPORT tab.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on Code Downloads & Errata.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Enter the name of the book in the Search box and follow the onscreen instructions.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Once the file is downloaded, please make sure that you unzip or extract the
    folder using the latest version of:'
  prefs: []
  type: TYPE_NORMAL
- en: WinRAR/7-Zip for Windows
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zipeg/iZip/UnRarX for Mac
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 7-Zip/PeaZip for Linux
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The code bundle for the book is also hosted on GitHub at [https://github.com/PacktPublishing/Deep-Learning-with-PyTorch](https://github.com/PacktPublishing/Deep-Learning-with-PyTorch). In
    case there's an update to the code, it will be updated on the existing GitHub
    repository.
  prefs: []
  type: TYPE_NORMAL
- en: We also have other code bundles from our rich catalog of books and videos available
    at **[https://github.com/PacktPublishing/](https://github.com/PacktPublishing/)**.
    Check them out!
  prefs: []
  type: TYPE_NORMAL
- en: Download the color images
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We also provide a PDF file that has color images of the screenshots/diagrams
    used in this book. You can download it here: [https://www.packtpub.com/sites/default/files/downloads/DeepLearningwithPyTorch_ColorImages.pdf](https://www.packtpub.com/sites/default/files/downloads/DeepLearningwithPyTorch_ColorImages.pdf)
  prefs: []
  type: TYPE_NORMAL
- en: Conventions used
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are a number of text conventions used throughout this book.
  prefs: []
  type: TYPE_NORMAL
- en: '`CodeInText`: Indicates code words in text, database table names, folder names,
    filenames, file extensions, pathnames, dummy URLs, user input, and Twitter handles.
    Here is an example: "The custom class has to implement two main functions, namely `__len__(self)` and `__getitem__(self,
    idx)`."'
  prefs: []
  type: TYPE_NORMAL
- en: 'A block of code is set as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Any command-line input or output is written as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '**Bold**: Indicates a new term, an important word, or words that you see onscreen.'
  prefs: []
  type: TYPE_NORMAL
- en: Warnings or important notes appear like this.
  prefs: []
  type: TYPE_NORMAL
- en: Tips and tricks appear like this.
  prefs: []
  type: TYPE_NORMAL
- en: Get in touch
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Feedback from our readers is always welcome.
  prefs: []
  type: TYPE_NORMAL
- en: '**General feedback**: Email `feedback@packtpub.com` and mention the book title
    in the subject of your message. If you have questions about any aspect of this
    book, please email us at `questions@packtpub.com`.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Errata**: Although we have taken every care to ensure the accuracy of our
    content, mistakes do happen. If you have found a mistake in this book, we would
    be grateful if you would report this to us. Please visit [www.packtpub.com/submit-errata](http://www.packtpub.com/submit-errata),
    selecting your book, clicking on the Errata Submission Form link, and entering
    the details.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Piracy**: If you come across any illegal copies of our works in any form
    on the Internet, we would be grateful if you would provide us with the location
    address or website name. Please contact us at `copyright@packtpub.com` with a
    link to the material.'
  prefs: []
  type: TYPE_NORMAL
- en: '**If you are interested in becoming an author**: If there is a topic that you
    have expertise in and you are interested in either writing or contributing to
    a book, please visit [authors.packtpub.com](http://authors.packtpub.com/).'
  prefs: []
  type: TYPE_NORMAL
- en: Reviews
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Please leave a review. Once you have read and used this book, why not leave
    a review on the site that you purchased it from? Potential readers can then see
    and use your unbiased opinion to make purchase decisions, we at Packt can understand
    what you think about our products, and our authors can see your feedback on their
    book. Thank you!
  prefs: []
  type: TYPE_NORMAL
- en: For more information about Packt, please visit [packtpub.com](https://www.packtpub.com/).
  prefs: []
  type: TYPE_NORMAL
