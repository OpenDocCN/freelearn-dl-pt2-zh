- en: Preface
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Hello there! I’m a system analyst and academic professor specializing in **High-Performance
    Computing** (**HPC**). Yes, you read it right! I’m not a data scientist. So, you
    are probably wondering why on Earth I decided to write a book about machine learning.
    Don’t worry; I will explain.
  prefs: []
  type: TYPE_NORMAL
- en: HPC systems comprise powerful computing resources tightly integrated to solve
    complex problems. The main goal of HPC is to employ resources, techniques, and
    methods to accelerate the execution of highly intensive computing tasks. Traditionally,
    HPC environments have been used to execute scientific applications from biology,
    physics, chemistry, and many other areas.
  prefs: []
  type: TYPE_NORMAL
- en: 'But this has changed in the past few years. Nowadays, HPC systems run tasks
    beyond scientific applications. In fact, the most prominent non-scientific workload
    executed in HPC environments is precisely the subject of this book: the building
    process of complex neural network models.'
  prefs: []
  type: TYPE_NORMAL
- en: As a data scientist, you know better than anyone else how long it could take
    to train complex models and how many times you need to retrain the model to evaluate
    different scenarios. For this reason, the usage of HPC systems to accelerate **Artificial
    Intelligence** (**AI**) applications (not only for training but also for inference)
    is a growth-demanding area.
  prefs: []
  type: TYPE_NORMAL
- en: This close relationship between AI and HPC sparked my interest in diving into
    the fields of machine learning and AI. By doing this, I could better understand
    how HPC has been applied to accelerate these applications.
  prefs: []
  type: TYPE_NORMAL
- en: So, here we are. I wrote this book to share what I have learned about this topic.
    My mission here is to give you the necessary knowledge to train your model faster
    by employing optimization techniques and methods using single or multiple computing
    resources.
  prefs: []
  type: TYPE_NORMAL
- en: 'By accelerating the training process, you can concentrate on what really matters:
    building stunning models!'
  prefs: []
  type: TYPE_NORMAL
- en: Who this book is for
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This book is for intermediate-level data scientists, engineers, and developers
    who want to know how to use PyTorch to accelerate the training process of their
    machine learning models. Although they are not the primary audience for this material,
    system analysts responsible for administrating and providing infrastructure for
    AI workloads will also find valuable information in this book.
  prefs: []
  type: TYPE_NORMAL
- en: Basic knowledge of machine learning, PyTorch, and Python is required to get
    the most out of this material. However, there is no obligation to have a prior
    understanding of distributed computing, accelerators, or multicore processors.
  prefs: []
  type: TYPE_NORMAL
- en: What this book covers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[*Chapter 1*](B20959_01.xhtml#_idTextAnchor016), *Deconstructing the Training
    Process*, provides an overview of how the training process works under the hood,
    describing the training algorithm and covering the phases executed by this process.
    This chapter also explains how factors such as hyperparameters, operations, and
    neural network parameters impact the training process’s computational burden.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 2*](B20959_02.xhtml#_idTextAnchor028), *Training Models Faster*,
    provides an overview of the possible approaches to accelerate the training process.
    This chapter discusses how to modify the application and environment layers of
    the software stack to reduce the training time. Moreover, it explains vertical
    and horizontal scalability as another option to improve performance by increasing
    the number of resources.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 3*](B20959_03.xhtml#_idTextAnchor044), *Compiling the Model*, provides
    an overview of the novel Compile API introduced on PyTorch 2.0\. This chapter
    covers the differences between eager and graph modes and describes how to use
    the Compile API to accelerate the model-building process. This chapter also explains
    the compiling workflow and components involved in the compiling process.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 4*](B20959_04.xhtml#_idTextAnchor060), *Using Specialized Libraries*,
    provides an overview of the libraries used by PyTorch to execute specialized tasks.
    This chapter describes how to install and configure OpenMP to deal with multithreading
    and IPEX to optimize the training process on an Intel CPU.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 5*](B20959_05.xhtml#_idTextAnchor072), *Building an Efficient Data
    Pipeline*, provides an overview of how to build an efficient data pipeline to
    keep the GPU working as much as possible. Besides explaining the steps executed
    on the data pipeline, this chapter describes how to accelerate the data-loading
    process by optimizing GPU data transfer and increasing the number of workers on
    the data pipeline.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 6*](B20959_06.xhtml#_idTextAnchor085), *Simplifying the Model*, provides
    an overview of how to simplify a model by reducing the number of parameters of
    the neural network without sacrificing the model’s quality. This chapter describes
    techniques used to reduce the model complexity, such as model pruning and compression,
    and explains how to use the Microsoft NNI toolkit to simplify a model easily.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 7*](B20959_07.xhtml#_idTextAnchor098), *Adopting Mixed Precision*,
    provides an overview of how to adopt a mixed precision strategy to burst the model
    training process without penalizing the model’s accuracy. This chapter briefly
    explains numeric representation in computer systems and describes how to employ
    PyTorch’s automatic mixed precision approach.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 8*](B20959_08.xhtml#_idTextAnchor117), *Distributed Training at a
    Glance*, provides an overview of the basic concepts of distributed training. This
    chapter presents the most adopted parallel strategies and describes the basic
    workflow to implement distributed training on PyTorch.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 9*](B20959_09.xhtml#_idTextAnchor132), *Training with Multiple CPUs*,
    provides an overview of how to code and execute distributed training in multiple
    CPUs on a single machine using a general approach and Intel oneCCL to optimize
    the execution on Intel platforms.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 10*](B20959_10.xhtml#_idTextAnchor149), *Training with Multiple GPUs*,
    provides an overview of how to code and execute distributed training in a multi-GPU
    environment on a single machine. This chapter presents the main characteristics
    of a multi-GPU environment and explains how to code and launch distributed training
    on multiple GPUs using NCCL, the default communication backend for NVIDIA GPUs.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 11*](B20959_11.xhtml#_idTextAnchor167), *Training with Multiple Machines*,
    provides an overview of how to code and execute distributed training in multiple
    GPUs on multiple machines. Besides an introductory explanation of computing clusters,
    this chapter shows how to code and launch distributed training among multiple
    machines using Open MPI as the launcher and NCCL as the communication backend.'
  prefs: []
  type: TYPE_NORMAL
- en: To get the most out of this book
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You will need to have an understanding of the basics of machine learning, PyTorch,
    and Python.
  prefs: []
  type: TYPE_NORMAL
- en: '| **Software/hardware covered in** **the book** | **Operating** **system requirements**
    |'
  prefs: []
  type: TYPE_TB
- en: '| PyTorch 2.X | Windows, Linux, or macOS |'
  prefs: []
  type: TYPE_TB
- en: If you are using the digital version of this book, we advise you to type the
    code yourself or access the code from the book’s GitHub repository (a link is
    available in the next section). Doing so will help you avoid any potential errors
    related to the copying and pasting of code.
  prefs: []
  type: TYPE_NORMAL
- en: Download the example code files
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can download the example code files for this book from GitHub at [https://github.com/PacktPublishing/Accelerate-Model-Training-with-PyTorch-2.X](https://github.com/PacktPublishing/Accelerate-Model-Training-with-PyTorch-2.X).
    If there’s an update to the code, it will be updated in the GitHub repository.
  prefs: []
  type: TYPE_NORMAL
- en: We also have other code bundles from our rich catalog of books and videos available
    at [https://github.com/PacktPublishing/](https://github.com/PacktPublishing/).
    Check them out!
  prefs: []
  type: TYPE_NORMAL
- en: Conventions used
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are a number of text conventions used throughout this book.
  prefs: []
  type: TYPE_NORMAL
- en: '`Code in text`: Indicates code words in text, database table names, folder
    names, filenames, file extensions, pathnames, dummy URLs, user input, and Twitter
    handles. Here is an example: “The `ipex.optimize` function returns an optimized
    version of the model.”'
  prefs: []
  type: TYPE_NORMAL
- en: 'A block of code is set as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'When we wish to draw your attention to a particular part of a code block, the
    relevant lines or items are set in bold:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Any command-line input or output is written as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '**Bold**: Indicates a new term, an important word, or words that you see onscreen.
    For instance, words in menus or dialog boxes appear in **bold**. Here is an example:
    “**OpenMP** is a library used for parallelizing tasks by harnessing all the power
    of multicore processors by using the multithreading technique.”'
  prefs: []
  type: TYPE_NORMAL
- en: Tips or important notes
  prefs: []
  type: TYPE_NORMAL
- en: Appear like this.
  prefs: []
  type: TYPE_NORMAL
- en: Get in touch
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Feedback from our readers is always welcome.
  prefs: []
  type: TYPE_NORMAL
- en: '**General feedback**: If you have questions about any aspect of this book,
    email us at [customercare@packtpub.com](mailto:customercare@packtpub.com) and
    mention the book title in the subject of your message.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Errata**: Although we have taken every care to ensure the accuracy of our
    content, mistakes do happen. If you have found a mistake in this book, we would
    be grateful if you would report this to us. Please visit [www.packtpub.com/support/errata](http://www.packtpub.com/support/errata)
    and fill in the form.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Piracy**: If you come across any illegal copies of our works in any form
    on the internet, we would be grateful if you would provide us with the location
    address or website name. Please contact us at [copyright@packt.com](mailto:copyright@packt.com)
    with a link to the material.'
  prefs: []
  type: TYPE_NORMAL
- en: '**If you are interested in becoming an author**: If there is a topic that you
    have expertise in and you are interested in either writing or contributing to
    a book, please visit [authors.packtpub.com](http://authors.packtpub.com).'
  prefs: []
  type: TYPE_NORMAL
- en: Share Your Thoughts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once you’ve read *Accelerate Model Training with PyTorch 2.X*, we’d love to
    hear your thoughts! Please [click here to go straight to the Amazon review page](https://packt.link/r/1-805-12010-7)
    for this book and share your feedback.
  prefs: []
  type: TYPE_NORMAL
- en: Your review is important to us and the tech community and will help us make
    sure we’re delivering excellent quality content.
  prefs: []
  type: TYPE_NORMAL
- en: Download a free PDF copy of this book
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Thanks for purchasing this book!
  prefs: []
  type: TYPE_NORMAL
- en: Do you like to read on the go but are unable to carry your print books everywhere?
  prefs: []
  type: TYPE_NORMAL
- en: Is your eBook purchase not compatible with the device of your choice?
  prefs: []
  type: TYPE_NORMAL
- en: Don’t worry, now with every Packt book you get a DRM-free PDF version of that
    book at no cost.
  prefs: []
  type: TYPE_NORMAL
- en: Read anywhere, any place, on any device. Search, copy, and paste code from your
    favorite technical books directly into your application.
  prefs: []
  type: TYPE_NORMAL
- en: The perks don’t stop there, you can get exclusive access to discounts, newsletters,
    and great free content in your inbox daily
  prefs: []
  type: TYPE_NORMAL
- en: 'Follow these simple steps to get the benefits:'
  prefs: []
  type: TYPE_NORMAL
- en: Scan the QR code or visit the link below
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B20959_QR_Free_PDF.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[https://packt.link/free-ebook/978-1-80512-010-0](https://packt.link/free-ebook/978-1-80512-010-0)'
  prefs: []
  type: TYPE_NORMAL
- en: Submit your proof of purchase
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: That’s it! We’ll send your free PDF and other benefits to your email directly
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
