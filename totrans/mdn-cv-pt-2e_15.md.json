["```py\n    !pip install -q torch_snippets\n    from torch_snippets import *\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    from torchvision.utils import make_grid \n    ```", "```py\n    from torchvision.datasets import MNIST\n    from torchvision import transforms\n    transform = transforms.Compose([\n                    transforms.ToTensor(),\n                    transforms.Normalize(mean=(0.5,), std=(0.5,))\n            ])\n    data_loader = torch.utils.data.DataLoader(MNIST('~/data', \\\n                           train=True, download=True, transform=transform), \\\n                           batch_size=128, shuffle=True, drop_last=True) \n    ```", "```py\n    class Discriminator(nn.Module):\n        def __init__(self):\n            super().__init__()\n            self.model = nn.Sequential( \n                                    nn.Linear(784, 1024),\n                                    nn.LeakyReLU(0.2),\n                                    nn.Dropout(0.3),\n                                    nn.Linear(1024, 512),\n                                    nn.LeakyReLU(0.2),\n                                    nn.Dropout(0.3),\n                                    nn.Linear(512, 256),\n                                    nn.LeakyReLU(0.2),\n                                    nn.Dropout(0.3),\n                                    nn.Linear(256, 1),\n                                    nn.Sigmoid()\n                                )\n        def forward(self, x): return self.model(x) \n    ```", "```py\n    !pip install torch_summary\n    from torchsummary import summary\n    discriminator = Discriminator().to(device)\n    summary(discriminator,torch.zeros(1,784)) \n    ```", "```py\n    class Generator(nn.Module):\n        def __init__(self):\n            super().__init__()\n            self.model = nn.Sequential(\n                                    nn.Linear(100, 256),\n                                    nn.LeakyReLU(0.2),\n                                    nn.Linear(256, 512),\n                                    nn.LeakyReLU(0.2),\n                                    nn.Linear(512, 1024),\n                                    nn.LeakyReLU(0.2),\n                                    nn.Linear(1024, 784),\n                                    nn.Tanh()\n                                )\n        def forward(self, x): return self.model(x) \n    ```", "```py\n    generator = Generator().to(device)\n    summary(generator,torch.zeros(1,100)) \n    ```", "```py\n    def noise(size):\n        n = torch.randn(size, 100)\n        return n.to(device) \n    ```", "```py\n    def discriminator_train_step(real_data, fake_data): \n    ```", "```py\n     d_optimizer.zero_grad() \n    ```", "```py\n     prediction_real = discriminator(real_data)\n            error_real = loss(prediction_real, \\\n                              torch.ones(len(real_data),1).to(device))\n            error_real.backward() \n    ```", "```py\n     prediction_fake = discriminator(fake_data)\n            error_fake = loss(prediction_fake, \\\n                        torch.zeros(len(fake_data),1).to(device))\n            error_fake.backward() \n    ```", "```py\n     d_optimizer.step()\n            return error_real + error_fake \n    ```", "```py\n    def generator_train_step(fake_data): \n    ```", "```py\n     g_optimizer.zero_grad() \n    ```", "```py\n     prediction = discriminator(fake_data) \n    ```", "```py\n     error = loss(prediction, torch.ones(len(real_data),1).to(device)) \n    ```", "```py\n     error.backward()\n        g_optimizer.step()\n        return error \n    ```", "```py\n    discriminator = Discriminator().to(device)\n    generator = Generator().to(device)\n    d_optimizer= optim.Adam(discriminator.parameters(),lr=0.0002)\n    g_optimizer = optim.Adam(generator.parameters(), lr=0.0002)\n    loss = nn.BCELoss()\n    num_epochs = 200\n    log = Report(num_epochs) \n    ```", "```py\n    for epoch in range(num_epochs):\n        N = len(data_loader)\n        for i, (images, _) in enumerate(data_loader): \n    ```", "```py\n     real_data = images.view(len(images), -1).to(device)\n            fake_data=generator(noise(len(real_data))).to(device)\n            fake_data = fake_data.detach() \n    ```", "```py\n     d_loss=discriminator_train_step(real_data, fake_data) \n    ```", "```py\n     fake_data=generator(noise(len(real_data))).to(device)\n            g_loss = generator_train_step(fake_data) \n    ```", "```py\n     log.record(epoch+(1+i)/N, d_loss=d_loss.item(), \\\n                       g_loss=g_loss.item(), end='\\r')\n        log.report_avgs(epoch+1)\n    log.plot_epochs(['d_loss', 'g_loss']) \n    ```", "```py\n    z = torch.randn(64, 100).to(device)\n    sample_images = generator(z).data.cpu().view(64, 1, 28, 28)\n    grid = make_grid(sample_images, nrow=8, normalize=True)\n    show(grid.cpu().detach().permute(1,2,0), sz=5) \n    ```", "```py\n    !wget https://www.dropbox.com/s/rbajpdlh7efkdo1/male_female_face_images.zip\n    !unzip male_female_face_images.zip \n    ```", "```py\n    !pip install -q --upgrade torch_snippets\n    from torch_snippets import *\n    import torchvision\n    from torchvision import transforms\n    import torchvision.utils as vutils\n    import cv2, numpy as np, pandas as pd\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\" \n    ```", "```py\n    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \\\n                            'haarcascade_frontalface_default.xml') \n    ```", "```py\n    !mkdir cropped_faces\n    images = Glob('/content/females/*.jpg') + \\\n                Glob('/content/males/*.jpg')\n    for i in range(len(images)):\n        img = read(images[i],1)\n        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n        faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n        for (x,y,w,h) in faces:\n            img2 = img[y:(y+h),x:(x+w),:]\n        cv2.imwrite('cropped_faces/'+str(i)+'.jpg', \\\n                    cv2.cvtColor(img2, cv2.COLOR_RGB2BGR)) \n    ```", "```py\n    transform=transforms.Compose([\n                                   transforms.Resize(64),\n                                   transforms.CenterCrop(64),\n                                   transforms.ToTensor(),\n        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) \n    ```", "```py\n    class Faces(Dataset):\n        def __init__(self, folder):\n            super().__init__()\n            self.folder = folder\n            self.images = sorted(Glob(folder))\n        def __len__(self):\n            return len(self.images)\n        def __getitem__(self, ix):\n            image_path = self.images[ix]\n            image = Image.open(image_path)\n            image = transform(image)\n            return image \n    ```", "```py\n    ds = Faces(folder='cropped_faces/') \n    ```", "```py\n    dataloader = DataLoader(ds, batch_size=64, shuffle=True, num_workers=8) \n    ```", "```py\n    def weights_init(m):\n        classname = m.__class__.__name__\n        if classname.find('Conv') != -1:\n            nn.init.normal_(m.weight.data, 0.0, 0.02)\n        elif classname.find('BatchNorm') != -1:\n            nn.init.normal_(m.weight.data, 1.0, 0.02)\n            nn.init.constant_(m.bias.data, 0) \n    ```", "```py\n    class Discriminator(nn.Module):\n        def __init__(self):\n            super(Discriminator, self).__init__()\n            self.model = nn.Sequential(\n                nn.Conv2d(3,64,4,2,1,bias=False),\n                nn.LeakyReLU(0.2,inplace=True),\n                nn.Conv2d(64,64*2,4,2,1,bias=False),\n                nn.BatchNorm2d(64*2),\n                nn.LeakyReLU(0.2,inplace=True),\n                nn.Conv2d(64*2,64*4,4,2,1,bias=False),\n                nn.BatchNorm2d(64*4),\n                nn.LeakyReLU(0.2,inplace=True),\n                nn.Conv2d(64*4,64*8,4,2,1,bias=False),\n                nn.BatchNorm2d(64*8),\n                nn.LeakyReLU(0.2,inplace=True),\n                nn.Conv2d(64*8,1,4,1,0,bias=False),\n                nn.Sigmoid()\n            )\n            self.apply(weights_init)\n        def forward(self, input): return self.model(input) \n    ```", "```py\n    !pip install torch_summary\n    from torchsummary import summary\n    discriminator = Discriminator().to(device)\n    summary(discriminator,torch.zeros(1,3,64,64)); \n    ```", "```py\n    class Generator(nn.Module):\n        def __init__(self):\n            super(Generator,self).__init__()\n            self.model = nn.Sequential(\n                nn.ConvTranspose2d(100,64*8,4,1,0,bias=False,),\n                nn.BatchNorm2d(64*8),\n                nn.ReLU(True),\n                nn.ConvTranspose2d(64*8,64*4,4,2,1,bias=False),\n                nn.BatchNorm2d(64*4),\n                nn.ReLU(True),\n                nn.ConvTranspose2d( 64*4,64*2,4,2,1,bias=False),\n                nn.BatchNorm2d(64*2),\n                nn.ReLU(True),\n                nn.ConvTranspose2d( 64*2,64,4,2,1,bias=False),\n                nn.BatchNorm2d(64),\n                nn.ReLU(True),\n                nn.ConvTranspose2d( 64,3,4,2,1,bias=False),\n                nn.Tanh()\n            )\n            self.apply(weights_init)\n        def forward(self,input): return self.model(input) \n    ```", "```py\n    generator = Generator().to(device)\n    summary(generator,torch.zeros(1,100,1,1)) \n    ```", "```py\n    def discriminator_train_step(real_data, fake_data):\n        d_optimizer.zero_grad()\n        prediction_real = discriminator(real_data)\n        error_real = loss(prediction_real.squeeze(), \\\n                          torch.ones(len(real_data)).to(device))\n        error_real.backward()\n        prediction_fake = discriminator(fake_data)\n        error_fake = loss(prediction_fake.squeeze(), \\\n                          torch.zeros(len(fake_data)).to(device))\n        error_fake.backward()\n        d_optimizer.step()\n        return error_real + error_fake\n    def generator_train_step(fake_data):\n        g_optimizer.zero_grad()\n        prediction = discriminator(fake_data)\n        error = loss(prediction.squeeze(), \\\n                     torch.ones(len(real_data)).to(device))\n        error.backward()\n        g_optimizer.step()\n        return error \n    ```", "```py\n    discriminator = Discriminator().to(device)\n    generator = Generator().to(device)\n    loss = nn.BCELoss()\n    d_optimizer = optim.Adam(discriminator.parameters(), \\\n                             lr=0.0002, betas=(0.5, 0.999))\n    g_optimizer = optim.Adam(generator.parameters(), \\\n                             lr=0.0002, betas=(0.5, 0.999)) \n    ```", "```py\n    log = Report(25)\n    for epoch in range(25):\n        N = len(dataloader)\n        for i, images in enumerate(dataloader): \n    ```", "```py\n     real_data = images.to(device)\n            fake_data = generator(torch.randn(len(real_data), 100, 1, \\\n                                        1).to(device)).to(device)\n            fake_data = fake_data.detach() \n    ```", "```py\n    d_loss=discriminator_train_step(real_data, fake_data) \n    ```", "```py\n    fake_data = generator(torch.randn(len(real_data), \\\n                        100, 1, 1).to(device)).to(device)\n    g_loss = generator_train_step(fake_data) \n    ```", "```py\n     log.record(epoch+(1+i)/N, d_loss=d_loss.item(), \\\n                       g_loss=g_loss.item(), end='\\r')\n      log.report_avgs(epoch+1)\n    log.plot_epochs(['d_loss','g_loss']) \n    ```", "```py\ngenerator.eval()\nnoise = torch.randn(64, 100, 1, 1, device=device)\nsample_images = generator(noise).detach().cpu()\ngrid = vutils.make_grid(sample_images,nrow=8,normalize=True)\nshow(grid.cpu().detach().permute(1,2,0), sz=10, \\\n     title='Generated images') \n```", "```py\n    !wget https://www.dropbox.com/s/rbajpdlh7efkdo1/male_female_face_images.zip\n    !unzip male_female_face_images.zip\n    !pip install -q --upgrade torch_snippets\n    from torch_snippets import *\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    from torchvision.utils import make_grid\n    from torch_snippets import *\n    from PIL import Image\n    import torchvision\n    from torchvision import transforms\n    import torchvision.utils as vutils \n    ```", "```py\n    female_images = Glob('/content/females/*.jpg')\n    male_images = Glob('/content/males/*.jpg') \n    ```", "```py\n    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \\\n                            'haarcascade_frontalface_default.xml') \n    ```", "```py\n    !mkdir cropped_faces_females\n    !mkdir cropped_faces_males\n    def crop_images(folder):\n        images = Glob(folder+'/*.jpg')\n        for i in range(len(images)):\n            img = read(images[i],1)\n            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n            faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n            for (x,y,w,h) in faces:\n                img2 = img[y:(y+h),x:(x+w),:]\n                cv2.imwrite('cropped_faces_'+folder+'/'+ \\\n                        str(i)+'.jpg',cv2.cvtColor(img2, cv2.COLOR_RGB2BGR))\n    crop_images('females')\n    crop_images('males') \n    ```", "```py\n    transform=transforms.Compose([\n                                   transforms.Resize(64),\n                                   transforms.CenterCrop(64),\n                                   transforms.ToTensor(),\n        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) \n    ```", "```py\n    class Faces(Dataset):\n        def __init__(self, folders):\n            super().__init__()\n            self.folderfemale = folders[0]\n            self.foldermale = folders[1]\n            self.images = sorted(Glob(self.folderfemale)) + \\\n                            sorted(Glob(self.foldermale))\n        def __len__(self):\n            return len(self.images)\n        def __getitem__(self, ix):\n            image_path = self.images[ix]\n            image = Image.open(image_path)\n            image = transform(image)\n            gender = np.where('female' in image_path,1,0)\n            return image, torch.tensor(gender).long() \n    ```", "```py\n    ds = Faces(folders=['cropped_faces_females', \\\n                        'cropped_faces_males'])\n    dataloader = DataLoader(ds, batch_size=64, \\\n                            shuffle=True, num_workers=8) \n    ```", "```py\n    def weights_init(m):\n        classname = m.__class__.__name__\n        if classname.find('Conv') != -1:\n            nn.init.normal_(m.weight.data, 0.0, 0.02)\n        elif classname.find('BatchNorm') != -1:\n            nn.init.normal_(m.weight.data, 1.0, 0.02)\n            nn.init.constant_(m.bias.data, 0) \n    ```", "```py\n    class Discriminator(nn.Module):\n        def __init__(self, emb_size=32):\n            super(Discriminator, self).__init__()\n            self.emb_size = 32\n            self.label_embeddings = nn.Embedding(2, self.emb_size)\n            self.model = nn.Sequential(\n                nn.Conv2d(3,64,4,2,1,bias=False),\n                nn.LeakyReLU(0.2,inplace=True),\n                nn.Conv2d(64,64*2,4,2,1,bias=False),\n                nn.BatchNorm2d(64*2),\n                nn.LeakyReLU(0.2,inplace=True),\n                nn.Conv2d(64*2,64*4,4,2,1,bias=False),\n                nn.BatchNorm2d(64*4),\n                nn.LeakyReLU(0.2,inplace=True),\n                nn.Conv2d(64*4,64*8,4,2,1,bias=False),\n                nn.BatchNorm2d(64*8),\n                nn.LeakyReLU(0.2,inplace=True),\n                nn.Conv2d(64*8,64,4,2,1,bias=False),\n                nn.BatchNorm2d(64),\n                nn.LeakyReLU(0.2,inplace=True),\n                nn.Flatten()\n            )\n            self.model2 = nn.Sequential(\n                nn.Linear(288,100),\n                nn.LeakyReLU(0.2,inplace=True),\n                nn.Linear(100,1),\n                nn.Sigmoid()\n            )\n            self.apply(weights_init) \n    ```", "```py\n    def forward(self, input, labels):\n        x = self.model(input)\n        y = self.label_embeddings(labels)\n        input = torch.cat([x, y], 1)\n        final_output = self.model2(input)\n        return final_output \n    ```", "```py\n    !pip install torch_summary\n    from torchsummary import summary\n    discriminator = Discriminator().to(device)\n    summary(discriminator,torch.zeros(32,3,64,64).to(device), \\\n            torch.zeros(32).long().to(device)); \n    ```", "```py\n    class Generator(nn.Module):\n        def __init__(self, emb_size=32):\n            super(Generator,self).__init__()\n            self.emb_size = emb_size\n            self.label_embeddings = nn.Embedding(2, self.emb_size) \n    ```", "```py\n     self.model = nn.Sequential(\n                nn.ConvTranspose2d(100+self.emb_size,\\\n                                   64*8,4,1,0,bias=False),\n                nn.BatchNorm2d(64*8),\n                nn.ReLU(True),\n                nn.ConvTranspose2d(64*8,64*4,4,2,1,bias=False),\n                nn.BatchNorm2d(64*4),\n                nn.ReLU(True),\n                nn.ConvTranspose2d(64*4,64*2,4,2,1,bias=False),\n                nn.BatchNorm2d(64*2),\n                nn.ReLU(True),\n                nn.ConvTranspose2d(64*2,64,4,2,1,bias=False),\n                nn.BatchNorm2d(64),\n                nn.ReLU(True),\n                nn.ConvTranspose2d(64,3,4,2,1,bias=False),\n                nn.Tanh()\n            ) \n    ```", "```py\n     self.apply(weights_init) \n    ```", "```py\n    def forward(self,input_noise,labels):\n        label_embeddings = self.label_embeddings(labels).view(len(labels), \\\n                                  self.emb_size,1, 1)\n        input = torch.cat([input_noise, label_embeddings], 1)\n        return self.model(input) \n    ```", "```py\n    generator = Generator().to(device)\n    summary(generator,torch.zeros(32,100,1,1).to(device), \\\n            torch.zeros(32).long().to(device)); \n    ```", "```py\n    def noise(size):\n        n = torch.randn(size, 100, 1, 1, device=device)\n        return n.to(device) \n    ```", "```py\n    def discriminator_train_step(real_data, real_labels, \\\n                                 fake_data, fake_labels):\n        d_optimizer.zero_grad() \n    ```", "```py\n    prediction_real = discriminator(real_data, real_labels)\n    error_real = loss(prediction_real, \\\n                      torch.ones(len(real_data),1).to(device))\n    error_real.backward() \n    ```", "```py\n    prediction_fake = discriminator(fake_data, fake_labels)\n    error_fake = loss(prediction_fake, \\\n                    torch.zeros(len(fake_data),1).to(device))\n    error_fake.backward() \n    ```", "```py\n    d_optimizer.step()    \n    return error_real + error_fake \n    ```", "```py\n    def generator_train_step(fake_data, fake_labels):\n        g_optimizer.zero_grad()\n        prediction = discriminator(fake_data, fake_labels)\n        error = loss(prediction, \\\n                     torch.ones(len(fake_data), 1).to(device))\n        error.backward()\n        g_optimizer.step()\n        return error \n    ```", "```py\n    discriminator = Discriminator().to(device)\n    generator = Generator().to(device)\n    loss = nn.BCELoss()\n    d_optimizer = optim.Adam(discriminator.parameters(), \\\n                             lr=0.0002, betas=(0.5, 0.999))\n    g_optimizer = optim.Adam(generator.parameters(), \\\n                             lr=0.0002, betas=(0.5, 0.999))\n    fixed_noise = torch.randn(64, 100, 1, 1, device=device)\n    fixed_fake_labels = torch.LongTensor([0]* (len(fixed_noise)//2) \\\n                        + [1]*(len(fixed_noise)//2)).to(device)\n    loss = nn.BCELoss()\n    n_epochs = 25\n    img_list = [] \n    ```", "```py\n    log = Report(n_epochs)\n    for epoch in range(n_epochs):\n        N = len(dataloader) \n    ```", "```py\n     for bx, (images, labels) in enumerate(dataloader): \n    ```", "```py\n     real_data, real_labels = images.to(device), labels.to(device) \n    ```", "```py\n     fake_labels = torch.LongTensor(np.random.randint(0, \\\n                            2,len(real_data))).to(device)\n            fake_data=generator(noise(len(real_data)),fake_labels)\n            fake_data = fake_data.detach() \n    ```", "```py\n     d_loss = discriminator_train_step(real_data, \\\n                    real_labels, fake_data, fake_labels) \n    ```", "```py\n     fake_labels = torch.LongTensor(np.random.randint(0, \\\n                            2,len(real_data))).to(device)\n            fake_data = generator(noise(len(real_data)), \\\n                                            fake_labels).to(device)\n            g_loss = generator_train_step(fake_data, fake_labels) \n    ```", "```py\n     pos = epoch + (1+bx)/N\n            log.record(pos, d_loss=d_loss.detach(), \\\n                   g_loss=g_loss.detach(), end='\\r')\n        log.report_avgs(epoch+1) \n    ```", "```py\n     with torch.no_grad():\n            fake = generator(fixed_noise, fixed_fake_labels).detach().cpu()\n            imgs = vutils.make_grid(fake, padding=2, \\\n                                normalize=True).permute(1,2,0)\n            img_list.append(imgs)\n            show(imgs, sz=10) \n    ```"]