- en: What Next?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You made it! Thanks for reading *Deep Learning with PyTorch*. You should have
    a firm understanding of the core mechanisms and the **application program interface**
    (**API**) required for building deep learning applications using PyTorch. By now,
    you should be comfortable in using all the fundamental blocks that power most
    of the modern-day deep learning algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: What next?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will summarize what we learned in this book and further
    explore different projects and resources. These projects and resources will help
    you further in the journey of keeping yourself up-to-date with the latest research.
  prefs: []
  type: TYPE_NORMAL
- en: Overview
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This section provides a bird''s-eye view of what we learned across the book:'
  prefs: []
  type: TYPE_NORMAL
- en: History of **artificial intelligence** (**AI**), machine learning—how various
    improvements in hardware and algorithms triggered huge successes in the implementation
    of deep learning across different applications.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to use various building blocks of PyTorch, such as variables, tensors, and
    `nn.module`, to develop neural networks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding the different processes involved in training a neural network,
    such as the PyTorch dataset for data preparation, data loaders for batching tensors,
    the `torch.nn` package for creating network architectures, and using PyTorch loss
    functions and optimizers.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We saw different types of machine learning problems along with challenges, such
    as overfitting and underfitting. We also went through different techniques, such
    as data augmentation, adding dropouts, and using batch normalization to prevent
    overfitting.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We learned the different building blocks of **Convolution Neural Networks**
    (**CNNs**), and also learned about transfer learning, which helps us to use a
    pretrained model. We also saw techniques, such as using pre-convoluted features,
    which helps in reducing the time taken to train the models.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We learned about word embeddings and how to use them for text classification
    problems. We also explored how we can use pretrained word embedding. We explored
    **recurrent neural network** (**RNN**), its variants such as **Long Short-Term Memory** (**LSTM**),
    and how to use them for text classification problems.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We explored generative models and learned how PyTorch can be used for creating
    artistic style transfer, and for creating new CIFAR images using a **generative
    adversarial network** (**GAN**). We also explored language modeling techniques
    which can be used to generate new text or to create domain-specific embedding.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We explored modern architectures, such as ResNet, Inception, DenseNet and encode-decoder
    architecture. We also saw how these models can be used for transfer learning.
    We also built an ensemble model by combining all these models.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Interesting ideas to explore
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Most of the concepts that we learned in the book form the foundation of modern
    applications that are powered by deep learning. In this section, we will look
    at the different interesting projects that we can do that are related to computer
    vision and **natural language processing** (**NLP**).
  prefs: []
  type: TYPE_NORMAL
- en: Object detection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'All the examples we have seen in this book help you in detecting whether a
    given image is this (cat) or that (dog). But, to solve some of the problems in
    the real world, you may need to identify different objects in an image, such as
    shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6fd9df64-6905-4ae4-9e33-c7f3741c6211.png)'
  prefs: []
  type: TYPE_IMG
- en: Output of object detection algorithm
  prefs: []
  type: TYPE_NORMAL
- en: 'This image shows the output of an object detection algorithm where the algorithm
    is detecting objects such as a beautiful dog and cat . Just as there are off-the-shelf
    algorithms for image classification, there are a bunch of amazing algorithms that
    can help in building object recognition systems. Here is a list of some of the
    important algorithms and the papers that mention them:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Single Shot Multibox Detector** (**SSD**) [https://arxiv.org/abs/1512.02325](https://arxiv.org/abs/1512.02325)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Faster RCNN [https://arxiv.org/abs/1506.01497](https://arxiv.org/abs/1506.01497)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: YOLO2 [https://arxiv.org/abs/1612.08242](https://arxiv.org/abs/1612.08242)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Image segmentation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s assume you are reading this book from the terrace of a building. What
    do you see around you? Can you draw an outline of what you see? If you are a good
    artist, unlike me, then you would have probably drawn a couple of buildings, trees,
    birds, and a few more interesting things surrounding you. Image segmentation algorithms
    try to capture something similar. Given an image, they generate a prediction for
    each pixel, identifying which class each pixel belongs to. The following image
    shows what image segmentation algorithms identify:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/abfd63aa-4643-4910-9faf-e447a4956a40.png)'
  prefs: []
  type: TYPE_IMG
- en: Output of image segmentation algorithm
  prefs: []
  type: TYPE_NORMAL
- en: 'Some of the important algorithms that you may want to explore for image segmentation
    are:'
  prefs: []
  type: TYPE_NORMAL
- en: R-CNN [https://arxiv.org/abs/1311.2524](https://arxiv.org/abs/1311.2524)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fast R-CNN [https://arxiv.org/abs/1504.08083](https://arxiv.org/abs/1504.08083)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Faster R-CNN [https://arxiv.org/abs/1506.01497](https://arxiv.org/abs/1506.01497)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mask R-CNN [https://arxiv.org/abs/1703.06870](https://arxiv.org/abs/1703.06870)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: OpenNMT in PyTorch
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The **Open-Source Neural Machine Translation** (**OpenNMT**) ([https://github.com/OpenNMT/OpenNMT-py](https://github.com/OpenNMT/OpenNMT-py)) project
    helps in building a lot of applications that are powered by the encoder-decoder
    architecture. Some of the applications that you can build are translation systems,
    text summarization, and image-to-text.
  prefs: []
  type: TYPE_NORMAL
- en: Alien NLP
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Alien NLP is an open source project built on PyTorch which enables us to do
    many NLP tasks much more easily. There is a demo page ([http://demo.allennlp.org/machine-comprehension](http://demo.allennlp.org/machine-comprehension))
    that you should look at to understand what you can build using Alien NLP.
  prefs: []
  type: TYPE_NORMAL
- en: fast.ai – making neural nets uncool again
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of my favorite places to learn about deep learning, and a great place of
    inspiration, is a MOOC with the sole motive of making deep learning accessible
    to all, organized by two amazing mentors from *fast.ai* ([http://www.fast.ai/](http://www.fast.ai/)),
    Jeremy Howard and Rachel Thomas. For a new version of their course, they built
    an incredible framework ([https://github.com/fastai/fastai](https://github.com/fastai/fastai))
    on top of PyTorch, making it much easier and quicker to build applications. If
    you have not already started their course, I would strongly recommend you start
    it. Exploring how the *fast.ai* framework is built will give you great insight
    into many powerful techniques.
  prefs: []
  type: TYPE_NORMAL
- en: Open Neural Network Exchange
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Open Neural Network Exchange** (**ONNX**) ([http://onnx.ai/](http://onnx.ai/)) is
    the first step towards an open ecosystem that empowers you to choose the right
    tools as the project evolves. ONNX provides an open source format for deep learning
    models. It defines an extensible computation graph model, as well as definitions
    of built-in operators and standard data types. Caffe2, PyTorch, Microsoft Cognitive
    Toolkit, Apache MXNet, and other tools are developing ONNX support. This project
    can help in product-ionizing PyTorch models.'
  prefs: []
  type: TYPE_NORMAL
- en: How to keep yourself updated
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Social media platforms, particularly Twitter, help you to stay updated in the
    field. There are many people you can follow. If you are unsure of where to start,
    I would recommend following Jeremy Howard ([https://twitter.com/jeremyphoward](https://twitter.com/jeremyphoward)),
    and any interesting people he may follow. By doing this, you would be forcing
    the Twitter recommendation system to work for you.
  prefs: []
  type: TYPE_NORMAL
- en: Another important Twitter account you need to follow is PyTorch's ([https://twitter.com/PyTorch](https://twitter.com/PyTorch)).
    The amazing people behind PyTorch have some great content being shared.
  prefs: []
  type: TYPE_NORMAL
- en: If you are looking for research papers, then look at *arxiv-sanity* ([http://www.arxiv-sanity.com/](http://www.arxiv-sanity.com/)),
    where many smart researchers publish their papers.
  prefs: []
  type: TYPE_NORMAL
- en: More great resources for learning about PyTorch are its tutorials ([http://pytorch.org/tutorials/](http://pytorch.org/tutorials/)),
    its source code ([https://github.com/pytorch/pytorch](https://github.com/pytorch/pytorch)),
    and its documentation ([http://pytorch.org/docs/0.3.0/](http://pytorch.org/docs/0.3.0/)).
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There is much more to deep learning and PyTorch. PyTorch is a relatively new
    framework, which, at the time of writing this chapter, is a year old. There is
    much more to learn and explore, so happy learning. All the best.
  prefs: []
  type: TYPE_NORMAL
