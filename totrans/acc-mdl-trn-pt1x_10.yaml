- en: 'Part 3: Going Distributed'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this part, you will learn how to spread the training process across multiple
    devices and machines. First, you will learn about the fundamental concepts related
    to the distributed training process. Then, you will learn how to distribute the
    training process on multiple CPUs in a single machine. After that, you will learn
    how to train the model by using multiple GPUs in a single machine. At the end,
    you will learn how to distribute the training process among multiple devices located
    in multiple machines.
  prefs: []
  type: TYPE_NORMAL
- en: 'This part has the following chapters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 8*](B20959_08.xhtml#_idTextAnchor117), *Distributed Training at a
    Glance,*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 9*](B20959_09.xhtml#_idTextAnchor132), *Training with Multiple CPUs*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 10*](B20959_10.xhtml#_idTextAnchor149), *Training with Multiple GPUs*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 11*](B20959_11.xhtml#_idTextAnchor167), *Training with Multiple Machines*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
