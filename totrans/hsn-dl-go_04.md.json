["```py\n\"gorgonia.org/gorgonia/examples/mnist\"\n```", "```py\nvar inputs, targets tensor.Tensor\nvar err error\ninputs, targets, err = mnist.Load(“train”, “./mnist/, “float64”)\n```", "```py\ntype nn struct {\n    g *gorgonia.ExprGraph\n    w0, w1, w2 *gorgonia.Node\n\n    out *gorgonia.Node\n    predVal gorgonia.Value\n}\n\nfunc newNN(g *gorgonia.ExprGraph) *nn {\n    // Create node for w/weight\n    w0 := gorgonia.NewMatrix(g, dt, gorgonia.WithShape(784, 300), gorgonia.WithName(\"w0\"), gorgonia.WithInit(gorgonia.GlorotN(1.0)))\n   w1 := gorgonia.NewMatrix(g, dt, gorgonia.WithShape(300, 100), gorgonia.WithName(\"w1\"), gorgonia.WithInit(gorgonia.GlorotN(1.0)))\n    w2 := gorgonia.NewMatrix(g, dt, gorgonia.WithShape(100, 10), gorgonia.WithName(\"w2\"), gorgonia.WithInit(gorgonia.GlorotN(1.0)))\n\n    return &nn{\n        g: g,\n        w0: w0,\n        w1: w1,\n        w2: w2,\n    }\n}\n```", "```py\nfunc (m *nn) fwd(x *gorgonia.Node) (err error) {\n    var l0, l1, l2 *gorgonia.Node\n    var l0dot, l1dot*gorgonia.Node\n\n    // Set first layer to be copy of input\n    l0 = x\n\n    // Dot product of l0 and w0, use as input for ReLU\n    if l0dot, err = gorgonia.Mul(l0, m.w0); err != nil {\n        return errors.Wrap(err, \"Unable to multiply l0 and w0\")\n    }\n\n    // Build hidden layer out of result\n    l1 = gorgonia.Must(gorgonia.Rectify(l0dot))\n\n    // MOAR layers\n\n    if l1dot, err = gorgonia.Mul(l1, m.w1); err != nil {\n        return errors.Wrap(err, \"Unable to multiply l1 and w1\")\n    }\n    l2 = gorgonia.Must(gorgonia.Rectify(l2dot))\n\n    var out *gorgonia.Node\n    if out, err = gorgonia.Mul(l2, m.w2); err != nil {\n        return errors.Wrapf(err, \"Unable to multiply l2 and w2\")\n    }\n\n    m.out, err = gorgonia.SoftMax(out)\n    gorgonia.Read(m.out, &m.predVal)\n    return\n}\n```", "```py\n[ 0.1 0.1 0.1 1.0 0.1 0.1 0.1 0.1 0.1 ]\n```", "```py\n[ 0 0 0 0.999681 0 0.000319 0 0 0 0 ]\n```", "```py\ncrossEntropyLoss = -1 * sum(actual_y * log(predicted_y))\n```", "```py\nloss = -1 * mean(actual_y * predicted_y)\n```", "```py\nlosses, err := gorgonia.HadamardProd(m.out, y)\nif err != nil {\n    log.Fatal(err)\n}\ncost := gorgonia.Must(gorgonia.Mean(losses))\ncost = gorgonia.Must(gorgonia.Neg(cost))\n\n// we wanna track costs\nvar costVal gorgonia.Value\ngorgonia.Read(cost, &costVal)\n```", "```py\nfor b := 0; b < batches; b++ {\n    start := b * bs\n    end := start + bs\n    if start >= numExamples {\n        break\n    }\n    if end > numExamples {\n        end = numExamples\n    }\n}\n```", "```py\nvar xVal, yVal tensor.Tensor\nif xVal, err = inputs.Slice(sli{start, end}); err != nil {\n    log.Fatal(\"Unable to slice x\")\n}\n\nif yVal, err = targets.Slice(sli{start, end}); err != nil {\n    log.Fatal(\"Unable to slice y\")\n}\n// if err = xVal.(*tensor.Dense).Reshape(bs, 1, 28, 28); err != nil {\n// log.Fatal(\"Unable to reshape %v\", err)\n// }\nif err = xVal.(*tensor.Dense).Reshape(bs, 784); err != nil {\n    log.Fatal(\"Unable to reshape %v\", err)\n}\n\ngorgonia.Let(x, xVal)\ngorgonia.Let(y, yVal)\nif err = vm.RunAll(); err != nil {\n    log.Fatalf(\"Failed at epoch %d: %v\", i, err)\n}\nsolver.Step(m.learnables())\nvm.Reset()\n```", "```py\nbatches := numExamples / bs\nlog.Printf(\"Batches %d\", batches)\nbar := pb.New(batches)\nbar.SetRefreshRate(time.Second / 20)\nbar.SetMaxWidth(80)\n\nfor i := 0; i < *epochs; i++ {\n    // for i := 0; i < 1; i++ {\n    bar.Prefix(fmt.Sprintf(\"Epoch %d\", i))\n    bar.Set(0)\n    bar.Start()\n    // put iteration and batch logic above here\n    bar.Update()\n    log.Printf(\"Epoch %d | cost %v\", i, costVal)\n}\n```", "```py\nsolver.Step(m.learnables())\n```", "```py\nfor j := 0; j < xVal.Shape()[0]; j++ {\n    rowT, _ := xVal.Slice(sli{j, j + 1})\n    row := rowT.Data().([]float64)\n\n    img := visualizeRow(row)\n\n    f, _ := os.OpenFile(fmt.Sprintf(\"images/%d - %d - %d - %d.jpg\", b, j, rowLabel, rowGuess), os.O_CREATE|os.O_WRONLY|os.O_TRUNC, 0644)\n    jpeg.Encode(f, img, &jpeg.Options{jpeg.DefaultQuality})\n    f.Close()\n}\n```", "```py\nyRowT, _ := yVal.Slice(sli{j, j + 1})\nyRow := yRowT.Data().([]float64)\nvar rowLabel int\nvar yRowHigh float64\n\nfor k := 0; k < 10; k++ {\n    if k == 0 {\n        rowLabel = 0\n        yRowHigh = yRow[k]\n    } else if yRow[k] > yRowHigh {\n        rowLabel = k\n        yRowHigh = yRow[k]\n    }\n}\n```", "```py\narrayOutput := m.predVal.Data().([]float64)\nyOutput := tensor.New(\n            tensor.WithShape(bs, 10),                                             tensor.WithBacking(arrayOutput)\n            )\n```", "```py\n// get prediction\npredRowT, _ := yOutput.Slice(sli{j, j + 1})\npredRow := predRowT.Data().([]float64)\nvar rowGuess int\nvar predRowHigh float64\n\n// guess result\nfor k := 0; k < 10; k++ {\n    if k == 0 {\n        rowGuess = 0\n        predRowHigh = predRow[k]\n    } else if predRow[k] > predRowHigh {\n        rowGuess = k\n        predRowHigh = predRow[k]\n    }\n}\n```", "```py\narrayOutput := m.predVal.Data().([]float64)\nyOutput := tensor.New(tensor.WithShape(bs, 10), tensor.WithBacking(arrayOutput))\n\nfile, err := os.OpenFile(fmt.Sprintf(\"%d.csv\", b), os.O_CREATE|os.O_WRONLY, 0777)\nif err = xVal.(*tensor.Dense).Reshape(bs, 784); err != nil {\n log.Fatal(\"Unable to create csv\", err)\n}\ndefer file.Close()\nvar matrixToWrite [][]string\n\nfor j := 0; j < yOutput.Shape()[0]; j++ {\n  rowT, _ := yOutput.Slice(sli{j, j + 1})\n  row := rowT.Data().([]float64)\n  var rowToWrite []string\n\n  for k := 0; k < 10; k++ {\n      rowToWrite = append(rowToWrite, strconv.FormatFloat(row[k], 'f', 6, 64))\n  }\n  matrixToWrite = append(matrixToWrite, rowToWrite)\n}\n\ncsvWriter := csv.NewWriter(file)\ncsvWriter.WriteAll(matrixToWrite)\ncsvWriter.Flush()\n```", "```py\n[ 0  0  0.000457  0.99897  0  0  0  0.000522  0.000051  0 ]\n```", "```py\n[0 0 0 0 0 0 0 1 0 0]\n```", "```py\nfunc newNN(g *gorgonia.ExprGraph) *nn {\n    // Create node for w/weight\n    w0 := gorgonia.NewMatrix(g, dt, gorgonia.WithShape(784, 128), gorgonia.WithName(\"w0\"), gorgonia.WithInit(gorgonia.GlorotU(1.0)))\n    w1 := gorgonia.NewMatrix(g, dt, gorgonia.WithShape(128, 64), gorgonia.WithName(\"w1\"), gorgonia.WithInit(gorgonia.GlorotU(1.0)))\n    w2 := gorgonia.NewMatrix(g, dt, gorgonia.WithShape(64, 128), gorgonia.WithName(\"w2\"), gorgonia.WithInit(gorgonia.GlorotU(1.0)))\n    w3 := gorgonia.NewMatrix(g, dt, gorgonia.WithShape(128, 784), gorgonia.WithName(\"w3\"), gorgonia.WithInit(gorgonia.GlorotU(1.0)))\n\n    return &nn{\n        g: g,\n        w0: w0,\n        w1: w1,\n        w2: w2,\n        w3: w3,\n    }\n}\n```", "```py\nfunc (m *nn) fwd(x *gorgonia.Node) (err error) {\n    var l0, l1, l2, l3, l4 *gorgonia.Node\n    var l0dot, l1dot, l2dot, l3dot *gorgonia.Node\n\n    // Set first layer to be copy of input\n    l0 = x\n\n    // Dot product of l0 and w0, use as input for Sigmoid\n    if l0dot, err = gorgonia.Mul(l0, m.w0); err != nil {\n        return errors.Wrap(err, \"Unable to multiple l0 and w0\")\n    }\n    l1 = gorgonia.Must(gorgonia.Sigmoid(l0dot))\n\n    if l1dot, err = gorgonia.Mul(l1, m.w1); err != nil {\n        return errors.Wrap(err, \"Unable to multiple l1 and w1\")\n    }\n    l2 = gorgonia.Must(gorgonia.Sigmoid(l1dot))\n\n    if l2dot, err = gorgonia.Mul(l2, m.w2); err != nil {\n        return errors.Wrap(err, \"Unable to multiple l2 and w2\")\n    }\n    l3 = gorgonia.Must(gorgonia.Sigmoid(l2dot))\n\n    if l3dot, err = gorgonia.Mul(l3, m.w3); err != nil {\n        return errors.Wrap(err, \"Unable to multiple l3 and w3\")\n    }\n    l4 = gorgonia.Must(gorgonia.Sigmoid(l3dot))\n\n    // m.pred = l3dot\n    // gorgonia.Read(m.pred, &m.predVal)\n    // return nil\n\n    m.out = l4\n    gorgonia.Read(l4, &m.predVal)\n    return\n\n}\n```", "```py\nmse = sum( (actual_y - predicted_y) ^ 2 ) / num_of_y\n```", "```py\nlosses, err := gorgonia.Square(gorgonia.Must(gorgonia.Sub(y, m.out)))\nif err != nil {\n    log.Fatal(err)\n}\ncost := gorgonia.Must(gorgonia.Mean(losses))\n```", "```py\ngorgonia.Let(x, xVal)\ngorgonia.Let(y, xVal)\n```", "```py\nfor j := 0; j < 1; j++ {\n    rowT, _ := yOutput.Slice(sli{j, j + 1})\n    row := rowT.Data().([]float64)\n\n    img := visualizeRow(row)\n\n    f, _ := os.OpenFile(fmt.Sprintf(\"training/%d - %d - %d training.jpg\", j, b, i), os.O_CREATE|os.O_WRONLY|os.O_TRUNC, 0644)\n    jpeg.Encode(f, img, &jpeg.Options{jpeg.DefaultQuality})\n    f.Close()\n}\n```", "```py\narrayOutput := m.predVal.Data().([]float64)\nyOutput := tensor.New(tensor.WithShape(bs, 784), tensor.WithBacking(arrayOutput))\n\nfor j := 0; j < yOutput.Shape()[0]; j++ {\n    rowT, _ := yOutput.Slice(sli{j, j + 1})\n    row := rowT.Data().([]float64)\n\n    img := visualizeRow(row)\n\n    f, _ := os.OpenFile(fmt.Sprintf(\"images/%d - %d output.jpg\", b, j), os.O_CREATE|os.O_WRONLY|os.O_TRUNC, 0644)\n    jpeg.Encode(f, img, &jpeg.Options{jpeg.DefaultQuality})\n    f.Close()\n}\n```", "```py\npackage main\n\nimport (\n\n  // \"github.com/aotimme/rbm\"\n\n  \"fmt\"\n  \"log\"\n  \"math\"\n  \"strconv\"\n\n  \"github.com/yunabe/easycsv\"\n  g \"gorgonia.org/gorgonia\"\n  \"gorgonia.org/tensor\"\n)\n\nvar datasetfilename string = \"dataset/cleanratings.csv\"\nvar movieindexfilename string = \"dataset/cleanmovies.csv\"    \n\nfunc BuildMovieIndex(input string) map[int]string {\n\n  var entrycount int\n  r := easycsv.NewReaderFile(input, easycsv.Option{\n    Comma: ',',\n  })\n\n  var entry struct {\n    Id int `index:\"0\"`\n    Title string `index:\"1\"`\n  }\n\n  //fix hardcode\n  movieindex := make(map[int]string, 3952)\n\n  for r.Read(&entry) {\n    // fmt.Println(entry)\n    movieindex[entry.Id] = entry.Title\n    // entries = append(entries, entry)\n    entrycount++\n  }\n\n  return movieindex\n\n}\n```", "```py\nfunc DataImport(input string) (out [][]int, uniquemovies map[int]int) {\n  //\n  // Initial data processing\n  //\n  // import from CSV, read into entries var\n  r := easycsv.NewReaderFile(input, easycsv.Option{\n    Comma: ',',\n  })\n\n  var entry []int\n  var entries [][]int\n  for r.Read(&entry) {\n    entries = append(entries, entry)\n  }\n\n  // maps for if unique true/false\n  seenuser := make(map[int]bool)\n  seenmovie := make(map[int]bool)\n\n  // maps for if unique index\n  uniqueusers := make(map[int]int)\n  uniquemovies = make(map[int]int)\n\n  // counters for uniques\n  var uniqueuserscount int = 0\n  var uniquemoviescount int = 0\n\n  // distinct movie lists/indices\n  for _, e := range entries {\n    if seenmovie[e[1]] == false {\n      uniquemovies[uniquemoviescount] = e[1]\n      seenmovie[e[1]] = true\n      uniquemoviescount++\n    } else if seenmovie[e[1]] == true {\n      // fmt.Printf(\"Seen movie %v before, aborting\\n\", e[0])\n      continue\n    }\n  }\n  // distinct user lists/indices\n  for _, e := range entries {\n    if seenuser[e[0]] == false {\n      uniqueusers[uniqueuserscount] = e[0]\n      seenuser[e[0]] = true\n      uniqueuserscount++\n      // uniqueusers[e[0]] =\n    } else if seenuser[e[0]] == true {\n      // fmt.Printf(\"Seen user %v before, aborting\\n\", e[0])\n      continue\n    }\n  }\n\n  uservecs := make([][]int, len(uniqueusers))\n  for i := range uservecs {\n    uservecs[i] = make([]int, len(uniquemovies))\n  }\n```", "```py\n  var entriesloop int\n  for _, e := range entries {\n    // hack - wtf\n    if entriesloop%100000 == 0 && entriesloop != 0 {\n      fmt.Printf(\"Processing rating %v of %v\\n\", entriesloop, len(entries))\n    }\n    if entriesloop > 999866 {\n      break\n    }\n    var currlike int\n\n    // normalisze ratings\n    if e[2] >= 4 {\n      currlike = 1\n    } else {\n      currlike = 0\n    }\n\n    // add to a user's vector of index e[1]/movie num whether current movie is +1\n    // fmt.Println(\"Now looping uniquemovies\")\n    for i, v := range uniquemovies {\n      if v == e[1] {\n        // fmt.Println(\"Now setting uservec to currlike\")\n        // uservec[i] = currlike\n        // fmt.Println(\"Now adding to uservecs\")\n        uservecs[e[0]][i] = currlike\n        break\n      }\n    }\n    // fmt.Printf(\"Processing rating %v of %v\\n\", entriesloop, len(entries))\n    entriesloop++\n  }\n  // fmt.Println(uservecs)\n  // os.Exit(1)\n\n  // fmt.Println(entry)\n  if err := r.Done(); err != nil {\n    log.Fatalf(\"Failed to read a CSV file: %v\", err)\n  }\n  // fmt.Printf(\"length uservecs %v and uservecs.movies %v\", len(uservecs))\n  fmt.Println(\"Number of unique users: \", len(seenuser))\n  fmt.Println(\"Number of unique movies: \", len(seenmovie))\n  out = uservecs\n\n  return\n\n}\n```", "```py\nconst cdS = 1\ntype ggRBM struct {\n    g *ExprGraph\n    v *Node // visible units\n    vB *Node // visible unit biases - same size tensor as v\n    h *Node // hidden units\n    hB *Node // hidden unit biases - same size tensor as h\n    w *Node // connection weights\n    cdSamples int // number of samples for contrastive divergence - WHAT ABOUT MOMENTUM\n}\nfunc (m *ggRBM) learnables() Nodes {\n    return Nodes{m.w, m.vB, m.hB}\n}\n```", "```py\n// Uses Gibbs Sampling\nfunc (r *ggRBM) ContrastiveDivergence(input *Node, learnRate float64, k int) {\n   rows := float64(r.TrainingSize)\n\n // CD-K\n   phMeans, phSamples := r.SampleHiddenFromVisible(input)\n   nvSamples := make([]float64, r.Inputs)\n// iteration 0\n\n   _, nvSamples, nhMeans, nhSamples := r.Gibbs(phSamples, nvSamples)\n\n   for step := 1; step < k; step++ {\n\n       /*nvMeans*/ _, nvSamples, nhMeans, nhSamples = r.Gibbs(nhSamples, nvSamples)\n\n   }\n\n   // Update weights\n   for i := 0; i < r.Outputs; i++ {\n\n       for j := 0; j < r.Inputs; j++ {\n\n           r.Weights[i][j] += learnRate * (phMeans[i]*input[j] - nhMeans[i]*nvSamples[j]) / rows\n       }\n       r.Biases[i] += learnRate * (phSamples[i] - nhMeans[i]) / rows\n   }\n\n   // update hidden biases\n   for j := 0; j < r.Inputs; j++ {\n\n       r.VisibleBiases[j] += learnRate * (input[j] - nvSamples[j]) / rows\n   }\n}\n```", "```py\nfunc (r *ggRBM) SampleHiddenFromVisible(vInput *Node) (means []float64, samples []float64) {\n   means = make([]float64, r.Outputs)\n   samples = make([]float64, r.Outputs)\n   for i := 0; i < r.Outputs; i++ {\n       mean := r.PropagateUp(vInput, r.Weights[i], r.Biases[i])\n       samples[i] = float64(binomial(1, mean))\n       means[i] = mean\n   }\n   return means, samples\n}\n\nfunc (r *ggRBM) SampleVisibleFromHidden(hInput *Node) (means []float64, samples []float64) {\n   means = make([]float64, r.Inputs)\n   samples = make([]float64, r.Inputs)\n   for j := 0; j < r.Inputs; j++ {\n       mean := r.PropagateDown(hInput, j, r.VisibleBiases[j])\n       samples[j] = float64(binomial(1, mean))\n       means[j] = mean\n   }\n   return means, samples\n}\n```", "```py\nfunc (r *ggRBM) PropagateDown(h *Node, j int, hB *Node) *Node {\n   retVal := 0.0\n   for i := 0; i < r.Outputs; i++ {\n       retVal += r.Weights[i][j] * h0[i]\n   }\n   retVal += bias\n   return sigmoid(retVal)\n}\n\nfunc (r *ggRBM) PropagateUp(v *Node, w *Node, vB *Node) float64 {\n   retVal := 0.0\n   for j := 0; j < r.Inputs; j++ {\n       retVal += weights[j] * v0[j]\n   }\n   retVal += bias\n   return sigmoid(retVal)\n}\n```", "```py\nfunc (r *ggRBM) Gibbs(h, v *Node) (vMeans []float64, vSamples []float64, hMeans []float64, hSamples []float64) {\n   vMeans, vSamples = r.SampleVisibleFromHidden(r.h)\n   hMeans, hSamples = r.SampleHiddenFromVisible(r.v)\n   return\n}\n\nfunc (r *ggRBM) Reconstruct(x *Node) *Node {\n   hiddenLayer := make([]float64, r.Outputs)\n   retVal := make([]float64, r.Inputs)\n\n   for i := 0; i < r.Outputs; i++ {\n       hiddenLayer[i] = r.PropagateUp(x, r.Weights[i], r.Biases[i])\n   }\n\n   for j := 0; j < r.Inputs; j++ {\n       activated := 0.0\n       for i := 0; i < r.Outputs; i++ {\n           activated += r.Weights[i][j] * hiddenLayer[i]\n       }\n       activated += r.VisibleBiases[j]\n       retVal[j] = sigmoid(activated)\n   }\n   return retVal\n}\n```", "```py\nfunc newggRBM(g *ExprGraph, cdS int) *ggRBM {\n\n   vT := tensor.New(tensor.WithBacking(tensor.Random(tensor.Int, 3952)), tensor.WithShape(3952, 1))\n\n   v := NewMatrix(g,\n       tensor.Int,\n       WithName(\"v\"),\n       WithShape(3952, 1),\n       WithValue(vT),\n   )\n\n   hT := tensor.New(tensor.WithBacking(tensor.Random(tensor.Int, 200)), tensor.WithShape(200, 1))\n\n   h := NewMatrix(g,\n       tensor.Int,\n       WithName(\"h\"),\n       WithShape(200, 1),\n       WithValue(hT),\n   )\n\n   wB := tensor.Random(tensor.Float64, 3952*200)\n   wT := tensor.New(tensor.WithBacking(wB), tensor.WithShape(3952*200, 1))\n   w := NewMatrix(g,\n       tensor.Float64,\n       WithName(\"w\"),\n       WithShape(3952*200, 1),\n       WithValue(wT),\n   )\n\n   return &ggRBM{\n       g: g,\n       v: v,\n       h: h,\n       w: w,\n       // hB: hB,\n       // vB: vB,\n       cdSamples: cdS,\n   }\n}\n```", "```py\nfunc main() {\n   g := NewGraph()\n   m := newggRBM(g, cdS)\n   data, err := ReadDataFile(datasetfilename)\n   if err != nil {\n       log.Fatal(err)\n   }\n   fmt.Println(\"Data read from CSV: \\n\", data)\n   vm := NewTapeMachine(g, BindDualValues(m.learnables()...))\n   // solver := NewVanillaSolver(WithLearnRate(1.0))\n   for i := 0; i < 1; i++ {\n       if vm.RunAll() != nil {\n           log.Fatal(err)\n       }\n   }\n}\n```", "```py\n#!/bin/bash\nexport LC_CTYPE=C\nexport LANG=C\ncat ratings.dat | sed 's/::/,/g' > cleanratings.csv\ncat movies.dat | sed 's/,//g; s/::/,/g' > cleanmovies.csv\n```"]