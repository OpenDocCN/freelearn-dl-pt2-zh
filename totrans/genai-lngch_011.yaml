- en: 10 The Future of Generative Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Join our book community on Discord
  id: totrans-1
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[https://packt.link/EarlyAccessCommunity](https://packt.link/EarlyAccessCommunity)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: '![Qr code Description automatically generated](img/file65.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
- en: 'In this book, so far, we’ve discussed generative models for building applications.
    We’ve explored LLMs and image models for content creation, tool use, agent strategies,
    semantic search with retrieval augmented generation, and conditioning of models
    with prompts and fine-tuning. Further, we’ve implemented a few simple applications,
    for example, for developers and data scientists. In this chapter, we’ll discuss
    where this leaves us and where the future leads us.The pace of progress in AI
    has accelerated dramatically in the past year, with breakthroughs like DALL-E,
    Midjourney, and ChatGPT producing astounding results. These generative AI models
    can create photorealistic images, write essays and code, and have conversational
    abilities surpassing most humans. Venture funding for generative AI startups skyrocketed
    in 2022, almost matched the total investments from the previous five years combined.
    Recently, major players like Salesforce and Accenture have made big commitments
    to generative AI with multibillion dollar investments. Unique customization of
    foundation models for specific use cases is seen as the real value creation opportunity.
    But it remains uncertain which entities - big tech firms, startups, or foundation
    model developers - will capture most upside.On a technical level, generative models
    like ChatGPT often function as black boxes, with limited transparency into their
    decision-making processes. A lack of model interpretability makes it difficult
    to fully understand model behavior or to control outputs. There are also concerns
    around potential biases that could emerge from imperfect training data. On a practical
    level, generative models require extensive computational resources for training
    and deployment. For many organizations, acquiring the infrastructure to effectively
    utilize these AI systems remains a barrier.On the positive side, AI can democratize
    skills, allowing amateurs to produce professional quality output in design, writing,
    etc. Businesses can benefit from faster, cheaper, on-demand work. However, there
    are major concerns around job losses, especially for specialized middle-class
    roles like graphic designers, lawyers and doctors. Their work is being automated
    while low skilled workers learn to leverage AI as a superpower. More ominously,
    AI could be weaponized by militaries, terrorists, criminals and governments for
    propaganda and influence. Deepfakes produced in real-time will proliferate scams
    and erode trust. The path forward balances enthusiasm with practicality, prioritizing
    human dignity. By acknowledging risks, fostering open discussion, and enacting
    thoughtful policies, we can build an equitable future enabled by AI’s enlivening
    possibilities.The main sections of this chapter are:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: Current State of Generative AI
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Possible Future Capabilities
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Societal Implications
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Practical Implementation
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Road Ahead
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s start from the current state of models and their capabilities.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: Current State of Generative AI
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As discussed in this book, in recent years, generative AI models have attained
    new milestones in producing human-like content across modalities including text,
    images, audio and video. Leading models like OpenAI’s GPT-4 and DALL-E 2, Google’s
    Imagen and Parti, and Anthropic’s Claude display impressive fluency in language
    generation along with creative visual artistry.Between 2022 and 2023, models have
    progressed in strides. If generative models were previously capable to produce
    barely coherent text or grainy images, now we see high-quality 3D models, videos,
    and generate coherent and contextually relevant prose and dialogue, rivaling or
    even surpassing the fluency levels of humans. These AI models leverage gargantuan
    datasets and computational scale, enabling them to capture intricate linguistic
    patterns, display a nuanced understanding of knowledge about the world, translate
    texts, summarize content, answer natural language questions, create appealing
    visual art, and acquire the capability to describe images. Seemingly by magic,
    the AI generated outputs mimic human ingenuity — painting original art, writing
    poetry, producing human-level prose, and even engaging in sophisticated aggregation
    and synthesis of information from diverse sources. But let’s be a bit more nuanced.
    Generative Models come with weaknesses as well as strengths. Deficiencies still
    persist compared to human cognition, including the frequent generation of plausible
    yet incorrect or nonsensical statements. Hallucinations show a lack of grounding
    in reality, given that they are based on patterns in data rather than an understanding
    of the real world. Further, models exhibit difficulties performing mathematical,
    logical, or causal reasoning. They are easily confused by complex inferential
    questions, which could limit their applicability in certain fields of work. The
    black box problem of lack of explainability for predictions as well as the models
    themselves hampers troubleshooting efforts, and controlling model behaviors within
    desired parameters remains challenging. AI models may exhibit harmful unintended
    biases that pose significant ethical concerns—a problem greatly due to the biases
    present in the training data itself. This issue of bias not only skews output
    but can propagate and amplify societal disparities.Here is a table visualizing
    the key strengths and deficiencies of current LLMs compared to human cognition:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: '| **Strengths of LLMs** | **Deficiencies of LLMs** |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
- en: '| Language Fluency - Ability to generate grammatically coherent, contextual
    prose and dialogue. GPT-4 produces human-level prose. | Factual Accuracy - LLMs
    frequently generate plausible but incorrect or nonsensical statements. Lack of
    grounding in reality. |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
- en: '| Knowledge Synthesis - Sophisticated aggregation and presentation of information
    from diverse sources. | Logical Reasoning - Inability to perform mathematical,
    logical or causal reasoning. Easily confused by complex inferential questions.
    |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
- en: '| Creative Output - Imaginative and original text, art, music reflecting human
    ingenuity. Claude writes poetry, DALL-E 2 paints original art. | Controllability
    - Difficulty constraining model behaviors within desired parameters. Can exhibit
    harmful unintended biases. |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
- en: '|  | Bias - Potential to propagate and amplify societal biases present in training
    data. Raises ethical concerns. |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
- en: '|  | Transparency - Lack of explainability for model predictions. The "black
    box" problem limits troubleshooting. |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
- en: 'Figure 10.1: Strengths and Deficiencies of LLMs.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: While generative AI capabilities have come a long way, their problematic areas
    need addressing for these technologies to effectively function in the future.
    Nonetheless, their profound potential indicates an exciting future if developed
    and regulated responsibly.The weaknesses of generative models define some of the
    technical challenges, as we’ll see now.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: Technical Challenges
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'While rapid progress has been made, significant technical obstacles remain
    to realize the full potential of generative AI safely and responsibly. As mentioned,
    generative AI models, despite their considerable advances, are grappling with
    significant technical challenges that need to be overcome to allow their full
    potential to be harnessed safely and responsibly. We’ve discussed some of these
    issues and potential solutions in previous chapters.This table shows a summary
    for a few of these challenges together with the technical approaches to tackle
    them:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: '| **Challenge** | **Description** | **Potential Solutions** |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
- en: '| Realistic and Diverse Content Generation | Existing models struggle with
    logical consistency and factual plausibility. Generates repetitive, bland samples
    lacking human nuance. | Reinforcement learning from human feedback Data augmentation
    and synthesis techniquesModular domain knowledge |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
- en: '| Output Quality Control | Lack of mechanisms to reliably constrain properties
    of generated content. Models sporadically produce harmful, biased or nonsensical
    results. | Constrained optimization objectivesModeration systemsInterruption and
    correction techniques |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
- en: '| Avoiding Bias | Models inadvertently amplify societal biases present in training
    data. Developing techniques to curtail prejudice remains difficult. | Balanced
    and representative training dataBias mitigation algorithmsOngoing testing and
    audits |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
- en: '| Factual Accuracy | Inability to reason about objective truths limits reliability
    for real-world applications. Grounding models in common sense and physics is an
    open problem. | Incorporating knowledge basesHybrid neuro-symbolic architecturesRetrieval
    augmented generation |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
- en: '| Explainability | The opaque behavior of large neural networks poses hurdles
    for troubleshooting failures or bias, necessitating explainable AI techniques.
    | Model introspection techniquesConcept attribution methodsSimplified model architectures
    |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| 可解释性 | 大型神经网络的不透明行为对故障排除或偏见构成障碍，因此需要可解释的人工智能技术。 | 模型内省技术概念归因方法简化模型架构 |'
- en: '| Data Privacy | Collecting and processing massive datasets raises challenges
    around consent, anonymization, access control and misuse of data. | Differential
    privacy and secure multi-party computationSynthetic data generationFederated learning
    |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| 数据隐私 | 收集和处理大规模数据集会带来关于同意、匿名化、访问控制和数据滥用的挑战。 | 差分隐私和安全多方计算合成数据生成联邦学习 |'
- en: '| Latency and Compute | Deploying huge models requires substantial computing
    resources, delaying real-time interactivity needed for many applications. | Model
    distillation into smaller form factorsOptimized inference enginesDedicated AI
    hardware accelerators |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| 延迟和计算 | 部署庞大的模型需要大量计算资源，延迟了许多应用所需的实时交互。 | 将模型压缩为更小的形式优化推断引擎专用的人工智能硬件加速器 |'
- en: '| Data Licenses | Organizations may need to obtain a commercial license to
    use existing datasets or to build bespoke datasets to train generative models.
    This can be a complex and time-consuming process. | Open-source and synthetic
    data |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| 数据许可证 | 组织可能需要获取商业许可证来使用现有数据集或构建定制数据集来训练生成模型。这可能是一个复杂和耗时的过程。 | 开源和合成数据 |'
- en: 'Figure 10.2: Technical Challenges and Potential Solutions.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.2：技术挑战和潜在解决方案。
- en: 'Primarily, the content generated by these models is often hindered by a lack
    of realism and diversity. While they have displayed impressive abilities to mimic
    human-like language and creativity, they still falter when it comes to producing
    content that is logically consistent and factually plausible. Their outputs often
    lack human nuance turning out to be quite repetitive and bland. Potential solutions
    include reinforcement learning from human feedback to improve coherence and nuance,
    controlled data augmentation and synthesis techniques, and architectures incorporating
    modular domain knowledge.Another critical hurdle is the control of output quality.
    Despite rigorous training and development, existing AI mechanisms fall short in
    reliably constraining properties of the generated content. This results in sporadic
    production of content that can be harmful, biased or outright nonsensical, posing
    a risk to their wider acceptance and application. Promising approaches involve
    constrained optimization objectives, human-in-the-loop moderation systems, and
    techniques to interrupt and correct model output during generation.Bias is indeed
    a major issue with these AI models as they frequently and inadvertently amplify
    societal prejudices present in their training data. Developing corrective techniques
    to curtail such biases remains a complicated issue. Strategies like balanced and
    representative training data, bias mitigation algorithms, and ongoing testing
    and audits for fairness seek to address this problem.The inability of these AI
    models to reason about objective truths noticeably limits their reliability for
    real-world applications. Grounding these models in common sense and physics represents
    an open problem that the AI community is still grappling with. Hybrid neuro-symbolic
    architectures, incorporation of knowledge bases, and retrieval augmented generation
    offer promising directions.The black box nature of AI presents another complex
    challenge: explainability. The opaque behavior of large neural networks poses
    hurdles for troubleshooting failures or bias, which emphasizes the need for more
    transparent AI techniques. Model introspection, concept attribution methods, and
    simplified model architectures could provide solutions.Furthermore, the issue
    of data privacy rises to prominence due to the collection and processing of extensive
    datasets. This aspect introduces challenges around consent, anonymization, access
    control and misuse of data. Techniques like differential privacy, secure multi-party
    computation, synthetic data generation, and federated learning may help address
    privacy risks.Last but not least, deploying these enormous models demands substantial
    computing resources, leading to significant latency and compute issues. This could
    delay the real-time interactivity required for many applications, indicating that
    efficiency improvements are key. Solutions involve model distillation into smaller
    form factors, optimized inference engines, and dedicated AI hardware accelerators.Looking
    ahead, generative AI systems are poised to become more powerful and multifaceted.
    Let’s see how!'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: Possible Future Capabilities
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可能的未来能力
- en: 'The current doubling time in training compute of very large models is about
    8 months, outstripping scaling laws such as Moore’s Law (transistor density at
    cost increases at a rate of currently about 18 months) or Rock’s Law (costs of
    hardware like GPUs and TPUs halve every 4 years).This graph illustrates this trend
    in training compute of large models (Source: Epoch, *Parameter, Compute and Data
    Trends in Machine Learning*. Published online at epochai.org. Retrieved from:
    https://epochai.org/mlinputs/visualization):'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，非常大型模型的训练计算的加倍时间约为8个月，超过了莫尔定律（晶体管密度的成本每18个月增加一倍）或洛克定律（像GPU和TPU这样的硬件成本每4年减半）等缩放定律。这张图表明了大型模型训练计算的这一趋势（来源：Epoch，《机器学习中参数、计算和数据趋势》。在线发布在epochai.org。检索自：https://epochai.org/mlinputs/visualization）：
- en: '![Figure 10.3: Training FLOPs of notable AI systems.](img/file66.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![图10.3：显著AI系统的训练FLOPs。](img/file66.png)'
- en: 'Figure 10.3: Training FLOPs of notable AI systems.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.3：显著AI系统的训练FLOPs。
- en: As discussed in chapter 1, parameter sizes for large systems have been increasing
    at a similar rate as the training compute, which means that we could be seeing
    much larger and more expensive systems if this growth continues. Empirically derived
    scaling laws predict the performance of LLMs based on the training budget, dataset
    size, and the number of parameters. This could mean that highly powerful systems
    would be concentrated in the hands of Big Tech.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 正如第1章所讨论的，大型系统的参数规模正在以与训练计算相似的速度增长，这意味着如果这种增长持续下去，我们可能会看到更大更昂贵的系统。经验推导的缩放定律预测了基于训练预算、数据集大小和参数数量的LLM性能。这意味着高度强大的系统可能会集中在大型科技公司手中。
- en: The **KM scaling** law, proposed by Kaplan and colleagues, derived through empirical
    analysis and fitting of model performance with varied data sizes, model sizes,
    and training compute, presents power-law relationships, indicate a strong dependence,
    between model performance and factors such as model size, dataset size, and training
    compute.
  id: totrans-41
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**KM缩放**定律，由Kaplan和同事提出，通过对模型性能与不同数据大小、模型大小和训练计算的拟合进行经验分析，提出了幂律关系，表明了模型性能与模型大小、数据集大小和训练计算等因素之间的强烈依赖关系。'
- en: ''
  id: totrans-42
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The **Chinchilla scaling law**, developed by the Google DeepMind team, involved
    experiments with a wider range of model sizes and data sizes, and suggests an
    optimal allocation of compute budget to model size and data size, which can be
    determined by optimizing a specific loss function under a constraint.
  id: totrans-43
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**Chinchilla缩放定律**，由Google DeepMind团队开发，涉及对更广泛范围的模型大小和数据大小进行实验，并建议将计算预算最优地分配到模型大小和数据大小，这可以通过在约束条件下优化特定损失函数来确定。'
- en: 'However, future progress may depend more on data efficiency and model quality
    than sheer size. Though massive models grab headlines, computing power and energy
    constraints put a limit on unrestrained model growth. The future will see co-existence
    of massive, general models with smaller and accessible specialized niche models
    that provide faster and cheaper training, maintenance, and inference. It has already
    been shown that smaller specialized models can prove highly performant. We’ve
    recently seen models such as phi-1 (*Textbooks Are All You Need*, 2023, Gunasekar
    and colleagues), on the order of 1 billion parameters, that – despite its smaller
    scale – achieve high accuracy on evaluation benchmarks. The authors suggest that
    improving data quality can dramatically change the shape of scaling laws.More
    work has shown that models can be substantially smaller with only a modest drop
    in accuracy (*One Wide Feedforward is All You Need*, Pessoa Pires and others,
    2023), which supports the argument for a democratization of model training and
    access. Further, techniques such as transfer learning, distillation and prompting
    techniques can enable smaller models to leverage capabilities of large foundations
    without replicating their costs. In order to compensate for limitations, tools
    like search engines and calculators have been incorporated into agents and multi-step
    reasoning strategies, plugins, and extensions may be increasingly used to expand
    capabilities.AI training costs are dropping because of different factors – according
    to ARK Investment Management LLC, about 70% per year. A recently released AI training
    tools by Mosaic ML can train language models to GPT-3 level performance for roughly
    one-tenth the estimated $4.6 million just two years ago. This will enable experimentation,
    but advances will increasingly emerge from training regimes, data quality, and
    novel architectures rather than model size alone. After an arms race dominated
    by resource-rich big tech firms, responsible, economical innovation may become
    the priority.In a timeframe of 3-5 years (2025-2027), constraints around computing
    and talent availability could ease considerably, eroding the centralized moat.
    Specifically, if cloud computing costs decline as projected, and AI skills become
    more widespread through education and automated tools, self-training customized
    LLMs may become feasible for many companies. This could better serve needs for
    personalization and data privacy.Some abilities, however, such as in-context learning,
    are not predictable according to the scaling laws and only emerge in large models.
    It has been further speculated that enormous models trained on even more data
    may exhibit more behaviors and skills, where extreme scaling could eventually
    produce **artificial general intelligence** (**AGI**) – reasoning on par or beyond
    human intellect. However, from a neuroscience perspective, the threat of AGI taking
    over the world seems highly exaggerated at our present stage of technology (compare
    Jaan Aru and others, *The feasibility of artificial consciousness through the
    lens of neuroscience*; 2023):'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: '**Lack of embodied, embedded information**: LLMs today are trained purely on
    textual data rather than the rich multimodal inputs that allow humans to develop
    common sense reasoning about the physical world. This absence of grounded learning
    poses a major obstacle to developing human-level intelligence.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**缺乏具象、嵌入信息**：当前的大型语言模型仅在文本数据上接受训练，而不是像人类那样通过丰富的多模态输入来发展对物理世界的常识推理。这种缺乏扎根的学习给发展人类级别的智能带来了重大障碍。'
- en: '**Different architecture from biological brains**: The relatively simple stacked
    transformer architecture used in models like GPT-4 lacks the complex recurrent
    and hierarchical structures of the thalamocortical system thought to enable consciousness
    and general reasoning in humans.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**与生物大脑的不同架构**：类似GPT-4这样的模型中使用的相对简单的堆叠变压器架构缺乏被认为能够启动人类意识和一般推理的复杂经常性和层次性结构。'
- en: '**Narrow capabilities**: Existing models remain specialized for particular
    domains like text and fall short in flexibility, causal reasoning, planning, social
    skills, and general problem-solving intelligence. This could change either with
    increasing tool use or with fundamental changes to the models.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**狭窄的能力**：现有模型仍然专门针对特定领域，如文本，并在灵活性、因果推理、规划、社交技能和一般问题解决智能方面表现不佳。这种情况可能会随着工具使用的增加或模型的根本性变化而改变。'
- en: '**Minimal social abilities or intent**: Current AI systems have no innate motivations,
    social intelligence, or intent beyond their training objectives. Fears of malicious
    goals or desire for domination seem unfounded.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**社会能力或意图有限**：当前的人工智能系统没有固有动机、社交智能或超出培训目标的意图。对恶意目标或对统治的欲望的担忧似乎没有根据。'
- en: '**Limited real-world knowledge**: Despite ingesting huge datasets, the factual
    knowledge and common sense of large models remains very restricted compared to
    humans. This impedes applicability in the physical world.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**有限的现实世界知识**：尽管摄取了大量数据集，大型模型的事实知识和常识与人类相比仍然非常有限。这影响了在物理世界中的适用性。'
- en: '**Data-driven limitations**: Reliance on pattern recognition from training
    data rather than structured knowledge makes reliable generalization to novel situations
    difficult.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于数据驱动的局限性**：依赖于训练数据中的模式识别，而非结构化知识，使得可靠地推广到新颖情况变得困难。'
- en: Given these arguments, the risk of today’s AI precipitously evolving into malicious
    superintelligence seems highly improbable. That said, thoughtfully addressing
    longer-term safety research and ethics remains prudent as capabilities continue
    advancing. But fears of imminent world takeover are not substantiated by evidence
    from neuroscience or current model capabilities. Therefore, claims of inevitable,
    imminent AGI lack rigorous support.However, the sheer pace of advancement creates
    unease surrounding human obsolescence and job displacement, which could further
    divide economic classes. Unlike physical automation of the past, generative AI
    threatens cognitive job categories previously considered safe from automation.
    Managing this workforce transition ethically and equitably will require foresight
    and planning. There are also philosophical debates around whether AI should be
    creating art, literature or music that has historically reflected the human condition.
    Let’s think a bit more broadly about the societal impact!
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于这些论点，如今人工智能迅速演化为恶意超级智能的风险似乎高度不太可能。也就是说，随着能力不断提升，深思熟虑地处理长期安全研究和伦理问题仍然是明智之举。但是，当前神经科学或模型能力的证据并不支持对即将到来的人工智能普遍性的不可避免和迫在眉睫的主张。然而，快速进步的速度引发了人类淘汰和失业的担忧，这可能进一步分化经济阶级。与过去的物理自动化不同，生成式人工智能威胁到先前被认为免于自动化的认知工作类别。道德和公平地管理这种劳动力转型将需要远见和规划。还有关于人工智能是否应该创作反映人类状况的艺术、文学或音乐的哲学辩论。让我们更广泛地考虑社会影响吧！
- en: Societal Implications
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 社会影响
- en: The advent of highly capable generative AI will likely transform many aspects
    of society in coming years. As generative models continue to develop and add value
    to businesses and creative projects, generative AI will shape the future of technology
    and human interaction across domains. While their widespread adoption brings forth
    numerous benefits and opportunities for businesses and individuals, it is crucial
    to address the ethical and societal concerns that arise from increasing reliance
    on AI models in various fields.Generative AI offers immense potential benefits
    across personal, societal, and industrial realms if deployed thoughtfully. At
    a personal level, these models can enhance creativity and productivity, and increase
    accessibility to services like healthcare, education and finance. Democratizing
    access to knowledge resources, they can help students learn or aid professionals
    make decisions by synthesizing expertise. As virtual assistants, they provide
    instant, customized information to facilitate routine tasks. By automating rote
    tasks, they may free up human time for higher-value work, boosting economic output.
    Economically, the gains in productivity will most likely result in massive disruptions
    of certain job categories. New industries and jobs may emerge to support AI systems.
    Thoughtfully considering and addressing these changes is crucial. As models become
    better and running them becomes cheaper, this could trigger a massive expansion
    of generative AI and LLM applications to new areas. On top of the reduction in
    hardware costs, with every cumulative doubling of AI systems produced, costs may
    fall by 10-30% according to Wright’s Law. This cost curve reflects efficiencies
    like reuse of code, tools and techniques. A virtuous cycle arises as lower costs
    expand adoption, which drives further cost reductions. This will lead to a feedback
    cycle of more efficiency driving more use driving more efficiency.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 高度完善的生成式人工智能的出现很可能会在未来几年改变社会的许多方面。随着生成模型的不断发展和为企业和创意项目增加价值，生成式人工智能将塑造技术和人类交互在各个领域的未来。尽管它们的广泛应用为企业和个人带来了许多好处和机遇，但对于日益依赖各个领域的AI模型所引发的伦理和社会问题，有必要加以重视和解决。如果能够慎重部署，生成式人工智能在个人、社会和工业领域都能带来巨大的潜在好处。在个人层面，这些模型可以增强创造力和生产力，增加对健康、教育和金融等服务的可及性。它们能够使知识资源的获取民主化，通过综合专业知识帮助学生学习或为专业人士做决策。作为虚拟助手，它们能够提供即时定制的信息，以便完成例行任务。通过自动化机械任务，它们可能会释放出人类的时间，从而提高更高价值工作的经济产出。从经济上讲，生产力的提高很可能会导致某些工作类别的大规模中断。新兴产业和工作可能会出现来支持AI系统。认真考虑和解决这些变化是至关重要的。随着模型的不断改进和运行成本的降低，这可能会触发生成式人工智能和LLM应用在新领域大规模扩展。除了硬件成本的降低外，根据赖特定律，随着每次累计生产倍增，成本可能会以10-30%的速度下降。这种成本曲线反映了诸如代码、工具和技术的重复利用等效率。随着成本的降低扩大了采用率，进一步推动了成本的降低。这将导致一个反馈周期，更多的效率推动更多的使用驱动更多的效率。
- en: '**Wright’s Law**, also known as the **experience curve effect**, is an observation
    in economics and business that states that for many products, costs decline by
    a fixed percentage each time cumulative production doubles. Specifically, it states
    that costs tend to decrease by a fixed percentage (typically ranging from 10-30%)
    for each cumulative doubling of production.'
  id: totrans-54
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**赖特定律**，又称**经验曲线效应**，是经济学和商业领域的一项观察，它指出对于许多产品，成本在每次累计生产翻倍时都会以固定百分比下降。具体来说，它指出在每次累计生产翻倍时，成本
    tend to decrease by a fixed percentage（通常在10-30%范围内）。'
- en: ''
  id: totrans-55
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The law is named after Theodore Paul Wright, an American aircraft engineer who
    first observed this phenomenon in 1936 when analyzing trends in aircraft production
    costs. Wright noticed that every time the cumulative production of airframes doubled,
    the labor required to produce them decreased by 10-15%.
  id: totrans-56
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 该定律以西奥多·保罗·赖特命名，他是一位美国飞机工程师，于1936年在分析飞机生产成本趋势时首次观察到这一现象。赖特注意到，每当飞机机身的累计生产量翻倍时，生产所需的劳动力就会减少10-15%。
- en: ''
  id: totrans-57
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'This relationship can be expressed mathematically as:'
  id: totrans-58
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这种关系可以用数学方式表达为：
- en: ''
  id: totrans-59
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](img/file67.png)'
  id: totrans-60
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_IMG
  zh: '![](img/file67.png)'
- en: ''
  id: totrans-61
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Where *C*[1] represents the cost to produce the first unit, *C*[*x*] the cost
    to produce the xth unit, and b is the progress ratio, which has been estimated
    across numerous industries between 0.75 to 0.9.
  id: totrans-62
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 其中，*C*[1]代表生产第一单位的成本，*C*[*x*]代表生产第x单位的成本，b代表进步比率，该比率在许多行业估计在0.75到0.9之间。
- en: ''
  id: totrans-63
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The logic behind Wright’s Law is that as production increases, workers become
    more efficient in manufacturing a product through practice, standardized workflows,
    and developing better tools and processes. Companies also identify ways to optimize
    supply chains, logistics and resource utilization to reduce costs.
  id: totrans-64
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 沃特定律背后的逻辑是随着生产增加，工人通过实践、标准化工作流程和开发更好的工具和流程，在制造产品方面变得更加高效。公司还会找到优化供应链、物流和资源利用的方法，以降低成本。
- en: Industrially, the models bring extensive opportunities to augment human capabilities
    and remake workflows. In content production, generative AI can draft initial versions
    for marketing campaigns or journalistic pieces faster than humans, enabling greater
    creativity and customization. For developers, autogenerated code and rapid iterations
    accelerate software building. Researchers can quickly synthesize discoveries from
    papers to advance science.Generative AI also facilitates new levels of personalization
    at scale for consumers. Recommendations can be tailored down to the individual.
    Marketing across segments and geographies can be customized. Overall, these models
    can enhance productivity across sectors from industrial design to supply chains.As
    for the spread of the technology, two primary scenarios exist. In the first scenario,
    each company or individual trains their own tailored model using their proprietary
    data. However, this requires considerable AI/ML expertise to properly develop,
    train and deploy such systems - talent that remains scarce and expensive currently.
    The computational costs are also extremely high, with specialized hardware like
    clusters of GPUs costing substantial sums only feasible for large entities. There
    are further risks around data privacy compliance when models are trained on sensitive
    information. If these barriers around expertise, computing requirements and data
    privacy can be overcome, personalized LLMs fine-tuned to an organization’s particular
    goals and data could significantly enhance their productivity and efficiency by
    automating routine tasks and offering insights customized to the specific business.
    However, a downside is that models trained on small, private datasets may lack
    the generalization capability of those trained on much larger diverse public corpuses.Both
    centralized and self-service models can co-exist serving different use cases.
    In the near term, large tech firms have strengths in providing industry-specific
    fine-tuning services given their resources. But over time, more in-house training
    may emerge driven by customization and privacy needs.The pace of progress on reducing
    costs, spreading expertise, and addressing robustness challenges will determine
    how long any centralized advantage persists. Rapid innovations in these areas
    favor erosion of the moat, but platform effects around dominant frameworks, datasets
    and models could enable continued concentration among current leaders.If robust
    tools emerge to simplify and automate AI development, custom generative models
    may even be viable for local governments, community groups, and individuals to
    address hyper-local challenges. While centralized Big Tech firms benefit currently
    from economies of scale, distributed innovation from smaller entities could unlock
    generative AI’s full potential across all sectors of society.Finally, the emergence
    of generative AI intersects with broader shifts in how we produce and consume
    creative works. The internet has already fostered a remix culture where derivative
    works and collaborative content creation are commonplace. As AI models generate
    new artifacts by recombining existing materials, they align with remix culture
    principles of iterative, collective production.However, the scale at which generative
    models can synthesize and repurpose copyrighted content raises challenging legal
    questions. With models trained on vast datasets of books, articles, images and
    more, attributing rights and royalties could become incredibly complex. Current
    detection mechanisms are unable to find content authored by generative AI at above
    chance level. This speaks to wider debates surrounding authorship and copyright
    law.Let’s look at the different aspects, where generative models will have profound
    near-term impacts, starting with creative endeavors.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在工业上，这些模型带来了广泛的机会，可以增强人类的能力并改变工作流程。在内容生产中，生成式人工智能可以比人类更快地为营销活动或新闻报道起草初稿，从而促进更大的创造力和定制。对于开发人员，自动生成的代码和快速迭代可以加快软件构建的速度。研究人员可以快速从论文中综合出新的发现，推动科学的进步。生成式人工智能还可以以大规模进行个性化定制。推荐内容可以精细到个人。市场推广可以针对不同的细分市场和地理位置进行定制。总的来说，这些模型可以提高从工业设计到供应链等各个领域的生产率。至于这项技术的推广，存在两种主要的情景。在第一种情况下，每家公司或个人都会使用自己的专有数据来训练定制模型。然而，这需要相当的人工智能/机器学习专业知识才能正确地开发、训练和部署这样的系统——这样的专业人才目前依然稀缺且昂贵。计算成本也极其高昂，专门的硬件如大量昂贵的GPU集群只适用于大型实体。在模型以敏感信息进行训练时也存在进一步的数据隐私合规风险。如果这些围绕专业知识、计算要求和数据隐私的障碍能够克服，那么精细调整的LLM（大语言模型）可以显著提高组织的生产率和效率，通过自动化例行任务和提供适合特定业务的见解。然而，一个缺点是在小型私有数据集上训练的模型可能缺乏大规模公共语料库上训练的模型的泛化能力。集中式和自助式模型可以共存，为不同的用例提供服务。短期内，大型科技公司在提供行业特定的精细调整服务方面具有优势。但随着时间的推移，更多的内部训练可能会出现，这是由定制和隐私需求驱动的。降低成本、传播专业知识和解决健壮性挑战的进展速度将决定集中式优势的持续时间。在这些领域的快速创新有利于瓦解留下的障碍，但围绕主导性框架、数据集和模型的平台效应可能使当前领导者继续聚集。如果出现了简化和自动化人工智能开发的强大工具，定制的生成模型甚至可能对地方政府、社区组织和个人来应对超局部挑战具有可行性。尽管目前大型科技公司受益于规模经济，但由小型实体驱动的分布式创新可能会释放生成式人工智能在社会各个领域的全部潜力。最后，生成式人工智能的出现与我们如何生产和消费创意作品的更广泛变化相交。互联网已经培育出了一个混搭文化，其中衍生作品和协作内容的创建非常普遍。随着人工智能模型通过重新组合现有材料生成新的作品，它们符合混搭文化的迭代、集体生产原则。然而，生成模型可以合成和重新利用受版权保护的内容的规模提出了棘手的法律问题。利用广泛数据集训练的模型，包括书籍、文章、图像等，归因权和版税问题可能变得非常复杂。当前的检测机制无法以高于机会水平的准确率找到由生成式人工智能创作的内容。这反映出了围绕作者身份和版权法的更广泛争论。让我们来看看生成模型在不同方面将产生深远的近期影响，从创意努力开始。
- en: Creative industries and advertising
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 创意产业和广告
- en: The gaming and entertainment industries are leveraging generative AI to craft
    uniquely immersive user experiences. Major efficiency gains from automating creative
    tasks could increase leisure time spent online. Generative AI can enable machines
    to generate new and original content, such as art, music, and literature, by learning
    from patterns and examples. This has implications for creative industries, as
    it can enhance the creative process and potentially create new revenue streams.
    It also unlocks new scales of personalized, dynamic content creation for media,
    film, and advertising. However, generative content requires extensive quality
    control around accuracy and eliminating biases before full deployment.For media,
    film, and advertising, AI unlocks new scales of personalized, dynamic content
    creation. In journalism, automated article generation using massive datasets can
    free up reporters to focus on more complex investigative stories. **AI-generated
    content** (**AIGC**) is playing a growing role in transforming media production
    and delivery by enhancing efficiency and diversity. In journalism, text generation
    tools automate writing tasks traditionally done by human reporters, significantly
    boosting productivity while maintaining timeliness. Media outlets like Associated
    Press generate thousands of stories per year using AIGC. Robot reporters like
    Los Angeles Times’ Quakebot can swiftly produce articles on breaking news. Other
    applications include Bloomberg News’ Butletin service where chatbots create personalized
    one-sentence news summaries. AIGC also enables AI news anchors that co-present
    broadcasts with real anchors by mimicking human appearance and speech from text
    input. Chinese news agency Xinhua’s virtual presenter Xin Xiaowei is an example,
    presenting broadcasts from different angles for an immersive effect.AIGC is transforming
    movie creation from screenwriting to post-production. AI screenwriting tools analyze
    data to generate optimized scripts. Visual effects teams blend AI-enhanced digital
    environments and de-aging with live footage for immersive visuals. Deep fake technology
    recreates or revives characters convincingly.AI also powers automated subtitle
    generation, even predicting dialogue in silent films by training models on extensive
    audio samples. This expands accessibility via subtitles and recreates voiceovers
    synchronized to scenes. In post-production, AI color grading and editing tools
    like Colourlab.Ai and Descript simplify processes like color correction using
    algorithms.In advertising, AIGC unlocks new potential for efficient, customized
    advertising creativity and personalization. AI-generated content allows advertisers
    to create personalized, engaging ads tailored to individual consumers at scale.
    Platforms like Creative Advertising System (CAS) and Personalized Advertising
    Copy Intelligent Generation System (SGS-PAC) leverage data to automatically generate
    ads with messaging targeted to specific user needs and interests.AI also assists
    in advertising creativity and design – Tools like Vinci produce customized attractive
    posters from product images and slogans, while companies like Brandmark.io generate
    logo variations based on user preferences. GAN technologies automate product listing
    generation with keywords for effective peer-to-peer marketing. Synthetic ad production
    is also on the rise, enabling highly personalized, scalable campaigns that save
    time.In music, tools like Google’s Magenta, IBM’s Watson Beat, or Sony CSL’s Flow
    Machine can generate original melodies and compositions. AIVA similarly creates
    unique compositions from parameters tuned by users. LANDR’s AI mastering uses
    machine learning to process and improve digital audio quality for musicians.In
    visual arts, MidJourney uses neural networks to generate inspirational images
    that can kickstart painting projects. Artists have used its outputs to create
    prize-winning works. DeepDream’s algorithm imposes patterns on images, creating
    psychedelic art. GANs can generate abstract paintings converging on a desired
    style. AI painting conservation analyzes artwork to digitally repair damage and
    restore pieces.Animation tools like Adobe’s Character Animator or Anthropic’s
    Claude can help with the generation of customized characters, scenes and motion
    sequences opening animation potential for non-professionals. ControlNet adds constraints
    to steer diffusion models, increasing output variability. For all these applications,
    advanced AI expands creative possibilities through both generative content and
    data-driven insights. It is important to note however that generative content
    requires extensive quality control around accuracy and eliminating biases before
    full deployment. For advertising, ethical use of consumer data and human oversight
    remain important. In all cases, properly attributing contributions of human artists,
    developers and training data remains an ongoing challenge as adoption spreads.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: Economic
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The deployment of generative AI and other technologies could help accelerate
    productivity growth, partially compensating for declining employment growth and
    enabling overall economic growth. Assuming energy and computing can scale sustainably,
    the huge productivity gains from integrating generative AI into business processes
    seem likely to usher automation of many tasks over the next decade. However, this
    transition may disrupt labor markets, requiring adjustments. Research by McKinsey
    and Company estimates 30-50% of current work activities could be automated by
    2030-2060\. Generative AI could boost global productivity by $6-8 trillion annually
    by 2030, adding 15-40% onto previous estimates for AI’s economic impact. According
    to Tyna Eloundou and colleagues (*GPTs are GPTs: An Early Look at the Labor Market
    Impact Potential of Large Language Models*, 2023) around 80% of US workers have
    at least 10% of work tasks affected by LLMs, while 19% may have over 50% of tasks
    impacted. Effects span all wage levels, with higher-wage jobs facing more exposure.
    Just 15% of all US worker tasks could be done significantly faster with LLMs alone.
    But with LLM-powered software, this increases to 47-56% of all tasks, showing
    the big impact of complementary technologies.From a geographic perspective, external
    private investment in generative AI, mostly from tech giants and venture capital
    firms, is largely concentrated in North America, reflecting the continent’s current
    domination of the overall AI investment landscape. Generative AI–related companies
    based in the United States raised about $8 billion from 2020 to 2022, accounting
    for 75 percent of total investments in such companies during that period.Automation
    adoption is likely to be faster in developed economies, where higher wages will
    make it economically feasible sooner. The scale of work automation does not directly
    equate to job losses. Like other technologies, generative AI typically enables
    individual activities within occupations to be automated, not entire occupations.
    However, organizations may decide to realize the benefits of increased productivity
    by reducing employment in some job categories.Productivity growth, the main engine
    of GDP growth over the past 30 years, slowed down in the past decade. The deployment
    of generative AI and other technologies could help accelerate productivity growth,
    partially compensating for declining employment growth and enabling overall economic
    growth. Based on estimates by analysts at McKinsey and Company, the automation
    of individual work activities could provide the global economy with an annual
    productivity boost of 0.2 to 3.3 percent from 2023 to 2040 depending on the rate
    of automation adoption, however, only if individuals affected by the technology
    were to shift to other work activities that at least match their 2022 productivity
    levels.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: Education
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: One potential near-future scenario is that the rise of personalized AI tutors
    and mentors could democratize access to education for high-demand skills aligned
    with an AI-driven economy. In the education sector, generative AI is already transforming
    how we teach and learn. Tools like ChatGPT can be used to automatically generate
    personalized lessons and customized content for individual students. This reduces
    instructor workloads substantially by automating repetitive teaching tasks. AI
    tutors provide real-time feedback on student writing assignments, freeing up teachers
    to focus on more complex skills. Virtual simulations powered by generative AI
    can also create engaging, tailored learning experiences adapted to different learners’
    needs and interests.However, risks around perpetuating biases and spreading misinformation
    need to be studied further as these technologies evolve. The accelerating pace
    of knowledge and the obsolescence of scientific findings means that training children’s
    curiosity-driven learning should focus on developing the cognitive mechanisms
    involved in initiating and sustaining curiosity, such as awareness of knowledge
    gaps and the use of appropriate strategies to resolve them.While AI tutors tailored
    to each student could enhance outcomes and engagement, poorer schools may be left
    behind, worsening inequality. Governments should promote equal access to prevent
    generative AI from becoming a privilege of the affluent. Democratizing opportunity
    for all students remains vital.If implemented thoughtfully, personalized AI-powered
    education could make crucial skills acquisition accessible to anyone motivated
    to learn. Interactive AI assistants that adapt courses to students’ strengths,
    needs and interests could make learning efficient, engaging and equitable. But
    challenges around access, biases, and socialization need addressing.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: Jobs
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Assuming energy and computing can scale sustainably, the huge productivity
    gains from integrating generative AI into business processes seem likely to usher
    automation of many tasks over the next decade. This transition may disrupt labor
    markets, requiring adjustments.Automation enabled by AI will likely displace many
    administrative, customer service, writing, legal, and creative jobs in the near
    term, while professions in agriculture and construction might be virtually unaffected.
    However, past industrial revolutions ultimately led to new types of jobs and industries,
    albeit with difficult workforce transitions. The same dynamic is likely to play
    out with AI automation over the long run. This will impact almost all occupations
    to some degree, though some will be affected more heavily. Generative AI’s ability
    to analyze and generate natural language content could significantly increase
    the automation potential for activities like communicating, collaborating and
    reporting across many white-collar occupations. However, the extent to which entire
    jobs are eliminated remains uncertain. Past technological innovations ultimately
    created new types of work, even if the transitions were difficult.According to
    research at McKinsey and company, about 75 percent of the value that generative
    AI use cases could deliver falls across four areas: Customer operations, marketing
    and sales, software engineering, and R&D. Prominent examples include generative
    AI’s ability to support interactions with customers, generate creative content
    for marketing and sales, and draft computer code based on natural-language prompts,
    among many other tasks.Language models and Generative AI carry the potential to
    disrupt and automate tasks within various industries that were traditionally performed
    by humans. As for different roles, these predictions seem credible:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: Junior software engineers may be augmented or replaced by AI coding assistants.
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Analysts and advisors utilizing data insights from AI Customer service agents
    replaced by conversational AI.
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical writers and journalists aided by AI content generation.
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Teachers leveraging AI for course prep and personalized tutoring.
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Paralegals utilizing AI for summarization and document review.
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Graphic designers will be empowered by AI image generation, however, making
    image creation and manipulation available to many more people could also have
    an impact on wages.
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: However, demand will remain strong for senior software engineers to develop
    specialized AI solutions and systems.
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data scientists may pivot from building predictive models to focusing more on
    validating, debugging and maximizing value from AI systems.
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Programmers will increasingly code tools to assist AI development.
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: New roles like prompt engineering have started to emerge.
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AI can perform certain tasks that extend to tasks involving natural language
    processing, content creation, and even intricate creative work, efficiently and
    with fewer errors than humans. Less skilled individuals may be able to perform
    more highly skilled work, while highly skilled individuals may be left with fewer
    job opportunities. For example, paralegals use boilerplate documents and fill
    in the necessary information to cater to clients’ needs. AI, equipped with vast
    knowledge of legal documents, legislation, university courses, journals, news
    articles, and court cases, can perform this task even better than paralegals.
    The result is a potential decrease in the need for junior lawyers for drafting
    purposes, with paralegals using AI-powered software to communicate clients’ specific
    requirements.Software developers and data scientists alike can benefit from the
    potential of LLMs but must carefully consider its capabilities and limitations
    for optimal use. For junior developers and data scientists, LLMs can automate
    routine tasks, provide basic solutions, and reduce errors, accelerating learning
    by freeing up time for more complex work. However, relying solely on AI risks
    hindering deeper technical growth, so LLMs should be seen as supportive tools
    while actively developing hands-on expertise.Senior developers and data scientists
    possess domain knowledge and problem-solving abilities beyond current AI capabilities.
    While automating standard solutions may save some time, their expertise is essential
    for guiding AI tools, ensuring reliable and scalable outcomes.The surge in AI
    productivity means that companies are in high demand for AI talent, and the competition
    for hiring and retaining this talent is fierce. There will also be a growing need
    for cybersecurity professionals who can protect AI systems from attack. Additionally,
    as AI systems become more prevalent, there may be more work in areas such as AI
    ethics, regulation, and public policy. Hence, investing in attracting and nurturing
    such talent is significant for companies to remain relevant in this rapidly evolving
    landscape.Creators in all sectors will be affected. In music, AI is aiding musicians
    across the creative process, from composing lyrics and melodies to digitally mastering
    and enhancing audio. Generative art tools allow visual artists to experiment with
    customized paintings catered to their unique styles.A Goldman Sachs study from
    March 2023 suggested that administrative and legal roles are most at risk. They
    estimated that about two thirds of current jobs will be exposed to automation
    by AI, and concluded that generative AI tools could impact 300 million full-time
    jobs worldwide, more than 20% of the current workforce. The pace of adoption is
    a critical unknown. McKinsey analysts estimated that automation could absorb between
    60 to 70 percent of employee hours so that between 2030 and 2060 about half of
    today’s work activities could be automated. According to PwC, by the mid-2030s,
    up to 30% of jobs could be automatable. But real-world adoption depends on many
    hard-to-predict factors like regulation, social acceptance and retraining policies.Knowledge
    work sectors such as software and app development are already seeing the effects
    of this transformation. Generative AI has been employed to streamline tasks ranging
    from initial code generation to image editing and design. It reduces repetitive
    manual work for developers and designers, enabling them to focus their efforts
    on higher-value innovation. However, meticulous monitoring and iterative correction
    of errors in auto-generated outputs remains critical.The large-scale automation
    of work activities could result in a major shift in labor demand, leading to substantial
    changes in occupation and necessitating employees to acquire new skills. Because
    their capabilities are fundamentally engineered to do cognitive tasks, Generative
    AI is likely to have the biggest impact on knowledge work, particularly activities
    involving decision making and collaboration, which previously had the lowest potential
    for automation. While previously, automation’s impact was highest in lower-middle-income
    quintiles, Further, Generative AI could have the biggest impact on activities
    in high-wage jobs. A significant number of workers will need to substantially
    change the work they do, either in their existing occupations or in new ones.
    They will also need support in making transitions to new activities.Managing this
    turnover will require policy foresight to minimize hardship for displaced workers
    through retraining programs, job creation incentives and portable benefits. If
    worker transitions and other risks can be managed, generative AI could contribute
    substantively to economic growth and support a more sustainable, inclusive world,
    where people are liberated from repetitive work.If the efficiency gains from AI
    automation are reinvested well, new industries and jobs could be created in the
    long run. But smooth workforce transitions will require policy foresight and employee
    training in the interim. In summary, while certain jobs may be displaced by AI
    in the near term, especially routine cognitive tasks, it may automate certain
    activities rather than eliminate entire occupations. Technical experts like data
    scientists and programmers will remain key to developing AI tools and realizing
    their full business potential.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: Law
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Generative models like LLMs can automate routine legal tasks such as contract
    review, documentation generation, and brief preparation. They also enable faster,
    comprehensive legal research and analysis. Additional applications include explaining
    complex legal concepts in plain language and predicting litigation outcomes using
    case data. However, responsible and ethical use remains critical given considerations
    around transparency, fairness and accountability. Overall, properly implemented
    AI tools promise to boost legal productivity and access to justice, while requiring
    ongoing scrutiny regarding reliability and ethics.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: Manufacturing
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the automotive sector, they are employed to generate 3D environments for
    simulations and aid in the development of cars. Additionally, generative AI is
    utilized for road testing autonomous vehicles using synthetic data. These models
    can also process object information to comprehend the surrounding environment,
    understand human intent through dialogues, generate natural language responses
    to human input, and create manipulation plans to assist humans in various tasks.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: Medicine
  id: totrans-89
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A model that can accurately predict physical properties from gene sequences
    would represent a major breakthrough in medicine and could have profound impacts
    on society. It could further accelerate drug discovery and precision medicine,
    enable earlier disease prediction and prevention, provide a deeper understanding
    of complex diseases, and improve gene therapies. However, it also raises major
    ethical concerns around genetic engineering and could exacerbate social inequalities.New
    techniques with neural networks are already employed to lower long-read DNA sequencing
    error rates (Baid and colleagues; *DeepConsensus improves the accuracy of sequences
    with a gap-aware sequence transformer*, September 2022), and according to a report
    by ARK Investment Management (2023), in the short-term, technology like this can
    make it already possible to deliver the first high-quality, whole long-read genome
    for less than $1,000\. This means that large-scale gene-to-expression models might
    not be far away either.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: Military
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Militaries worldwide are investing in research to develop lethal autonomous
    weapons systems (LAWS). Robots and drones can identify targets and deploy lethal
    force without any human supervision. Machines can process information and react
    faster than humans, removing emotion from lethal decisions. However, this raises
    significant moral questions. Allowing machines to determine if lives should be
    taken crosses a troubling threshold. Even with sophisticated AI, complex factors
    in war like proportionality and distinction between civilians and combatants require
    human judgment.If deployed, completely autonomous lethal weapons would represent
    an alarming step towards relinquishing control over life-and-death decisions.
    They could violate international humanitarian law or be used by despotic regimes
    to terrorize populations. Once unleashed fully independently, the actions of autonomous
    killer robots would be impossible to predict or restrain.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: Misinformation and cybersecurity
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: AI presents a dual-edged sword against disinformation. While it enables scalable
    detection, automation makes it easier to spread sophisticated, personalized propaganda.
    AI could help or harm security depending on whether it is used responsibly. It
    increases vulnerabilities to misinformation along with cyberattacks using generative
    hacking and social engineering. There are significant threats associated with
    AI techniques like micro-targeting and deepfakes. Powerful AI can profile users
    psychologically to deliver personalized disinformation that facilitates concealed
    manipulation, escaping broad examination Big data and AI could be leveraged to
    exploit psychological vulnerabilities and infiltrate online forums to attack and
    spread conspiracy theories. Disinformation has transformed into a multifaceted
    phenomenon, involving biased information, manipulation, propaganda, and intent
    to influence political behavior. For example, during the COVID-19 pandemic, the
    spread of misinformation and infodemics has been a major challenge. AI has a potential
    to influence public opinion on topics like elections, war, or foreign powers.It
    can also generate fake audio/video content to damage reputations and sow confusion.
    State and non-state actors are weaponizing these capabilities for propaganda,
    to damage reputations and sow confusion. AI can be used by political parties,
    governments, criminal groups, and even the legal system, launch lawsuits, and
    extract money. This likely will have far-reaching consequences in various domains.
    A significant portion of internet users may be obtaining the information they
    need without accessing external websites. There is a danger of large corporations
    being the gatekeepers of information and controlling public opinion, effectively
    being able to restrict certain actions or viewpoints.Careful governance and digital
    literacy are essential to build resilience. Though no single fix exists, collective
    efforts promoting responsible AI development can help democratic societies address
    emerging threats.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: Practical Implementation Challenges
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Realizing the potential of generative AI in a responsible manner involves addressing
    a number of practical legal, ethical and regulatory issues:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: '**Legal**: Copyright laws remain ambiguous regarding AI-generated content.
    Who owns the output - the model creator, training data contributors, or end users?
    Replicating copyrighted data in training also raises fair use debates that need
    clarification.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data Protection**: Collecting, processing and storing the massive datasets
    required to train advanced models creates data privacy and security risks. Governance
    models ensuring consent, anonymity and safe access are vital.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Oversight and Regulations**: Calls are mounting for oversight to ensure non-discrimination,
    accuracy and accountability from advanced AI systems. But flexible policies balancing
    innovation and risk are needed rather than burdensome bureaucracy.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Ethics**: Frameworks guiding development toward beneficial outcomes are indispensible.
    Integrating ethics through design practices focused on transparency, explicability
    and human oversight helps build trust.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Overall, proactive collaboration between policymakers, researchers and civil
    society is essential to settle unresolved issues around rights, ethics and governance.
    With pragmatic guardrails in place, generative models can fulfill their promise
    while mitigating harm. But public interest must remain the compass guiding AI
    progress.There is a growing demand for algorithmic transparency. This means that
    tech companies and developers should reveal the source code and inner workings
    of their systems. However, there is resistance from these companies and developers
    who argue that disclosing proprietary information would harm their competitive
    advantage. Open-source models will continue to thrive and local legislation in
    EU and other countries will push for transparent use of AI.The consequence of
    AI bias includes potential harm to individuals or groups due to biased decisions
    made by AI systems. Incorporating ethics training into computer science curricula
    can help reduce biases in AI codes. By teaching developers how to build applications
    that are ethical by design applications, the probability of biases being embedded
    into the codes can be minimized. To stay on the right path, organizations need
    to prioritize transparency, accountability, and guardrails to prevent bias in
    their AI systems. AI bias prevention is a long-term priority for many organizations,
    however, without legislation driving it, it can take time to be introduced. Local
    legislation in EU countries, for example, such as the European Commission’s proposal
    for harmonized rules on AI regulation, will drive more ethical use of language
    and imagery.A current German law on fake news, which imposes a 24-hour timeframe
    for platforms to remove fake news and hate speech, is impractical for both large
    and small platforms. Additionally, the limited resources of smaller platforms
    make it unrealistic for them to police all content. Further, online platforms
    should not have the sole authority to determine what is considered truth, as this
    could lead to excessive censorship. More nuanced policies are needed that balance
    free speech, accountability, and feasibility for a diversity of technology platforms
    to comply. Relying solely on private companies to regulate online content raises
    concerns around lack of oversight and due process. Broader collaboration between
    government, civil society, academics, and industry can develop more effective
    frameworks to counter misinformation while protecting rights.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: The Road Ahead
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The forthcoming era of generative AI models offers a plethora of intriguing
    opportunities and unparalleled progression, yet it is interspersed with numerous
    uncertainties. As discussed in this book, many breakthroughs have been accomplished
    in the recent years but successive challenges continue to linger, mainly pertaining
    to precision, rationalizing ability, controllability and entrenched bias within
    these models. While grandiose claims of superintelligent AI on the horizon may
    seem hyperbolic, consistent trends predict sophisticated capabilities sprouting
    within a few decades. On an individual level, the proliferation of generative
    content raises valid concerns around misinformation, plagiarism in academia, and
    impersonation in online spaces. As these models become more adept at mimicking
    human expression, people may have difficulty discerning what is human-generated
    versus AI-generated, enabling new forms of deception. There are also fears about
    generative models exacerbating social media addiction due to their ability to
    produce endless customized content.From a societal perspective, the sheer pace
    of advancement creates unease surrounding human obsolescence and job displacement,
    which could further divide economic classes. Unlike physical automation of the
    past, generative AI threatens cognitive job categories previously considered safe
    from automation. Managing this workforce transition ethically and equitably will
    require foresight and planning. There are also philosophical debates around whether
    AI should be creating art, literature or music that has historically reflected
    the human condition.For corporations, effective governance frameworks have yet
    to be established around acceptable use cases. Generative models amplify risks
    of misuse, ranging from creating misinformation such as deepfakes to generating
    unsafe medical advice. Legal questions around content licensing and intellectual
    property arise. While these models can enhance business productivity, quality
    control and bias mitigation incur additional costs. While large tech firms currently
    dominate generative AI research and development, smaller entities may ultimately
    stand to gain the most from these technologies. As costs decline for computing,
    data storage, and AI talent, custom pre-training of specialized models could become
    feasible for small and mid-sized companies. Rather than relying on generic models
    from Big Tech, tailored generative AI fine-tuned on niche datasets could better
    serve unique needs. Startups and non-profits often excel at rapidly iterating
    to build cutting-edge solutions for specialized domains. Democratized access through
    cost reductions could enable such focused players to train performant models exceeding
    capabilities of generalized systems. Concerns have emerged about saturation as
    generative AI tools are relatively easy to build using foundation models. Customization
    of models and tools is will allow value creation, but it’s unclear who will capture
    most upsides. While current market hype is high, investors are tempering decisions
    given lower valuations and skepticism following the 2021 AI boom/bust cycle. The
    long-term market impact and winning generative AI business models have yet to
    unfold.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: The **2021 AI boom/bust cycle** refers to a rapid acceleration in investment
    and growth in the AI startup space followed by a market cooldown and stabilization
    in 2022 as projections failed to materialize and valuations declined.
  id: totrans-104
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  id: totrans-105
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Here’s a quick summary:'
  id: totrans-106
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  id: totrans-107
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Boom Phase (2020-2021):'
  id: totrans-108
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  id: totrans-109
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: There was huge interest and skyrocketing investment in AI startups offering
    innovative capabilities like computer vision, natural language processing, robotics,
    and machine learning platforms. Total funding for AI startups hit record levels
    in 2021, with over $73 billion invested globally according to Pitchbook. Hundreds
    of AI startups were founded and funded during this period.
  id: totrans-110
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  id: totrans-111
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Bust Phase (2022):'
  id: totrans-112
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  id: totrans-113
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In 2022, the market underwent a correction, with valuations of AI startups falling
    significantly from their 2021 highs. Several high-profile AI startups like Anthropic
    and Cohere faced valuation markdowns. Many investors became more cautious and
    selective with funding AI startups. Market corrections in the broader tech sector
    also contributed to the bust.
  id: totrans-114
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  id: totrans-115
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Key Factors:'
  id: totrans-116
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  id: totrans-117
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Excessive hype, unrealistic growth projections, historically high valuations
    in 2021, and broader economic conditions all contributed to the boom-bust cycle.
    The cycle followed a classic pattern seen previously in sectors like dot-com and
    blockchain.
  id: totrans-118
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Looking decades ahead, perhaps the deepest challenges are ethical. As AI is
    entrusted with more consequential decisions, alignment with human values becomes
    critical. While accuracy, reasoning ability, controllability, and mitigating bias
    remain technical priorities, other priorities should include fortifying model
    robustness, promoting transparency and ensuring alignment with human values. In
    order to maximize benefits, companies need to ensure human oversight, diversity,
    and transparency in development. Policy makers may need to implement guardrails
    preventing misuse while providing workers with support to transition as activities
    shift. With responsible implementation, generative AI could propel growth, creativity
    and accessibility in a more prosperous society. Addressing potential risks early
    on and ensuring a just distribution of benefits designed to serve public welfare
    will cultivate a sense of trust among stakeholders, such as:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: '**The Dynamics of Progress**: Fine-tuning the pace of transformation is critical
    to avoid any undesired repercussions. Moreover, excessively slow developments
    could stifle innovation, suggesting that determining an ideal pace through encompassing
    public discourse is crucial.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The Human-AI Symbiosis**: Rather than striving for outright automation, more
    advantageous systems would integrate and complement the creative prowess of humans
    with the productive efficiency of AI. Such a hybrid model will ensure optimal
    oversight.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Promoting Access and Inclusion**: Equitable access to resources, relevant
    education and myriad opportunities concerning AI is key to negating the amplification
    of disparities. Representativeness and diversity should be prioritized.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Preventive Measures and Risk Management**: Constant evaluation of freshly
    emerging capabilities via interdisciplinary insights is necessary to evade future
    dangers. Excessive apprehensions, however, should not impede potential progress.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Upholding Democratic Norms**: Collaborative discussions, communal efforts
    and reaching compromise will inevitably prove more constructive in defining the
    future course of AI, as compared to unilateral decrees imposed by a solitary entity.
    Public interest must take precedence.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While future capabilities remain uncertain, proactive governance and democratization
    of access are essential to direct these technologies toward equitable, benevolent
    outcomes. Collaboration between researchers, policymakers and civil society around
    issues of transparency, accountability and ethics can help align emerging innovations
    with shared human values. The goal should be empowering human potential, not mere
    technological advancement.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
