["```py\npip install streamlit altair\n```", "```py\nimport streamlit as st\n\nchosen_option = st.sidebar.selectbox('Hello', ['A', 'B', 'C'])\nst.write(chosen_option)\n```", "```py\nstreamlit run streamlit_test.py --server.port=80\n```", "```py\nimport numpy as np\nimport pandas as pd\nimport altair as alt\nimport streamlit as st\n\nfrom sklearn.datasets import (\n    load_iris,\n    load_wine,\n    fetch_covtype\n)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import (\n    RandomForestClassifier,\n    ExtraTreesClassifier,\n)\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import classification_report\n\n```", "```py\ndataset_lookup = {\n    'Iris': load_iris,\n    'Wine': load_wine,\n    'Covertype': fetch_covtype,\n}\n\n@st.cache\ndef load_data(name):\n    iris = dataset_lookup[name]()\n    X_train, X_test, y_train, y_test = train_test_split(\n        iris.data, iris.target, test_size=0.33, random_state=42\n    )\n    feature_names = getattr(\n        iris, 'feature_names',\n        [str(i) for i in range(X_train.shape[1])]\n    )\n    target_names = getattr(\n        iris, 'target_names',\n        [str(i) for i in np.unique(iris.target)]\n    )\n    return (\n        X_train, X_test, y_train, y_test,\n        target_names, feature_names\n    )\n```", "```py\n@st.cache\ndef train_model(dataset_name, model_name, n_estimators, max_depth):\n    model = [m for m in models if m.__class__.__name__ == model_name][0]\n    with st.spinner('Building a {} model for {} ...'.format(\n            model_name, dataset_name\n    )):\n        return model.fit(X_train, y_train)\n```", "```py\nst.sidebar.title('Model and dataset selection')\ndataset_name = st.sidebar.selectbox(\n    'Dataset',\n    list(dataset_lookup.keys())\n)\n(X_train, X_test, y_train, y_test,\n target_names, feature_names) = load_data(dataset_name)\n```", "```py\nn_estimators = st.sidebar.slider(\n    'n_estimators',\n    1, 100, 25\n)\nmax_depth = st.sidebar.slider(\n    'max_depth',\n    1, 150, 10\n)\n```", "```py\nmodels = [\n    DecisionTreeClassifier(max_depth=max_depth),\n    RandomForestClassifier(\n        n_estimators=n_estimators,\n        max_depth=max_depth\n    ),\n    ExtraTreesClassifier(\n        n_estimators=n_estimators,\n        max_depth=max_depth\n    ),\n]\nmodel_name = st.sidebar.selectbox(\n    'Model',\n    [m.__class__.__name__ for m in models]\n)\nmodel = train_model(dataset_name, model_name, n_estimators, max_depth)\n```", "```py\nst.title('{model} on {dataset}'.format(\n    model=model_name,\n    dataset=dataset_name\n))\n```", "```py\npredictions = model.predict(X_test)\nprobs = model.predict_proba(X_test)\nst.subheader('Model performance in test')\nst.write('AUC: {:.2f}'.format(\n    roc_auc_score(\n        y_test, probs,\n        multi_class='ovo' if len(target_names) > 2 else 'raise',\n        average='macro' if len(target_names) > 2 else None\n    )\n))\nst.write(\n    pd.DataFrame(\n        classification_report(\n            y_test, predictions,\n            target_names=target_names,\n            output_dict=True\n        )\n    )\n) \n```", "```py\ntest_df = pd.DataFrame(\n    data=np.concatenate([\n        X_test,\n        y_test.reshape(-1, 1),\n        predictions.reshape(-1, 1)\n    ], axis=1),\n    columns=feature_names + [\n        'target', 'predicted'\n    ]\n)\ntarget_map = {i: n for i, n in enumerate(target_names)}\ntest_df.target = test_df.target.map(target_map)\ntest_df.predicted = test_df.predicted.map(target_map)\nconfusion_matrix = pd.crosstab(\n    test_df['target'],\n    test_df['predicted'],\n    rownames=['Actual'],\n    colnames=['Predicted']\n)\nst.subheader('Confusion Matrix')\nst.write(confusion_matrix)\n```", "```py\ndef highlight_error(s):\n    if s.predicted == s.target:\n        return ['background-color: None'] * len(s)\n    return ['background-color: red'] * len(s)\n\nif st.checkbox('Show test data'):\n    st.subheader('Test data')\n    st.write(test_df.style.apply(highlight_error, axis=1))\n```", "```py\nif st.checkbox('Show test distributions'):\n    st.subheader('Distributions')\n    row_features = feature_names[:len(feature_names)//2]\n    col_features = feature_names[len(row_features):]\n    test_df_with_error = test_df.copy()\n    test_df_with_error['error'] = test_df.predicted == test_df.target\n    chart = alt.Chart(test_df_with_error).mark_circle().encode(\n            alt.X(alt.repeat(\"column\"), type='quantitative'),\n            alt.Y(alt.repeat(\"row\"), type='quantitative'),\n            color='error:N'\n    ).properties(\n            width=250,\n            height=250\n    ).repeat(\n        row=row_features,\n        column=col_features\n    ).interactive()\n    st.write(chart)\n```", "```py\npip install mlflow\n```", "```py\nmlflow server --backend-store-uri sqlite:///mlflow.db --host 0.0.0.0 --default-artifact-root file://$PWD/mlruns\n```", "```py\n!pip install fastapi\n```", "```py\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\n\ncsv_url =\\\n    'http://archive.ics.uci.edu/ml/machine-' \\\n    'learning-databases/wine-quality/winequality-red.csv'\ndata = pd.read_csv(csv_url, sep=';')\n```", "```py\ntrain_x, test_x, train_y, test_y = train_test_split(\n    data.drop(['quality'], axis=1),\n    data['quality']\n)\n```", "```py\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n\ndef eval_metrics(actual, pred):\n    rmse = np.sqrt(mean_squared_error(actual, pred))\n    mae = mean_absolute_error(actual, pred)\n    r2 = r2_score(actual, pred)\n    return rmse, mae, r2\n```", "```py\nimport mlflow\n\nmlflow.set_tracking_uri('http://0.0.0.0:5000')\nmlflow.set_experiment('/wine')\n```", "```py\nfrom sklearn.linear_model import ElasticNet\nimport mlflow.sklearn\n\nnp.random.seed(40)\n\ndef train(alpha=0.5, l1_ratio=0.5):\n with mlflow.start_run():\n lr = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42)\n lr.fit(train_x, train_y)\n predicted = lr.predict(test_x)\n rmse, mae, r2 = eval_metrics(test_y, predicted)\n\n        model_name = lr.__class__.__name__\n        print('{} (alpha={}, l1_ratio={}):'.format(\n            model_name, alpha, l1_ratio\n        ))\n        print(' RMSE: %s' % rmse)\n        print(' MAE: %s' % mae)\n        print(' R2: %s' % r2)\n\n        mlflow.log_params({key: value for key, value in lr.get_params().items()})\n        mlflow.log_metric('rmse', rmse)\n        mlflow.log_metric('r2', r2)\n        mlflow.log_metric('mae', mae)\n        mlflow.sklearn.log_model(lr, model_name)\n```", "```py\ntrain(0.5, 0.5)\n```", "```py\nElasticNet (alpha=0.5, l1_ratio=0.5):\n  RMSE: 0.7325693777577805\n  MAE: 0.5895721434715478\n  R2: 0.12163690293641838\n```", "```py\nmlflow models serve -m /Users/ben/mlflow/examples/sklearn_elasticnet_wine/mlruns/1/208e2f5250814335977b265b328c5c49\n/artifacts/ElasticNet/\n```", "```py\ncurl -X POST -H \"Content-Type:application/json; format=pandas-split\" --data '{\"columns\":[\"alcohol\", \"chlorides\", \"citric acid\", \"density\", \"fixed acidity\", \"free sulfur dioxide\", \"pH\", \"residual sugar\", \"sulphates\", \"total sulfur dioxide\", \"volatile acidity\"],\"data\":[[1.2, 0.231, 0.28, 0.61, 4.5, 13, 2.88, 2.1, 0.26, 63, 0.51]]}' http://127.0.0.1:1234/invocations\n```", "```py\n!git clone https://github.com/tensorflow/privacy\n```", "```py\nfrom torchvision import datasets\nimport torchvision.transforms as transforms\n\nbatch_size = 32\n\ntransform = transforms.Compose(\n    [transforms.ToTensor(),\n     transforms.Normalize((0.1307,), (0.3081,))]\n)\n\ntrain_data = datasets.MNIST(\n    root='data', train=True,\n    download=True,\n    transform=transform\n)\ntest_data = datasets.MNIST(\n    root='data', train=False,\n    download=True,\n    transform=transform\n)\n```", "```py\nnum_teachers = 100\n\ndef get_data_loaders(train_data, num_teachers=10):\n    teacher_loaders = []\n    data_size = len(train_data) // num_teachers\n\n    for i in range(num_teachers):\n        indices = list(range(i * data_size, (i+1) * data_size))\n        subset_data = Subset(train_data, indices)\n        loader = torch.utils.data.DataLoader(\n            subset_data,\n            batch_size=batch_size,\n            num_workers=num_workers\n        )\n        teacher_loaders.append(loader)\n\n    return teacher_loaders\n\nteacher_loaders = get_data_loaders(train_data, num_teachers)\n```", "```py\nimport torch\nfrom torch.utils.data import Subset\n\nstudent_train_data = Subset(test_data, list(range(9000)))\nstudent_test_data = Subset(test_data, list(range(9000, 10000)))\n\nstudent_train_loader = torch.utils.data.DataLoader(\n    student_train_data, batch_size=batch_size, \n    num_workers=num_workers\n)\nstudent_test_loader = torch.utils.data.DataLoader(\n    student_test_data, batch_size=batch_size, \n    num_workers=num_workers\n)\n```", "```py\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n        self.conv2_drop = nn.Dropout2d()\n        self.fc1 = nn.Linear(320, 50)\n        self.fc2 = nn.Linear(50, 10)\n\n    def forward(self, x):\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n        x = x.view(-1, 320)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, training=self.training)\n        x = self.fc2(x)\n        return F.log_softmax(x)\n```", "```py\ndef predict(model, dataloader):\n    outputs = torch.zeros(0, dtype=torch.long).to(device)\n    model.to(device)\n    model.eval()\n    for images, labels in dataloader:\n        images, labels = images.to(device), labels.to(device)\n        output = model.forward(images)\n        ps = torch.argmax(torch.exp(output), dim=1)\n        outputs = torch.cat((outputs, ps))\n\n    return outputs\n```", "```py\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n\ndef train(model, trainloader, criterion, optimizer, epochs=10, print_every=120):\n    model.to(device)\n    steps = 0\n    running_loss = 0\n    for e in range(epochs):\n        model.train()\n        for images, labels in trainloader:\n            images, labels = images.to(device), labels.to(device)\n            steps += 1         \n            optimizer.zero_grad()     \n            output = model.forward(images)\n            loss = criterion(output, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n```", "```py\nfrom tqdm.notebook import trange\n\ndef train_models(num_teachers):\n    models = []\n    for t in trange(num_teachers):\n        model = Net()\n        criterion = nn.NLLLoss()\n        optimizer = optim.Adam(model.parameters(), lr=0.003)\n        train(model, teacher_loaders[t], criterion, optimizer)\n        models.append(model)\n    return models\n\nmodels = train_models(num_teachers) \n```", "```py\nimport numpy as np\n\ndef aggregated_teacher(models, data_loader, standard_deviation=1.0):\n    preds = torch.torch.zeros((len(models), 9000), dtype=torch.long)\n    print('Running teacher predictions...')\n    for i, model in enumerate(models):\n        results = predict(model, data_loader)\n        preds[i] = results\n\n    print('Calculating aggregates...')\n    labels = np.zeros(preds.shape[1]).astype(int)\n    for i, image_preds in enumerate(np.transpose(preds)):\n        label_counts = np.bincount(image_preds, minlength=10).astype(float)\n        label_counts += np.random.normal(0, standard_deviation, len(label_counts))\n        labels[i] = np.argmax(label_counts)\n\n    return preds.numpy(), np.array(labels)\n\nstandard_deviation = 5.0\nteacher_models = models\npreds, student_labels = aggregated_teacher(\n    teacher_models,\n    student_train_loader,\n    standard_deviation\n)\n```", "```py\ndef student_loader(student_train_loader, labels):\n    for i, (data, _) in enumerate(iter(student_train_loader)):\n        yield data, torch.from_numpy(labels[i*len(data):(i+1)*len(data)])\n```", "```py\nstudent_model = Net()\ncriterion = nn.NLLLoss()\noptimizer = optim.Adam(student_model.parameters(), lr=0.001)\nepochs = 10\nstudent_model.to(device)\nsteps = 0\nrunning_loss = 0\nfor e in range(epochs):\n    student_model.train()\n    train_loader = student_loader(student_train_loader, student_labels)\n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n        steps += 1\n        optimizer.zero_grad()\n        output = student_model.forward(images)\n        loss = criterion(output, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n        # <validation code omitted>\n```", "```py\n        if steps % 50 == 0:\n            test_loss = 0\n            accuracy = 0\n            student_model.eval()\n            with torch.no_grad():\n                for images, labels in student_test_loader:\n                    images, labels = images.to(device), labels.to(device)\n                    log_ps = student_model(images)\n                    test_loss += criterion(log_ps, labels).item()\n\n                    ps = torch.exp(log_ps)\n                    top_p, top_class = ps.topk(1, dim=1)\n                    equals = top_class == labels.view(*top_class.shape)\n                    accuracy += torch.mean(equals.type(torch.FloatTensor))\n            student_model.train()\n            print('Training Loss: {:.3f}.. '.format(running_loss/len(student_train_loader)),\n                  'Test Loss: {:.3f}.. '.format(test_loss/len(student_test_loader)),\n                  'Test Accuracy: {:.3f}'.format(accuracy/len(student_test_loader)))\n            running_loss = 0\n```", "```py\nEpoch: 10/10..  Training Loss: 0.026..  Test Loss: 0.190..  Test Accuracy: 0.952\n```", "```py\n%cd privacy/research/pate_2018/ICLR2018\n```", "```py\nclean_votes = []\nfor image_preds in np.transpose(preds):\n    label_counts = np.bincount(image_preds, minlength=10).astype(float)\n    clean_votes.append(label_counts)\n\nclean_votes = np.array(counts)\nwith open('clean_votes.npy', 'wb') as file_obj:\n  np.save(file_obj, clean_votes)\n```", "```py\n!python smooth_sensitivity_table.py  --sigma2=5.0 --counts_file=clean_votes.npy --delta=1e-5\n```"]