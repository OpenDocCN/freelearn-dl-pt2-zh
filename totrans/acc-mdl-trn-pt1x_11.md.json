["```py\nimport torch.distributed as distdist.init_process_group()\n```", "```py\nmy_rank = dist.get_rank()\n```", "```py\nif my_rank == 0:    test(ddp_model, test_loader, device)\n```", "```py\ndist.destroy_process_group()\n```", "```py\nfrom torch.utils.data.distributed import DistributedSamplerdist_loader = DistributedSampler(train_dataset)\ntrain_loader = torch.utils.data.DataLoader(train_dataset,\n                                           batch_size=batch_size,\n                                           shuffle=False,\n                                           sampler=dist_loader)\n```", "```py\nfrom torch.nn.parallel import DistributedDataParallel as DDPmodel = CNN()\nddp_model = DDP(model)\n```", "```py\noptimizer = optimizer(ddp_model.parameters(), lr,                       weight_decay=weight_decay)\n```", "```py\ntrain(ddp_model, train_loader, num_epochs, criterion, optimizer,       device)\n```"]