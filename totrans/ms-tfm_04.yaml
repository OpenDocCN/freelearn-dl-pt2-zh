- en: 'Section 2: Transformer Models â€“ From Autoencoding to Autoregressive Models'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, you will learn about the architecture of autoencoding models
    such as BERT and autoregressive models such as GPT. You will learn how to train,
    test, and fine-tune the models for a variety of natural language understanding
    and natural language generation problems. You will also learn how to share the
    models with the community and how to fine-tune other pre-trained language models
    shared by the community.
  prefs: []
  type: TYPE_NORMAL
- en: 'This section comprises the following chapters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 3*](B17123_03_Epub_AM.xhtml#_idTextAnchor050), *Autoencoding Language
    Models*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 4*](B17123_04_Epub_AM.xhtml#_idTextAnchor067), *Autoregressive and
    Other Language Models*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 5*](B17123_05_Epub_AM.xhtml#_idTextAnchor081), *Fine-Tuning Language
    Models for Text Classification*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 6*](B17123_06_Epub_AM.xhtml#_idTextAnchor090), *Fine-Tuning Language
    Models for Token Classification*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 7*](B17123_07_Epub_AM.xhtml#_idTextAnchor099), *Text Representation*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
