- en: '*Chaper 1*'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Introduction to Deep Learning and PyTorch
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Learning Objectives
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'By the end of this chapter, you will be able to:'
  prefs: []
  type: TYPE_NORMAL
- en: Explain what deep learning is, its importance, and how it fits into AI and ML
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Identify the sort of data problems that can be solved using deep learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Differentiate PyTorch from other machine learning libraries by understanding
    the advantages and disadvantages of the library
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create a single-layer neural network using PyTorch
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this chapter, we'll go through how deep learning resonates with artificial
    intelligence and machine learning. And with an introduction to PyTorch, we'll
    explore basic programming exercises to apply the knowledge on the PyTorch syntax.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Deep learning is a subset of machine learning that focuses on using deep neural
    networks to solve complex data problems. It has become increasingly popular nowadays,
    thanks to advances in software and hardware that allow the gathering and processing
    of large amounts of data (we are talking about millions and billions of entries),
    considering that neural networks are currently the only algorithms capable of
    reaching higher levels of accuracy by feeding more data to the model.
  prefs: []
  type: TYPE_NORMAL
- en: With this in mind, the need for faster processing times is inevitable. PyTorch
    was born back in 2017 and its main characteristic relies on the fact that it uses
    the power of GPUs to run data using tensors. This allows algorithms to run at
    very high speeds, and at the same time it provides its users with flexibility
    and a standard syntax to obtain the best results for many data problems.
  prefs: []
  type: TYPE_NORMAL
- en: This book focuses on demystifying neural networks using PyTorch, in order to
    eliminate some of the fear that has been built implicitly around the complexity
    of neural network architectures.
  prefs: []
  type: TYPE_NORMAL
- en: Considering this, this chapter focuses on introducing both the topics of deep
    learning and PyTorch. Here, you will learn what deep learning is, how it fits
    into the world of machine learning and artificial intelligence, how it works in
    general terms, and finally, some of the most popular applications nowadays. Additionally,
    you will learn how PyTorch works, what some of its main modules and characteristics
    are, and some of the main advantages and disadvantages that it poses to its users.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding Deep Learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In order to understand what deep learning is and why it has become so popular
    nowadays, it is important to first define what artificial intelligence and machine
    learning are, and how deep learning fits into that world.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.1: A diagram of artificial intelligence, machine learning, and deep
    learning'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C11865_01_01.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.1: A diagram of artificial intelligence, machine learning, and deep
    learning'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: As seen in the preceding figure, **artificial intelligence** (**AI**) is a general
    category that encapsulates both machine learning and deep learning. It refers
    to any intelligence demonstrated by machines that ultimately leads to solving
    a problem. These techniques include following a set of rules or logic, or learning
    from previous data, among others. Considering this, an artificial intelligence
    solution may or may not possess the learning ability to achieve an optimal solution.
  prefs: []
  type: TYPE_NORMAL
- en: Artificial intelligence solutions that possess the ability to learn fall inside
    the machine learning subset. Put simply, **machine learning** is just one of the
    ways to achieve artificial intelligence, and it consists of algorithms that have
    the ability to learn without being explicitly programmed to do so. This means
    that the algorithms are capable of parsing data, learning from it, and making
    a decision (prediction) accordingly. This method of machine learning is called
    "supervised learning," and it basically means that the algorithm is fed both with
    the input data and the target values (the desired outcome).
  prefs: []
  type: TYPE_NORMAL
- en: Another methodology of machine learning is called "unsupervised learning," and
    in contrast with the aforementioned, only the input data is fed without any relation
    to an output. The objective of the algorithm here is to understand the data at
    hand in order to find similarities.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, **deep learning** is a subset of machine learning that uses multi-layer
    neural networks (large neural networks), inspired by the biological structure
    of the human brain, where neurons in a layer receive some input data, process
    it, and send the output to the following layer. These neural networks can consist
    of thousands of interconnected nodes (neurons), mostly organized in different
    layers, where one node is connected to several nodes in the previous layer from
    where it receives its input data, as well as being connected to several nodes
    in the following layer, to which it sends the output data after being processed.
  prefs: []
  type: TYPE_NORMAL
- en: The structure and functioning of neural networks will be further explained in
    subsequent sections of this book.
  prefs: []
  type: TYPE_NORMAL
- en: Why Is Deep Learning Important? Why Has It Become Popular?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In general terms, its popularity is due to a matter of accuracy. Deep learning
    has achieved higher accuracy levels than ever before for very complex data problems.
    This ability to perform outstandingly well has reached levels where machines can
    outperform humans, which allows the model to not only optimize processes, but
    to improve their quality. Thanks to this, there have been advances in revolutionary
    fields where accuracy is vital for safety reasons, such as self-driven cars.
  prefs: []
  type: TYPE_NORMAL
- en: 'And, even though neural networks were theorized decades ago, there are two
    main reasons why they have recently become popular:'
  prefs: []
  type: TYPE_NORMAL
- en: Neural networks require, and actually capitalize on, vast amounts of labeled
    data to achieve an optimal solution. This means that for the algorithm to create
    an outstanding model, it is required to have hundreds of thousands of entries
    (and even millions for some data problems), containing both the features and the
    target values.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: Labeled data refers to data that contains a set of features (characteristics
    that describe an instance) and a target value (the value to be achieved).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](img/C11865_01_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.2: Performance of deep learning against other algorithms in terms
    of quantity of data'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: This is possible nowadays thanks to advances in software that allow the gathering
    of such granularity, while advances in hardware allow for the processing of it.
  prefs: []
  type: TYPE_NORMAL
- en: Neural networks require considerable computing power to be able to process such
    amounts of data, as mentioned before. This is crucial as, otherwise, it would
    take weeks (or even longer) for a traditional network to be trained, and considering
    that the process of achieving the best possible model is based on trial-and-error,
    it is necessary to be able to run the training process as efficiently as possible.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This can be achieved today through the use of GPUs that can cut down the training
    time of a neural network from weeks to hours.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: Moreover, with the objective of accelerating deep learning in order to be able
    to make use of large amounts of training data and construct state-of-the-art models,
    FPGAs (Field-Programmable Gate Arrays) and TPUs (Tensor Processing Units) are
    being developed by major cloud computing providers, such as AWS, Microsoft Azure,
    and Google.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Applications of Deep Learning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Deep learning is revolutionizing technology as we know it in that many developments
    based on its application are impacting our lives currently. Moreover, it is thought
    that within the next 5 to 10 years, the way in which many processes are handled
    will change drastically.
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, deep learning can be applied to a wide variety of situations, ranging
    from medical and safety purposes, to more trivial tasks such as colorizing black
    and white images or translating text in real time.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some of the applications of deep learning that are either under development
    or in use today can be found here:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Self-driving vehicles**: Several companies, such as Google, have been working
    on the development of partially or totally self-driving vehicles that learn to
    drive by using digital sensors to identify the objects around them.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 1.3: Google’s self-driving car'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C11865_01_03.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.3: Google''s self-driving car'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '**Medical diagnosis**: Deep learning is redefining this industry by improving
    the diagnosis accuracy of terminal diseases such as brain and breast cancer. This
    is done by classifying images of new patients, based on labeled images from previous
    patients that did or did not have cancer.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Voice assistants**: This may be one of the most popular applications nowadays,
    due to the proliferation of different voice-activated intelligent assistants,
    such as Apple''s Siri, Google Home, and Amazon''s Alexa.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 1.4: Amazon’s Alexa intelligent assistant'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C11865_01_04.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.4: Amazon''s Alexa intelligent assistant'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '**Automatic text generation**: This involves generating new text based on an
    input sentence. This is popularly used in email writing, where the email provider
    suggests the next couple of words to the user, based on the text written so far.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 1.5: Gmail’s text generation feature'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C11865_01_05.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.5: Gmail''s text generation feature'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '**Advertising**: Here, the main idea is to increase the return on investment
    of ads by targeting the right audiences or by creating more effective ads, among
    other methodologies.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Price forecasting**: For beginners, this is a typical example of what can
    be achieved through the use of machine learning algorithms. Price forecasting
    consists of training a model based on real data, including, for instance in the
    field of real state, property characteristics and their final price in order to
    be able to predict the prices of future entries based solely on property characteristics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: PyTorch Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![Figure 1.6: PyTorch library logo'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C11865_01_06.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.6: PyTorch library logo'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: PyTorch is an open-source library developed mainly by Facebook's artificial
    intelligence research group as a Python version of Torch, first released to the
    public in January 2017\. It uses the power of **graphic processing units** (**GPUs**)
    to speed up the computation of tensors, which accelerates the training times of
    complex models.
  prefs: []
  type: TYPE_NORMAL
- en: The library has a C++ backend, combined with the deep learning framework of
    Torch, which allows much faster computations than native Python libraries with
    many deep learning features. On the other hand, its frontend is in Python, which
    has helped its popularity considering that data scientists new to the library
    can construct very complex neural networks effortlessly. And thanks to this integration
    with Python, it is possible to use PyTorch alongside other popular Python packages.
  prefs: []
  type: TYPE_NORMAL
- en: Although the library is fairly new, it has gained popularity very quickly as
    it was developed using feedback from many experts in the field, which converted
    it into a library created for users. The many advantages and disadvantages of
    using it are discussed in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Advantages
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There are several libraries nowadays that can be used for developing deep learning
    solutions, so why use PyTorch? Because PyTorch is a dynamic library, which allows
    its users great flexibility to develop very complex architectures that can be
    adapted to each particular data problem.
  prefs: []
  type: TYPE_NORMAL
- en: Due to this, it has been adopted by a great deal of researchers and artificial
    intelligence developers, which makes it a must for landing a job in the field
    of machine learning.
  prefs: []
  type: TYPE_NORMAL
- en: 'The key aspects to highlight are shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Ease of use**: With respect to the API, PyTorch has a simple interface that
    makes it very easy to develop and run models. Many early adopters consider it
    to be more intuitive than other libraries, such as TensorFlow. It is Pythonic
    in nature, which means it is integrated with Python, as mentioned before, which
    makes it very intuitive and easy to use even though the library is new to many
    developers. This integration also allows the use of many Python packages, such
    as NumPy and SciPy, to extend its functionalities.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Speed**: PyTorch makes use of GPUs that allow GPU-accelerated tensor computations.
    This enables the library to train faster than other deep learning libraries. This
    is especially useful when different approximations have to be tested in order
    to achieve the best possible model, and speed is a crucial matter. Additionally,
    even though other libraries may also have the option to accelerate computations
    with GPUs, PyTorch achieves this operation by typing just a couple of simple lines
    of code.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The following URL contains a speed benchmark on different deep learning frameworks
    (considering that the difference in training time is evident when dealing with
    very large amounts of training data):'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[https://github.com/u39kun/deep-learning-benchmark](https://github.com/u39kun/deep-learning-benchmark)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Convenience**: PyTorch is flexible. It uses dynamic computational graphs
    that allow you to make changes to networks on the go. Additionally, it allows
    great flexibility when building the architecture as it is very easy to make adjustments
    to conventional architectures.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Imperative**: PyTorch is also imperative. Each line of code is executed individually,
    allowing you to track the model in real time, as well as to debug the model in
    a much convenient way.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Pretrained models**: Finally, it contains many pretrained models that are
    very easy to use and are a great starting point for some data problems.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Disadvantages
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Although the advantages are huge and many, there are still some disadvantages
    to consider, which are explained here:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Small community**: The community of adapters of this library is very small
    in comparison to some of the other libraries, such as TensorFlow. However, having
    been available to the public for only two years, today it is the third most popular
    library for implementing deep learning solutions, and its community grows by the
    day.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Spotty documentation**: Considering that the library is new, the documentation
    is not as complete as some of the more mature libraries, such as TensorFlow. However,
    as the features and capabilities of the library increase, the documentation is
    being extended. Additionally, as the community continues to grow, there will be
    more information available on the internet.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Not production-ready**: Although many of the complaints about the library
    have focused on its inability to be deployed for production, after the launch
    of version 1.0, the library included production capabilities to be able to export
    finalized models and use them in production environments.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What Are Tensors?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Similar to NumPy, PyTorch uses tensors to represent data, which are matrix-like
    structures of *n* dimensions, as shown in *Figure 1.7*, with the difference that
    tensors can run on the GPU, which helps to accelerate numerical computations.
    Moreover, it is important to mention that, for tensors, the dimension is known
    as the rank.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.7: Visual representation of tensors of different dimensions'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C11865_01_07.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.7: Visual representation of tensors of different dimensions'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In contrast with a matrix, a tensor is a mathematical entity contained in a
    structure that can interact with other mathematical entities. When one tensor
    transforms another, the former also carries a transformation of its own.
  prefs: []
  type: TYPE_NORMAL
- en: This means that tensors are not just data structures, but rather containers
    that, when fed some data, can map in a multi-linear manner with other tensors.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 1: Creating Tensors of Different Ranks Using PyTorch'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: All exercises and activities will be primarily developed in a Jupyter notebook.
    It is recommended to keep a separate notebook for different assignments, unless
    advised not to.
  prefs: []
  type: TYPE_NORMAL
- en: In this exercise, we will use the PyTorch library to create tensors of one,
    two, and three ranks.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: For the exercises and activities in this chapter, you will need to have Python
    3.6, Jupyter, Matplotlib, and PyTorch 1.0.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'To clone the repository containing all the exercises and activities in this
    book, use the following commands in your CMD or terminal, after navigating to
    the desired path:'
  prefs: []
  type: TYPE_NORMAL
- en: '[`git clone https://github.com/TrainingByPackt/Applied-Deep-Learning-with-PyTorch.git`](git
    clone https://github.com/TrainingByPackt/Applied-Deep-Learning-with-PyTorch.git
    )'
  prefs: []
  type: TYPE_NORMAL
- en: Open a Jupyter notebook to implement this exercise.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Open your CMD or terminal, navigate to the desired path, and use the following
    command to open a Jupyter notebook: `jupyter notebook`.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: This command may change depending on your operating system and its configurations.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Import the PyTorch library called `torch`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create tensors of the following ranks: 1, 2, and 3.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Use values between 0 and 1 to fill your tensors. The size of the tensors can
    be defined as you desire, given that the ranks are created correctly:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'When using a GPU-enabled machine, use the following script to create the tensors:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Print the shape of each of the tensors using the `shape` property, just as
    you would do with NumPy arrays:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The final shape of each tensor should be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Congratulations! You have successfully created tensors of different ranks.
  prefs: []
  type: TYPE_NORMAL
- en: Key Elements of PyTorch
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Like any other library, PyTorch has a variety of modules, libraries, and packages
    for developing different functionalities. In this section, the three most commonly
    used elements for building deep neural networks will be explained, along with
    a simple example of the syntax.
  prefs: []
  type: TYPE_NORMAL
- en: '**PyTorch autograd Library**'
  prefs: []
  type: TYPE_NORMAL
- en: The `autograd` library consists of a technique called automatic differentiation.
    Its purpose is to numerically calculate the derivative of a function. This is
    crucial for a concept we will learn about in the next chapter called backward
    propagation, which is carried out while training a neural network.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: A detailed explanation on neural networks will be carried out in subsequent
    sections, explaining the different steps taken to train a model.
  prefs: []
  type: TYPE_NORMAL
- en: 'To compute the gradients, simply call the `backward()` function, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code, two tensors were created. We use the `requires_grad`
    argument here to tell PyTorch to calculate the gradients of that tensor. However,
    when building your neural network, this argument is not required.
  prefs: []
  type: TYPE_NORMAL
- en: Next, a function was defined using the values of both tensors. Finally, the
    `backward()` function was used to calculate the gradients.
  prefs: []
  type: TYPE_NORMAL
- en: '**The PyTorch nn Module**'
  prefs: []
  type: TYPE_NORMAL
- en: The `autograd` library alone can be used to build simple neural networks, considering
    that the trickier part (the calculation of gradients) has been taken care of.
    However, this methodology can be troublesome, hence the introduction of the nn
    module.
  prefs: []
  type: TYPE_NORMAL
- en: The nn module is a complete PyTorch module used to create and train neural networks,
    which, through the use of different elements, allows for very simple and very
    complex developments. For instance, the `Sequential()` container allows the easy
    creation of network architectures that follow a sequence of predefined modules
    (or layers) without the need for much knowledge.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The different layers that can be used for each neural network architecture will
    be further explained in subsequent chapters.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, this module also has the capability to define the loss function to
    evaluate the model, and many more advanced features that will be discussed in
    this book.
  prefs: []
  type: TYPE_NORMAL
- en: 'The process of building a neural network architecture as a sequence of predefined
    modules can be achieved in just a couple of lines, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: First, the module is imported. Next, the model architecture is defined. `input_units`
    refers to the number of features that the input data contains, `hidden_units`
    refers to the number of nodes of the hidden layer, and `output_units` refers to
    the number of nodes of the output layer.
  prefs: []
  type: TYPE_NORMAL
- en: As can be seen, the architecture of the network contains one hidden layer, with
    a ReLU activation function and an output layer with a sigmoid activation function.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the loss function is defined as the **Mean Squared Error** (**MSE**).
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: To create models that do not follow a sequence of existing modules, custom nn
    modules are used. We'll introduce these later in the book.
  prefs: []
  type: TYPE_NORMAL
- en: '**The PyTorch optim Package**'
  prefs: []
  type: TYPE_NORMAL
- en: The `optim` package is used to define the optimizer that will be used to update
    the parameters in each iteration (which will be further explained in the following
    chapters), using the gradients calculated by the `autograd` module. Here, it is
    possible to choose from the optimization algorithms available, such as Adam, **Stochastic
    Gradient Descent** (**SGD**), and RMSprop, among others.
  prefs: []
  type: TYPE_NORMAL
- en: 'To set the optimizer to be used, the following line of code suffices:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Here, the `model.parameters()` argument refers to the weights and biases from
    the model previously created, and `lr` refers to the learning rate, which was
    set as `0.01`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, the process of running the optimization for 100 iterations is shown here,
    which, as you can see, uses the model created by the nn module and the gradients
    calculated by the `autograd` library:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: For each iteration, the model is called to obtain a prediction (`y_pred`). This
    prediction and the ground truth values (`y`) are fed to the loss functions in
    order to determine the ability of the model to approximate to the ground truth.
  prefs: []
  type: TYPE_NORMAL
- en: Next, the gradients are zeroed, and the gradients of the loss function are calculated
    using the `backward()` function.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the `step()` function is called to update the weights and biases based
    on the optimization algorithm and the gradients calculated previously.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 1: Creating a Single-Layer Neural Network'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For this activity, we will create a single-layer neural network, which will
    be a starting point from which we will create deep neural networks in future activities.
    Let's look at the following scenario.
  prefs: []
  type: TYPE_NORMAL
- en: 'You are applying for a job at a major technology firm and have passed all the
    screening interviews. The next step in the recruitment process is to display your
    programming machine learning skills in real time during an interview. They have
    asked you to build a single-layer neural network using PyTorch:'
  prefs: []
  type: TYPE_NORMAL
- en: Import the required libraries.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create dummy input data (`x`) of random values and dummy target data (`y`) that
    only contains 0s and 1s. Store the data in tensors. Tensor `x` should have a size
    of (100,5), while the size of `y` should be (100,1).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: PyTorch tensors can be manipulated like NumPy arrays.Use `torch.randn(number_instances`,
    number features) to create `x`.Use `torch.randint(low=0, high, size)` to create
    `y`. Take into account that `randint` is upper-bound exclusive. Make sure you
    convert the `y` tensor to a `FloatTensor` type, as this is the default type that
    the nn module handles. Use `.type(torch.FloatTensor)` for that purpose.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Define the architecture of the model and store it in a variable named `model`.
    Remember to create a single-layer model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Define the loss function to be used.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use the Mean Square Error loss function.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Define the optimizer of your model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use the Adam optimizer.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Run the optimization for 100 iterations. In each iteration, print and save the
    loss value.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: Use the following line of code to append the loss value of each iteration step
    to a list previously created outside the for loop (losses):`losses.append(loss.item())`
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Print the values of the final weights and bias. There should be a total of
    five weights (one for each feature of the input data) and one bias value:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Make a line plot to display the loss value for each iteration step.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: The solution for this activity can be found on page 186.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The term artificial intelligence has become increasingly popular in the last
    couple of years. We have seen it in movies and we have seen it in real life, and
    it basically refers to any form of intelligence demonstrated by machines with
    the purpose of optimizing human tasks. A subcategory of AI that focuses on those
    algorithms that have the ability to learn from data, is called machine learning.
  prefs: []
  type: TYPE_NORMAL
- en: In turn, deep learning is a subset of machine learning that was inspired by
    the biological structure of human brains. It uses deep neural networks to solve
    complex data problems through the use of vast amounts of data. And even though
    the theory was developed decades ago, it has been used recently thanks to advances
    in hardware and software, which allow for the collection and processing of millions
    of pieces of data.
  prefs: []
  type: TYPE_NORMAL
- en: With the popularity of deep learning solutions, many deep learning libraries
    have been developed. Among them, one of the most recent ones is PyTorch. PyTorch
    uses a C++ backend that helps speed up computations, while having a Python frontend
    to keep the library easy to use.
  prefs: []
  type: TYPE_NORMAL
- en: It uses tensors to store data, which are n-ranked matrix-like structures that
    can be run on GPUs to speed up processing. And it offers three main elements that
    are highly useful for creating complex neural network architectures with little
    effort.
  prefs: []
  type: TYPE_NORMAL
- en: The `autograd` library can compute the derivatives of a function, which are
    used as the gradients to optimize the weights and biases of a model. Moreover,
    the `nn` module helps you to easily define the model's architecture as a sequence
    of predefined modules, as well as to determine the loss function to be used to
    measure the model. Finally, the `optim` package is used to select the optimization
    algorithm to be used to update the parameters, considering the gradients calculated
    previously.
  prefs: []
  type: TYPE_NORMAL
