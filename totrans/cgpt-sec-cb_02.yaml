- en: '2'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Vulnerability Assessment
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Building on the fundamental knowledge and skills established in [*Chapter 1*](B21091_01.xhtml#_idTextAnchor022),
    this chapter explores using ChatGPT and the OpenAI API to assist with and automate
    many vulnerability assessment tasks.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Throughout this chapter, you’ll discover how to employ ChatGPT in creating vulnerability
    and threat assessment plans, a crucial part of any cybersecurity strategy. You’ll
    see how automating these processes using the OpenAI API and Python can offer even
    more efficiency, especially in environments with numerous network configurations
    or recurring planning needs.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, this chapter will delve into using ChatGPT in conjunction with
    the MITRE ATT&CK framework, a globally accessible knowledge base of adversary
    tactics and techniques. This fusion will enable you to generate detailed threat
    reports, providing valuable insights for threat analysis, attack vector assessment,
    and threat hunting.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: You’ll be introduced to the concept of **Generative Pre-training Transformer**
    (**GPT**)-assisted vulnerability scanning. This approach simplifies some of the
    complexity of vulnerability scanning, transforming natural language requests into
    accurate command strings that can be executed in **command-line interfaces** (**CLIs**).
    This methodology is not only a time-saver but also enhances accuracy and understanding
    in performing vulnerability scans.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: Lastly, this chapter will tackle the challenge of analyzing large vulnerability
    assessment reports. Using the OpenAI API in conjunction with LangChain, a framework
    designed to enable language models to assist with complex tasks, you’ll see how
    large documents can be processed and understood, despite the current token limitations
    of ChatGPT.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following recipes:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: Creating Vulnerability Assessment Plans
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Threat Assessment using ChatGPT and the MITRE ATT&CK framework
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GPT-Assisted Vulnerability Scanning
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Analyzing Vulnerability Assessment Reports using LangChain
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For this chapter, you will need a **web browser** and a stable **internet connection**
    to access the ChatGPT platform and set up your account. You will also need to
    have your OpenAI account set up and have obtained your API key. If not, revisit
    [*Chapter 1*](B21091_01.xhtml#_idTextAnchor022) for details. Basic familiarity
    with the Python programming language and working with the command line is necessary,
    as you’ll be using **Python 3.x**, which needs to be installed on your system,
    for working with the OpenAI GPT API and creating Python scripts. A **code editor**
    will also be essential for writing and editing Python code and prompt files as
    you work through the recipes in this chapter.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: 'The code files for this chapter can be found here: [https://github.com/PacktPublishing/ChatGPT-for-Cybersecurity-Cookbook](https://github.com/PacktPublishing/ChatGPT-for-Cybersecurity-Cookbook).'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: Creating Vulnerability Assessment Plans
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, you’ll learn how to harness the power of **ChatGPT** and the
    **OpenAI API** to **create comprehensive vulnerability assessment plans** using
    network, system, and business details as input. This recipe is invaluable for
    both cybersecurity students and beginners looking to familiarize themselves with
    proper methods and tools for vulnerability assessments, as well as experienced
    cybersecurity professionals aiming to save time on planning and documentation.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在此食谱中，您将学习如何利用**ChatGPT**和**OpenAI API**来使用网络、系统和业务细节创建全面的**漏洞评估计划**。此食谱对于既有网络安全专业学生和初学者尤其有价值，他们希望熟悉漏洞评估的适当方法和工具，也适用于有经验的网络安全专业人员，以节省在计划和文件记录上的时间。
- en: 'Building upon the skills acquired in [*Chapter 1*](B21091_01.xhtml#_idTextAnchor022),
    you will delve deeper into establishing the system role of a cybersecurity professional
    specializing in vulnerability assessments. You’ll learn how to craft effective
    prompts that generate well-formatted output using Markdown language. This recipe
    will also expand on the techniques explored in the *Enhancing Output with Templates
    (Application: Threat Report)* and *Formatting Output as a Table (Application:
    Security Controls Table)* recipes in [*Chapter 1*](B21091_01.xhtml#_idTextAnchor022),
    enabling you to design prompts that produce the desired output format.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 基于[*第1章*](B21091_01.xhtml#_idTextAnchor022)中所学到的技能，您将深入了解专门从事漏洞评估的网络安全专业人员的系统角色建立。您将学习如何使用Markdown语言制作有效的提示，生成格式良好的输出。此食谱还将扩展[*第1章*](B21091_01.xhtml#_idTextAnchor022)中探讨的*使用模板增强输出（应用：威胁报告）*以及*将输出格式化为表格（应用：安全控制表）*的技术，使您能够设计生成所需输出格式的提示。
- en: Finally, you’ll discover how to use the OpenAI API and **Python** to generate
    a vulnerability assessment plan, and then **export it as a Microsoft Word file**.
    This recipe will serve as a practical guide for creating detailed and efficient
    vulnerability assessment plans using ChatGPT and the OpenAI API.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，您将了解如何使用OpenAI API和**Python**来生成漏洞评估计划，然后**将其导出为Microsoft Word文件**。此食谱将作为一个实用指南，教您如何使用ChatGPT和OpenAI
    API创建详细、高效的漏洞评估计划。
- en: Getting ready
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备就绪
- en: 'Before diving into the recipe, you should already have your OpenAI account
    set up and obtained your API key. If not, revisit [*Chapter 1*](B21091_01.xhtml#_idTextAnchor022)
    for details. You will also need to be sure you have the following Python libraries
    installed:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行食谱之前，您应该已经设置好OpenAI账户并获得了API密钥。如果没有，可以返回[*第1章*](B21091_01.xhtml#_idTextAnchor022)了解详情。您还需要确保已安装以下Python库：
- en: '`python-docx`: This library will be used to generate Microsoft Word files.
    You can install it using the `pip install` `python-docx` command.'
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`python-docx`：将使用此库生成Microsoft Word文件。您可以使用 `pip install python-docx` 命令安装它。'
- en: '`tqdm`: This library will be used to display progress bars. You can install
    it using the `pip install` `tqdm` command.'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`tqdm`：将使用此库显示进度条。您可以使用 `pip install tqdm` 命令安装它。'
- en: How to do it…
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 怎么做…
- en: 'In this section, we will walk you through the process of using ChatGPT to create
    a comprehensive vulnerability assessment plan tailored to a specific network and
    organization’s needs. By providing the necessary details and using the given system
    role and prompt, you will be able to generate a well-structured assessment plan:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将指导您使用ChatGPT创建针对特定网络和组织需求定制的全面漏洞评估计划的过程。通过提供必要的细节，并使用给定的系统角色和提示，您将能够生成结构良好的评估计划：
- en: Begin by logging in to your ChatGPT account and navigating to the ChatGPT web
    UI.
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先登录到您的ChatGPT账户，然后导航到ChatGPT Web UI。
- en: Start a new conversation with ChatGPT by clicking the **New** **chat** button.
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 单击**新建** **聊天**按钮，与ChatGPT开始新对话。
- en: 'Enter the following prompt to establish a system role:'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入以下提示以建立系统角色：
- en: '[PRE0]'
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Enter the following message text, but replace the placeholders in the `{ }`
    brackets with the appropriate data of your choice. You can either combine this
    prompt with the system role or enter it separately as follows:'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入以下消息文本，但用 `{ }` 括号中的适当数据替换占位符。您可以将此提示与系统角色结合使用，也可以分开输入，如下所示：
- en: '[PRE1]'
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Hint
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 提示
- en: If you are performing this in the **OpenAI Playground**, it is advisable to
    use **Chat mode** and enter the role in the **System** window, and the prompt
    in the **User** **message** window.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在**OpenAI Playground**中进行此操作，建议使用**聊天模式**，在**系统**窗口中输入角色，在**用户** **消息**窗口中输入提示。
- en: '*Figure 2**.1* shows the system role and user prompt entered into the **OpenAI
    Playground**:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.1 – OpenAI Playground method](img/Figure_2.01_B21091.jpg)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
- en: Figure 2.1 – OpenAI Playground method
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: Review the generated output from ChatGPT. If the output is satisfactory and
    meets the requirements, you can proceed to the next step. If not, you can either
    refine your prompt or rerun the conversation to generate a new output.
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once you have obtained the desired output, you can use the generated Markdown
    to create a well-structured vulnerability assessment plan in your preferred text
    editor or Markdown viewer.
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Figure 2**.2* shows an example ChatGPT generation of a vulnerability assessment
    plan using Markdown language formatting:'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 2.2 – Example ChatGPT assessment plan output](img/Figure_2.02_B21091.jpg)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
- en: Figure 2.2 – Example ChatGPT assessment plan output
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This GPT-assisted vulnerability assessment plan recipe leverages the sophistication
    of **natural language processing** (**NLP**) and **machine learning (ML) algorithms**
    to generate a comprehensive and detailed vulnerability assessment plan. By adopting
    a specific system role and an elaborate user request as a prompt, ChatGPT is able
    to customize its response to meet the requirements of a seasoned cybersecurity
    professional who is tasked with assessing an extensive network system.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s a closer look at how this process works:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: '**System role and detailed prompt**: The system role designates ChatGPT as
    a seasoned cybersecurity professional specializing in vulnerability assessment.
    The prompt, which serves as the user request, is detailed and outlines the specifics
    of the assessment plan, from the size of the network and types of devices to the
    required compliance and the expected deliverables. These inputs provide context
    and guide ChatGPT’s response, ensuring it is tailored to the complexities and
    requirements of the vulnerability assessment task.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**NLP and ML**: NLP and ML form the bedrock of ChatGPT’s capabilities. It applies
    these technologies to understand the intricacies of the user request, learn from
    the patterns, and generate a well-structured vulnerability assessment plan that
    is detailed, specific, and actionable.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Knowledge and language understanding capabilities**: ChatGPT uses its extensive
    knowledge base and language understanding capabilities to conform to industry-standard
    methodologies and best practices. This is particularly important in the rapidly
    evolving field of cybersecurity, ensuring that the resulting vulnerability assessment
    plan is up to date and adheres to recognized standards.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Markdown language output**: The use of Markdown language output ensures that
    the plan is formatted in a consistent and easy-to-read manner. This format can
    be easily integrated into reports, presentations, and other formal documents,
    which is crucial when communicating the plan to IT departments, senior management,
    and external auditors or regulators.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Streamlining the assessment planning process**: The overall advantage of
    using this GPT-assisted vulnerability assessment plan recipe is that it streamlines
    the process of creating a comprehensive vulnerability assessment plan. You save
    time on planning and documentation and can generate a professional-grade assessment
    plan that aligns with industry standards and is tailored to the specific needs
    of your organization.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**简化评估计划过程**：使用这个GPT辅助的漏洞评估计划配方的整体优势在于它简化了创建全面漏洞评估计划的过程。您节省了规划和文档编制的时间，并可以生成符合行业标准并根据您组织特定需求定制的专业级评估计划。'
- en: By applying these detailed inputs, you transform ChatGPT into a potential tool
    that can assist in creating a comprehensive, tailored vulnerability assessment
    plan. This not only bolsters your cybersecurity efforts but also ensures your
    resources are utilized effectively in protecting your network systems.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 通过应用这些详细的输入，您可以将ChatGPT转化为一个潜在的工具，以协助创建全面、定制的漏洞评估计划。这不仅增强了您的网络安全工作，还确保您有效利用资源来保护网络系统。
- en: There’s more…
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多…
- en: In addition to using ChatGPT to generate a vulnerability assessment plan, you
    can also use the OpenAI API and Python to automate the process. This approach
    is particularly useful when you have a large number of network configurations
    to assess or when you need to generate plans on a recurring basis.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 除了使用ChatGPT生成漏洞评估计划外，您还可以使用OpenAI API和Python来自动化该过程。当您需要评估大量网络配置或需要定期生成计划时，这种方法特别有用。
- en: The Python script we will present here reads input data from a text file and
    uses it to fill in the placeholders in the prompt. The resulting Markdown output
    can then be used to create a well-structured vulnerability assessment plan.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在这里介绍的Python脚本从文本文件中读取输入数据，并将其用于填充提示中的占位符。然后，生成的Markdown输出可用于创建结构良好的漏洞评估计划。
- en: 'While the process is similar to the ChatGPT version, the use of the OpenAI
    API provides additional flexibility and control over the generated content. Let’s
    dive into the steps involved in the OpenAI API version of the vulnerability assessment
    plan recipe:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然该过程与ChatGPT版本相似，但使用OpenAI API可以提供对生成内容的额外灵活性和控制。让我们深入了解OpenAI API版本的漏洞评估计划配方中涉及的步骤：
- en: 'Import the necessary libraries and set up the OpenAI API:'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入必要的库并设置OpenAI API：
- en: '[PRE2]'
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: In this section, we import the necessary libraries, such as `openai`, `os`,
    `docx`, `tqdm`, `threading`, `time`, and `datetime`. We also set up the OpenAI
    API by providing the API key.
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在本部分中，我们导入必要的库，如`openai`、`os`、`docx`、`tqdm`、`threading`、`time`和`datetime`。我们还通过提供API密钥来设置OpenAI
    API。
- en: 'Read user input data from a text file:'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从文本文件中读取用户输入数据：
- en: '[PRE3]'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Here, we define a `read_user_input_file` function that reads the user input
    data from a text file and stores it in a dictionary. We then call this function
    with the `assessment_data.txt` file to obtain the `user_data` dictionary.
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，我们定义了一个`read_user_input_file`函数，用于从文本文件中读取用户输入数据并将其存储在字典中。然后，我们使用`assessment_data.txt`文件调用此功能以获得`user_data`字典。
- en: 'Generate a vulnerability assessment plan using the OpenAI API:'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用OpenAI API生成漏洞评估计划：
- en: Important note
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: The `…'` notation signifies that we will fill in this section of code in a later
    step.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '`…''`注释表示我们将在稍后的步骤中填写此代码部分。'
- en: '[PRE4]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: In this code block, we define a `generate_report` function, which takes the
    user input data and calls the OpenAI API to generate the vulnerability assessment
    plan. The function returns the generated text.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在此代码块中，我们定义了一个`generate_report`函数，该函数接受用户输入数据并调用OpenAI API来生成漏洞评估计划。该函数返回所生成的文本。
- en: 'Define the API messages:'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义API消息：
- en: '[PRE5]'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'In the conversation messages, we define two roles: `system` and `user`. The
    `system` role is used to set the context for the AI model, informing it that it’s
    a cybersecurity professional specializing in vulnerability assessment. The `user`
    role provides the instructions for the AI, which include generating a detailed
    vulnerability assessment plan based on industry standards, best practices, and
    user-supplied data.'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在对话消息中，我们定义了两个角色：`system`和`user`。`system`角色用于为AI模型设置上下文，告知其是一位专门从事漏洞评估的网络安全专业人员。`user`角色为AI提供指令，包括基于行业标准、最佳实践和用户提供的数据生成详细的漏洞评估计划。
- en: The `system` role helps set the stage for the AI, while the `user` role guides
    the AI in its content generation. This approach follows a similar pattern to the
    ChatGPT UI section we discussed earlier, where we provided an initial message
    to the AI to set the context.
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: For more information on sending API requests and handling responses, please
    refer to the *Sending API Requests and Handling Responses with Python* recipe
    in [*Chapter 1*](B21091_01.xhtml#_idTextAnchor022). This recipe provides a deeper
    understanding of interacting with the OpenAI API, including how to structure requests
    and process the generated content.
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Convert the generated Markdown text to a Word document:'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The `markdown_to_docx` function converts the generated Markdown text to a Word
    document. It iterates through the lines of the Markdown text, adding headings
    and paragraphs based on the Markdown formatting, and saves the resulting Word
    document.
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Display the elapsed time while waiting for the API call:'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The `display_elapsed_time` function is used to display the elapsed time while
    waiting for the API call to complete. It uses a loop to print the elapsed time
    in seconds.
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Write the main function:'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: In the main part of the script, we start by defining an `assessment_name` function
    based on the current date and time. We then use threading to display the elapsed
    time while making the API call. The script calls the `generate_report` function
    with the user data as arguments, and upon successful completion, it saves the
    generated report as a Word document using the `markdown_to_docx` function. The
    progress is displayed using the `tqdm` library. If any errors occur during the
    API call or report generation, they are displayed to the user.
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Hint
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: You can swap out the **chat-3.5-turbo** model with the **GPT-4** model, if you
    are a ChatGPT Plus subscriber, for often improved results. In fact, GPT-4 is capable
    of generating a much longer and more detailed generation and/or document. Just
    keep in mind that the GPT-4 model is a bit more expensive than the chat-3.5-turbo
    model.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is how the completed script should look:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: This script automates the process of generating a vulnerability assessment plan
    by using the OpenAI API in conjunction with Python. It starts by importing the
    necessary libraries and setting up the OpenAI API. It then reads user input data
    from a text file (the file path is stored as a `user_data_file` string) and then
    stores this data in a dictionary for easy access.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: The core of the script is the function that generates the vulnerability assessment
    plan. It leverages the OpenAI API to create a detailed report based on the user
    input data. The conversation with the API is formatted with both `system` and
    `user` roles to guide the generation process effectively.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: Once the report is generated, it is converted from Markdown text to a Word document,
    providing a well-structured, readable output. To provide user feedback during
    the process, the script includes a function that displays the elapsed time while
    the API call is being made.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the script’s main function ties everything together. It initiates the
    process of generating the report using the OpenAI API, shows the elapsed time
    during the API call, and finally, converts the generated report to a Word document.
    If any errors occur during the API call or the document generation, they are handled
    and displayed to the user.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: Threat Assessment using ChatGPT and the MITRE ATT&CK framework
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, you will learn how to leverage **ChatGPT** and the **OpenAI
    API** to conduct a threat assessment by providing a threat, attack, or campaign
    name. By combining the power of ChatGPT with the **MITRE ATT&CK** framework, you
    will be able to generate detailed threat reports, **tactics, techniques, and procedures**
    (**TTPs**) mappings, and associated **indicators of compromise** (**IoCs**). This
    information will enable cybersecurity professionals to analyze attack vectors
    in their environment and extend their capabilities into threat hunting.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: Building upon the skills acquired in [*Chapter 1*](B21091_01.xhtml#_idTextAnchor022),
    this recipe will guide you through establishing the system role of a cybersecurity
    analyst and engineering effective prompts that generate well-formatted output,
    including tables. You will learn how to design prompts to obtain the desired output
    from ChatGPT using both the ChatGPT web UI and a Python script. Additionally,
    you will learn how to use the OpenAI API to generate a comprehensive threat report
    in a Microsoft Word file format.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Before diving into the recipe, you should already have your OpenAI account
    set up and obtained your API key. If not, revisit [*Chapter 1*](B21091_01.xhtml#_idTextAnchor022)
    for details. You will also need to do the following:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: '`python-docx` library installed in your Python environment, as it will be used
    to generate Microsoft Word files. You can install it using the `pip install` `python-docx`
    command.'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Familiarize yourself with the MITRE ATT&CK framework**: To make the most
    of this recipe, it’s helpful to have a basic understanding of the MITRE ATT&CK
    framework. Visit [https://attack.mitre.org/](https://attack.mitre.org/) for more
    information and resources.'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**List sample threats**: Prepare a list of sample threat names, attack campaigns,
    or adversary groups to use as examples while working through the recipe.'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How to do it…
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'By following these steps, you can successfully utilize ChatGPT to generate
    a TTP-based threat report using the MITRE ATT&CK framework and proper Markdown
    formatting. We will be specifying the name of a threat and applying prompt engineering
    techniques. ChatGPT will then generate a well-formatted report with valuable insights
    that can assist you in threat analysis, attack vector assessment, and even in
    gathering IoCs for threat hunting:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: Begin by logging in to your ChatGPT account and navigating to the ChatGPT web
    UI.
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Start a new conversation with ChatGPT by clicking the **New** **chat** button.
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Enter the following prompt to establish a system role:'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Replace `{threat_name}` in the user prompt below with the threat name of your
    choice (in our example, we will use **WannaCry**). You can either combine this
    prompt with the system role or enter it separately:'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Hint
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: Just as with the previous recipe, you can perform this in the **OpenAI Playground**
    and use **Chat mode** to enter the role in the **System** window, and the prompt
    in the **User** **message** window.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 2**.3* shows the system role and user prompt entered into the **OpenAI
    Playground**:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.3 – OpenAI Playground method](img/Figure_2.03_B21091.jpg)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
- en: Figure 2.3 – OpenAI Playground method
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: After entering the appropriate system role and user prompt, press *Enter*.
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: ChatGPT will process the prompt and generate a formatted threat report with
    Markdown language formatting, headings, bold keywords, tables, and other elements
    specified in the prompt.
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Figure 2**.4* and *Figure 2**.5* illustrate an example ChatGPT generation
    of a threat report using Markdown language formatting with a table:'
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.4 – ChatGPT threat report narrative output](img/Figure_2.04_B21091.jpg)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
- en: Figure 2.4 – ChatGPT threat report narrative output
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.5 – ChatGPT threat report table output](img/Figure_2.05_B21091.jpg)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
- en: Figure 2.5 – ChatGPT threat report table output
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: Review the generated report to ensure it contains the desired information and
    formatting. If necessary, adjust your user prompt and resubmit it to improve the
    output.
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Hint
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes, ChatGPT will stop generating before it has completed the entire out.
    This is due to the token limit of the model being used. In such cases, you can
    click on the **Continue** **Generating** button.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Just as we did in the *Applying ChatGPT Roles (Application: AI CISO)* recipe
    in[*Chapter 1*](B21091_01.xhtml#_idTextAnchor022), when you assign a role to ChatGPT,
    you provide a specific context or persona for the model to work with. This helps
    the model generate responses that are tailored to the given role, resulting in
    more accurate, relevant, and detailed content. The model will generate content
    that aligns with the expertise and perspective of the assigned role, offering
    better insights, opinions, or recommendations.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: When we provide a threat name and direct ChatGPT to reference the MITRE ATT&CK
    framework, we are able to leverage its massive dataset, which includes detailed
    information about threats and the MITRE ATT&CK framework. As a result, it is able
    to correlate the two and quickly give us the relevant threat information as it
    pertains to the TTPs identified in the framework.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: When using the current version of ChatGPT and the OpenAI API as of the time
    of this writing, the dataset is only trained up through September 2021\. Therefore,
    it will not have knowledge of any threat data after that. However, we will cover
    techniques later in this book on how to use the API and Python to feed recent
    data into the request.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: 'By providing a clear template for the output in your prompt, you guide ChatGPT
    to generate responses that adhere to the specified structure and formatting. This
    helps ensure that the generated content is consistent, well organized, and suitable
    for use in reports, presentations, or other formal documents. The model will focus
    on generating content that matches the formatting and structure you’ve provided
    while still delivering the information you requested. See the *Enhancing Output
    with Templates (Application: Threat Report)* and *Formatting Output as a Table
    (Application: Security Controls Table)* recipes in [*Chapter 1*](B21091_01.xhtml#_idTextAnchor022)
    for further details.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: There’s more…
  id: totrans-124
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You can extend the power and flexibility of this recipe by using the OpenAI
    API with a Python script to generate a threat report, similar to the one created
    in the ChatGPT web UI. Here’s how you do it:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: 'Start by importing the necessary libraries:'
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Set up the OpenAI API the same as we did in the *Setting the OpenAI API key
    as an Environment Variable* recipe in [*Chapter 1*](B21091_01.xhtml#_idTextAnchor022):'
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Create a function to generate a report using the OpenAI API:'
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: This function takes a threat name as input and sends it as part of a prompt
    to the OpenAI API. It returns the generated text from the API response.
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Create a function to convert the generated text, which is in Markdown format,
    to a Microsoft Word document:'
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: This function takes the generated text in Markdown format and an output filename.
    It parses the Markdown text and creates a Word document with the appropriate formatting.
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Create a function to extract tables from the Markdown text:'
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: This function iterates through the Markdown text and extracts any tables it
    finds.
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Create a function to display the elapsed time while waiting for the API call:'
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: This function shows the elapsed time in seconds while waiting for the API call
    to complete.
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Get the threat name from user input:'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Start a separate thread to display the elapsed time while making the API call:'
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Make the API call and handle exceptions:'
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Save the generated report as a Word document:'
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Generate the report and handle exceptions:'
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Here is how the completed script should look:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: This script uses the **OpenAI API** to generate a cyber threat report as a **Microsoft**
    **Word document**.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: The crux of this script lies in several key functions. The first function, `generate_report()`,
    takes in a cyber threat name and uses it as a prompt for the OpenAI API. It returns
    the generated text from the API response. This text is in Markdown format and
    is subsequently transformed into a Microsoft Word document by the `markdown_to_docx()`
    function.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: This function parses through the Markdown text line by line, creating tables
    and headings as required, and finally saves it as a Word document. In parallel,
    there is an `extract_tables()` function that is designed to locate and extract
    any tables present within the Markdown text.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: 'To enhance the user experience, the `display_elapsed_time()` function is incorporated.
    This function tracks and displays the time taken for the API call to complete.
    It runs in a separate thread, initiated before making the API call:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.6 – Example output of the display_elapsed_time function](img/Figure_2.06_B21091.jpg)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
- en: Figure 2.6 – Example output of the display_elapsed_time function
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: The API call itself, as well as the report generation, are wrapped in `try`-`except`
    blocks to handle any potential exceptions. Once the report is generated, it is
    saved as a Word document, with the filename based on the user-inputted cyber threat
    name.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: Upon successful execution of this script, a detailed threat report in Word document
    format is produced, mimicking the output generated by the ChatGPT web UI. This
    recipe demonstrates how the OpenAI API can be adapted within a Python script to
    automate the generation of comprehensive reports.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: Hint
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: You can swap out the **chat-3.5-turbo** model with the **GPT-4** model, if you
    are a ChatGPT Plus subscriber, for often improved results. Just keep in mind that
    the GPT-4 model is a bit more expensive than the chat-3.5-turbo model.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: You can also improve accuracy and get a more consistent output by lowering the
    `temperature` value.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: GPT-Assisted Vulnerability Scanning
  id: totrans-165
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Vulnerability scanning** plays a crucial role in identifying and remediating
    weaknesses before they can be exploited by malicious actors. The tools we use
    to conduct these scans, such as **NMAP**, **OpenVAS**, or **Nessus**, offer robust
    functionality but can often be complex and challenging to navigate, especially
    for those new to the field or unfamiliar with their advanced options.'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: This is where our recipe comes into play. It leverages the power of ChatGPT
    to streamline the process of generating command strings for these tools based
    on user input. With this recipe, you will be able to create precise command strings
    that can be directly copied and pasted into a CLI to initiate a vulnerability
    scan, provided the respective tool is installed.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: This recipe is not just about saving time; it’s about enhancing accuracy, understanding,
    and effectiveness. It is beneficial for those learning vulnerability assessments,
    those who are new to these tools, and even seasoned professionals who need a quick
    reference to ensure their command options are correct. It is especially useful
    when dealing with advanced options, such as parsing the output or outputting results
    to files or other formats.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: By the end of this recipe, you will be able to generate precise command strings
    for NMAP, OpenVAS, or Nessus, helping you navigate their functionalities with
    ease and confidence. Whether you are a cybersecurity beginner or a seasoned expert,
    this recipe will serve as a valuable tool in your vulnerability assessment arsenal.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  id: totrans-170
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Before we begin this recipe, it’s essential to ensure that you have properly
    set up your OpenAI account and obtained your API key. If this hasn’t been done
    yet, you can refer back to [*Chapter 1*](B21091_01.xhtml#_idTextAnchor022) for
    detailed instructions. Additionally, you will require the following:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: '**Vulnerability scanning tools**: It’s crucial to have NMAP, OpenVAS, or Nessus
    installed on your system as the recipe generates command strings for these specific
    tools. Please refer to their official documentation for installation and setup
    guidelines.'
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Basic understanding of the tools**: The more familiar you are with NMAP,
    OpenVAS, or Nessus, the better you will be able to utilize this recipe. If you’re
    new to these tools, consider spending some time understanding their basic functionalities
    and command-line options.'
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Command-line environment**: As the recipe generates command strings intended
    for CLIs, you should have access to a suitable command-line environment where
    you can run these commands. This could be a terminal in Unix/Linux systems or
    Command Prompt or PowerShell in Windows.'
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Sample network configuration data**: Prepare some sample network data that
    the vulnerability scanning tools can use. This could include IP addresses, hostnames,
    or other relevant information about the systems you’d like to scan.'
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How to do it…
  id: totrans-176
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this recipe, we’ll show you how to use ChatGPT to create command strings
    for vulnerability scanning tools such as NMAP, OpenVAS, and Nessus. We’ll be providing
    ChatGPT with the necessary details and using a specific system role and prompt.
    This will allow you to generate the simplest form of the command necessary to
    complete your request:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: Start by logging in to your OpenAI account and go to the ChatGPT web UI.
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Begin a new conversation with ChatGPT by clicking on the **New** **chat** button.
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Next, establish the system’s role by entering the following:'
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Important note
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: Just as in the *Creating Vulnerability Assessment Plans* recipe, you can enter
    the role separately using the **OpenAI Playground**, or you can combine it as
    a single prompt in ChatGPT.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, prepare your request. This is the information that will replace the `{user_input}`
    placeholder in the next step. It should be a natural language request such as
    the following:'
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Once your request is ready, enter the following message text, replacing the
    `{user_input}` placeholder with your specific request from the previous step:'
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: ChatGPT will then generate the command string based on your request. Review
    the output. If it meets your requirements, you can proceed to copy the command
    and use it as needed. If it doesn’t, you may need to refine your request and try
    again.
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Once you’ve obtained a satisfactory command, you can copy and paste it directly
    into your command line to perform the vulnerability scan as described in your
    request.
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Important note
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: Remember—it’s important to review and understand any command before running
    it in your environment. While ChatGPT aims to provide accurate commands, you are
    ultimately responsible for ensuring the command’s safety and appropriateness for
    your specific context.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 2**.7* shows an example ChatGPT command generated from the prompt used
    in this recipe:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.7 – Example ChatGPT command generation](img/Figure_2.07_B21091.jpg)'
  id: totrans-193
  prefs: []
  type: TYPE_IMG
- en: Figure 2.7 – Example ChatGPT command generation
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  id: totrans-195
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The GPT-assisted vulnerability scanning recipe taps into the power of NLP and
    the vast knowledge of ML algorithms to generate accurate and appropriate command
    strings for vulnerability scanning tools such as NMAP, OpenVAS, and Nessus. When
    you provide a specific system role and a prompt that represents a user request,
    ChatGPT uses these inputs to understand the context and generate a response that
    aligns with the given role:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: '**System role definition**: By defining ChatGPT’s role as a professional cybersecurity
    red team specialist and an expert in penetration testing and vulnerability scanning
    tools, you’re instructing the model to answer from a perspective of deep technical
    understanding and expertise in this field. This context helps in generating accurate
    and relevant command strings.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Natural language prompt**: The natural language prompt that simulates a user
    request allows ChatGPT to understand the task at hand in a human-like manner.
    Instead of needing structured data or specific keywords, ChatGPT can interpret
    the request as a human would and provide a suitable response.'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Command generation**: With the role and the prompt, ChatGPT generates the
    Linux command necessary to complete the request. The command is based on the specific
    details of the user input and the expertise of the assigned role. This is where
    the AI leverages its knowledge of cybersecurity and language understanding to
    construct the necessary command string.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**One-line command**: The specification of providing a one-line command, including
    all necessary operators and pipes, compels ChatGPT to generate a command that’s
    ready to be pasted into a command line for immediate execution. This removes the
    need for the user to manually combine or modify the command, saving time and potential
    errors.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Simplicity and clarity**: By asking for the simplest form of the command
    and without any further explanation, the output is kept clear and concise, which
    is particularly helpful for those learning or in need of a quick reference.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In summary, the GPT-assisted vulnerability scanning recipe harnesses the power
    of NLP and ML algorithms to generate precise, ready-to-run commands for vulnerability
    scanning. By using the defined system role and prompt, users can streamline the
    process of crafting commands for vulnerability assessments, save time, and improve
    accuracy.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: There’s more…
  id: totrans-203
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The flexibility and capabilities of this GPT-assisted process extend beyond
    the example given. First is the versatility of the prompt. It’s actually designed
    to accommodate virtually any request for *any* Linux command across any domain
    or task. This is a significant advantage as it enables you to leverage ChatGPT’s
    capabilities across a wide range of scenarios. By assigning the role appropriately,
    such as `"You are a Linux system administrator"`, and substituting your specific
    request in place of `{user_input}`, you can guide the AI to generate accurate
    and context-specific command strings for a plethora of Linux operations.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: Beyond simply generating command strings, the potential of this recipe is amplified
    when combined with the OpenAI API and Python. With the proper setup, not only
    can you generate the necessary Linux commands but you can also automate the execution
    of these commands. Essentially, this could turn ChatGPT into an active participant
    in your command-line operations, potentially saving you significant time and effort.
    This level of automation represents a substantial step forward in interacting
    with AI models, turning them into active assistants rather than passive information
    generators.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: In upcoming recipes in this book, we’ll delve deeper into command automation.
    This is just the beginning of the possibilities opened up by the integration of
    AI with your operating system tasks.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: Analyzing Vulnerability Assessment Reports using LangChain
  id: totrans-207
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As powerful as ChatGPT and the OpenAI API are, they currently have a significant
    limitation—the **token window**. This window determines how many characters can
    be exchanged in a complete message between the user and ChatGPT. Once the token
    count exceeds this limitation, ChatGPT may lose track of the original context,
    making the analysis of large bodies of text or documents challenging.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: Enter **LangChain**—a framework designed to navigate around this very hurdle.
    LangChain allows us to embed and vectorize large groups of text.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: '**Embedding** refers to the process of transforming text into numerical vectors
    that an ML model can understand and process. **Vectorizing**, on the other hand,
    is a technique to encode non-numeric features as numbers. By converting large
    bodies of text into vectors, we can enable ChatGPT to access and analyze vast
    amounts of information, effectively turning the text into a *knowledgebase* that
    the model can refer to, even if it hasn’t been trained on this data previously.'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we will leverage the power of LangChain, Python, the OpenAI
    API, and **Streamlit** (a framework for quickly and easily creating web applications)
    to analyze voluminous documents such as vulnerability assessment reports, threat
    reports, standards, and more. With a simple UI for uploading files and crafting
    prompts, the task of analyzing these documents will be simplified to the point
    of asking ChatGPT straightforward natural language queries.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  id: totrans-213
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Before we start with the recipe, ensure that you have an OpenAI account set
    up and have obtained your API key. If you haven’t done this yet, please revisit
    [*Chapter 1*](B21091_01.xhtml#_idTextAnchor022) for the steps. Apart from this,
    you’ll also need the following:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: '`python-docx`, `langchain`, `streamlit`, and `openai`. You can install these
    using the `pip install` command as follows:'
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '**Vulnerability assessment report (or a large document of your choice to be
    analyzed)**: Prepare a vulnerability assessment report or any other substantial
    document that you aim to analyze. The document can be in any format as long as
    you can convert it into a **PDF**.'
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Access to LangChain documentation**: Throughout this recipe, we will be utilizing
    LangChain, a relatively new framework. Although we will walk you through the process,
    having the LangChain documentation handy might be beneficial. You can access it
    at [https://docs.langchain.com/docs/](https://docs.langchain.com/docs/).'
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Streamlit**: We will be using Streamlit, a fast and straightforward way to
    create web apps for Python scripts. While we will guide you through the basics
    in this recipe, you may want to explore it on your own. You can learn more about
    Streamlit at [https://streamlit.io/](https://streamlit.io/).'
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How to do it…
  id: totrans-220
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this recipe, we’ll walk you through the steps needed to create a document
    analyzer using LangChain, Streamlit, OpenAI, and Python. The application will
    allow you to upload a PDF document, ask questions about it in natural language,
    and get responses generated by the language model based on the document’s content:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: '`dotenv` to load environment variables, `streamlit` to create the web interface,
    `PyPDF2` to read the PDF files, and various components from `langchain` to handle
    the language model and text processing:'
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-223
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '`"Document Analyzer"` and a `"What would you like to know about this document?"`
    header text prompt:'
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-225
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '**Upload the PDF**: Add a file uploader to the Streamlit application to allow
    users to upload a PDF document:'
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-227
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '**Extract the text from the PDF**: If a PDF is uploaded, read the PDF and extract
    the text from it:'
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '**Split the text into chunks**: Break down the extracted text into manageable
    chunks that can be processed by the language model:'
  id: totrans-230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '`OpenAIEmbeddings` to create vector representations of the chunks:'
  id: totrans-232
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '**Ask a question about the PDF**: Show a text input field in the Streamlit
    application for the user to ask a question about the uploaded PDF:'
  id: totrans-234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-235
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '**Generate a response**: If the user asks a question, find the chunks that
    are semantically similar to the question, feed those chunks to the language model,
    and generate a response:'
  id: totrans-236
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-237
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Run the script with Streamlit. Using a command-line terminal, run the following
    command from the same directory as the script:'
  id: totrans-238
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  id: totrans-239
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Here is how the completed script should look:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: The script essentially automates the analysis of large documents, such as vulnerability
    assessment reports, using the LangChain framework, Python, and OpenAI. It leverages
    Streamlit to create an intuitive web interface where users can upload a PDF file
    for analysis.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
- en: 'The uploaded document undergoes a series of operations: it’s read and its text
    is extracted, then split into manageable chunks. These chunks are transformed
    into vector representations (embeddings) using OpenAI Embeddings, enabling the
    language model to interpret and process the text semantically. These embeddings
    are stored in a database (**Facebook AI Similarity Search**, or **FAISS** for
    short), facilitating efficient similarity searches.'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
- en: The script then provides an interface for users to ask questions about the uploaded
    document. Upon receiving a question, it identifies the most semantically relevant
    chunks of text to the question from the database. These chunks, along with the
    user’s question, are processed by a question-answering chain in LangChain, generating
    a response that is displayed back to the user.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
- en: In essence, this script transforms large, unstructured documents into an interactive
    knowledge base, enabling users to pose questions and receive AI-generated responses
    based on the document’s content.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  id: totrans-246
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: First, the necessary modules are imported. These include the `dotenv` module
    for loading environment variables, `streamlit` for creating the application’s
    UI, `PyPDF2` for handling PDF documents, and various modules from `langchain`
    for handling language model tasks.
  id: totrans-247
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `PyPDF2` to read the text of the PDF.
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The text from the PDF is then split into smaller chunks using LangChain’s `chunk``size`,
    `overlap`, and `separator`, used to split the text—are specified.
  id: totrans-249
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Next, OpenAI **Embeddings** from LangChain are used to convert the chunks of
    text into **vector representations**. This involves encoding the semantic information
    of the text into a mathematical form that can be processed by the language model.
    These embeddings are stored in a FAISS database, which allows efficient similarity
    searching for **high-dimensional vectors**.
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The application then takes a user input in the form of a question about the
    PDF. It uses the FAISS database to find the chunks of text that are semantically
    most similar to the question. These chunks are likely to contain the information
    needed to answer the question.
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The chosen chunks of text and the user’s question are fed into a question-answering
    *chain* from LangChain. This chain is loaded with an instance of the OpenAI language
    model. The chain processes the input documents and the question, using the language
    model to generate a response.
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The OpenAI callback is used to capture metadata about the API usage, such as
    the number of tokens used in the request.
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, the response from the chain is displayed in the Streamlit application.
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This process allows for semantic querying of large documents that exceed the
    language model’s token limit. By splitting the document into smaller chunks and
    using semantic similarity to find the chunks most relevant to a user’s question,
    the application can provide useful answers even when the entire document can’t
    be processed at once by the language model. This demonstrates one way to overcome
    the token limit challenge when working with large documents and language models.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
- en: There’s more…
  id: totrans-256
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: LangChain is not just a tool for overcoming the token window limitation; it’s
    a comprehensive framework for creating applications that interact intelligently
    with language models. These applications can connect a language model to other
    data sources and allow the model to interact with its environment—essentially
    providing the model with a degree of agency. LangChain offers modular abstractions
    for the components necessary to work with language models, along with a collection
    of implementations for these abstractions. Designed for ease of use, these components
    can be employed whether you’re using the full LangChain framework or not.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
- en: What’s more, LangChain introduces the concept of *chains*—these are combinations
    of the aforementioned components, assembled in specific ways to accomplish particular
    use cases. Chains offer a high-level interface for users to get started with a
    specific use case easily and are designed to be customizable to cater to a variety
    of tasks.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
- en: In later recipes, we’ll demonstrate how to use these features of LangChain to
    analyze even larger and more complex documents, such as `.csv` files and spreadsheets.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
