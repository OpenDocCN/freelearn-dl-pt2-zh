["```py\npip install torch torchvision \n```", "```py\npip install torch==1.9.0 torchvision==0.10.0 \n```", "```py\npip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html \n```", "```py\npip install torch==1.9.0 torchvision==0.10.0\\  -f https://download.pytorch.org/whl/torch_stable.html \n```", "```py\npython -c 'import torch; print(torch.__version__)' \n```", "```py\n>>> import torch\n>>> import numpy as np\n>>> np.set_printoptions(precision=3)\n>>> a = [1, 2, 3]\n>>> b = np.array([4, 5, 6], dtype=np.int32)\n>>> t_a = torch.tensor(a)\n>>> t_b = torch.from_numpy(b)\n>>> print(t_a)\n>>> print(t_b)\ntensor([1, 2, 3])\ntensor([4, 5, 6], dtype=torch.int32) \n```", "```py\n>>> t_ones = torch.ones(2, 3)\n>>> t_ones.shape\ntorch.Size([2, 3])\n>>> print(t_ones)\ntensor([[1., 1., 1.],\n        [1., 1., 1.]]) \n```", "```py\n>>> rand_tensor = torch.rand(2,3)\n>>> print(rand_tensor)\ntensor([[0.1409, 0.2848, 0.8914],\n        [0.9223, 0.2924, 0.7889]]) \n```", "```py\n>>> t_a_new = t_a.to(torch.int64)\n>>> print(t_a_new.dtype)\ntorch.int64 \n```", "```py\n    >>> t = torch.rand(3, 5)\n    >>> t_tr = torch.transpose(t, 0, 1)\n    >>> print(t.shape, ' --> ', t_tr.shape)\n    torch.Size([3, 5])  -->  torch.Size([5, 3]) \n    ```", "```py\n    >>> t = torch.zeros(30)\n    >>> t_reshape = t.reshape(5, 6)\n    >>> print(t_reshape.shape)\n    torch.Size([5, 6]) \n    ```", "```py\n    >>> t = torch.zeros(1, 2, 1, 4, 1)\n    >>> t_sqz = torch.squeeze(t, 2)\n    >>> print(t.shape, ' --> ', t_sqz.shape)\n    torch.Size([1, 2, 1, 4, 1])  -->  torch.Size([1, 2, 4, 1]) \n    ```", "```py\n>>> torch.manual_seed(1)\n>>> t1 = 2 * torch.rand(5, 2) - 1\n>>> t2 = torch.normal(mean=0, std=1, size=(5, 2)) \n```", "```py\n>>> t3 = torch.multiply(t1, t2)\n>>> print(t3)\ntensor([[ 0.4426, -0.3114], \n        [ 0.0660, -0.5970], \n        [ 1.1249,  0.0150], \n        [ 0.1569,  0.7107], \n        [-0.0451, -0.0352]]) \n```", "```py\n>>> t4 = torch.mean(t1, axis=0)\n>>> print(t4)\ntensor([-0.1373,  0.2028]) \n```", "```py\n>>> t5 = torch.matmul(t1, torch.transpose(t2, 0, 1))\n>>> print(t5)\ntensor([[ 0.1312,  0.3860, -0.6267, -1.0096, -0.2943],\n        [ 0.1647, -0.5310,  0.2434,  0.8035,  0.1980],\n        [-0.3855, -0.4422,  1.1399,  1.5558,  0.4781],\n        [ 0.1822, -0.5771,  0.2585,  0.8676,  0.2132],\n        [ 0.0330,  0.1084, -0.1692, -0.2771, -0.0804]]) \n```", "```py\n>>> t6 = torch.matmul(torch.transpose(t1, 0, 1), t2)\n>>> print(t6)\ntensor([[ 1.7453,  0.3392],\n        [-1.6038, -0.2180]]) \n```", "```py\n>>> norm_t1 = torch.linalg.norm(t1, ord=2, dim=1)\n>>> print(norm_t1)\ntensor([0.6785, 0.5078, 1.1162, 0.5488, 0.1853]) \nL2 norm of t1 correctly, you can compare the results with the following NumPy function: np.sqrt(np.sum(np.square(t1.numpy()), axis=1)).\n```", "```py\n    >>> torch.manual_seed(1)\n    >>> t = torch.rand(6)\n    >>> print(t)\n    tensor([0.7576, 0.2793, 0.4031, 0.7347, 0.0293, 0.7999])\n    >>> t_splits = torch.chunk(t, 3)\n    >>> [item.numpy() for item in t_splits]\n    [array([0.758, 0.279], dtype=float32),\n     array([0.403, 0.735], dtype=float32),\n     array([0.029, 0.8  ], dtype=float32)] \n    ```", "```py\n    >>> torch.manual_seed(1)\n    >>> t = torch.rand(5)\n    >>> print(t)\n    tensor([0.7576, 0.2793, 0.4031, 0.7347, 0.0293])\n    >>> t_splits = torch.split(t, split_size_or_sections=[3, 2])\n    >>> [item.numpy() for item in t_splits]\n    [array([0.758, 0.279, 0.403], dtype=float32),\n     array([0.735, 0.029], dtype=float32)] \n    ```", "```py\n>>> A = torch.ones(3)\n>>> B = torch.zeros(2)\n>>> C = torch.cat([A, B], axis=0)\n>>> print(C)\ntensor([1., 1., 1., 0., 0.]) \n```", "```py\n>>> A = torch.ones(3)\n>>> B = torch.zeros(3)\n>>> S = torch.stack([A, B], axis=1)\n>>> print(S)\ntensor([[1., 0.],\n        [1., 0.],\n        [1., 0.]]) \n```", "```py\n>>> from torch.utils.data import DataLoader\n>>> t = torch.arange(6, dtype=torch.float32)\n>>> data_loader = DataLoader(t) \n```", "```py\n>>> for item in data_loader:\n...     print(item)\ntensor([0.])\ntensor([1.])\ntensor([2.])\ntensor([3.])\ntensor([4.])\ntensor([5.]) \n```", "```py\n>>> data_loader = DataLoader(t, batch_size=3, drop_last=False)\n>>> for i, batch in enumerate(data_loader, 1):\n...    print(f'batch {i}:', batch)\nbatch 1: tensor([0., 1., 2.])\nbatch 2: tensor([3., 4., 5.]) \n```", "```py\n>>> torch.manual_seed(1)\n>>> t_x = torch.rand([4, 3], dtype=torch.float32)\n>>> t_y = torch.arange(4) \n```", "```py\n>>> from torch.utils.data import Dataset\n>>> class JointDataset(Dataset):\n...     def __init__(self, x, y):\n...         self.x = x\n...         self.y = y\n...        \n...     def __len__(self):\n...         return len(self.x)\n...\n...     def __getitem__(self, idx):\n...         return self.x[idx], self.y[idx] \n```", "```py\n>>> joint_dataset = JointDataset(t_x, t_y) \n```", "```py\n>>> for example in joint_dataset:\n...     print('  x: ', example[0], '  y: ', example[1])\n  x:  tensor([0.7576, 0.2793, 0.4031])   y:  tensor(0)\n  x:  tensor([0.7347, 0.0293, 0.7999])   y:  tensor(1)\n  x:  tensor([0.3971, 0.7544, 0.5695])   y:  tensor(2)\n  x:  tensor([0.4388, 0.6387, 0.5247])   y:  tensor(3) \n```", "```py\n>>> joint_dataset = JointDataset(t_x, t_y) \n```", "```py\n>>> torch.manual_seed(1) \n>>> data_loader = DataLoader(dataset=joint_dataset, batch_size=2, shuffle=True) \n```", "```py\n>>> for i, batch in enumerate(data_loader, 1):\n...     print(f'batch {i}:', 'x:', batch[0],\n              '\\n         y:', batch[1])\nbatch 1: x: tensor([[0.4388, 0.6387, 0.5247],\n        [0.3971, 0.7544, 0.5695]]) \n         y: tensor([3, 2])\nbatch 2: x: tensor([[0.7576, 0.2793, 0.4031],\n        [0.7347, 0.0293, 0.7999]]) \n         y: tensor([0, 1]) \n```", "```py\n>>> for epoch in range(2): \n>>>     print(f'epoch {epoch+1}')\n>>>     for i, batch in enumerate(data_loader, 1):\n...         print(f'batch {i}:', 'x:', batch[0], \n                  '\\n         y:', batch[1])\nepoch 1\nbatch 1: x: tensor([[0.7347, 0.0293, 0.7999],\n        [0.3971, 0.7544, 0.5695]]) \n         y: tensor([1, 2])\nbatch 2: x: tensor([[0.4388, 0.6387, 0.5247],\n        [0.7576, 0.2793, 0.4031]]) \n         y: tensor([3, 0])\nepoch 2\nbatch 1: x: tensor([[0.3971, 0.7544, 0.5695],\n        [0.7576, 0.2793, 0.4031]]) \n         y: tensor([2, 0])\nbatch 2: x: tensor([[0.7347, 0.0293, 0.7999],\n        [0.4388, 0.6387, 0.5247]]) \n         y: tensor([1, 3]) \n```", "```py\n>>> import pathlib\n>>> imgdir_path = pathlib.Path('cat_dog_images')\n>>> file_list = sorted([str(path) for path in\n... imgdir_path.glob('*.jpg')])\n>>> print(file_list)\n['cat_dog_images/dog-03.jpg', 'cat_dog_images/cat-01.jpg', 'cat_dog_images/cat-02.jpg', 'cat_dog_images/cat-03.jpg', 'cat_dog_images/dog-01.jpg', 'cat_dog_images/dog-02.jpg'] \n```", "```py\n>>> import matplotlib.pyplot as plt\n>>> import os\n>>> from PIL import Image\n>>> fig = plt.figure(figsize=(10, 5))\n>>> for i, file in enumerate(file_list):\n...     img = Image.open(file)\n...     print('Image shape:', np.array(img).shape)\n...     ax = fig.add_subplot(2, 3, i+1)\n...     ax.set_xticks([]); ax.set_yticks([])\n...     ax.imshow(img)\n...     ax.set_title(os.path.basename(file), size=15)\n>>> plt.tight_layout()\n>>> plt.show()\nImage shape: (900, 1200, 3)\nImage shape: (900, 1200, 3)\nImage shape: (900, 1200, 3)\nImage shape: (900, 742, 3)\nImage shape: (800, 1200, 3)\nImage shape: (800, 1200, 3) \n```", "```py\n>>> labels = [1 if 'dog' in \n...              os.path.basename(file) else 0\n...                      for file in file_list]\n>>> print(labels)\n[0, 0, 0, 1, 1, 1] \n```", "```py\n>>> class ImageDataset(Dataset):\n...     def __init__(self, file_list, labels):\n...         self.file_list = file_list\n...         self.labels = labels\n... \n...     def __getitem__(self, index):\n...         file = self.file_list[index]\n...         label = self.labels[index]\n...         return file, label\n...\n...     def __len__(self):\n...         return len(self.labels)\n>>> image_dataset = ImageDataset(file_list, labels)\n>>> for file, label in image_dataset:\n...     print(file, label)\ncat_dog_images/cat-01.jpg 0\ncat_dog_images/cat-02.jpg 0\ncat_dog_images/cat-03.jpg 0\ncat_dog_images/dog-01.jpg 1\ncat_dog_images/dog-02.jpg 1\ncat_dog_images/dog-03.jpg 1 \n```", "```py\n>>> import torchvision.transforms as transforms \n>>> img_height, img_width = 80, 120\n>>> transform = transforms.Compose([\n...     transforms.ToTensor(),\n...     transforms.Resize((img_height, img_width)),\n... ]) \n```", "```py\n>>> class ImageDataset(Dataset):\n...     def __init__(self, file_list, labels, transform=None):\n...         self.file_list = file_list\n...         self.labels = labels\n...         self.transform = transform\n...\n...     def __getitem__(self, index):\n...         img = Image.open(self.file_list[index])\n...         if self.transform is not None:\n...             img = self.transform(img)\n...         label = self.labels[index]\n...         return img, label\n...\n...     def __len__(self):\n...         return len(self.labels)\n>>> \n>>> image_dataset = ImageDataset(file_list, labels, transform) \n```", "```py\n>>> fig = plt.figure(figsize=(10, 6))\n>>> for i, example in enumerate(image_dataset):\n...     ax = fig.add_subplot(2, 3, i+1)\n...     ax.set_xticks([]); ax.set_yticks([])\n...     ax.imshow(example[0].numpy().transpose((1, 2, 0)))\n...     ax.set_title(f'{example[1]}', size=15)\n...\n>>> plt.tight_layout()\n>>> plt.show() \n```", "```py\npip install torchvision \n```", "```py\n>>> import torchvision \n>>> image_path = './' \n>>> celeba_dataset = torchvision.datasets.CelebA(\n...     image_path, split='train', target_type='attr', download=True\n... )\n1443490838/? [01:28<00:00, 6730259.81it/s]\n26721026/? [00:03<00:00, 8225581.57it/s]\n3424458/? [00:00<00:00, 14141274.46it/s]\n6082035/? [00:00<00:00, 21695906.49it/s]\n12156055/? [00:00<00:00, 12002767.35it/s]\n2836386/? [00:00<00:00, 3858079.93it/s] \n```", "```py\n>>> assert isinstance(celeba_dataset, torch.utils.data.Dataset) \n```", "```py\n>>> example = next(iter(celeba_dataset))\n>>> print(example)\n(<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=178x218 at 0x120C6C668>, tensor([0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1])) \n```", "```py\n>>> from itertools import islice\n>>> fig = plt.figure(figsize=(12, 8))\n>>> for i, (image, attributes) in islice(enumerate(celeba_dataset), 18):\n...     ax = fig.add_subplot(3, 6, i+1)\n...     ax.set_xticks([]); ax.set_yticks([])\n...     ax.imshow(image)\n...     ax.set_title(f'{attributes[31]}', size=15)\n>>> plt.show() \n```", "```py\n>>> mnist_dataset = torchvision.datasets.MNIST(image_path, 'train', download=True)\n>>> assert isinstance(mnist_dataset, torch.utils.data.Dataset)\n>>> example = next(iter(mnist_dataset))\n>>> print(example)\n(<PIL.Image.Image image mode=L size=28x28 at 0x126895B00>, 5)\n>>> fig = plt.figure(figsize=(15, 6))\n>>> for i, (image, label) in  islice(enumerate(mnist_dataset), 10):\n...     ax = fig.add_subplot(2, 5, i+1)\n...     ax.set_xticks([]); ax.set_yticks([])\n...     ax.imshow(image, cmap='gray_r')\n...     ax.set_title(f'{label}', size=15)\n>>> plt.show() \n```", "```py\n>>> X_train = np.arange(10, dtype='float32').reshape((10, 1))\n>>> y_train = np.array([1.0, 1.3, 3.1, 2.0, 5.0, \n...                     6.3, 6.6,7.4, 8.0,\n...                     9.0], dtype='float32')\n>>> plt.plot(X_train, y_train, 'o', markersize=10)\n>>> plt.xlabel('x')\n>>> plt.ylabel('y')\n>>> plt.show() \n```", "```py\n>>> from torch.utils.data import TensorDataset\n>>> X_train_norm = (X_train - np.mean(X_train)) / np.std(X_train)\n>>> X_train_norm = torch.from_numpy(X_train_norm)\n>>> y_train = torch.from_numpy(y_train)\n>>> train_ds = TensorDataset(X_train_norm, y_train)\n>>> batch_size = 1\n>>> train_dl = DataLoader(train_ds, batch_size, shuffle=True) \n```", "```py\n>>> torch.manual_seed(1)\n>>> weight = torch.randn(1)\n>>> weight.requires_grad_()\n>>> bias = torch.zeros(1, requires_grad=True)\n>>> def model(xb):\n...     return xb @ weight + bias \n```", "```py\n>>> def loss_fn(input, target):\n...     return (input-target).pow(2).mean() \n```", "```py\n>>> learning_rate = 0.001\n>>> num_epochs = 200\n>>> log_epochs = 10\n>>> for epoch in range(num_epochs):\n...     for x_batch, y_batch in train_dl:\n...         pred = model(x_batch)\n...         loss = loss_fn(pred, y_batch)\n...         loss.backward()\n...     with torch.no_grad():\n...         weight -= weight.grad * learning_rate\n...         bias -= bias.grad * learning_rate\n...         weight.grad.zero_() \n...         bias.grad.zero_()   \n...     if epoch % log_epochs==0:\n...         print(f'Epoch {epoch}  Loss {loss.item():.4f}')\nEpoch 0  Loss 5.1701\nEpoch 10  Loss 30.3370\nEpoch 20  Loss 26.9436\nEpoch 30  Loss 0.9315\nEpoch 40  Loss 3.5942\nEpoch 50  Loss 5.8960\nEpoch 60  Loss 3.7567\nEpoch 70  Loss 1.5877\nEpoch 80  Loss 0.6213\nEpoch 90  Loss 1.5596\nEpoch 100  Loss 0.2583\nEpoch 110  Loss 0.6957\nEpoch 120  Loss 0.2659\nEpoch 130  Loss 0.1615\nEpoch 140  Loss 0.6025\nEpoch 150  Loss 0.0639\nEpoch 160  Loss 0.1177\nEpoch 170  Loss 0.3501\nEpoch 180  Loss 0.3281\nEpoch 190  Loss 0.0970 \n```", "```py\n>>> print('Final Parameters:', weight.item(), bias.item())\nFinal Parameters:  2.669806480407715 4.879569053649902\n>>> X_test = np.linspace(0, 9, num=100, dtype='float32').reshape(-1, 1)\n>>> X_test_norm = (X_test - np.mean(X_train)) / np.std(X_train)\n>>> X_test_norm = torch.from_numpy(X_test_norm)\n>>> y_pred = model(X_test_norm).detach().numpy()\n>>> fig = plt.figure(figsize=(13, 5))\n>>> ax = fig.add_subplot(1, 2, 1)\n>>> plt.plot(X_train_norm, y_train, 'o', markersize=10)\n>>> plt.plot(X_test_norm, y_pred, '--', lw=3)\n>>> plt.legend(['Training examples', 'Linear reg.'], fontsize=15)\n>>> ax.set_xlabel('x', size=15)\n>>> ax.set_ylabel('y', size=15)\n>>> ax.tick_params(axis='both', which='major', labelsize=15)\n>>> plt.show() \n```", "```py\n>>> import torch.nn as nn\n>>> loss_fn = nn.MSELoss(reduction='mean')\n>>> input_size = 1\n>>> output_size = 1\n>>> model = nn.Linear(input_size, output_size)\n>>> optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate) \n```", "```py\n>>> for epoch in range(num_epochs):\n...     for x_batch, y_batch in train_dl:\n...         # 1\\. Generate predictions\n...         pred = model(x_batch)[:, 0]\n...         # 2\\. Calculate loss\n...         loss = loss_fn(pred, y_batch)\n...         # 3\\. Compute gradients\n...         loss.backward()\n...         # 4\\. Update parameters using gradients\n...         optimizer.step()\n...         # 5\\. Reset the gradients to zero\n...         optimizer.zero_grad()    \n...     if epoch % log_epochs==0:\n...         print(f'Epoch {epoch}  Loss {loss.item():.4f}') \n```", "```py\n>>> print('Final Parameters:', model.weight.item(), model.bias.item())\nFinal Parameters: 2.646660089492798 4.883835315704346 \n```", "```py\n>>> from sklearn.datasets import load_iris\n>>> from sklearn.model_selection import train_test_split \n>>> iris = load_iris()\n>>> X = iris['data']\n>>> y = iris['target']\n>>> X_train, X_test, y_train, y_test = train_test_split(\n...    X, y, test_size=1./3, random_state=1) \n```", "```py\n>>> X_train_norm = (X_train - np.mean(X_train)) / np.std(X_train)\n>>> X_train_norm = torch.from_numpy(X_train_norm).float()\n>>> y_train = torch.from_numpy(y_train) \n>>> train_ds = TensorDataset(X_train_norm, y_train)\n>>> torch.manual_seed(1)\n>>> batch_size = 2\n>>> train_dl = DataLoader(train_ds, batch_size, shuffle=True) \n```", "```py\n>>> class Model(nn.Module):\n...     def __init__(self, input_size, hidden_size, output_size):\n...         super().__init__()\n...         self.layer1 = nn.Linear(input_size, hidden_size)\n...         self.layer2 = nn.Linear(hidden_size, output_size)\n...     def forward(self, x):\n...         x = self.layer1(x)\n...         x = nn.Sigmoid()(x)\n...         x = self.layer2(x)\n...         x = nn.Softmax(dim=1)(x)\n...         return x\n>>> input_size = X_train_norm.shape[1]\n>>> hidden_size = 16\n>>> output_size = 3 \n>>> model = Model(input_size, hidden_size, output_size) \n```", "```py\n>>> learning_rate = 0.001\n>>> loss_fn = nn.CrossEntropyLoss()\n>>> optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) \n```", "```py\n>>> num_epochs = 100\n>>> loss_hist = [0] * num_epochs\n>>> accuracy_hist = [0] * num_epochs\n>>> for epoch in range(num_epochs):\n...     for x_batch, y_batch in train_dl:\n...         pred = model(x_batch)\n...         loss = loss_fn(pred, y_batch)\n...         loss.backward()\n...         optimizer.step()\n...         optimizer.zero_grad()\n...         loss_hist[epoch] += loss.item()*y_batch.size(0)\n...         is_correct = (torch.argmax(pred, dim=1) == y_batch).float()\n...         accuracy_hist[epoch] += is_correct.mean()\n...      loss_hist[epoch] /= len(train_dl.dataset)\n...      accuracy_hist[epoch] /= len(train_dl.dataset) \n```", "```py\n>>> fig = plt.figure(figsize=(12, 5))\n>>> ax = fig.add_subplot(1, 2, 1)\n>>> ax.plot(loss_hist, lw=3)\n>>> ax.set_title('Training loss', size=15)\n>>> ax.set_xlabel('Epoch', size=15)\n>>> ax.tick_params(axis='both', which='major', labelsize=15)\n>>> ax = fig.add_subplot(1, 2, 2)\n>>> ax.plot(accuracy_hist, lw=3)\n>>> ax.set_title('Training accuracy', size=15)\n>>> ax.set_xlabel('Epoch', size=15)\n>>> ax.tick_params(axis='both', which='major', labelsize=15)\n>>> plt.show() \n```", "```py\n>>> X_test_norm = (X_test - np.mean(X_train)) / np.std(X_train)\n>>> X_test_norm = torch.from_numpy(X_test_norm).float()\n>>> y_test = torch.from_numpy(y_test) \n>>> pred_test = model(X_test_norm)\n>>> correct = (torch.argmax(pred_test, dim=1) == y_test).float()\n>>> accuracy = correct.mean()\n>>> print(f'Test Acc.: {accuracy:.4f}')\nTest Acc.: 0.9800 \n```", "```py\n>>> path = 'iris_classifier.pt'\n>>> torch.save(model, path) \n```", "```py\n>>> model_new = torch.load(path) \n```", "```py\n>>> model_new.eval()\nModel(\n  (layer1): Linear(in_features=4, out_features=16, bias=True)\n  (layer2): Linear(in_features=16, out_features=3, bias=True)\n) \n```", "```py\n>>> pred_test = model_new(X_test_norm)\n>>> correct = (torch.argmax(pred_test, dim=1) == y_test).float()\n>>> accuracy = correct.mean() \n>>> print(f'Test Acc.: {accuracy:.4f}')\nTest Acc.: 0.9800 \n```", "```py\n>>> path = 'iris_classifier_state.pt'\n>>> torch.save(model.state_dict(), path) \n```", "```py\n>>> model_new = Model(input_size, hidden_size, output_size)\n>>> model_new.load_state_dict(torch.load(path)) \n```", "```py\n>>> import numpy as np\n>>> X = np.array([1, 1.4, 2.5]) ## first value must be 1\n>>> w = np.array([0.4, 0.3, 0.5])\n>>> def net_input(X, w):\n...     return np.dot(X, w)\n>>> def logistic(z):\n...     return 1.0 / (1.0 + np.exp(-z))\n>>> def logistic_activation(X, w):\n...     z = net_input(X, w)\n...     return logistic(z)\n>>> print(f'P(y=1|x) = {logistic_activation(X, w):.3f}')\nP(y=1|x) = 0.888 \n```", "```py\n>>> # W : array with shape = (n_output_units, n_hidden_units+1)\n>>> #     note that the first column are the bias units\n>>> W = np.array([[1.1, 1.2, 0.8, 0.4],\n...               [0.2, 0.4, 1.0, 0.2],\n...               [0.6, 1.5, 1.2, 0.7]])\n>>> # A : data array with shape = (n_hidden_units + 1, n_samples)\n>>> #     note that the first column of this array must be 1\n>>> A = np.array([[1, 0.1, 0.4, 0.6]])\n>>> Z = np.dot(W, A[0])\n>>> y_probas = logistic(Z)\n>>> print('Net Input: \\n', Z)\nNet Input:\n[1.78  0.76  1.65]\n>>> print('Output Units:\\n', y_probas)\nOutput Units:\n[ 0.85569687  0.68135373  0.83889105] \n```", "```py\n>>> y_class = np.argmax(Z, axis=0)\n>>> print('Predicted class label:', y_class) \nPredicted class label: 0 \n```", "```py\n>>> def softmax(z):\n...     return np.exp(z) / np.sum(np.exp(z))\n>>> y_probas = softmax(Z)\n>>> print('Probabilities:\\n', y_probas)\nProbabilities:\n[ 0.44668973  0.16107406  0.39223621]\n>>> np.sum(y_probas)\n1.0 \n```", "```py\n>>> torch.softmax(torch.from_numpy(Z), dim=0)\ntensor([0.4467, 0.1611, 0.3922], dtype=torch.float64) \n```", "```py\n>>> import matplotlib.pyplot as plt\n>>> def tanh(z):\n...     e_p = np.exp(z)\n...     e_m = np.exp(-z)\n...     return (e_p - e_m) / (e_p + e_m)\n>>> z = np.arange(-5, 5, 0.005)\n>>> log_act = logistic(z)\n>>> tanh_act = tanh(z)\n>>> plt.ylim([-1.5, 1.5])\n>>> plt.xlabel('net input $z$')\n>>> plt.ylabel('activation $\\phi(z)$')\n>>> plt.axhline(1, color='black', linestyle=':')\n>>> plt.axhline(0.5, color='black', linestyle=':')\n>>> plt.axhline(0, color='black', linestyle=':')\n>>> plt.axhline(-0.5, color='black', linestyle=':')\n>>> plt.axhline(-1, color='black', linestyle=':')\n>>> plt.plot(z, tanh_act,\n...          linewidth=3, linestyle='--',\n...          label='tanh')\n>>> plt.plot(z, log_act,\n...          linewidth=3,\n...          label='logistic')\n>>> plt.legend(loc='lower right')\n>>> plt.tight_layout()\n>>> plt.show() \n```", "```py\n>>> np.tanh(z)\narray([-0.9999092 , -0.99990829, -0.99990737, ...,  0.99990644,\n        0.99990737,  0.99990829])\n>>> torch.tanh(torch.from_numpy(z))\ntensor([-0.9999, -0.9999, -0.9999,  ...,  0.9999,  0.9999,  0.9999],\n       dtype=torch.float64) \n```", "```py\n>>> from scipy.special import expit\n>>> expit(z)\narray([0.00669285, 0.00672617, 0.00675966, ..., 0.99320669, 0.99324034,\n       0.99327383]) \n```", "```py\n>>> torch.sigmoid(torch.from_numpy(z))\ntensor([0.0067, 0.0067, 0.0068,  ..., 0.9932, 0.9932, 0.9933],\n       dtype=torch.float64) \n```", "```py\n>>> torch.relu(torch.from_numpy(z))\ntensor([0.0000, 0.0000, 0.0000,  ..., 4.9850, 4.9900, 4.9950],\n       dtype=torch.float64) \n```"]