- en: Getting Started with Artificial Intelligence in Python
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: Python 中的人工智能入门
- en: In this chapter, we'll start by setting up a Jupyter environment to run our
    experiments and algorithms in, we'll get into different nifty Python and Jupyter
    hacks for **artificial intelligence** (**AI**), we'll do a toy example in scikit-learn,
    Keras, and PyTorch, and then a slightly more elaborate example in Keras to round
    things off. This chapter is largely introductory, and a lot of what see in this
    chapter will be built on in subsequent chapters as we get into more advanced applications.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将首先设置一个 Jupyter 环境来运行我们的实验和算法，我们将介绍不同的巧妙 Python 和 Jupyter 的 AI 技巧，我们将在
    scikit-learn、Keras 和 PyTorch 中进行一个玩具示例，然后在 Keras 中进行稍微复杂的示例以完成这些事情。本章主要是介绍性的，本章中看到的许多内容将在后续章节中进一步构建，因为我们将涉及更高级的应用。
- en: 'In this chapter, we''ll cover the following recipes:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下示例：
- en: Setting up a Jupyter environment
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置 Jupyter 环境
- en: Getting proficient in Python for AI
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python AI 熟练掌握
- en: Classifying in scikit-learn, Keras, and PyTorch
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 scikit-learn、Keras 和 PyTorch 中进行分类
- en: Modeling with Keras
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Keras 进行建模
- en: Technical requirements
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: You really should have a GPU available in order to run some of the recipes in
    this book, or you would better off using Google Colab. There are some extra steps
    required to make sure you have the correct NVIDIA graphics drivers installed,
    along with some additional libraries. Google provides up-to-date instructions
    on the TensorFlow website at [https:/​/​www. tensorflow.​org/​install/​gpu](https:/%E2%80%8B/%E2%80%8Bwww.%20tensorflow.%E2%80%8Borg/%E2%80%8Binstall/%E2%80%8Bgpu).
    Similarly, PyTorch versions have minimum requirements for NVIDIA driver versions
    (which you'd have to check manually for each PyTorch version). Let's see how to
    use dockerized environments to help set this up.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 为了能够运行本书中的一些示例，您确实应该有一个 GPU 可用，或者最好使用 Google Colab。需要一些额外步骤来确保您安装了正确的 NVIDIA
    图形驱动程序，以及一些额外的库。在 TensorFlow 网站上，Google 提供了有关最新的 NVIDIA 驱动程序的安装指南，网址为 [https:/​/​www.
    tensorflow.​org/​install/​gpu](https:/%E2%80%8B/%E2%80%8Bwww.%20tensorflow.%E2%80%8Borg/%E2%80%8Binstall/%E2%80%8Bgpu)。同样，PyTorch
    版本对 NVIDIA 驱动程序版本有最低要求（您需要手动检查每个 PyTorch 版本）。让我们看看如何使用 Docker 环境来帮助设置这些。
- en: You can find the recipes in this chapter in the GitHub repository of this book
    at [https://github.com/PacktPublishing/Artificial-Intelligence-with-Python-Cookbook](https://github.com/PacktPublishing/Artificial-Intelligence-with-Python-Cookbook).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在本书的 GitHub 存储库中找到本章的示例，网址为 [https://github.com/PacktPublishing/Artificial-Intelligence-with-Python-Cookbook](https://github.com/PacktPublishing/Artificial-Intelligence-with-Python-Cookbook)。
- en: Setting up a Jupyter environment
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置 Jupyter 环境
- en: As you are aware, since you've acquired this book, Python is the dominant programming
    language in AI. It has the richest ecosystem of all programming languages, including
    many implementations of state-of-the-art algorithms that make using them often
    a matter of simply importing and setting a few selected parameters. It should
    go without saying that we will go beyond the basic usage in many cases and we
    will talk about a lot of the underlying ideas and technologies as we go through
    the recipes.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所知，自从你获取了这本书以来，Python 已经成为人工智能领域的主导编程语言。它拥有所有编程语言中最丰富的生态系统，包括许多最先进算法的实现，使用它们通常只需简单导入并设置少量参数。无需多言，在许多情况下我们将超越基本用法，并在我们深入实例时讨论很多潜在的思想和技术。
- en: We can't emphasize enough the importance of being able to quickly prototype
    ideas and see how well they work as part of a solution. This is often the main
    part of AI or data science work. A **read-eval-print loop** (**REPL**) is essential
    for quick iteration when turning an idea into a prototype, and you want functionality
    such as edit history, graphing, and more. This explains why Jupyter Notebook (where
    **Jupyter** is short for **Julia, Python, R**) is so central to working in AI.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们无法强调快速原型设计和查看其作为解决方案的效果的重要性。这通常是 AI 或数据科学工作的主要部分。当将想法转化为原型时，**读取-求值-打印循环**（REPL）是快速迭代的关键，您希望具有编辑历史、图形化等功能。这就解释了为什么
    Jupyter Notebook（其中 **Jupyter** 简称 **Julia, Python, R**）在 AI 工作中如此重要。
- en: Please note that, although we'll be focusing on Jupyter Notebook, or Google
    Colab, which runs Jupyter notebooks in the cloud, there are a few functionally
    similar alternatives around such as JupyterLab or even PyCharm running with a
    remote interpreter. Jupyter Notebook is still, however, the most popular (and
    probably the best supported) choice.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，尽管我们将专注于 Jupyter Notebook 或 Google Colab（它在云中运行 Jupyter 笔记本），但还有几个功能上类似的替代方案，例如
    JupyterLab 或者使用远程解释器运行的 PyCharm。然而，Jupyter Notebook 仍然是最流行（可能也是最受支持）的选择。
- en: In this recipe, we will make sure we have a working Python environment with
    the software libraries that we need throughout this book. We'll be dealing with
    installing relevant Python libraries for working with AI, and we'll set up a Jupyter
    Notebook server.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个步骤中，我们将确保我们有一个正常工作的 Python 环境，并安装我们在本书中需要的软件库。我们将处理安装与 AI 相关的 Python 库，并设置一个
    Jupyter Notebook 服务器。
- en: Getting ready
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'Firstly, ensure you have Python installed, as well as a method of installing
    libraries. There are different ways of using and installing libraries, depending
    on the following two scenarios:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 首先确保您已安装 Python，并有安装库的方法。根据以下两种情况使用和安装库有不同的方法：
- en: You use one of the services that host interactive notebooks, such as Google
    Colab.
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可以使用像 Google Colab 这样的服务来托管交互式笔记本。
- en: You install Python libraries on your own machine(s).
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可以在自己的机器上安装 Python 库。
- en: In Python, a **module** is a Python file that contains functions, variables,
    or classes. A **package** is a collection of modules within the same path. A **library**
    is a collection of related functionality, often in the form of different packages
    or modules. Informally, it's quite common to refer to a Python library as a package,
    and we'll sometimes do this here as well.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Python 中，**模块**是一个包含函数、变量或类的 Python 文件。**包**是在同一路径中包含多个模块的集合。**库**是相关功能的集合，通常以不同的包或模块形式存在。非正式地，将
    Python 库称为包是很常见的，我们这里有时也会这样称呼。
- en: How to do it...
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实施...
- en: Let's set up our Python environment(s)!
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们设置我们的 Python 环境！
- en: 'As we''ve mentioned, we''ll be looking at two scenarios:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们提到的，我们将看两种情况：
- en: Working with Google Colab
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Google Colab
- en: Setting up a computer ourselves to host a Jupyter Notebook instance
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自行设置计算机以托管 Jupyter Notebook 实例
- en: In the first case, we won't need to set up anything on our server as we'll only
    be installing a few additional libraries. In the second case, we'll be installing
    an environment with the Anaconda distribution, and we'll be looking at setup options
    for Jupyter.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一种情况下，我们无需在服务器上设置任何东西，只需安装几个额外的库。在第二种情况下，我们将安装 Anaconda 发行版的环境，并查看 Jupyter
    的设置选项。
- en: In both cases, we'll have an interactive Python notebook available through which
    we'll be running most of our experiments.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在这两种情况下，我们将有一个交互式的 Python 笔记本，通过它我们将运行大部分的实验。
- en: Installing libraries with Google Colab
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在 Google Colab 中安装库
- en: Google Colab is a modified version of Jupyter Notebook that runs on Google hardware and provides
    access to runtimes  with hardware acceleration such as TPUs and GPUs.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: Google Colab 是 Jupyter Notebook 的修改版本，在 Google 硬件上运行，并提供访问支持硬件加速（如 TPU 和 GPU）的运行时。
- en: 'The downside of using Colab is that there is a maximum timeout of 12 hours;
    that is, jobs that run longer than 12 hours will stop. If you want to get around that,
    you can do either of the following:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Colab 的缺点是最长运行时间为 12 小时；也就是说，超过 12 小时的作业将停止。如果想要避开这个限制，可以采取以下任一方法：
- en: Run Colab with local kernels. This means you use the Colab interface but the models compute
    on your own  computer ([https://research.google.com/Colaboratory/local-runtimes.html](https://research.google.com/colaboratory/local-runtimes.html)).
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用本地内核运行 Colab。这意味着您使用 Colab 界面，但模型在您自己的计算机上计算（[https://research.google.com/colaboratory/local-runtimes.html](https://research.google.com/colaboratory/local-runtimes.html)）。
- en: Install Jupyter Notebook yourself and don't use Google Colab.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自行安装 Jupyter Notebook，不使用 Google Colab。
- en: For Google Colab, just go to [https://colab.research.google.com/](https://colab.research.google.com/), and
    sign in with your Google credentials. In the following section, we'll deal with
    hosting notebooks on your own machine(s).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 Google Colab，只需访问 [https://colab.research.google.com/](https://colab.research.google.com/)，使用您的
    Google 凭据登录。在接下来的部分，我们将处理在自己的机器上托管笔记本。
- en: 'In Google Colab, you can save and re-load your models to and from the remote
    disk on Google servers. From there you can either download the models to your
    own computer or synchronize with Google Drive. The Colab GUI provides many useful
    code snippets for these use cases. Here''s how to download files from Colab:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在Google Colab中，您可以将模型保存到Google服务器的远程磁盘并重新加载。从那里，您可以将模型下载到自己的计算机或与Google Drive同步。Colab
    GUI为这些用例提供了许多有用的代码片段。以下是如何从Colab下载文件的方法：
- en: '`from joblib import dump`'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '`from joblib import dump`'
- en: '`dump(`'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '`dump(`'
- en: '`     my_model,`'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '`my_model,`'
- en: '`     ''my_model_auc0.84.joblib''`'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '`''my_model_auc0.84.joblib''`'
- en: '`)`'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '`)`'
- en: '`files.download(''my_model_auc0.84.joblib'')`'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '`files.download(''my_model_auc0.84.joblib'')`'
- en: Self-hosting a Jupyter Notebook environment
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 自托管Jupyter Notebook环境
- en: There are different ways to maintain your Python libraries (see [https://packaging.Python.org/tutorials/installing-packages/](https://packaging.python.org/tutorials/installing-packages/)
    for more details). For installations of Jupyter Notebook and all libraries, we recommend the
    Anaconda Python distribution, which works with the `conda` environment manager.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 有不同的方法来维护您的Python库（有关更多详细信息，请参阅[https://packaging.python.org/tutorials/installing-packages/](https://packaging.python.org/tutorials/installing-packages/)）。对于Jupyter
    Notebook和所有库的安装，我们推荐Anaconda Python分发版，它与`conda`环境管理器兼容。
- en: Anaconda is a Python distribution that comes with its own package installer
    and environment manager, called `conda`. This makes it easier to keep your libraries
    up to date and it handles system dependency management as well as Python dependency
    management. We'll mention a few alternatives to Anaconda/conda later; for now,
    we will quickly go through instructions for a local install. In the online material,
    you'll find instructions that will show how to serve similar installations to
    other people across a team, for example, in a company using a dockerized setup,
    which helps manage the setup of a machine or a set of machines across a network
    with a Python environment for AI.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: Anaconda是一个Python发行版，带有自己的包安装程序和环境管理器，称为`conda`。这使得保持你的库更新更容易，它还处理系统依赖性管理以及Python依赖性管理。稍后我们会提到一些Anaconda/conda的替代方案；现在，我们将快速浏览本地安装的说明。在线材料中，您会找到说明如何为团队中的其他人提供类似安装，例如在使用docker化设置的公司中，这有助于管理设置一个或一组机器上的Python环境。
- en: If you have your computer already set up, and you are familiar with `conda`
    and `pip`, please feel free to skip this section.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的计算机已经设置好，并且您熟悉`conda`和`pip`，请随意跳过此部分。
- en: 'For the Anaconda installation, we will need to download an installer and then
    choose a few settings:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 对于Anaconda安装，我们需要下载一个安装程序，然后选择一些设置：
- en: Go to the Anaconda distribution page at [https://www.anaconda.com/products/individual](https://www.anaconda.com/products/individual) and download the
    appropriate installer for Python 3.7 for your system, such as 64-Bit (x86) Installer (506 MB).
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 转到Anaconda分发页面，网址是[https://www.anaconda.com/products/individual](https://www.anaconda.com/products/individual)，下载适合您系统的Python
    3.7的安装程序，例如64位（x86）安装程序（506 MB）。
- en: Anaconda supports Linux, macOS, and Windows installers.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: Anaconda支持Linux、macOS和Windows安装程序。
- en: For macOS and Windows, you also have the choice of a graphical installer. This
    is all well explained in the Anaconda documentation; however, we'll just quickly
    go through the terminal installation.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 对于macOS和Windows，您也可以选择图形安装程序。这在Anaconda文档中都有详细说明；但是，我们将快速浏览终端安装。
- en: 'Execute the downloaded shell script from your terminal:'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从您的终端执行下载的shell脚本：
- en: '[PRE0]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: You need to read and confirm the license agreement. You can do this by pressing
    the spacebar until you see the question asking  you to agree. You need to press
    *Y* and then *Enter*.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要阅读并确认许可协议。你可以通过按下空格键直到看到要求同意的问题。你需要按下*Y*然后按*Enter*。
- en: You can go with the suggested download location or choose a directory that's shared between users
    on your computer.  Once you've done that, you can get yourself a cup of tasty
    coffee or stay to watch the installation of Python and lots of Python libraries.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以选择建议的下载位置或选择在您计算机上共享的目录。完成后，您可以享用美味的咖啡或观看Python和许多Python库的安装。
- en: At the end, you can decide if you want to run the `conda init` routine. This will set up the PATH variables on your
    terminal, so when you type `python`, `pip`, `conda`, or `jupyter`, the conda versions
    will take precedence before any other installed version on your computer.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，您可以决定是否运行 `conda init` 程序。这将在您的终端上设置 PATH 变量，以便在输入 `python`、`pip`、`conda`
    或 `jupyter` 时，conda 版本将优先于计算机上安装的任何其他版本。
- en: 'Note that on Unix/Linux based systems, including macOS, you can always check
    the location of the Python binary you are using as follows:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在基于 Unix/Linux 的系统上，包括 macOS，您始终可以按如下方式检查您正在使用的 Python 二进制文件的位置：
- en: '[PRE1]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: On Windows, you can use the `where.exe` command.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Windows 上，您可以使用 `where.exe` 命令。
- en: 'If you see something like the following, then you know you are using the right
    Python runtime:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 如果看到类似以下内容，则知道您正在使用正确的 Python 运行时：
- en: '[PRE2]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'If you don''t see the correct path, you  might have to run the following:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 如果未看到正确的路径，可能需要运行以下命令：
- en: '[PRE3]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This will set up your environment variables, including `PATH`. On Windows, you'd
    have to check your PATH variable.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这将设置您的环境变量，包括 `PATH`。在 Windows 上，您需要检查您的 PATH 变量。
- en: 'It''s also possible to set up and switch between different environments on
    the same machine. Anaconda comes with Jupyter/iPython by default, so you can start
    your Jupyter notebook from the terminal as follows:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 同一台机器上也可以设置和切换不同的环境。Anaconda 默认带有 Jupyter/iPython，因此您可以通过终端启动 Jupyter 笔记本，如下所示：
- en: '[PRE4]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: You should see the Jupyter Notebook server starting up. As a part of this information,
    a URL for login is printed to the screen.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 当您看到 Jupyter Notebook 服务器启动时，部分信息将打印到屏幕上，包括登录的 URL。
- en: If you run this from a server that you access over the network, make sure you
    use a screen multiplexer such as GNU screen or tmux to make sure your Jupyter
    Notebook client doesn't stop once your terminal gets disconnected.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您从访问的服务器运行此操作，请确保使用 GNU screen 或 tmux 等屏幕复用器，以确保您的 Jupyter Notebook 客户端在终端断开连接后不会停止。
- en: 'We''ll use many libraries in this book such as pandas, NumPy, scikit-learn,
    TensorFlow, Keras, PyTorch, Dash, Matplotlib, and others, so we''ll be installing lots as we go through the recipes. This will often look
    like the following:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本书中使用许多库，如 pandas、NumPy、scikit-learn、TensorFlow、Keras、PyTorch、Dash、Matplotlib
    等，因此在逐步介绍配方时，我们将经常进行安装，通常如下所示：
- en: '[PRE5]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Or, sometimes, like this:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，有时候像这样：
- en: '[PRE6]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: If we use conda's `pip`, or conda directly, this means the libraries will all
    be managed by Anaconda's Python installation.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 如果使用 conda 的 `pip` 或直接使用 conda，这意味着所有库将由 Anaconda 的 Python 安装管理。
- en: 'You can install the aforementioned libraries like this:'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您可以像这样安装前述的库：
- en: '[PRE7]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Please note that for the `tensorflow-gpu` library, you need to have a GPU available
    and ready to use. If not, change this to `tensorflow` (that is, without `-gpu`).
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，对于 `tensorflow-gpu` 库，您需要有可用且准备好使用的 GPU。如果没有，将其更改为 `tensorflow`（即去掉 `-gpu`）。
- en: This should use the `pip` binary that comes with Anaconda and run it to install
    the preceding libraries. Please note that Keras is part of the TensorFlow library.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 这将使用 Anaconda 提供的 `pip` 二进制文件来安装前述库。请注意，Keras 是 TensorFlow 库的一部分。
- en: 'Alternatively, you can run the `conda` package installer as follows:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，您可以如下运行 `conda` 包安装程序：
- en: '[PRE8]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Well done! You've successfully set up your computer for working with the many
    exciting recipes to come.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 干得好！您已成功设置好计算机，准备开始使用即将介绍的许多精彩的配方。
- en: How it works...
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理...
- en: Conda is an environment and package manager. Like many other libraries that
    we will use throughout this book, and like the Python language itself, conda is
    open source, so we can always find out exactly what an algorithm does and easily
    modify it. Conda is also cross-platform and not only supports Python but also
    R and other languages.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: Conda 是一个环境和包管理器。与本书中将使用的许多其他库以及 Python 语言本身一样，conda 是开源的，因此我们总是可以准确了解算法的操作并轻松修改它。Conda
    还是跨平台的，不仅支持 Python，还支持 R 和其他语言。
- en: Package management can present many vexing challenges and, if you've been around
    for some time, you will probably remember spending many hours on issues such as
    conflicting dependencies or re-compiling packages and fixing paths – and you might
    be lucky if it's only that.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 包管理可能会带来许多棘手的挑战，如果您已经使用了一段时间，可能会记得花费许多时间处理诸如冲突依赖关系、重新编译包和修复路径等问题 —— 如果只是这些问题的话，您可能算是幸运的。
- en: Conda goes beyond the earlier `pip` package manager (see [https://pip.pypa.io/en/stable/](https://pip.pypa.io/en/stable/)) in
    that it checks dependencies of all packages installed within the environment and
    tries to come up with a way to resolve all the requirements. It also not only
    installs packages, but also allows us to set up environments that have separate
    installations of Python and binaries from different software repositories such
    as Bioconda ([https://bioconda.github.io/](https://bioconda.github.io/)), which
    specializes in bioinformatics, or the Anaconda repositories ([https://anaconda.org/anaconda/repo](https://anaconda.org/anaconda/repo)).
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: Conda 不仅仅是之前的 `pip` 包管理器（参见 [https://pip.pypa.io/en/stable/](https://pip.pypa.io/en/stable/)），它还检查环境中所有安装的包的依赖关系，并尝试找出解决所有要求的方法。它不仅安装包，还允许我们设置具有来自不同软件仓库的
    Python 和二进制文件的环境，如 Bioconda（[https://bioconda.github.io/](https://bioconda.github.io/)，专门用于生物信息学）或
    Anaconda 仓库（[https://anaconda.org/anaconda/repo](https://anaconda.org/anaconda/repo)）。
- en: There are hundreds of dedicated channels that you can use with conda. These
    are sub-repositories that can contain hundreds or thousands of different packages.
    Some of them are maintained by companies that develop specific libraries or software.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 有数百个专门的渠道可以与 conda 一起使用。这些是包含数百甚至数千种不同包的子仓库。其中一些由开发特定库或软件的公司维护。
- en: 'For example, you can install the `pytorch` package from the PyTorch channel
    as follows:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，您可以按如下方式从 PyTorch 渠道安装 `pytorch` 包：
- en: '[PRE9]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: It's tempting to enable many channels in order to get the bleeding edge technology
    for everything. There's one catch, however, with this. If you enable many channels,
    or channels that are very big, conda's dependency resolution can become very slow.
    So be careful with using many additional channels, especially if they contain
    a lot of libraries.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然尝试启用许多渠道以获取所有领域的最新技术是非常诱人的。然而，这里有一个要注意的地方。如果您启用了许多渠道，或者是非常大的渠道，conda 的依赖解析可能会变得非常慢。因此，在使用许多额外的渠道时要小心，特别是如果它们包含大量的库。
- en: There's more...
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多内容……
- en: 'There are a number of Jupyter options you should probably be familiar with. These are
    in the file at `$HOME/.jupyter/jupyter_notebook_config.py`. If you don''t have
    the file yet, you can create it using this command:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能应该熟悉一些 Jupyter 的选项。这些选项在文件 `$HOME/.jupyter/jupyter_notebook_config.py` 中。如果您还没有这个文件，可以使用以下命令创建它：
- en: '[PRE10]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Here is an example configuration for `/home/ben/.jupyter/jupyter_notebook_config.py`:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是 `/home/ben/.jupyter/jupyter_notebook_config.py` 的一个示例配置：
- en: '[PRE11]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: If you install your Python environment on a server that you want to access from
    your laptop (I have my local compute server in the attic), you'd first want make sure you
    can access the compute server remotely from another computer such as a laptop
    (`c.NotebookApp.ip = '*'`).
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您将 Python 环境安装在希望从笔记本电脑访问的服务器上（我把我的本地计算服务器放在了阁楼上），您首先需要确保可以从其他计算机（如笔记本电脑）远程访问计算服务器（`c.NotebookApp.ip
    = '*'`）。
- en: Then we create a random password and configure it.  We disable the option to
    have the browser open when we run Jupyter Notebook, and we then set the default port to `8888`.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们创建一个随机密码并进行配置。我们禁用在运行 Jupyter Notebook 时自动打开浏览器的选项，然后将默认端口设置为 `8888`。
- en: 'So Jupyter Notebook will be available when you open `localhost:8888` in a browser
    on the same computer. If you are in a team as part of a larger organization, you''d be mostly working on remote number-crunching
    machines, and as a convenience, you – or your sysadmins – can set up a hosted
    Jupyter Notebook environment. This has several advantages:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，当您在浏览器中打开 `localhost:8888` 时，Jupyter Notebook 将可用。如果您作为较大组织中的团队一部分，大部分时间都在远程数值计算机上工作，那么为了方便起见，您或者您的系统管理员可以设置托管的
    Jupyter Notebook 环境。这有几个优点：
- en: You can use the resources of a powerful server while simply accessing it through your browser.
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可以通过浏览器简单地访问强大服务器的资源。
- en: You can manage your packages in a contained environment on that server, while not affecting the server itself.
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可以在该服务器上的封闭环境中管理您的包，而不会影响服务器本身。
- en: You'll find yourself interacting with Jupyter Notebook's familiar REPL, which allows you to quickly test ideas and prototype projects.
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您将发现自己正在与 Jupyter Notebook 熟悉的 REPL 交互，它允许您快速测试想法和原型项目。
- en: If you are a single person, you don't need this; however, if you work in a team,
    you can put each person into a contained environment using either Docker or JupyterHub.
    Online, you'll find setup instructions for setting up a Jupyter environment with
    Docker.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你是单独工作，你不需要这个工具；但是，如果你在团队中工作，你可以使用Docker或JupyterHub将每个人放入独立的环境中。在线上，你可以找到设置Jupyter环境与Docker的设置指南。
- en: See also
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参阅
- en: 'You can read up more on conda, Docker, JupyterHub, and other related tools
    on their respective documentation sites, as follows:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在以下各自的文档站点上阅读更多关于conda、Docker、JupyterHub及其他相关工具的信息：
- en: The conda documentation: [https://docs.conda.io/en/latest/](https://docs.conda.io/en/latest/)
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: conda文档：[https://docs.conda.io/en/latest/](https://docs.conda.io/en/latest/)
- en: The Docker documentation: [https://docs.docker.com/](https://docs.docker.com/)
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker文档：[https://docs.docker.com/](https://docs.docker.com/)
- en: JupyterHub: [https://jupyterhub.readthedocs.io/en/stable/](https://jupyterhub.readthedocs.io/en/stable/)
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: JupyterHub：[https://jupyterhub.readthedocs.io/en/stable/](https://jupyterhub.readthedocs.io/en/stable/)
- en: Jupyter: [https://jupyter.org/](https://jupyter.org/)
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jupyter：[https://jupyter.org/](https://jupyter.org/)
- en: JupyterLab: [https://jupyterlab.readthedocs.io/en/stable/](https://jupyterlab.readthedocs.io/en/stable/)
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: JupyterLab：[https://jupyterlab.readthedocs.io/en/stable/](https://jupyterlab.readthedocs.io/en/stable/)
- en: PyCharm: [https://www.jetbrains.com/pycharm/](https://www.jetbrains.com/pycharm/)
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PyCharm：[https://www.jetbrains.com/pycharm/](https://www.jetbrains.com/pycharm/)
- en: Colab: [https://Colab.research.google.com](https://colab.research.google.com)
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Colab：[https://Colab.research.google.com](https://colab.research.google.com)
- en: Pipenv: [https://pipenv-fork.readthedocs.io/en/latest/](https://pipenv-fork.readthedocs.io/en/latest/)
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pipenv: [https://pipenv-fork.readthedocs.io/en/latest/](https://pipenv-fork.readthedocs.io/en/latest/)
- en: Pip: [https://pip.pypa.io/en/stable/](https://pip.pypa.io/en/stable/)
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pip：[https://pip.pypa.io/en/stable/](https://pip.pypa.io/en/stable/)
- en: Getting proficient in Python for AI
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Python AI方面提高技能
- en: In this set of quick-fire recipes, we'll look at ways to become more productive
    in Jupyter and to write more efficient Python code. If you are not familiar with
    Jupyter Notebook, please read a tutorial and then come back here. You can find
    a well-written tutorial at [https://realPython.com/jupyter-notebook-introduction/](https://realpython.com/jupyter-notebook-introduction/). In
    the following recipe, we'll assume you have some familiarity with Jupyter Notebook.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在这组快速操作的示例中，我们将看看如何在Jupyter中变得更加高效，并编写更有效率的Python代码。如果你对Jupyter Notebook不熟悉，请先阅读一篇教程，然后再回到这里。你可以在[https://realPython.com/jupyter-notebook-introduction/](https://realpython.com/jupyter-notebook-introduction/)找到一篇写得很好的教程。在接下来的示例中，我们假设你对Jupyter
    Notebook有一定的了解。
- en: Let's look at some simple but very handy tricks to make working in notebooks
    more comfortable and efficient. These are applicable whether you are relying on a local or
    hosted Python environment.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看一些简单但非常实用的技巧，使在笔记本中工作更加舒适和高效。这些技巧适用于无论你是在本地环境还是托管的Python环境中工作。
- en: In this recipe, we'll look at a lot of different things that can help you become
    more productive when you are working in your notebook and writing Python code
    for AI solutions. Some of the built-in or externally available magic commands or extensions can also come in handy
    (see [https://iPython.readthedocs.io/en/stable/interactive/magics.html](https://ipython.readthedocs.io/en/stable/interactive/magics.html)
    for more details).
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将探讨在你的笔记本中工作并为AI解决方案编写Python代码时，可以帮助你提高效率的各种技巧。一些内置或外部可用的魔术命令或扩展也可能会派上用场（详细信息请参阅[https://iPython.readthedocs.io/en/stable/interactive/magics.html](https://ipython.readthedocs.io/en/stable/interactive/magics.html)）。
- en: It's important to be aware of some of the Python efficiency hacks when it comes
    to machine learning, especially when working with some of the bigger datasets
    or more complex algorithms. Sometimes, your jobs can take very long to run, but
    often there are ways around it. For example, one, often relatively easy, way of
    finishing a job faster is to use parallelism.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及到机器学习时，尤其是处理较大数据集或更复杂算法时，了解一些Python的效率技巧非常重要。有时，你的任务可能需要很长时间才能完成，但通常有解决的办法。例如，加速完成任务的一个相对容易的方法是使用并行处理。
- en: 'The following short recipes cover the following:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 以下简短的示例涵盖了以下内容：
- en: Obtaining the Jupyter command history
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取Jupyter命令历史记录
- en: Auto-reloading packages
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动重新加载包
- en: Debugging
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调试
- en: Timing code execution
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计时代码执行时间
- en: Compiling your code
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编译你的代码
- en: Speeding up pandas DataFrames
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加速pandas DataFrames
- en: Displaying progress bars
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 显示进度条
- en: Parallelizing your code
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并行化你的代码
- en: Getting ready
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: If you are using your own installation, whether directly on your system or inside
    a Docker environment, make sure that it's running. Then put the address of your
    Colab or Jupyter Notebook instance into your browser and press *Enter*.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您使用自己的安装，无论是直接在您的系统上还是在Docker环境中，都要确保它正在运行。然后将您的Colab或Jupyter笔记本实例的地址放入浏览器中，然后按下*Enter*键。
- en: 'We will be using the following libraries:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用以下库：
- en: '`tqdm` for progress bars'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`tqdm`来显示进度条
- en: '`swifter` for quicker pandas processing'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`swifter`来加快pandas的处理速度
- en: '`ray` and `joblib` for multiprocessing'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`ray`和`joblib`进行多进程处理
- en: '`numba` for **just-in-time** (**JIT**) compilation'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`numba`进行即时编译（JIT）
- en: '`jax` (later on in this section) for array processing with autograd'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`jax`（稍后在本节中）进行带有自动微分的数组处理
- en: '`cython` for compiling Cython extensions in the notebook'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`cython`在笔记本中编译Cython扩展
- en: 'We can install them with `pip` as before:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以像之前一样使用`pip`来安装它们：
- en: '[PRE12]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: With that done, let's get to some efficiency hacks that make working in Jupyter
    faster and more convenient.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 完成这些后，让我们来看看一些提高在Jupyter中工作效率的技巧。
- en: How to do it...
  id: totrans-134
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 怎么做...
- en: The sub-recipes here are short and sweet, and all provide ways to be more productive
    in Jupyter and Python.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的小贴士简洁明了，都提供了在Jupyter和Python中提高生产力的方法。
- en: If not indicated otherwise, all of the code needs to be run in a notebook, or,
    more precisely, in a notebook cell.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 如果没有特别说明，所有的代码都需要在笔记本中运行，或者更准确地说，在一个笔记本单元格中。
- en: Let's get to these little recipes!
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看这些小贴士吧！
- en: Obtaining the history of Jupyter commands and outputs
  id: totrans-138
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 获取Jupyter命令和输出的历史记录
- en: There are lots of different ways to obtain the code in Jupyter cells programmatically.
    Apart from these inputs, you can also look at the generated outputs. We'll get
    to both, and we can use global variables for this purpose.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在Jupyter单元格中，有很多不同的方式可以通过程序来获取代码。除了这些输入之外，还可以查看生成的输出。我们将介绍这两个方面，并可以使用全局变量来实现。
- en: Execution history
  id: totrans-140
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 执行历史记录
- en: 'In order to get the execution history of your cells, the `_ih` list holds the code of executed cells. In
    order to get the complete execution history and write it to a file, you can do
    the following:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获取您的单元格执行历史记录，`_ih`列表保存了已执行单元格的代码。要获取完整的执行历史记录并将其写入文件，可以按以下步骤操作：
- en: '[PRE13]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'If up to this point, we only ran a single cell consisting of `print(''hello,
    world!'')`, that''s exactly what we should see in our newly created file, `command_history.py`:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 如果到目前为止，我们只运行了一个单元格，其中包含`print('hello, world!')`，那么在我们新创建的文件`command_history.py`中正好会看到这样的内容：
- en: '[PRE14]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: On Windows, to print the content of a file, you can use the `type` command.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在Windows上，要打印文件的内容，可以使用`type`命令。
- en: Instead of `_ih`, we can use a shorthand for the content of the last three cells.
    `_i` gives you the code of the cell that just executed, `_ii` is used for the
    code of the cell executed before that, and `_iii` for the one before that.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`_ih`的简写来代替最近三个单元格的内容。 `_i`表示刚刚执行的单元格的代码，`_ii`表示上一个执行的单元格的代码，而`_iii`则表示再上一个。
- en: Outputs
  id: totrans-147
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 输出
- en: In order to get recent outputs, you can use `_` (single underscore), `__` (double
    underscore), and `___` (triple underscore), respectively, for the most recent,
    second, and third most recent outputs.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获取最近的输出，可以使用`_`（单个下划线）、`__`（双下划线）和`___`（三个下划线），分别对应最近的、第二个和第三个最近的输出。
- en: Auto-reloading packages
  id: totrans-149
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 自动重新加载包
- en: '`autoreload` is a built-in extension that reloads the module when you make
    changes to a module on disk. It will automagically reload the module once you''ve saved it.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '`autoreload`是一个内置扩展，当您对磁盘上的模块进行更改时会重新加载该模块。一旦您保存了模块，它就会自动重新加载模块。'
- en: Instead of manually reloading your package or restarting the notebook, with
    `autoreload`, the only thing you have to do is to load and enable the extension,
    and it will do its magic.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 不需要手动重新加载您的包或重新启动笔记本，使用`autoreload`，您只需要加载并启用该扩展，它将自动完成其工作。
- en: 'We first load the extension as follows:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先加载扩展，如下所示：
- en: '[PRE15]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'And then we enable it as follows:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们按如下方式启用它：
- en: '[PRE16]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: This can save a lot of time when you are developing (and testing) a library
    or module.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 在开发（和测试）库或模块时，这可以节省大量时间。
- en: Debugging
  id: totrans-157
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 调试
- en: 'If you cannot spot an error and the traceback of the error is not enough to find the problem, debugging can speed up
    the error-searching process a lot. Let''s have a quick look at the debug magic:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您找不到错误并且错误的回溯信息不足以找到问题，调试可以大大加快错误搜索过程。让我们快速看一下调试魔法：
- en: 'Put the following code into a cell:'
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将以下代码放入一个单元格中：
- en: '[PRE17]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: You should see `5.0` as the cell output.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该看到单元格输出为`5.0`。
- en: However, there's an error in the function, and I am sure the attentive reader
    will already have spotted it. Let's debug!
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在函数中有一个错误，我相信细心的读者已经注意到了。让我们进行调试！
- en: 'Put this into a new cell:'
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将这段代码放入新的单元格中：
- en: '[PRE18]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Execute the cell by pressing *Ctrl* + *Enter* or *Alt* + *Enter*. You will
    get a debug prompt:'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过按下*Ctrl* + *Enter*或*Alt* + *Enter*执行该单元格。您将会得到一个调试提示：
- en: '[PRE19]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: We've used the argument command to print out the arguments of the executed function,
    and then we quit the debugger with the `quit` command. You can find more commands
    on **The Python Debugger** (**pdb**) documentation page at [https://docs.Python.org/3/library/pdb.html](https://docs.python.org/3/library/pdb.html).
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经使用参数命令打印出执行函数的参数，然后使用`quit`命令退出调试器。您可以在**Python调试器**（**pdb**）文档页面上找到更多命令，网址是[https://docs.Python.org/3/library/pdb.html](https://docs.python.org/3/library/pdb.html)。
- en: Let's look at a few more useful magic commands.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看几个更有用的魔术命令。
- en: Timing code execution
  id: totrans-169
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 代码执行计时
- en: Once your code does what it's supposed to, you often get into squeezing every
    bit of performance out of your models or algorithms. For this, you'll check execution
    times and create benchmarks using them. Let's see how to time executions.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您的代码按预期运行，通常会开始尽可能提高模型或算法的性能。为此，您将检查执行时间并使用它们创建基准测试。让我们看看如何计时执行。
- en: 'There is a built-in magic command for timing cell execution – `timeit`. The
    `timeit` functionality is part of the Python standard library ([https://docs.Python.org/3/library/timeit.html](https://docs.python.org/3/library/timeit.html)).
    It runs a command 10,000 times (by default) in a period of 5 times inside a loop
    (by default) and shows an average execution time as a result:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 有一个内置的计时单元执行的魔术命令 - `timeit`。`timeit`功能是Python标准库的一部分（网址是[https://docs.Python.org/3/library/timeit.html](https://docs.python.org/3/library/timeit.html)）。它默认在一个循环内运行一条命令10,000次，并显示平均执行时间：
- en: '[PRE20]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'We see the following output:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到以下输出：
- en: '[PRE21]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The `iPython-autotime` library ([https://github.com/cpcloud/iPython-autotime](https://github.com/cpcloud/ipython-autotime)) is an external extension
    that provides you the  timings for all the cells that execute, rather than having
    to use `%%timeit` every time:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '`iPython-autotime`库（网址是[https://github.com/cpcloud/iPython-autotime](https://github.com/cpcloud/ipython-autotime)）是一个外部扩展，为执行的所有单元格提供时间，而不是每次都使用`%%timeit`：'
- en: 'Install `autotime` as follows:'
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装`autotime`如下所示：
- en: '[PRE22]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Please note that this syntax works for Colab, but not in standard Jupyter Notebook.
    What always works to install libraries is using the `pip` or `conda` magic commands, `%pip` and `%conda`, respectively.
    Also, you can  execute any  shell command from the notebook if you start your line with an exclamation mark, like this:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这种语法适用于Colab，但不适用于标准的Jupyter Notebook。安装库的永远有效的方法是使用`pip`或`conda`的魔术命令，分别是`%pip`和`%conda`。此外，如果您在行首使用感叹号，如下所示，还可以从笔记本中执行任何shell命令：
- en: '[PRE23]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Now let''s use it, as follows:'
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在让我们按如下方式使用它：
- en: '[PRE24]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Test how long a simple list comprehension takes with the following command:'
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令测试简单列表理解所需的时间：
- en: '[PRE25]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'We''ll see this output: `time: 5.62 ms`.'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '我们将看到这个输出：`time: 5.62 ms`。'
- en: Hopefully, you can see how this can come in handy for comparing different implementations.
    Especially in situations where you have a lot of data, or complex processing,
    this can be very useful.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 希望您能看到这在比较不同实现时有多有用。特别是在处理大量数据或复杂处理的情况下，这非常有用。
- en: Displaying progress bars
  id: totrans-186
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 显示进度条
- en: 'Even if your code is optimized, it''s good to know if it''s going to finish
    in minutes, hours, or days. `tqdm` provides progress bars with time estimates.
    If you aren''t sure how long your job will run, it''s just one letter away – in
    many cases, it''s just a matter of changing `range` for `trange`:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 即使您的代码已经优化，知道它将在几分钟、几小时或几天内完成也是很好的。`tqdm`提供带有时间估计的进度条。如果您不确定作业将运行多长时间，这只是一步之遥
    - 在许多情况下，只需将`range`替换为`trange`即可：
- en: '[PRE26]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: The `tqdm` pandas integration (optional) means that you can see progress bars
    for pandas `apply` operations. Just swap `apply` for `progress_apply`.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '`tqdm` pandas集成（可选）意味着您可以看到pandas `apply`操作的进度条。只需将`apply`替换为`progress_apply`。'
- en: For Python loops just wrap your loop with a `tqdm` function and voila, there'll
    be a progress bar and time estimates for your loop completion!
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 对于Python循环，只需用`tqdm`函数包装您的循环，完成时将显示进度条和时间估计！
- en: '[PRE27]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Tqdm provides different ways to do this, and they all require minimal code
    changes - sometimes as little as one letter, as you can see in the previous example.
    The more general syntax is wrapping your loop iterator with `tqdm` like this:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: tqdm 提供了不同的方法来实现这一点，它们都需要最小的代码更改 - 有时仅仅是一个字母，正如您在前面的例子中所看到的。更通用的语法是像这样将您的循环迭代器用
    `tqdm` 包装起来：
- en: '[PRE28]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'You should see a progress bar like in this screenshot:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该看到类似以下截图的进度条：
- en: '![](img/2299dce8-af59-48c8-8528-ab2a4c777965.png)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2299dce8-af59-48c8-8528-ab2a4c777965.png)'
- en: So, next time you are just about to set off long-running loop, and you are not
    just sure how long it will take, just remember this sub-recipe, and use `tqdm`.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，下次当您即将启动长时间运行的循环时，而且您不确定它将花费多长时间时，只需记住这个子方法，并使用 `tqdm`。
- en: Compiling your code
  id: totrans-197
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 编译您的代码
- en: Python is an interpreted language, which is a great advantage for experimenting,
    but it can be detrimental to speed. There are different ways to compile your Python
    code, or to use compiled code from Python.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: Python 是一种解释性语言，这对于进行实验是一个很大的优势，但对速度可能是不利的。有不同的方法来编译您的 Python 代码，或者使用从 Python
    编译的代码。
- en: 'Let''s first look at Cython. Cython is an optimizing static compiler for Python,
    and the programming language compiled by the Cython compiler. The main idea is
    to write code in a language very similar to Python, and generate C code. This
    C code can then be compiled as a binary Python extension. SciPy (and NumPy), scikit-learn,
    and many other libraries have significant parts written in Cython for speed up.
    You can find out more about Cython on its website at [https://cython.org/](https://cython.org/):'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先看看 Cython。Cython 是一个用于 Python 的优化静态编译器，通过 Cython 编译器编译的编程语言。其主要思想是用一种非常类似
    Python 的语言编写代码，并生成 C 代码。这些 C 代码可以编译为二进制 Python 扩展。SciPy（和 NumPy）、scikit-learn
    等许多库的重要部分都使用 Cython 编写以加速。您可以在其网站 [https://cython.org/](https://cython.org/) 上了解更多关于
    Cython 的信息：
- en: 'You can use the `Cython` extension for building cython functions in your notebook:'
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您可以在笔记本中使用 `Cython` 扩展来构建 Cython 函数：
- en: '[PRE29]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'After loading the extension, annotate your cell as follows:'
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载扩展后，将您的单元格标记如下：
- en: '[PRE30]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'We can call this function just like any Python function – with the added benefit
    that it''s already compiled:'
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以像调用任何 Python 函数一样调用这个函数 - 而且它已经编译好了，这是额外的好处：
- en: '[PRE31]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: This is perhaps not the most useful example of compiling code. For such a small
    function, the overhead of compilation is too big. You would probably want to compile
    something that's a bit more complex.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能不是编译代码最有用的例子。对于这样一个小函数，编译的开销太大了。您可能希望编译一些更复杂的内容。
- en: 'Numba is a JIT compiler for Python ([https://numba.pydata.org/](https://numba.pydata.org/)).
    You can often get a speed-up similar to C or Cython using `numba` and writing idiomatic Python code
    like the following:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: Numba 是一个用于 Python 的 JIT 编译器（[https://numba.pydata.org/](https://numba.pydata.org/)）。您可以通过使用
    `numba` 并编写符合 Python 习惯的代码，通常获得类似于 C 或 Cython 的加速：
- en: '[PRE32]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'With `autotime` activated, you should see something like this:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `autotime` 激活后，您应该看到类似以下的输出：
- en: '[PRE33]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'So again, the overhead of the compilation is too big to make a meaningful impact. Of course, we''d only see the
    benefit if it''s offset against the compilation. However, if we use this function
    again, we should see a speedup. Try it out yourself! Once the code is already compiled, the time significantly improves:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，再次编译的开销对于产生有意义的影响来说太大了。当然，我们只有在与编译相抵消时才能看到其好处。然而，如果我们再次使用这个函数，应该会看到加速。您可以自行尝试！一旦代码已经编译，时间显著改善：
- en: '[PRE34]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'You should see something like this:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该看到类似以下的输出：
- en: '[PRE35]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: There are other libraries that provide JIT compilation including TensorFlow,
    PyTorch, and JAX, that can help you get similar benefits.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 还有其他提供 JIT 编译的库，包括 TensorFlow、PyTorch 和 JAX，这些都可以帮助您获得类似的好处。
- en: 'The following example comes directly from the JAX documentation, at [https://jax.readthedocs.io/en/latest/index.html](https://jax.readthedocs.io/en/latest/index.html):'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的例子直接来自 JAX 文档，网址为 [https://jax.readthedocs.io/en/latest/index.html](https://jax.readthedocs.io/en/latest/index.html)：
- en: '[PRE36]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: So there are different ways to get speed benefits from using JIT or ahead-of-time
    compilation. We'll see some other ways of speeding up your code in the following
    sections.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，有不同的方法可以通过使用 JIT 或预编译来获得速度优势。我们将在接下来的部分看到一些加快代码速度的其他方法。
- en: Speeding up pandas DataFrames
  id: totrans-219
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 加速 pandas 的 DataFrames
- en: One of the most important libraries throughout this book will be `pandas`, a
    library for tabular data that's useful for **Extract**, **Transform**, **Load**
    (**ETL**) jobs. Pandas is a wonderful library, however; once you get to more demanding
    tasks, you'll hit some of its limitations. Pandas is the go-to library for loading
    and transforming data. One problem with data processing is that it can be slow,
    even if you vectorize the function or if you use `df.apply()`.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中最重要的库之一将是`pandas`，一个用于表格数据的库，非常适用于**提取**、**转换**、**加载**（**ETL**）任务。Pandas是一个很棒的库，但是一旦涉及到更复杂的任务，您可能会遇到一些限制。Pandas是处理数据加载和转换的首选库。数据处理的一个问题是，即使您向量化函数或使用`df.apply()`，它也可能速度较慢。
- en: 'You can move further by parallelizing `apply`. Some libraries, such as `swifter`,
    can help you by choosing backends for computations for you, or you can make the
    choice yourself:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 通过并行化`apply`可以进一步提升效率。某些库，如`swifter`，可以通过为您选择计算后端来帮助您，或者您可以自行选择：
- en: You can use Dask DataFrames instead of pandas if you want to run on multiple
    cores of the same or several machines over a network.
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果您希望在同一台或多台机器上的多个核心上运行，可以使用Dask DataFrames代替pandas在网络上运行。
- en: You can use CuPy or cuDF if you want to run computations on the GPU instead
    of the CPU. These have stable integrations with Dask, so you can run both on multiple
    cores and multiple GPUs, and you can still rely on a pandas-like syntax (see [https://docs.dask.org/en/latest/gpu.html](https://docs.dask.org/en/latest/gpu.html)).
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果您希望在GPU上而不是CPU上运行计算，可以使用CuPy或cuDF。它们与Dask稳定集成，因此可以在多核和多GPU上运行，并且仍然可以依赖于类似pandas的语法（参见[https://docs.dask.org/en/latest/gpu.html](https://docs.dask.org/en/latest/gpu.html)）。
- en: 'As we''ve mentioned, `swifter` can choose a backend for you with no change
    of syntax. Here is a quick setup for using `pandas` with `swifter`:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所提到的，`swifter`可以为您选择后端，而不改变语法。这里是使用`pandas`与`swifter`的快速设置：
- en: '[PRE37]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Generally, `apply()` is much faster than looping over DataFrames.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，`apply()`要比循环DataFrame快得多。
- en: 'You can further improve the speed of execution by using the underlying NumPy arrays
    directly and accessing NumPy functions, for example, using `df.values.apply()`.
    NumPy vectorization can be a breeze, really. See the following example of applying
    a NumPy vectorization on a pandas DataFrame column:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 通过直接使用底层的NumPy数组并访问NumPy函数，例如使用`df.values.apply()`，您可以进一步提高执行速度。NumPy向量化真是太方便了。以下是在pandas
    DataFrame列上应用NumPy向量化的示例：
- en: '[PRE38]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: These are just two ways, but if you look at the next sub-recipe, you should
    be able to write a parallel map function as yet another alternative.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 这只是两种方法之一，但如果您查看下一个子配方，应该能够编写并行映射函数作为另一种选择。
- en: Parallelizing your code
  id: totrans-230
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 并行化您的代码
- en: One way to get something done more quickly is to do multiple things at once.
    There are different ways to implement your routines or algorithms with parallelism.
    Python has a lot of libraries that support this functionality. Let's see a few
    examples with multiprocessing, Ray, joblib, and how to make use of scikit-learn's
    parallelism.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 要更快地完成某些事情，一种方法是同时做多件事情。有不同的方法可以使用并行处理来实现您的例程或算法。Python有许多支持此功能的库。让我们看看使用multiprocessing、Ray、joblib的几个示例，以及如何利用scikit-learn的并行处理。
- en: 'The multiprocessing library comes as part of Python''s standard library. Let''s
    look at it first. We don''t provide a dataset of millions of points here – the
    point is to show a usage pattern – however, please imagine a large dataset. Here''s
    a code snippet of using our pseudo-dataset:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: multiprocessing库作为Python标准库的一部分。让我们首先来看一下它。我们这里没有提供数百万点的数据集 – 关键是展示一个使用模式 –
    不过，请想象一个大数据集。以下是使用我们的伪数据集的代码片段：
- en: '[PRE39]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Using Ray, you can parallelize over multiple machines in addition to multiple
    cores, leaving your code virtually unchanged. Ray efficiently handles data through
    shared memory (and zero-copy serialization) and uses a distributed task scheduler
    with fault tolerance:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Ray，除了多核心，还可以在多台机器上并行化，几乎不需要更改代码。Ray通过共享内存（和零拷贝序列化）高效处理数据，并使用具有容错性的分布式任务调度器：
- en: '[PRE40]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Scikit-learn, the machine learning library we installed earlier, internally
    uses `joblib` for parallelization. The following is an example of this:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: Scikit-learn，我们之前安装的机器学习库，内部使用`joblib`进行并行化。以下是一个例子：
- en: '[PRE41]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: This would give you `[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]`. We
    took this example from the `joblib` examples about parallel for loops, available
    at [https://joblib.readthedocs.io/en/latest/parallel.html](https://joblib.readthedocs.io/en/latest/parallel.html).
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 这将给您 `[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]`。我们从 `joblib` 并行循环示例中获取此示例，详细信息请参阅
    [https://joblib.readthedocs.io/en/latest/parallel.html](https://joblib.readthedocs.io/en/latest/parallel.html)。
- en: When using scikit-learn, watch out for functions that have an `n_jobs` parameter.
    This parameter is directly handed over to `joblib.Parallel` ([https://github.com/joblib/joblib/blob/master/joblib/parallel.py](https://github.com/joblib/joblib/blob/master/joblib/parallel.py)).
    `none` (the default setting) means sequential execution, in other words, no parallelism.
    So if you want to execute code in parallel, make sure to set this `n_jobs` parameter,
    for example, to `-1` in order to make full use of all your CPUs.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 scikit-learn 时，请注意具有 `n_jobs` 参数的函数。此参数直接传递给 `joblib.Parallel` ([https://github.com/joblib/joblib/blob/master/joblib/parallel.py](https://github.com/joblib/joblib/blob/master/joblib/parallel.py))。`none`（默认设置）意味着顺序执行，换句话说，没有并行化。因此，如果要并行执行代码，请务必设置此
    `n_jobs` 参数，例如将其设置为 `-1`，以充分利用所有 CPU。
- en: PyTorch and Keras both support multi-GPU and multi-CPU execution. Multi-core
    parallelization is done by default. Multi-machine execution in Keras is getting
    easier from release to release with TensorFlow as the default backend.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch 和 Keras 都支持多 GPU 和多 CPU 执行。多核并行化是默认的。Keras 中的多机执行在每个 TensorFlow 发布中都变得更加容易作为默认后端。
- en: See also
  id: totrans-241
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参阅
- en: While notebooks are convenient, they are often messy, not conducive to good coding habits, and they cannot be versioned
    cleanly. Fastai has developed an extension for literate code development in notebooks called nbdev
    ([https://github.com/fastai/nbdev](https://github.com/fastai/nbdev)), which provides tools for exporting and documenting code.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然笔记本很方便，但通常很混乱，不利于良好的编码习惯，并且无法干净地进行版本控制。Fastai 开发了一个称为 nbdev 的笔记本文学代码开发扩展（[https://github.com/fastai/nbdev](https://github.com/fastai/nbdev)），提供了导出和文档化代码的工具。
- en: 'There are a lot more useful extensions that you can find in different places:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 还有很多有用的扩展可以在不同的地方找到：
- en: 'The extension index: [https://github.com/iPython/iPython/wiki/Extensions-Index](https://github.com/ipython/ipython/wiki/Extensions-Index)'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 扩展索引：[https://github.com/iPython/iPython/wiki/Extensions-Index](https://github.com/ipython/ipython/wiki/Extensions-Index)
- en: Jupyter contrib extensions: [https://jupyter-contrib-nbextensions.readthedocs.io/en/latest/nbextensions.html](https://jupyter-contrib-nbextensions.readthedocs.io/en/latest/nbextensions.html)
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jupyter contrib 扩展：[https://jupyter-contrib-nbextensions.readthedocs.io/en/latest/nbextensions.html](https://jupyter-contrib-nbextensions.readthedocs.io/en/latest/nbextensions.html)
- en: The awesome-jupyter list: [https://github.com/markusschanta/awesome-jupyter](https://github.com/markusschanta/awesome-jupyter)
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: The awesome-jupyter 列表：[https://github.com/markusschanta/awesome-jupyter](https://github.com/markusschanta/awesome-jupyter)
- en: 'We would also like to highlight the following extensions:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还想强调以下扩展：
- en: SQL Magic, which performs SQL queries: [https://github.com/catherinedevlin/iPython-sql](https://github.com/catherinedevlin/ipython-sql)
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SQL Magic，执行 SQL 查询的工具：[https://github.com/catherinedevlin/iPython-sql](https://github.com/catherinedevlin/ipython-sql)
- en: Watermark, which extracts version information for used packages: [https://github.com/rasbt/watermark](https://github.com/rasbt/watermark)
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Watermark，用于提取所用包的版本信息：[https://github.com/rasbt/watermark](https://github.com/rasbt/watermark)
- en: Pyheatmagic, for profiling with heat maps: [https://github.com/csurfer/pyheatmagic](https://github.com/csurfer/pyheatmagic)
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pyheatmagic，用于使用热图进行性能分析：[https://github.com/csurfer/pyheatmagic](https://github.com/csurfer/pyheatmagic)
- en: Nose testing, for testing using nose: [https://github.com/taavi/iPython_nose](https://github.com/taavi/ipython_nose)
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nose 测试，用于使用 nose 进行测试：[https://github.com/taavi/iPython_nose](https://github.com/taavi/ipython_nose)
- en: Pytest magic, for testing using pytest: [https://github.com/cjdrake/iPython-magic](https://github.com/cjdrake/ipython-magic)
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pytest 魔法，用于使用 pytest 进行测试：[https://github.com/cjdrake/iPython-magic](https://github.com/cjdrake/ipython-magic)
- en: Dot and others, used for drawing diagrams using graphviz: [https://github.com/cjdrake/iPython-magic](https://github.com/cjdrake/ipython-magic)
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dot 和其他工具，用于使用 graphviz 绘制图表：[https://github.com/cjdrake/iPython-magic](https://github.com/cjdrake/ipython-magic)
- en: Scalene, a CPU and memory profiler: [https://github.com/emeryberger/scalene](https://github.com/emeryberger/scalene)
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Scalene，一个 CPU 和内存分析器：[https://github.com/emeryberger/scalene](https://github.com/emeryberger/scalene)
- en: 'Some other libraries used or mentioned in this recipe include the following:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 本配方中使用或提到的其他库包括以下内容：
- en: '`Swifter`: [https://github.com/jmcarpenter2/swifter](https://github.com/jmcarpenter2/swifter)'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Swifter`: [https://github.com/jmcarpenter2/swifter](https://github.com/jmcarpenter2/swifter)'
- en: '`Autoreload`: [https://iPython.org/iPython-doc/3/config/extensions/autoreload.html](https://ipython.org/ipython-doc/3/config/extensions/autoreload.html)'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Autoreload`: [https://iPython.org/iPython-doc/3/config/extensions/autoreload.html](https://ipython.org/ipython-doc/3/config/extensions/autoreload.html)'
- en: '`pdb`: [https://docs.Python.org/3/library/pdb.html](https://docs.python.org/3/library/pdb.html)'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pdb`: [https://docs.Python.org/3/library/pdb.html](https://docs.python.org/3/library/pdb.html)'
- en: '`tqdm`: [https://github.com/tqdm/tqdm](https://github.com/tqdm/tqdm)'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tqdm`: [https://github.com/tqdm/tqdm](https://github.com/tqdm/tqdm)'
- en: '`JAX`: [https://jax.readthedocs.io/](https://jax.readthedocs.io/)'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`JAX`: [https://jax.readthedocs.io/](https://jax.readthedocs.io/)'
- en: '`Seaborn`: [https://seaborn.pydata.org/](https://seaborn.pydata.org/)'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Seaborn`: [https://seaborn.pydata.org/](https://seaborn.pydata.org/)'
- en: '`Numba`: [https://numba.pydata.org/numba-doc/latest/index.html](https://numba.pydata.org/numba-doc/latest/index.html)'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Numba`: [https://numba.pydata.org/numba-doc/latest/index.html](https://numba.pydata.org/numba-doc/latest/index.html)'
- en: '`Dask`: [https://ml.dask.org/](https://ml.dask.org/)'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Dask`: [https://ml.dask.org/](https://ml.dask.org/)'
- en: '`CuPy`: [https://cupy.chainer.org](https://cupy.chainer.org)'
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CuPy`: [https://cupy.chainer.org](https://cupy.chainer.org)'
- en: '`cuDF`: [https://github.com/rapidsai/cudf](https://github.com/rapidsai/cudf)'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cuDF`: [https://github.com/rapidsai/cudf](https://github.com/rapidsai/cudf)'
- en: '`Ray`: [http://ray.readthedocs.io/en/latest/rllib.html](http://ray.readthedocs.io/en/latest/rllib.html)'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Ray`: [http://ray.readthedocs.io/en/latest/rllib.html](http://ray.readthedocs.io/en/latest/rllib.html)'
- en: '`joblib`: [https://joblib.readthedocs.io/en/latest/](https://joblib.readthedocs.io/en/latest/)'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`joblib`: [https://joblib.readthedocs.io/en/latest/](https://joblib.readthedocs.io/en/latest/)'
- en: Classifying in scikit-learn, Keras, and PyTorch
  id: totrans-268
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在scikit-learn、Keras和PyTorch中进行分类
- en: 'In this section, we''ll be looking at data exploration, and modeling in three
    of the most important libraries. Therefore, we''ll break things down into the
    following sub-recipes:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将探讨数据探索和在三个最重要的库中建模。因此，我们将将事物分解为以下子食谱：
- en: Visualizing data in Seaborn
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Seaborn中可视化数据
- en: Modeling in scikit-learn
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在scikit-learn中进行建模
- en: Modeling in Keras
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Keras中进行建模
- en: Modeling in PyTorch
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用PyTorch进行建模
- en: 'Throughout these recipes and several subsequent ones, we''ll focus on covering
    first the basics of the three most important libraries for AI in Python: scikit-learn,
    Keras, and PyTorch. Through this, we will introduce basic and intermediate techniques
    in supervised machine learning with deep neural networks and other algorithms. This
    recipe will cover the basics of these three main libraries in machine learning
    and deep learning.'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些食谱和随后的几个食谱中，我们将专注于首先涵盖Python中AI三个最重要库的基础：scikit-learn、Keras和PyTorch。通过这些，我们将介绍监督机器学习和深度神经网络等中级和基础技术。
- en: We'll go through a simple classification task using scikit-learn, Keras, and
    PyTorch in turn. We'll run both of the deep learning frameworks in offline mode.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将依次通过scikit-learn、Keras和PyTorch进行一个简单的分类任务。我们将同时运行这两个深度学习框架的离线模式。
- en: These recipes are for introducing the basics of the three libraries. However,
    even if you've already worked with all of them, you might still find something
    of interest.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 这些食谱旨在介绍三个库的基础知识。但即使你已经使用过它们所有，你可能仍会发现一些感兴趣的内容。
- en: Getting ready
  id: totrans-277
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: The Iris Flower dataset is one of the oldest machine learning datasets still
    in use. It was published by Ronald Fisher in 1936 to illustrate linear discriminant
    analysis. The problem is to classify one of three iris flower species based on
    measurements of sepal and petal width and length.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 鸢尾花数据集是仍在使用的最古老的机器学习数据集之一。它由罗纳德·费希尔于1936年发布，用于说明线性判别分析。问题是基于萼片和花瓣的宽度和长度的测量来分类三种鸢尾花物种中的一种。
- en: 'Although this is a very simple problem, the basic workflow is as follows:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这是一个非常简单的问题，但基本工作流程如下：
- en: Load the dataset.
  id: totrans-280
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载数据集。
- en: Visualize the data.
  id: totrans-281
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可视化数据。
- en: Preprocess and transform the data.
  id: totrans-282
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 预处理和转换数据。
- en: Choose a model to use.
  id: totrans-283
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择要使用的模型。
- en: Check the model performance.
  id: totrans-284
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查模型性能。
- en: Interpret and understand the model (this stage is often optional).
  id: totrans-285
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解释和理解模型（这个阶段通常是可选的）。
- en: This is a standard process template that we will have to apply to most of the
    problems shown throughout this book. Typically, with industrial-scale problems,
    *Steps 1* and *2* can take much longer (sometimes estimated to take about 95 percent
    of the time) than for one of the already preprocessed datasets that you will get
    for a Kaggle competition or at the UCI machine learning repository. We will go
    into the complexities of each of these steps in later recipes and chapters.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个标准的流程模板，我们将不得不应用到本书中所展示的大多数问题上。典型的工业规模问题，*步骤1*和*2*可能需要更长的时间（有时估计要花费大约95%的时间），而不像在Kaggle竞赛或UCI机器学习存储库中获得的已预处理数据集那样。我们将在后面的食谱和章节中深入探讨每个步骤的复杂性。
- en: 'We''ll assume you''ve installed the three libraries earlier on and that you
    have your Jupyter Notebook or Colab instance running. Additionally, we will use
    the seaborn and scikit-plot libraries for visualization, so we''ll install them
    as well:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 我们假设您之前已安装了这三个库，并且您的Jupyter Notebook或Colab实例正在运行。此外，我们还将使用seaborn和scikit-plot库进行可视化，因此我们也会安装它们：
- en: '[PRE42]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'The convenience of using a dataset so well known is that we can easily load
    it from many packages, for example, like this:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 使用一个如此广为人知的数据集的便利之处在于，我们可以从许多包中轻松加载它，例如：
- en: '[PRE43]'
  id: totrans-290
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: Let's jump right in, starting with data visualization.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们直接开始，从数据可视化开始。
- en: How to do it...
  id: totrans-292
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做…
- en: Let's first have a look at the dataset.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先查看数据集。
- en: Visualizing data in seaborn
  id: totrans-294
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在seaborn中可视化数据
- en: 'In this recipe, we''ll go through the basic steps of data exploration. This
    is often important to understand the complexity of the problem and any underlying
    issues with the data:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将介绍数据探索的基本步骤。理解问题的复杂性和数据中的任何潜在问题通常是很重要的：
- en: 'Plot a pair-plot:'
  id: totrans-296
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制一对图：
- en: '[PRE44]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Here it comes (rendered in seaborn''s pleasant spacing and coloring):'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是（在seaborn愉悦的间距和颜色中呈现）：
- en: '![](img/cfd7ec2a-4641-48a0-88bf-bec5dcfe675c.png)'
  id: totrans-299
  prefs: []
  type: TYPE_IMG
  zh: '![](img/cfd7ec2a-4641-48a0-88bf-bec5dcfe675c.png)'
- en: A pair-plot in seaborn visualizes pair-wise relationships in a dataset. Each
    subplot shows one variable plotted against another in a scatterplot. The subplots
    on the diagonal show the distribution of the variables. The colors correspond
    to the three classes.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 在seaborn中绘制一对图可视化数据集中的成对关系。每个子图显示一个散点图中的一个变量与另一个变量。对角线上的子图显示变量的分布。颜色对应于三个类别。
- en: From this plot, especially if you look along the diagonal, we can see that the
    virginica and versicolor species are not (linearly) separable. This is something
    we are going to struggle with, and that we'll have to overcome.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个图中，特别是沿着对角线看，我们可以看到弗吉尼亚和变色鸢尾品种并不是（线性）可分的。这是我们将要努力解决的问题，我们将不得不克服它。
- en: 'Let''s have a quick look at the dataset:'
  id: totrans-302
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们快速查看数据集：
- en: '[PRE45]'
  id: totrans-303
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'We only see setosa, since the flower species are ordered and listed one after
    another:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只看到setosa，因为花的种类是按顺序列出的：
- en: '![](img/0ae80d8e-725a-4cf3-8933-e84757f96b0d.png)'
  id: totrans-305
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0ae80d8e-725a-4cf3-8933-e84757f96b0d.png)'
- en: 'Separate the features and target in preparation for training as follows:'
  id: totrans-306
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 准备好训练的特征和目标如下：
- en: '[PRE46]'
  id: totrans-307
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: The last line converted the three strings corresponding to the three classes
    into numbers – this is called an ordinal coding. A multiclass machine learning
    algorithm can deal with this. For neural networks, we'll use another encoding,
    as you'll see later.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一行将三个对应于三个类别的字符串转换为数字 - 这称为序数编码。多类别机器学习算法可以处理这个问题。对于神经网络，我们将使用另一种编码方式，稍后您将看到。
- en: After these basic steps, we are ready to start developing predictive models.
    These are models that predict the flower class from the features. We'll see this
    in turn for each of the three most important machine learning libraries in Python.
    Let's start with scikit-learn.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 经过这些基本步骤，我们准备开始开发预测模型。这些模型可以根据特征预测花的类别。我们将依次看到Python中最重要的三个机器学习库中的每一个。让我们从scikit-learn开始。
- en: Modeling in scikit-learn
  id: totrans-310
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在scikit-learn中建模
- en: In this recipe, we'll create a classifier in scikit-learn, and check its performance.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将在scikit-learn中创建一个分类器，并检查其性能。
- en: Scikit-learn (also known as sklearn) is a Python machine learning framework
    developed since 2007\. It is also one of the most comprehensive frameworks available,
    and it is interoperable with the pandas, NumPy, SciPy, and Matplotlib libraries.
    Much of scikit-learn has been optimized for speed and efficiency in Cython, C,
    and C++.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: Scikit-learn（也称为sklearn）是自2007年以来开发的Python机器学习框架。它也是可用的最全面的框架之一，与pandas、NumPy、SciPy和Matplotlib库兼容。Scikit-learn的大部分都经过了Cython、C和C++的优化，以提高速度和效率。
- en: Please note that not all scikit-learn classifiers can do multiclass problems.
    All classifiers can do binary classification, but not all can do more than two
    classes. The random forest model can, fortunately. The **random forest** model
    (sometimes referred to as **random decision forest**) is an algorithm that can
    be applied to classification and regression tasks, and is an ensemble of decision
    trees. The main idea is that we can increase precision by creating decision trees
    on bootstrapped samples of the dataset, and average over these trees.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，并非所有的scikit-learn分类器都能处理多类问题。所有分类器都能进行二元分类，但并非所有都能处理超过两类的情况。幸运的是，随机森林模型能够处理。随机森林模型（有时称为随机决策森林）是一种可以应用于分类和回归任务的算法，是决策树的集成。其主要思想是通过在数据集的自助采样上创建决策树，并对这些树进行平均，以提高精度。
- en: 'Some of the following lines of code should appear to you as boilerplate, and
    we''ll use them over and over:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 以下几行代码中的一些应该对你来说是样板代码，并且我们会一遍又一遍地使用它们：
- en: Separate training and validation.
  id: totrans-315
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 分离训练和验证。
- en: 'As a matter of good practice, we should always test the performance of our
    models on a sample of our data that wasn''t used in training (referred to as a **hold-out
    set** or **validation set**). We can do this as follows:'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 作为良好实践的一部分，我们应该始终在未用于训练的数据样本上测试模型的性能（称为**保留集**或**验证集**）。我们可以这样做：
- en: '[PRE47]'
  id: totrans-317
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: Define a model.
  id: totrans-318
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个模型。
- en: 'Here we define our model **hyperparameters**, and create the model instance
    with these hyperparameters. This goes as follows in our case:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们定义我们的模型**超参数**，并使用这些超参数创建模型实例。在我们的情况下，过程如下：
- en: Hyperparameters are parameters that are not part of the learning process, but
    control the learning. In the case of neural networks, this includes the learning
    rate, model architecture, and activation functions.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 超参数是不属于学习过程但控制学习的参数。在神经网络的情况下，这包括学习率、模型架构和激活函数。
- en: '[PRE48]'
  id: totrans-321
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: Train the model.
  id: totrans-322
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练模型。
- en: Here, we pass the training dataset to our model. During training, the parameters
    of the model are being fit so that we obtain better results (where *better* is
    defined by a function, called the **cost function** or **loss function**).
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将训练数据集传递给我们的模型。在训练过程中，调整模型的参数以获得更好的结果（其中“更好”由一个称为**成本函数**或**损失函数**的函数定义）。
- en: 'For training we use the `fit` method, which is available for all sklearn-compatible
    models:'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 对于训练，我们使用`fit`方法，该方法适用于所有与sklearn兼容的模型：
- en: '[PRE49]'
  id: totrans-325
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: Check the performance of the model.
  id: totrans-326
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查模型的性能。
- en: 'While there''s a measure internal to the model (the cost function), we might
    want to look at additional measures. In the context of modeling, these are referred
    to as metrics. In scikit-learn, we have a lot of metrics at our fingertips. For
    classification, we would usually look at the confusion matrix, and often we''d
    want to plot it:'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管模型内部有一个度量（成本函数），我们可能希望查看额外的度量。在建模的背景下，这些被称为指标。在scikit-learn中，我们可以方便地使用许多度量。对于分类问题，我们通常会查看混淆矩阵，并经常希望将其绘制出来：
- en: '[PRE50]'
  id: totrans-328
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: The confusion matrix is relatively intuitive, especially when the presentation
    is as clear as with sklearn's `plot_confusion_matrix()`. Basically, we see how
    well our class predictions line up with the actual classes. We can see the predictions
    against actual labels, grouped by class, so that each entry corresponds to how
    many times class A was predicted given the actual class B. In this case, we've
    normalized the matrix, so that each row (actual labels) sums to one.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 混淆矩阵相对直观，特别是在类似于sklearn的`plot_confusion_matrix()`中呈现得如此清晰的情况下。基本上，我们可以看到我们的类预测与实际类别的对应情况。我们可以看到预测值与实际标签之间的对比，按类别分组，因此每个条目对应于在给定实际类别B的情况下预测为类别A的次数。在这种情况下，我们对矩阵进行了归一化处理，使每行（实际标签）的总和为一。
- en: 'Here is the confusion matrix:'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 这是混淆矩阵：
- en: '![](img/325f66c1-c69a-48e8-8691-29c58bf857e0.png)'
  id: totrans-331
  prefs: []
  type: TYPE_IMG
  zh: '![](img/325f66c1-c69a-48e8-8691-29c58bf857e0.png)'
- en: Since this is a normalized martix, the numbers on the diagonal are also called
    the **hit rate **or **true positive rate**. We can see that setosa was predicted
    as setosa 100% (1) of the time. By contrast, versicolor was predicted as versicolor
    95% of the time (0.95), while 5% of the time (0.053) it was predicted as virginica.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这是一个归一化矩阵，对角线上的数字也被称为**命中率**或**真正率**。我们可以看到setosa被预测为setosa的比例为100%（1）。相比之下，versicolor被预测为versicolor的比例为95%（0.95），而5%的时间（0.053）被预测为virginica。
- en: The performance is very good in terms of hit rate, however; as expected, we
    are having a small problem distinguishing between versicolor and virginica.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 在命中率方面表现非常好，然而，正如预期的那样，我们在区分变色鸢尾和弗吉尼亚鸢尾之间有一点小问题。
- en: Let's move on to Keras.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续使用Keras。
- en: Modeling in Keras
  id: totrans-335
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在Keras中建模
- en: In this recipe, we'll be predicting the flower species in Keras.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将使用Keras预测花的种类。
- en: Keras is a high-level interface for (deep) neural network models that can use
    TensorFlow as a backend, but also **Microsoft Cognitive Toolkit** (**CNTK**),
    Theano, or PlaidML. Keras is an interface for developing AI models, rather than
    a standalone framework itself. Keras has been integrated as part of TensorFlow,
    so we import Keras from TensorFlow. Both TensorFlow and Keras are open source
    and developed by Google.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: Keras是一个高级接口，用于（深度）神经网络模型，可以使用TensorFlow作为后端，但也可以使用**Microsoft Cognitive Toolkit**（**CNTK**）、Theano或PlaidML。Keras是开发AI模型的接口，而不是一个独立的框架。Keras已作为TensorFlow的一部分进行了集成，因此我们从TensorFlow导入Keras。TensorFlow和Keras都是由Google开发的开源工具。
- en: 'Since Keras is tightly integrated with TensorFlow, Keras models can be saved
    as TensorFlow models and then deployed in Google''s deployment system, TensorFlow
    Serving (see [https://www.tensorflow.org/tfx/guide/serving](https://www.tensorflow.org/tfx/guide/serving)),
    or used from any of the programming languages such as, C++ or Java. Let''s get
    into it:'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 由于Keras与TensorFlow紧密集成，Keras模型可以保存为TensorFlow模型，然后部署在Google的部署系统TensorFlow Serving中（参见[https://www.tensorflow.org/tfx/guide/serving](https://www.tensorflow.org/tfx/guide/serving)），或者从任何编程语言（如C++或Java）使用。让我们深入了解一下：
- en: 'Run the following code. If you are familiar with Keras, you''ll recognize it
    as boilerplate:'
  id: totrans-339
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下代码。如果您熟悉Keras，您会认识到这是样板代码：
- en: '[PRE51]'
  id: totrans-340
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'This yields the following model construction:'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 这导致以下模型构建：
- en: '![](img/e2ed7f28-0410-4d45-b145-f52df00637d9.png)'
  id: totrans-342
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e2ed7f28-0410-4d45-b145-f52df00637d9.png)'
- en: 'We can visualize this model in different ways. We can use the built-in Keras
    functionality as follows:'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以用不同的方式可视化这个模型。我们可以使用内置的Keras功能如下：
- en: '[PRE52]'
  id: totrans-344
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'This writes a visualization of the network to a file called `iris_model_keras.png`.
    The image produced looks like this:'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 这将把网络的可视化写入一个名为`iris_model_keras.png`的文件中。生成的图像如下所示：
- en: '![](img/5556bf37-dfcc-4ab1-80e6-92e6b4d7f02f.png)'
  id: totrans-346
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5556bf37-dfcc-4ab1-80e6-92e6b4d7f02f.png)'
- en: This shows that we have 4 input neurons, 10 hidden neurons, and 3 output neurons,
    fully connected in a feed-forward fashion. This means that all neurons in the
    input feed input to all neurons in the hidden layer, which in turn feed to all
    neurons in the output layer.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 这显示我们有4个输入神经元，10个隐藏神经元和3个输出神经元，完全连接以前馈方式。这意味着输入中的所有神经元都馈送到隐藏层中的所有神经元，然后馈送到输出层中的所有神经元。
- en: We are using the sequential model construction (as opposed to the graph). The
    sequential model type is more straightforward to build than the graph type. The
    layers are constructed the same way; however, for the sequential model, you have
    to define the input dimensionality, `input_dim`.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用顺序模型构建（与图形相对）。顺序模型类型比图形类型更容易构建。层的构建方式相同；然而，对于顺序模型，您必须定义输入维度，`input_dim`。
- en: We use two dense layers, the intermediate layer with SELU activation function,
    and the final layer with the softmax activation function. We'll explain both of
    these in the *How it works...* section. As for the **SELU activation function**,
    suffice it to say for now that it provides a necessary nonlinearity so that the
    neural network can deal with more variables that are not linearly separable, as
    in our case. In practice, it is rare to use a linear (**identity function**) activation
    in the hidden layers.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用两个密集层，中间层使用SELU激活函数，最后一层使用softmax激活函数。我们将在*工作原理……*部分解释这两者。至于**SELU激活函数**，现在可以说它提供了必要的非线性，使得神经网络能够处理更多线性不可分的变量，正如我们的情况。实际上，在隐藏层中很少使用线性（**恒等函数**）激活。
- en: Each unit (or neuron) in the final layer corresponds to one of the three classes.
    The **softmax function** normalizes the output layer so that its neural activations
    add up to 1\. We train with categorical cross-entropy as our loss function. Cross-entropy
    is typically used for classification problems with neural networks. The binary
    cross-entropy loss is for two classes, and categorical cross-entropy is for two
    or more classes (cross-entropy will be explained in more detail in the *How it
    works...* section).
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 最终层中的每个单元（或神经元）对应于三个类别中的一个。**softmax 函数**将输出层归一化，使其神经激活总和为 1。我们使用分类交叉熵作为损失函数进行训练。交叉熵通常用于神经网络的分类问题。二元交叉熵损失用于两类问题，而分类交叉熵损失用于两类或更多类问题（交叉熵将在
    *工作原理...* 部分详细解释）。
- en: Next, one-hot encode the features.
  id: totrans-351
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，对特征进行独热编码。
- en: 'This means we have three columns that each stand for one of the species, and
    one of them will be set to `1` for the corresponding class:'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着我们有三列，每一列代表一个物种，其中一个将被设为 `1` 对应于相应的类别：
- en: '[PRE53]'
  id: totrans-353
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: Our `y_categorical` therefore has the shape (150, 3). This means that to indicate
    class 0 as the label, instead of having a `0` (this would be sometimes called
    **label encoding** or **integer encoding**), we have a vector of `[1.0, 0.0, 0.0]`.
    This is called **one-hot encoding**. The sum of each row is equal to 1.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们的 `y_categorical` 的形状为 (150, 3)。这意味着，为了表示类别 0 作为标签，而不是使用 `0`（有时称为**标签编码**或**整数编码**），我们使用了一个向量
    `[1.0, 0.0, 0.0]`。这被称为**独热编码**。每行的总和等于 1。
- en: Normalize the features.
  id: totrans-355
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对特征进行归一化。
- en: 'For neural networks, our features should be normalized in a way that the activation
    functions can deal with the whole range of inputs – often this normalization is
    to the standard distribution, which has a mean of 0.0 and standard deviation of
    1.0:'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 对于神经网络，我们的特征应该以一种激活函数可以处理整个输入范围的方式进行归一化 —— 通常是到标准分布，其平均值为 0.0，标准差为 1.0：
- en: '[PRE54]'
  id: totrans-357
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'The output of this cell is this:'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 此单元格的输出如下：
- en: '[PRE55]'
  id: totrans-359
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'We see that the mean values for each column are very close to zero. We can
    also see the standard deviations with the following command:'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到每列的均值非常接近零。我们还可以通过以下命令查看标准差：
- en: '[PRE56]'
  id: totrans-361
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'The output is as follows:'
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE57]'
  id: totrans-363
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: The standard deviation is exactly `1`, as expected.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 标准差正好为 `1`，与预期一致。
- en: Display our training progress in TensorBoard.
  id: totrans-365
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 TensorBoard 中显示我们的训练进度。
- en: 'TensorBoard is a visualization tool for neural network learning, such as tracking
    and visualizing metrics, model graphs, feature histograms, projecting embeddings,
    and much more:'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: TensorBoard 是一种神经网络学习的可视化工具，用于跟踪和可视化指标、模型图、特征直方图、投影嵌入等等：
- en: '[PRE58]'
  id: totrans-367
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'At this point, a TensorBoard widget should pop up in your notebook. We just
    have to make sure it gets the information it needs:'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，应在笔记本中弹出一个 TensorBoard 小部件。我们只需确保它获得所需的信息：
- en: 'Plug the TensorBoard details into the Keras training function as a callback
    so TensorBoard gets the training information:'
  id: totrans-369
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 TensorBoard 的详细信息作为回调插入 Keras 训练函数，以便 TensorBoard 获取训练信息：
- en: '[PRE59]'
  id: totrans-370
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: This runs our training. An epoch is an entire pass of the dataset through the
    neural network. We use `150` here, which is a bit arbitrary. We could have used
    a stopping criterion to stop training automatically when validation and training
    errors start to diverge, or in other words, when overfitting occurs.
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 这会运行我们的训练。一个 epoch 是整个数据集通过神经网络的一次完整遍历。我们在这里使用了 `150`，这有点任意。我们可以使用停止准则，在验证和训练误差开始发散，或者换句话说，过拟合发生时自动停止训练。
- en: In order to use `plot_confusion_matrix()` as before, for comparison, we'd have
    to wrap the model in a class that implements the `predict()` method, and has a
    list of `classes_` and an attribute of `_estimator_type` that is equal to the
    classifier. We will show that in the online material.
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 为了像以前一样使用 `plot_confusion_matrix()` 进行比较，我们必须将模型包装在一个实现 `predict()` 方法的类中，并具有
    `classes_` 列表和一个等于分类器的 `_estimator_type` 属性。我们将在在线资料中展示这一点。
- en: Plot the confusion matrix.
  id: totrans-373
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制混淆矩阵。
- en: 'Here, it''s easier to use a `scikitplot` function:'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，使用 `scikitplot` 函数会更容易：
- en: '[PRE60]'
  id: totrans-375
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Again, as before, we normalize the matrix, so we get fractions. The output
    should look similar to the following:'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 同样地，我们归一化矩阵，以便得到分数。输出应该类似于以下内容：
- en: '![](img/21ef449d-bb15-482e-be0d-bdfe51162cd1.png)'
  id: totrans-377
  prefs: []
  type: TYPE_IMG
  zh: '![](img/21ef449d-bb15-482e-be0d-bdfe51162cd1.png)'
- en: This is a bit worse than our previous attempt in scikit-learn, but with some
    tweaking we can get to a comparable level, or maybe even better performance. Examples
    of tweaking would be changing any of the model's hyperparameters such as the number
    of neurons in the hidden layer, any changes to the network architecture (adding
    a new layer), or changing the activation function of the hidden layer.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 这比我们在 scikit-learn 中之前的尝试稍逊一筹，但通过一些调整，我们可以达到一个可比较的水平，甚至可能有更好的表现。调整的例子包括改变模型的任何超参数，比如隐藏层中的神经元数，对网络架构的任何更改（添加新层），或者改变隐藏层的激活函数。
- en: 'Check the charts from TensorBoard: the training progress and the model graph.
    Here they are:'
  id: totrans-379
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看来自 TensorBoard 的图表：训练进度和模型图。这里它们：
- en: '![](img/4c4ed8a1-0309-42c6-9043-cb4e2e5232d2.png)'
  id: totrans-380
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4c4ed8a1-0309-42c6-9043-cb4e2e5232d2.png)'
- en: 'These plots show the accuracy and loss, respectively, over the entire training.
    We also get another visualization of the network in TensorBoard:'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 这些图显示了整个训练过程中的准确率和损失。我们还可以在 TensorBoard 中获得另一种对网络的可视化：
- en: '![](img/f7234bd4-41b4-41cf-a8d7-1bec34ba6bf3.png)'
  id: totrans-382
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f7234bd4-41b4-41cf-a8d7-1bec34ba6bf3.png)'
- en: This shows all the network layers, the loss and metrics, the optimizer (RMSprop),
    and the training routine, and how they are related. As for the network architecture,
    we can see four dense layers (the presented input and targets are not considered
    proper parts of the network, and are therefore colored in white). The network
    consists of a dense hidden layer (being fed by the input), and an dense output
    layer (being fed by the hidden layer). The loss function is calculated between
    the output layer activation and the targets. The optimizer works with all layers
    based on the loss. You can find a tutorial on TensorBoard at [https://www.tensorflow.org/tensorboard/get_started](https://www.tensorflow.org/tensorboard/get_started).
    The TensorBoard documentation explains more about configuration and options.
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 此处显示了所有网络层，损失和指标，优化器（RMSprop），以及训练过程，以及它们之间的关系。关于网络架构，我们可以看到四个密集层（所呈现的输入和目标不被视为网络的适当部分，因此呈白色）。网络由一个密集隐藏层（由输入提供数据），和一个密集输出层（由隐藏层提供数据）组成。损失函数在输出层激活和目标之间进行计算。优化器根据损失与所有层一起工作。您可以在
    TensorBoard 的教程中找到更多信息：[https://www.tensorflow.org/tensorboard/get_started](https://www.tensorflow.org/tensorboard/get_started)。TensorBoard
    的文档解释了更多的配置和选项。
- en: So the classification accuracy is improving and the loss is decreasing over
    the course of the training epochs. The final graph shows the network and training
    architecture, including the two dense layers, the loss and metrics, and the optimizer.
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，分类准确性随着训练周期的增加而提高，损失逐渐减少。最终的图表显示了网络和训练架构，包括两个密集层、损失和指标，以及优化器。
- en: Modeling in PyTorch
  id: totrans-385
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在 PyTorch 中建模
- en: In this recipe, we will describe a network equivalent to the previous one shown
    in Keras, train it, and plot the performance.
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将描述一个与之前在 Keras 中展示的网络等效的网络，训练它，并绘制其性能。
- en: 'PyTorch is a deep learning framework that is based on the Torch library primarily
    developed by Facebook. For some time, Facebook was developing another deep learning
    framework, called Caffe2; however, it was merged into PyTorch in March 2018\.
    Some of the strengths of PyTorch are in image and language processing applications.
    Apart from Python, Torch provides a C++ interface, both for learning and model
    deployment:'
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch 是一个基于 Torch 库开发的深度学习框架，主要由 Facebook 开发。一段时间以来，Facebook 一直在开发另一个深度学习框架，名为
    Caffe2；然而，它在 2018 年 3 月并入了 PyTorch。PyTorch 在图像和语言处理应用中具有一些优势。除了 Python 外，Torch
    还提供了一个 C++ 接口，用于学习和模型部署：
- en: 'Let''s define the model architecture first. This looks very similar to Keras:'
  id: totrans-388
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们首先定义模型架构。这看起来与 Keras 非常相似：
- en: '[PRE61]'
  id: totrans-389
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'This is the same architecture that we defined before in Keras: this is a feed-forward,
    two-layer neural network with a SELU activation on the hidden layer, and 10 and
    3 neurons in the 2 layers.'
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 这与我们之前在 Keras 中定义的架构相同：这是一个前馈式、两层神经网络，隐藏层采用 SELU 激活函数，第一层有 10 个神经元，第二层有 3 个神经元。
- en: If you prefer an output similar to the `summary()` function in Keras, you can
    use the `torchsummary` package ([https://github.com/sksq96/pytorch-summary](https://github.com/sksq96/pytorch-summary)).
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您喜欢类似于 Keras 中 `summary()` 函数的输出，可以使用 `torchsummary` 包（[https://github.com/sksq96/pytorch-summary](https://github.com/sksq96/pytorch-summary)）。
- en: 'We need to convert our NumPy arrays to Torch tensors:'
  id: totrans-392
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要将 NumPy 数组转换为 Torch 张量：
- en: '[PRE62]'
  id: totrans-393
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: '`y_train` is the one-hot encoded target matrix that we created earlier. We
    are converting it back to integer encoding since the PyTorch cross-entropy loss
    expects this.'
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: '`y_train` 是我们之前创建的 one-hot 编码的目标矩阵。由于 PyTorch 交叉熵损失函数期望这样，我们将其转换回整数编码。'
- en: 'Now we can train, as follows:'
  id: totrans-395
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们可以进行训练，如下所示：
- en: '[PRE63]'
  id: totrans-396
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'And then we''ll use `scikitplot` to visualize our results, similar to before:'
  id: totrans-397
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们将使用`scikitplot`来可视化我们的结果，与之前类似：
- en: '[PRE64]'
  id: totrans-398
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'This is the plot we get:'
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们得到的图表：
- en: '![](img/51e3ae5f-09dc-4f19-aed3-6f27cf259b29.png)'
  id: totrans-400
  prefs: []
  type: TYPE_IMG
  zh: '![](img/51e3ae5f-09dc-4f19-aed3-6f27cf259b29.png)'
- en: Your plot might differ. Neural network learning is not deterministic, so you
    could get better or worse numbers, or just different ones.
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 你的绘图可能有所不同。神经网络学习不是确定性的，因此你可能得到更好或更差的数字，或者完全不同的数字。
- en: We can get better performance if we let this run longer. This is left as an
    exercise for you.
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们让这个过程运行更长时间，我们可以获得更好的性能。这留给你作为一个练习。
- en: How it works...
  id: totrans-403
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理...
- en: We'll first look at the intuitions behind neural network training, then we'll
    look a bit more at some of the technical details that we will use in the PyTorch
    and Keras recipes.
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先看看神经网络训练背后的直觉，然后稍微深入探讨一些我们将在 PyTorch 和 Keras 配方中使用的技术细节。
- en: Neural network training
  id: totrans-405
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 神经网络训练
- en: The basic idea in machine learning is that we try to minimize an error by changing
    the parameters of a model. This adaption of the parameter is called learning.
    In supervised learning, the error is defined by a loss function calculated between
    the prediction of the model and the target. This error is calculated at every
    step and the model parameters are adjusted accordingly.
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习的基本思想是通过改变模型的参数来尽量减少误差。这种参数的调整被称为学习。在监督学习中，误差由模型预测与目标之间的损失函数计算得出。这种误差在每一步计算，并且相应地调整模型参数。
- en: 'Neural networks are composable function approximators consisting of tunable
    affine transformations (*f*) with an activation function (sigma):'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络是由可调的仿射变换(*f*)和激活函数(sigma)组成的可组合函数逼近器：
- en: '![](img/6425a5ac-bd5c-4e81-9ab6-a6bb964f35b3.png)'
  id: totrans-408
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6425a5ac-bd5c-4e81-9ab6-a6bb964f35b3.png)'
- en: 'In the simplest terms, in a feed-forward neural network of one layer with linear
    activations, the model predictions are given by the sum of the product of the
    coefficients with the input in all of its dimensions:'
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，在具有线性激活函数的单层前馈神经网络中，模型预测由系数与所有维度输入的乘积之和给出：
- en: '![](img/bd55b3c9-45ed-44de-adec-ec3c4333e188.png)'
  id: totrans-410
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bd55b3c9-45ed-44de-adec-ec3c4333e188.png)'
- en: 'This is called a **perceptron**, and it is a linear binary classifier. A simple
    illustration with four inputs is shown in the following diagram:'
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 这被称为**感知器**，它是一个线性二元分类器。下图展示了具有四个输入的简单示例：
- en: '![](img/0e27d0f2-78c4-4412-b4bc-bd5b03621320.png)'
  id: totrans-412
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0e27d0f2-78c4-4412-b4bc-bd5b03621320.png)'
- en: The predictor for a one-dimensional input breaks down to the slope-intercept
    form of a line in two dimensions, ![](img/a4f3202a-015a-495a-81b3-4961062c7b23.png). Here,
    *m* is the slope and *b* the y-intercept. For higher-dimensional inputs, we can
    write (changing notation and vectorizing) ![](img/17e269e4-d56c-43fe-86ed-87f0bf939d21.png) with
    bias term ![](img/8689ae91-7972-4bdd-bdc7-26012b51bcdf.png) and weights ![](img/3a360d26-1c7e-4e50-94bf-429445299518.png). This
    is still a line, just in a space of the same dimensionality as the input. Please
    note that ![](img/6041b6ec-241c-4596-b926-39a613d89aa4.png) denotes our model
    prediction for ![](img/a696c282-1619-4d11-bafe-1b295f4e8775.png), and for the
    examples where we know ![](img/04cca892-4e5e-4509-a9b4-bfac3eee0493.png), we can
    calculate the difference between the two as our prediction error.
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 一维输入的预测器可以分解为二维中的斜率-截距形式的线，如图所示：![](img/a4f3202a-015a-495a-81b3-4961062c7b23.png)。这里，*m*
    是斜率，*b* 是 y-截距。对于更高维度的输入，我们可以写成（改变符号并向量化）![](img/17e269e4-d56c-43fe-86ed-87f0bf939d21.png)，具有偏置项![](img/8689ae91-7972-4bdd-bdc7-26012b51bcdf.png)
    和权重![](img/3a360d26-1c7e-4e50-94bf-429445299518.png)。这仍然是一条线，只不过在与输入维度相同的空间中。请注意，![](img/6041b6ec-241c-4596-b926-39a613d89aa4.png)
    表示我们对于![](img/a696c282-1619-4d11-bafe-1b295f4e8775.png) 的模型预测，对于我们知道的例子，我们可以计算两者之间的差异作为我们的预测误差。
- en: 'We can also use the same very simple linear algebra to define the binary classifier
    by thresholding as follows:'
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以使用非常简单的线性代数来定义二元分类器，如下所示：
- en: '![](img/3fbde85b-3a06-4d69-8145-130055ff600c.png)'
  id: totrans-415
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3fbde85b-3a06-4d69-8145-130055ff600c.png)'
- en: This is still very simple linear algebra. This linear model with just one layer,
    called a perceptron, has difficulty predicting any more complex relationships.
    This lead to deep concern about the limitations of neural networks following an
    influential paper by Minsky and Papert in 1969\. However, since the 1990s, neural
    networks have been experiencing a resurgence in the shape of **support vector
    machines** (**SVMs**) and the **multilayer perceptron** (**MLP**). The MLP is
    a feed-forward neural network with at least one layer between the input and output
    (**hidden layer**). Since a multilayer perceptron with many layers of linear activations
    can be reduced to just one layer, non-trivially, we'll be referring to neural
    networks with hidden layers and nonlinear activation functions. These types of
    models can approximate arbitrary functions and perform nonlinear classification
    (according to the Universal Approximation Theorem). The activation function on
    any layer can be any differentiable nonlinearity; traditionally, the sigmoid, ![](img/dc02480a-fdad-4123-878d-6dfe65543152.png), has
    been used a lot for this purpose.
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 这仍然是非常简单的线性代数。这个只有一个层的线性模型，称为感知器，很难预测更复杂的关系。这导致了对神经网络限制的深刻担忧，这些担忧在1969年由Minsky和Papert的一篇有影响力的论文后变得流行。然而，自1990年以来，神经网络在支持向量机（**SVMs**）和多层感知器（**MLP**）的形式下经历了复苏。MLP是一个前馈神经网络，其输入和输出之间至少有一层（**隐藏层**）。由于具有许多层线性激活的多层感知器可以被非平凡地减少为仅一个层，我们将引用具有隐藏层和非线性激活函数的神经网络。这些类型的模型可以近似任意函数，并执行非线性分类（根据通用逼近定理）。任何层上的激活函数都可以是任何可微的非线性函数；传统上，sigmoid函数，![](img/dc02480a-fdad-4123-878d-6dfe65543152.png)，在这个目的上经常被使用。
- en: 'For illustration, let''s write this down with `jax`:'
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明，让我们用`jax`来写下这些内容：
- en: '[PRE65]'
  id: totrans-418
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: If you look at this code, you'll see that we could have equally written this
    up with operations in NumPy, TensorFlow, or PyTorch. You'll also note that the
    `construct_network()` function takes a `layer_sizes` argument. This is one of
    the hyperparameters of the network, something to decide on before learning. We
    can choose just an output of [1] to get the perceptron, or [10, 1] to get a two-layer
    perceptron. So this shows how to get a network as a set of parameters and how
    to get a prediction from this network. We still haven't discussed how we learn
    the parameters, and this brings us to errors.
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您看这段代码，您会发现我们可以同样地在NumPy、TensorFlow或PyTorch中进行操作。您还会注意到`construct_network()`函数接受一个`layer_sizes`参数。这是网络的超参数之一，在学习之前需要决定的内容。我们可以选择仅输出[1]来得到感知器，或者[10,
    1]来得到一个两层感知器。这展示了如何将网络作为一组参数以及如何从该网络获得预测。我们还没有讨论如何学习这些参数，这将引出我们的错误。
- en: There's an adage that says, *"all models are wrong, but some are useful."* We
    can measure the error of our model, and this can help us to calculate the magnitude
    and direction of changes that we can make to our parameters in order to reduce
    the error.
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 有一句古语说，“*所有的模型都是错误的，但有些是有用的*”。我们可以测量我们模型的误差，这可以帮助我们计算我们可以对参数进行的变化的大小和方向，以减少误差。
- en: 'Given a (differentiable) loss function (also called the cost function), ![](img/964429e0-1680-46d8-9984-1bea6fdb7def.png),
    such as the **mean squared error** (**MSE**), we can calculate our error. In the
    case of the MSE, the loss function is as follows:'
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一个（可微分的）损失函数（也称为成本函数），![](img/964429e0-1680-46d8-9984-1bea6fdb7def.png)，例如**均方误差**（**MSE**），我们可以计算我们的误差。在MSE的情况下，损失函数如下：
- en: '![](img/ec6a8cd3-5213-4436-9780-717e176e8ddf.png)'
  id: totrans-422
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ec6a8cd3-5213-4436-9780-717e176e8ddf.png)'
- en: 'Then in order to get the change to our weights, we''ll use the derivative of
    the loss over the points in training:'
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 然后为了得到我们权重的变化，我们将使用训练中点上损失的导数：
- en: '![](img/663fd8c7-b8df-4971-9b56-6a230558dc5d.png)'
  id: totrans-424
  prefs: []
  type: TYPE_IMG
  zh: '![](img/663fd8c7-b8df-4971-9b56-6a230558dc5d.png)'
- en: 'This means we are applying a gradient descent, which means that over time,
    our error will be reduced proportionally to the gradient (scaled by learning rate
    ![](img/1e7e2a35-9229-426f-af13-21aa5dd25e61.png)). Let''s continue with our code:'
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着我们正在应用梯度下降，这意味着随着时间的推移，我们的误差将按梯度（乘以学习率![](img/1e7e2a35-9229-426f-af13-21aa5dd25e61.png)）比例减少。让我们继续我们的代码：
- en: '[PRE66]'
  id: totrans-426
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: Both PyTorch and JAX have `autograd` functionality, which means that we can
    automatically get derivatives (gradients) of a wide range of functions.
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch和JAX都具有`autograd`功能，这意味着我们可以自动获取各种函数的导数（梯度）。
- en: We'll encounter a lot of different activation and loss functions throughout
    this book. In this chapter, we used the SELU activation function.
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本书中遇到许多不同的激活和损失函数。在本章中，我们使用SELU激活函数。
- en: The SELU activation function
  id: totrans-429
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: SELU激活函数
- en: 'The **scaled exponential linear unit** (**SELU**) activation function was published
    quite recently by Klambauer et al in 2017 ([http://papers.nips.cc/paper/6698-self-normalizing-neural-networks.pdf](http://papers.nips.cc/paper/6698-self-normalizing-neural-networks.pdf)):'
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: '**缩放指数线性单元**（**SELU**）激活函数是由Klambauer等人于2017年最近发布的（[http://papers.nips.cc/paper/6698-self-normalizing-neural-networks.pdf](http://papers.nips.cc/paper/6698-self-normalizing-neural-networks.pdf)）：'
- en: '![](img/8e764eba-0ced-43e8-b1f6-e8646d4e3a6e.png)'
  id: totrans-431
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8e764eba-0ced-43e8-b1f6-e8646d4e3a6e.png)'
- en: The SELU function is linear for positive values of *x,* a scaled exponential
    for negative values, and 0 when *x* is 0. ![](img/3c854e13-516d-455d-88f0-2eb1c4132e4f.png) is
    a value greater than 1.  You can find the details in the original paper. The SELU
    function has been shown to have better convergence properties than other functions.
    You can find a comparison of activation functions in Padamonti (2018) at [https://arxiv.org/pdf/1804.02763.pdf](https://arxiv.org/pdf/1804.02763.pdf).
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: SELU函数对于正值*x*是线性的，对于负值是缩放指数，*x*为0时为0。在原始论文中可以找到详细信息。SELU函数显示出比其他函数更好的收敛性能。您可以在Padamonti（2018）的比较激活函数中找到更多信息，网址为[https://arxiv.org/pdf/1804.02763.pdf](https://arxiv.org/pdf/1804.02763.pdf)。
- en: Softmax activation
  id: totrans-433
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Softmax激活
- en: 'As our activation function for the output layer in the neural networks, we
    use a softmax function. This works as a normalization to sum 1.0 of the neural
    activations of the output layer. The output can be therefore interpreted as the
    class probabilities. The softmax activation function is defined as follows:'
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: 作为我们神经网络输出层的激活函数，我们使用softmax函数。这作为输出层神经激活的归一化，总和为1.0的类激活。因此，输出可以解释为类概率。softmax激活函数定义如下：
- en: '![](img/f36d5b2e-1c77-47fb-98e4-c3b7839e1275.png)'
  id: totrans-435
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f36d5b2e-1c77-47fb-98e4-c3b7839e1275.png)'
- en: Cross-entropy
  id: totrans-436
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 交叉熵
- en: 'In the multiclass training with neural networks, it''s common to train for
    cross-entropy. The binary cross-entropy for multiclass cases looks like the following:'
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用神经网络进行多类训练时，通常会训练交叉熵。多类别情况下的二元交叉熵如下所示：
- en: '![](img/73a3d1d0-507a-40e8-8035-4b1075d149b9.png)'
  id: totrans-438
  prefs: []
  type: TYPE_IMG
  zh: '![](img/73a3d1d0-507a-40e8-8035-4b1075d149b9.png)'
- en: Here, *M* is the number of classes (setosa, versicolor, and virginica), *y*
    is 0 or 1 if the class label *c* is correct, and *p* is the predicted probability
    that the observation *o* is of class *c*. You can read up more on different loss
    functions and metrics on the ml-cheatsheet site, at [https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html](https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html).
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*M*是类的数量（setosa、versicolor和virginica），*y*是类标签*c*是否正确的0或1，*p*是观测值*o*属于类*c*的预测概率。您可以在ml-cheatsheet网站上了解更多关于不同损失函数和度量的信息，网址为[https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html](https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html)。
- en: See also
  id: totrans-440
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参见
- en: 'You can find out more details on the website of each of the libraries used
    in this recipe:'
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在每个库的网站上找到本教程中使用的更多详细信息：
- en: '`Seaborn`: [https://seaborn.pydata.org/](https://seaborn.pydata.org/)'
  id: totrans-442
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Seaborn`：[https://seaborn.pydata.org/](https://seaborn.pydata.org/)'
- en: '`Scikit-plot`: [https://scikit-plot.readthedocs.io/](https://scikit-plot.readthedocs.io/)'
  id: totrans-443
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Scikit-plot`：[https://scikit-plot.readthedocs.io/](https://scikit-plot.readthedocs.io/)'
- en: '`Scikit-learn`: [https://github.com/scikit-learn/scikit-learn](https://github.com/scikit-learn/scikit-learn)'
  id: totrans-444
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Scikit-learn`：[https://github.com/scikit-learn/scikit-learn](https://github.com/scikit-learn/scikit-learn)'
- en: '`Keras`: [https://github.com/keras-team/keras](https://github.com/keras-team/keras)'
  id: totrans-445
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Keras`：[https://github.com/keras-team/keras](https://github.com/keras-team/keras)'
- en: '`TensorFlow`: [http://tensorflow.org/](http://tensorflow.org/)'
  id: totrans-446
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TensorFlow`：[http://tensorflow.org/](http://tensorflow.org/)'
- en: '`TensorBoard`: [https://www.tensorflow.org/tensorboard](https://www.tensorflow.org/tensorboard)'
  id: totrans-447
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TensorBoard`：[https://www.tensorflow.org/tensorboard](https://www.tensorflow.org/tensorboard)'
- en: '`PyTorch`: [https://pytorch.org/](https://pytorch.org/)'
  id: totrans-448
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PyTorch`：[https://pytorch.org/](https://pytorch.org/)'
- en: TensorboardX is a TensorBoard interface for other deep learning frameworks apart
    from TensorFlow (PyTorch, Chainer, MXNet, and others), available at [https://github.com/lanpa/tensorboardX](https://github.com/lanpa/tensorboardX).
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: TensorboardX是TensorFlow之外的其他深度学习框架（如PyTorch、Chainer、MXNet等）的TensorBoard接口，网址为[https://github.com/lanpa/tensorboardX](https://github.com/lanpa/tensorboardX)。
- en: It should probably be noted that scikit-plot is not maintained anymore. For
    the plotting of machine learning metrics and charts, mlxtend is a good option,
    at [http://rasbt.github.io/mlxtend/](http://rasbt.github.io/mlxtend/).
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，scikit-plot现在已不再维护。对于机器学习指标和图表的绘制，mlxtend是一个很好的选择，网址是：[http://rasbt.github.io/mlxtend/](http://rasbt.github.io/mlxtend/)
- en: 'Some other libraries we used here and that we will encounter throughout this
    book include the following:'
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里使用了一些其他库，而且在本书中我们将会遇到以下内容：
- en: '`Matplotlib`: [https://matplotlib.org/](https://matplotlib.org/)'
  id: totrans-452
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Matplotlib`: [https://matplotlib.org/](https://matplotlib.org/)'
- en: '`NumPy`: [https://docs.scipy.org/doc/numpy](https://docs.scipy.org/doc/numpy)'
  id: totrans-453
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`NumPy`: [https://docs.scipy.org/doc/numpy](https://docs.scipy.org/doc/numpy)'
- en: '`SciPy`: [https://docs.scipy.org/doc/scipy/reference](https://docs.scipy.org/doc/scipy/reference)'
  id: totrans-454
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`SciPy`: [https://docs.scipy.org/doc/scipy/reference](https://docs.scipy.org/doc/scipy/reference)'
- en: '`pandas`: [https://pandas.pydata.org/pandas-docs/stable](https://pandas.pydata.org/pandas-docs/stable)'
  id: totrans-455
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pandas`: [https://pandas.pydata.org/pandas-docs/stable](https://pandas.pydata.org/pandas-docs/stable)'
- en: In the following recipe, we'll get to grips with a more realistic example in
    Keras.
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的示例中，我们将通过Keras了解一个更实际的例子。
- en: Modeling with Keras
  id: totrans-457
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Keras进行建模
- en: In this recipe, we will load a dataset and then we will conduct **exploratory data analysis** (**EDA**),
    such as visualizing the distributions.
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将加载一个数据集，然后进行**探索性数据分析**（**EDA**），如可视化分布。
- en: 'We will do typical preprocessing tasks such as encoding categorical variables,
    and normalizing and rescaling for neural network training. We will then create a simple neural network model in
    Keras, train the model plotting using a generator, and plot the training and validation performance. We will
    look at a still quite simple dataset: the dult dataset from the UCI machine learning repository.
    With this dataset (also known as the Census Income dataset), the goal is to predict from census data
    whether someone earns more than US$50,000 per year.'
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将执行典型的预处理任务，如编码分类变量，并进行归一化和缩放以用于神经网络训练。然后我们将在Keras中创建一个简单的神经网络模型，使用生成器进行训练，绘制训练和验证性能。我们将查看一个仍然相当简单的数据集：来自UCI机器学习库的成人收入数据集（也称为人口普查收入数据集）。在这个数据集中，目标是根据人口普查数据预测某人是否年收入超过5万美元。
- en: Since we have a few categorical variables, we'll also deal with the encoding
    of categorical variables.
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们有一些分类变量，我们还将处理分类变量的编码。
- en: 'Since this is still an introductory recipe, we''ll go through this problem
    with a lot of detail for illustration. We''ll have the following parts:'
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这仍然是一个入门的示例，我们将详细介绍这个问题。我们将包括以下部分：
- en: 'Data loading and preprocessing:'
  id: totrans-462
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据加载和预处理：
- en: Loading the datasets
  id: totrans-463
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载数据集
- en: Inspecting the data
  id: totrans-464
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查数据
- en: Categorical encoding
  id: totrans-465
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 分类编码
- en: Plotting variables and distributions
  id: totrans-466
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制变量和分布图
- en: Plotting correlations
  id: totrans-467
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制相关性
- en: Label encoding
  id: totrans-468
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 标签编码
- en: Normalizing and scaling
  id: totrans-469
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 规范化和缩放
- en: Saving the preprocessed data
  id: totrans-470
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 保存预处理后的数据
- en: 'Model training:'
  id: totrans-471
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型训练：
- en: Creating the model
  id: totrans-472
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建模型
- en: Writing a data generator
  id: totrans-473
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编写数据生成器
- en: Training the model
  id: totrans-474
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练模型
- en: Plotting the performance
  id: totrans-475
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制性能
- en: Extracting performance metrics
  id: totrans-476
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提取性能指标
- en: Calculating feature importances
  id: totrans-477
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算特征重要性
- en: Getting ready
  id: totrans-478
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'We''ll need a few libraries for this recipe in addition to the libraries we
    installed earlier:'
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: 除了之前安装的库外，这个示例还需要一些其他库：
- en: '`category_encoders` for the encoding of categorical variables'
  id: totrans-480
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`category_encoders` 用于编码分类变量'
- en: '`minepy` for information-based correlation measures'
  id: totrans-481
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`minepy` 用于基于信息的相关性测量'
- en: '`eli5` for the inspection of black-box models'
  id: totrans-482
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`eli5` 用于检查黑盒模型'
- en: We've used Seaborn before for visualization.
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前用过Seaborn进行可视化。
- en: 'We can install these libraries as follows:'
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以按以下方式安装这些库：
- en: '[PRE67]'
  id: totrans-485
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'As a note to you, the reader: if you use `pip` and `conda` together, there
    is a danger that some of the libraries might become incompatible, creating a broken
    environment. We''d recommend using `conda` when a version of `conda` is available,
    although it is usually faster to use `pip`.'
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: 作为给您读者的一条注：如果您同时使用`pip`和`conda`，可能会导致一些库不兼容，造成环境混乱。我们建议在有`conda`版本的情况下使用`conda`，尽管通常使用`pip`更快。
- en: 'This dataset is already split into training and test. Let''s download the dataset
    from UCI as follows:'
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
  zh: 这个数据集已经分成了训练集和测试集。让我们从UCI下载数据集，如下所示：
- en: '[PRE68]'
  id: totrans-488
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: '`wget` doesn''t ship with macOS by default; we suggest installing `wget` using
    `brew` ([https://formulae.brew.sh/formula/wget](https://formulae.brew.sh/formula/wget)). On
    Windows, you can visit the two preceding URLs and download both via the File menu.
    Make sure you remember the directory where you save the files, so you can find
    them later. There are a few alternatives, however:'
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: '`wget`在macOS上默认未包含；我们建议使用`brew`安装`wget`（[https://formulae.brew.sh/formula/wget](https://formulae.brew.sh/formula/wget)）。在Windows上，您可以访问前述两个URL，并通过文件菜单下载这两个文件。确保您记住保存文件的目录，以便稍后找到它们。然而，也有一些其他替代方法：'
- en: You can use the download script we provide in [Chapter 2](bca59029-1915-4856-b47d-6041d7b10a0a.xhtml),
    *Advanced Topics in Supervised Machine Learning*, in the *Predicting house prices
    in PyTorch* recipe.
  id: totrans-490
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可以使用我们在[第2章](bca59029-1915-4856-b47d-6041d7b10a0a.xhtml)中提供的下载脚本，*监督机器学习的高级主题*，*在PyTorch中预测房价*
    配方。
- en: You can install the `wget` library and run `import wget; wget.download(URL,
    filepath)`.
  id: totrans-491
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可以安装`wget`库并运行`import wget; wget.download(URL, filepath)`。
- en: 'We have the following information from the UCI dataset description page:'
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从UCI数据集描述页面获得以下信息：
- en: '- age: continuous.'
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
  zh: '- age: 连续。'
- en: '- workclass: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov,
    State-gov, Without-pay, Never-worked.'
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
  zh: '- workclass: 私人企业，自雇-无薪，自雇-有薪，联邦政府，地方政府，州政府，无报酬，从未工作过。'
- en: '- fnlwgt: continuous.'
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
  zh: '- fnlwgt: 连续。'
- en: '- education: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm,
    Assoc-voc, 9th, 7th-th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.'
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
  zh: '- education: 学士，一些大学，11年级，高中毕业，专业学校，副学士学位，副职业学位，9年级，7年级，12年级，硕士，1-4年级，10年级，博士，5-6年级，学前教育。'
- en: '- education-num: continuous.'
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
  zh: '- education-num: 连续。'
- en: '- marital-status: Married-civ-spouse, Divorced, Never-married, Separated, Widowed,
    Married-spouse-absent, Married-AF-spouse.'
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
  zh: '- marital-status: 已婚-市民配偶，离婚，从未结过婚，分居，丧偶，已婚-配偶缺席，已婚-空军。'
- en: '- occupation: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial,
    Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing,
    Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.'
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
  zh: '- occupation: 技术支持，手工修理，其他服务，销售，执行管理，专业特长，处理器清洁工，机器操作检查，行政文员，农业捕捞，运输搬运，私人家务，保护服务，武装部队。'
- en: '- relationship: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.'
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
  zh: '- relationship: 妻子，自己的孩子，丈夫，非家庭成员，其他亲戚，未婚。'
- en: '- race: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.'
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
  zh: '- race: 白人，亚裔太平洋岛民，美印-爱斯基摩人，其他，黑人。'
- en: '- sex: Female, Male.'
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
  zh: '- sex: 女性，男性。'
- en: '- capital-gain: continuous.'
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
  zh: '- capital-gain: 连续。'
- en: '- capital-loss: continuous.'
  id: totrans-504
  prefs: []
  type: TYPE_NORMAL
  zh: '- capital-loss: 连续。'
- en: '- hours-per-week: continuous.'
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
  zh: '- hours-per-week: 连续。'
- en: '- native-country: United-States, and so on.'
  id: totrans-506
  prefs: []
  type: TYPE_NORMAL
  zh: '- native-country: 美国，等等。'
- en: '`fnlwgt` actually stands for the final weight; in other words, the total number
    of people constituting the entry.'
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
  zh: '`fnlwgt`实际上代表最终权重；换句话说，构成条目的总人数。'
- en: Please keep in mind that this dataset is a well-known dataset that has been
    used many times in scientific publications and in machine learning tutorials.
    We are using it here to go over some basics in Keras without having to focus on
    the dataset.
  id: totrans-508
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，这个数据集是一个知名的数据集，已经多次在科学出版物和机器学习教程中使用。我们在这里使用它来回顾一些Keras基础知识，而不需要专注于数据集。
- en: How to do it...
  id: totrans-509
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实现...
- en: As we've mentioned before, we'll first load the dataset, do some EDA, then create
    a model in Keras, train it, and look at the performance.
  id: totrans-510
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前提到的，我们首先加载数据集，进行一些探索性数据分析，然后在Keras中创建模型，训练它，并查看性能。
- en: We've split this recipe up into data loading and preprocessing, and secondly,
    model training.
  id: totrans-511
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将这个配方分成数据加载和预处理，以及模型训练两部分。
- en: Data loading and preprocessing
  id: totrans-512
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据加载和预处理
- en: 'We will start by loading the training and test sets:'
  id: totrans-513
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从加载训练集和测试集开始：
- en: '**Loading the dataset**: In order to load the dataset, we''ll use pandas again.
    We use pandas'' `read_csv()` command as before:'
  id: totrans-514
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**加载数据集**：为了加载数据集，我们将再次使用pandas。我们像之前一样使用pandas的`read_csv()`命令：'
- en: '[PRE69]'
  id: totrans-515
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: Now let's look at the data!
  id: totrans-516
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看数据！
- en: '**Inspecting the data**: The beginning of the DataFrame we can see with the
    `head()` method:'
  id: totrans-517
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**检查数据**：我们可以用`head()`方法看到DataFrame的开头：'
- en: '[PRE70]'
  id: totrans-518
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'This yields the following output:'
  id: totrans-519
  prefs: []
  type: TYPE_NORMAL
  zh: 这导致以下输出：
- en: '![](img/aac1b92d-ed03-42d6-a37c-0640dc0561b0.png)'
  id: totrans-520
  prefs: []
  type: TYPE_IMG
  zh: '![](img/aac1b92d-ed03-42d6-a37c-0640dc0561b0.png)'
- en: 'Next, we''ll look at the test data:'
  id: totrans-521
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将查看测试数据：
- en: '[PRE71]'
  id: totrans-522
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'This looks as follows:'
  id: totrans-523
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来如下：
- en: '![](img/97723596-e151-4600-844b-e97d23b32359.png)'
  id: totrans-524
  prefs: []
  type: TYPE_IMG
  zh: '![](img/97723596-e151-4600-844b-e97d23b32359.png)'
- en: 'The first row has 14 nulls and 1 unusable column out of 15 columns. We will
    discard this row:'
  id: totrans-525
  prefs: []
  type: TYPE_NORMAL
  zh: 第一行有15列中的14个空值和1列不可用列。我们将丢弃这一行：
- en: '[PRE72]'
  id: totrans-526
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: And it's gone.
  id: totrans-527
  prefs: []
  type: TYPE_NORMAL
  zh: 然后它消失了。
- en: '**Categorical encoding**: Let''s start with category encoding. For EDA, it''s
    good to use ordinal encoding. This means that for a categorical feature, we map
    each value to a distinct number:'
  id: totrans-528
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**分类编码**：让我们从分类编码开始。对于探索性数据分析（EDA），最好使用序数编码。这意味着对于分类特征，我们将每个值映射到一个不同的数字：'
- en: '[PRE73]'
  id: totrans-529
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: We are separating *X*, the features, and *y*, the targets, here. The features
    don't contain the labels; that's the purpose of the `drop()` method – we could
    have equally used `del train['50k']`.
  id: totrans-530
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里分离*X*，即特征，和*y*，即目标。特征不包含标签；这就是`drop()`方法的目的——我们也可以使用`del train['50k']`。
- en: 'Here is the result:'
  id: totrans-531
  prefs: []
  type: TYPE_NORMAL
  zh: 这是结果：
- en: '![](img/73a4a855-f798-4be9-b4cd-90ed8471b4d6.png)'
  id: totrans-532
  prefs: []
  type: TYPE_IMG
  zh: '![](img/73a4a855-f798-4be9-b4cd-90ed8471b4d6.png)'
- en: When starting with a new task, it's best to do EDA. Let's plot some of these
    variables.
  id: totrans-533
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始新任务时，最好进行探索性数据分析（EDA）。让我们绘制一些这些变量。
- en: 'To plot variables and distributions, use the following code block:'
  id: totrans-534
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要绘制变量和分布，请使用以下代码块：
- en: '[PRE74]'
  id: totrans-535
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'We''ll get the following plot:'
  id: totrans-536
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将得到以下绘图：
- en: '![](img/a3b9e6d9-0e56-41bc-a33b-dfbbb277730e.png)'
  id: totrans-537
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a3b9e6d9-0e56-41bc-a33b-dfbbb277730e.png)'
- en: 'Next, we''ll look at a pair-plot again. We''ll plot all numerical variables
    against each other:'
  id: totrans-538
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们再次看一下配对图。我们将所有数值变量相互绘制：
- en: '[PRE75]'
  id: totrans-539
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'As discussed in the previous recipe, the diagonal in the pair-plot shows us
    histograms of single variables – that is, the distribution of the variable – with
    the hue defined by the classes. Here we have orange versus blue (see the legend
    on the right of the following plot). The following subplots on the diagonal show
    scatter plots between the two variables:'
  id: totrans-540
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，在对角线上的配对图中，显示了单变量的直方图——即变量的分布——其色调由类别定义。这里我们有橙色与蓝色（请参见图右侧的图例）。对角线上的子图显示了两个变量之间的散点图：
- en: '![](img/c5c8972a-b5bb-49cb-b002-1f497047c2c9.png)'
  id: totrans-541
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c5c8972a-b5bb-49cb-b002-1f497047c2c9.png)'
- en: If we look at the age variable on the diagonal (second row), we see that the
    two classes have a different distribution, although they are still overlapping. Therefore,
    age seems to be discriminative with respect to our target class.
  id: totrans-542
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们看一下对角线上的年龄变量（第二行），我们会发现两个类别有不同的分布，尽管它们仍然重叠。因此，年龄似乎在我们的目标类别方面具有区分性。
- en: 'We can see that in a categorical plot as well:'
  id: totrans-543
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到在分类图中也是如此：
- en: '[PRE76]'
  id: totrans-544
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'Here''s the resulting plot:'
  id: totrans-545
  prefs: []
  type: TYPE_NORMAL
  zh: 这是生成的图形：
- en: '![](img/4e2aac99-455b-44dd-bd28-def2c5a841c1.png)'
  id: totrans-546
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4e2aac99-455b-44dd-bd28-def2c5a841c1.png)'
- en: After this, let's move on to a correlation plot.
  id: totrans-547
  prefs: []
  type: TYPE_NORMAL
  zh: 完成这些后，让我们转向相关性图。
- en: '**Plotting correlations**: In order to get an idea of the redundancy between
    variables, we''ll plot a correlation matrix based on the **Maximal Information
    Coefficient** (**MIC**), a correlation metric based on information entropy. We''ll
    explain the MIC at the end of this recipe.'
  id: totrans-548
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**绘制相关性**：为了了解变量之间的冗余程度，我们将基于最大信息系数（MIC），这是一种基于信息熵的相关性度量，绘制相关性矩阵。我们将在本文末尾解释MIC。'
- en: 'Since the MIC can take a while to compute, we''ll take the parallelization
    pattern we introduced   earlier. Please note the creation of the thread pool and
    the `map` operation:'
  id: totrans-549
  prefs: []
  type: TYPE_NORMAL
  zh: 由于计算MIC可能需要一些时间，我们将采用之前介绍的并行化模式。请注意线程池的创建和`map`操作：
- en: '[PRE77]'
  id: totrans-550
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: This can still take a while, but should be much faster than doing the computations
    in sequence.
  id: totrans-551
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能仍然需要一些时间，但应该比按顺序计算要快得多。
- en: 'Let''s visualize the correlation matrix as a heatmap: since the matrix is symmetric,
    here, we''ll only show the lower triangle and apply some nice styling:'
  id: totrans-552
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将相关性矩阵可视化为热图：由于矩阵是对称的，这里我们只显示下三角部分并应用一些漂亮的样式：
- en: '[PRE78]'
  id: totrans-553
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'This looks as follows:'
  id: totrans-554
  prefs: []
  type: TYPE_NORMAL
  zh: 如下所示：
- en: '![](img/e0db7638-366d-46f9-8058-cd18f98ea38a.png)'
  id: totrans-555
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e0db7638-366d-46f9-8058-cd18f98ea38a.png)'
- en: 'We can see in the correlation matrix heatmap that most pair correlations are
    pretty low (most correlations are below 0.4), meaning that most features are relatively
    uncorrelated; however, there is one pair of variables that stands out, those of
    `education-num` and `education`:'
  id: totrans-556
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到在相关性矩阵热图中，大多数变量对之间的相关性都相当低（大多数相关性都低于0.4），这意味着大多数特征相对不相关；然而，有一对变量明显突出，即`education-num`和`education`：
- en: '[PRE79]'
  id: totrans-557
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: The output is `0.9995095286140694`.
  id: totrans-558
  prefs: []
  type: TYPE_NORMAL
  zh: 输出为 `0.9995095286140694`。
- en: This is about as close to a perfect correlation as it can get. These two variables
    do in fact refer to the same information.
  id: totrans-559
  prefs: []
  type: TYPE_NORMAL
  zh: 这几乎是完美相关的情况。这两个变量实际上指向相同的信息。
- en: 'Let''s see the variance in `education-num` for each value in `education`:'
  id: totrans-560
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看`education`中每个值的`education-num`的方差：
- en: '[PRE80]'
  id: totrans-561
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: We only see zeros. There's no variance. In other words, each value in `education`
    corresponds to exactly one value in `education-num`. The variables are exactly
    the same! We should be able to remove one of them, for example with `del train['education']`,
    or just ignore one of them during training.
  id: totrans-562
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只看到零。没有变异。换句话说，`education`中的每个值都恰好对应于`education-num`中的一个值。这些变量完全相同！我们应该能够删除其中一个，例如通过`del
    train['education']`，或者在训练期间忽略其中一个。
- en: 'The UCI description page mentions missing variables. Let''s look for missing
    variables now:'
  id: totrans-563
  prefs: []
  type: TYPE_NORMAL
  zh: UCI描述页面提到了缺失变量。现在让我们来寻找缺失的变量：
- en: '[PRE81]'
  id: totrans-564
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: We only see `False` for each variable, so we cannot see any missing values here.
  id: totrans-565
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个变量，我们只看到`False`，因此在这里我们看不到任何缺失值。
- en: In neural network training, for categorical variables, we have the choice of either using embeddings
    (we'll get to these in [Chapter 10](955f3e81-9e58-483b-bc9d-b23981325b62.xhtml),
    *Natural Language Processing*) or feeding them as one-hot encodings; this means
    that each factor, each possible value, is encoded in a binary variable that indicates
    whether it is given or not. Let's try one-hot encodings for simplicity.
  id: totrans-566
  prefs: []
  type: TYPE_NORMAL
  zh: 在神经网络训练中，对于分类变量，我们可以选择使用嵌入（我们将在[第10章](955f3e81-9e58-483b-bc9d-b23981325b62.xhtml)，*自然语言处理*中讨论）或者将它们作为一位热编码来进行输入；这意味着每个因子，每个可能的值，都被编码为一个二进制变量，指示其是否存在。让我们试试一位热编码以简化问题。
- en: 'So, first, let''s re-encode the variables:'
  id: totrans-567
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，首先让我们重新编码变量：
- en: '[PRE82]'
  id: totrans-568
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: 'Our `x_cleaned_cols` looks as follows:'
  id: totrans-569
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的`x_cleaned_cols`如下所示：
- en: '![](img/5289bf87-d1f6-4a83-9abc-dd74dc3ead59.png)'
  id: totrans-570
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5289bf87-d1f6-4a83-9abc-dd74dc3ead59.png)'
- en: After this, it's time to encode our labels.
  id: totrans-571
  prefs: []
  type: TYPE_NORMAL
  zh: 完成后，是时候对我们的标签进行编码了。
- en: '**Label encoding**: We are going to encode target values in two columns as
    1 if present and 0 if not present. It is good to remember that the Python truth
    values correspond to 0 and 1, respectively, for false and true. Since we have
    a binary classification task (that is, we only have two classes), we can use 0
    and 1 in a single output. If we have more than two classes, we''d have to use
    categorical encoding for the output, which typically means we use as many output
    neurons as we do classes. Often, we have to try different solutions in order to
    see what works best.'
  id: totrans-572
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**标签编码**：我们将在两列中对目标值进行编码，如果存在则为1，如果不存在则为0。需要记住，Python的真值对应于0和1，分别表示假和真。由于我们有一个二元分类任务（即，我们只有两个类别），我们可以在单个输出中使用0和1。如果我们有超过两个类别，我们将不得不对输出进行分类编码，通常意味着我们使用与类别数量相同的输出神经元。通常情况下，我们需要尝试不同的解决方案来找出最佳的方法。'
- en: 'In the following code block, we just made a choice and stuck with it:'
  id: totrans-573
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下代码块中，我们只是做了一个选择并坚持了下来：
- en: '[PRE83]'
  id: totrans-574
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: '**Normalizing and scaling**: We have to convert all values to z-values. This
    is when we subtract the mean and divide by the standard deviation, in order to
    get a normal distribution with a mean of 0.0 and a standard deviation of 1.0\.
    It''s not necessary to have normal distributions for neural network input. However,
    it''s important that numerical values are scaled to the sensitive part of the
    neural network activation functions. Converting to z-scores is a standard way
    to do this:'
  id: totrans-575
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**归一化和缩放**：我们必须将所有值转换为z值。这是通过减去均值并除以标准差来实现的，以便获得均值为0.0，标准差为1.0的正态分布。对于神经网络输入并不一定需要正态分布。然而，重要的是将数值缩放到神经网络激活函数的敏感部分。将值转换为z分数是一种标准方法：'
- en: '[PRE84]'
  id: totrans-576
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: '**Saving our preprocessing**: For good practice, we save our datasets and the
    transformers so we have an audit trail. This can be useful for bigger projects:'
  id: totrans-577
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**保存我们的预处理**：出于良好的实践，我们保存我们的数据集和转换器，以便有审计追踪。这对于更大的项目非常有用：'
- en: '[PRE85]'
  id: totrans-578
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: We are ready to train now.
  id: totrans-579
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在准备好进行训练了。
- en: Model training
  id: totrans-580
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型训练
- en: We'll create the model, train it, plot performance, and then calculate the feature
    importance.
  id: totrans-581
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将创建模型，训练它，绘制性能，然后计算特征重要性。
- en: 'To create the model, we use the** `Sequential`** model type again. Here''s
    our network architecture:'
  id: totrans-582
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要创建模型，我们再次使用**`Sequential`**模型类型。这是我们的网络架构：
- en: '[PRE86]'
  id: totrans-583
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: 'Here''s the Keras model summary:'
  id: totrans-584
  prefs: []
  type: TYPE_NORMAL
  zh: 这是Keras模型的摘要：
- en: '![](img/eff395f3-5357-4681-8c71-d02b6e9e02c7.png)'
  id: totrans-585
  prefs: []
  type: TYPE_IMG
  zh: '![](img/eff395f3-5357-4681-8c71-d02b6e9e02c7.png)'
- en: Now, let's write a data generator. To make this a bit more interesting, we will
    use a generator this time to feed in our data in batches. This means that we stream
    in our data instead of putting all of our training data into the `fit()` function
    at once. This can be useful for very big datasets.
  id: totrans-586
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们编写一个数据生成器。为了让这个过程更加有趣，这次我们将使用一个生成器来批量输入我们的数据。这意味着我们会逐批次地将数据流入，而不是一次性将所有训练数据放入`fit()`函数中。这对于非常大的数据集非常有用。
- en: 'We''ll use the `fit_generator()` function as follows:'
  id: totrans-587
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用`fit_generator()`函数如下：
- en: '[PRE87]'
  id: totrans-588
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: If we had not done our preprocessing already, we could put it into this function.
  id: totrans-589
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们还没有进行预处理，我们可以将其放入此函数中。
- en: 'Now that we have our data generator, we can train our model as follows:'
  id: totrans-590
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们有了数据生成器，我们可以按如下方式训练我们的模型：
- en: '[PRE88]'
  id: totrans-591
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: This should be relatively quick since this is a small dataset; however, if you
    find that this takes too long, you can always reduce the dataset size or the number
    of epochs.
  id: totrans-592
  prefs: []
  type: TYPE_NORMAL
  zh: 因为这是一个小数据集，所以应该相对快速；然而，如果发现这太耗时，您可以减少数据集大小或训练周期数。
- en: We have the output from the training, such as loss and metrics, in our `history`
    variable.
  id: totrans-593
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有来自训练的输出，如损失和指标，保存在我们的`history`变量中。
- en: 'This time we will plot the training progress over epochs from the Keras training
    history instead of using TensorBoard. We didn''t do validation, so we will only
    plot the training loss and training accuracy:'
  id: totrans-594
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这次我们将绘制来自Keras训练历史的训练进度随时间变化的图表，而不是使用TensorBoard。由于我们没有验证，所以我们只绘制训练损失和训练准确率：
- en: '[PRE89]'
  id: totrans-595
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: Please note that in some versions of Keras, accuracy is stored as `accuracy`
    rather than `acc` in the history.
  id: totrans-596
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在某些Keras版本中，准确率存储为`accuracy`而不是`acc`在历史记录中。
- en: 'Here''s the resulting graph:'
  id: totrans-597
  prefs: []
  type: TYPE_NORMAL
  zh: 这是生成的图表：
- en: '![](img/9a08f66b-0b15-49e0-8580-50a05b7c8e4a.png)'
  id: totrans-598
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9a08f66b-0b15-49e0-8580-50a05b7c8e4a.png)'
- en: Over the training epochs, the accuracy is increasing while the loss is decreasing,
    so that's good.
  id: totrans-599
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练过程中，准确率在增加而损失在减少，这是一个好兆头。
- en: 'Since we''ve already one-hot encoded and scaled our test data, we can directly
    predict and calculate our performance. We will calculate the **AUC** (**area-under-the-curve**) score
    using sklearn''s built-in functions. The AUC score comes from the receiver operating
    characteristics, which is a visualization of the false positive rate (also called
    the false alarm rate) on the *x* axis, against the true positive rate (also called
    the hit rate) on the *y* axis. The integral under this curve, the AUC score, is
    a popular measure of classification performance and is useful for understanding
    the trade-off between a high hit rate and any false alarms:'
  id: totrans-600
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于我们已经对测试数据进行了独热编码和缩放，我们可以直接进行预测并计算我们的性能。我们将使用sklearn内置函数计算**AUC**（曲线下面积）得分。AUC得分来自接收器操作特性曲线，这是对*假阳率*（也称为误报率）在*x*轴上的可视化，与*真阳率*（也称为命中率）在*y*轴上的对比。该曲线下的积分，即AUC得分，是分类性能的常用指标，有助于理解高命中率和任何假警报之间的平衡：
- en: '[PRE90]'
  id: totrans-601
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: We get `0.7579310072282265` as the AUC score. An AUC score of 76% can be a good
    or bad score depending on the difficulty of the task. It's not bad for this dataset,
    but we could probably improve the performance by tweaking the model more. However,
    for now, we'll leave it as it is here.
  id: totrans-602
  prefs: []
  type: TYPE_NORMAL
  zh: 我们获得了`0.7579310072282265`作为AUC得分。76%的AUC得分可以根据任务的难度而有好坏之分。对于这个数据集来说并不差，但我们可能通过进一步调整模型来提高性能。不过，目前我们会保留它如此。
- en: Finally, we are going to check the feature importances. For this, we are going
    to use the `eli5` library for black-box permutation importance. Black-box permutation
    importance encompasses a range of techniques that are model-agnostic, and, roughly
    speaking, permute features in order to establish their importance. You can read
    more about permuation importance in the *How it works...* section.
  id: totrans-603
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们将检查特征重要性。为此，我们将使用`eli5`库进行黑盒排列重要性评估。黑盒排列重要性包括一系列与模型无关的技术，大致上来说，它们会对特征进行排列以确定它们的重要性。您可以在*它是如何工作...*部分阅读更多关于排列重要性的信息。
- en: 'For this to work, we need a scoring function, as follows:'
  id: totrans-604
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使其工作，我们需要一个评分函数，如下所示：
- en: '[PRE91]'
  id: totrans-605
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: 'Now we can print the feature importances in sorted order:'
  id: totrans-606
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以按排序顺序打印特征重要性：
- en: '[PRE92]'
  id: totrans-607
  prefs: []
  type: TYPE_PRE
  zh: '[PRE92]'
- en: 'We obtain something like the following list:'
  id: totrans-608
  prefs: []
  type: TYPE_NORMAL
  zh: 我们获得类似以下列表的内容：
- en: '![](img/fb2a0851-b9a9-4b7e-881c-c89f9b3c86b0.png)'
  id: totrans-609
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fb2a0851-b9a9-4b7e-881c-c89f9b3c86b0.png)'
- en: Your final list might differ from the list here. The neural network training
    is not deterministic, although we could have tried to fix the random generator
    seed. Here, as we've expected, age is a significant factor; however, some categories
    in relationship status and marital status come up before age.
  id: totrans-610
  prefs: []
  type: TYPE_NORMAL
  zh: 您的最终列表可能会与此列表不同。神经网络训练并不确定性，尽管我们可以尝试固定随机生成器种子。在这里，正如我们所预料的，年龄是一个重要因素；然而，在关系状态和婚姻状况的某些类别中，年龄之前的因素也显现出来。
- en: How it works...
  id: totrans-611
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作...
- en: 'We went through a typical process in machine learning: we loaded a dataset,
    plotted and explored it, and did preprocessing with the encoding of categorical
    variables and normalization. We then created and trained a neural network model
    in Keras, and plotted the training and validation performance. Let''s talk about
    what we did in more detail.'
  id: totrans-612
  prefs: []
  type: TYPE_NORMAL
  zh: 我们经历了机器学习中的典型流程：加载数据集，绘制和探索数据，对分类变量进行编码和归一化预处理。然后在 Keras 中创建和训练神经网络模型，并绘制训练和验证性能。让我们更详细地讨论我们所做的事情。
- en: Maximal information coefficient
  id: totrans-613
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 最大信息系数
- en: There are many ways to calculate and plot correlation matrices, and we'll see
    some more possibilities in the recipes to come. Here we've calculated correlations
    based on the **maximal information coefficient** (**MIC**). The MIC comes from
    the framework of *maximal information-based nonparametric exploration*. This was
    published in *Science* *Magazine* in 2011, where it was hailed as the correlation
    metric of the 21st century (the article can be found at [https://science.sciencemag.org/content/334/6062/1518.full](https://science.sciencemag.org/content/334/6062/1518.full)).
  id: totrans-614
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多方法可以计算和绘制相关矩阵，我们将在接下来的示例中看到更多可能性。在这里，我们基于**最大信息系数**（**MIC**）计算了相关性。 MIC 来自于*基于最大信息的非参数探索*框架。这篇文章于2011年发表在*科学*杂志上，被誉为21世纪的相关度量标准（文章链接在[https://science.sciencemag.org/content/334/6062/1518.full](https://science.sciencemag.org/content/334/6062/1518.full)）。
- en: Applied to two variables, *X* and *Y*, it heuristically searches for bins in
    both variables, so that the mutual information between *X* and *Y* given the bins
    is maximal. The coefficient ranges between 0 (no correlation) and 1 (perfect correlation).
    It has an advantage with respect to the Pearson correlation coefficient, firstly
    in that it finds correlations that are non-linear, and secondly that it works
    with categorical variables.
  id: totrans-615
  prefs: []
  type: TYPE_NORMAL
  zh: 应用于两个变量 *X* 和 *Y*，它启发性地搜索两个变量中的分箱，使得给定分箱时 *X* 和 *Y* 之间的互信息最大化。该系数的范围介于0（无相关性）和1（完全相关性）之间。与皮尔逊相关系数相比，它有一个优势，首先是找到非线性相关性，其次是可以处理分类变量。
- en: Data generators
  id: totrans-616
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据生成器
- en: If you are familiar with Python generators, you won't need an explanation for
    what this is, but maybe a few clarifying words are in order. Using a generator
    gives the possibility of loading data **on-demand** or **on-line**, rather than
    at once. This means that you can work with datasets much larger than your available
    memory.
  id: totrans-617
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你熟悉 Python 生成器，你就不需要解释这是什么，但也许需要一些澄清。使用生成器可以按需或在线加载数据，而不是一次性加载。这意味着你可以处理比可用内存大得多的数据集。
- en: Some important terminology for generators in neural networks and Keras is as
    follows
  id: totrans-618
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络和 Keras 生成器的一些重要术语如下所示
- en: '*Iterations* (`steps_per_epoch`) are the number of batches needed to complete
    one epoch.'
  id: totrans-619
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*迭代*（`steps_per_epoch`）是完成一个 epoch 所需的批次数。'
- en: The *batch size* is the number of training examples in a single batch.
  id: totrans-620
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*批量大小*是单个批次中的训练示例数量。'
- en: 'There are different ways to implement generators with Keras, such as the following:'
  id: totrans-621
  prefs: []
  type: TYPE_NORMAL
  zh: 有多种方法可以使用 Keras 实现生成器，例如以下方式：
- en: Using any Python generator
  id: totrans-622
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用任何 Python 生成器
- en: Implementing `tensorflow.keras.utils.Sequence`
  id: totrans-623
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现 `tensorflow.keras.utils.Sequence`
- en: For the first option, we can use any generator really, but this uses a function
    with yield. This means we're providing the `steps_per_epoch` parameter for the
    Keras `fit_generator()` function.
  id: totrans-624
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第一个选项，我们可以使用任何生成器，但这里使用了一个带有 yield 函数。这意味着我们为 Keras 的 `fit_generator()` 函数提供了
    `steps_per_epoch` 参数。
- en: 'As for the second, we write a class that inherits from `tensorflow.keras.utils.Sequence`,
    which implements the following methods:'
  id: totrans-625
  prefs: []
  type: TYPE_NORMAL
  zh: 至于第二个选项，我们编写了一个继承自 `tensorflow.keras.utils.Sequence` 的类，该类实现了以下方法：
- en: '`len()`, in order for the `fit_generator()` function to know how much more
    data is to come. This corresponds to `steps_per_epoch` and is ![](img/0a609a51-8332-480d-a92d-78bc4b0077ac.png).'
  id: totrans-626
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`len()`，以便 `fit_generator()` 函数知道还有多少数据要加载。这对应于 `steps_per_epoch`，并且是 ![](img/0a609a51-8332-480d-a92d-78bc4b0077ac.png)。'
- en: '`__getitem__()`, for the `fit_generator` to ask for the next batch.'
  id: totrans-627
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`__getitem__()`，用于 `fit_generator` 请求下一个批次。'
- en: '`on_epoch_end()` to do some shuffling or other things at the end of an epoch
    – this is optional.'
  id: totrans-628
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`on_epoch_end()` 在 epoch 结束时执行一些洗牌或其他操作 - 这是可选的。'
- en: For simplicity, we've taken the former approach.
  id: totrans-629
  prefs: []
  type: TYPE_NORMAL
  zh: 为简单起见，我们采用了前一种方法。
- en: We'll see later that batch data loading using generators is often a part of
    online learning, that is, the type of learning where we incrementally train a
    model on more and more data as it comes in.
  id: totrans-630
  prefs: []
  type: TYPE_NORMAL
  zh: 我们稍后将看到，使用生成器进行批数据加载通常是在线学习的一部分，即我们根据数据增量地训练模型。
- en: Permutation importance
  id: totrans-631
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 排列重要性
- en: The `eli5` library can calculate permutation importance, which measures the
    increase in the prediction error when features are not present. It's also called
    the **mean decrease accuracy** (**MDA**). Instead of re-training the model in
    a leave-one-feature-out fashion, the feature can be replaced by random noise.
    This noise is drawn from the same distribution as the feature so as to avoid distortions.
    Practically, the easiest way to do this is to randomly shuffle the feature values
    between rows. You can find more details about permutation importance in Breiman's *Random
    Forests* (2001), at [https://www.stat.berkeley.edu/%7Ebreiman/randomforest2001.pdf](https://www.stat.berkeley.edu/%7Ebreiman/randomforest2001.pdf).
  id: totrans-632
  prefs: []
  type: TYPE_NORMAL
  zh: '`eli5`库可以计算排列重要性，该重要性衡量了当特征不存在时预测错误的增加。这也称为**平均减少精度**（**MDA**）。与以一特征为一组的重新训练模型不同，可以将特征替换为随机噪声。该噪声从与特征相同的分布中绘制，以避免扭曲。实际上，最简单的方法是在行之间随机混洗特征值。您可以在Breiman的《*随机森林*》（2001）中找到有关排列重要性的更多细节，网址为[https://www.stat.berkeley.edu/%7Ebreiman/randomforest2001.pdf](https://www.stat.berkeley.edu/%7Ebreiman/randomforest2001.pdf)。'
- en: See also
  id: totrans-633
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参阅
- en: We'll cover a lot more about Keras, the underlying TensorFlow library, online
    learning, and generators in the recipes to come. I'd recommend you get familiar
    with layer types, data loaders and preprocessors, losses, metrics, and training
    options. All this is transferable to other frameworks such as PyTorch, where the
    **application programming interface** (**API**) differs; however, the essential
    principles are the same.
  id: totrans-634
  prefs: []
  type: TYPE_NORMAL
  zh: 关于Keras、底层TensorFlow库、在线学习和生成器，我们将在接下来的示例中详细讨论。我建议您熟悉层类型、数据加载器和预处理器、损失、指标和训练选项。所有这些都可以转移到其他框架，例如PyTorch，其**应用程序编程接口**（**API**）不同，但基本原则相同。
- en: 'Here are links to the documentation for TensorFlow/Keras:'
  id: totrans-635
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是TensorFlow/Keras文档的链接：
- en: Layer types: [https://www.tensorflow.org/api_docs/Python/tf/keras/layers](https://www.tensorflow.org/api_docs/python/tf/keras/layers)
  id: totrans-636
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 层类型：[https://www.tensorflow.org/api_docs/Python/tf/keras/layers](https://www.tensorflow.org/api_docs/python/tf/keras/layers)
- en: Data loading: [https://www.tensorflow.org/guide/data](https://www.tensorflow.org/guide/data)
  id: totrans-637
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据加载：[https://www.tensorflow.org/guide/data](https://www.tensorflow.org/guide/data)
- en: Losses: [https://www.tensorflow.org/api_docs/Python/tf/keras/losses](https://www.tensorflow.org/api_docs/python/tf/keras/losses)
  id: totrans-638
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 损失：[https://www.tensorflow.org/api_docs/Python/tf/keras/losses](https://www.tensorflow.org/api_docs/python/tf/keras/losses)
- en: Metrics: [https://www.tensorflow.org/api_docs/Python/tf/keras/metrics](https://www.tensorflow.org/api_docs/python/tf/keras/metrics)
  id: totrans-639
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指标：[https://www.tensorflow.org/api_docs/Python/tf/keras/metrics](https://www.tensorflow.org/api_docs/python/tf/keras/metrics)
- en: Training: [https://www.tensorflow.org/guide/keras/train_and_evaluate](https://www.tensorflow.org/guide/keras/train_and_evaluate)
  id: totrans-640
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练：[https://www.tensorflow.org/guide/keras/train_and_evaluate](https://www.tensorflow.org/guide/keras/train_and_evaluate)
- en: Both the Keras/TensorFlow combination and PyTorch provide a lot of interesting
    functionality that's beyond the scope of this recipe – or even this book. To name
    just a few, PyTorch has automatic differentiation functionality (in the form of
    autograd, with more info at [https://pytorch.org/docs/stable/autograd.html](https://pytorch.org/docs/stable/autograd.html)),
    and TensorFlow has an estimator API, which is an abstraction similar to Keras
    (for more detail on this, see [https://www.tensorflow.org/guide/estimator](https://www.tensorflow.org/guide/estimator)).
  id: totrans-641
  prefs: []
  type: TYPE_NORMAL
  zh: Keras/TensorFlow组合和PyTorch都提供了许多有趣的功能，超出了本示例或本书的范围。举几个例子，PyTorch具有自动区分功能（以autograd形式存在，详细信息请参见[https://pytorch.org/docs/stable/autograd.html](https://pytorch.org/docs/stable/autograd.html)），而TensorFlow具有估算器API，这是与Keras类似的抽象（有关更多详细信息，请参见[https://www.tensorflow.org/guide/estimator](https://www.tensorflow.org/guide/estimator)）。
- en: For information on `eli5`, please visit its website at [https://eli5.readthedocs.io/.](https://eli5.readthedocs.io/)
  id: totrans-642
  prefs: []
  type: TYPE_NORMAL
  zh: 关于`eli5`的信息，请访问其网站：[https://eli5.readthedocs.io/.](https://eli5.readthedocs.io/)
- en: 'For more datasets, the following three websites are your friends:'
  id: totrans-643
  prefs: []
  type: TYPE_NORMAL
  zh: 对于更多数据集，以下三个网站是您的好帮手：
- en: 'UCI machine learning datasets: [http://archive.ics.uci.edu/ml/datasets](http://archive.ics.uci.edu/ml/datasets)'
  id: totrans-644
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: UCI机器学习数据集：[http://archive.ics.uci.edu/ml/datasets](http://archive.ics.uci.edu/ml/datasets)
- en: Kaggle datasets: [https://www.kaggle.com/datasets/](https://www.kaggle.com/datasets/)
  id: totrans-645
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kaggle数据集：[https://www.kaggle.com/datasets/](https://www.kaggle.com/datasets/)
- en: Google Dataset Search: [https://datasetsearch.research.google.com/](https://datasetsearch.research.google.com/)
  id: totrans-646
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Google 数据集搜索：[https://datasetsearch.research.google.com/](https://datasetsearch.research.google.com/)
