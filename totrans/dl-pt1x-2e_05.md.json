["```py\nfrom torch.nn import Linear\nlinear_layer = Linear(in_features=5,out_features=3,bias=True)\n```", "```py\ninp = Variable(torch.randn(1,5))\nlinear_layer(inp)\n```", "```py\nLinear_layer.weight\n```", "```py\nlinear_layer.bias\n```", "```py\nlinear_layer = Linear(5,3)\nlinear_layer_2 = Linear(3,2)\nlinear_layer_2(linear_layer(inp))\n```", "```py\nexample_data = Variable(torch.Tensor([[10,2,-1,-1]]))\nexample_relu = ReLU()\nexample_relu(example_data)\n```", "```py\nclass NeuralNetwork(nn.Module):\n    def __init__(self,input_size,hidden_size,output_size):\n        super(NeuralNetwork,self).__init__()\n        self.layer1 = nn.Linear(input_size,hidden_size)\n        self.layer2 = nn.Linear(hidden_size,output_size)\n    def __forward__(self,input):\n        out = self.layer1(input)\n        out = nn.ReLU(out)\n        out = self.layer2(out)\n        return out\n```", "```py\nloss = nn.MSELoss()\ninput = Variable(torch.randn(2, 6), requires_grad=True)\ntarget = Variable(torch.randn(2, 6))\noutput = loss(input, target)\noutput.backward()\n```", "```py\ndef cross_entropy_function(true_label, prediction):\n    if true_label == 1:\n        return -log(prediction)\n    else:\n        return -log(1 - prediction)\n```", "```py\nloss = nn.CrossEntropyLoss()\ninput = Variable(torch.randn(2, 6), requires_grad=True)\ntarget = Variable(torch.LongTensor(2).random_(6))\noutput = loss(input, target)\noutput.backward()\n```", "```py\nsgd_optimizer = optim.SGD(model.parameters(), lr = 0.01)\n```", "```py\nfor input, target in dataset:\n    sgd_optimizer.zero_grad()\n    output = model(input)\n   loss = loss_fn(output, target)\n    loss.backward()\n    sgd_optimizer.step()\n```", "```py\npath = 'Dog-Cat-Classifier/Data/Train_Data/'\n#Read all the files inside our folder.\ndog_files = [f for f in glob.glob('Dog-Cat-Classifier/Data/Train_Data/dog/*.jpg')]\ncat_files = [f for f in glob.glob('Dog-Cat-Classifier/Data/Train_Data/cat/*.jpg')]\nfiles = dog_files + cat_files\nprint(f'Total no of images {len(files)}')\nno_of_images = len(files)\n```", "```py\nshuffle = np.random.permutation(no_of_images)\n```", "```py\nos.mkdir(os.path.join(path,'train'))\nos.mkdir(os.path.join(path,'valid'))\nCreate directories with label names.\nfor t in ['train','valid']:\n    for folder in ['dog/','cat/']:\n         os.mkdir(os.path.join(path,t,folder))\n```", "```py\nfor i in shuffle[:250]:\n    folder = files[i].split('/')[-2].split('.')[0]\n    image = files[i].split('/')[-1]\n    os.rename(files[i],os.path.join(path,'valid',folder,image))\n```", "```py\nfor i in shuffle[250:]:\n    folder = files[i].split('/')[-2].split('.')[0]\n    image = files[i].split('/')[-1]\n    os.rename(files[i],os.path.join(path,'train',folder,image))\n```", "```py\ndog_files = [f for f in glob.glob('Dog-Cat-Classifier/Data/Train_Data/dog/*.jpg')]\ncat_files = [f for f in glob.glob('Dog-Cat-Classifier/Data/Train_Data/cat/*.jpg')]\n```", "```py\nshuffle = np.random.permutation(no_of_images)\n```", "```py\nos.mkdir(os.path.join(path,'train'))\nos.mkdir(os.path.join(path,'valid'))\nfor t in ['train','valid']:\n    for folder in ['dog/','cat/']:\n         os.mkdir(os.path.join(path,t,folder))\n```", "```py\nfor i in shuffle[:250]:\n    folder = files[i].split('/')[-2].split('.')[0]\n    image = files[i].split('/')[-1]\n    os.rename(files[i],os.path.join(path,'valid',folder,image))\n```", "```py\ntransform = transforms.Compose([transforms.Resize((224,224))\n                                       ,transforms.ToTensor()\n                                       ,transforms.Normalize([0.12, 0.11, 0.40], [0.89, 0.21, 0.12])])\ntrain = ImageFolder('Dog-Cat-Classifier/Data/Train_Data/train/',transform)\nvalid = ImageFolder('Dog-Cat-Classifier/Data/Train_Data/valid/',transform)\n```", "```py\nimport matplotlib.pyplot as plt\ndef imshow(inp):\n    \"\"\"Imshow for Tensor.\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    mean = np.array([0.12, 0.12, 0.40])\n    std = np.array([0.22, 0.20, 0.20])\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n    plt.imshow(inp) \n```", "```py\nimshow(train[30][0])\n```", "```py\ntrain_data_generator = torch.utils.data.DataLoader(train,shuffle=True,batch_size=64,num_workers=8)\nvalid_data_generator = torch.utils.data.DataLoader(valid,batch_size=64,num_workers=8)\n```", "```py\npretrained_resnet = models.resnet18(pretrained=True)\nnumber_features = pretrained_resnet.fc.in_features\npretrained_resnet.fc = nn.Linear(number_features, 4)\n```", "```py\npretrained_resnet.fc = nn.Linear(number_features, 4)\n```", "```py\nif is_cuda:\n   pretrained_resnet = pretrained_resnet.cuda()\n```", "```py\nlearning_rate = 0.005\ncriterion = nn.CrossEntropyLoss()\nfit_optimizer = optim.SGD(pretrained_resnet.parameters(), lr=0.005, momentum=0.6)\nexp_learning_rate_scheduler = lr_scheduler.StepLR(fit_optimizer, step_size=2, gamma=0.05)\n```", "```py\ndef train_my_model(model, criterion, optimizer, scheduler, number_epochs=20):\n    since = time.time()\n    best_model_weights = model.state_dict()\n    best_accuracy = 0.0\n    for epoch in range(number_epochs):\n        print('Epoch {}/{}'.format(epoch, number_epochs - 1))\n        print('-' * 10)\n```", "```py\n        for each_phase in ['train', 'valid']:\n            if each_phase == 'train':\n                scheduler.step()\n                model.train(True) \n            else:\n                model.train(False)\n\n            running_loss = 0.0\n            running_corrects = 0\n```", "```py\n            for data in dataloaders[each_phase]:\n                input_data, label_data = data\n                if torch.cuda.is_available():\n                    input_data = Variable(inputs.cuda())\n                    label_data = Variable(labels.cuda())\n                else:\n                    input_data, label_data = Variable(input_data), Variable(label_data)\n                optimizer.zero_grad()  \n                outputs = model(input_data)\n                _, preds = torch.max(outputs.data, 1)\n                loss = criterion(outputs, label_data)\n                if each_phase == 'train':\n                    loss.backward()\n                    optimizer.step()\n                running_loss += loss.data[0]\n                running_corrects += torch.sum(preds == label_data.data)\n            epoch_loss = running_loss / dataset_sizes[each_phase]\n            epoch_acc = running_corrects / dataset_sizes[each_phase]\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(each_phase, epoch_loss, epoch_acc))\n            if each_phase == 'valid' and epoch_acc > best_acc:\n                best_accuracy = epoch_acc\n                best_model_weights = model.state_dict()\n        print()\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_accuracy))\n    model.load_state_dict(best_model_weights)\n    return model\n```", "```py\ntrain_my_model(pretrained_resnet, criterion, fit_optimizer, exp_learning_rate_scheduler, number_epochs=20)\n```"]