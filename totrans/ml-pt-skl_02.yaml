- en: '2'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Training Simple Machine Learning Algorithms for Classification
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will make use of two of the first algorithmically described
    machine learning algorithms for classification: the perceptron and adaptive linear
    neurons. We will start by implementing a perceptron step by step in Python and
    training it to classify different flower species in the Iris dataset. This will
    help us to understand the concept of machine learning algorithms for classification
    and how they can be efficiently implemented in Python.'
  prefs: []
  type: TYPE_NORMAL
- en: Discussing the basics of optimization using adaptive linear neurons will then
    lay the groundwork for using more sophisticated classifiers via the scikit-learn
    machine learning library in *Chapter 3*, *A Tour of Machine Learning Classifiers
    Using Scikit-Learn*.
  prefs: []
  type: TYPE_NORMAL
- en: 'The topics that we will cover in this chapter are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Building an understanding of machine learning algorithms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using pandas, NumPy, and Matplotlib to read in, process, and visualize data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing linear classifiers for 2-class problems in Python
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Artificial neurons – a brief glimpse into the early history of machine learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before we discuss the perceptron and related algorithms in more detail, let’s
    take a brief tour of the beginnings of machine learning. Trying to understand
    how the biological brain works in order to design an **artificial intelligence**
    (**AI**), Warren McCulloch and Walter Pitts published the first concept of a simplified
    brain cell, the so-called **McCulloch-Pitts** (**MCP**) neuron, in 1943 (*A Logical
    Calculus of the Ideas Immanent in Nervous Activity* by *W. S. McCulloch* and *W.
    Pitts*, *Bulletin of Mathematical Biophysics*, 5(4): 115-133, 1943).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Biological neurons are interconnected nerve cells in the brain that are involved
    in the processing and transmitting of chemical and electrical signals, which is
    illustrated in *Figure 2.1*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram  Description automatically generated](img/B17582_02_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.1: A neuron processing chemical and electrical signals'
  prefs: []
  type: TYPE_NORMAL
- en: McCulloch and Pitts described such a nerve cell as a simple logic gate with
    binary outputs; multiple signals arrive at the dendrites, they are then integrated
    into the cell body, and, if the accumulated signal exceeds a certain threshold,
    an output signal is generated that will be passed on by the axon.
  prefs: []
  type: TYPE_NORMAL
- en: 'Only a few years later, Frank Rosenblatt published the first concept of the
    perceptron learning rule based on the MCP neuron model (*The Perceptron: A Perceiving
    and Recognizing Automaton* by *F. Rosenblatt*, *Cornell Aeronautical Laboratory*,
    1957). With his perceptron rule, Rosenblatt proposed an algorithm that would automatically
    learn the optimal weight coefficients that would then be multiplied with the input
    features in order to make the decision of whether a neuron fires (transmits a
    signal) or not. In the context of supervised learning and classification, such
    an algorithm could then be used to predict whether a new data point belongs to
    one class or the other.'
  prefs: []
  type: TYPE_NORMAL
- en: The formal definition of an artificial neuron
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'More formally, we can put the idea behind **artificial neurons** into the context
    of a binary classification task with two classes: 0 and 1\. We can then define
    a decision function, ![](img/B17582_02_001.png), that takes a linear combination
    of certain input values, *x*, and a corresponding weight vector, *w*, where *z*
    is the so-called net input *z* = *w*[1]*x*[1] + *w*[2]*x*[2] + ... + *w*[m]*x*[m]:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_02_002.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now, if the net input of a particular example, **x**^(^i^), is greater than
    a defined threshold, ![](img/B17582_02_003.png), we predict class 1, and class
    0 otherwise. In the perceptron algorithm, the decision function, ![](img/B17582_02_004.png),
    is a variant of a **unit step function**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_02_005.png)'
  prefs: []
  type: TYPE_IMG
- en: 'To simplify the code implementation later, we can modify this setup via a couple
    of steps. First, we move the threshold, ![](img/B17582_02_006.png), to the left
    side of the equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_02_007.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Second, we define a so-called *bias unit* as ![](img/B17582_02_008.png) and
    make it part of the net input:'
  prefs: []
  type: TYPE_NORMAL
- en: '*z* = *w*[1]*x*[1] + ... + *w*[m]*x*[m] + *b* = **w**^T**x** + *b*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Third, given the introduction of the bias unit and the redefinition of the
    net input *z* above, we can redefine the decision function as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_02_009.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Linear algebra basics: dot product and matrix transpose**'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following sections, we will often make use of basic notations from linear
    algebra. For example, we will abbreviate the sum of the products of the values
    in **x** and **w** using a vector dot product, whereas the superscript *T* stands
    for transpose, which is an operation that transforms a column vector into a row
    vector and vice versa. For example, assume we have the following two column vectors:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_02_010.png)'
  prefs: []
  type: TYPE_IMG
- en: Then, we can write the transpose of vector **a** as **a**^T = [*a*[1] *a*[2] *a*[3]]
    and write the dot product as
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_02_011.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Furthermore, the transpose operation can also be applied to matrices to reflect
    it over its diagonal, for example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_02_012.png)'
  prefs: []
  type: TYPE_IMG
- en: Please note that the transpose operation is strictly only defined for matrices;
    however, in the context of machine learning, we refer to *n* × 1 or 1 × *m* matrices
    when we use the term “vector.”
  prefs: []
  type: TYPE_NORMAL
- en: In this book, we will only use very basic concepts from linear algebra; however,
    if you need a quick refresher, please take a look at Zico Kolter’s excellent *Linear
    Algebra Review and Reference*, which is freely available at [http://www.cs.cmu.edu/~zkolter/course/linalg/linalg_notes.pdf](http://www.cs.cmu.edu/~zkolter/course/linalg/linalg_notes.pdf).
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 2.2* illustrates how the net input *z* = **w**^T**x** + *b* is squashed
    into a binary output (0 or 1) by the decision function of the perceptron (left
    subfigure) and how it can be used to discriminate between two classes separable
    by a linear decision boundary (right subfigure):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Chart, scatter chart  Description automatically generated](img/B17582_02_02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.2: A threshold function producing a linear decision boundary for a
    binary classification problem'
  prefs: []
  type: TYPE_NORMAL
- en: The perceptron learning rule
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The whole idea behind the MCP neuron and Rosenblatt’s *thresholded* perceptron
    model is to use a reductionist approach to mimic how a single neuron in the brain
    works: it either *fires* or it doesn’t. Thus, Rosenblatt’s classic perceptron
    rule is fairly simple, and the perceptron algorithm can be summarized by the following
    steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Initialize the weights and bias unit to 0 or small random numbers
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For each training example, **x**^(^i^):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compute the output value, ![](img/B17582_02_013.png)
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Update the weights and bias unit
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Here, the output value is the class label predicted by the unit step function
    that we defined earlier, and the simultaneous update of the bias unit and each
    weight, *w*[j], in the weight vector, **w**, can be more formally written as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_02_014.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The update values (“deltas”) are computed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_02_015.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Note that unlike the bias unit, each weight, *w*[j], corresponds to a feature,
    *x*[j], in the dataset, which is involved in determining the update value, ![](img/B17582_02_016.png),
    defined above. Furthermore, ![](img/B17582_02_017.png) is the **learning rate**
    (typically a constant between 0.0 and 1.0), *y*^(^i^) is the **true class label**
    of the *i*th training example, and ![](img/B17582_02_018.png) is the **predicted
    class label**. It is important to note that the bias unit and all weights in the
    weight vector are being updated simultaneously, which means that we don’t recompute
    the predicted label, ![](img/B17582_02_019.png), before the bias unit and all
    of the weights are updated via the respective update values, ![](img/B17582_02_020.png)
    and ![](img/B17582_02_021.png). Concretely, for a two-dimensional dataset, we
    would write the update as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_02_022.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Before we implement the perceptron rule in Python, let’s go through a simple
    thought experiment to illustrate how beautifully simple this learning rule really
    is. In the two scenarios where the perceptron predicts the class label correctly,
    the bias unit and weights remain unchanged, since the update values are 0:'
  prefs: []
  type: TYPE_NORMAL
- en: (1) ![](img/B17582_02_023.png)
  prefs: []
  type: TYPE_NORMAL
- en: (2) ![](img/B17582_02_024.png)
  prefs: []
  type: TYPE_NORMAL
- en: 'However, in the case of a wrong prediction, the weights are being pushed toward
    the direction of the positive or negative target class:'
  prefs: []
  type: TYPE_NORMAL
- en: (3) ![](img/B17582_02_025.png)
  prefs: []
  type: TYPE_NORMAL
- en: (4) ![](img/B17582_02_026.png)
  prefs: []
  type: TYPE_NORMAL
- en: 'To get a better understanding of the feature value as a multiplicative factor,
    ![](img/B17582_02_027.png), let’s go through another simple example, where:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_02_028.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let’s assume that ![](img/B17582_02_029.png) and we misclassify this example
    as *class 0*. In this case, we would increase the corresponding weight by 2.5
    in total so that the net input, ![](img/B17582_02_030.png), would be more positive
    the next time we encounter this example, and thus be more likely to be above the
    threshold of the unit step function to classify the example as *class 1*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_02_031.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The weight update, ![](img/B17582_02_032.png), is proportional to the value
    of ![](img/B17582_02_027.png). For instance, if we have another example, ![](img/B17582_02_034.png),
    that is incorrectly classified as *class 0*, we will push the decision boundary
    by an even larger extent to classify this example correctly the next time:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_02_035.png)'
  prefs: []
  type: TYPE_IMG
- en: 'It is important to note that the convergence of the perceptron is only guaranteed
    if the two classes are linearly separable, which means that the two classes cannot
    be perfectly separated by a linear decision boundary. (Interested readers can
    find the convergence proof in my lecture notes: [https://sebastianraschka.com/pdf/lecture-notes/stat453ss21/L03_perceptron_slides.pdf](https://sebastianraschka.com/pdf/lecture-notes/stat453ss21/L03_perceptron_slides.pdf)).
    *Figure 2.3* shows visual examples of linearly separable and linearly inseparable
    scenarios:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Chart, scatter chart  Description automatically generated](img/B17582_02_03.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.3: Examples of linearly and nonlinearly separable classes'
  prefs: []
  type: TYPE_NORMAL
- en: If the two classes can’t be separated by a linear decision boundary, we can
    set a maximum number of passes over the training dataset (**epochs**) and/or a
    threshold for the number of tolerated misclassifications—the perceptron would
    never stop updating the weights otherwise. Later in this chapter, we will cover
    the Adaline algorithm that produces linear decision boundaries and converges even
    if the classes are not perfectly linearly separable. In *Chapter 3*, we will learn
    about algorithms that can produce nonlinear decision boundaries.
  prefs: []
  type: TYPE_NORMAL
- en: '**Downloading the example code**'
  prefs: []
  type: TYPE_NORMAL
- en: If you bought this book directly from Packt, you can download the example code
    files from your account at [http://www.packtpub.com](http://www.packtpub.com).
    If you purchased this book elsewhere, you can download all code examples and datasets
    directly from [https://github.com/rasbt/machine-learning-book](https://github.com/rasbt/machine-learning-book).
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, before we jump into the implementation in the next section, what you just
    learned can be summarized in a simple diagram that illustrates the general concept
    of the perceptron:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram  Description automatically generated](img/B17582_02_04.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.4: Weights and bias of the model are updated based on the error function'
  prefs: []
  type: TYPE_NORMAL
- en: The preceding diagram illustrates how the perceptron receives the inputs of
    an example (**x**) and combines them with the bias unit (**b**) and weights (**w**)
    to compute the net input. The net input is then passed on to the threshold function,
    which generates a binary output of 0 or 1—the predicted class label of the example.
    During the learning phase, this output is used to calculate the error of the prediction
    and update the weights and bias unit.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing a perceptron learning algorithm in Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous section, we learned how Rosenblatt’s perceptron rule works;
    let’s now implement it in Python and apply it to the Iris dataset that we introduced
    in *Chapter 1*, *Giving Computers the Ability to Learn from Data*.
  prefs: []
  type: TYPE_NORMAL
- en: An object-oriented perceptron API
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will take an object-oriented approach to defining the perceptron interface
    as a Python class, which will allow us to initialize new `Perceptron` objects
    that can learn from data via a `fit` method and make predictions via a separate
    `predict` method. As a convention, we append an underscore (`_`) to attributes
    that are not created upon the initialization of the object, but we do this by
    calling the object’s other methods, for example, `self.w_`.
  prefs: []
  type: TYPE_NORMAL
- en: '**Additional resources for Python’s scientific computing stack**'
  prefs: []
  type: TYPE_NORMAL
- en: 'If you are not yet familiar with Python’s scientific libraries or need a refresher,
    please see the following resources:'
  prefs: []
  type: TYPE_NORMAL
- en: '**NumPy**: [https://sebastianraschka.com/blog/2020/numpy-intro.html](https://sebastianraschka.com/blog/2020/numpy-intro.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**pandas**: [https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html](https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Matplotlib**: [https://matplotlib.org/stable/tutorials/introductory/usage.html](https://matplotlib.org/stable/tutorials/introductory/usage.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following is the implementation of a perceptron in Python:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Using this perceptron implementation, we can now initialize new `Perceptron`
    objects with a given learning rate, `eta` (![](img/B17582_02_036.png)), and the
    number of epochs, `n_iter` (passes over the training dataset).
  prefs: []
  type: TYPE_NORMAL
- en: Via the `fit` method, we initialize the bias `self.b_` to an initial value 0
    and the weights in `self.w_` to a vector, ![](img/B17582_02_037.png), where *m*
    stands for the number of dimensions (features) in the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Notice that the initial weight vector contains small random numbers drawn from
    a normal distribution with a standard deviation of 0.01 via `rgen.normal(loc=0.0,
    scale=0.01, size=1 + X.shape[1])`, where `rgen` is a NumPy random number generator
    that we seeded with a user-specified random seed so that we can reproduce previous
    results if desired.
  prefs: []
  type: TYPE_NORMAL
- en: 'Technically, we could initialize the weights to zero (in fact, this is done
    in the original perceptron algorithm). However, if we did that, then the learning
    rate ![](img/B17582_02_036.png) (`eta`) would have no effect on the decision boundary.
    If all the weights are initialized to zero, the learning rate parameter, `eta`,
    affects only the scale of the weight vector, not the direction. If you are familiar
    with trigonometry, consider a vector, *v*1 =[1 2 3], where the angle between *v*1
    and a vector, *v*2 = 0.5 × *v*1, would be exactly zero, as demonstrated by the
    following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Here, `np.arccos` is the trigonometric inverse cosine, and `np.linalg.norm`
    is a function that computes the length of a vector. (Our decision to draw the
    random numbers from a random normal distribution—for example, instead of from
    a uniform distribution—and to use a standard deviation of `0.01` was arbitrary;
    remember, we are just interested in small random values to avoid the properties
    of all-zero vectors, as discussed earlier.)
  prefs: []
  type: TYPE_NORMAL
- en: As an optional exercise after reading this chapter, you can change `self.w_
    = rgen.normal(loc=0.0, scale=0.01, size=X.shape[1])` to `self.w_ = np.zeros(X.shape[1])`
    and run the perceptron training code presented in the next section with different
    values for `eta`. You will observe that the decision boundary does not change.
  prefs: []
  type: TYPE_NORMAL
- en: '**NumPy array indexing**'
  prefs: []
  type: TYPE_NORMAL
- en: NumPy indexing for one-dimensional arrays works similarly to Python lists using
    the square-bracket (`[]`) notation. For two-dimensional arrays, the first indexer
    refers to the row number and the second indexer to the column number. For example,
    we would use `X[2, 3]` to select the third row and fourth column of a two-dimensional
    array, `X`.
  prefs: []
  type: TYPE_NORMAL
- en: After the weights have been initialized, the `fit` method loops over all individual
    examples in the training dataset and updates the weights according to the perceptron
    learning rule that we discussed in the previous section.
  prefs: []
  type: TYPE_NORMAL
- en: The class labels are predicted by the `predict` method, which is called in the
    `fit` method during training to get the class label for the weight update; but
    `predict` can also be used to predict the class labels of new data after we have
    fitted our model. Furthermore, we also collect the number of misclassifications
    during each epoch in the `self.errors_` list so that we can later analyze how
    well our perceptron performed during the training. The `np.dot` function that
    is used in the `net_input` method simply calculates the vector dot product, **w**^T**x** + *b*.
  prefs: []
  type: TYPE_NORMAL
- en: '**Vectorization: Replacing for loops with vectorized code**'
  prefs: []
  type: TYPE_NORMAL
- en: Instead of using NumPy to calculate the vector dot product between two arrays,
    `a` and `b`, via `a.dot(b)` or `np.dot(a, b)`, we could also perform the calculation
    in pure Python via `sum([i * j for i, j in zip(a, b)])`. However, the advantage
    of using NumPy over classic Python `for` loop structures is that its arithmetic
    operations are vectorized. Vectorization means that an elemental arithmetic operation
    is automatically applied to all elements in an array. By formulating our arithmetic
    operations as a sequence of instructions on an array, rather than performing a
    set of operations for each element at a time, we can make better use of our modern
    **central processing unit** (**CPU**) architectures with **single instruction,
    multiple data** (**SIMD**) support. Furthermore, NumPy uses highly optimized linear
    algebra libraries, such as **Basic Linear Algebra Subprograms** (**BLAS**) and
    **Linear Algebra Package** (**LAPACK**), that have been written in C or Fortran.
    Lastly, NumPy also allows us to write our code in a more compact and intuitive
    way using the basics of linear algebra, such as vector and matrix dot products.
  prefs: []
  type: TYPE_NORMAL
- en: Training a perceptron model on the Iris dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To test our perceptron implementation, we will restrict the following analyses
    and examples in the remainder of this chapter to two feature variables (dimensions).
    Although the perceptron rule is not restricted to two dimensions, considering
    only two features, sepal length and petal length, will allow us to visualize the
    decision regions of the trained model in a scatterplot for learning purposes.
  prefs: []
  type: TYPE_NORMAL
- en: Note that we will also only consider two flower classes, setosa and versicolor,
    from the Iris dataset for practical reasons—remember, the perceptron is a binary
    classifier. However, the perceptron algorithm can be extended to multi-class classification—for
    example, the **one-versus-all** (**OvA**) technique.
  prefs: []
  type: TYPE_NORMAL
- en: '**The OvA method for multi-class classification**'
  prefs: []
  type: TYPE_NORMAL
- en: OvA, which is sometimes also called **one-versus-rest** (**OvR**), is a technique
    that allows us to extend any binary classifier to multi-class problems. Using
    OvA, we can train one classifier per class, where the particular class is treated
    as the positive class and the examples from all other classes are considered negative
    classes. If we were to classify a new, unlabeled data instance, we would use our
    *n* classifiers, where *n* is the number of class labels, and assign the class
    label with the highest confidence to the particular instance we want to classify.
    In the case of the perceptron, we would use OvA to choose the class label that
    is associated with the largest absolute net input value.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we will use the `pandas` library to load the Iris dataset directly from
    the *UCI Machine Learning Repository* into a `DataFrame` object and print the
    last five lines via the `tail` method to check that the data was loaded correctly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'After executing the previous code, we should see the following output, which
    shows the last five lines of the Iris dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '![A picture containing calendar  Description automatically generated](img/B17582_02_05.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.5: The last five lines of the Iris dataset'
  prefs: []
  type: TYPE_NORMAL
- en: '**Loading the Iris dataset**'
  prefs: []
  type: TYPE_NORMAL
- en: You can find a copy of the Iris dataset (and all other datasets used in this
    book) in the code bundle of this book, which you can use if you are working offline
    or if the UCI server at [https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data](https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data)
    is temporarily unavailable. For instance, to load the Iris dataset from a local
    directory, you can replace this line,
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'with the following one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Next, we extract the first 100 class labels that correspond to the 50 Iris-setosa
    and 50 Iris-versicolor flowers and convert the class labels into the two integer
    class labels, `1` (versicolor) and `0` (setosa), that we assign to a vector, `y`,
    where the `values` method of a pandas `DataFrame` yields the corresponding NumPy
    representation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Similarly, we extract the first feature column (sepal length) and the third
    feature column (petal length) of those 100 training examples and assign them to
    a feature matrix, `X`, which we can visualize via a two-dimensional scatterplot:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'After executing the preceding code example, we should see the following scatterplot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Chart, scatter chart  Description automatically generated](img/B17582_02_06.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.6: Scatterplot of setosa and versicolor flowers by sepal and petal
    length'
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 2.6* shows the distribution of flower examples in the Iris dataset
    along the two feature axes: petal length and sepal length (measured in centimeters).
    In this two-dimensional feature subspace, we can see that a linear decision boundary
    should be sufficient to separate setosa from versicolor flowers. Thus, a linear
    classifier such as the perceptron should be able to classify the flowers in this
    dataset perfectly.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, it’s time to train our perceptron algorithm on the Iris data subset that
    we just extracted. Also, we will plot the misclassification error for each epoch
    to check whether the algorithm converged and found a decision boundary that separates
    the two Iris flower classes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that the number of misclassification errors and the number of updates
    is the same, since the perceptron weights and bias are updated each time it misclassifies
    an example. After executing the preceding code, we should see the plot of the
    misclassification errors versus the number of epochs, as shown in *Figure 2.7*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_02_07.png)Figure 2.7: A plot of the misclassification errors
    against the number of epochs'
  prefs: []
  type: TYPE_NORMAL
- en: 'As we can see in *Figure 2.7*, our perceptron converged after the sixth epoch
    and should now be able to classify the training examples perfectly. Let’s implement
    a small convenience function to visualize the decision boundaries for two-dimensional
    datasets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: First, we define a number of `colors` and `markers` and create a colormap from
    the list of colors via `ListedColormap`. Then, we determine the minimum and maximum
    values for the two features and use those feature vectors to create a pair of
    grid arrays, `xx1` and `xx2`, via the NumPy `meshgrid` function. Since we trained
    our perceptron classifier on two feature dimensions, we need to flatten the grid
    arrays and create a matrix that has the same number of columns as the Iris training
    subset so that we can use the `predict` method to predict the class labels, `lab`,
    of the corresponding grid points.
  prefs: []
  type: TYPE_NORMAL
- en: 'After reshaping the predicted class labels, `lab`, into a grid with the same
    dimensions as `xx1` and `xx2`, we can now draw a contour plot via Matplotlib’s
    `contourf` function, which maps the different decision regions to different colors
    for each predicted class in the grid array:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'After executing the preceding code example, we should now see a plot of the
    decision regions, as shown in *Figure 2.8*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Chart, scatter chart  Description automatically generated](img/B17582_02_08.png)Figure
    2.8: A plot of the perceptron’s decision regions'
  prefs: []
  type: TYPE_NORMAL
- en: As we can see in the plot, the perceptron learned a decision boundary that can
    classify all flower examples in the Iris training subset perfectly.
  prefs: []
  type: TYPE_NORMAL
- en: '**Perceptron convergence**'
  prefs: []
  type: TYPE_NORMAL
- en: Although the perceptron classified the two Iris flower classes perfectly, convergence
    is one of the biggest problems of the perceptron. Rosenblatt proved mathematically
    that the perceptron learning rule converges if the two classes can be separated
    by a linear hyperplane. However, if the classes cannot be separated perfectly
    by such a linear decision boundary, the weights will never stop updating unless
    we set a maximum number of epochs. Interested readers can find a summary of the
    proof in my lecture notes at [https://sebastianraschka.com/pdf/lecture-notes/stat453ss21/L03_perceptron_slides.pdf](https://sebastianraschka.com/pdf/lecture-notes/stat453ss21/L03_perceptron_slides.pdf).
  prefs: []
  type: TYPE_NORMAL
- en: Adaptive linear neurons and the convergence of learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we will take a look at another type of single-layer **neural
    network** (**NN**): **ADAptive LInear NEuron** (**Adaline**). Adaline was published
    by Bernard Widrow and his doctoral student Tedd Hoff only a few years after Rosenblatt’s
    perceptron algorithm, and it can be considered an improvement on the latter (*An
    Adaptive “Adaline” Neuron Using Chemical “Memistors”*, *Technical Report Number
    1553-2* by *B. Widrow and colleagues*, *Stanford Electron Labs*, Stanford, CA,
    *October* 1960).'
  prefs: []
  type: TYPE_NORMAL
- en: The Adaline algorithm is particularly interesting because it illustrates the
    key concepts of defining and minimizing continuous loss functions. This lays the
    groundwork for understanding other machine learning algorithms for classification,
    such as logistic regression, support vector machines, and multilayer neural networks,
    as well as linear regression models, which we will discuss in future chapters.
  prefs: []
  type: TYPE_NORMAL
- en: The key difference between the Adaline rule (also known as the **Widrow-Hoff
    rule**) and Rosenblatt’s perceptron is that the weights are updated based on a
    linear activation function rather than a unit step function like in the perceptron.
    In Adaline, this linear activation function, ![](img/B17582_02_039.png), is simply
    the identity function of the net input, so that ![](img/B17582_02_040.png).
  prefs: []
  type: TYPE_NORMAL
- en: While the linear activation function is used for learning the weights, we still
    use a threshold function to make the final prediction, which is similar to the
    unit step function that we covered earlier.
  prefs: []
  type: TYPE_NORMAL
- en: 'The main differences between the perceptron and Adaline algorithm are highlighted
    in *Figure 2.9*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram  Description automatically generated](img/B17582_02_09.png)Figure
    2.9: A comparison between a perceptron and the Adaline algorithm'
  prefs: []
  type: TYPE_NORMAL
- en: As *Figure 2.9* indicates, the Adaline algorithm compares the true class labels
    with the linear activation function’s continuous valued output to compute the
    model error and update the weights. In contrast, the perceptron compares the true
    class labels to the predicted class labels.
  prefs: []
  type: TYPE_NORMAL
- en: Minimizing loss functions with gradient descent
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'One of the key ingredients of supervised machine learning algorithms is a defined
    **objective function** that is to be optimized during the learning process. This
    objective function is often a loss or cost function that we want to minimize.
    In the case of Adaline, we can define the loss function, *L*, to learn the model
    parameters as the **mean squared error** (**MSE**) between the calculated outcome
    and the true class label:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_02_041.png)'
  prefs: []
  type: TYPE_IMG
- en: The term ![](img/B17582_02_042.png) is just added for our convenience and will
    make it easier to derive the gradient of the loss function with respect to the
    weight parameters, as we will see in the following paragraphs. The main advantage
    of this continuous linear activation function, in contrast to the unit step function,
    is that the loss function becomes differentiable. Another nice property of this
    loss function is that it is convex; thus, we can use a very simple yet powerful
    optimization algorithm called **gradient descent** to find the weights that minimize
    our loss function to classify the examples in the Iris dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'As illustrated in *Figure 2.10*, we can describe the main idea behind gradient
    descent as *climbing down a hill* until a local or global loss minimum is reached.
    In each iteration, we take a step in the opposite direction of the gradient, where
    the step size is determined by the value of the learning rate, as well as the
    slope of the gradient (for simplicity, the following figure visualizes this only
    for a single weight, *w*):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram  Description automatically generated](img/B17582_02_10.png)Figure
    2.10: How gradient descent works'
  prefs: []
  type: TYPE_NORMAL
- en: 'Using gradient descent, we can now update the model parameters by taking a
    step in the opposite direction of the gradient, ![](img/B17582_02_043.png), of
    our loss function, *L*(**w**, *b*):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_02_044.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The parameter changes, ![](img/B17582_02_045.png) and ![](img/B17582_02_046.png),
    are defined as the negative gradient multiplied by the learning rate, ![](img/B17582_02_036.png):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_02_048.png)'
  prefs: []
  type: TYPE_IMG
- en: 'To compute the gradient of the loss function, we need to compute the partial
    derivative of the loss function with respect to each weight, *w*[j]:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_02_049.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Similarly, we compute the partial derivative of the loss with respect to the
    bias as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_02_050.png)'
  prefs: []
  type: TYPE_IMG
- en: Please note that the 2 in the numerator above is merely a constant scaling factor,
    and we could omit it without affecting the algorithm. Removing the scaling factor
    has the same effect as changing the learning rate by a factor of 2\. The following
    information box explains where this scaling factor originates.
  prefs: []
  type: TYPE_NORMAL
- en: 'So we can write the weight update as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_02_051.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Since we update all parameters simultaneously, our Adaline learning rule becomes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_02_052.png)'
  prefs: []
  type: TYPE_IMG
- en: '**The mean squared error derivative**'
  prefs: []
  type: TYPE_NORMAL
- en: 'If you are familiar with calculus, the partial derivative of the MSE loss function
    with respect to the *j*th weight can be obtained as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_02_053.png)'
  prefs: []
  type: TYPE_IMG
- en: The same approach can be used to find partial derivative ![](img/B17582_02_054.png)
    except that ![](img/B17582_02_055.png) is equal to –1 and thus the last step simplifies
    to ![](img/B17582_02_056.png).
  prefs: []
  type: TYPE_NORMAL
- en: Although the Adaline learning rule looks identical to the perceptron rule, we
    should note that ![](img/B17582_02_057.png) with ![](img/B17582_02_058.png) is
    a real number and not an integer class label. Furthermore, the weight update is
    calculated based on all examples in the training dataset (instead of updating
    the parameters incrementally after each training example), which is why this approach
    is also referred to as **batch gradient descent**. To be more explicit and avoid
    confusion when talking about related concepts later in this chapter and this book,
    we will refer to this process as **full batch gradient descent**.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing Adaline in Python
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Since the perceptron rule and Adaline are very similar, we will take the perceptron
    implementation that we defined earlier and change the `fit` method so that the
    weight and bias parameters are now updated by minimizing the loss function via
    gradient descent:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Instead of updating the weights after evaluating each individual training example,
    as in the perceptron, we calculate the gradient based on the whole training dataset.
    For the bias unit, this is done via `self.eta * 2.0 * errors.mean()`, where `errors`
    is an array containing the partial derivative values ![](img/B17582_02_059.png).
    Similarly, we update the weights. However note that the weight updates via the
    partial derivatives ![](img/B17582_02_060.png) involve the feature values *x*[j],
    which we can compute by multiplying `errors` with each feature value for each
    weight:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'To implement the weight update more efficiently without using a `for` loop,
    we can use a matrix-vector multiplication between our feature matrix and the error
    vector instead:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Please note that the `activation` method has no effect on the code since it
    is simply an identity function. Here, we added the activation function (computed
    via the `activation` method) to illustrate the general concept with regard to
    how information flows through a single-layer NN: features from the input data,
    net input, activation, and output.'
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will learn about a logistic regression classifier that
    uses a non-identity, nonlinear activation function. We will see that a logistic
    regression model is closely related to Adaline, with the only difference being
    its activation and loss function.
  prefs: []
  type: TYPE_NORMAL
- en: Now, similar to the previous perceptron implementation, we collect the loss
    values in a `self.losses_` list to check whether the algorithm converged after
    training.
  prefs: []
  type: TYPE_NORMAL
- en: '**Matrix multiplication**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Performing a matrix multiplication is similar to calculating a vector dot-product
    where each row in the matrix is treated as a single row vector. This vectorized
    approach represents a more compact notation and results in a more efficient computation
    using NumPy. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_02_061.png)'
  prefs: []
  type: TYPE_IMG
- en: Please note that in the preceding equation, we are multiplying a matrix with
    a vector, which is mathematically not defined. However, remember that we use the
    convention that this preceding vector is regarded as a 3×1 matrix.
  prefs: []
  type: TYPE_NORMAL
- en: In practice, it often requires some experimentation to find a good learning
    rate, ![](img/B17582_02_036.png), for optimal convergence. So, let’s choose two
    different learning rates, ![](img/B17582_02_063.png) and ![](img/B17582_02_064.png),
    to start with and plot the loss functions versus the number of epochs to see how
    well the Adaline implementation learns from the training data.
  prefs: []
  type: TYPE_NORMAL
- en: '**Hyperparameters**'
  prefs: []
  type: TYPE_NORMAL
- en: The learning rate, ![](img/B17582_02_065.png) (`eta`), as well as the number
    of epochs (`n_iter`), are the so-called hyperparameters (or tuning parameters)
    of the perceptron and Adaline learning algorithms. In *Chapter 6*, *Learning Best
    Practices for Model Evaluation and Hyperparameter Tuning*, we will take a look
    at different techniques to automatically find the values of different hyperparameters
    that yield optimal performance of the classification model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s now plot the loss against the number of epochs for the two different
    learning rates:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'As we can see in the resulting loss function plots, we encountered two different
    types of problems. The left chart shows what could happen if we choose a learning
    rate that is too large. Instead of minimizing the loss function, the MSE becomes
    larger in every epoch, because we *overshoot* the global minimum. On the other
    hand, we can see that the loss decreases on the right plot, but the chosen learning
    rate, ![](img/B17582_02_064.png), is so small that the algorithm would require
    a very large number of epochs to converge to the global loss minimum:'
  prefs: []
  type: TYPE_NORMAL
- en: '![A picture containing icon  Description automatically generated](img/B17582_02_11.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.11: Error plots for suboptimal learning rates'
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 2.12* illustrates what might happen if we change the value of a particular
    weight parameter to minimize the loss function, *L*. The left subfigure illustrates
    the case of a well-chosen learning rate, where the loss decreases gradually, moving
    in the direction of the global minimum.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The subfigure on the right, however, illustrates what happens if we choose
    a learning rate that is too large—we overshoot the global minimum:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram  Description automatically generated](img/B17582_02_12.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.12: A comparison of a well-chosen learning rate and a learning rate
    that is too large'
  prefs: []
  type: TYPE_NORMAL
- en: Improving gradient descent through feature scaling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Many machine learning algorithms that we will encounter throughout this book
    require some sort of feature scaling for optimal performance, which we will discuss
    in more detail in *Chapter 3*, *A Tour of Machine Learning Classifiers Using Scikit-Learn*,
    and *Chapter 4*, *Building Good Training Datasets – Data Preprocessing*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Gradient descent is one of the many algorithms that benefit from feature scaling.
    In this section, we will use a feature scaling method called **standardization**.
    This normalization procedure helps gradient descent learning to converge more
    quickly; however, it does not make the original dataset normally distributed.
    Standardization shifts the mean of each feature so that it is centered at zero
    and each feature has a standard deviation of 1 (unit variance). For instance,
    to standardize the *j*th feature, we can simply subtract the sample mean, ![](img/B17582_02_067.png),
    from every training example and divide it by its standard deviation, ![](img/B17582_02_068.png):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_02_069.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, *x*[j] is a vector consisting of the *j*th feature values of all training
    examples, *n*, and this standardization technique is applied to each feature,
    *j*, in our dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'One of the reasons why standardization helps with gradient descent learning
    is that it is easier to find a learning rate that works well for all weights (and
    the bias). If the features are on vastly different scales, a learning rate that
    works well for updating one weight might be too large or too small to update the
    other weight equally well. Overall, using standardized features can stabilize
    the training such that the optimizer has to go through fewer steps to find a good
    or optimal solution (the global loss minimum). *Figure 2.13* illustrates possible
    gradient updates with unscaled features (left) and standardized features (right),
    where the concentric circles represent the loss surface as a function of two model
    weights in a two-dimensional classification problem:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram, engineering drawing  Description automatically generated](img/B17582_02_13.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.13: A comparison of unscaled and standardized features on gradient
    updates'
  prefs: []
  type: TYPE_NORMAL
- en: 'Standardization can easily be achieved by using the built-in NumPy methods
    `mean` and `std`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'After standardization, we will train Adaline again and see that it now converges
    after a small number of epochs using a learning rate of ![](img/B17582_02_070.png):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'After executing this code, we should see a figure of the decision regions,
    as well as a plot of the declining loss, as shown in *Figure 2.14*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Chart  Description automatically generated](img/B17582_02_14.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.14: Plots of Adaline’s decision regions and MSE by number of epochs'
  prefs: []
  type: TYPE_NORMAL
- en: As we can see in the plots, Adaline has now converged after training on the
    standardized features. However, note that the MSE remains non-zero even though
    all flower examples were classified correctly.
  prefs: []
  type: TYPE_NORMAL
- en: Large-scale machine learning and stochastic gradient descent
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the previous section, we learned how to minimize a loss function by taking
    a step in the opposite direction of the loss gradient that is calculated from
    the whole training dataset; this is why this approach is sometimes also referred
    to as full batch gradient descent. Now imagine that we have a very large dataset
    with millions of data points, which is not uncommon in many machine learning applications.
    Running full batch gradient descent can be computationally quite costly in such
    scenarios, since we need to reevaluate the whole training dataset each time we
    take one step toward the global minimum.
  prefs: []
  type: TYPE_NORMAL
- en: 'A popular alternative to the batch gradient descent algorithm is **stochastic
    gradient descent** (**SGD**), which is sometimes also called iterative or online
    gradient descent. Instead of updating the weights based on the sum of the accumulated
    errors over all training examples, **x**^(^i^):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_02_071.png)'
  prefs: []
  type: TYPE_IMG
- en: 'we update the parameters incrementally for each training example, for instance:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_02_072.png)'
  prefs: []
  type: TYPE_IMG
- en: Although SGD can be considered as an approximation of gradient descent, it typically
    reaches convergence much faster because of the more frequent weight updates. Since
    each gradient is calculated based on a single training example, the error surface
    is noisier than in gradient descent, which can also have the advantage that SGD
    can escape shallow local minima more readily if we are working with nonlinear
    loss functions, as we will see later in *Chapter 11*, *Implementing a Multilayer
    Artificial Neural Network from Scratch*. To obtain satisfying results via SGD,
    it is important to present training data in a random order; also, we want to shuffle
    the training dataset for every epoch to prevent cycles.
  prefs: []
  type: TYPE_NORMAL
- en: '**Adjusting the learning rate during training**'
  prefs: []
  type: TYPE_NORMAL
- en: 'In SGD implementations, the fixed learning rate, ![](img/B17582_02_065.png),
    is often replaced by an adaptive learning rate that decreases over time, for example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17582_02_074.png)'
  prefs: []
  type: TYPE_IMG
- en: where *c*[1] and *c*[2] are constants. Note that SGD does not reach the global
    loss minimum but an area very close to it. And using an adaptive learning rate,
    we can achieve further annealing to the loss minimum.
  prefs: []
  type: TYPE_NORMAL
- en: Another advantage of SGD is that we can use it for **online learning**. In online
    learning, our model is trained on the fly as new training data arrives. This is
    especially useful if we are accumulating large amounts of data, for example, customer
    data in web applications. Using online learning, the system can immediately adapt
    to changes, and the training data can be discarded after updating the model if
    storage space is an issue.
  prefs: []
  type: TYPE_NORMAL
- en: '**Mini-batch gradient descent**'
  prefs: []
  type: TYPE_NORMAL
- en: A compromise between full batch gradient descent and SGD is so-called **mini-batch
    gradient descent**. Mini-batch gradient descent can be understood as applying
    full batch gradient descent to smaller subsets of the training data, for example,
    32 training examples at a time. The advantage over full batch gradient descent
    is that convergence is reached faster via mini-batches because of the more frequent
    weight updates. Furthermore, mini-batch learning allows us to replace the `for`
    loop over the training examples in SGD with vectorized operations leveraging concepts
    from linear algebra (for example, implementing a weighted sum via a dot product),
    which can further improve the computational efficiency of our learning algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since we already implemented the Adaline learning rule using gradient descent,
    we only need to make a few adjustments to modify the learning algorithm to update
    the weights via SGD. Inside the `fit` method, we will now update the weights after
    each training example. Furthermore, we will implement an additional `partial_fit`
    method, which does not reinitialize the weights, for online learning. In order
    to check whether our algorithm converged after training, we will calculate the
    loss as the average loss of the training examples in each epoch. Furthermore,
    we will add an option to shuffle the training data before each epoch to avoid
    repetitive cycles when we are optimizing the loss function; via the `random_state`
    parameter, we allow the specification of a random seed for reproducibility:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The `_shuffle` method that we are now using in the `AdalineSGD` classifier
    works as follows: via the `permutation` function in `np.random`, we generate a
    random sequence of unique numbers in the range 0 to 100\. Those numbers can then
    be used as indices to shuffle our feature matrix and class label vector.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can then use the `fit` method to train the `AdalineSGD` classifier and use
    our `plot_decision_regions` to plot our training results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'The two plots that we obtain from executing the preceding code example are
    shown in *Figure 2.15*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Chart  Description automatically generated](img/B17582_02_15.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.15: Decision regions and average loss plots after training an Adaline
    model using SGD'
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, the average loss goes down pretty quickly, and the final decision
    boundary after 15 epochs looks similar to the batch gradient descent Adaline.
    If we want to update our model, for example, in an online learning scenario with
    streaming data, we could simply call the `partial_fit` method on individual training
    examples—for instance, `ada_sgd.partial_fit(X_std[0, :], y[0])`.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we gained a good understanding of the basic concepts of linear
    classifiers for supervised learning. After we implemented a perceptron, we saw
    how we can train adaptive linear neurons efficiently via a vectorized implementation
    of gradient descent and online learning via SGD.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have seen how to implement simple classifiers in Python, we are
    ready to move on to the next chapter, where we will use the Python scikit-learn
    machine learning library to get access to more advanced and powerful machine learning
    classifiers, which are commonly used in academia as well as in industry.
  prefs: []
  type: TYPE_NORMAL
- en: 'The object-oriented approach that we used to implement the perceptron and Adaline
    algorithms will help with understanding the scikit-learn API, which is implemented
    based on the same core concepts that we used in this chapter: the `fit` and `predict`
    methods. Based on these core concepts, we will learn about logistic regression
    for modeling class probabilities and support vector machines for working with
    nonlinear decision boundaries. In addition, we will introduce a different class
    of supervised learning algorithms, tree-based algorithms, which are commonly combined
    into robust ensemble classifiers.'
  prefs: []
  type: TYPE_NORMAL
- en: Join our book’s Discord space
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Join the book’s Discord workspace for a monthly *Ask me Anything* session with
    the authors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://packt.link/MLwPyTorch](https://packt.link/MLwPyTorch)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/QR_Code874410888448293359.png)'
  prefs: []
  type: TYPE_IMG
