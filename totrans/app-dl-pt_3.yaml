- en: '*Chaper 3*'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A Classification Problem Using DNNs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Learning Objectives
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'By the end of this chapter, you will be able to:'
  prefs: []
  type: TYPE_NORMAL
- en: Explain the uses of deep learning in banking
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Differentiate between building a neural network for a regression task and a
    classification task
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Apply the concept of custom modules in PyTorch to solve a problem
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Solve a classification problem using a deep neural network
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deal with an underfitted or overfitted model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploy a PyTorch model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this chapter, we'll focus on solving simple classification tasks using DNNs
    to cement our knowledge on deep neural networks.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Although deep neural networks (DNNs) can be used to solve regression problems,
    as seen in the previous chapter, they are more commonly used to solve classification
    tasks, where the objective is to predict an outcome out of a series of options.
  prefs: []
  type: TYPE_NORMAL
- en: One field making use of such models is banking. This is mainly due to their
    need to predict future behavior based on demographical data, alongside the main
    objective of ensuring profitability in the long term. Some of the uses in the
    banking sector include the evaluation of loan applications, credit card approval,
    the prediction of stock market prices, and the detection of fraud by analyzing
    behavior.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter will focus on solving a classification banking problem using a
    deep artificial neural network, following all the steps required to arrive at
    an effective model: data exploration, data preparation, architecture definition
    and model training, model fine-tuning, error analysis, and finally, deployment
    of the final model.'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: As a reminder, the GitHub repository containing all code used in this chapter
    can be found at the following site:[https://github.com/TrainingByPackt/Applied-Deep-Learning-with-PyTorch](https://github.com/TrainingByPackt/Applied-Deep-Learning-with-PyTorch).
  prefs: []
  type: TYPE_NORMAL
- en: Problem Definition
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Defining the problem is as important as building your model or improving accuracy.
    Why is this so? Because even though you may be able to use the most powerful algorithm,
    and use the most advanced methodologies to improve its results, it may be useless
    if you are solving the wrong problem, or if you are using the wrong data.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, it is crucial to learn how to think deeply to understand what can
    and cannot be done, and how what can be done could be accomplished. This is especially
    pertinent considering that when we are learning to apply machine learning or deep
    learning algorithms, the problems are always clearly presented, and there is no
    need of further analysis other than the training of the model and the improving
    of the performance; on the other hand, in real life, problems are often confusing,
    and data is often messy.
  prefs: []
  type: TYPE_NORMAL
- en: Due to all this, in this section you will learn some of the best practices to
    define your problem based on the needs of your organization and on the data that
    you have at hand.
  prefs: []
  type: TYPE_NORMAL
- en: 'To do so, the things that need to be done are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Understand the what, why, and how of the problem.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Analyze the data at hand to determine some of the key parameters of our model,
    such as the type of learning task to be performed, the necessary preparation,
    and the definition of the performance metric.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Perform data preparation to reduce the probability of introducing bias to the
    model.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deep Learning in Banking
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Similar to the health sector, banks and financial entities deal with great amounts
    of information every day, with which they need to make crucial decisions that
    not only impact the future of their own organization, but that of the millions
    of individuals who trust them.
  prefs: []
  type: TYPE_NORMAL
- en: These decisions are made every second, and back in the 1990s, people in the
    banking sector used to rely on expert systems that basically used human expert
    knowledge to code rule-based programs. Not surprisingly, such programs fell short,
    as they required all the information or possible scenarios to be programmed upfront,
    which made them inefficient for dealing with uncertainty and highly changing markets.
  prefs: []
  type: TYPE_NORMAL
- en: As technology improved, as well as the capability to gather customer data, the
    banking sector has been leading the transition to more specialized systems that
    make use of statistical models to help make such decisions. Moreover, thanks to
    the fact that banks need to consider both their own profitability as well as that
    of their clients, they are considered among the industries that constantly keep
    up with technological improvements to become more efficient and accurate every
    day.
  prefs: []
  type: TYPE_NORMAL
- en: Nowadays, along with the healthcare market, the banking and financial industries
    are driving the market of neural networks. This is mostly due to neural networks'
    capability to deal with uncertainty by using vast amounts of previous data to
    predict future behavior. This is something that human expert knowledge-based systems
    are unable to achieve, considering that the human brain is not capable of analyzing
    such large amounts of data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some of the fields of the banking and financial services in which deep learning
    is being used are presented and briefly explained here:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Loan application evaluation**: Banks issue loans to customers based on different
    factors, including demographical information, credit history, and so on. Their
    main objective in this process is to minimize the number of customers that will
    default on loan payments (minimize the failure rate), and this way, maximize the
    returns obtained through the loans that have been issued.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Neural networks are used to help make the decision of whether to grant a loan.
    They are usually trained using data from previous loan applicants that failed
    to pay loans back, as well as those that paid the loans on time. Once a model
    is created, the idea is to input the data of a new applicant into the model in
    order to get a prediction of whether they will pay the loan back, considering
    that the focus of the model should be to reduce the number of false positives
    (customers who the model predicted would default the loan, but actually they do
    not).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: It is known in the industry that the failure rate of neural networks is lower
    than traditional methodologies that rely on human expertise.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Detection of fraud**: Fraud detection is crucial for banks and financial
    providers, now more than ever, considering the advancements of technology that,
    in spite of making our lives easier, also leave us exposed to greater financial
    risks, especially on online banking platforms.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Neural networks are used in this domain, specifically convolution neural networks
    (CNNs), for character and image recognition to detect hidden and abstract patterns
    in images of characters, in order to determine whether the user is being supplanted.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`.xls` file.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exploring the Dataset
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the following sections, we will focus on solving a classification task related
    to credit card payments using the **Default of Credit Card Clients** (**DCCC**)
    dataset, which was previously downloaded from the UC Irvine Repository site.
  prefs: []
  type: TYPE_NORMAL
- en: The main idea of this section is to clearly state the what, why, and how of
    the data problem, which will help determine the purpose of the study and the evaluation
    metric. Additionally, in this section, we will analyze in detail the data at hand
    in order to identify some of the steps required during the preparation of the
    data (for instance, converting qualitative features into their numerical representation).
  prefs: []
  type: TYPE_NORMAL
- en: 'First of all, let''s define the what, why, and how. Take into consideration
    that this should be done to identify the real needs of the organization:'
  prefs: []
  type: TYPE_NORMAL
- en: '**What**: Build a model that is able to determine whether a client will default
    on the upcoming payment.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Why**: To be able to foresee the amount (in money) of payments to be received
    in the following month. This will help companies determine the spending strategies
    for that month, in addition to allowing them to define the actions to be carried
    with each customer, to both ensure future payments from those who will pay their
    bills, and to improve the probabilities of payments of those clients who will
    default.'
  prefs: []
  type: TYPE_NORMAL
- en: '**How**: Use historical data containing demographical information, credit histories,
    and previous bill statements of clients that have and have not defaulted on their
    payments to train a model. After being trained over the input data, this model
    should be able to determine whether a client is likely to default its next payment.'
  prefs: []
  type: TYPE_NORMAL
- en: Considering this, it seems that the target feature should be one stating whether
    a client will default the next payment, which entails a binary outcome (yes/no).
    This means that the learning task to be developed is a classification task, and
    hence, the loss function should be one capable of measuring differences for such
    a type of learning (for instance, the cross-entropy function, as explained in
    the previous chapter).
  prefs: []
  type: TYPE_NORMAL
- en: Once the problem is well defined, you need to determine the priorities of the
    final model. This means determining whether all output classes are equally important.
    For instance, a model measuring whether a lung mass is malignant should focus
    primarily on minimizing `false negatives` (patients that the model predicted as
    not having a malignant mass, but the mass was actually malignant). On the other
    hand, a model built to recognize hand-written characters should not focus in one
    particular character, but rather maximize its performance in recognizing all characters
    equally.
  prefs: []
  type: TYPE_NORMAL
- en: Considering this, as well as the explanation in the why statement, the priority
    of the model for the `Default of Credit Card Clients` dataset should be to maximize
    the overall performance of the model, without prioritizing any of the class labels.
    This is mainly because the why statement declares that the main purpose of the
    study should be to have a better idea of the money that the bank will receive,
    as well as to perform certain actions regarding clients that are likely to default
    on a payment, and different actions for those who will not default on it.
  prefs: []
  type: TYPE_NORMAL
- en: According to this, the performance metric to be used in this case study is the
    **accuracy**, which focuses on maximizing the **correctly classified instances**.
    This refers to the ratio between the correctly classified instances of any of
    the class labels against the total number of instances.
  prefs: []
  type: TYPE_NORMAL
- en: The following table contains a brief explanation of each of the features present
    in the dataset, which can help determine their relevance to the purpose of the
    study, as well as identify some of the preparation tasks that need to be performed.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.1: A description of features from the DCCC dataset](img/C11865_03_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.1: A description of features from the DCCC dataset'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '![Figure 3.2: A description of features from the DCCC dataset, continued](img/C11865_03_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.2: A description of features from the DCCC dataset, continued'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Considering this information, it is possible to conclude that out of the 25
    features (including the target feature), 2 need to be removed from the dataset
    as they are considered to be irrelevant to the purpose of the study. Please remember
    that features irrelevant to this study may be relevant in other studies. For instance,
    a study on the topic of intimate hygiene products may consider the gender feature
    as relevant.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, all features are quantitative, which means that there is no need to
    convert their values, other than rescaling them. The target feature has also been
    converted to its numerical representation, where a customer that defaulted the
    next payment is represented by a one, while a customer that did not default the
    payment is represented by a zero.
  prefs: []
  type: TYPE_NORMAL
- en: Data Preparation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Although there are some good practices in this matter, there is not a fixed
    set of steps to prepare (pre-process) your dataset to develop a deep learning
    solution, and most of the time, the steps to take will depend on the data at hand,
    the algorithm to be used, and other characteristics of the study.
  prefs: []
  type: TYPE_NORMAL
- en: 'Nonetheless, there are some key aspects that must be dealt with as a good practice
    before starting to train your model. Most of them you already know from the previous
    chapter, which will be revised for the dataset in question, with the addition
    of the revision of class imbalance in the target feature:'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The process of preparing the DCCC Dataset will be handled in this section, accompanied
    by a brief explanation. Feel free to open a Jupyter notebook and replicate this
    process, considering that it will be the starting point for subsequent activities.
  prefs: []
  type: TYPE_NORMAL
- en: '`skiprows` argument to remove the first row of the Excel file, which is irrelevant
    as it contains a second set of headers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'From the lines of code given, the following result is obtained:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.3: The head of the DCCC dataset](img/C11865_03_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.3: The head of the DCCC dataset'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The shape of the dataset is of 30,000 rows and 25 columns, which can be obtained
    using the following line of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '**Remove irrelevant features**: By performing the analysis of each of the features,
    it was possible to determine that two of the features are to be removed from the
    dataset as they are irrelevant to the purpose of the study.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The resulting dataset should contain 23 columns, instead of the original 25:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](img/C11865_03_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.4: The head of the DCCC dataset after removing irrelevant features'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '**Check for missing values**: Next, it is time to check whether the dataset
    is missing values, and if so, calculate the percentage of how much they represent
    each feature, which can be done using the following lines of code:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The first line performs a sum of missing values for each of the features of
    the dataset. Next, we calculate the participation of missing values along all
    values in each feature. Finally, we concatenate both values calculated before,
    displaying the results in a table. The results are shown in *Figure 3.5*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: .
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.5: The count of missing values in DCCC dataset](img/C11865_03_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.5: The count of missing values in DCCC dataset'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: From these results, it is possible to say that the dataset is not missing any
    values, so no further procedure is required here.
  prefs: []
  type: TYPE_NORMAL
- en: '`BILL_AMT1` and `BILL_AMT4`, each with a participation of 2.3% of the total
    instances.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This means that there are no further actions required considering that their
    participation is too little, and is unlikely to have an effect in the final model.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Check for class imbalance**: Class imbalance occurs when the class labels
    in the target feature are not equally represented; for instance, a dataset containing
    90% of customers that did not default on the next payment, against 10% of customers
    that did, is considered to be imbalanced.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'There are several ways to handle class imbalance, some of which are explained
    here:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Collecting more data**: Although this is not always an available route, it
    may help balance out the classes, or allow the removal of the over-represented
    class without reducing the dataset severely.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Changing performance metrics**: Some metrics, such as accuracy, are not good
    for measuring performance of imbalanced datasets. In turn, it is recommended to
    measure performance using metrics such as precision or recall for classification
    problems.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Resampling the dataset**: This consists of changing the dataset to balance
    out the classes. It can be done in two different ways: 1) adding copies of the
    under-represented class (called over-sampling), or, 2) deleting instances of the
    over-represented class (called under-sampling).'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Class imbalance can be detected by simply counting the occurrences of each
    of the classes in the target feature, as shown here:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'From the preceding code, it is possible to conclude that the number of customers
    that defaulted on payments represents, 22.12% of the dataset. These results can
    also be displayed in a plot using the following lines of code:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This results in the following figure:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.6: The count of classes of the target feature](img/C11865_03_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.6: The count of classes of the target feature'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In order to fix this problem, and considering that there is no more data to
    be added and that the performance metric is in fact the accuracy, it is necessary
    to perform data resampling.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is a code snippet that performs over-sampling over the dataset,
    randomly creating duplicated rows of the under-represented class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: First, we separate the data for each class label into independent DataFrames.
    Next, we use pandas' `sample()` function to construct a new DataFrame that contains
    as many duplicated instances as the over-represented class' DataFrame.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the `concat()` function is used to concatenate the DataFrame of the
    over-represented class and the newly created DataFrame of the same size.
  prefs: []
  type: TYPE_NORMAL
- en: By calculating the participation of each class over the entire dataset, the
    result should show equally represented classes. Moreover, the final shape of the
    dataset to this point should be equal to (46728, 23).
  prefs: []
  type: TYPE_NORMAL
- en: '**Split features from target**: We split the dataset into a features matrix
    and a target matrix, to avoid rescaling the target values:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '**Rescale the data**: Finally, we rescale the values of the features matrix
    in order to avoid introducing bias to the model:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The result from the preceding lines of code are shown in *Figure 3.7*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.7: The features matrix after being normalized](img/C11865_03_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.7: The features matrix after being normalized'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Consider that both **Marriage** and **Education** are ordinal features, meaning
    that they follow an order or hierarchy; when choosing a rescaling methodology,
    make sure to maintain order.
  prefs: []
  type: TYPE_NORMAL
- en: 'With the purpose of facilitating the use of the prepared dataset for the upcoming
    activities, both the features (`X`) and target (`y`) matrices will be concatenates
    into one pandas DataFrame, which will be saved into a CSV file, using the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: After performing all of these steps, the DCCC dataset is ready (in a new CSV
    file) to be used for training the model, which will be explained in the following
    section.
  prefs: []
  type: TYPE_NORMAL
- en: Building the Model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Once the problem is defined and the data at hand is explored and prepared, it
    is time to define the model. The definition of the architecture of the network,
    the type of layers, the loss function, and so on should be dealt with after the
    previous analysis. This is mainly because there is no "one-size-fits-all" approach
    in machine learning, and even less so in deep learning.
  prefs: []
  type: TYPE_NORMAL
- en: A regression task requires a different methodology than a classification task,
    and so does clustering, computer vision, or machine translation. Due to this,
    in the following section, you will find the key characteristics to building a
    model for solving a classification task, along with an explanation of how to arrive
    at a "good" architecture, and how and when to use custom modules in PyTorch.
  prefs: []
  type: TYPE_NORMAL
- en: ANNs for Classification Tasks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As seen in the activity from the previous chapter, neural networks built for
    regression tasks use outputs as continuous values, which is why the output function
    is left without an activation function and with only one output node (the real
    value), as in the case of a model built to predict house prices based on the characteristics
    of the house and the neighborhood.
  prefs: []
  type: TYPE_NORMAL
- en: Considering this, the measuring of performance should be done by calculating
    the difference between the ground truth and the predicted value, as in calculating
    the distance between 125.3 (the prediction) and 126.38 (the ground truth). As
    mentioned before, there are many ways to measure this difference, with the **mean
    squared error** (**MSE**), or its variation, the **root mean squared error** (**RMSE**),
    being the most commonly used metrics.
  prefs: []
  type: TYPE_NORMAL
- en: Contrary to this, the output from a classification task is the probability of
    a certain set of input features belonging to each of the output labels or classes,
    which is done using a Sigmoid (for binary classification) or a Softmax (for multi-class
    classification) activation function. Moreover, for binary classification tasks,
    the output layer should contain one (for sigmoid) or two (for softmax) output
    nodes, while for multi-class classification tasks, the output nodes should be
    equal to the number of class labels.
  prefs: []
  type: TYPE_NORMAL
- en: This ability to calculate the likelihood of belonging to each output class,
    coupled with an argmax function, will retrieve the class with higher probability
    as the final prediction.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The argmax, in Python, is a function capable of returning the index of the maximum
    value along an axis.
  prefs: []
  type: TYPE_NORMAL
- en: Considering this, the performance of the model should be a matter of whether
    the instances have been classified to the correct class label, rather than anything
    to do with the measuring of the distance between two values, hence the use of
    a different loss function (the cross-entropy being the most commonly used) for
    training neural networks for classification problems, as well as the use of different
    performance metrics, such as accuracy, precision, and recall.
  prefs: []
  type: TYPE_NORMAL
- en: A Good Architecture
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: First of all, as has been explained throughout the book, it is important to
    understand the data problem at hand in order to determine the general topology
    of the neural network. Again, a regular classification problem does not require
    the same network architecture as a computer vision one.
  prefs: []
  type: TYPE_NORMAL
- en: Once this is defined, and considering that there is not a right answer in terms
    of determining the number of hidden layers, their type, or the number of units
    in each layer, the best approach is to get started with an initial architecture,
    which then can be improved to increment performance.
  prefs: []
  type: TYPE_NORMAL
- en: Why is this so important? Because with a large number of parameters to tune,
    sometimes it can be difficult to commit to something and start. This is unfortunate
    considering that in training neural networks, there are several ways to determine
    what needs to be improved once an initial architecture has been trained and tested.
    In fact, the whole reason for dividing your dataset into three subsets is to allow
    for the possibility of training the dataset with one set, measuring and fine-tuning
    the model with another, and finally, measuring the performance of the final model
    with a final subset that has not been used before.
  prefs: []
  type: TYPE_NORMAL
- en: 'Considering all this, the following set of conventions and rules of thumb will
    be explained to aid the decision process of defining the initial architecture
    of an ANN:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Input layer**: This is simple enough – there is only one input layer, and
    its number of units is dependent on the shape of the training data. Specifically,
    the number of units in the input layer should be equal to the number of features
    that the input data contains.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Hidden layer**: Hidden layers can vary in quantity. ANNs can have one, more,
    or none. To choose the right number, it is important to consider the following:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The simpler the data problem, the fewer hidden layers it requires. Remember
    that data problems that can be linearly separable should only have one hidden
    layer. On the other hand, with the advancements of deep learning, it is now possible
    to solve really complex data problems with the use of many hidden layers (without
    limitation).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The number of hidden units, to start off, should be between the number of units
    in the input layer and the number of units in the output layer.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Output layer**: Again, any ANN only has one output layer. The number of units
    that it contains depends on the learning task to be developed, as well as on the
    data problem. As explained before, for regression tasks, there would only be one
    unit, which is the predicted value. On the other hand, for classification problems,
    the number of units should be equal to the number of class labels available, considering
    that the output from the model should be the probability of a set of features
    belonging to each of the class labels.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Other parameters**: Conventionally, other parameters should be left with
    their default values for the first configuration of the network. This is mainly
    because it is always a good practice to test the simplest model over your data
    problem before considering more complex approximations that may perform equally
    well or worse, but will require more resources.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Once an initial architecture has been defined, it is time to train and measure
    the performance of the model in order to perform further analysis, which will
    most likely result in changes in the architecture of the network or values of
    other parameters, such as changes in the learning rate or the addition of a regularization
    term.
  prefs: []
  type: TYPE_NORMAL
- en: PyTorch Custom Modules
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Custom modules were created by PyTorch's development team as a way to allow
    further flexibility to the user. Contrary to the `Sequential` container explored
    in previous chapters, custom modules should be used whenever there is a desire
    to build more complex model architectures, or whenever you wish to have further
    control over the calculations that occur in each layer.
  prefs: []
  type: TYPE_NORMAL
- en: Nevertheless, this does not mean that the custom module methodology can only
    be used in such scenarios. On the contrary, once you learn to use both approaches,
    it is a matter of preference when choosing which one to use for the less complex
    architectures.
  prefs: []
  type: TYPE_NORMAL
- en: 'Take, for instance, the following code snippet of a two-layer neural network
    defined using the `Sequential` container:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Here, `D_i` refers to the input dimensions (the features in the input data),
    `D_h` refers to the hidden dimensions (the number of nodes in a hidden layer),
    and `D_o` refers to the output dimensions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using custom modules, it is possible to build an equivalent network architecture,
    as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: It is important to mention that the cross-entropy loss function requires the
    output from the network to be raw (before obtaining the probabilities through
    the use of the softmax activation function), which is why it is common to find
    neural network architectures for classification problems without an activation
    function for the output layer. Moreover, in order to get a prediction out of this
    approach, it is necessary to apply the softmax activation function to the output
    of the network after being trained.
  prefs: []
  type: TYPE_NORMAL
- en: Another approach to handle this restriction is to use the `log_softmax` activation
    function for the output layer, instead. Next, the loss function is defined as
    the negative log likelihood loss (`nn.NLLLoss`). Finally, it is possible to get
    the actual probabilities of belonging to each class label by taking the exponential
    from the output of the network. This is the approach that will be used in the
    activities of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Once the model architecture has been defined, the following step would be to
    code the section in charge of training the model over the training data, as well
    as measuring its performance both over the training and validations sets.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, the step-by-step instructions to code what we have discussed will be
    given:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: As can be seen, the first step is to define all the variables that will be used
    during the training of the network.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: As a reminder, "`epochs`" refers to the number of times that the entire dataset
    is passed forward and backward through the network architecture. "`batch_size`"
    refers to the number of training examples in a single batch (a slice of the dataset).
    Finally, iterations refer to the number of batches required to complete one epoch.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, a first `for` loop is used to go through the number of epochs defined
    previously. Following it, a new `for` loop is used to go through each batch of
    the total dataset until an epoch is completed. Inside this loop, the following
    computations occur:'
  prefs: []
  type: TYPE_NORMAL
- en: The model is trained over a batch of the training set. A prediction is obtained
    here.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The loss is calculated by comparing the prediction from the previous step and
    the labels from the training set (ground truth).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The gradients are zeroed and calculated again for the current step.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The parameters of the network are updated based on the gradients.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The accuracy of the model over the training data is calculated as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Get the exponential of the predictions of the model in order to get the probabilities
    of a given piece of data belonging to each class label.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Use the `topk()` method to get the class label with higher probability.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Using scikit-learn's metric section, calculate the accuracy, precision, or recall.
    You can also explore other performance metrics.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The calculation of gradients is turned off in order to verify the performance
    of the current model over the validation data, which occurs as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The model performs a prediction for the data in the validation set.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The loss function is calculated by comparing the previous prediction against
    the labels from the validation set.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To calculate the accuracy of the model over the validation set, use the same
    set of steps as for the same calculation over the training data:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: The preceding code snippet will print the loss and accuracy for both sets of
    data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 4: Building an ANN'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For this activity, using the previously prepared dataset, we will build a four-layer
    model that is able to determine whether a client will default the next payment.
    To do so, we will use the custom modules methodology.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s look at the following scenario: You work at a data science boutique
    that specializes in providing machine/deep learning solutions to banks all around
    the world. They have recently taken on a project for a bank that wishes to foresee
    the payments that will not be received the next month. The exploratory data analysis
    team has already prepared the dataset for you and they have asked you to build
    the model and calculate the accuracy of the model:'
  prefs: []
  type: TYPE_NORMAL
- en: Import the following libraries.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: Even with the use of a seed, the exact results of this activity will not be
    reproducible, considering that the training sets are shuffled before each epoch.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Read the previously prepared dataset, which should have been named `dccc_prepared.csv`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Separate the features from the target.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Using scikit-learn's `train_test_split` function, split the dataset into training,
    validation, and testing sets. Use a 60/20/20% split ratio. Set `random_state`
    as 0.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Convert the validation and testing sets to tensors, considering that the features
    matrices should be of type float, while the target matrices should not. Leave
    the training sets unconverted for the moment as they will undergo further transformations.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Build a custom module class defining the layers of the network. Include a forward
    function that specifies the activation functions that will be applied to the output
    of each layer. Use ReLU for all layers, except for the output, where you should
    use `log_softmax`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Define all the variables required for the training of the model. Set the number
    of epochs to 50 and the batch size to 128\. Use a learning rate of 0.001.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Train the network using the training sets data. Use the validation sets to measure
    performance. To do so, save the loss and the accuracy for both the training and
    validation sets in each epoch.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: The training process may take several minutes, depending on your resources.
    Adding print statements is a good practice to see the progress of the training
    process.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Plot the loss of both sets.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Plot the accuracy of both sets.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: The solution for this activity can be found on page 192.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Dealing with an Underfitted or Overfitted Model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Building a deep learning solution is not just a matter of defining an architecture
    and then training a model using the input data; on the contrary, most would agree
    that that is the easy part. The art of creating high-tech models consists of achieving
    high levels of accuracy that surpass human performance. Given this, this section
    will introduce the topic of error analysis, which is commonly used to diagnose
    a trained model in order to discover what actions are more likely to have a positive
    impact in the performance of the model.
  prefs: []
  type: TYPE_NORMAL
- en: Error Analysis
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Error analysis refers, as the name suggests, to the initial analysis of the
    error rate over the training and validation sets of data. This analysis is then
    used to determine the best book of action to improve the performance of the model.
  prefs: []
  type: TYPE_NORMAL
- en: In order to perform error analysis, it is necessary to determine the Bayes error,
    also known as the irreducible error, which is the minimum achievable error. Several
    decades ago, the Bayes error was equivalent to human error, meaning that back
    then, the conceived minimum level of error was the one that experts could achieve.
  prefs: []
  type: TYPE_NORMAL
- en: Nowadays, with the improvements of technology and algorithms, this value has
    become increasingly difficult to estimate, as machines are capable of surpassing
    human performance, but there is no measure of how much better they can do in comparison
    to humans, as we can only understand as far as our capacity goes.
  prefs: []
  type: TYPE_NORMAL
- en: It is common for the Bayes error to be set equal to the human error, initially,
    to perform error analysis. However, this limitation is not set in stone, and researchers
    know that surpassing human performance should be an end goal as well.
  prefs: []
  type: TYPE_NORMAL
- en: 'The process of performing error analysis is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Calculate the metric of choice to measure the performance of the model by. This
    measure should be calculated over both training and validation sets of data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Using this measure, calculate the error rate of each of the sets by subtracting
    from 1 the performance metric previously calculated. Take, for instance, the following
    equation:![](img/C11865_03_08.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Figure 3.8: The equation to calculate the error rate of the model over the
    training set'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: Subtract the Bayes error from the training set error (A). Save the difference,
    which will be used for further analysis.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Subtract the training set error from the validation set error (B) and save the
    value of the difference.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Take the differences calculated in steps 3 and 4, and use the following set
    of rules:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If the difference calculated in step 3 is higher than the other, the model is
    underfitted, also described as high bias.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If the difference calculated in step 4 is higher than the other, the model
    is overfitted, also known as high variance:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 3.9: Diagram showing how to perform error analysis](img/C11865_03_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.9: Diagram showing how to perform error analysis'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The rules we've explained do not indicate that the model could only be suffering
    from one of the issues mentioned, but that the one with higher difference is having
    a greater effect on the performance of the model, which means that fixing it will
    improve the performance to a greater degree.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s explain how to deal with each of these issues:'
  prefs: []
  type: TYPE_NORMAL
- en: '**High-bias**: An underfitted model, or a model suffering from high bias, is
    a model that is not capable of understanding the training data, and hence, it
    is not able to uncover patterns and generalize with other sets of data. This means
    that the model does not perform well over any set of data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To decrease the bias affecting the model, it is recommended to define a bigger/deeper
    network (more hidden layers) or to train for more iterations. By adding more layers
    and increasing the training time, the network has more resources to discover the
    patterns that describe the training data.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**High-variance**: An overfitted model, or a model suffering from high variance,
    is a model that is having trouble generalizing the training data; it is learning
    the details of the training data too well, including its outliers. This means
    that the model is performing too well over the training data, but poorly over
    other sets of data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This is typically handled by adding more data to the training set, or by adding
    a regularization term to the loss function. The first approach aims to force the
    network to generalize to the data rather than understand the details of a small
    quantity of examples. The second approach, on the other hand, penalizes the inputs
    that have higher weights in order to overlook outlier values, and equally consider
    all values.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Considering this, dealing with one condition that is affecting the model may
    cause another one to appear or increase. For instance, a model suffering from
    high bias, after being treated may improve its performance over the training data
    but not over the validation data, which means that the model will have started
    to suffer from high variance and would require another set of remedial actions
    to be taken.
  prefs: []
  type: TYPE_NORMAL
- en: Once the model has been diagnosed and the required measures have been taken
    to improve the performance, the best models should be selected for a final test.
    Each of these models should be used to perform predictions over the testing set
    (the only set that does not have an effect on the building of the model).
  prefs: []
  type: TYPE_NORMAL
- en: Considering this, it would be possible to select the final model as the one
    that performs best over the testing data. This is mainly because the performance
    over the testing data serves as an indicator of the model's performance on future
    unseen sets of data, which is the ultimate goal.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 7: Performing Error Analysis'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Using the accuracy metric calculated in the previous activity, in this activity,
    we will perform error analysis, which will help us determine the actions to be
    performed over the model in the upcoming activity:'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: This activity does not require coding, but rather analysis of the previous activity's
    results.
  prefs: []
  type: TYPE_NORMAL
- en: 'Assuming a Bayes error of 0.15, perform error analysis and diagnose the model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The values used as the accuracy of both sets (0.715 and 0.706) are the ones
    obtained during the last iteration of the previous activity.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: According to this, the model is suffering from high bias, meaning that the model
    is underfitted.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Determine the actions to be followed to improve accuracy of the model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To improve the model's performance, two books of actions that can be followed
    are incrementing the number of epochs and increasing the number of hidden layers
    and/or the number of units.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In accordance with this, a set of tests can be performed in order to arrive
    at the best result.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Congratulations! You have successfully performed error analysis.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 5: Improving a Model''s Performance'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'For the following activity, we will implement the actions defined in the exercise
    to reduce the high bias that is affecting the performance of the model. Let''s
    look at the following scenario: after delivering the model to your teammates,
    they are impressed with your work and the way that your code is organized (well
    done!), but they have asked you to try improving the performance to 80%, considering
    that this is what they promised to the client:'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Use a different notebook for this activity. There, you will load the dataset
    again, and perform similar steps as in the previous activity, with the difference
    being that the training process will be done several times to train different
    architectures and training times.
  prefs: []
  type: TYPE_NORMAL
- en: Import the same libraries as in the previous activity.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Load the data and split the features from the target. Next, split the data into
    three subsets (training, validation, and testing), using a 60:20:20 split ratio.
    Finally, convert the validation and testing sets into PyTorch tensors, just as
    you did in the previous activity.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Considering that the model is suffering from high bias, the focus should be
    on increasing the number of epochs or increasing the size of the network by adding
    additional layers or units to each layer. The aim should be to approximate the
    accuracy over the testing set to 80%.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: Consider that there is not a right way to choose which test to carry out first,
    so be creative and analytical. If changes in your model's architecture reduce
    or eliminate the high bias but introduce high variance, then consider, for instance,
    keeping the changes but adding some measure to combat the high variance.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Plot the loss and accuracy for both sets of data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Using the best performing model, perform prediction over the testing set (which
    should have not been used during the fine-tuning process). Compare the prediction
    to the ground truth by calculating the accuracy of the model over this set.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: The solution for this activity can be found on page 196.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Deploying Your Model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: By now, the key concepts and tips for building exceptional deep learning models
    for regular regression and classification problems have been discussed and put
    into practice. In real life, models are not just built for learning purposes.
    On the contrary, when training models for purposes other than research, the main
    idea is to be able to reuse them in the future to perform predictions over new
    data that, although the model was not trained on, the model should perform similarly
    well with.
  prefs: []
  type: TYPE_NORMAL
- en: In a small organization, the ability to serialize and deserialize models suffices.
    However, when models are to be used by large corporations, by users, or to alter
    a massively important and large task, it is a better practice to convert the model
    to a format that can be used in most production environments, such as APIs, websites,
    online and offline applications, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: In accordance with this, in this section, we will learn how to save and load
    models, as well as how to use PyTorch's most recent feature for converting your
    model into a C++ application that is highly versatile.
  prefs: []
  type: TYPE_NORMAL
- en: Saving and Loading Your Model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As you might imagine, retraining a model every time it is to be used is highly
    impractical, especially considering that most deep learning models may take quite
    some time to train (depending on your resources).
  prefs: []
  type: TYPE_NORMAL
- en: Instead, models in PyTorch can be trained, saved, and reloaded to either perform
    further training or to make inferences. This can be achieved considering that
    the parameters (weights and biases) for each layer of PyTorch models are saved
    into the `state_dict dictionary`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, a step-by-step guide is given on how to save and load a trained model:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Originally, a checkpoint of a model will only include the model''s parameters.
    However, when loading the model, this is not the only information required, but
    depending on the arguments that your classifier takes in, it may be necessary
    to save further information, such as the number of input units. Considering this,
    the first step is to define the information to be saved:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This will save into the checkpoint the number of units in the input layer, which
    will come in handy when loading the model.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Using the text editor of your choice, create a Python file that imports PyTorch
    libraries and contains the class that creates the network architecture of your
    model. This is done to be able to conveniently load the model into a new worksheet,
    other than the one you used to train the model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Save the model using PyTorch''s `save()` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The first argument refers to the dictionary previously created, and the second
    arguments is the filename to be used.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'To load the model, let''s create a function that will perform three main actions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The function receives as input the path to the saved model file. First, the
    checkpoint is loaded. Next, a model is initialized using the network's architecture
    saved into the Python file. Here, `final_model` refers to the name of the Python
    file, which should have been imported to the new worksheet, and `Classifier()`
    refers to the name of the class saved in that file. This model will have randomly
    initialized parameters. Finally, the parameters from the checkpoint are loaded
    into the model.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: When called, this function returns the trained model, which now can be used
    for further training or to perform inferences.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: PyTorch for Production in C++
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As per the name of the framework, PyTorch's primary interface is the Python
    programming language. This is mainly due to the preference of this programming
    language by many users, thanks to the language's dynamism and ease of use for
    developing machine learning solutions.
  prefs: []
  type: TYPE_NORMAL
- en: Nevertheless, in some scenarios, Python properties become unfavorable. This
    is precisely the case for environments developed for production, where other programming
    languages have been proved to be more useful. Such is the case with C++, which
    is widely used for production purposes with machine/deep learning solutions.
  prefs: []
  type: TYPE_NORMAL
- en: Given this, PyTorch recently proposed an easy approach to allow users to enjoy
    the benefits of both worlds. While they get to continue programming in a Pythonic
    nature, there is now the possibility to serialize your model into a representation
    that can be loaded and executed from C++, with no dependency on Python.
  prefs: []
  type: TYPE_NORMAL
- en: 'Converting a PyTorch model into a Torch Script is done through PyTorch''s JIT
    (Just-In-Time) compiler module. It is achieved by passing your model, along with
    an example input, through the `torch.jit.trace()` function, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'This will return a script module, which can be used as a regular PyTorch module,
    as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: The above will return the output obtained from running the input data through
    your model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 6: Making Use of Your Model'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'For this activity, save the model created in the previous activity. Moreover,
    the saved model will be loaded into a new notebook for use. What we will do is
    convert the model into a serialized representation than can be executed on C++.
    Let''s look at the following scenario: wow! Everyone is very happy with your commitment
    to improving the model, as well as with the final version of it, so they have
    asked you to save the model, as well as to convert it into a format that they
    can use to build an online application for the client.'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: This activity will make use of two Jupyter notebooks. First, we will use the
    same notebook as from the previous activity to save the final model. Next, we
    will open a new notebook, which will be used to loading the saved model.
  prefs: []
  type: TYPE_NORMAL
- en: Open the Jupyter notebook that you used for the previous activity.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Save a Python file containing the class where you define the architecture of
    your best performing module. Make sure to import PyTorch's required libraries
    and modules. Name it `final_model.py`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Save the best-performing model. Make sure to save the information of the units
    of each layer along with the parameters of the model. Name it `checkpoint.pth`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Open a new Jupyter notebook.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Import PyTorch, as well as the Python file previously created.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a function that loads the model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Perform a prediction by inputting the following tensor into your model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Convert the model using JIT module.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Perform a prediction by inputting the same tensor to the traced script of your
    model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: The solution for this activity can be found on page 202.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: After covering most of the theoretical knowledge in the previous chapters, this
    chapter uses a real-life case study to cement our knowledge. The idea is to encourage
    learning by practice with a hands-on approach.
  prefs: []
  type: TYPE_NORMAL
- en: The chapter starts off by explaining the influence of deep learning in a wide
    range of industries, where accuracy is required. One of the main industries driving
    deep learning's growth is banking and finance, where such algorithms are being
    used in domains such as the evaluation of loan applications, the detection of
    fraud, and the evaluation of past decision-making to foresee future behavior,
    mainly due to the algorithm's ability to supersede human performance in these
    respects.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter used a real-life dataset from an Asian bank, with the objective
    of predicting whether a client would default on a payment. The chapter started
    with the development of the solution by explaining the importance of defining
    the what, why, and how of any data problem, as well as analyzing the data at hand
    to make the best use of it.
  prefs: []
  type: TYPE_NORMAL
- en: Once the data was prepared according to the problem definition, the chapter
    explored the idea of defining a "good" architecture. In this subject, even though
    there are a couple rules of thumb that can be considered, the main takeaway was
    to build an initial architecture without overthinking it, in order to get some
    results that can be used to perform error analysis to improve the model's performance.
  prefs: []
  type: TYPE_NORMAL
- en: The idea of error analysis consists of analyzing the error rate of the model
    over the training and validation sets in order to determine whether the model
    is suffering in greater proportion from high bias or high variance. This diagnosis
    of the model is then used to alter the model's architecture and some of the learning
    parameters, which will result in an improvement of performance.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the chapter explored two main approaches for making use of the best
    performing model. The first approach consists of saving the model, and then reloading
    it into any coding platform to continue training or to perform inferences. On
    the other hand, the second approach is mainly used to launch the model into production
    and is achieved by making use of PyTorch's JIT module, which created a serialized
    representation of the model that can be run on C++.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we'll focus on solving simple classification tasks using
    Deep Neural Networks.
  prefs: []
  type: TYPE_NORMAL
