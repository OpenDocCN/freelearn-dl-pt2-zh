- en: '*Chaper 3*'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第三章*'
- en: A Classification Problem Using DNNs
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 DNN 解决分类问题
- en: Learning Objectives
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 学习目标
- en: 'By the end of this chapter, you will be able to:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章结束时，您将能够：
- en: Explain the uses of deep learning in banking
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解释深度学习在银行业的应用
- en: Differentiate between building a neural network for a regression task and a
    classification task
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 区分为回归任务和分类任务构建神经网络
- en: Apply the concept of custom modules in PyTorch to solve a problem
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用 PyTorch 中的自定义模块概念来解决问题
- en: Solve a classification problem using a deep neural network
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用深度神经网络解决分类问题
- en: Deal with an underfitted or overfitted model
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理欠拟合或过拟合的模型
- en: Deploy a PyTorch model
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署 PyTorch 模型
- en: In this chapter, we'll focus on solving simple classification tasks using DNNs
    to cement our knowledge on deep neural networks.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将专注于使用 DNN 解决简单的分类任务，以巩固我们对深度神经网络的知识。
- en: Introduction
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 引言
- en: Although deep neural networks (DNNs) can be used to solve regression problems,
    as seen in the previous chapter, they are more commonly used to solve classification
    tasks, where the objective is to predict an outcome out of a series of options.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然深度神经网络（DNNs）可以用来解决回归问题，正如前一章所见，但它们更常用于解决分类任务，目标是从一系列选项中预测结果。
- en: One field making use of such models is banking. This is mainly due to their
    need to predict future behavior based on demographical data, alongside the main
    objective of ensuring profitability in the long term. Some of the uses in the
    banking sector include the evaluation of loan applications, credit card approval,
    the prediction of stock market prices, and the detection of fraud by analyzing
    behavior.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 利用这些模型的一个领域是银行业。这主要是由于他们需要基于人口统计数据预测未来行为，以及确保长期盈利的主要目标。在银行业的一些应用包括评估贷款申请、信用卡批准、预测股市价格和通过分析行为检测欺诈。
- en: 'This chapter will focus on solving a classification banking problem using a
    deep artificial neural network, following all the steps required to arrive at
    an effective model: data exploration, data preparation, architecture definition
    and model training, model fine-tuning, error analysis, and finally, deployment
    of the final model.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将专注于使用深度人工神经网络解决银行业的分类问题，遵循到达有效模型所需的所有步骤：数据探索、数据准备、架构定义和模型训练、模型微调、错误分析，最后是最终模型的部署。
- en: Note
  id: totrans-15
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: As a reminder, the GitHub repository containing all code used in this chapter
    can be found at the following site:[https://github.com/TrainingByPackt/Applied-Deep-Learning-with-PyTorch](https://github.com/TrainingByPackt/Applied-Deep-Learning-with-PyTorch).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 提醒一下，在本章中使用的所有代码的 GitHub 仓库可以在以下网址找到：[https://github.com/TrainingByPackt/Applied-Deep-Learning-with-PyTorch](https://github.com/TrainingByPackt/Applied-Deep-Learning-with-PyTorch)。
- en: Problem Definition
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题定义
- en: Defining the problem is as important as building your model or improving accuracy.
    Why is this so? Because even though you may be able to use the most powerful algorithm,
    and use the most advanced methodologies to improve its results, it may be useless
    if you are solving the wrong problem, or if you are using the wrong data.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 定义问题和构建模型或提高准确性同等重要。为什么呢？因为即使您可能使用了最强大的算法，并使用了最先进的方法来改进其结果，如果您解决了错误的问题或使用了错误的数据，这一切可能都是无用的。
- en: Moreover, it is crucial to learn how to think deeply to understand what can
    and cannot be done, and how what can be done could be accomplished. This is especially
    pertinent considering that when we are learning to apply machine learning or deep
    learning algorithms, the problems are always clearly presented, and there is no
    need of further analysis other than the training of the model and the improving
    of the performance; on the other hand, in real life, problems are often confusing,
    and data is often messy.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，学会深入思考理解什么可以做和不能做，以及如何完成可以做的事情至关重要。特别是考虑到当我们学习应用机器学习或深度学习算法时，问题总是清楚呈现的，除了模型训练和性能改进外，不需要进一步的分析；另一方面，在现实生活中，问题通常令人困惑，数据也常常混乱。
- en: Due to all this, in this section you will learn some of the best practices to
    define your problem based on the needs of your organization and on the data that
    you have at hand.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在本节中，您将学习如何根据组织需求和手头数据的最佳实践来定义问题。
- en: 'To do so, the things that need to be done are as follows:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，需要完成以下事项：
- en: Understand the what, why, and how of the problem.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解问题的“什么”、“为什么”和“如何”。
- en: Analyze the data at hand to determine some of the key parameters of our model,
    such as the type of learning task to be performed, the necessary preparation,
    and the definition of the performance metric.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析手头的数据以确定我们模型的一些关键参数，例如要执行的学习任务类型、必要的准备工作和性能指标的定义。
- en: Perform data preparation to reduce the probability of introducing bias to the
    model.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 进行数据准备以减少向模型引入偏见的概率。
- en: Deep Learning in Banking
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 银行业中的深度学习
- en: Similar to the health sector, banks and financial entities deal with great amounts
    of information every day, with which they need to make crucial decisions that
    not only impact the future of their own organization, but that of the millions
    of individuals who trust them.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于健康领域，银行和金融机构每天都处理大量信息，这些信息需要做出关键决策，这些决策不仅影响到他们自己组织的未来，还影响到信任他们的数百万个人的未来。
- en: These decisions are made every second, and back in the 1990s, people in the
    banking sector used to rely on expert systems that basically used human expert
    knowledge to code rule-based programs. Not surprisingly, such programs fell short,
    as they required all the information or possible scenarios to be programmed upfront,
    which made them inefficient for dealing with uncertainty and highly changing markets.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 每一秒都在做出这些决策，在1990年代，银行业人士过去依赖于基本上利用人类专家知识来编码基于规则的程序的专家系统。毫不奇怪，这些程序表现不佳，因为它们要求所有信息或可能的情景在前期都进行编程，这使得它们对处理不确定性和高度变化的市场效率低下。
- en: As technology improved, as well as the capability to gather customer data, the
    banking sector has been leading the transition to more specialized systems that
    make use of statistical models to help make such decisions. Moreover, thanks to
    the fact that banks need to consider both their own profitability as well as that
    of their clients, they are considered among the industries that constantly keep
    up with technological improvements to become more efficient and accurate every
    day.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 随着技术的进步以及获取客户数据的能力的提高，银行业已经引领了向更专业的系统过渡，这些系统利用统计模型来帮助做出此类决策。此外，由于银行需要同时考虑自身的盈利能力和客户的盈利能力，它们被认为是那些不断跟上技术进步以日益提高效率和准确性的行业之一。
- en: Nowadays, along with the healthcare market, the banking and financial industries
    are driving the market of neural networks. This is mostly due to neural networks'
    capability to deal with uncertainty by using vast amounts of previous data to
    predict future behavior. This is something that human expert knowledge-based systems
    are unable to achieve, considering that the human brain is not capable of analyzing
    such large amounts of data.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 如今，与医疗市场一样，银行和金融行业正在推动神经网络市场。这主要是因为神经网络能够利用大量先前数据来预测未来行为中的不确定性。这是人类专家知识基础系统无法实现的，考虑到人类大脑无法分析如此大量的数据。
- en: 'Some of the fields of the banking and financial services in which deep learning
    is being used are presented and briefly explained here:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 以下简要介绍了银行和金融服务领域中使用深度学习的一些领域：
- en: '**Loan application evaluation**: Banks issue loans to customers based on different
    factors, including demographical information, credit history, and so on. Their
    main objective in this process is to minimize the number of customers that will
    default on loan payments (minimize the failure rate), and this way, maximize the
    returns obtained through the loans that have been issued.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**贷款申请评估**：银行根据不同因素向客户发放贷款，包括人口统计信息、信用历史等。他们在此过程中的主要目标是最小化客户违约贷款的数量（最小化失败率），从而最大化通过发放贷款获得的回报。'
- en: Neural networks are used to help make the decision of whether to grant a loan.
    They are usually trained using data from previous loan applicants that failed
    to pay loans back, as well as those that paid the loans on time. Once a model
    is created, the idea is to input the data of a new applicant into the model in
    order to get a prediction of whether they will pay the loan back, considering
    that the focus of the model should be to reduce the number of false positives
    (customers who the model predicted would default the loan, but actually they do
    not).
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 神经网络被用来帮助决定是否批准贷款。通常使用以前未能按时还款的贷款申请人以及按时还款的贷款申请人的数据来训练它们。一旦建立了模型，想法就是将新申请人的数据输入到模型中，以便预测他们是否会还款，考虑到模型的重点是减少误判（即模型预测会违约贷款的客户，但实际上他们没有）。
- en: It is known in the industry that the failure rate of neural networks is lower
    than traditional methodologies that rely on human expertise.
  id: totrans-33
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 行业已知神经网络的失败率低于依赖人类专业知识的传统方法。
- en: '**Detection of fraud**: Fraud detection is crucial for banks and financial
    providers, now more than ever, considering the advancements of technology that,
    in spite of making our lives easier, also leave us exposed to greater financial
    risks, especially on online banking platforms.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**欺诈检测**: 对于银行和金融服务提供商来说，欺诈检测至关重要，现在比以往任何时候都更加重要，考虑到技术的进步，尽管使我们的生活更轻松，但也使我们在网上银行平台上面临更大的财务风险。'
- en: Neural networks are used in this domain, specifically convolution neural networks
    (CNNs), for character and image recognition to detect hidden and abstract patterns
    in images of characters, in order to determine whether the user is being supplanted.
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这个领域使用神经网络，具体来说是卷积神经网络（CNN），用于字符和图像识别，以检测图像中隐藏的抽象模式，以确定用户是否被替代。
- en: '`.xls` file.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`.xls` 文件。'
- en: Exploring the Dataset
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 探索数据集
- en: In the following sections, we will focus on solving a classification task related
    to credit card payments using the **Default of Credit Card Clients** (**DCCC**)
    dataset, which was previously downloaded from the UC Irvine Repository site.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将专注于使用**信用卡客户违约**（**DCCC**）数据集解决与信用卡付款相关的分类任务，该数据集已经从UC Irvine Repository网站上下载。
- en: The main idea of this section is to clearly state the what, why, and how of
    the data problem, which will help determine the purpose of the study and the evaluation
    metric. Additionally, in this section, we will analyze in detail the data at hand
    in order to identify some of the steps required during the preparation of the
    data (for instance, converting qualitative features into their numerical representation).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 本节的主要目的是清楚地说明数据问题的什么、为什么和如何，这将有助于确定研究目的和评估指标。此外，在本节中，我们将详细分析手头的数据，以便识别准备数据时需要的一些步骤（例如，将定性特征转换为它们的数值表示）。
- en: 'First of all, let''s define the what, why, and how. Take into consideration
    that this should be done to identify the real needs of the organization:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们定义什么、为什么和如何。考虑到这一点，应该确保识别组织的真实需求：
- en: '**What**: Build a model that is able to determine whether a client will default
    on the upcoming payment.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**什么**: 构建一个能够确定客户是否会在即将到期的付款中违约的模型。'
- en: '**Why**: To be able to foresee the amount (in money) of payments to be received
    in the following month. This will help companies determine the spending strategies
    for that month, in addition to allowing them to define the actions to be carried
    with each customer, to both ensure future payments from those who will pay their
    bills, and to improve the probabilities of payments of those clients who will
    default.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**为什么**: 能够预见下个月将收到的付款金额（以货币形式）。这将帮助公司确定该月的支出策略，此外还允许他们为每个客户定义应采取的行动，既确保那些将支付账单的客户未来的付款，又提高那些将违约客户的支付概率。'
- en: '**How**: Use historical data containing demographical information, credit histories,
    and previous bill statements of clients that have and have not defaulted on their
    payments to train a model. After being trained over the input data, this model
    should be able to determine whether a client is likely to default its next payment.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**如何**: 使用包含客户人口统计信息、信用历史和之前账单声明的历史数据来训练模型。在对输入数据进行训练后，该模型应能够确定客户是否有可能在下一个付款中违约。'
- en: Considering this, it seems that the target feature should be one stating whether
    a client will default the next payment, which entails a binary outcome (yes/no).
    This means that the learning task to be developed is a classification task, and
    hence, the loss function should be one capable of measuring differences for such
    a type of learning (for instance, the cross-entropy function, as explained in
    the previous chapter).
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这一点，似乎目标特征应该是一个说明客户是否会违约下一个付款的特征，这意味着学习任务是一个分类任务，因此损失函数应该能够测量这种类型学习的差异（例如，交叉熵函数，如前一章所述）。
- en: Once the problem is well defined, you need to determine the priorities of the
    final model. This means determining whether all output classes are equally important.
    For instance, a model measuring whether a lung mass is malignant should focus
    primarily on minimizing `false negatives` (patients that the model predicted as
    not having a malignant mass, but the mass was actually malignant). On the other
    hand, a model built to recognize hand-written characters should not focus in one
    particular character, but rather maximize its performance in recognizing all characters
    equally.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦问题定义清楚，就需要确定最终模型的优先级。这意味着确定所有输出类是否同等重要。例如，一个测量肺部肿块是否恶性的模型应主要集中在最小化`假阴性`（模型预测为没有恶性肿块的患者，但实际上是恶性的肿块）。另一方面，一个用于识别手写字符的模型不应专注于一个特定字符，而应最大化在识别所有字符方面的性能。
- en: Considering this, as well as the explanation in the why statement, the priority
    of the model for the `Default of Credit Card Clients` dataset should be to maximize
    the overall performance of the model, without prioritizing any of the class labels.
    This is mainly because the why statement declares that the main purpose of the
    study should be to have a better idea of the money that the bank will receive,
    as well as to perform certain actions regarding clients that are likely to default
    on a payment, and different actions for those who will not default on it.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这一点，以及为什么声明中的解释，`信用卡客户违约`数据集的模型优先级应该是最大化模型的整体性能，而不优先考虑任何类标签。这主要是因为为什么声明宣称，研究的主要目的应该更好地了解银行将收到的款项，并对可能违约付款的客户执行某些操作，以及对不会违约的客户执行不同的操作。
- en: According to this, the performance metric to be used in this case study is the
    **accuracy**, which focuses on maximizing the **correctly classified instances**.
    This refers to the ratio between the correctly classified instances of any of
    the class labels against the total number of instances.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 根据此，本案例研究中要使用的性能指标是**准确度**，其侧重点是最大化**正确分类的实例**。这指的是任何类标签的正确分类实例与总实例数之间的比率。
- en: The following table contains a brief explanation of each of the features present
    in the dataset, which can help determine their relevance to the purpose of the
    study, as well as identify some of the preparation tasks that need to be performed.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 下表包含数据集中每个特征的简要解释，这可以帮助确定它们对研究目的的相关性，并确定需要执行的一些准备任务。
- en: '![Figure 3.1: A description of features from the DCCC dataset](img/C11865_03_01.jpg)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.1：来自DCCC数据集的特征描述](img/C11865_03_01.jpg)'
- en: 'Figure 3.1: A description of features from the DCCC dataset'
  id: totrans-50
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.1：来自DCCC数据集的特征描述
- en: '![Figure 3.2: A description of features from the DCCC dataset, continued](img/C11865_03_02.jpg)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.2：来自DCCC数据集的特征描述，继续](img/C11865_03_02.jpg)'
- en: 'Figure 3.2: A description of features from the DCCC dataset, continued'
  id: totrans-52
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.2：来自DCCC数据集的特征描述，继续
- en: Considering this information, it is possible to conclude that out of the 25
    features (including the target feature), 2 need to be removed from the dataset
    as they are considered to be irrelevant to the purpose of the study. Please remember
    that features irrelevant to this study may be relevant in other studies. For instance,
    a study on the topic of intimate hygiene products may consider the gender feature
    as relevant.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 综合考虑这些信息，可以得出结论，在25个特征（包括目标特征）中，有2个需要从数据集中移除，因为它们被认为与研究目的无关。请记住，对于本研究无关的特征可能在其他研究中是相关的。例如，关于私密卫生产品的研究可能认为性别特征是相关的。
- en: Moreover, all features are quantitative, which means that there is no need to
    convert their values, other than rescaling them. The target feature has also been
    converted to its numerical representation, where a customer that defaulted the
    next payment is represented by a one, while a customer that did not default the
    payment is represented by a zero.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，所有特征都是定量的，这意味着除了重新缩放它们之外，无需转换它们的值。目标特征也已转换为其数值表示，其中下次付款违约的客户表示为1，而未违约的付款客户表示为0。
- en: Data Preparation
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据准备
- en: Although there are some good practices in this matter, there is not a fixed
    set of steps to prepare (pre-process) your dataset to develop a deep learning
    solution, and most of the time, the steps to take will depend on the data at hand,
    the algorithm to be used, and other characteristics of the study.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然在这方面有一些良好的实践，但在准备数据集以开发深度学习解决方案时，没有固定的步骤集，大多数情况下，需要采取的步骤将取决于手头的数据、要使用的算法以及研究的其他特性。
- en: 'Nonetheless, there are some key aspects that must be dealt with as a good practice
    before starting to train your model. Most of them you already know from the previous
    chapter, which will be revised for the dataset in question, with the addition
    of the revision of class imbalance in the target feature:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，在开始训练模型之前，有一些必须遵循的关键方面作为良好的实践。其中大部分您已经从前一章中了解到，将针对所讨论的数据集进行修订，另外还要对目标特征的类别不平衡进行修订：
- en: Note
  id: totrans-58
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The process of preparing the DCCC Dataset will be handled in this section, accompanied
    by a brief explanation. Feel free to open a Jupyter notebook and replicate this
    process, considering that it will be the starting point for subsequent activities.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中将处理准备DCCC数据集的过程，并附上简要说明。随时打开Jupyter笔记本，复制这个过程，考虑到这将是后续活动的起点。
- en: '`skiprows` argument to remove the first row of the Excel file, which is irrelevant
    as it contains a second set of headers.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`skiprows`参数移除Excel文件的第一行，该行不相关，因为它包含第二组标题。
- en: 'From the lines of code given, the following result is obtained:'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 根据给定的代码行，得出以下结果：
- en: '![Figure 3.3: The head of the DCCC dataset](img/C11865_03_03.jpg)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![图3.3：DCCC数据集的头部](img/C11865_03_03.jpg)'
- en: 'Figure 3.3: The head of the DCCC dataset'
  id: totrans-63
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3.3：DCCC数据集的头部
- en: 'The shape of the dataset is of 30,000 rows and 25 columns, which can be obtained
    using the following line of code:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '数据集的形状是30,000行和25列，可以使用以下代码行获取：  '
- en: '[PRE0]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '**Remove irrelevant features**: By performing the analysis of each of the features,
    it was possible to determine that two of the features are to be removed from the
    dataset as they are irrelevant to the purpose of the study.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**删除不相关的特征**：通过对每个特征的分析，确定了两个特征与研究目的无关，因此应将其从数据集中移除。'
- en: '[PRE1]'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The resulting dataset should contain 23 columns, instead of the original 25:'
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 最终的数据集应包含23列，而不是原来的25列：
- en: '![](img/C11865_03_04.jpg)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](img/C11865_03_04.jpg)'
- en: 'Figure 3.4: The head of the DCCC dataset after removing irrelevant features'
  id: totrans-70
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3.4：删除不相关特征后的DCCC数据集的头部
- en: '**Check for missing values**: Next, it is time to check whether the dataset
    is missing values, and if so, calculate the percentage of how much they represent
    each feature, which can be done using the following lines of code:'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**检查缺失值**：接下来是检查数据集是否存在缺失值，并计算它们在每个特征中所占的百分比，可以使用以下代码行完成：'
- en: '[PRE2]'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The first line performs a sum of missing values for each of the features of
    the dataset. Next, we calculate the participation of missing values along all
    values in each feature. Finally, we concatenate both values calculated before,
    displaying the results in a table. The results are shown in *Figure 3.5*:'
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 第一行对数据集的每个特征的缺失值进行求和。接下来，计算每个特征中缺失值在所有值中的参与度。最后，将之前计算的两个值连接起来，以表格形式显示结果。结果显示在*图3.5*中：
- en: .
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 。
- en: '![Figure 3.5: The count of missing values in DCCC dataset](img/C11865_03_05.jpg)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![图3.5：DCCC数据集中缺失值的计数](img/C11865_03_05.jpg)'
- en: 'Figure 3.5: The count of missing values in DCCC dataset'
  id: totrans-76
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3.5：DCCC数据集中缺失值的计数
- en: From these results, it is possible to say that the dataset is not missing any
    values, so no further procedure is required here.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 从这些结果可以看出，数据集中没有缺失任何值，因此在这里不需要进一步的步骤。
- en: '`BILL_AMT1` and `BILL_AMT4`, each with a participation of 2.3% of the total
    instances.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`BILL_AMT1` 和 `BILL_AMT4`，每个占总实例的2.3%。'
- en: This means that there are no further actions required considering that their
    participation is too little, and is unlikely to have an effect in the final model.
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这意味着考虑到它们的参与度太低，并且不太可能对最终模型产生影响，因此不需要进一步操作。
- en: '**Check for class imbalance**: Class imbalance occurs when the class labels
    in the target feature are not equally represented; for instance, a dataset containing
    90% of customers that did not default on the next payment, against 10% of customers
    that did, is considered to be imbalanced.'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**检查类别不平衡**：当目标特征中的类标签表示不均匀时，就会发生类别不平衡；例如，一个包含90%未来未违约客户与10%违约客户的数据集被认为是不平衡的。'
- en: 'There are several ways to handle class imbalance, some of which are explained
    here:'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 处理类别不平衡的几种方法，其中一些在这里解释：
- en: '**Collecting more data**: Although this is not always an available route, it
    may help balance out the classes, or allow the removal of the over-represented
    class without reducing the dataset severely.'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**收集更多数据**：尽管这并非总是可行的途径，但可能有助于平衡类别，或者允许删除过度表示类别而不严重减少数据集。'
- en: '**Changing performance metrics**: Some metrics, such as accuracy, are not good
    for measuring performance of imbalanced datasets. In turn, it is recommended to
    measure performance using metrics such as precision or recall for classification
    problems.'
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**更改性能指标**：某些指标，如准确性，不适合用于衡量不平衡数据集的性能。因此，建议使用精确度或召回率等指标来衡量分类问题的性能。'
- en: '**Resampling the dataset**: This consists of changing the dataset to balance
    out the classes. It can be done in two different ways: 1) adding copies of the
    under-represented class (called over-sampling), or, 2) deleting instances of the
    over-represented class (called under-sampling).'
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**对数据集进行重新采样**：这包括改变数据集以平衡各类别。可以通过两种不同的方式实现：1）添加欠表示类别的副本（称为过采样），或者，2）删除过度表示类别的实例（称为欠采样）。'
- en: 'Class imbalance can be detected by simply counting the occurrences of each
    of the classes in the target feature, as shown here:'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可以通过简单地计算目标特征中每个类别的出现次数来检测类别不平衡，如下所示：
- en: '[PRE3]'
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'From the preceding code, it is possible to conclude that the number of customers
    that defaulted on payments represents, 22.12% of the dataset. These results can
    also be displayed in a plot using the following lines of code:'
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从前述代码中可以得出结论，违约支付客户的数量占数据集的22.12%。这些结果也可以使用以下代码行显示在图中：
- en: '[PRE4]'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'This results in the following figure:'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这导致以下图表：
- en: '![Figure 3.6: The count of classes of the target feature](img/C11865_03_06.jpg)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![图3.6：目标特征的类别计数](img/C11865_03_06.jpg)'
- en: 'Figure 3.6: The count of classes of the target feature'
  id: totrans-91
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3.6：目标特征的类别计数
- en: In order to fix this problem, and considering that there is no more data to
    be added and that the performance metric is in fact the accuracy, it is necessary
    to perform data resampling.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，并考虑到没有更多数据可以添加，并且性能指标实际上是准确性，需要进行数据重新采样。
- en: 'The following is a code snippet that performs over-sampling over the dataset,
    randomly creating duplicated rows of the under-represented class:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是执行数据集过采样的代码片段，随机创建欠表示类别的重复行：
- en: '[PRE5]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: First, we separate the data for each class label into independent DataFrames.
    Next, we use pandas' `sample()` function to construct a new DataFrame that contains
    as many duplicated instances as the over-represented class' DataFrame.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将每个类标签的数据分别放入独立的DataFrame中。接下来，我们使用pandas的`sample()`函数构建一个包含与过度表示的类别DataFrame相同数量的重复实例的新DataFrame。
- en: Finally, the `concat()` function is used to concatenate the DataFrame of the
    over-represented class and the newly created DataFrame of the same size.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，使用`concat()`函数将过度表示类别的DataFrame和相同大小的新DataFrame连接起来。
- en: By calculating the participation of each class over the entire dataset, the
    result should show equally represented classes. Moreover, the final shape of the
    dataset to this point should be equal to (46728, 23).
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 通过计算整个数据集中每个类别的参与度，结果应显示出均衡的类别。此外，到目前为止数据集的最终形状应为（46728，23）。
- en: '**Split features from target**: We split the dataset into a features matrix
    and a target matrix, to avoid rescaling the target values:'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**从目标中分离特征**：我们将数据集分割成特征矩阵和目标矩阵，以避免重新调整目标值：'
- en: '[PRE6]'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '**Rescale the data**: Finally, we rescale the values of the features matrix
    in order to avoid introducing bias to the model:'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**重新调整数据**：最后，我们重新调整特征矩阵的值，以避免向模型引入偏差：'
- en: '[PRE7]'
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The result from the preceding lines of code are shown in *Figure 3.7*:'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 前面几行代码的结果显示在*图3.7*中：
- en: '![Figure 3.7: The features matrix after being normalized](img/C11865_03_07.jpg)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![图3.7：归一化后的特征矩阵](img/C11865_03_07.jpg)'
- en: 'Figure 3.7: The features matrix after being normalized'
  id: totrans-104
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Note
  id: totrans-105
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Consider that both **Marriage** and **Education** are ordinal features, meaning
    that they follow an order or hierarchy; when choosing a rescaling methodology,
    make sure to maintain order.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: 'With the purpose of facilitating the use of the prepared dataset for the upcoming
    activities, both the features (`X`) and target (`y`) matrices will be concatenates
    into one pandas DataFrame, which will be saved into a CSV file, using the following
    code:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: After performing all of these steps, the DCCC dataset is ready (in a new CSV
    file) to be used for training the model, which will be explained in the following
    section.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: Building the Model
  id: totrans-110
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Once the problem is defined and the data at hand is explored and prepared, it
    is time to define the model. The definition of the architecture of the network,
    the type of layers, the loss function, and so on should be dealt with after the
    previous analysis. This is mainly because there is no "one-size-fits-all" approach
    in machine learning, and even less so in deep learning.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: A regression task requires a different methodology than a classification task,
    and so does clustering, computer vision, or machine translation. Due to this,
    in the following section, you will find the key characteristics to building a
    model for solving a classification task, along with an explanation of how to arrive
    at a "good" architecture, and how and when to use custom modules in PyTorch.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: ANNs for Classification Tasks
  id: totrans-113
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As seen in the activity from the previous chapter, neural networks built for
    regression tasks use outputs as continuous values, which is why the output function
    is left without an activation function and with only one output node (the real
    value), as in the case of a model built to predict house prices based on the characteristics
    of the house and the neighborhood.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: Considering this, the measuring of performance should be done by calculating
    the difference between the ground truth and the predicted value, as in calculating
    the distance between 125.3 (the prediction) and 126.38 (the ground truth). As
    mentioned before, there are many ways to measure this difference, with the **mean
    squared error** (**MSE**), or its variation, the **root mean squared error** (**RMSE**),
    being the most commonly used metrics.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: Contrary to this, the output from a classification task is the probability of
    a certain set of input features belonging to each of the output labels or classes,
    which is done using a Sigmoid (for binary classification) or a Softmax (for multi-class
    classification) activation function. Moreover, for binary classification tasks,
    the output layer should contain one (for sigmoid) or two (for softmax) output
    nodes, while for multi-class classification tasks, the output nodes should be
    equal to the number of class labels.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: This ability to calculate the likelihood of belonging to each output class,
    coupled with an argmax function, will retrieve the class with higher probability
    as the final prediction.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 能够计算属于每个输出类的可能性的这种能力，再加上`argmax`函数，将检索具有更高概率的类作为最终预测。
- en: Note
  id: totrans-118
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注
- en: The argmax, in Python, is a function capable of returning the index of the maximum
    value along an axis.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在Python中，`argmax`是一个函数，能够返回沿着轴的最大值的索引。
- en: Considering this, the performance of the model should be a matter of whether
    the instances have been classified to the correct class label, rather than anything
    to do with the measuring of the distance between two values, hence the use of
    a different loss function (the cross-entropy being the most commonly used) for
    training neural networks for classification problems, as well as the use of different
    performance metrics, such as accuracy, precision, and recall.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这一点，模型的性能应该是实例是否已被分类到正确的类别标签的问题，而不是与测量两个值之间的距离有关的任何事情，因此训练神经网络用于分类问题的使用不同的损失函数（交叉熵是最常用的），以及使用不同的性能指标，如准确率、精确率和召回率。
- en: A Good Architecture
  id: totrans-121
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 一个良好的架构
- en: First of all, as has been explained throughout the book, it is important to
    understand the data problem at hand in order to determine the general topology
    of the neural network. Again, a regular classification problem does not require
    the same network architecture as a computer vision one.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，正如本书中所解释的那样，重要的是理解手头的数据问题，以确定神经网络的一般拓扑结构。再次强调，普通的分类问题不需要与计算机视觉问题相同的网络架构。
- en: Once this is defined, and considering that there is not a right answer in terms
    of determining the number of hidden layers, their type, or the number of units
    in each layer, the best approach is to get started with an initial architecture,
    which then can be improved to increment performance.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦定义了这一点，并考虑到在确定隐藏层数量、其类型或每个层中单元数量方面没有正确答案，最好的方法是从一个初始架构开始，然后可以改进以增加性能。
- en: Why is this so important? Because with a large number of parameters to tune,
    sometimes it can be difficult to commit to something and start. This is unfortunate
    considering that in training neural networks, there are several ways to determine
    what needs to be improved once an initial architecture has been trained and tested.
    In fact, the whole reason for dividing your dataset into three subsets is to allow
    for the possibility of training the dataset with one set, measuring and fine-tuning
    the model with another, and finally, measuring the performance of the final model
    with a final subset that has not been used before.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么这么重要？因为有大量参数需要调整时，有时很难承诺并开始。这是不幸的，因为在训练神经网络时，有几种方法可以确定一旦训练和测试了初始架构后需要改进的内容。实际上，将数据集分成三个子集的整个目的是允许用一个集合训练数据集，用另一个集合测量和微调模型，并最终用一个之前未使用过的最终子集测量最终模型的性能。
- en: 'Considering all this, the following set of conventions and rules of thumb will
    be explained to aid the decision process of defining the initial architecture
    of an ANN:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到所有这些，将解释以下一套惯例和经验法则，以帮助决策过程，定义人工神经网络的初始架构：
- en: '**Input layer**: This is simple enough – there is only one input layer, and
    its number of units is dependent on the shape of the training data. Specifically,
    the number of units in the input layer should be equal to the number of features
    that the input data contains.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输入层**：这很简单 - 只有一个输入层，其单元数取决于训练数据的形状。具体来说，输入层中的单元数应该等于输入数据包含的特征数。'
- en: '**Hidden layer**: Hidden layers can vary in quantity. ANNs can have one, more,
    or none. To choose the right number, it is important to consider the following:'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**隐藏层**：隐藏层的数量可以不同。人工神经网络可以有一个、多个或者没有隐藏层。要选择合适的数量，重要的是考虑以下几点：'
- en: The simpler the data problem, the fewer hidden layers it requires. Remember
    that data problems that can be linearly separable should only have one hidden
    layer. On the other hand, with the advancements of deep learning, it is now possible
    to solve really complex data problems with the use of many hidden layers (without
    limitation).
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 数据问题越简单，需要的隐藏层就越少。请记住，可以线性可分的数据问题应该只有一个隐藏层。另一方面，随着深度学习的进步，现在可以使用许多隐藏层（没有限制）来解决非常复杂的数据问题。
- en: The number of hidden units, to start off, should be between the number of units
    in the input layer and the number of units in the output layer.
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 要开始的隐藏单元数应该在输入层单元数和输出层单元数之间。
- en: '**Output layer**: Again, any ANN only has one output layer. The number of units
    that it contains depends on the learning task to be developed, as well as on the
    data problem. As explained before, for regression tasks, there would only be one
    unit, which is the predicted value. On the other hand, for classification problems,
    the number of units should be equal to the number of class labels available, considering
    that the output from the model should be the probability of a set of features
    belonging to each of the class labels.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输出层**：同样，任何人工神经网络只有一个输出层。它包含的单元数取决于要开发的学习任务以及数据问题。如前所述，对于回归任务，只会有一个单元，即预测值。另一方面，对于分类问题，单元数应等于可用的类标签数，考虑到模型的输出应该是一组特征属于每个类标签的概率。'
- en: '**Other parameters**: Conventionally, other parameters should be left with
    their default values for the first configuration of the network. This is mainly
    because it is always a good practice to test the simplest model over your data
    problem before considering more complex approximations that may perform equally
    well or worse, but will require more resources.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**其他参数**：传统上，应该将其他参数保留为网络的第一个配置的默认值。这主要是因为在考虑可能表现同样良好或更差但需要更多资源的更复杂近似方法之前，测试数据问题上最简单的模型是一种良好的实践。'
- en: Once an initial architecture has been defined, it is time to train and measure
    the performance of the model in order to perform further analysis, which will
    most likely result in changes in the architecture of the network or values of
    other parameters, such as changes in the learning rate or the addition of a regularization
    term.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦定义了初始架构，就是训练和评估模型性能的时候了，以便进行进一步的分析，这很可能会导致网络架构或其他参数值的更改，例如学习率的更改或添加正则化项。
- en: PyTorch Custom Modules
  id: totrans-133
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: PyTorch 自定义模块
- en: Custom modules were created by PyTorch's development team as a way to allow
    further flexibility to the user. Contrary to the `Sequential` container explored
    in previous chapters, custom modules should be used whenever there is a desire
    to build more complex model architectures, or whenever you wish to have further
    control over the calculations that occur in each layer.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch 的开发团队创建了自定义模块，以允许用户更进一步地灵活性。与前几章探讨的 `Sequential` 容器相反，只要希望构建更复杂的模型架构或者希望在每一层的计算中具有更多控制权，就应该使用自定义模块。
- en: Nevertheless, this does not mean that the custom module methodology can only
    be used in such scenarios. On the contrary, once you learn to use both approaches,
    it is a matter of preference when choosing which one to use for the less complex
    architectures.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，这并不意味着自定义模块方法只能在这种情况下使用。相反，一旦学会同时使用两种方法，选择在较不复杂的架构中使用哪种方法就成为一种偏好问题。
- en: 'Take, for instance, the following code snippet of a two-layer neural network
    defined using the `Sequential` container:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，以下代码片段展示了使用 `Sequential` 容器定义的两层神经网络：
- en: '[PRE9]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Here, `D_i` refers to the input dimensions (the features in the input data),
    `D_h` refers to the hidden dimensions (the number of nodes in a hidden layer),
    and `D_o` refers to the output dimensions.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，`D_i` 指的是输入维度（输入数据中的特征），`D_h` 指的是隐藏层的节点数（隐藏维度），`D_o` 指的是输出维度。
- en: 'Using custom modules, it is possible to build an equivalent network architecture,
    as shown here:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 使用自定义模块，可以构建一个等效的网络架构，如下所示：
- en: '[PRE10]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: It is important to mention that the cross-entropy loss function requires the
    output from the network to be raw (before obtaining the probabilities through
    the use of the softmax activation function), which is why it is common to find
    neural network architectures for classification problems without an activation
    function for the output layer. Moreover, in order to get a prediction out of this
    approach, it is necessary to apply the softmax activation function to the output
    of the network after being trained.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 需要提及的是，交叉熵损失函数要求网络输出是原始的（在通过 softmax 激活函数获得概率之前），这就是为什么在没有激活函数的情况下找到用于分类问题的神经网络架构是常见的。此外，在采用这种方法后，为了得到预测结果，需要在训练后将
    softmax 激活函数应用于网络输出。
- en: Another approach to handle this restriction is to use the `log_softmax` activation
    function for the output layer, instead. Next, the loss function is defined as
    the negative log likelihood loss (`nn.NLLLoss`). Finally, it is possible to get
    the actual probabilities of belonging to each class label by taking the exponential
    from the output of the network. This is the approach that will be used in the
    activities of this chapter.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 处理此限制的另一种方法是在输出层使用`log_softmax`激活函数。接下来，损失函数被定义为负对数似然损失(`nn.NLLLoss`)。最后，可以通过从网络输出中取指数来获取属于每个类标签的实际概率。这是本章活动中将要使用的方法。
- en: Once the model architecture has been defined, the following step would be to
    code the section in charge of training the model over the training data, as well
    as measuring its performance both over the training and validations sets.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦模型架构被定义，接下来的步骤将是编写负责在训练数据上训练模型并测量其在训练和验证集上性能的部分代码。
- en: 'Here, the step-by-step instructions to code what we have discussed will be
    given:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，将给出按步骤编码我们讨论过的内容的说明：
- en: '[PRE11]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: As can be seen, the first step is to define all the variables that will be used
    during the training of the network.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 如可见，第一步是定义在网络训练期间将使用的所有变量。
- en: Note
  id: totrans-147
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: As a reminder, "`epochs`" refers to the number of times that the entire dataset
    is passed forward and backward through the network architecture. "`batch_size`"
    refers to the number of training examples in a single batch (a slice of the dataset).
    Finally, iterations refer to the number of batches required to complete one epoch.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 提醒一下，“`epochs`”指的是整个数据集通过网络结构前后传递的次数。“`batch_size`”是单个批次（数据集的一个片段）中的训练样本数。最后，“iterations”指的是完成一个epoch所需的批次数。
- en: 'Next, a first `for` loop is used to go through the number of epochs defined
    previously. Following it, a new `for` loop is used to go through each batch of
    the total dataset until an epoch is completed. Inside this loop, the following
    computations occur:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，首先使用一个`for`循环遍历之前定义的epoch次数。随后，使用一个新的`for`循环遍历总数据集的每个批次，直到一个epoch完成。在这个循环内，发生以下计算：
- en: The model is trained over a batch of the training set. A prediction is obtained
    here.
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型在训练集的一个批次上进行训练。这里得到一个预测。
- en: The loss is calculated by comparing the prediction from the previous step and
    the labels from the training set (ground truth).
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过比较上一步的预测和训练集（地面真实）的标签来计算损失。
- en: The gradients are zeroed and calculated again for the current step.
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 梯度被归零，并且针对当前步骤再次计算。
- en: The parameters of the network are updated based on the gradients.
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据梯度更新网络的参数。
- en: 'The accuracy of the model over the training data is calculated as follows:'
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在训练数据上计算模型的准确率如下：
- en: Get the exponential of the predictions of the model in order to get the probabilities
    of a given piece of data belonging to each class label.
  id: totrans-155
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取模型预测的指数，以获得给定数据属于每个类标签的概率。
- en: Use the `topk()` method to get the class label with higher probability.
  id: totrans-156
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`topk()`方法获取具有较高概率的类标签。
- en: Using scikit-learn's metric section, calculate the accuracy, precision, or recall.
    You can also explore other performance metrics.
  id: totrans-157
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用scikit-learn的指标部分计算准确率、精确率或召回率。您还可以探索其他性能指标。
- en: 'The calculation of gradients is turned off in order to verify the performance
    of the current model over the validation data, which occurs as follows:'
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 关闭梯度计算，以验证当前模型在验证数据上的表现，具体操作如下：
- en: The model performs a prediction for the data in the validation set.
  id: totrans-159
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型对验证集中的数据进行预测。
- en: The loss function is calculated by comparing the previous prediction against
    the labels from the validation set.
  id: totrans-160
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过比较前一个预测和验证集标签来计算损失函数。
- en: 'To calculate the accuracy of the model over the validation set, use the same
    set of steps as for the same calculation over the training data:'
  id: totrans-161
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要计算模型在验证集上的准确率，使用与在训练数据上进行相同计算的步骤：
- en: '[PRE12]'
  id: totrans-162
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The preceding code snippet will print the loss and accuracy for both sets of
    data.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码片段将打印出训练集和验证集数据的损失和准确率。
- en: 'Activity 4: Building an ANN'
  id: totrans-164
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动 4：构建人工神经网络
- en: For this activity, using the previously prepared dataset, we will build a four-layer
    model that is able to determine whether a client will default the next payment.
    To do so, we will use the custom modules methodology.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 为了此活动，使用先前准备好的数据集，我们将构建一个能够确定客户是否会违约下一个付款的四层模型。为此，我们将使用自定义模块的方法。
- en: 'Let''s look at the following scenario: You work at a data science boutique
    that specializes in providing machine/deep learning solutions to banks all around
    the world. They have recently taken on a project for a bank that wishes to foresee
    the payments that will not be received the next month. The exploratory data analysis
    team has already prepared the dataset for you and they have asked you to build
    the model and calculate the accuracy of the model:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看以下场景：您在一家专门为全球各地的银行提供机器/深度学习解决方案的数据科学精品公司工作。他们最近接受了一个银行的项目，希望预测下个月不会收到的付款。探索性数据分析团队已经为您准备好了数据集，并要求您构建模型并计算模型的准确性：
- en: Import the following libraries.
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入以下库。
- en: '[PRE13]'
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Note
  id: totrans-169
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: Even with the use of a seed, the exact results of this activity will not be
    reproducible, considering that the training sets are shuffled before each epoch.
  id: totrans-170
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 即使使用了种子，由于每个epoch之前训练集都会被洗牌，因此这些活动的确切结果也无法再现。
- en: Read the previously prepared dataset, which should have been named `dccc_prepared.csv`.
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 读取先前准备好的数据集，该数据集应命名为`dccc_prepared.csv`。
- en: Separate the features from the target.
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将特征和目标分开。
- en: Using scikit-learn's `train_test_split` function, split the dataset into training,
    validation, and testing sets. Use a 60/20/20% split ratio. Set `random_state`
    as 0.
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用scikit-learn的`train_test_split`函数，将数据集分割为训练集、验证集和测试集。使用60/20/20%的分割比例。将`random_state`设置为0。
- en: Convert the validation and testing sets to tensors, considering that the features
    matrices should be of type float, while the target matrices should not. Leave
    the training sets unconverted for the moment as they will undergo further transformations.
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将验证集和测试集转换为张量，考虑到特征矩阵应为float类型，而目标矩阵则不应为float类型。目前保持训练集未转换，因为它们将经历进一步的转换。
- en: Build a custom module class defining the layers of the network. Include a forward
    function that specifies the activation functions that will be applied to the output
    of each layer. Use ReLU for all layers, except for the output, where you should
    use `log_softmax`.
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建一个自定义模块类来定义网络的各层。包括一个forward函数，指定将应用于每个层输出的激活函数。在所有层中使用ReLU，除了输出层，其中应使用`log_softmax`。
- en: Define all the variables required for the training of the model. Set the number
    of epochs to 50 and the batch size to 128\. Use a learning rate of 0.001.
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义训练模型所需的所有变量。将epoch数设置为50，批量大小设置为128。使用学习率0.001。
- en: Train the network using the training sets data. Use the validation sets to measure
    performance. To do so, save the loss and the accuracy for both the training and
    validation sets in each epoch.
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用训练集数据训练网络。使用验证集来衡量性能。因此，在每个epoch中保存训练集和验证集的损失和准确性。
- en: Note
  id: totrans-178
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The training process may take several minutes, depending on your resources.
    Adding print statements is a good practice to see the progress of the training
    process.
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 训练过程可能需要几分钟，具体取决于您的资源。添加打印语句是查看训练进程的良好实践。
- en: Plot the loss of both sets.
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制两个数据集的损失。
- en: Plot the accuracy of both sets.
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制两个数据集的准确性。
- en: Note
  id: totrans-182
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The solution for this activity can be found on page 192.
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 此活动的解决方案可以在第192页找到。
- en: Dealing with an Underfitted or Overfitted Model
  id: totrans-184
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 处理欠拟合或过拟合模型
- en: Building a deep learning solution is not just a matter of defining an architecture
    and then training a model using the input data; on the contrary, most would agree
    that that is the easy part. The art of creating high-tech models consists of achieving
    high levels of accuracy that surpass human performance. Given this, this section
    will introduce the topic of error analysis, which is commonly used to diagnose
    a trained model in order to discover what actions are more likely to have a positive
    impact in the performance of the model.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 建立深度学习解决方案不仅仅是定义架构然后使用输入数据训练模型的问题；相反，大多数人认为那只是简单部分。创建高科技模型的艺术在于实现超过人类性能的高准确性水平。鉴于此，本节将介绍错误分析的主题，该主题通常用于诊断已训练模型，以发现哪些操作更有可能对模型的性能产生积极影响。
- en: Error Analysis
  id: totrans-186
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 错误分析。
- en: Error analysis refers, as the name suggests, to the initial analysis of the
    error rate over the training and validation sets of data. This analysis is then
    used to determine the best book of action to improve the performance of the model.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 误差分析顾名思义是对训练和验证数据集的错误率进行初步分析。然后使用这个分析来确定改进模型性能的最佳方案。
- en: In order to perform error analysis, it is necessary to determine the Bayes error,
    also known as the irreducible error, which is the minimum achievable error. Several
    decades ago, the Bayes error was equivalent to human error, meaning that back
    then, the conceived minimum level of error was the one that experts could achieve.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 为了执行误差分析，需要确定贝叶斯误差，也称为不可约误差，这是可达到的最小误差。几十年前，贝叶斯误差等同于人类误差，这意味着那时专家可以达到的最低误差水平。
- en: Nowadays, with the improvements of technology and algorithms, this value has
    become increasingly difficult to estimate, as machines are capable of surpassing
    human performance, but there is no measure of how much better they can do in comparison
    to humans, as we can only understand as far as our capacity goes.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 如今，随着技术和算法的改进，估计这个值变得越来越困难，因为机器能够超越人类的表现，但我们无法衡量它们相比于人类能做得更好多少，因为我们只能理解到我们的能力所及。
- en: It is common for the Bayes error to be set equal to the human error, initially,
    to perform error analysis. However, this limitation is not set in stone, and researchers
    know that surpassing human performance should be an end goal as well.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 通常将贝叶斯误差初步设置为人类误差，以执行误差分析。然而，这种限制并不是一成不变的，研究人员知道，超越人类表现也应该是一个最终目标。
- en: 'The process of performing error analysis is as follows:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 执行误差分析的过程如下所示：
- en: Calculate the metric of choice to measure the performance of the model by. This
    measure should be calculated over both training and validation sets of data.
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算选择的指标来衡量模型的表现。这个度量应该在训练集和验证集上都计算。
- en: Using this measure, calculate the error rate of each of the sets by subtracting
    from 1 the performance metric previously calculated. Take, for instance, the following
    equation:![](img/C11865_03_08.jpg)
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用这个度量，通过从1中减去先前计算的性能指标来计算每个集合的错误率。例如，使用以下方程式：![](img/C11865_03_08.jpg)
- en: 'Figure 3.8: The equation to calculate the error rate of the model over the
    training set'
  id: totrans-194
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3.8：计算模型在训练集上错误率的方程式
- en: Subtract the Bayes error from the training set error (A). Save the difference,
    which will be used for further analysis.
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从训练集误差（A）中减去贝叶斯误差。保存这个差值，将用于进一步分析。
- en: Subtract the training set error from the validation set error (B) and save the
    value of the difference.
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从验证集错误（B）中减去训练集错误，并保存差值的值。
- en: 'Take the differences calculated in steps 3 and 4, and use the following set
    of rules:'
  id: totrans-197
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 取步骤3和4中计算的差异，并使用以下一组规则：
- en: If the difference calculated in step 3 is higher than the other, the model is
    underfitted, also described as high bias.
  id: totrans-198
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果步骤3中计算的差异高于其他差异，则模型欠拟合，也称为高偏差。
- en: 'If the difference calculated in step 4 is higher than the other, the model
    is overfitted, also known as high variance:'
  id: totrans-199
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果步骤4中计算的差异高于其他差异，则模型过拟合，也称为高方差：
- en: '![Figure 3.9: Diagram showing how to perform error analysis](img/C11865_03_09.jpg)'
  id: totrans-200
  prefs: []
  type: TYPE_IMG
  zh: '![图3.9：展示如何执行误差分析](img/C11865_03_09.jpg)'
- en: 'Figure 3.9: Diagram showing how to perform error analysis'
  id: totrans-201
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3.9：展示如何执行误差分析的图表
- en: The rules we've explained do not indicate that the model could only be suffering
    from one of the issues mentioned, but that the one with higher difference is having
    a greater effect on the performance of the model, which means that fixing it will
    improve the performance to a greater degree.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 我们解释的规则并不表明模型只能遭受提到的问题之一，而是高差异的那个问题对模型性能影响更大，修复它将更大程度地提高性能。
- en: 'Let''s explain how to deal with each of these issues:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们解释如何处理每个问题：
- en: '**High-bias**: An underfitted model, or a model suffering from high bias, is
    a model that is not capable of understanding the training data, and hence, it
    is not able to uncover patterns and generalize with other sets of data. This means
    that the model does not perform well over any set of data.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**高偏差**：欠拟合模型，或者受到高偏差影响的模型，是一种不能理解训练数据的模型，因此，它不能揭示模式并且不能与其他数据集泛化。这意味着该模型在任何数据集上的表现都不佳。'
- en: To decrease the bias affecting the model, it is recommended to define a bigger/deeper
    network (more hidden layers) or to train for more iterations. By adding more layers
    and increasing the training time, the network has more resources to discover the
    patterns that describe the training data.
  id: totrans-205
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为了减少影响模型的偏差，建议定义更大/更深的网络（增加隐藏层）或增加训练迭代次数。通过增加层数和增加训练时间，网络有更多资源来发现描述训练数据的模式。
- en: '**High-variance**: An overfitted model, or a model suffering from high variance,
    is a model that is having trouble generalizing the training data; it is learning
    the details of the training data too well, including its outliers. This means
    that the model is performing too well over the training data, but poorly over
    other sets of data.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**高方差**：一个过拟合的模型或者受到高方差影响的模型，是指模型在泛化训练数据时出现困难；它过于深入学习训练数据的细节，包括异常值。这意味着模型在训练数据上表现过好，但在其他数据集上表现不佳。'
- en: This is typically handled by adding more data to the training set, or by adding
    a regularization term to the loss function. The first approach aims to force the
    network to generalize to the data rather than understand the details of a small
    quantity of examples. The second approach, on the other hand, penalizes the inputs
    that have higher weights in order to overlook outlier values, and equally consider
    all values.
  id: totrans-207
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通常可以通过向训练集添加更多数据或在损失函数中添加正则化项来处理这种情况。第一种方法旨在强制网络泛化到数据，而不是理解少量示例的细节。另一种方法则通过惩罚具有更高权重的输入来忽略异常值，并平等考虑所有值。
- en: Considering this, dealing with one condition that is affecting the model may
    cause another one to appear or increase. For instance, a model suffering from
    high bias, after being treated may improve its performance over the training data
    but not over the validation data, which means that the model will have started
    to suffer from high variance and would require another set of remedial actions
    to be taken.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这一点，处理影响模型的一个条件可能会导致另一个条件的出现或增加。例如，一个受到高偏差影响的模型，在处理后可能会改善其在训练数据上的表现，但在验证数据上却没有改善，这意味着模型开始受到高方差的影响，并需要采取另一组补救措施。
- en: Once the model has been diagnosed and the required measures have been taken
    to improve the performance, the best models should be selected for a final test.
    Each of these models should be used to perform predictions over the testing set
    (the only set that does not have an effect on the building of the model).
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦对模型进行了诊断并采取了必要的措施来提高性能，应选择最佳模型进行最终测试。每个模型都应用于对测试集的预测（这是唯一不会影响模型构建的数据集）。
- en: Considering this, it would be possible to select the final model as the one
    that performs best over the testing data. This is mainly because the performance
    over the testing data serves as an indicator of the model's performance on future
    unseen sets of data, which is the ultimate goal.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这一点，可以选择在测试数据上表现最佳的模型作为最终模型。这主要是因为在测试数据上的表现作为模型在未来未见数据集上性能的指标，这是最终目标。
- en: 'Exercise 7: Performing Error Analysis'
  id: totrans-211
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 7：执行误差分析
- en: 'Using the accuracy metric calculated in the previous activity, in this activity,
    we will perform error analysis, which will help us determine the actions to be
    performed over the model in the upcoming activity:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 使用前一活动计算的准确度指标，在本活动中我们将执行错误分析，帮助我们确定下一活动中需要执行的行动：
- en: Note
  id: totrans-213
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: This activity does not require coding, but rather analysis of the previous activity's
    results.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 此活动无需编码，而是要分析前一活动的结果。
- en: 'Assuming a Bayes error of 0.15, perform error analysis and diagnose the model:'
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 假设贝叶斯错误率为0.15，执行错误分析并诊断模型：
- en: '[PRE14]'
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The values used as the accuracy of both sets (0.715 and 0.706) are the ones
    obtained during the last iteration of the previous activity.
  id: totrans-217
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 作为两个集合准确性的值（0.715 和 0.706），它们是在前一活动的最后迭代中获得的。
- en: '[PRE15]'
  id: totrans-218
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: According to this, the model is suffering from high bias, meaning that the model
    is underfitted.
  id: totrans-219
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 根据此，模型存在高偏差问题，意味着模型欠拟合。
- en: Determine the actions to be followed to improve accuracy of the model.
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确定要遵循以提高模型准确性的行动方案。
- en: To improve the model's performance, two books of actions that can be followed
    are incrementing the number of epochs and increasing the number of hidden layers
    and/or the number of units.
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为了提高模型的性能，可以采取以下两种行动方案：增加迭代次数并增加隐藏层和/或单元数。
- en: In accordance with this, a set of tests can be performed in order to arrive
    at the best result.
  id: totrans-222
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 根据此，可以进行一系列测试，以达到最佳结果。
- en: Congratulations! You have successfully performed error analysis.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜！您已成功进行了错误分析。
- en: 'Activity 5: Improving a Model''s Performance'
  id: totrans-224
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动5：改善模型性能
- en: 'For the following activity, we will implement the actions defined in the exercise
    to reduce the high bias that is affecting the performance of the model. Let''s
    look at the following scenario: after delivering the model to your teammates,
    they are impressed with your work and the way that your code is organized (well
    done!), but they have asked you to try improving the performance to 80%, considering
    that this is what they promised to the client:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 对于接下来的活动，我们将实施在练习中定义的操作，以减少影响模型性能的高偏差。让我们看一下以下情景：在将模型交付给您的队友后，他们对您的工作以及您组织代码的方式印象深刻（做得好！），但他们要求您尝试将性能提高到80%，考虑到这是他们向客户承诺的。
- en: Note
  id: totrans-226
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: Use a different notebook for this activity. There, you will load the dataset
    again, and perform similar steps as in the previous activity, with the difference
    being that the training process will be done several times to train different
    architectures and training times.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 使用不同的笔记本进行此活动。在那里，您将再次加载数据集，并执行与上一个活动类似的步骤，不同之处在于训练过程将多次进行，以训练不同的架构和训练时间。
- en: Import the same libraries as in the previous activity.
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入与上一个活动相同的库。
- en: Load the data and split the features from the target. Next, split the data into
    three subsets (training, validation, and testing), using a 60:20:20 split ratio.
    Finally, convert the validation and testing sets into PyTorch tensors, just as
    you did in the previous activity.
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载数据并将特征与目标分离。然后，将数据分成三个子集（训练、验证和测试），使用60:20:20的分割比例。最后，将验证和测试集转换为PyTorch张量，就像您在上一个活动中所做的那样。
- en: Considering that the model is suffering from high bias, the focus should be
    on increasing the number of epochs or increasing the size of the network by adding
    additional layers or units to each layer. The aim should be to approximate the
    accuracy over the testing set to 80%.
  id: totrans-230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 考虑到模型正在遭受高偏差，重点应放在增加epochs的数量或通过添加额外的层或单位来增加网络的大小。目标应该是将测试集上的准确性近似到80%。
- en: Note
  id: totrans-231
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: Consider that there is not a right way to choose which test to carry out first,
    so be creative and analytical. If changes in your model's architecture reduce
    or eliminate the high bias but introduce high variance, then consider, for instance,
    keeping the changes but adding some measure to combat the high variance.
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 考虑到选择先进行哪项测试没有正确的方法，因此要有创造性和分析能力。如果模型架构的更改减少或消除了高偏差，但引入了高方差，则考虑保留这些更改，同时添加一些措施来对抗高方差。
- en: Plot the loss and accuracy for both sets of data.
  id: totrans-233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制两组数据的损失和准确率。
- en: Using the best performing model, perform prediction over the testing set (which
    should have not been used during the fine-tuning process). Compare the prediction
    to the ground truth by calculating the accuracy of the model over this set.
  id: totrans-234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用表现最佳的模型，对测试集进行预测（在微调过程中不应使用）。通过计算模型在此集合上的准确性，将预测与实际情况进行比较。
- en: Note
  id: totrans-235
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The solution for this activity can be found on page 196.
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可在第196页找到此活动的解决方案。
- en: Deploying Your Model
  id: totrans-237
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 部署您的模型
- en: By now, the key concepts and tips for building exceptional deep learning models
    for regular regression and classification problems have been discussed and put
    into practice. In real life, models are not just built for learning purposes.
    On the contrary, when training models for purposes other than research, the main
    idea is to be able to reuse them in the future to perform predictions over new
    data that, although the model was not trained on, the model should perform similarly
    well with.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，已经讨论并实践了用于常规回归和分类问题构建出色深度学习模型的关键概念和技巧。在现实生活中，模型不仅仅是为了学习目的而构建的。相反，当为除研究目的以外的目的训练模型时，主要思想是能够在未来重复使用它们，以对新数据执行预测，即使该模型未经训练，也应该表现出类似的良好性能。
- en: In a small organization, the ability to serialize and deserialize models suffices.
    However, when models are to be used by large corporations, by users, or to alter
    a massively important and large task, it is a better practice to convert the model
    to a format that can be used in most production environments, such as APIs, websites,
    online and offline applications, and so on.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 在小型组织中，序列化和反序列化模型的能力就足够了。然而，当模型需要被大型企业、用户使用或用于改变重要且大型任务时，将模型转换为能在大多数生产环境中使用的格式，如
    API、网站、在线和离线应用等，会是更好的做法。
- en: In accordance with this, in this section, we will learn how to save and load
    models, as well as how to use PyTorch's most recent feature for converting your
    model into a C++ application that is highly versatile.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 根据此文，本节中我们将学习如何保存和加载模型，以及如何使用 PyTorch 的最新功能将您的模型转换为高度通用的 C++ 应用程序。
- en: Saving and Loading Your Model
  id: totrans-241
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 保存和加载您的模型
- en: As you might imagine, retraining a model every time it is to be used is highly
    impractical, especially considering that most deep learning models may take quite
    some time to train (depending on your resources).
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能想象，每次使用模型都重新训练是非常不实际的，尤其是考虑到大多数深度学习模型可能需要相当长的时间来训练（根据您的资源）。
- en: Instead, models in PyTorch can be trained, saved, and reloaded to either perform
    further training or to make inferences. This can be achieved considering that
    the parameters (weights and biases) for each layer of PyTorch models are saved
    into the `state_dict dictionary`.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，PyTorch 中的模型可以被训练、保存和重新加载，以进行进一步的训练或推断。这可以通过保存每个 PyTorch 模型层的参数（权重和偏置）到 `state_dict`
    字典中来实现。
- en: 'Here, a step-by-step guide is given on how to save and load a trained model:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 这里提供了关于如何保存和加载训练过的模型的逐步指南：
- en: 'Originally, a checkpoint of a model will only include the model''s parameters.
    However, when loading the model, this is not the only information required, but
    depending on the arguments that your classifier takes in, it may be necessary
    to save further information, such as the number of input units. Considering this,
    the first step is to define the information to be saved:'
  id: totrans-245
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最初，模型的检查点仅包括模型的参数。然而，在加载模型时，不仅需要这些信息，还可能需要保存其他信息，例如输入单元的数量，这取决于分类器接受的参数。因此，第一步是定义要保存的信息：
- en: '[PRE16]'
  id: totrans-246
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: This will save into the checkpoint the number of units in the input layer, which
    will come in handy when loading the model.
  id: totrans-247
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 当加载模型时，将保存输入层中的单位数到检查点中将非常有用。
- en: Using the text editor of your choice, create a Python file that imports PyTorch
    libraries and contains the class that creates the network architecture of your
    model. This is done to be able to conveniently load the model into a new worksheet,
    other than the one you used to train the model.
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用您选择的文本编辑器创建一个 Python 文件，导入 PyTorch 库，并包含创建模型网络架构的类。这样做是为了能够方便地将模型加载到不同于训练模型所用的工作表中。
- en: 'Save the model using PyTorch''s `save()` function:'
  id: totrans-249
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 PyTorch 的 `save()` 函数保存模型：
- en: '[PRE17]'
  id: totrans-250
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The first argument refers to the dictionary previously created, and the second
    arguments is the filename to be used.
  id: totrans-251
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 第一个参数是先前创建的字典，第二个参数是要使用的文件名。
- en: 'To load the model, let''s create a function that will perform three main actions:'
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要加载模型，让我们创建一个执行三个主要操作的函数：
- en: '[PRE18]'
  id: totrans-253
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The function receives as input the path to the saved model file. First, the
    checkpoint is loaded. Next, a model is initialized using the network's architecture
    saved into the Python file. Here, `final_model` refers to the name of the Python
    file, which should have been imported to the new worksheet, and `Classifier()`
    refers to the name of the class saved in that file. This model will have randomly
    initialized parameters. Finally, the parameters from the checkpoint are loaded
    into the model.
  id: totrans-254
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 函数接收保存的模型文件路径作为输入。首先加载检查点，接着使用保存在 Python 文件中的网络架构初始化模型。这里，`final_model` 是 Python
    文件的名称，应该已经被导入到新的工作表中，而 `Classifier()` 是保存在该文件中的类的名称。此模型将具有随机初始化的参数。最后，将检查点中的参数加载到模型中。
- en: When called, this function returns the trained model, which now can be used
    for further training or to perform inferences.
  id: totrans-255
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 调用时，该函数返回经过训练的模型，现在可以用于进一步训练或进行推断。
- en: PyTorch for Production in C++
  id: totrans-256
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: PyTorch 用于 C++ 生产环境
- en: As per the name of the framework, PyTorch's primary interface is the Python
    programming language. This is mainly due to the preference of this programming
    language by many users, thanks to the language's dynamism and ease of use for
    developing machine learning solutions.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 根据框架名称，PyTorch的主要接口是Python编程语言。这主要是因为许多用户偏爱这种编程语言，因为它的动态性和用于开发机器学习解决方案的易用性。
- en: Nevertheless, in some scenarios, Python properties become unfavorable. This
    is precisely the case for environments developed for production, where other programming
    languages have been proved to be more useful. Such is the case with C++, which
    is widely used for production purposes with machine/deep learning solutions.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在某些情况下，Python的特性变得不利。这正是为生产环境开发的场景，其他编程语言被证明更有用的情况。例如，C++广泛用于机器/深度学习解决方案的生产目的。
- en: Given this, PyTorch recently proposed an easy approach to allow users to enjoy
    the benefits of both worlds. While they get to continue programming in a Pythonic
    nature, there is now the possibility to serialize your model into a representation
    that can be loaded and executed from C++, with no dependency on Python.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于此，PyTorch最近提出了一个简单的方法，允许用户享受两个世界的好处。虽然他们继续以Python方式编程，但现在有可能将模型序列化为可以在C++中加载和执行的表示形式，不依赖于Python。
- en: 'Converting a PyTorch model into a Torch Script is done through PyTorch''s JIT
    (Just-In-Time) compiler module. It is achieved by passing your model, along with
    an example input, through the `torch.jit.trace()` function, as shown here:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 将PyTorch模型转换为Torch Script是通过PyTorch的JIT（即时编译）模块完成的。通过将你的模型以及示例输入传递给`torch.jit.trace()`函数来实现，如下所示：
- en: '[PRE19]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'This will return a script module, which can be used as a regular PyTorch module,
    as shown here:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 这将返回一个脚本模块，可以像常规的PyTorch模块一样使用，如下所示：
- en: '[PRE20]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: The above will return the output obtained from running the input data through
    your model.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 上述操作将返回通过模型运行输入数据得到的输出。
- en: 'Activity 6: Making Use of Your Model'
  id: totrans-265
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动6：利用你的模型
- en: 'For this activity, save the model created in the previous activity. Moreover,
    the saved model will be loaded into a new notebook for use. What we will do is
    convert the model into a serialized representation than can be executed on C++.
    Let''s look at the following scenario: wow! Everyone is very happy with your commitment
    to improving the model, as well as with the final version of it, so they have
    asked you to save the model, as well as to convert it into a format that they
    can use to build an online application for the client.'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个活动，保存在前一活动中创建的模型。此外，保存的模型将加载到一个新的笔记本中供使用。我们将把模型转换为一个序列化的表示形式，可以在C++上执行。让我们看一下以下的情景：哇！大家都对你改进模型的承诺以及最终版本感到非常满意，因此他们要求你保存模型，并将其转换为可以用于客户端构建在线应用程序的格式。
- en: Note
  id: totrans-267
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: This activity will make use of two Jupyter notebooks. First, we will use the
    same notebook as from the previous activity to save the final model. Next, we
    will open a new notebook, which will be used to loading the saved model.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 这个活动将使用两个Jupyter笔记本。首先，我们将使用与前一活动相同的笔记本保存最终模型。接下来，我们将打开一个新的笔记本，用于加载保存的模型。
- en: Open the Jupyter notebook that you used for the previous activity.
  id: totrans-269
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开你用于前一活动的Jupyter笔记本。
- en: Save a Python file containing the class where you define the architecture of
    your best performing module. Make sure to import PyTorch's required libraries
    and modules. Name it `final_model.py`.
  id: totrans-270
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 保存一个包含定义你的最佳性能模块架构的类的Python文件。确保导入PyTorch所需的库和模块。命名为`final_model.py`。
- en: Save the best-performing model. Make sure to save the information of the units
    of each layer along with the parameters of the model. Name it `checkpoint.pth`.
  id: totrans-271
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 保存表现最佳的模型。确保保存每层单元的信息以及模型的参数。命名为`checkpoint.pth`。
- en: Open a new Jupyter notebook.
  id: totrans-272
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个新的Jupyter笔记本。
- en: Import PyTorch, as well as the Python file previously created.
  id: totrans-273
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入PyTorch，以及之前创建的Python文件。
- en: Create a function that loads the model.
  id: totrans-274
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个加载模型的函数。
- en: Perform a prediction by inputting the following tensor into your model.
  id: totrans-275
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过将以下张量输入到你的模型中进行预测。
- en: '[PRE21]'
  id: totrans-276
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Convert the model using JIT module.
  id: totrans-277
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用JIT模块转换模型。
- en: Perform a prediction by inputting the same tensor to the traced script of your
    model.
  id: totrans-278
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过输入相同的张量到你的模型的追踪脚本中执行预测。
- en: Note
  id: totrans-279
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The solution for this activity can be found on page 202.
  id: totrans-280
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 此活动的解决方案可在202页找到。
- en: Summary
  id: totrans-281
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结
- en: After covering most of the theoretical knowledge in the previous chapters, this
    chapter uses a real-life case study to cement our knowledge. The idea is to encourage
    learning by practice with a hands-on approach.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 在前几章涵盖了大部分理论知识之后，本章通过一个真实案例研究来巩固我们的知识。其想法是通过实践和动手操作来鼓励学习。
- en: The chapter starts off by explaining the influence of deep learning in a wide
    range of industries, where accuracy is required. One of the main industries driving
    deep learning's growth is banking and finance, where such algorithms are being
    used in domains such as the evaluation of loan applications, the detection of
    fraud, and the evaluation of past decision-making to foresee future behavior,
    mainly due to the algorithm's ability to supersede human performance in these
    respects.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 本章首先解释了深度学习在需要精确度的广泛行业中的影响。推动深度学习增长的主要行业之一是银行和金融，这些算法在诸如评估贷款申请、欺诈检测以及评估过去决策以预见未来行为等领域中得到应用，主要是由于这些算法在这些方面能够超越人类的表现。
- en: This chapter used a real-life dataset from an Asian bank, with the objective
    of predicting whether a client would default on a payment. The chapter started
    with the development of the solution by explaining the importance of defining
    the what, why, and how of any data problem, as well as analyzing the data at hand
    to make the best use of it.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 本章使用了一个来自亚洲银行的真实数据集，目标是预测客户是否会违约。本章从解决方案的开发开始，通过解释定义数据问题的什么、为什么和如何的重要性，以及分析手头的数据来最大程度地利用它。
- en: Once the data was prepared according to the problem definition, the chapter
    explored the idea of defining a "good" architecture. In this subject, even though
    there are a couple rules of thumb that can be considered, the main takeaway was
    to build an initial architecture without overthinking it, in order to get some
    results that can be used to perform error analysis to improve the model's performance.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦数据根据问题定义准备好，本章探讨了定义“好”架构的想法。在这个主题中，即使有几个经验法则可以考虑，主要的要点是不要过度思考，构建一个初始架构以获得一些可以用于执行错误分析以改进模型性能的结果。
- en: The idea of error analysis consists of analyzing the error rate of the model
    over the training and validation sets in order to determine whether the model
    is suffering in greater proportion from high bias or high variance. This diagnosis
    of the model is then used to alter the model's architecture and some of the learning
    parameters, which will result in an improvement of performance.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 错误分析的概念包括分析模型在训练集和验证集上的错误率，以确定模型是否在更大比例上受到高偏差或高方差的影响。然后利用模型的这一诊断来修改模型的架构和一些学习参数，从而提高性能。
- en: Finally, the chapter explored two main approaches for making use of the best
    performing model. The first approach consists of saving the model, and then reloading
    it into any coding platform to continue training or to perform inferences. On
    the other hand, the second approach is mainly used to launch the model into production
    and is achieved by making use of PyTorch's JIT module, which created a serialized
    representation of the model that can be run on C++.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，本章探讨了两种利用表现最佳模型的主要方法。第一种方法是保存模型，然后将其重新加载到任何编码平台以继续训练或执行推断。另一种方法主要用于将模型投入生产，并通过使用PyTorch的JIT模块来实现，该模块创建了一个可以在C++上运行的模型的序列化表示。
- en: In the next chapter, we'll focus on solving simple classification tasks using
    Deep Neural Networks.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章中，我们将专注于使用深度神经网络解决简单的分类任务。
