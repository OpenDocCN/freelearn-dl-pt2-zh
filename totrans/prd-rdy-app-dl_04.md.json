["```py\nfrom torch.utils.data import Dataset\nclass SampleDataset(Dataset):\n   def __len__(self):\n      \"\"\"return number of samples\"\"\"\n   def __getitem__(self, index):\n      \"\"\"loads and returns a sample from the dataset at the given index\"\"\"\n```", "```py\nfrom torch.utils.data import DataLoader\nfrom pytorch_lightning.core.lightning import LightningDataModule\nclass SampleDataModule(LightningDataModule):\n   def prepare_data(self):\n       \"\"\"download and preprocess the data; triggered only on single GPU\"\"\"\n       ...\n   def setup(self):\n       \"\"\"define necessary components for data loading on each GPU\"\"\"\n       ...\n   def train_dataloader(self):\n       \"\"\"define train data loader\"\"\"\n       return data.DataLoader(\n         self.train_dataset, \n           batch_size=self.batch_size, \n           shuffle=True)\n   def val_dataloader(self):\n       \"\"\"define validation data loader\"\"\"\n       return data.DataLoader(\n          self.validation_dataset, \n          batch_size=self.batch_size, \n          shuffle=False)             \n   def test_dataloader(self):\n       \"\"\"define test data loader\"\"\"\n       return data.DataLoader(\n          self.test_dataset, \n          batch_size=self.batch_size, \n          shuffle=False)\n```", "```py\nfrom pytorch_lightning import LightningModule\nfrom torch import nn\nclass SampleModel(LightningModule):\n   def __init__(self):\n      \"\"\"instantiate necessary layers\"\"\"\n       self.individual_layer_1 = nn.Linear(..., ...)\n       self.individual_layer_2 = nn.Linear(..., ...)\n       self.individual_layer_3 = nn.Linear(..., ...)\n   def forward(self, input):\n       \"\"\"define forward propagation logic\"\"\"\n       output_1 = self.individual_layer_1(input)\n       output_2 = self.individual_layer_2(output_1)\n       final_output = self.individual_layer_3(output_2)\n       return final_output\n```", "```py\nclass SampleModel(LightningModule):\n   def __init__(self):\n       \"\"\"instantiate necessary layers\"\"\"\n       self.multiple_layers = nn.Sequential(\n       nn.Linear(    ,    ),\n       nn.Linear(    ,    ),\n       nn.Linear(    ,    ))\n   def forward(self, input):\n       \"\"\"define forward propagation logic\"\"\"\n       final_output = self.multiple_layers(input)\n       return final_output\n```", "```py\nlinear_layer = torch.nn.Linear(\n              in_features,   # Size of each input sample\n              out_features,  # Size of each output sample)\n# N = batch size\n# * = any number of additional dimensions\ninput_tensor = torch.rand(N, *, in_features)\noutput_tensor = linear_layer(input_tensor) # (N, *, out_features)\n```", "```py\n# 2D max pooling\nmax_pool_layer = torch.nn.MaxPool2d(\n   kernel_size,         # the size of the window to take a max over\n   stride=None,         # the stride of the window. Default value is kernel_size\n   padding=0,           # implicit zero padding to be added on both sides\n   dilation=1,          # a parameter that controls the stride of elements in the window)\n# N = batch size\n# C = number of channels\n# H = height of input planes in pixels\n# W = width of input planes in pixels\ninput_tensor = torch.rand(N, C, H, W)\noutput_tensor = max_pool_layer(input_tensor) # (N, C, H_out, W_out) \n```", "```py\n# 2D average pooling\navg_pool_layer = torch.nn.AvgPool2d(\n   kernel_size,         # the size of the window to take a max over\n   stride=None,         # the stride of the window. Default value is kernel_size\n   padding=0,           # implicit zero padding to be added on both sides)\n# N = batch size\n# C = number of channels\n# H = height of input planes in pixels\n# W = width of input planes in pixels\ninput_tensor = torch.rand(N, C, H, W)\noutput_tensor = avg_pool_layer(input_tensor) # (N, C, H_out, W_out)\n```", "```py\nbatch_norm_layer = torch.nn.BatchNorm2d(\n   num_features,      # Number of channels in the input image\n   eps=1e-05,         # A value added to the denominator for numerical stability\n   momentum=0.1,      # The value used for the running_mean and running_var computation\n   affine=True,       # a boolean value that when set to True, this module has learnable affine parameters)\n# N = batch size\n# C = number of channels\n# H = height of input planes in pixels\n# W = width of input planes in pixels\ninput_tensor = torch.rand(N, C, H, W)\noutput_tensor = batch_norm_layer(input_tensor) # same shape as input (N, C, H, W)\n```", "```py\ndrop_out_layer = torch.nn.Dropout2d(\n   p=0.5,  # probability of an element to be zeroed )\n# N = batch size\n# C = number of channels\n# H = height of input planes in pixels\n# W = width of input planes in pixels\ninput_tensor = torch.rand(N, C, H, W)\noutput_tensor = drop_out_layer(input_tensor) # same shape as input (N, C, H, W)\n```", "```py\nconv_layer = torch.nn.Conv2d(\n   in_channels,         # Number of channels in the input image\n   out_channels,        # Number of channels produced by the convolution\n   kernel_size,         # Size of the convolving kernel\n   stride=1,            # Stride of the convolution\n   padding=0,           # Padding added to all four sides of the input.\n   dilation=1,          # Spacing between kernel elements)\n# N = batch size\n# C = number of channels\n# H = height of input planes in pixels\n# W = width of input planes in pixels\ninput_tensor = torch.rand(N, C_in, H, W)\noutput_tensor = conv_layer(input_tensor) # (N, C_out, H_out, W_out)\n```", "```py\n# multi-layer Elman RNN with tanh or ReLU non-linearity to an input sequence.\nrnn = torch.nn.RNN(\n   input_size,                     # The number of expected features in the input x\n   hidden_size,                    # The number of features in the hidden state h\n   num_layers = 1,                 # Number of recurrent layers\n   nonlinearity=\"tanh\",            # The non-linearity to use. Can be either 'tanh' or 'relu'\n   bias=True,                      # If False, then the layer does not use bias weights\n   batch_first=False,              # If True, then the input and output tensors are provided\n                                                                                                 # as (batch, seq, feature) instead of (seq, batch, feature)\n             dropout=0,                                                # If non-zero, introduces a Dropout layer on the outputs of each RNN layer\n                                                                                                 # except the last layer, with dropout probability equal to dropout\n   bidirectional=False,             # If True, becomes a bidirectional RNN)\n# N = batch size\n# L = sequence length\n# D = 2 if bidirectionally, otherwise 1\n# H_in = input_size\n# H_out = hidden_size\nrnn = nn.RNN(H_in, H_out, num_layers)\ninput_tensor = torch.randn(L, N, H_in)\n# H_0 = tensor containing the initial hidden state for each element in the batch\nh0 = torch.randn(D * num_layers, N, H_out)\n# output_tensor (L, N, D * H_out)\n# hn (D * num_layers, N, H_out) \noutput_tensor, hn = rnn(input_tensor, h0)\n```", "```py\nclass SampleModel(LightningModule):\n   def configure_optimizers(self):\n      \"\"\"Define optimizer to use\"\"\"\n      return torch.optim.Adam(self.parameters(), lr=0.02)\n   def training_step(self, batch, batch_idx):\n      \"\"\"Define single training iteration\"\"\"\n      x, y = batch\n      y_hat = self(x)\n      loss = F.cross_entropy(y_hat, y)\n      return loss\n```", "```py\n   def validation_step(self, batch, batch_idx):\n      \"\"\"Define single validation iteration\"\"\"\n      loss, acc = self._shared_eval_step(batch, batch_idx)\n      metrics = {\"val_acc\": acc, \"val_loss\": loss}\n      self.log_dict(metrics)\n      return metrics\n   def test_step(self, batch, batch_idx):\n      \"\"\"Define single test iteration\"\"\"\n      loss, acc = self._shared_eval_step(batch, batch_idx)\n      metrics = {\"test_acc\": acc, \"test_loss\": loss}\n      self.log_dict(metrics)\n      return metrics\n   def _shared_eval_step(self, batch, batch_idx):\n      x, y = batch\n      outputs = self(x)\n      loss = self.criterion(outputs, targets)\n      acc = accuracy(outputs.round(), targets.int())\n      return loss, acc\n   def predict_step(self, batch, batch_idx, dataloader_idx=0):\n      \"\"\"Compute prediction for the given batch of data\"\"\"\n      x, y = batch\n      y_hat = self(x)\n      return y_hat\n```", "```py\nmodel.train()\ntorch.set_grad_enabled(True)\nouts = []\nfor batch_idx, batch in enumerate(train_dataloader):\n   loss = training_step(batch, batch_idx)\n   outs.append(loss.detach())\n   # clear gradients\n   optimizer.zero_grad()\n   # backward\n   loss.backward()\n   # update parameters\n   optimizer.step()\n   if validate_at_some_point\n      model.eval()\n      for val_batch_idx, val_batch in enumerate(val_dataloader):\n         val_out = model.validation_step(val_batch, val_batch_idx)\n         model.train()\n```", "```py\nfrom pytorch_lightning import Trainer\ndata_module = SampleDataModule()\ntrainer = Trainer(max_epochs=num_epochs)\nmodel = SampleModel()\ntrainer.fit(model, data_module)\nresult = trainer.test()\n```", "```py\nloss = nn.MSELoss(reduction='mean')\ninput = torch.randn(3, 5, requires_grad=True)\ntarget = torch.randn(3, 5)\noutput = loss(input, target)\n```", "```py\nLoss = nn.L1Loss(reduction='mean')\ninput = torch.randn(3, 5, requires_grad=True)\ntarget = torch.randn(3, 5)\noutput = loss(input, target)\n```", "```py\nloss = nn.CrossEntropyLoss(reduction=\"mean\")\ninput = torch.randn(3, 5, requires_grad=True)\ntarget = torch.empty(3, dtype=torch.long).random_(5)\noutput = loss(input, target)\n```", "```py\nloss = torch.nn.BCEWithLogitsLoss(reduction=\"mean\")\ninput = torch.randn(3, requires_grad=True)\ntarget = torch.empty(3).random_(2)\noutput = loss(input, target)\n```", "```py\ndef custom_mse_loss(output, target):\n   loss = torch.mean((output - target)**2)\n   return loss\ninput = torch.randn(3, 5, requires_grad=True)\ntarget = torch.randn(3, 5)\noutput = custom_mse_loss(input, target)\n```", "```py\noptimizer = torch.optim.SGD(model.parameters(), lr=0.1 momentum=0.9, nesterov=True)\n```", "```py\noptimizer = torch.optim.Adam(model.parameters(), lr=0.1) \n```", "```py\nimport tensorflow_datasets as tfds\nclass DataLoader: \n   \"\"\" DataLoader class\"\"\"\n   @staticmethod \n   def load_data(config): \n      return tfds.load(config.data_url)\n```", "```py\n    import tensorflow as tf \n    dataset = tf.data.TFRecordDataset(list_of_files)\n    ```", "```py\n    dataset = tf.data.Dataset.from_tensor_slices(numpy_array)\n    ```", "```py\n    dataset = tf.data.Dataset.from_tensor_slices((df_features.values, df_target.values))\n    ```", "```py\n    def data_generator(images, labels):\n       def fetch_examples(): \n           i = 0 \n           while True: \n              example = (images[i], labels[i]) \n              i += 1 \n              i %= len(labels) \n              yield example \n           return fetch_examples\n    training_dataset = tf.data.Dataset.from_generator(\n       data_generator(images, labels),\n       output_types=(tf.float32, tf.int32), \n       output_shapes=(tf.TensorShape(features_shape), tf.TensorShape(labels_shape)))\n    ```", "```py\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\ninput_shape = 50\nmodel = keras.Sequential(\n   [\n      keras.Input(shape=input_shape),\n      layers.Dense(128, activation=\"relu\", name=\"layer1\"),\n      layers.Dense(64, activation=\"relu\", name=\"layer2\"),\n      layers.Dense(1, activation=\"sigmoid\", name=\"layer3\"),\n   ])\n```", "```py\nnum_classes = 5 \ninput_1 = layers.Input(50)\ninput_2 = layers.Input(10)\nx_1 = layers.Dense(128, activation=\"relu\", name=\"layer1x\")(input_1)\nx_1 = layers.Dense(64, activation=\"relu\", name=\"layer1_2x\")(x_1)\nx_2 = layers.Dense(128, activation=\"relu\", name=\"layer2x\")(input_2)\nx_2 = layers.Dense(64, activation=\"relu\", name=\"layer2_1x\")(x_2)\nx = layers.concatenate([x_1, x_2], name=\"concatenate\")\nout = layers.Dense(num_classes, activation=\"softmax\", name=\"output\")(x)\nmodel = keras.Model((input_1,input_2), out)\n```", "```py\nclass SimpleANN(keras.Model):\n   def __init__(self):\n      super().__init__()\n      self.dense_1 = layers.Dense(128, activation=\"relu\", name=\"layer1\")\n      self.dense_2 = layers.Dense(64, activation=\"relu\", name=\"layer2\")\n      self.out = layers.Dense(1, activation=\"sigmoid\", name=\"output\")\n   def call(self, inputs):\n      x = self.dense_1(inputs)\n      x = self.dense_3(x)\n      return self.out(x)\nmodel = SimpleANN()\n```", "```py\nclass SimpleANN(keras.Model):\n   def __init__(self):\n   ...\n   def call(self, inputs):\n   ...\n   def build_graph(self, raw_shape):\n      x = tf.keras.layers.Input(shape=raw_shape)\n      return keras.Model(inputs=[x], outputs=self.call(x))\n```", "```py\ntf.keras.layers.Dense(units, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)\n```", "```py\nX = layers.Dense(128, name=\"layer2\")(input)\nx = tf.keras.layers.Activation('relu')(x)\n```", "```py\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Layer\nclass CustomDenseLayer(Layer):\n   def __init__(self, units=32):\n      super(SimpleDense, self).__init__()\n      self.units = units\n   def build(self, input_shape):\n      w_init = tf.random_normal_initializer()\n      self.w = tf.Variable(name=\"kernel\", initial_value=w_init(shape=(input_shape[-1], self.units),\n      dtype='float32'),trainable=True)\n      b_init = tf.zeros_initializer()\n      self.b = tf.Variable(name=\"bias\",initial_value=b_init(shape=(self.units,), dtype='float32'),trainable=True)\n   def call(self, inputs):\n      return tf.matmul(inputs, self.w) + self.b\n```", "```py\ntf.keras.layers.MaxPool2D(\n   pool_size=(2, 2), strides=None, padding='valid', data_format=None,\n   kwargs)\ntf.keras.layers.AveragePooling2D(\n   pool_size=(2, 2), strides=None, padding='valid', data_format=None,\n   kwargs)\n```", "```py\ntf.keras.layers.BatchNormalization(\n   axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True,\n   beta_initializer='zeros', gamma_initializer='ones',\n   moving_mean_initializer='zeros',\n   moving_variance_initializer='ones', beta_regularizer=None,\n   gamma_regularizer=None, beta_constraint=None, gamma_constraint=None, **kwargs)\n```", "```py\ntf.keras.layers.Dropout(rate, noise_shape=None, seed=None, **kwargs)\n```", "```py\ntf.keras.layers.Conv2D(\n   filters, kernel_size, strides=(1, 1), padding='valid',\n   data_format=None, dilation_rate=(1, 1), groups=1,\n   activation=None, use_bias=True,\n   kernel_initializer='glorot_uniform',\n   bias_initializer='zeros', kernel_regularizer=None,\n   bias_regularizer=None, activity_regularizer=None,\n   kernel_constraint=None, bias_constraint=None, **kwargs)\n```", "```py\nmodel = Sequential()\nmodel.add(Bidirectional(LSTM(10, return_sequences=True), input_shape=(5, 10)))\nmodel.add(Bidirectional(LSTM(10)))\nmodel.add(Dense(5))\nmodel.add(Activation('softmax'))\n```", "```py\nmodel.fit(\n   x=None, y=None, batch_size=None, epochs=1,\n   verbose='auto', callbacks=None, validation_split=0.0,\n   validation_data=None, shuffle=True,\n   class_weight=None, sample_weight=None, \n   initial_epoch=0, steps_per_epoch=None,\n   validation_steps=None, validation_batch_size=None,\n   validation_freq=1, max_queue_size=10, workers=1,\n   use_multiprocessing=False)\n```", "```py\nOptimizer = tf.keras.optimizers.Adam()\nloss_fn = tf.keras.losses.CategoricalCrossentropy()\ntrain_acc_metric = tf.keras.metrics.CategoricalAccuracy()\nfor epoch in range(epochs):\n   for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n       with tf.GradientTape() as tape:\n          logits = model(x_batch_train, training=True)\n          loss_value = loss_fn(y_batch_train, logits)\n       grads = tape.gradient(loss_value, model.trainable_weights)\n       optimizer.apply_gradients(zip(grads, model.trainable_weights))\n       train_acc_metric.update_state(y, logits)\n```", "```py\nmodel.compile(loss=tf.keras.losses.BinaryFocalCrossentropy(gamma=2.0, from_logits=True), ...)\n```", "```py\nmodel.compile(loss='sparse_categorical_crossentropy', ...)\n```", "```py\nmse = tf.keras.losses.MeanSquaredError()\n```", "```py\nmae = tf.keras.losses.MeanAbsoluteError()\n```", "```py\ncce = tf.keras.losses.CategoricalCrossentropy()\n```", "```py\nloss = tf.keras.losses.BinaryFocalCrossentropy(from_logits=True)\n```", "```py\ndef custom_huber_loss(threshold=1.0):\n   def huber_fn(y_true, y_pred):\n       error = y_true - y_pred\n       is_small_error = tf.abs(error) < threshold\n       squared_loss = tf.square(error) / 2\n       linear_loss = threshold * tf.abs(error) - threshold**2 / 2\n       return tf.where(is_small_error, squared_loss, linear_loss)\n   return huber_fn\nmodel.compile(loss=custom_huber_loss (2.0), optimizer=\"adam\"\n```", "```py\nclass CustomLoss(tf.keras.losses.Loss):\n   def __init__(self, threshold=1.0):\n      super().__init__()\n      self.threshold = threshold\n   def call(self, y_true, y_pred):\n      error = y_true - y_pred \n      is_small_error = tf.abs(error) < threshold\n      squared_loss = tf.square(error) / 2 \n      linear_loss = threshold*tf.abs(error) - threshold**2 / 2 \n      return tf.where(is_small_error, squared_loss, linear_loss)\nmodel.compile(optimizer=\"adam\", loss=CustomLoss(),\n```", "```py\ntf.keras.optimizers.SGD(\n   learning_rate=0.01,\n   momentum=0.0,\n   nesterov=False,\n   name='SGD',\n   kwargs)\n```", "```py\ntf.keras.optimizers.Adam(\n   learning_rate=0.001, beta_1=0.9, beta_2=0.999,\n   epsilon=1e-07, amsgrad=False, name='Adam', **kwargs)\n```", "```py\ntf.keras.callbacks.EarlyStopping(\n   monitor='val_loss', min_delta=0.1, patience=2, \n   verbose=0, mode='min', baseline=None, \n   restore_best_weights=False)\n```", "```py\nclass MappingNetwork(torch.nn.Module):\n   def __init__(self, ...):\n       ...\n       for idx in range(num_layers):\n          in_features = features_list[idx]\n          out_features = features_list[idx + 1]\n          layer = FullyConnectedLayer(in_features, out_features, activation=activation, lr_multiplier= lr_multiplier) setattr(self, f'fc{idx}', layer)\n\n   def forward(self, z, ...):\n       # Embed, normalize, and concat inputs.\n       x = normalize_2nd_moment(z.to(torch.float32))\n\n       # Main layers\n       for idx in range(self.num_layers):\n          layer = getattr(self, f'fc{idx}')\n          x = layer(x)\n       return x\n```", "```py\nclass Generator(torch.nn.Module):\n   def __init__(self, …):\n       self.z_dim = z_dim\n       self.c_dim = c_dim\n       self.w_dim = w_dim\n       self.img_resolution = img_resolution\n       self.img_channels = img_channels\n       self.synthesis = SynthesisNetwork(\n          w_dim=w_dim, \n          img_resolution=img_resolution,\n          img_channels=img_channels,\n          synthesis_kwargs)\n       self.num_ws = self.synthesis.num_ws\n       self.mapping = MappingNetwork(\n          z_dim=z_dim, c_dim=c_dim, w_dim=w_dim,\n          num_ws=self.num_ws, **mapping_kwargs)\n   def forward(self, z, c, truncation_psi=1, truncation_cutoff=None, **synthesis_kwargs):\n       ws = self.mapping(z, c, \n       truncation_psi=truncation_psi, \n       truncation_cutoff=truncation_cutoff)\n       img = self.synthesis(ws, **synthesis_kwargs)\n       return img\n```", "```py\nclass SynthesisNetwork(torch.nn.Module):\n   def __init__(self, ...):\n       for res in self.block_resolutions:\n          block = SynthesisBlock(\n             in_channels, out_channels, w_dim=w_dim,\n             resolution=res, img_channels=img_channels,\n             is_last=is_last, use_fp16=use_fp16,\n             block_kwargs)\n          setattr(self, f'b{res}', block)\n       ...\n   def forward(self, ws, **block_kwargs):\n       ...\n       x = img = None\n       for res, cur_ws in zip(self.block_resolutions, block_ws):\n          block = getattr(self, f'b{res}')\n          x, img = block(x, img, cur_ws, **block_kwargs)\n       return img\n```", "```py\nclass Discriminator(torch.nn.Module):\n   def __init__(self, ...):\n       self.block_resolutions = [2 ** i for i in range(self.img_resolution_log2, 2, -1)]\n       for res in self.block_resolutions:\n          block = DiscriminatorBlock(\n              in_channels, tmp_channels, out_channels,\n              resolution=res,\n              first_layer_idx = cur_layer_idx,\n              use_fp16=use_fp16, **block_kwargs, \n              common_kwargs)\n          setattr(self, f'b{res}', block)\n   def forward(self, img, c, **block_kwargs):\n       x = None\n       for res in self.block_resolutions:\n          block = getattr(self, f'b{res}')\n          x, img = block(x, img, **block_kwargs)\n       return x\n```", "```py\ndef training_loop(...):\n   ...\ntraining_set_iterator = iter(torch.utils.data.DataLoader(dataset=training_set, sampler=training_set_sampler, batch_size=batch_size//num_gpus, **data_loader_kwargs))\n   loss = dnnlib.util.construct_class_by_name(device=device, **ddp_modules, **loss_kwargs) # subclass of training.loss.Loss\n   while True:\n      # Fetch training data.\n      with torch.autograd.profiler.record_function('data_fetch'):\n         phase_real_img, phase_real_c = next(training_set_iterator)\n      # Execute training phases.\n      for phase, phase_gen_z, phase_gen_c in zip(phases, all_gen_z, all_gen_c):\n         # Accumulate gradients over multiple rounds.\n      for round_idx, (real_img, real_c, gen_z, gen_c) in enumerate(zip(phase_real_img, phase_real_c, phase_gen_z, phase_gen_c)):\n         loss.accumulate_gradients(phase=phase.name, real_img=real_img, real_c=real_c, gen_z=gen_z, gen_c=gen_c, sync=sync, gain=gain)\n      # Update weights.\n      phase.module.requires_grad_(False)\n      with torch.autograd.profiler.record_function(phase.name + '_opt'):\n         phase.opt.step()\n```", "```py\ndef Mapping(num_stages, input_shape=512):\n   z = Input(shape=(input_shape))\n   w = PixelNorm()(z)\n   for i in range(8):\n      w = DenseBlock(512, lrmul=0.01)(w)\n      w = LeakyReLU(0.2)(w)\n      w = tf.tile(tf.expand_dims(w, 1), (1,num_stages,1))\n   return Model(z, w, name='mapping') \n```", "```py\nclass PixelNorm(Layer):\n   def __init__(self, epsilon=1e-8):\n      super(PixelNorm, self).__init__()\n      self.epsilon = epsilon                \n   def call(self, input_tensor):\n      return input_tensor / tf.math.sqrt(tf.reduce_mean(input_tensor**2, axis=-1, keepdims=True) + self.epsilon)\n```", "```py\ndef GenBlock(filter_num, res, input_shape, is_base):\n   input_tensor = Input(shape=input_shape, name=f'g_{res}')\n   noise = Input(shape=(res, res, 1), name=f'noise_{res}')\n   w = Input(shape=512)\n   x = input_tensor\n   if not is_base:\n      x = UpSampling2D((2,2))(x)\n      x = ConvBlock(filter_num, 3)(x)\n   x = AddNoise()([x, noise])\n   x = LeakyReLU(0.2)(x)\n   x = InstanceNormalization()(x)\n   x = AdaIN()([x, w])\n   # Adding noise\n   x = ConvBlock(filter_num, 3)(x)\n   x = AddNoise()([x, noise])\n   x = LeakyReLU(0.2)(x)\n   x = InstanceNormalization()(x)                    \n   x = AdaIN()([x, w])\n   return Model([input_tensor, w, noise], x, name=f'genblock_{res}x{res}')\n```", "```py\ndef block(x, res): # res = 2 … resolution_log2\n   with tf.variable_scope('%dx%d' % (2**res, 2**res)):\n       x = act(apply_bias(conv2d(x, fmaps=nf(res-1), kernel=3, gain=gain, use_wscale=use_wscale)))\n       x = act(apply_bias(conv2d_downscale2d(blur(x), fmaps=nf(res-2), kernel=3, gain=gain, use_wscale=use_wscale, fused_scale=fused_scale)))\n   return x\n```"]