- en: Getting Started with Deep Learning Using PyTorch
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用PyTorch入门深度学习
- en: '**Deep learning** (**DL**) has revolutionized industry after industry. It was
    once famously described by Andrew Ng on Twitter as follows:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '**深度学习**（**DL**）已经彻底改变了一个又一个行业。安德鲁·吴曾在Twitter上著名地描述它如下：'
- en: '*"Artificial intelligence is the new electricity!"*'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '*"人工智能是新的电力！"*'
- en: Electricity transformed countless industries; now, **artificial intelligence**
    (**AI**) will do the same.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 电力改变了无数行业；现在，**人工智能**（**AI**）也将如此。
- en: AI and DL are used as synonyms, but there are substantial differences between
    the two. Let's demystify the terminology that's used in the industry so that you,
    as a practitioner, will be able to differentiate between signal and noise.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: AI和DL被用作同义词，但两者之间存在实质性的区别。让我们揭开行业术语的神秘面纱，这样作为从业者的你就能够区分信号和噪音。
- en: 'In this chapter, we will cover the following different parts of AI:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖AI的以下不同部分：
- en: Exploring artificial intelligence
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索人工智能
- en: Machine learning in the real world
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在现实世界中的机器学习
- en: Applications of deep learning
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深度学习的应用
- en: Deep learning frameworks
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深度学习框架
- en: Setting up PyTorch 1.x
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置PyTorch 1.x
- en: Exploring artificial intelligence
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索人工智能
- en: Countless articles discussing AI are published every day. The trend has increased
    in the last 2 years. There are several definitions of AI floating around the web,
    with my favorite being *the* *automation of intellectual tasks normally* *performed
    by humans*.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 每天都有无数篇讨论AI的文章发表。过去两年这一趋势有所增加。网络上有许多关于AI的定义，我最喜欢的是*智能任务的自动化，通常由人类执行*。
- en: The history of AI
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AI的历史
- en: Since you've picked up this book, you may be well aware of the recent hype in
    AI. But it all started when John McCarthy, then a young assistant professor at
    Dartmouth, coined the term *artificial intelligence* in 1995, which he defined
    as a field pertaining to the science and engineering of intelligent machines.
    This kick-started the first wave of AI, which was primarily driven by symbolic
    reasoning; its outcomes were astonishing, to say the least. AI that was developed
    during this time was capable of reading and solving high-school Algebra problems
    [STUDENT], proving theorems in Geometry [SAINT], and learning the English language
    [SHRDLU]. Symbolic reasoning is the use of complex rules nested in if-then statements.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 自从你拿起这本书，你可能已经对AI的最近热潮有所了解。但一切都始于约翰·麦卡锡，当时是达特茅斯学院的年轻助理教授，他在1995年创造了术语*人工智能*，并将其定义为涉及智能机器科学和工程的领域。这掀起了AI的第一波浪潮，主要由符号推理驱动；其成果令人惊叹不已。在此期间开发的AI能够阅读和解决高中代数问题[STUDENT]、证明几何定理[SAINT]以及学习英语语言[SHRDLU]。符号推理是复杂规则嵌套在if-then语句中的使用。
- en: The most promising work in this era, though, was the perceptron, which was introduced
    in 1958 by Frank Rosenblatt. The perceptron, when combined with intelligent optimization techniques
    that were discovered later, laid the foundations for deep learning as we know
    it today.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在这个时代最有前途的工作是感知器，由Frank Rosenblatt于1958年引入。感知器与后来发现的智能优化技术结合，为我们今天所知的深度学习奠定了基础。
- en: It wasn't plain sailing for AI, though, since the funding in the field significantly
    reduced during lean periods, mostly due to overpromising initial discoveries and,
    as we were yet to discover, a lack of data and compute power. The rise in prominence
    of **machine learning** (**ML**) in the early nineties bucked the trend and created
    significant interest in the field. First, we need to understand the paradigm of
    ML and its relationship with DL.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: AI并非一帆风顺，由于初期发现过度宣称以及缺乏数据和计算能力，领域内的资金显著减少。然而，**机器学习**（**ML**）在九十年代初的突出表现扭转了这一趋势，并在该领域引发了极大兴趣。首先，我们需要了解ML的范式及其与DL的关系。
- en: Machine learning in the real world
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在现实世界中的机器学习
- en: ML is a subfield of AI that uses algorithms and statistical techniques to perform
    a task without the use of any explicit instructions. Instead, it relies on underlying
    statistical patterns in the data.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: ML是AI的一个子领域，利用算法和统计技术执行任务，无需任何明确的指令，而是依赖于数据中的统计模式。
- en: To build successful machine learning models, we need to provide ML algorithms
    with labeled data. The success of this approach was heavily dependent on the available
    data and compute power so that large amounts of data could be used.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 要构建成功的机器学习模型，我们需要为 ML 算法提供标记数据。这种方法的成功在很大程度上依赖于可用的数据和计算能力，以便能够使用大量数据。
- en: So, why DL?
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 那么，为什么要用 DL？
- en: Most ML algorithms perform well on structured data, such as sales predictions,
    recommendation systems, and marketing personalization. An important factor for
    any ML algorithm is feature engineering and data scientists need to spend a lot
    of time exploring possible features with high predictive power for ML algorithms.
    In certain domains, such as computer vision and **natural language processing**
    (**NLP**), feature engineering is challenging as features that are important for
    one task may not hold up well for other tasks. This is where DL excels—the algorithm
    itself engineers features in a non-linear space so that they are important for
    a particular task.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数 ML 算法在结构化数据上表现良好，比如销售预测、推荐系统和营销个性化。对于任何 ML 算法来说，特征工程都是一个重要因素，数据科学家需要花费大量时间探索可能对
    ML 算法有高预测力的特征。在某些领域，如计算机视觉和**自然语言处理**（**NLP**），特征工程具有挑战性，因为对于一个任务重要的特征可能对其他任务效果不佳。这就是
    DL 的优势所在——算法本身在非线性空间中工程化特征，使其对特定任务至关重要。
- en: Traditional ML algorithms still outperform DL methods when there is a paucity
    of data, but as data increases, the performance of traditional machine learning
    algorithms tends to plateau and deep learning algorithms tend to significantly
    outperform other learning strategies.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 当数据稀缺时，传统的 ML 算法仍然优于 DL 方法，但随着数据增加，传统机器学习算法的性能往往会趋于平稳，而深度学习算法则往往会显著优于其他学习策略。
- en: 'The following diagram shows the relationship DL has with ML and AI:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图示展示了 DL 与 ML 和 AI 的关系：
- en: '![](img/5af5f990-efc1-438a-adad-f17373307f5b.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5af5f990-efc1-438a-adad-f17373307f5b.png)'
- en: To summarize this, DL is a subfield of machine learning; feature engineering
    is where the algorithm non-linearly explores its space.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，DL 是机器学习的一个子领域；特征工程是算法非线性地探索其空间的地方。
- en: Applications of deep learning
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度学习的应用
- en: DL is at the center of the most important innovations of the 21^(st) century,
    from detecting tumors with a lower error rate than radiologists to self-driving
    cars. Let's quickly look at a few DL applications.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: DL 是 21 世纪最重要创新的中心，从检测肿瘤的误差率低于放射科医生到自动驾驶汽车。让我们快速看一些 DL 应用。
- en: Automatic translation of text from images
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 文字自动翻译图像
- en: 'A 2015 blog from Google details how the team at Google can translate text from
    images. The following image shows the steps involved:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 2015 年谷歌的一篇博客详细介绍了谷歌团队如何从图像中翻译文本。以下图片展示了相关步骤：
- en: '![](img/8c92634a-07ee-4595-b502-5d9ebfc32e10.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8c92634a-07ee-4595-b502-5d9ebfc32e10.png)'
- en: First, a DL algorithm is used to perform **optical character recognition** (**OCR**)
    and recognize the text from the image. Later, another DL algorithm is used to
    translate the text from the source language to the language of choice. The improvements
    we see today in machine translation are attributed to the switch to DL from traditional
    methods.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，DL 算法用于执行**光学字符识别**（**OCR**）并识别图像中的文本。随后，另一个 DL 算法用于将文本从源语言翻译到选择的语言。我们今天看到的机器翻译的改进归因于从传统方法转向
    DL。
- en: Object detection in self-driving cars
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自动驾驶车辆中的目标检测
- en: 'Tesla did a deep dive into their autonomous driving system for investors in
    2019, where they mentioned how they use deep neural networks to detect objects
    from cameras in the car. The output of this algorithm is used by the proprietary
    self-driving policy developed by Tesla:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 特斯拉在2019年向投资者深入介绍了他们的自动驾驶系统，提到了他们如何使用深度神经网络从车辆摄像头中检测物体。该算法的输出被特斯拉开发的专有自动驾驶策略所使用。
- en: '![](img/ec4ad571-9360-44e3-8326-912fd5c7a0e0.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ec4ad571-9360-44e3-8326-912fd5c7a0e0.png)'
- en: The preceding image is the output of an object detection deep learning network.
    The semantic information it has captured from the visual image is crucial for
    self-driving tasks.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的图片是一个目标检测深度学习网络的输出。它从视觉图像中捕获的语义信息对于自动驾驶任务至关重要。
- en: Deep learning frameworks
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度学习框架
- en: 'It used to be extremely hard to write code for deep learning algorithms since
    writing code for the learning step, which involved chaining complex derivatives,
    was extremely error-prone and lengthy. DL frameworks used ingenious heuristics
    to automate the computation of these complex derivatives. The choice of such heuristics
    significantly changes the way these frameworks work. The following diagram shows
    the current ecosystem of DL frameworks:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 以前编写深度学习算法的代码非常困难，因为编写学习步骤的代码（涉及复杂导数链的链接）非常容易出错且冗长。深度学习框架使用巧妙的启发式算法自动计算这些复杂导数。选择这种启发式显著改变了这些框架的工作方式。以下图表显示了当前的深度学习框架生态系统：
- en: '![](img/a9e22904-cd5b-43c5-959c-056577097188.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a9e22904-cd5b-43c5-959c-056577097188.png)'
- en: TensorFlow is the most popular deep learning framework but the simplicity and
    usefulness of PyTorch has made DL research accessible to a lot of people. Let's
    look at why using PyTorch can speed up our DL research and development time significantly.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow是最流行的深度学习框架，但PyTorch的简洁和实用性使得深度学习研究对许多人更加可接近。让我们看看为什么使用PyTorch可以显著加速我们的深度学习研究和开发时间。
- en: Why PyTorch?
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么选择PyTorch？
- en: 'To compute complex chained derivatives, TensorFlow uses a **Define and Run**
    paradigm, whereas PyTorch uses a more ingenuous **Define by Run** paradigm. Let''s
    delve deeper into this by looking at the following image, where we will be computing
    the sum of the series *1 + 1 / 2 + 1 / 4 + 1 / 8 ...*, which should add up to
    2:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow使用**定义然后运行**的范式来计算复杂的链式导数，而PyTorch则使用更聪明的**定义即运行**范式。让我们通过查看下面的图像深入探讨这个问题，我们将计算系列*1
    + 1 / 2 + 1 / 4 + 1 / 8 ...*的总和，结果应该是2：
- en: '![](img/4fdbadfc-20f4-4a8a-a02b-57dc759cf1b5.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4fdbadfc-20f4-4a8a-a02b-57dc759cf1b5.png)'
- en: We can immediately see how succinct and simple it is to write code to perform
    operations in PyTorch. This difference is more widely noticeable in more complex
    scenarios.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以立即看到，在PyTorch中编写操作的代码是多么简洁和简单。在更复杂的场景中，这种差异更加显著。
- en: As the head of AI at Tesla and one of the biggest thought leaders in computer
    vision at the moment, Andrej Karpathy tweeted—*I've been using PyTorch for a few
    months now and I've never felt better. I have more energy. My skin is clearer.
    My eyesight has improved.* PyTorch definitely makes the lives of people writing
    DL code better.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 作为特斯拉人工智能部门的负责人和当前计算机视觉领域最重要的思想领袖之一，Andrej Karpathy发推文说：“我现在已经使用PyTorch几个月了，感觉从未如此之好。我更有精力了。我的皮肤更清爽了。我的视力也有所改善。”
    PyTorch绝对使得编写深度学习代码的人们生活更加美好。
- en: This **Define by Run** paradigm also has many advantages other than just creating
    cleaner and simpler code. Debugging also becomes extremely easy and all of the
    tools that you currently use to debug Python code can be used with PyTorch as
    well. This is a significant advantage because, as networks get more and more complex,
    debugging your networks with ease will be a lifesaver.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这种**定义即运行**的范式除了创建更清晰和简单的代码之外还有许多其他优点。调试也变得极其容易，你当前用于调试Python代码的所有工具也同样适用于PyTorch。这是一个重大优势，因为随着网络变得越来越复杂，轻松调试您的网络将是救命稻草。
- en: What's new in PyTorch v1.x?
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: PyTorch v1.x的新功能有哪些？
- en: PyTorch 1.x expands on its flexibility and tries to unify research and production
    capabilities into a single framework. Caffe2, a production-grade deep learning
    framework, is integrated into PyTorch, allowing us to deploy PyTorch models to
    mobile operating systems and high-performance C++ services. PyTorch v1.0 also
    natively supports exporting models into the ONNX format, which allows PyTorch
    models to be imported into other DL frameworks. It truly is an exciting time to
    be a PyTorch developer!
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch 1.x在其灵活性上有所扩展，并试图将研究和生产能力统一到一个框架中。Caffe2，一个生产级深度学习框架，已集成到PyTorch中，使我们能够将PyTorch模型部署到移动操作系统和高性能C++服务中。PyTorch
    v1.0还原生支持将模型导出为ONNX格式，这使得PyTorch模型可以导入其他深度学习框架。对于PyTorch开发者来说，现在真是令人兴奋的时刻！
- en: CPU versus GPU
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CPU与GPU
- en: 'CPUs have fewer but more powerful compute cores, whereas GPUs have a large
    number of lower-performant cores. CPUs are more suited to sequential tasks, whereas
    GPUs are suitable for tasks with significant parallelization. In summary, a CPU
    can execute large, sequential instructions but can only execute a small number
    of instructions in parallel in contrast to a GPU, which can execute hundreds of
    small instructions in parallel:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: CPU具有较少但更强大的计算核心，而GPU具有大量的性能较低的核心。CPU更适合顺序任务，而GPU适合具有显著并行性的任务。总之，CPU可以执行大型的顺序指令，但在并行执行少量指令方面不如GPU，后者可以并行执行数百个小指令：
- en: '![](img/fd4c49c5-0ffa-4eaf-a81e-69e4735ca792.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
- en: While using DL, we will be performing a large number of linear algebraic operations
    that are more suited to a GPU and can provide a significant boost in terms of
    the time it takes to train a neural network.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: What is CUDA?
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: CUDA is a framework developed by NVIDIA that allows us to use **General Purpose
    Computing on Graphics Processing Units** (**GPGPU**). It is a widely used framework
    written in C++ that allows us to write general-purpose programs that run on GPUs.
    Almost all deep learning frameworks leverage CUDA to execute instructions on GPUs.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: Which GPUs should we use?
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Since most deep learning frameworks, including PyTorch, use NVIDIA''s CUDA
    framework, it is highly recommended that you buy and use a NVIDIA GPU for deep
    learning. Let''s do a quick comparison of a few NVIDIA GPU models:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ecafa3fd-4629-4ba1-8cff-76d2ad6949a6.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
- en: What should you do if you don't have a GPU?
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are a lot of Cloud services such as Azure, AWS, and GCP that provide instances
    that have GPUs and all the required deep learning software preinstalled. FloydHub
    is a great tool for running deep learning models in the cloud. However, the single
    most important tool you should definitely check out is Google's Colaboratory,
    which provides high-performance GPUs for free so that you can run deep learning
    models.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: Setting up PyTorch v1.x
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Throughout this book, we will be using the Anaconda Distribution for Python
    and PyTorch 1.x. You can follow along with the code by executing the relevant
    command based on your current configuration by going to the official PyTorch website
    ([https://pytorch.org/get-started/locally/](https://pytorch.org/get-started/locally/)).
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: Installing PyTorch
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: PyTorch is available as a Python package and you can either use `pip` or `conda` to
    build it. Alternatively, you can build it from the source. The recommended approach
    for this book is to use the Anaconda Python 3 distribution. To install Anaconda,
    please refer to the Anaconda official documentation at [https://conda.io/docs/user-guide/install/index.html](https://conda.io/docs/user-guide/install/index.html).
    All the examples will be available as Jupyter Notebooks in this book's GitHub
    repository. I would strongly recommend that you use Jupyter Notebook since it
    allows you to experiment interactively. If you already have Anaconda Python installed,
    then you can proceed with the following instructions for PyTorch installation.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: 'For GPU-based installation with Cuda 8, use the following command:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'For GPU-based installation with Cuda 7.5, use the following command:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'For non-GPU-based installation, use the following command:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: At the time of writing, PyTorch does not work on Windows machines, so you can
    try a **virtual machine** (**VM**) or Docker image.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we've learned about the history of AI, why we use deep learning,
    multiple frameworks in the deep learning ecosystem, why PyTorch is an important
    tool, why we use GPUs for deep learning, and setting up PyTorch v1.0.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们学习了人工智能的历史，为什么使用深度学习，深度学习生态系统中的多个框架，PyTorch 为何是一个重要工具，为何我们在深度学习中使用 GPU，并且如何设置
    PyTorch v1.0。
- en: In the next chapter, we will delve into the building blocks of neural networks
    and learn how to write PyTorch code to train them.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将深入研究神经网络的构建模块，并学习如何编写 PyTorch 代码来进行训练。
