- en: Beyond Basic Neural Networks - Autoencoders and RBMs
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 超越基本神经网络 - 自编码器和RBM
- en: Now that we have learned how to build and train a simple neural network, we
    should build some models that are suitable for real-world problems.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经学会了如何构建和训练一个简单的神经网络，我们应该构建一些适合实际问题的模型。
- en: In this chapter, we will discuss how to build a model to recognize and generate
    handwriting, as well as perform collaborative filtering.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论如何构建一个能识别和生成手写体的模型，以及执行协同过滤。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Loading data – the **Modified National Institute of Standards and Technology **(**MNIST**)
    database
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加载数据 – **修改的国家标准技术研究所**（**MNIST**）数据库
- en: Building a neural network for handwriting recognition
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 建立手写体识别的神经网络
- en: Building an autoencoder – generating MNIST digits
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 建立自编码器 – 生成MNIST数字
- en: Building a **Restricted Boltzmann Machine** (**RBM**) for Netflix-style collaborative
    filtering
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 建立**受限玻尔兹曼机**（**RBM**）以进行类似Netflix的协同过滤
- en: Loading data – MNIST
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加载数据 – MNIST
- en: Before we can even begin to train or build our model, we first need to get some
    data. As it turns out, a lot of people have made data available online for us
    to use for this purpose. One of the best-curated datasets around is MNIST, which
    we will use for the first two examples in this chapter.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们甚至可以开始训练或构建我们的模型之前，我们首先需要获取一些数据。事实证明，许多人已经在线上提供了可供我们使用的数据。其中一个最好的精选数据集就是MNIST，我们将在本章的前两个示例中使用它。
- en: We'll learn how to download MNIST and load it into our Go program so that we
    can use it in our model.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将学习如何下载MNIST并将其加载到我们的Go程序中，以便在我们的模型中使用。
- en: What is MNIST?
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是MNIST？
- en: Throughout this chapter, we're going to make use of a popular dataset called
    the MNIST database. This has been made available by Yann LeCun, Corinna Cortes,
    and Christopher Burges at [http://yann.lecun.com/exdb/mnist](http://yann.lecun.com/exdb/mnist).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用一个名为MNIST的流行数据集。这个数据集由Yann LeCun、Corinna Cortes和Christopher Burges在[http://yann.lecun.com/exdb/mnist](http://yann.lecun.com/exdb/mnist)上提供。
- en: The database gets its name from the fact that it was made by mixing two databases
    that contain black and white images of handwritten digits. It is an example of
    an ideal dataset that has been preprocessed and formatted nicely for us so that
    we can immediately start using it. When you download it, it is already divided
    into training and testing (validation) sets, with 60,000 labeled examples in the
    training set and 10,000 labeled examples in the test set.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这个数据库因其由两个包含黑白手写数字图像的数据库混合而成的事实而得名。它是一个理想的数据集示例，已经经过预处理和良好的格式化，因此我们可以立即开始使用它。当您下载它时，它已经分成了训练集和测试（验证）集，训练集中有60,000个标记示例，测试集中有10,000个标记示例。
- en: Each image is exactly 28 x 28 pixels and contains a value from 1 to 255 (reflecting
    the pixel intensity or grayscale value). This greatly simplifies things for us,
    as it means that we can immediately put the image into a matrix/tensor and start
    training our models on it.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 每个图像正好是28 x 28像素，包含一个从1到255的值（反映像素强度或灰度值）。这对我们来说非常简化了事情，因为这意味着我们可以立即将图像放入矩阵/张量中，并开始对其进行训练。
- en: Loading MNIST
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加载MNIST
- en: 'Gorgonia comes with an MNIST loader in its `examples` folder, and we can easily use
    this in our code by putting the following in our imports:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: Gorgonia在其`examples`文件夹中带有一个MNIST加载器，我们可以通过将以下内容放入我们的导入中轻松在我们的代码中使用它：
- en: '[PRE0]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Then, we can add the following lines to our code:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以将以下行添加到我们的代码中：
- en: '[PRE1]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This loads our images into a tensor named `inputs` and our labels into a tensor
    named `targets` (given that you have uncompressed the relevant files into an `mnist`
    folder, which should be where your executable is running).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这将我们的图像加载到名为`inputs`的张量中，并将我们的标签加载到名为`targets`的张量中（假设您已将相关文件解压缩到一个名为`mnist`的文件夹中，该文件夹应该在您的可执行文件所在的位置）。
- en: In this example, we are loading the training set of MNIST, so it will produce
    a two-dimensional tensor with a size of 60,000 x 784 for the images, and another
    one with a size of 60,000 x 10 for the labels. The loader in Gorgonia will also
    helpfully rescale all the numbers to be between 0 and 1; we like small, normalized
    numbers when training our models.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们正在加载MNIST的训练集，因此会产生一个大小为60,000 x 784的二维张量用于图像，以及一个大小为60,000 x 10的张量用于标签。Gorgonia中的加载器还会很方便地将所有数字重新缩放到0到1之间；在训练模型时，我们喜欢小而标准化的数字。
- en: Building a neural network for handwriting recognition
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 建立手写体识别的神经网络
- en: Now that we have loaded all that useful data, let's put it to good use. Since
    it's full of handwritten digits, we should most certainly build a model to recognize
    this handwriting and what it says.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经加载了所有这些有用的数据，让我们好好利用它。因为它充满了手写数字，我们应该确实构建一个模型来识别这种手写和它所说的内容。
- en: 'In [Chapter 2](d80f3d0b-0a4e-4695-923c-4feef972214a.xhtml), *What is a Neural
    Network and How Do I Train One**?*, we demonstrated how to build a simple neural
    network. Now, it''s time to build something more substantial: a model for recognizing
    handwriting from the MNIST database.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第2章](d80f3d0b-0a4e-4695-923c-4feef972214a.xhtml)，*什么是神经网络以及如何训练一个*中，我们演示了如何构建一个简单的神经网络。现在，是时候建立更为重要的东西了：一个能够识别MNIST数据库中手写内容的模型。
- en: Introduction to the model structure
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型结构简介
- en: 'First, let''s think back to the original example: we had a single-layer network,
    which we wanted to get from a 4 x 3 matrix to a 4 x 1 vector. Now, we have to
    get from an MNIST image that is 28 x 28 pixels to one single number. This number
    is our network''s guess about which number the image actually represents.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们回顾一下原始示例：我们有一个单层网络，我们希望从一个4x3矩阵得到一个4x1向量。现在，我们必须从一个MNIST图像（28x28像素）得到一个单一的数字。这个数字是我们的网络关于图像实际代表的数字的猜测。
- en: 'The following screenshot represents a rough example of what we can expect to
    find in the MNIST data: some grayscale images of handwritten digits next to their
    labels (which are stored separately):'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图展示了在MNIST数据中可以找到的粗略示例：一些手写数字的灰度图像旁边有它们的标签（这些标签是单独存储的）：
- en: '![](img/5b39bdad-3532-4e10-92e3-71ed72237ed9.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5b39bdad-3532-4e10-92e3-71ed72237ed9.png)'
- en: Layers
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 层
- en: Remember that we are working with tensors, and so we need to relate this data
    back to those data formats. A single image can be a 28 x 28 matrix, or it can
    be a 784 value long vector. Our labels are currently integers from 0 to 9\. However,
    as these are really categorical values—not a continuous numerical value from 0
    to 9—it is best if we turn the results into a vector. Instead of requiring our
    model to produce this outright, we should think of the output as a vector of 10
    values, with a 1 in the position telling us which digit it thinks it is.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，我们正在处理张量数据，因此我们需要将这些数据与那些数据格式联系起来。一个单独的图像可以是一个28x28的矩阵，或者可以是一个784个值的长向量。我们的标签当前是从0到9的整数。然而，由于这些实际上是分类值而不是从0到9的连续数值，最好将结果转换为向量。我们不应该要求我们的模型直接产生这个输出，而是应该将输出视为一个包含10个值的向量，其中位置为1告诉我们它认为是哪个数字。
- en: 'This gives us the parameters that we are working with; we have to input 784
    values, and then get 10 values out of our trained network. For this example, we
    are constructing our layers as per the following diagram:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这为我们提供了正在使用的参数；我们需要输入784个值，然后从我们训练过的网络中获取10个值。例如，我们按照以下图表构建我们的层：
- en: '![](img/e1e90645-3505-49bb-80cf-6b5a953f34fa.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e1e90645-3505-49bb-80cf-6b5a953f34fa.png)'
- en: 'This structure would typically be described as a network with two hidden layers
    of **300** and **100** units each. This can be implemented in Gorgonia with the
    following code:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这种结构通常被描述为具有两个隐藏层，每个层分别有**300**和**100**个单元。这可以用以下代码在Gorgonia中实现：
- en: '[PRE2]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We are also using the ReLU activation function you learned about in [Chapter
    2](d80f3d0b-0a4e-4695-923c-4feef972214a.xhtml), *What Is a Neural Network and
    How Do I Train One?*.As it turns out, ReLU is well suited for this task. So, a
    forward pass of our network looks like the following:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还使用了你在[第2章](d80f3d0b-0a4e-4695-923c-4feef972214a.xhtml)*什么是神经网络以及如何训练一个*中学到的ReLU激活函数。事实证明，ReLU非常适合这个任务。因此，我们网络的前向传播看起来像是这样：
- en: '[PRE3]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'You can see that our network''s final output is passed to the Gorgonia `SoftMax`
    function. This squashes our outputs to a sum of `1` by rescaling all the values
    to a value between `0` and `1`. This is useful as we are using ReLU activation
    units, which can go into very large numbers. We want an easy way to keep our values
    as close as possible to our labels, which look something like the following:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以看到，我们网络的最终输出传递到Gorgonia的`SoftMax`函数。这通过将所有值重新缩放到0到1之间的值来压缩我们的输出总和为1。这非常有用，因为我们使用的ReLU激活单元可能会产生非常大的数值。我们希望有一个简单的方法使我们的值尽可能接近我们的标签，看起来有点像以下内容：
- en: '[PRE4]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'A model trained by `SoftMax` will produce values that are like this:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`SoftMax`训练的模型将产生如下值：
- en: '[PRE5]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: By taking the element of this vector with the maximum value, we can see that
    the predicted label is `4`.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 通过获取具有最大值的向量元素，我们可以看到预测的标签是`4`。
- en: Training
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练
- en: Training a model requires several important components. We have the inputs,
    but we also need to have a loss function and a way to interpret the outputs, as
    well as setting a few other hyperparameters for our model training process.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 训练模型需要几个重要的组件。我们有输入，但我们还需要有损失函数和解释输出的方法，以及设置一些其他模型训练过程中的超参数。
- en: Loss functions
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 损失函数
- en: Loss functions play an important part in training our network. We haven't discussed
    them in much detail, but their role is to tell our model when it gets things wrong,
    so it can learn from its mistakes.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 损失函数在训练我们的网络中发挥了重要作用。虽然我们没有详细讨论它们，但它们的作用是告诉我们的模型什么时候出错，以便它可以从错误中学习。
- en: In this example, we are using a version of cross-entropy loss that has been
    modified to be as efficient as possible.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在本例中，我们使用了经过修改以尽可能高效的方式实现的交叉熵损失版本。
- en: 'It should be noted that cross-entropy loss would typically be expressed in
    pseudocode, such as the following:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 应该注意的是，交叉熵损失通常用伪代码表示，如下所示：
- en: '[PRE6]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'However, in our case, we are going for a simpler version:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在我们的情况下，我们要选择一个更简化的版本：
- en: '[PRE7]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'So, we are implementing the loss function as follows:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，我们正在实现损失函数如下：
- en: '[PRE8]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: As an exercise, you can modify the loss function to the more commonly used cross-entropy
    loss and compare your results.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 作为练习，你可以将损失函数修改为更常用的交叉熵损失，并比较你的结果。
- en: Epochs, iterations, and batch sizes
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Epochs（时期）、iterations（迭代）和batch sizes（批量大小）
- en: As our dataset is much larger now, we need to also think about the practicalities
    of training it. Performing training on an item-by-item basis is fine, but we can
    train items in batches as well. Instead of training on all 60,000 items in MNIST,
    we can split up our data into 600 iterations, with batches of 100 items each.
    For our dataset, this means feeding our model 100 x 784 matrices as input instead
    of a 784-value-long vector. We could also feed it a three-dimensional tensor of
    100 x 28 x 28, but we'll do that in a later chapter when we cover a model architecture
    that makes good use of this structure.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们的数据集现在要大得多，我们也需要考虑如何实际进行训练。逐个项目进行训练是可以的，但我们也可以批量训练项目。与其在MNIST的所有60,000个项目上进行训练，不如将数据分成600次迭代，每次迭代100个项目。对于我们的数据集，这意味着将100
    x 784的矩阵作为输入而不是784个值的长向量。我们也可以将其作为100 x 28 x 28的三维张量输入，但这将在后面的章节中涵盖适合利用这种结构的模型架构时再详细讨论。
- en: 'Since we are doing this in a programming language, we can just build a loop
    as follows:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们是在一个编程语言中进行操作，我们只需构建如下循环：
- en: '[PRE9]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'And then, within each loop, we can insert our logic to extract the necessary
    information to feed into our machine:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在每个循环内，我们可以插入我们的逻辑来提取必要的信息以输入到我们的机器中：
- en: '[PRE10]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Another term you''ll hear a lot in deep learning is epochs. Epochs really just
    run your input data into your data multiple times. If you recall, gradient descent
    is an iterative process: it depends heavily on repetition to converge to the optimal
    solution. This means that we have a simple way to improve our model despite having
    only 60,000 training images: we can repeat the process a number of times until
    our network converges.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在深度学习中，你会经常听到另一个术语，epochs（时期）。Epochs实际上只是多次运行输入数据到你的数据中。如果你回忆一下，梯度下降是一个迭代过程：它非常依赖于重复来收敛到最优解。这意味着我们有一种简单的方法来改进我们的模型，尽管只有60,000张训练图片：我们可以重复这个过程多次，直到我们的网络收敛。
- en: We can certainly manage this in several different ways. For example, we can
    stop repetition when the difference in our loss function between the previous
    epoch and the current epoch is small enough. We can also run a champion-challenger
    approach and take the weights from the epochs that emerge as champions on our
    test set. However, as we want to keep our example simple, we'll pick an arbitrary
    number of epochs; in this case, 100.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们当然可以以几种不同的方式来管理这个问题。例如，当我们的损失函数在前一个epoch和当前epoch之间的差异足够小时，我们可以停止重复。我们还可以运行冠军挑战者方法，并从在我们的测试集上出现为冠军的epochs中取权重。然而，因为我们想保持我们的例子简单，我们将选择一个任意数量的epochs；在这种情况下，是100个。
- en: 'While we''re at it, let''s also add a progress bar so we can watch our model
    train:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们在进行这些操作时，让我们也加上一个进度条，这样我们可以看着我们的模型训练：
- en: '[PRE11]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Testing and validation
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测试和验证
- en: Training is all well and good, but we also need to know whether or not our model
    is actually doing what it claims to be doing. We can reuse our training code,
    but let's make a few changes.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 训练当然很重要，但我们还需要知道我们的模型是否确实在做它声称要做的事情。我们可以重复使用我们的训练代码，但让我们做一些改变。
- en: 'First, let''s remove the `solver` command. We''re testing our model, not training
    it, so we shouldn''t be updating weights:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们删除 `solver` 命令。我们正在测试我们的模型，而不是训练它，所以我们不应该更新权重：
- en: '[PRE12]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Second, let''s actually get an image out of our dataset into a convenient file:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，让我们将数据集中的图像保存到一个便于处理的文件中：
- en: '[PRE13]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'As you can see, the following points are true:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，以下几点是正确的：
- en: '`b` is our batch number'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`b` 是我们的批次号'
- en: '`j` is the item number in said batch'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`j` 是批次中的项目编号'
- en: '`rowLabel` is the MNIST-provided label'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rowLabel` 是由 MNIST 提供的标签'
- en: '`rowGuess` is our model''s guess or prediction'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rowGuess` 是我们模型的猜测或预测'
- en: Now, let's add some ways for us to extract both our data labels and our predictions
    into more human-readable formats (that is, as integers from 0 to 9).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们添加一些方法来将我们的数据标签和预测提取到更易读的格式中（即作为从 0 到 9 的整数）。
- en: 'For our data labels, let''s add the following:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的数据标签，让我们添加以下内容：
- en: '[PRE14]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'For our predictions, we first need to extract them into a familiar format.
    In this case, let''s put them into a tensor so we can reuse all of our earlier
    code:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的预测，我们首先需要将它们提取到熟悉的格式中。在这种情况下，让我们将它们放入一个张量中，这样我们就可以重复使用我们之前的所有代码：
- en: '[PRE15]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Notice that the output coming out of `m.predVal`, which contains our prediction
    values, is an array of `float64`. You can also retrieve the original shape of
    the object, which helps you to make a tensor of the correct shape. In this case,
    we know the shape already, so we'll just put those parameters straight in.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，从 `m.predVal` 输出的结果是包含我们预测值的 `float64` 数组。您也可以检索对象的原始形状，这有助于您创建正确形状的张量。在这种情况下，我们已经知道形状，所以我们直接放入这些参数。
- en: 'The prediction code is, of course, similar to extracting our labels from our
    preprocessed MNIST dataset:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 预测代码当然与从预处理的 MNIST 数据集中提取标签类似：
- en: '[PRE16]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'For all that hard work, you''ll be rewarded with a folder full of image files
    with the following labels and guesses:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 为了所有这些辛勤工作，您将获得一个包含以下标签和猜测的图像文件夹：
- en: '![](img/67b13aba-0122-4f41-9098-22e70d235005.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](img/67b13aba-0122-4f41-9098-22e70d235005.png)'
- en: You'll see that in its current form, our model struggles with some (potentially
    poor) handwriting.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 您会发现，在其当前形式下，我们的模型在处理一些（可能是糟糕的）手写时存在困难。
- en: Taking a closer look
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 仔细观察
- en: 'Alternatively, you may also want to inspect the predictions coming out, in
    order to get a better understanding of what''s happening in your model. In that
    case, you may wish to extract your results into a `.csv` file, which you can do
    with the following code:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，您可能还想检查输出的预测，以更好地理解模型中发生的情况。在这种情况下，您可能希望将结果提取到 `.csv` 文件中，您可以使用以下代码来完成：
- en: '[PRE17]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The output for the offending digit can be seen in the following screenshot and
    code output.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 有问题的数字的输出可以在以下截图和代码输出中看到。
- en: 'The following is the screenshot output:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是截图输出：
- en: '![](img/83c522b4-e303-45c7-95d7-6be78ea024c0.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](img/83c522b4-e303-45c7-95d7-6be78ea024c0.png)'
- en: 'You can also observe the same output in code:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 您也可以在代码中观察相同的输出：
- en: '[PRE18]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Likewise, you can see it wavers from a good guess if only slightly, as shown
    in the following screenshot:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，你可以看到它稍微有所变动，如下截图所示：
- en: '![](img/84ce9f72-9a9a-4ef9-bbc8-384ba1e4bb57.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](img/84ce9f72-9a9a-4ef9-bbc8-384ba1e4bb57.png)'
- en: 'In code format, this is also the same:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在代码格式中，这也是相同的：
- en: '[PRE19]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Exercises
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 练习
- en: 'We''ve expanded our simple example from the [Chapter 2](d80f3d0b-0a4e-4695-923c-4feef972214a.xhtml), *What
    is a Neural Network and How Do I Train One?* quite a bit. At this point, it would
    be a good idea to have a little fun. Try the following and observe for yourself
    what happens, in order to get a better understanding of the impact your choices
    may have. For example, you should try all of the following:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经从[第 2 章](d80f3d0b-0a4e-4695-923c-4feef972214a.xhtml)，*什么是神经网络以及如何训练它？*，扩展了我们的简单示例。此时，尝试一些内容并自行观察结果，以更好地理解您的选择可能产生的影响，将是个好主意。例如，您应该尝试以下所有内容：
- en: Change the loss function
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更改损失函数
- en: Change the number of units in each layer
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更改每层的单元数
- en: Change the number of layers
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更改层数
- en: Change the number of epochs
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更改时期数量
- en: Change the batch size
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更改批次大小
- en: Building an autoencoder – generating MNIST digits
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 建立自编码器 - 生成 MNIST 数字
- en: 'An autoencoder is exactly what it sounds like: it automatically learns how
    to encode data. Typically, the goal for an autoencoder is to train it to automatically
    encode data in fewer dimensions, or to pick out certain details or other useful
    things in the data. It can also be used for removing noise from the data or compressing
    the data.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 自动编码器的作用正如其名：它自动学习如何对数据进行编码。通常，自动编码器的目标是训练它自动将数据编码到更少的维度中，或者提取数据中的某些细节或其他有用的信息。它还可用于去除数据中的噪声或压缩数据。
- en: In general, an autoencoder has two parts; an encoder half and a decoder half.
    We tend to train these two parts in tandem, with the goal being to get the output
    of the decoder to be as close as possible to our inputs.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，自动编码器有两部分：编码器和解码器。我们倾向于同时训练这两部分，目标是使解码器的输出尽可能接近我们的输入。
- en: Layers
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 层
- en: Just like before, we need to consider our input and output. We are using MNIST
    again, since encoding digits is a useful feature. As such, we know that our input
    is 784 pixels, and we know that our output must also have 784 pixels.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 就像之前一样，我们需要考虑我们的输入和输出。我们再次使用MNIST，因为编码数字是一个有用的特征。因此，我们知道我们的输入是784像素，我们也知道我们的输出也必须有784像素。
- en: 'Since we already have helper functions to decode our input and output into
    tensors, we can just leave that work aside and go straight to our neural network.
    Our network is as follows:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们已经有了将输入和输出解码为张量的辅助函数，我们可以直接转向我们的神经网络。我们的网络如下：
- en: '![](img/59013001-e839-43de-83d6-0d5eae84747c.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/59013001-e839-43de-83d6-0d5eae84747c.png)'
- en: 'We can reuse most of our code from the last example and just change up our
    layers:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以重复使用上一个示例中的大部分代码，只需更改我们的层次结构：
- en: '[PRE20]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'However, this time, we won''t use ReLU activation functions, as we know our
    output has to be zeros and ones. We are using the `Sigmoid` activation function,
    as this gives us a convenient output. As you can see in the following code block,
    while we are using it for every layer, you could also just use ReLU activation
    functions everywhere except the last layer, since the output layer should ideally
    be constrained to values between `0` and `1`:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，这次我们不会使用ReLU激活函数，因为我们知道我们的输出必须是0和1。我们使用`Sigmoid`激活函数，因为这给了我们一个方便的输出。正如您在以下代码块中看到的，虽然我们在每一层都使用它，但你也可以在除了最后一层以外的每个地方都使用ReLU激活函数，因为理想情况下，输出层应该被限制在`0`到`1`之间：
- en: '[PRE21]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Training
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练
- en: As before, we need a loss function for training purposes. The input and output
    for an autoencoder are also different!
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 与以前一样，我们需要一个用于训练目的的损失函数。自动编码器的输入和输出也是不同的！
- en: Loss function
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 损失函数
- en: 'This time, our loss function is different. We are using the mean of the squared
    errors that have pseudocode, which looks something like this:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 这次，我们的损失函数不同。我们使用的是均方误差的平均值，其伪代码如下所示：
- en: '[PRE22]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'This can be trivially implemented in Gorgonia as follows:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在Gorgonia中可以轻松实现如下：
- en: '[PRE23]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Input and output
  id: totrans-123
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 输入和输出
- en: 'Note that, this time, our input and output are the same. This means that we
    do not need to get the labels for our dataset and that when we are running the
    virtual machine, we can set both `x` and `y` to be our input data:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，这次我们的输入和输出是相同的。这意味着我们不需要为数据集获取标签，并且在运行虚拟机时，我们可以将`x`和`y`都设置为我们的输入数据：
- en: '[PRE24]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Epochs, iterations, and batch sizes
  id: totrans-126
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 时期、迭代和批次大小
- en: 'This problem is much harder to solve. You''ll find that in order to get a feel
    for how our output improves, running for several epochs is very valuable here
    since we can write our model''s output as the training takes place, with the following
    code:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 这个问题要解决起来更难。您会发现，为了了解我们的输出如何改进，这里非常有价值地运行几个时期，因为我们可以在训练过程中编写我们模型的输出，如下代码：
- en: '[PRE25]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'As we''re training the model, we can now watch it improve over every epoch:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们训练模型的过程中，我们可以观察到它在每个时期的改善：
- en: '![](img/4a955319-e0f1-4444-a4ac-b86763072c17.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/4a955319-e0f1-4444-a4ac-b86763072c17.png)'
- en: You can see that we start with almost pure noise, and then very quickly get
    to a blurry shape, which slowly gets sharper as we progress through the epochs.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到我们从几乎纯噪声开始，然后很快得到一个模糊的形状，随着时期的推移，形状逐渐变得更清晰。
- en: Test and validation
  id: totrans-132
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测试和验证
- en: 'We won''t cover the code for testing in extensive detail as we''ve already
    covered how to get our images out of our output, but note that `y` is now also
    `784` columns wide:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不会详细讨论测试代码，因为我们已经讲过如何从输出中获取图像，但请注意，现在`y`也有`784`列：
- en: '[PRE26]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Now, here''s the fun part; getting results out of our autoencoder:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，这里有个有趣的部分：从我们的自动编码器中获取结果：
- en: '![](img/99aa8eea-c18d-4fb1-b57f-766adac96015.png)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![](img/99aa8eea-c18d-4fb1-b57f-766adac96015.png)'
- en: You'll notice that the results are noticeably less well defined than the input
    images. However, it also removes some of the noise in the images!
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 您会注意到结果与输入图像相比明显不太清晰。然而，它也消除了一些图像中的噪音！
- en: Building an RBM for Netflix-style collaborative filtering
  id: totrans-138
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建类似Netflix风格的协同过滤的RBM
- en: We will now explore a different kind of unsupervised learning technique that,
    in our example, is capable of working with data that reflects a given group of
    users' preferences for particular pieces of content. This section will introduce
    new concepts around network architecture and probability distributions, as well
    as how they can be used in practical implementations of recommendation systems,
    specifically for recommending films that a given user may find interesting.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将探索一种不同的无监督学习技术，例如，能够处理反映特定用户对特定内容喜好的数据。本节将介绍网络架构和概率分布的新概念，以及它们如何在实际推荐系统的实施中使用，特别是用于推荐可能对给定用户感兴趣的电影。
- en: Introduction to RBMs
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: RBM 简介。
- en: By their textbook definition, RBMs are **probabilistic graphical models**, which—given
    what we've already covered regarding the structure of neural networks—simply means
    a bunch of neurons that have weighted connections to another bunch of neurons.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 从教科书的定义来看，RBM 是**概率图模型**，这——考虑到我们已经涵盖的神经网络结构——简单地意味着一群神经元之间存在加权连接。
- en: 'These networks have two layers: a **visible** layer and a **hidden** layer.
    A visible layer is a layer into which you feed the data, and a hidden layer is
    a layer that isn''t exposed to your data directly, but has to develop a meaningful
    representation of it for the task at hand. These tasks include dimensionality
    reduction, collaborative filtering, binary classification, and others. The restricted
    means that the connections are not lateral (that is, between nodes of the same
    layer), but rather that each hidden unit is connected to each visible unit across
    the layers of the network. The graph is undirected, meaning that data is not fixed
    into flowing in one direction. This is illustrated as follows:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 这些网络有两层：一个**可见**层和一个**隐藏**层。可见层是您向其中输入数据的层，隐藏层则是不直接暴露于您的数据，但必须为当前任务开发其有意义的表示的层。这些任务包括降维、协同过滤、二元分类等。受限意味着连接不是横向的（即在同一层的节点之间），而是每个隐藏单元与网络层之间的每个可见单元连接。图是无向的，这意味着数据不能固定在一个方向上流动。如下所示：
- en: '![](img/0da31393-6c89-4254-b0b9-c37b5f52c3a5.png)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0da31393-6c89-4254-b0b9-c37b5f52c3a5.png)'
- en: The training process is fairly straightforward and differs from our vanilla
    neural networks in that we are not only making a prediction, testing the strength
    of that prediction, and then backpropagating the error back through the network.
    In the case of our RBM, this is only half of the story.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 训练过程相对简单，并与我们的普通神经网络不同，我们不仅进行预测、测试预测的强度，然后反向传播错误通过网络。在我们的RBM的情况下，这只是故事的一半。
- en: 'To break the training process down further, a forward pass on an RBM looks
    like this:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 进一步分解训练过程，RBM 的前向传播如下：
- en: Visible layer node values are multiplied by connection weights
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可见层节点值乘以连接权重。
- en: A hidden unit bias is added to the sum of all nodes of the resulting value (forcing
    activations)
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 隐藏单元偏置被添加到结果值的所有节点之和中（强制激活）。
- en: The activation function is applied
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 激活函数被应用。
- en: The value of the hidden node is given (activation probability)
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 给定隐藏节点的值（激活概率）。
- en: Were this a deep network, the output for the hidden layer would be passed on
    as input to another layer. An example of this kind of architecture is a **Deep
    Belief Network** (**DBN**), which is another important piece of work by Geoff
    Hinton and his group at the University of Toronto, that uses multiple RBMs stacked
    on top of each other.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这是一个深度网络，隐藏层的输出将作为另一层的输入传递。这种架构的一个例子是**深度置信网络**（**DBN**），这是由Geoff Hinton及其在多伦多大学的团队完成的另一项重要工作，它使用多个叠加的RBM。
- en: Our RBM is not, however, a deep network. Thus, we will do something different
    with the hidden unit output. We will use it to attempt to reconstruct the input
    (visible units) of the network. We will do this by using the hidden units as input
    for the backward or reconstruction phase of network training.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们的RBM不是一个深度网络。因此，我们将使用隐藏单元输出做一些与网络的可见单元重构的不同尝试。我们将通过使用隐藏单元作为网络训练的后向或重构阶段的输入来实现这一点。
- en: 'The backward pass looks similar to the forward pass, and is performed by following
    these steps:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 后向传递看起来与前向传递相似，并通过以下步骤执行：
- en: The activation of the hidden layer as input is multiplied by the connection
    weights
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 隐藏层激活作为输入乘以连接权重
- en: The visible unit bias is added to the sum of all nodes of the result from the
    multiplication
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可见单元偏置被添加到所有节点乘积的总和中
- en: Calculate the reconstruction error, or the difference between the predicted
    input, and the actual input (known to us from our forward pass)
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算重构误差，或者预测输入与实际输入（我们从前向传递中了解到的）的差异
- en: The error is used to update the weights in an effort to minimize the reconstruction
    error
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 该错误用于更新权重以尽量减少重构误差
- en: Together, the two states (the predicted activation of the hidden layer and the
    predicted input of the visible layer) form a joint probability distribution.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 两个状态（隐藏层预测激活和可见层预测输入）共同形成联合概率分布。
- en: 'If you''re mathematically inclined, the formulas for both passes are given as
    follows:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您对数学有兴趣，两个传递的公式如下所示：
- en: '**Forward pass**: The probability of a (hidden node activation) is given a
    weighted input, *x*:'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**前向传递**：*a*（隐藏节点激活）的概率给出加权输入*x*：'
- en: '*p(a|x; w)*'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '*p(a|x; w)*'
- en: '**Backward pass**: The probability of *x* (visible layer input) is given a
    weighted activation, *a*:'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**后向传递**：*x*（可见层输入）的概率给出加权激活*a*：'
- en: '*p(x|a; w)*'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '*p(x|a; w)*'
- en: 'The joint probability distribution is therefore given simply by the following:'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 因此，联合概率分布简单地由以下给出：
- en: '*p(a, x)*'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '*p(a, x)*'
- en: 'Reconstruction can thus be thought of differently from the kinds of techniques
    we have discussed so far. It is neither regression (predicting a continuous output
    for a given set of inputs) nor classification (applying a class label for a given
    set of inputs). This is made clear by the way in which we calculate the error
    in the reconstruction phase. We do not merely measure input versus predicted input
    as a real number (a difference of the output); rather, we compare the probability
    distribution for all values of the `x` input versus all values of the *reconstructed*
    input. We use a method called **Kullback-Leibler divergence** to perform this
    comparison. Essentially, this approach measures the area under the curve of each
    probability distribution that does not overlap. We then try to make our weight
    adjustments and rerun the training loop in an attempt to reduce this divergence
    (error), thus bringing the curves closer together, as shown in the following diagram:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 重构因此可以从我们迄今讨论过的技术种类中以不同方式考虑。它既不是回归（为给定的输入集预测连续输出），也不是分类（为给定的输入集应用类标签）。这一点通过我们在重构阶段计算错误的方式来清楚地表现出来。我们不仅仅测量输入与预测输入之间的实数差异（输出的差异）；相反，我们比较所有值的概率分布的*x*输入与*重建*输入的所有值。我们使用一种称为**Kullback-Leibler散度**的方法执行此比较。本质上，这种方法测量每个概率分布曲线下不重叠的面积。然后，我们尝试通过权重调整和重新运行训练循环来减少这种散度（误差），从而使曲线更接近，如下图所示：
- en: '![](img/b661799c-c5b3-4e91-a0cf-65d936f27cc7.png)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b661799c-c5b3-4e91-a0cf-65d936f27cc7.png)'
- en: At the end of the training, when this error has been minimized, we are then
    able to make a prediction about what other films a given user might give the thumbs-up
    to.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练结束时，当这种错误被最小化时，我们可以预测给定用户可能会喜欢哪些其他电影。
- en: RBMs for collaborative filtering
  id: totrans-168
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: RBMs用于协同过滤
- en: As discussed in the introduction to this section, RBMs can be used in a number
    of situations, in either a supervised or unsupervised manner. **Collaborative
    filtering** refers to a strategy for predicting user preferences on the underlying
    assumption that if user *A* likes item *Z*, and user *B* also likes item *Z*,
    then user *B* might also like something else that user *A* likes (say, item *Y*).
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 如本节介绍所讨论的，RBM可以在多种情况下，无论是监督还是非监督方式下使用。**协同过滤**是一种预测用户偏好的策略，其基本假设是如果用户*A*喜欢物品*Z*，并且用户*B*也喜欢物品*Z*，那么用户*B*可能还喜欢用户*A*喜欢的其他东西（例如物品*Y*）。
- en: We see this use case in action every time Netflix recommends something to us
    or every time Amazon recommends us a new vacuum cleaner (because, of course, we
    bought a vacuum cleaner and are now very clearly into domestic appliances).
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 我们每次看到 Netflix 向我们推荐内容时，或每次亚马逊向我们推荐新吸尘器时（因为我们当然买了一个吸尘器，现在显然对家用电器感兴趣）都可以看到这种用例。
- en: So now that we've covered a bit of theory on what RBMs are, how they work, and
    how they are used, let's jump into building one!
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经涵盖了 RBM 是什么、它们如何工作以及它们如何使用的一些理论知识，让我们开始构建一个吧！
- en: Preparing our data – GroupLens movie ratings
  id: totrans-172
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备我们的数据 – GroupLens 电影评分
- en: We are using the GroupLens dataset. It contains a collection of users, movies,
    and ratings collected from MovieLens ([http://www.movielens.org](http://www.movielens.org)),
    and is run by a number of academic researchers at the University of Minnesota.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在使用 GroupLens 数据集。它包含了从 MovieLens（[http://www.movielens.org](http://www.movielens.org)）收集的用户、电影和评分的集合，并由明尼苏达大学的多位学术研究人员管理。
- en: We need to parse the `ratings.dat` file, delimited with a colon, for `userids`,
    `ratings`, and `movieids`. We can then match up `movieids` with those in `movies.dat`.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要解析 `ratings.dat` 文件，该文件使用冒号作为分隔符，以获取 `userids`、`ratings` 和 `movieids`。然后，我们可以将
    `movieids` 与 `movies.dat` 中的电影匹配。
- en: 'First, let''s look at the code we need to build our index of movies:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们看看我们需要构建电影索引的代码：
- en: '[PRE27]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Now, we write a function to import the raw data and turn it into an *m* x *n*
    matrix. In this, the rows represent individual users and the columns are their
    (normalized) ratings across every movie in our dataset:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们编写一个函数来导入原始数据并将其转换为 *m* x *n* 矩阵。在此矩阵中，行代表单个用户，列代表他们在数据集中每部电影上的（归一化）评分：
- en: '[PRE28]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The following is the main loop where we process each line from the CSV, and
    then add to the master slices of users and sub-slices of movie ratings with the
    correct index:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我们处理 CSV 中每行数据并添加到用户主切片和电影评分子切片的主循环：
- en: '[PRE29]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Building an RBM in Gorgonia
  id: totrans-181
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 Gorgonia 中构建 RBM
- en: Now that we've cleaned up our data, created a training or test set, and written
    the code necessary to produce the input required by our network, we can begin
    coding up the RBM itself.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们清理了数据，创建了训练或测试集，并编写了生成网络输入所需的代码后，我们可以开始编写 RBM 本身的代码。
- en: 'First, we begin with our now standard `struct`, the scaffold onto which we
    attach the various components of our network:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们从现在开始使用我们的标准 `struct`，这是我们将网络各组件附加到其中的基础架构：
- en: '[PRE30]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Then, we add the helper functions that attach to our RBM:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们添加附加到我们的 RBM 的辅助函数：
- en: 'First, we add `func` for our `ContrastiveDivergence` learning algorithm (with
    Gibbs sampling):'
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们添加用于我们的 `ContrastiveDivergence` 学习算法（使用 Gibbs 采样）的 `func`：
- en: '[PRE31]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Now, we add functions to sample our respective visible or hidden layers:'
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们添加了函数来采样我们的可见层或隐藏层：
- en: '[PRE32]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Next, we add a couple of functions to handle the propagation of weight updates:'
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接着，我们添加几个处理权重更新传播的函数：
- en: '[PRE33]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Now, we add a function for Gibbs sampling (as used in our previous `ContrastiveDivergence`
    function) as well as a function to perform the reconstruction step in our network:'
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们添加了 Gibbs 采样的函数（与我们之前使用的 `ContrastiveDivergence` 函数相同），以及执行网络重构步骤的函数：
- en: '[PRE34]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'After that, we add the function that instantiates our RBM:'
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们添加实例化我们的 RBM 的函数：
- en: '[PRE35]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Finally, we train the model:'
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们训练模型：
- en: '[PRE36]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Before we execute the code, we need to preprocess our data a little bit. This
    is because the delimiter used in our dataset is `::` but we want to change it
    to `,`. The repository for this chapter includes `preprocess.sh` in the root of
    the folder, which does the following for us:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 在执行代码之前，我们需要对数据进行一些预处理。这是因为我们数据集中使用的分隔符是 `::`，但我们希望将其更改为 `,`。本章节的存储库包含在文件夹根目录中的
    `preprocess.sh`，它会为我们执行以下操作：
- en: '[PRE37]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Now that we have our data formatted nicely, let''s execute the code for our
    RBM and observe the output as follows:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们的数据格式化得很好，让我们执行 RBM 的代码并观察输出如下：
- en: '![](img/89483ba0-81b9-4fc5-af89-96331c709723.png)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
  zh: '![](img/89483ba0-81b9-4fc5-af89-96331c709723.png)'
- en: 'Here, we see our data import functions processing the ratings and movie index
    files, as well as building the per-user vectors of a length of `3706` that index
    all the users'' ratings (normalized to `0`/`1`):'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们看到我们的数据导入函数正在处理评分和电影索引文件，并构建每个用户向量的长度为 `3706` 的用户评分（归一化为 `0`/`1`）：
- en: '![](img/1493bb5a-51fd-497f-b5ad-4f96229aafa2.png)'
  id: totrans-203
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1493bb5a-51fd-497f-b5ad-4f96229aafa2.png)'
- en: After the training phase is complete (here, it is set at 1,000 iterations),
    the RBM generates a set of recommendations for a randomly selected user.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 训练阶段完成后（这里设置为1,000次迭代），RBM会为随机选择的用户生成一组推荐。
- en: You can now experiment with the different hyperparameters and try feeding in
    your own data!
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您可以尝试不同的超参数，并尝试输入您自己的数据！
- en: Summary
  id: totrans-206
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we learned about how to build a simple multilayer neural network
    and an autoencoder. We also explored the design and implementation of a probabilistic
    graphical model, the RBM, used in an unsupervised manner to create a recommendation
    engine for films.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了如何构建一个简单的多层神经网络和自编码器。我们还探讨了概率图模型RBM的设计和实现，以无监督方式创建电影推荐引擎。
- en: It is highly recommended that you try these models and architectures on other
    pieces of data to see how they perform.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 强烈建议您尝试将这些模型和架构应用于其他数据片段，以查看它们的表现如何。
- en: In the next chapter, we will have a look at the hardware side of deep learning,
    and also find out how exactly CPUs and GPUs serve our computational needs.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将看一下深度学习的硬件方面，以及CPU和GPU如何确切地满足我们的计算需求。
- en: Further reading
  id: totrans-210
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: '*Restricted Boltzmann Machines for Collaborative Filtering*, the original paper
    of the research group at the University of Toronto, available at [https://www.cs.toronto.edu/~rsalakhu/papers/rbmcf.pdf](https://www.cs.toronto.edu/~rsalakhu/papers/rbmcf.pdf)'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*协同过滤的限制玻尔兹曼机*，这是多伦多大学研究小组的原始论文，可以在[https://www.cs.toronto.edu/~rsalakhu/papers/rbmcf.pdf](https://www.cs.toronto.edu/~rsalakhu/papers/rbmcf.pdf)查阅。'
- en: '*Restricted Boltzmann Machines Modeling Human Choice*, a paper that explores
    the notion that RBMs are effective at modeling *human choice* (in our example,
    a preference for a type of film), and suggests applications in other fields such
    as psychology, available at[://papers.nips.cc/paper/5280-restricted-boltzmann-machines-modeling-human-choice.pdf](https://papers.nips.cc/paper/5280-restricted-boltzmann-machines-modeling-human-choice.pdf)'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*限制玻尔兹曼机模拟人类选择*，这篇论文探讨了限制玻尔兹曼机在建模*人类选择*（例如我们例子中对某种类型电影的偏好）方面的有效性，并提出了在心理学等其他领域的应用，可在[://papers.nips.cc/paper/5280-restricted-boltzmann-machines-modeling-human-choice.pdf](https://papers.nips.cc/paper/5280-restricted-boltzmann-machines-modeling-human-choice.pdf)查阅。'
